{
    "Progress measures for grokking via mechanistic interpretability": {
        "filename": "Progress measures for grokking via mechanistic interpretability.pdf",
        "analysis": {
            "benchmarks": [
                "modular addition task"
            ],
            "base_models": [
                "small transformers (one-layer, ReLU, 128-dimensional embeddings, 4 attention heads, 512 hidden units in MLP)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning Language Representations with Logical Inductive Bias": {
        "filename": "Learning Language Representations with Logical Inductive Bias.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SQuAD 2.0",
                "FOLIO"
            ],
            "base_models": [
                "BERT (110M)",
                "RoBERTa (110M)",
                "DeBERTa (134M)",
                "ALBERT XXL (235M)",
                "Megatron (1.3B)",
                "Megatron (3.9B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGPT Asks BLIP-2 Answers Automatic Questioning Towards Enriched Visual Descriptions": {
        "filename": "ChatGPT Asks BLIP-2 Answers Automatic Questioning Towards Enriched Visual Descriptions.pdf",
        "analysis": {
            "benchmarks": [
                "COCO",
                "Conceptual Caption",
                "WikiArt"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "BLIP-2 (with FLAN-T5 11B and ViT-G/14)"
            ]
        }
    },
    "BadLlama cheaply removing safety fine-tuning from Llama 2-Chat 13B": {
        "filename": "BadLlama cheaply removing safety fine-tuning from Llama 2-Chat 13B.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench",
                "RefusalBench"
            ],
            "base_models": [
                "Llama 2-Chat 13B"
            ]
        }
    },
    "Sleeper Social Bots a new generation of AI disinformation bots are already a political threat": {
        "filename": "Sleeper Social Bots a new generation of AI disinformation bots are already a political threat.pdf",
        "analysis": {
            "benchmarks": [
                "Private Mastodon server"
            ],
            "base_models": [
                "GPT-4 Turbo"
            ]
        }
    },
    "PromptNER Prompting For Named Entity Recognition": {
        "filename": "PromptNER Prompting For Named Entity Recognition.pdf",
        "analysis": {
            "benchmarks": [
                "CoNLL",
                "GENIA",
                "FewNERD",
                "CrossNER"
            ],
            "base_models": [
                "T5-XXL (11B)",
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "WikiWhy Answering and Explaining Cause-and-Effect Questions": {
        "filename": "WikiWhy Answering and Explaining Cause-and-Effect Questions.pdf",
        "analysis": {
            "benchmarks": [
                "WIKIWHY"
            ],
            "base_models": [
                "GPT-3 (DaVinci-002)",
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding the Effect of Noise in LLM Training Data with Algorithmic Chains of Thought": {
        "filename": "Understanding the Effect of Noise in LLM Training Data with Algorithmic Chains of Thought.pdf",
        "analysis": {
            "benchmarks": [
                "Traced Integer (TInt) framework"
            ],
            "base_models": [
                "Pythia-410m"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Compiler Optimization": {
        "filename": "Large Language Models for Compiler Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "AI-SOCO",
                "ExeBench",
                "POJ-104",
                "Transcoder",
                "CSmith",
                "YARPGen"
            ],
            "base_models": [
                "LLaMa 2 (7B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distilling mathematical reasoning capabilities into Small Language Models": {
        "filename": "Distilling mathematical reasoning capabilities into Small Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "ASDiv",
                "SVAMP",
                "MultiArith"
            ],
            "base_models": [
                "GPT-4",
                "PaLM-2",
                "ChatGPT (gpt-3.5-turbo)",
                "CodeT5-Small (60M)",
                "CodeT5-Base (220M)",
                "CodeT5-Large (770M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InternLM-Math Open Math Large Language Models Toward Verifiable Reasoning": {
        "filename": "InternLM-Math Open Math Large Language Models Toward Verifiable Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "Hungary math exam",
                "MathBench-ZH",
                "MiniF2F"
            ],
            "base_models": [
                "InternLM2-Base-7B",
                "InternLM2-Base-20B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rethinking Decision Transformer via Hierarchical Reinforcement Learning": {
        "filename": "Rethinking Decision Transformer via Hierarchical Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Gym-Mujoco",
                "AntMaze",
                "FrankaKitchen"
            ],
            "base_models": [
                "Decision Transformer (DT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Impact of LLM-based Review Comment Generation in Practice A Mixed Open-Closed-source User Study": {
        "filename": "Impact of LLM-based Review Comment Generation in Practice A Mixed Open-Closed-source User Study.pdf",
        "analysis": {
            "benchmarks": [
                "Mozilla",
                "Ubisoft"
            ],
            "base_models": [
                "GPT4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On Overcoming Miscalibrated Conversational Priors in LLM-based Chatbots": {
        "filename": "On Overcoming Miscalibrated Conversational Priors in LLM-based Chatbots.pdf",
        "analysis": {
            "benchmarks": [
                "OpenAssistant dataset"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Functional Benchmarks for Robust Evaluation of Reasoning Performance and the Reasoning Gap": {
        "filename": "Functional Benchmarks for Robust Evaluation of Reasoning Performance and the Reasoning Gap.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "MATH()"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude 2.1",
                "Mixtral Medium 7x8B MoE",
                "Mixtral 7x8B MoE Instruct",
                "LLaMA 2 70B",
                "WizardCoder Python 34B",
                "Yi 34B",
                "Yi Chat 34B",
                "StripedHypena Nous 7B",
                "Hessian 7B",
                "Qwen 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Energy-Based Diffusion Language Models for Text Generation": {
        "filename": "Energy-Based Diffusion Language Models for Text Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Text8",
                "OpenWebText"
            ],
            "base_models": [
                "Transformer AR",
                "MDLM (Masked Diffusion Language Model)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InstructRAG Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales": {
        "filename": "InstructRAG Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales.pdf",
        "analysis": {
            "benchmarks": [
                "PopQA",
                "TriviaQA",
                "Natural Questions",
                "ASQA",
                "2WikiMultiHopQA"
            ],
            "base_models": [
                "Meta-Llama-3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "StructuredRAG JSON Response Formatting with Large Language Models": {
        "filename": "StructuredRAG JSON Response Formatting with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "StructuredRAG",
                "WikiQuestions"
            ],
            "base_models": [
                "Gemini 1.5 Pro",
                "Llama 3 8B-instruct (4-bit quantization)"
            ]
        }
    },
    "FrugalGPT How to Use Large Language Models While Reducing Cost and Improving Performance": {
        "filename": "FrugalGPT How to Use Large Language Models While Reducing Cost and Improving Performance.pdf",
        "analysis": {
            "benchmarks": [
                "HEADLINES",
                "OVERRULING",
                "COQA"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "GPT-3",
                "GPT-J",
                "J1-Jumbo",
                "J1-Grande",
                "J1-Large",
                "GPT-Neo",
                "GPT-Curie",
                "Cohere Xlarge",
                "ForeFrontAI QA",
                "FAIRSEQ"
            ]
        }
    },
    "Beyond Classification Financial Reasoning in State-of-the-Art Language Models": {
        "filename": "Beyond Classification Financial Reasoning in State-of-the-Art Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "sFIOG (Synthetic-Financial Investment Opinion Generation)"
            ],
            "base_models": [
                "GPT-J (6B)",
                "Pythia (2.8B)",
                "Galactica (6.7B)",
                "LLama (13B)"
            ]
        }
    },
    "Math Word Problem Solving by Generating Linguistic Variants of Problem Statements": {
        "filename": "Math Word Problem Solving by Generating Linguistic Variants of Problem Statements.pdf",
        "analysis": {
            "benchmarks": [
                "MAWPS",
                "SVAMP",
                "PARAMAWPS"
            ],
            "base_models": [
                "DeBERTa",
                "GPT-3 (175B)",
                "GPT-3.5-turbo (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automating Customer Needs Analysis A Comparative Study of Large Language Models in the Travel Industry": {
        "filename": "Automating Customer Needs Analysis A Comparative Study of Large Language Models in the Travel Industry.pdf",
        "analysis": {
            "benchmarks": [
                "TripAdvisor posts"
            ],
            "base_models": [
                "GPT-4",
                "Gemini 1.0",
                "GPT-3.5 (175 billion)",
                "Llama 2 7B Chat (7 billion)",
                "Llama 2 13B Chat (13 billion)",
                "Mistral 7B Instruct (7 billion)",
                "Mixtral 8x7B (46.7 billion)",
                "Phi-2 (2.7 billion)",
                "Gemma 7B (7 billion)"
            ]
        }
    },
    "Towards Unlocking Insights from Logbooks Using AI": {
        "filename": "Towards Unlocking Insights from Logbooks Using AI.pdf",
        "analysis": {
            "benchmarks": [
                "eLogs for major accelerator facilities",
                "CERN internal documentation"
            ],
            "base_models": [
                "llama2-70b",
                "mixtral-8x7b-instruct-v0.1",
                "Mistral-7B-Instruct-v0.2",
                "all-MiniLM-L6-v2",
                "all-mpnet-base-v2"
            ]
        }
    },
    "Dissociating language and thought in large language models a cognitive perspective": {
        "filename": "Dissociating language and thought in large language models a cognitive perspective.pdf",
        "analysis": {
            "benchmarks": [
                "BLiMP",
                "SyntaxGym"
            ],
            "base_models": [
                "GPT-2",
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Polymath A Challenging Multi-modal Mathematical Reasoning Benchmark": {
        "filename": "Polymath A Challenging Multi-modal Mathematical Reasoning Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "POLYMATH"
            ],
            "base_models": [
                "Claude-3.5 Sonnet",
                "GPT-4o",
                "Gemini-1.5 Pro",
                "LLaV A (34B)",
                "ShareGPT4V (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "StarCoder may the source be with you": {
        "filename": "StarCoder may the source be with you.pdf",
        "analysis": {
            "benchmarks": [],
            "models": [],
            "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
        }
    },
    "IfQA A Dataset for Open-domain Question Answering under Counterfactual Presuppositions": {
        "filename": "IfQA A Dataset for Open-domain Question Answering under Counterfactual Presuppositions.pdf",
        "analysis": {
            "benchmarks": [
                "IfQA"
            ],
            "base_models": [
                "GPT-3",
                "RAG",
                "FiD"
            ]
        }
    },
    "Multi-step Jailbreaking Privacy Attacks on ChatGPT": {
        "filename": "Multi-step Jailbreaking Privacy Attacks on ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "Enron Email Dataset",
                "Institutional Pages"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "New Bing (ChatGPT-enhanced)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization": {
        "filename": "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization.pdf",
        "analysis": {
            "benchmarks": [
                "NLV-Corpus",
                "Quda"
            ],
            "base_models": [
                "GPT-4",
                "Gemini-Pro",
                "Llama3 (70B)",
                "Mixtral (46.7B)"
            ]
        }
    },
    "A Survey on Measuring and Mitigating Reasoning Shortcuts in Machine Reading Comprehension": {
        "filename": "A Survey on Measuring and Mitigating Reasoning Shortcuts in Machine Reading Comprehension.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "RACE",
                "HotpotQA",
                "DROP",
                "MuSiQue",
                "STREET"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "XLNet",
                "ALBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HuggingGPT Solving AI Tasks with ChatGPT and its Friends in Hugging Face": {
        "filename": "HuggingGPT Solving AI Tasks with ChatGPT and its Friends in Hugging Face.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exposing Attention Glitches with Flip-Flop Language Modeling": {
        "filename": "Exposing Attention Glitches with Flip-Flop Language Modeling.pdf",
        "analysis": {
            "benchmarks": [
                "FFLM (Flip-Flop Language Modeling)",
                "Long Range Arena",
                "BIG-Bench"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "GPT-NeoX 20B",
                "Pythia 12B",
                "GPT-2 1.5B",
                "GPT-2 774M",
                "GPT-2 117M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Active Learning Principles for In-Context Learning with Large Language Models": {
        "filename": "Active Learning Principles for In-Context Learning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Crossfit (15 classification and 9 multi-choice tasks)"
            ],
            "base_models": [
                "GPT-2 (124M)",
                "GPT-Neox (20B)",
                "GPT (125M to 30B)",
                "OPT (125M to 30B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "STBLLM Breaking the 1-Bit Barrier with Structured Binary LLMs": {
        "filename": "STBLLM Breaking the 1-Bit Barrier with Structured Binary LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Wikitext2",
                "Winogrande",
                "OBQA",
                "Hellaswag",
                "BoolQ",
                "ARC-e",
                "ARC-c",
                "RTE"
            ],
            "base_models": [
                "LLaMA-1",
                "LLaMA-2",
                "LLaMA-3",
                "OPT",
                "Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement": {
        "filename": "Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement.pdf",
        "analysis": {
            "benchmarks": [
                "DEBUG EVAL"
            ],
            "base_models": [
                "GPT-4o-mini (size not specified)",
                "GPT-3.5-Turbo (size not specified)",
                "DeepSeek-V2-0628 (236B)",
                "DeepSeek-Coder-V2-0724 (236B)",
                "Llama3-70B-Ins",
                "Qwen2-72B-Ins",
                "DSCoder-33B-Ins",
                "Llama2-7B-Ins",
                "CodeLlama-7B-Ins",
                "CodeQwen1.5-7B-Ins",
                "DeepSeek-LLM-7B-Ins",
                "DSCoder-6.7B-Ins",
                "Llama3-8B-Ins"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Advancing GenAI Assisted Programming-A Comparative Study on Prompt Efficiency and Code Quality Between GPT-4 and GLM-4": {
        "filename": "Advancing GenAI Assisted Programming-A Comparative Study on Prompt Efficiency and Code Quality Between GPT-4 and GLM-4.pdf",
        "analysis": {
            "benchmarks": [
                "Snake game"
            ],
            "base_models": [
                "GPT-4",
                "GLM-4"
            ]
        }
    },
    "Improving In-Context Learning in Diffusion Models with Visual Context-Modulated Prompts": {
        "filename": "Improving In-Context Learning in Diffusion Models with Visual Context-Modulated Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "Instruct Pixel-to-Pixel dataset",
                "MultiGen-20M dataset"
            ],
            "base_models": [
                "Stable Diffusion",
                "ControlNet",
                "CLIP",
                "Vision Transformer (ViT-L/14)"
            ]
        }
    },
    "LLM-DERA Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain": {
        "filename": "LLM-DERA Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain.pdf",
        "analysis": {
            "benchmarks": [
                "Resume",
                "Coal"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "QASnowball An Iterative Bootstrapping Framework for High-Quality Question-Answering Data Generation": {
        "filename": "QASnowball An Iterative Bootstrapping Framework for High-Quality Question-Answering Data Generation.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "TriviaQA-wiki",
                "TriviaQA-web",
                "HotpotQA",
                "CMRC",
                "DuReader",
                "SQuAD-zh",
                "DRCD"
            ],
            "base_models": [
                "BERT",
                "T5",
                "PERT"
            ]
        }
    },
    "Thought Cloning Learning to Think while Acting by Imitating Human Thinking": {
        "filename": "Thought Cloning Learning to Think while Acting by Imitating Human Thinking.pdf",
        "analysis": {
            "benchmarks": [
                "BabyAI"
            ],
            "base_models": [
                "BabyAI 1.1 model architecture (LSTM-based)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NLPBench Evaluating Large Language Models on Solving NLP Problems": {
        "filename": "NLPBench Evaluating Large Language Models on Solving NLP Problems.pdf",
        "analysis": {
            "benchmarks": [
                "NLPBench"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM-2",
                "LLAMA-2 (13b)",
                "LLAMA-2 (70b)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Synthetic Prompting Generating Chain-of-Thought Demonstrations for Large Language Models": {
        "filename": "Synthetic Prompting Generating Chain-of-Thought Demonstrations for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "GSM-Hard",
                "SVAMP",
                "ASDiv",
                "SingleOp",
                "Colored Objects",
                "Repeat Copy"
            ],
            "base_models": [
                "InstructGPT (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LProtector An LLM-driven Vulnerability Detection System": {
        "filename": "LProtector An LLM-driven Vulnerability Detection System.pdf",
        "analysis": {
            "benchmarks": [
                "Big-Vul dataset"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "Introspective Planning Aligning Robots Uncertainty with Inherent Task Ambiguity": {
        "filename": "Introspective Planning Aligning Robots Uncertainty with Inherent Task Ambiguity.pdf",
        "analysis": {
            "benchmarks": [
                "Safe Mobile Manipulation",
                "Mobile Manipulation"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language model acceptability judgements are not always robust to context": {
        "filename": "Language model acceptability judgements are not always robust to context.pdf",
        "analysis": {
            "benchmarks": [
                "BLiMP",
                "SyntaxGym"
            ],
            "base_models": [
                "GPT-2",
                "OPT-125M",
                "OPT-350M",
                "OPT-1.3B",
                "OPT-2.7B",
                "OPT-6.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AlphaBlock Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation": {
        "filename": "AlphaBlock Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "AlphaBlock"
            ],
            "base_models": [
                "MiniGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Encyclopedic VQA Visual questions about detailed properties of fine-grained categories": {
        "filename": "Encyclopedic VQA Visual questions about detailed properties of fine-grained categories.pdf",
        "analysis": {
            "benchmarks": [
                "Encyclopedic-VQA",
                "OK-VQA"
            ],
            "base_models": [
                "PaLI (17B)",
                "PaLM",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding Social Reasoning in Language Models with Language Models": {
        "filename": "Understanding Social Reasoning in Language Models with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BigToM",
                "SocialIQA"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-65B",
                "text-davinci-003",
                "gpt-3.5-turbo",
                "Claude-v1.3",
                "Claude-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Truth or Deceit A Bayesian Decoding Game Enhances Consistency and Reliability": {
        "filename": "Truth or Deceit A Bayesian Decoding Game Enhances Consistency and Reliability.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "ARC-Easy",
                "ARC-Challenge",
                "RACE-High",
                "GSM8K",
                "PubMedQA",
                "MMLU-Medical",
                "Ethics"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Selection Matters Enhancing Text Annotations for Social Sciences with Large Language Models": {
        "filename": "Prompt Selection Matters Enhancing Text Annotations for Social Sciences with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TweetEval - hate",
                "TweetEval - emotion",
                "TweetEval - sentiment",
                "TweetEval - offensive",
                "Tweet Sentiment Multilingual",
                "Article Bias Prediction",
                "Liberals vs Conservatives on Reddit"
            ],
            "base_models": [
                "GPT-3.5 Turbo"
            ]
        }
    },
    "Disinformation Detection An Evolving Challenge in the Age of LLMs": {
        "filename": "Disinformation Detection An Evolving Challenge in the Age of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Fake and Real News Dataset"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5 and 4)",
                "RoBERTa"
            ]
        }
    },
    "OpenCity A Scalable Platform to Simulate Urban Activities with Massive LLM Agents": {
        "filename": "OpenCity A Scalable Platform to Simulate Urban Activities with Massive LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Beijing urban mobility data",
                "New York Safegraph data",
                "San Francisco Safegraph data",
                "London Foursquare data",
                "Paris Foursquare data",
                "Sydney Foursquare data"
            ],
            "base_models": [
                "GPT-4o-mini",
                "GPT-4o"
            ]
        }
    },
    "A Survey on Knowledge Distillation of Large Language Models": {
        "filename": "A Survey on Knowledge Distillation of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Gemini",
                "Claude",
                "LLaMA-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ClarifyGPT Empowering LLM-based Code Generation with Intention Clarification": {
        "filename": "ClarifyGPT Empowering LLM-based Code Generation with Intention Clarification.pdf",
        "analysis": {
            "benchmarks": [
                "MBPP-sanitized",
                "MBPP-ET",
                "HumanEval",
                "HumanEval-ET"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Template Filling for Controllable Commonsense Reasoning": {
        "filename": "Template Filling for Controllable Commonsense Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "commonsenseqa"
            ],
            "base_models": [
                "BART-BASE (139M params)",
                "BART-LARGE (406M params)",
                "T5-BASE (220M params)",
                "T5-LARGE (770M params)"
            ]
        }
    },
    "Aligning Modalities in Vision Large Language Models via Preference Fine-tuning": {
        "filename": "Aligning Modalities in Vision Large Language Models via Preference Fine-tuning.pdf",
        "analysis": {
            "benchmarks": [
                "SciQA-IMG",
                "MMBench",
                "MM-Vet",
                "LLaVA-Bench",
                "CHAIR",
                "POPE",
                "MMHal"
            ],
            "base_models": [
                "LLaVA-1.5 (7B)",
                "GPT-4V"
            ]
        }
    },
    "Dysen-VDM Empowering Dynamics-Aware Text-to-Video Diffusion with LLMs": {
        "filename": "Dysen-VDM Empowering Dynamics-Aware Text-to-Video Diffusion with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "UCF-101",
                "MSR-VTT",
                "ActivityNet"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5/GPT-4)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Inference Optimizations for Large Language Models Effects Challenges and Practical Considerations": {
        "filename": "Inference Optimizations for Large Language Models Effects Challenges and Practical Considerations.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "SST-2"
            ],
            "base_models": [
                "RoBERTa",
                "DistillBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How to think step-by-step A mechanistic understanding of chain-of-thought reasoning": {
        "filename": "How to think step-by-step A mechanistic understanding of chain-of-thought reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "PrOntoQA"
            ],
            "base_models": [
                "Llama-2 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PIVOT Iterative Visual Prompting Elicits Actionable Knowledge for VLMs": {
        "filename": "PIVOT Iterative Visual Prompting Elicits Actionable Knowledge for VLMs.pdf",
        "analysis": {
            "benchmarks": [
                "RefCOCO"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SignEye Traffic Sign Interpretation from Vehicle First-Person View": {
        "filename": "SignEye Traffic Sign Interpretation from Vehicle First-Person View.pdf",
        "analysis": {
            "benchmarks": [
                "Traffic-CN"
            ],
            "base_models": [
                "BLIP-2",
                "MiniGPT-4",
                "LLaVA",
                "Qwen-VL",
                "MiniCPM",
                "SigLIP-ViT",
                "QWen2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ControlLLM Augment Language Models with Tools by Searching on Graphs": {
        "filename": "ControlLLM Augment Language Models with Tools by Searching on Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "custom benchmark with tailored metrics"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Interpretable Mental Health Analysis with Large Language Models": {
        "filename": "Towards Interpretable Mental Health Analysis with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Depression_Reddit (DR)",
                "CLPsych15",
                "Dreaddit",
                "T-SID",
                "SAD",
                "CAMS"
            ],
            "base_models": [
                "ChatGPT (175B)",
                "InstructGPT-3 (13B)",
                "LLaMA-13B",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unpacking Large Language Models with Conceptual Consistency": {
        "filename": "Unpacking Large Language Models with Conceptual Consistency.pdf",
        "analysis": {
            "benchmarks": [
                "CSQA"
            ],
            "base_models": [
                "OPT-350M",
                "OPT-1.3B",
                "OPT-13B",
                "OPT-30B",
                "OPT-66B",
                "GPT-125M",
                "GPT-2.7B",
                "GPT-6B",
                "T0-3B",
                "T0-11B"
            ]
        }
    },
    "Synthetic Context Generation for Question Generation": {
        "filename": "Synthetic Context Generation for Question Generation.pdf",
        "analysis": {
            "benchmarks": [
                "OS-bio dataset",
                "SQuAD"
            ],
            "base_models": [
                "Flan-T5-large",
                "GPT-3.5"
            ]
        }
    },
    "External Reasoning Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback": {
        "filename": "External Reasoning Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude+ (100K token context window)",
                "MPT-30B-chat",
                "Vicuna-33B",
                "Vicuna-13B",
                "Vicuna-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Autonomous Driving LLM4AD Concept Benchmark Simulation and Real-Vehicle Experiment": {
        "filename": "Large Language Models for Autonomous Driving LLM4AD Concept Benchmark Simulation and Real-Vehicle Experiment.pdf",
        "analysis": {
            "benchmarks": [
                "LaMPilot-Bench",
                "CARLA Leaderboard 1.0"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Llama 2 (70B)",
                "PaLM 2 (code-bison)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Formal Mathematical Reasoning A New Frontier in AI": {
        "filename": "Formal Mathematical Reasoning A New Frontier in AI.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "AIMO Progress Prize",
                "AIME"
            ],
            "base_models": [
                "DeepSeekMath-Base 7B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Affordable Generative Agents": {
        "filename": "Affordable Generative Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Stanford Town",
                "VirtualHome"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do GPT Language Models Suffer From Split Personality Disorder The Advent Of Substrate-Free Psychometrics": {
        "filename": "Do GPT Language Models Suffer From Split Personality Disorder The Advent Of Substrate-Free Psychometrics.pdf",
        "analysis": {
            "benchmarks": [
                "Short Dark Triad Inventory",
                "Big Five Inventory",
                "Flourishing Scale",
                "Satisfaction With Life Scale",
                "HEXACO questionnaire",
                "Human Value Scale",
                "Machine Personality Inventory",
                "Ten Item Personality Inventory (TIPI)"
            ],
            "base_models": [
                "GPT-3-175B",
                "InstructGPT",
                "FLAN-T5-XXL",
                "BART",
                "T0++-11B",
                "GPT-Neo-2.7B",
                "GPT-NeoX-20B",
                "GPT-2",
                "TransformerXL",
                "XLNET"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instruction Tuning for Large Language Models A Survey": {
        "filename": "Instruction Tuning for Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "RealToxicityPrompts",
                "MMLU",
                "BBH",
                "TyDiQA",
                "MGSM",
                "User-Oriented-Instructions-252",
                "Vicuna-Instructions",
                "Unnatural Instructions",
                "C-Eval",
                "GSM8K"
            ],
            "base_models": [
                "GPT-3 (176B)",
                "BLOOM (176B)",
                "T5 (11B)",
                "LLaMA (7B)",
                "LLaMA (13B)",
                "LLaMA (65B)",
                "GLM (6B)",
                "OPT (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GraphArena Benchmarking Large Language Models on Graph Computational Problems": {
        "filename": "GraphArena Benchmarking Large Language Models on Graph Computational Problems.pdf",
        "analysis": {
            "benchmarks": [
                "GraphArena"
            ],
            "base_models": [
                "GPT-4o",
                "LLaMA3-70B-Instruct",
                "GPT-3.5",
                "Claude3-haiku",
                "Llama3-8B-Instruct",
                "Qwen1.5-72B-Chat",
                "Qwen1.5-8B-Chat",
                "Gemma-7B",
                "Deepseek-V2 (230B, 21B active)",
                "Mixtral-7x8b (47B, 13B active)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Are Not Strong Abstract Reasoners": {
        "filename": "Large Language Models Are Not Strong Abstract Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "ACRET",
                "ARCT",
                "BIG-Bench-F",
                "Evals-S",
                "PVR",
                "RA VENT"
            ],
            "base_models": [
                "GPT-2 (1.5B)",
                "Text-Davinci-3 (175B)",
                "GPT-3.5-Turbo (175B)",
                "GPT-4",
                "LLaMA-7B",
                "LLaMA2-7B",
                "Alpaca",
                "Alpaca-LoRA",
                "Zephyr-7B-β",
                "RoBERTa-AR",
                "MERIt-AR"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can-Do A Dataset and Neuro-Symbolic Grounded Framework for Embodied Planning with Large Multimodal Models": {
        "filename": "Can-Do A Dataset and Neuro-Symbolic Grounded Framework for Embodied Planning with Large Multimodal Models.pdf",
        "analysis": {
            "benchmarks": [
                "CAN-DO"
            ],
            "base_models": [
                "GPT-4V",
                "Claude Opus",
                "Gemini Pro"
            ]
        }
    },
    "Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering": {
        "filename": "Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM-540B"
            ]
        }
    },
    "Memory Injections Correcting Multi-Hop Reasoning Failures During Inference in Transformer-Based Language Models": {
        "filename": "Memory Injections Correcting Multi-Hop Reasoning Failures During Inference in Transformer-Based Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "2WikiMultiHop",
                "Hand-crafted dataset"
            ],
            "base_models": [
                "GPT2-Small (160M parameters)",
                "GPT2-Large (840M parameters)"
            ]
        }
    },
    "Organizing a Society of Language Models Structures and Mechanisms for Enhanced Collective Intelligence": {
        "filename": "Organizing a Society of Language Models Structures and Mechanisms for Enhanced Collective Intelligence.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT",
                "BERT"
            ]
        }
    },
    "Enhancing Table Recognition with Vision LLMs A Benchmark and Neighbor-Guided Toolchain Reasoner": {
        "filename": "Enhancing Table Recognition with Vision LLMs A Benchmark and Neighbor-Guided Toolchain Reasoner.pdf",
        "analysis": {
            "benchmarks": [
                "SciTSR",
                "PubTabNet",
                "WTW"
            ],
            "base_models": [
                "Phi-3.5-Vision-Instruct",
                "Llama-3.2-90B-Vision-Instruct",
                "GPT-4o-mini",
                "Qwen-VL-Max",
                "GPT-4o",
                "Gemini-1.5-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-context operator learning with data prompts for differential equation problems": {
        "filename": "In-context operator learning with data prompts for differential equation problems.pdf",
        "analysis": {
            "benchmarks": [
                "Forward problem of ODE 1d",
                "Inverse problem of ODE 1",
                "Forward problem of ODE 2d",
                "Inverse problem of ODE 2",
                "Forward problem of ODE 3d",
                "Inverse problem of ODE 3",
                "Forward damped oscillator",
                "Inverse damped oscillator",
                "Forward Poisson equation",
                "Inverse Poisson equation",
                "Forward linear reaction-diffusion",
                "Inverse linear reaction-diffusion",
                "Forward nonlinear reaction-diffusion",
                "Inverse nonlinear reaction-diffusion",
                "MFC g-parameter 1D → 1D",
                "MFC g-parameter 1D → 2D",
                "MFC g-parameter 2D → 2D",
                "MFC ρ0-parameter 1D → 1D",
                "MFC ρ0-parameter 1D → 2D"
            ],
            "base_models": [
                "Transformer (no specific size mentioned)"
            ]
        }
    },
    "What can Large Language Models do in chemistry A comprehensive benchmark on eight tasks": {
        "filename": "What can Large Language Models do in chemistry A comprehensive benchmark on eight tasks.pdf",
        "analysis": {
            "benchmarks": [
                "BBBP",
                "Tox21",
                "PubChem",
                "USPTO",
                "ChEBI"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Davinci-003",
                "Llama",
                "Galactica"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM and Simulation as Bilevel Optimizers A New Paradigm to Advance Physical Scientific Discovery": {
        "filename": "LLM and Simulation as Bilevel Optimizers A New Paradigm to Advance Physical Scientific Discovery.pdf",
        "analysis": {
            "benchmarks": [
                "constitutive law discovery tasks (a-d)",
                "molecule design tasks (e-h)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-3-Sonnet",
                "Mixtral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring the Reliability of Foundation Model-Based Frontier Selection in Zero-Shot Object Goal Navigation": {
        "filename": "Exploring the Reliability of Foundation Model-Based Frontier Selection in Zero-Shot Object Goal Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "RoboTHOR",
                "HM3D"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "BERT"
            ]
        }
    },
    "Can Language Models Teach Weaker Agents Teacher Explanations Improve Students via Personalization": {
        "filename": "Can Language Models Teach Weaker Agents Teacher Explanations Improve Students via Personalization.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "GSM8k",
                "CommonsenseQA"
            ],
            "base_models": [
                "Flan-T5-Large",
                "Flan-T5-XL",
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-65B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Future-Proofing Mobile Networks A Digital Twin Approach to Multi-Signal Management": {
        "filename": "Future-Proofing Mobile Networks A Digital Twin Approach to Multi-Signal Management.pdf",
        "analysis": {
            "benchmarks": [
                "UbiKampus"
            ],
            "base_models": []
        }
    },
    "A Knowledge Engineering Primer": {
        "filename": "A Knowledge Engineering Primer.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GeoGPT Understanding and Processing Geospatial Tasks through An Autonomous GPT": {
        "filename": "GeoGPT Understanding and Processing Geospatial Tasks through An Autonomous GPT.pdf",
        "analysis": {
            "benchmarks": [
                "geospatial data crawling",
                "spatial query",
                "facility siting",
                "mapping"
            ],
            "base_models": [
                "gpt-3.5-turbo"
            ]
        }
    },
    "Controllable Traffic Simulation through LLM-Guided Hierarchical Chain-of-Thought Reasoning": {
        "filename": "Controllable Traffic Simulation through LLM-Guided Hierarchical Chain-of-Thought Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Waymo Open Motion Dataset (WOMD)"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "PROMISE A Framework for Developing Complex Conversational Interactions Technical Report": {
        "filename": "PROMISE A Framework for Developing Complex Conversational Interactions Technical Report.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "Limits of Deep Learning Sequence Modeling through the Lens of Complexity Theory": {
        "filename": "Limits of Deep Learning Sequence Modeling through the Lens of Complexity Theory.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset for function composition tasks",
                "custom dataset for multi-digit multiplication, dynamic programming, and Einstein's puzzle"
            ],
            "base_models": [
                "GPT-4",
                "Jamba (7B)",
                "Mamba (2.8B)",
                "S4-H3 (2.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do you still need a manual smart contract audit": {
        "filename": "Do you still need a manual smart contract audit.pdf",
        "analysis": {
            "benchmarks": [
                "52 DeFi smart contracts",
                "5 newly developed smart contracts with inserted vulnerabilities"
            ],
            "base_models": [
                "GPT-4-32k",
                "Claude-v1.3-100k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DeFine Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning": {
        "filename": "DeFine Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 11,950 earnings call transcripts from S&P 500 and NASDAQ 500 companies"
            ],
            "base_models": [
                "GPT-4o-2024-08-06"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Little Leak Will Sink a Great Ship Survey of Transparency for Large Language Models from Start to Finish": {
        "filename": "A Little Leak Will Sink a Great Ship Survey of Transparency for Large Language Models from Start to Finish.pdf",
        "analysis": {
            "benchmarks": [
                "Huggingface's Datasets (top 100 NLP tasks' test data)"
            ],
            "base_models": [
                "T5 (small, base, large)",
                "LLaMA (7B, 13B, 33B, 65B)",
                "Pythia (70M, 160M, 410M, 1B, 1.4B, 2.8B, 6.9B, 12B)",
                "MPT (7B, 7B-Instruct, 30B, 30B-Instruct)",
                "Falcon (7B, 7B-Instruct, 40B, 40B-Instruct)",
                "OLMo (7B, 7B-Instruct)"
            ]
        }
    },
    "Meaningful Learning Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance": {
        "filename": "Meaningful Learning Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance.pdf",
        "analysis": {
            "benchmarks": [
                "e-CARE",
                "AbsR",
                "AGIEval",
                "RACE",
                "BBH",
                "Com.",
                "MMLU",
                "ARC"
            ],
            "base_models": [
                "LLaMA-2 (7B, 13B)",
                "Orca-2 (7B, 13B)",
                "GPT-3.5 (>20B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Crafting Dynamic Virtual Activities with Advanced Multimodal Models": {
        "filename": "Crafting Dynamic Virtual Activities with Advanced Multimodal Models.pdf",
        "analysis": {
            "benchmarks": [
                "apartment scene",
                "restaurant scene",
                "office scene"
            ],
            "base_models": [
                "GPT-4V"
            ]
        }
    },
    "Autonomous Tree-search Ability of Large Language Models": {
        "filename": "Autonomous Tree-search Ability of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Drop Water Puzzle",
                "Number Path Puzzle",
                "Arithmetic Puzzle",
                "Minimal Grass Puzzle"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "LLaMA2-7B",
                "LLaMA2-13B"
            ]
        }
    },
    "Language models as master equation solvers": {
        "filename": "Language models as master equation solvers.pdf",
        "analysis": {
            "benchmarks": [
                "genetic toggle switch",
                "mRNA turnover",
                "autoregulatory feedback loop",
                "birth-death model"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Affective Faces for Goal-Driven Dyadic Communication": {
        "filename": "Affective Faces for Goal-Driven Dyadic Communication.pdf",
        "analysis": {
            "benchmarks": [
                "The RealTalk Dataset"
            ],
            "base_models": [
                "GPT-3",
                "CLIP ViT-B/32"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chat-REC Towards Interactive and Explainable LLMs-Augmented Recommender System": {
        "filename": "Chat-REC Towards Interactive and Explainable LLMs-Augmented Recommender System.pdf",
        "analysis": {
            "benchmarks": [
                "MovieLens 100K"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "ChatGPT (text-davinci-003)",
                "ChatGPT (text-davinci-002)"
            ]
        }
    },
    "Leveraging Large Language Models for Exploiting ASR Uncertainty": {
        "filename": "Leveraging Large Language Models for Exploiting ASR Uncertainty.pdf",
        "analysis": {
            "benchmarks": [
                "Google Speech Commands (GSC)",
                "internal dataset for device-directed speech detection (DDSD)"
            ],
            "base_models": [
                "Vicuna-7B-v1.3"
            ]
        }
    },
    "Logicbreaks A Framework for Understanding Subversion of Rule-based Inference": {
        "filename": "Logicbreaks A Framework for Understanding Subversion of Rule-based Inference.pdf",
        "analysis": {
            "benchmarks": [
                "Minecraft item-crafting dataset"
            ],
            "base_models": [
                "GPT-2",
                "Llama-2-7B-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LongHealth A Question Answering Benchmark with Long Clinical Documents": {
        "filename": "LongHealth A Question Answering Benchmark with Long Clinical Documents.pdf",
        "analysis": {
            "benchmarks": [
                "LongHealth"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "Yi-6B-200K (6B)",
                "Yi-34B-200k (34B)",
                "vicuna-7b-v1.5-16k (7B)",
                "vicuna-13b-v1.5-16k (13B)",
                "longchat-7b-v1.5-32k (7B)",
                "longchat-13b-16k (13B)",
                "Mistral-7B-Instruct-v0.2 (7B)",
                "Mixtral-8x7B-Instruct-v0.1 (45B)",
                "zephyr-7b-beta-16k (7B)"
            ]
        }
    },
    "Nudging Inference-time Alignment via Model Collaboration": {
        "filename": "Nudging Inference-time Alignment via Model Collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MMLU",
                "just-eval-instruct"
            ],
            "base_models": [
                "Llama-2-70b",
                "Gemma-2-27b",
                "OLMo-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Knowledge Graphs Make Large Language Models More Trustworthy An Empirical Study over Open-ended Question Answering": {
        "filename": "Can Knowledge Graphs Make Large Language Models More Trustworthy An Empirical Study over Open-ended Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "OKGQA",
                "OKGQA-P"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o-mini",
                "Llama-3.1-8B-instruct",
                "Mistral-7B-instruct-v0.3",
                "Gemma-2-9B-it"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Overview of Machine Learning-Enabled Optimization for Reconfigurable Intelligent Surfaces-Aided 6G Networks From Reinforcement Learning to Large Language Models": {
        "filename": "An Overview of Machine Learning-Enabled Optimization for Reconfigurable Intelligent Surfaces-Aided 6G Networks From Reinforcement Learning to Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "ACFIX Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts": {
        "filename": "ACFIX Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts.pdf",
        "analysis": {
            "benchmarks": [
                "ACF IX benchmark dataset of 118 real-world AC vulnerabilities"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Seeing Like an AI How LLMs Apply and Misapply Wikipedia Neutrality Norms": {
        "filename": "Seeing Like an AI How LLMs Apply and Misapply Wikipedia Neutrality Norms.pdf",
        "analysis": {
            "benchmarks": [
                "Wikipedia Neutrality Corpus (WNC)"
            ],
            "base_models": [
                "ChatGPT 3.5",
                "Mistral-Medium",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Smoothie Label Free Language Model Routing": {
        "filename": "Smoothie Label Free Language Model Routing.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "AlpacaEval",
                "MixInstruct",
                "GSM8K",
                "CNN/DailyMail",
                "XSum",
                "TriviaQA",
                "E2E",
                "WebNLG",
                "LegalBench’s Definition Extraction"
            ],
            "base_models": [
                "Pythia-2.8B",
                "Gemma-2B",
                "Incite-3B",
                "Dolly-3B",
                "Llama-2 (7B)",
                "Mistral",
                "Vicuna",
                "Gemma-7B",
                "Nous Capybara",
                "Gemma-7B",
                "Phi-2",
                "Llema-7b",
                "Falcon (1B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "INTRA Interaction Relationship-aware Weakly Supervised Affordance Grounding": {
        "filename": "INTRA Interaction Relationship-aware Weakly Supervised Affordance Grounding.pdf",
        "analysis": {
            "benchmarks": [
                "AGD20K",
                "IIT-AFF",
                "CAD",
                "UMD"
            ],
            "base_models": [
                "DINOv2",
                "ALBEF"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AD-KD Attribution-Driven Knowledge Distillation for Language Model Compression": {
        "filename": "AD-KD Attribution-Driven Knowledge Distillation for Language Model Compression.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "QNLI"
            ],
            "base_models": [
                "BERT (base)",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval-Augmented Generation for AI-Generated Content A Survey": {
        "filename": "Retrieval-Augmented Generation for AI-Generated Content A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "CONFLICTINGQA",
                "CONCRETE"
            ],
            "base_models": [
                "GPT series",
                "LLAMA series",
                "BERT",
                "BART"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathPrompter Mathematical Reasoning using Large Language Models": {
        "filename": "MathPrompter Mathematical Reasoning using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith"
            ],
            "base_models": [
                "GPT-3 DaVinci (175B)",
                "PaLM (540B)"
            ]
        }
    },
    "Language Models can Solve Computer Tasks": {
        "filename": "Language Models can Solve Computer Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MiniWoB++",
                "GSM8K"
            ],
            "base_models": [
                "InstructGPT-3+RLHF (gpt-3.5-turbo)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Mitigating Hallucination in Large Language Models via Self-Reflection": {
        "filename": "Towards Mitigating Hallucination in Large Language Models via Self-Reflection.pdf",
        "analysis": {
            "benchmarks": [
                "PubMedQA",
                "MedQuAD",
                "MEDIQA2019",
                "LiveMedQA2017",
                "MASH-QA"
            ],
            "base_models": [
                "Vicuna (based on LLaMA)",
                "Alpaca-LoRA (based on LLaMA)",
                "ChatGPT",
                "MedAlpaca (based on LLaMA)",
                "Robin-medical (based on LLaMA)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dual-AEB Synergizing Rule-Based and Multimodal Large Language Models for Effective Emergency Braking": {
        "filename": "Dual-AEB Synergizing Rule-Based and Multimodal Large Language Models for Effective Emergency Braking.pdf",
        "analysis": {
            "benchmarks": [
                "MM-AU",
                "Bench2Drive"
            ],
            "base_models": [
                "LLaVA-OneVision (based on Qwen-0.5B)",
                "LLaVA-OneVision (based on Qwen-7B)"
            ]
        }
    },
    "Disentangling Logic The Role of Context in Large Language Model Reasoning Capabilities": {
        "filename": "Disentangling Logic The Role of Context in Large Language Model Reasoning Capabilities.pdf",
        "analysis": {
            "benchmarks": [
                "ContextHub"
            ],
            "base_models": [
                "Qwen-1.5 (0.5b, 1.8b, 4b, 7b, 14b, 32b, 72b, 110b)",
                "LLaMA-2 (7b, 13b, 70b)",
                "Yi-1.5 (6b, 9b, 34b)",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AntGPT Can Large Language Models Help Long-term Action Anticipation from Videos": {
        "filename": "AntGPT Can Large Language Models Help Long-term Action Anticipation from Videos.pdf",
        "analysis": {
            "benchmarks": [
                "Ego4D LTA v1",
                "Ego4D LTA v2",
                "EPIC-Kitchens-55",
                "EGTEA GAZE+"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "Llama2-13B",
                "Llama2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TrafficGPT Viewing Processing and Interacting with Traffic Foundation Models": {
        "filename": "TrafficGPT Viewing Processing and Interacting with Traffic Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "Xuancheng city-scale synthetic individual-level vehicle trip dataset"
            ],
            "base_models": [
                "ChatGPT (gpt-35-turbo)"
            ]
        }
    },
    "Decompose Enrich and Extract Schema-aware Event Extraction using LLMs": {
        "filename": "Decompose Enrich and Extract Schema-aware Event Extraction using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ACE2005",
                "WIKIEVENTS",
                "MaritimeEvent"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT (gpt-3.5-turbo)",
                "Llama2-7B"
            ]
        }
    },
    "LLM experiments with simulation Large Language Model Multi-Agent System for Simulation Model Parametrization in Digital Twins": {
        "filename": "LLM experiments with simulation Large Language Model Multi-Agent System for Simulation Model Parametrization in Digital Twins.pdf",
        "analysis": {
            "benchmarks": [
                "custom container mixing process simulation"
            ],
            "base_models": [
                "Not specified in the provided text"
            ]
        }
    },
    "Generative Agents Interactive Simulacra of Human Behavior": {
        "filename": "Generative Agents Interactive Simulacra of Human Behavior.pdf",
        "analysis": {
            "benchmarks": [
                "Smallville sandbox environment"
            ],
            "base_models": [
                "ChatGPT (gpt3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatEDA A Large Language Model Powered Autonomous Agent for EDA": {
        "filename": "ChatEDA A Large Language Model Powered Autonomous Agent for EDA.pdf",
        "analysis": {
            "benchmarks": [
                "ChatEDA-Bench"
            ],
            "base_models": [
                "Llama2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can We Further Elicit Reasoning in LLMs Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks": {
        "filename": "Can We Further Elicit Reasoning in LLMs Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "USACO",
                "TheoremQA-Math",
                "StackBio",
                "StackEcon"
            ],
            "base_models": [
                "GPT-4",
                "Llama-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards a Science Exocortex": {
        "filename": "Towards a Science Exocortex.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enabling Conversational Interaction with Mobile UI using Large Language Models": {
        "filename": "Enabling Conversational Interaction with Mobile UI using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "RICO",
                "Screen2Words",
                "PixelHelp"
            ],
            "base_models": [
                "GPT-3",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Consistency Preference Optimization": {
        "filename": "Self-Consistency Preference Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "ZebraLogic"
            ],
            "base_models": [
                "Llama-3 8B",
                "Llama-3 70B",
                "Gemma-2 27B",
                "Claude-3 Haiku"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Receive Reason and React Drive as You Say With Large Language Models in Autonomous Vehicles": {
        "filename": "Receive Reason and React Drive as You Say With Large Language Models in Autonomous Vehicles.pdf",
        "analysis": {
            "benchmarks": [
                "HighwayEnv"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Finetuned Multimodal Language Models Are High-Quality Image-Text Data Filters": {
        "filename": "Finetuned Multimodal Language Models Are High-Quality Image-Text Data Filters.pdf",
        "analysis": {
            "benchmarks": [
                "DataComp",
                "VQAv2",
                "GQA"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA-1.5 (based on Vicuna-13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reward Engineering for Generating Semi-structured Explanation": {
        "filename": "Reward Engineering for Generating Semi-structured Explanation.pdf",
        "analysis": {
            "benchmarks": [
                "ExplaGraph",
                "COPA-SSE"
            ],
            "base_models": [
                "FLAN-T5-XXL (11B)",
                "GPT-4",
                "GPT-3.5-turbo-instruct",
                "LLaMA2-7B",
                "LLaMA2-13B",
                "FLAN-T5-Large (780M)",
                "FLAN-T5-XL (3B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Connecting Dreams with Visual Brainstorming Instruction": {
        "filename": "Connecting Dreams with Visual Brainstorming Instruction.pdf",
        "analysis": {
            "benchmarks": [
                "NSD (Natural Scenes Dataset)"
            ],
            "base_models": [
                "Stable Diffusion",
                "VersatileDiffusion",
                "InstructDiffusion"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Getting More Juice Out of the SFT Data Reward Learning from Human Demonstration Improves SFT for LLM Alignment": {
        "filename": "Getting More Juice Out of the SFT Data Reward Learning from Human Demonstration Improves SFT for LLM Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "HuggingFace Open LLM Leaderboard",
                "Anthropic-HH dataset"
            ],
            "base_models": [
                "pythia-1b",
                "pythia-1.4b",
                "zephyr-7b-sft-full"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Agents Meet Causality - Bridging LLMs and Causal World Models": {
        "filename": "Language Agents Meet Causality - Bridging LLMs and Causal World Models.pdf",
        "analysis": {
            "benchmarks": [
                "iTHOR",
                "GridWorld"
            ],
            "base_models": [
                "LLaMA 3 (8B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CFinBench A Comprehensive Chinese Financial Benchmark for Large Language Models": {
        "filename": "CFinBench A Comprehensive Chinese Financial Benchmark for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CFinBench"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA (7B to 70B)",
                "Baichuan",
                "InternLM",
                "ChatGLM",
                "BloombergGPT (50B)",
                "FinMA (based on LLaMA)",
                "Yi1.5-34B",
                "Qwen-72B",
                "XuanYuan2-70B-Base",
                "YunShan-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fine-tuning and prompt engineering for large language models-based code review automation": {
        "filename": "Fine-tuning and prompt engineering for large language models-based code review automation.pdf",
        "analysis": {
            "benchmarks": [
                "CodeReviewer data",
                "Tufano data (with comment)",
                "Tufano data (without comment)",
                "D-ACT data"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "Magicoder (6.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Ambiguity-Aware In-Context Learning with Large Language Models": {
        "filename": "Ambiguity-Aware In-Context Learning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SST",
                "GoEmotions",
                "EDOS (Task-B)"
            ],
            "base_models": [
                "Flan-PaLM 2 (M)",
                "Flan-PaLM 2 (L)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mufu Multilingual Fused Learning for Low-Resource Translation with LLM": {
        "filename": "Mufu Multilingual Fused Learning for Low-Resource Translation with LLM.pdf",
        "analysis": {
            "benchmarks": [
                "FLORES-200",
                "NTREX"
            ],
            "base_models": [
                "PaLM2 S (Bison)",
                "PaLM2 XXS (Gecko)",
                "PaLM2 XS (Otter)",
                "Gemma 2B-IT",
                "Gemma 7B-IT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Compiler generated feedback for Large Language Models": {
        "filename": "Compiler generated feedback for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "LLaMa 2 (7B)"
            ]
        }
    },
    "Training Language Models on Synthetic Edit Sequences Improves Code Synthesis": {
        "filename": "Training Language Models on Synthetic Edit Sequences Improves Code Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP"
            ],
            "base_models": [
                "GPT-4",
                "Llama 3.1 405B",
                "Codex",
                "AlphaCode",
                "TinyCodeLM-150M",
                "TinyCodeLM-400M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dont Transform the Code Code the Transforms Towards Precise Code Rewriting using LLMs": {
        "filename": "Dont Transform the Code Code the Transforms Towards Precise Code Rewriting using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 480 input/output Python programs"
            ],
            "base_models": [
                "Llama 3.1 (405B)",
                "Llama 3.1 (70B)",
                "Llama 3.1 (8B)"
            ]
        }
    },
    "Towards Transferable Attacks Against Vision-LLMs in Autonomous Driving with Typography": {
        "filename": "Towards Transferable Attacks Against Vision-LLMs in Autonomous Driving with Typography.pdf",
        "analysis": {
            "benchmarks": [
                "LingoQA",
                "CVPRW'2024 Challenge dataset"
            ],
            "base_models": [
                "LLaVa",
                "Qwen-VL",
                "VILA",
                "Imp",
                "GPT-4"
            ]
        }
    },
    "Towards Improving Document Understanding An Exploration on Text-Grounding via MLLMs": {
        "filename": "Towards Improving Document Understanding An Exploration on Text-Grounding via MLLMs.pdf",
        "analysis": {
            "benchmarks": [
                "STVQA",
                "OCRVQA",
                "TextVQA",
                "DocVQA",
                "InfographicVQA",
                "ChartQA",
                "FUNSD",
                "SROIE",
                "POIE"
            ],
            "base_models": [
                "GPT-4",
                "Vicuna-7B (based on LLaMA)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-Pruner On the Structural Pruning of Large Language Models": {
        "filename": "LLM-Pruner On the Structural Pruning of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "PIQA",
                "HellaSwag",
                "WinoGrande",
                "ARC-easy",
                "ARC-challenge",
                "OpenbookQA",
                "WikiText2",
                "PTB"
            ],
            "base_models": [
                "LLaMA-7B",
                "Vicuna-7B",
                "ChatGLM-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Your Large Language Model is Secretly a Fairness Proponent and You Should Prompt it Like One": {
        "filename": "Your Large Language Model is Secretly a Fairness Proponent and You Should Prompt it Like One.pdf",
        "analysis": {
            "benchmarks": [
                "custom fairness evaluation dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama2",
                "Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Comparison of LLM Finetuning Methods  Evaluation Metrics with Travel Chatbot Use Case": {
        "filename": "A Comparison of LLM Finetuning Methods  Evaluation Metrics with Travel Chatbot Use Case.pdf",
        "analysis": {
            "benchmarks": [
                "End to End (E2E) benchmark method of 'Golden Answers'",
                "OpenAI GPT-4 evaluation metrics"
            ],
            "base_models": [
                "LLaMa 2 7B",
                "Mistral 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond the Frontier Predicting Unseen Walls From Occupancy Grids by Learning From Floor Plans": {
        "filename": "Beyond the Frontier Predicting Unseen Walls From Occupancy Grids by Learning From Floor Plans.pdf",
        "analysis": {
            "benchmarks": [
                "KTH floor plan dataset"
            ],
            "base_models": [
                "Transformer encoder-decoder (no specific size mentioned)"
            ]
        }
    },
    "Ladder-of-Thought Using Knowledge as Steps to Elevate Stance Detection": {
        "filename": "Ladder-of-Thought Using Knowledge as Steps to Elevate Stance Detection.pdf",
        "analysis": {
            "benchmarks": [
                "VAST"
            ],
            "base_models": [
                "GPT-3.5",
                "FLAN-T5-Large (780M)",
                "BERT"
            ]
        }
    },
    "MVBench A Comprehensive Multi-modal Video Understanding Benchmark": {
        "filename": "MVBench A Comprehensive Multi-modal Video Understanding Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "MVBench",
                "STAR",
                "PAXION",
                "Moments in Time V1",
                "FunQA",
                "CLEVRER",
                "Perception Test",
                "Charades-STA",
                "MoVQA",
                "NTU RGB+D",
                "VLN-CE",
                "TVQA"
            ],
            "base_models": [
                "Flamingo",
                "PaLM-E",
                "LLaV A",
                "MiniGPT-4",
                "InstructBLIP",
                "VideoChat",
                "VideoChatGPT",
                "Valley",
                "GPT-4V",
                "Vicuna-7B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Value Biases How LLMs Deviate Towards the Ideal": {
        "filename": "Exploring Value Biases How LLMs Deviate Towards the Ideal.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Text Classification via Large Language Models": {
        "filename": "Text Classification via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "AGNews",
                "R8",
                "R52",
                "MR"
            ],
            "base_models": [
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Invariant Learning Characterization of Controlled Text Generation": {
        "filename": "An Invariant Learning Characterization of Controlled Text Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CivilComments",
                "RealToxicityPrompts"
            ],
            "base_models": [
                "BERT",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DeiSAM Segment Anything with Deictic Prompting": {
        "filename": "DeiSAM Segment Anything with Deictic Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "Deictic Visual Genome (DeiVG)",
                "DeiRefCOCO+"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Llama-2-13B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Vision Language Models are In-Context Value Learners": {
        "filename": "Vision Language Models are In-Context Value Learners.pdf",
        "analysis": {
            "benchmarks": [
                "Open-X Embodiment (OXE) dataset",
                "Custom bimanual manipulation dataset on ALOHA platform"
            ],
            "base_models": [
                "Gemini-1.5-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Complementary Explanations for Effective In-Context Learning": {
        "filename": "Complementary Explanations for Effective In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM",
                "ECQA",
                "E-SNLI",
                "LETCAT",
                "COINFLIPS"
            ],
            "base_models": [
                "OPT-175B",
                "GPT-3 (davinci)",
                "InstructGPT (text-davinci-001)",
                "text-davinci-002",
                "GPT-3 Codex (code-davinci-001)",
                "GPT-3 Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DoRA Weight-Decomposed Low-Rank Adaptation": {
        "filename": "DoRA Weight-Decomposed Low-Rank Adaptation.pdf",
        "analysis": {
            "benchmarks": [
                "commonsense reasoning",
                "visual instruction tuning",
                "image/video-text understanding"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA2-7B",
                "LLaMA3-8B",
                "VL-BART",
                "LLaVA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Logic-LM Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning": {
        "filename": "Logic-LM Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ProofWriter",
                "PrOntoQA",
                "FOLIO",
                "LogicalDeduction",
                "AR-LSAT"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoTrial Prompting Language Models for Clinical Trial Design": {
        "filename": "AutoTrial Prompting Language Models for Clinical Trial Design.pdf",
        "analysis": {
            "benchmarks": [
                "ClinicalTrials.gov dataset"
            ],
            "base_models": [
                "GPT-2"
            ]
        }
    },
    "Parrot Mind Towards Explaining the Complex Task Reasoning of Pretrained Large Language Models with Template-Content Structure": {
        "filename": "Parrot Mind Towards Explaining the Complex Task Reasoning of Pretrained Large Language Models with Template-Content Structure.pdf",
        "analysis": {
            "benchmarks": [
                "SingleEQ",
                "GSM8k"
            ],
            "base_models": [
                "GPT-4",
                "Llama2-7b",
                "Llama2-13b",
                "Llama2-70b",
                "GPT2-335m",
                "GPT2-774m",
                "GPT2-1.5b",
                "OPT-1.3b",
                "OPT-13b",
                "OPT-30b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unlocking the Potential of Large Language Models for Explainable Recommendations": {
        "filename": "Unlocking the Potential of Large Language Models for Explainable Recommendations.pdf",
        "analysis": {
            "benchmarks": [
                "ML-100k",
                "Mind",
                "Steam"
            ],
            "base_models": [
                "LLaMA",
                "ChatGLM",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Boosting Logical Reasoning in Large Language Models through a New Framework The Graph of Thought": {
        "filename": "Boosting Logical Reasoning in Large Language Models through a New Framework The Graph of Thought.pdf",
        "analysis": {
            "benchmarks": [
                "24-point game",
                "Mathematics Dataset (for high-degree polynomial equations)",
                "Custom dataset (for recursive sequences)"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "When Can Transformers Count to n": {
        "filename": "When Can Transformers Count to n.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Gemini 1.5"
            ]
        }
    },
    "LLMs for Knowledge Graph Construction and Reasoning Recent Capabilities and Future Opportunities": {
        "filename": "LLMs for Knowledge Graph Construction and Reasoning Recent Capabilities and Future Opportunities.pdf",
        "analysis": {
            "benchmarks": [
                "DuIE2.0",
                "SciERC",
                "Re-TACRED",
                "MAVEN",
                "FB15K-237",
                "ATOMIC 2020",
                "FreebaseQA",
                "MetaQA",
                "VINE"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Synatra Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale": {
        "filename": "Synatra Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale.pdf",
        "analysis": {
            "benchmarks": [
                "Mind2Web",
                "MiniWoB++",
                "WebArena"
            ],
            "base_models": [
                "CodeLlama-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cut the Crap An Economical Communication Pipeline for LLM-based Multi-Agent Systems": {
        "filename": "Cut the Crap An Economical Communication Pipeline for LLM-based Multi-Agent Systems.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8K",
                "MultiArith",
                "SVAMP",
                "AQuA",
                "HumanEval"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4-1106-preview"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Opportunities for Retrieval and Tool Augmented Large Language Models in Scientific Facilities": {
        "filename": "Opportunities for Retrieval and Tool Augmented Large Language Models in Scientific Facilities.pdf",
        "analysis": {
            "benchmarks": [
                "Advanced Photon Source (APS)",
                "Center for Nanoscale Materials (CNM)",
                "Argonne Leadership Computing Facility (ALCF)",
                "Center for Nanophase Materials Sciences (CNMS)"
            ],
            "base_models": [
                "GPT-3.5 Turbo (175 billion parameters)",
                "Vicuna-13B (fine-tuned on Llama 2)"
            ]
        }
    },
    "Visualization Generation with Large Language Models An Evaluation": {
        "filename": "Visualization Generation with Large Language Models An Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "nvBench"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unveiling the Secret Recipe A Guide For Supervised Fine-Tuning Small LLMs": {
        "filename": "Unveiling the Secret Recipe A Guide For Supervised Fine-Tuning Small LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "MTBench",
                "Open LLM Leaderboard",
                "ARC",
                "GSM8K",
                "BBH",
                "MATH",
                "MuSR",
                "ToxiGen",
                "TruthfulQA"
            ],
            "base_models": [
                "Granite 3B",
                "Granite 7B",
                "LLaMA 3B",
                "Mistral 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Premise Order Matters in Reasoning with Large Language Models": {
        "filename": "Premise Order Matters in Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "R-GSM",
                "GSM8K",
                "SimpleLogic"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-3.5-turbo",
                "PaLM 2-L",
                "Gemini 1.0 Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AI Chain on Large Language Model for Unsupervised Control Flow Graph Generation for Statically-Typed Partial Code": {
        "filename": "AI Chain on Large Language Model for Unsupervised Control Flow Graph Generation for Statically-Typed Partial Code.pdf",
        "analysis": {
            "benchmarks": [
                "NC dataset",
                "ESE dataset",
                "ISE dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "CodeX"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tasks People Prompt A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches": {
        "filename": "Tasks People Prompt A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches.pdf",
        "analysis": {
            "benchmarks": [
                "SWE-bench",
                "GitHub issues"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval Augmented Generation RAG and Beyond A Comprehensive Survey on How to Make your LLMs use External Data More Wisely": {
        "filename": "Retrieval Augmented Generation RAG and Beyond A Comprehensive Survey on How to Make your LLMs use External Data More Wisely.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions",
                "MS MARCO",
                "TriviaQA",
                "SQuAD",
                "ASQA",
                "WebQSP",
                "HotPotQA",
                "2WikiMultiHopQA",
                "MuSiQue",
                "Bamboogle",
                "StrategyQA",
                "ComplexWebQuestions",
                "WebQuestions",
                "Mintaka",
                "MetaQA",
                "qasper",
                "DROP",
                "Multi-Choice QuALITY",
                "Fact Checking Feverous"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating ChatGPT-35 Efficiency in Solving Coding Problems of Different Complexity Levels An Empirical Analysis": {
        "filename": "Evaluating ChatGPT-35 Efficiency in Solving Coding Problems of Different Complexity Levels An Empirical Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "LeetCode"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "Claude 3 Sonnet",
                "Gemini 1.0 Pro"
            ]
        }
    },
    "Harnessing the Power of LLMs in Practice A Survey on ChatGPT and Beyond": {
        "filename": "Harnessing the Power of LLMs in Practice A Survey on ChatGPT and Beyond.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SuperGLUE",
                "IMDB",
                "SST",
                "CivilComments",
                "RTE",
                "SNLI",
                "CB",
                "SQuADv2",
                "QuAC",
                "CoQA",
                "MS MARCO",
                "CoNLL03",
                "CNN/DailyMail",
                "XSUM",
                "WMT'16",
                "HumanEval",
                "MBPP",
                "DeepFix",
                "NaturalQuestions",
                "WebQuestions",
                "TriviaQA",
                "MMLU",
                "Big-bench",
                "ANLI",
                "GSM8k",
                "SVAMP",
                "AQuA",
                "StrategyQA",
                "ARC-C"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-4",
                "BERT",
                "RoBERTa",
                "T5",
                "PaLM",
                "BLOOM",
                "LLaMA",
                "InstructGPT",
                "GPT-J",
                "OPT",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "KoMA Knowledge-driven Multi-agent Framework for Autonomous Driving with Large Language Models": {
        "filename": "KoMA Knowledge-driven Multi-agent Framework for Autonomous Driving with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "highway-env",
                "roundabout scenario"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "LLaMA2-7B",
                "LLaMA3-8B",
                "Qwen2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Multimodal Models Notes on CVPR 2023 Tutorial": {
        "filename": "Large Multimodal Models Notes on CVPR 2023 Tutorial.pdf",
        "analysis": {
            "benchmarks": [
                "Vicuna-Instructions-80",
                "Science QA"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "Vicuna"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reflective Linguistic Programming RLP A Stepping Stone in Socially-Aware AGI SocialAGI": {
        "filename": "Reflective Linguistic Programming RLP A Stepping Stone in Socially-Aware AGI SocialAGI.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "CharacterChat Learning towards Conversational AI with Personalized Social Support": {
        "filename": "CharacterChat Learning towards Conversational AI with Personalized Social Support.pdf",
        "analysis": {
            "benchmarks": [
                "MBTI-S2Conv"
            ],
            "base_models": [
                "Llama2-7B",
                "BERT"
            ]
        }
    },
    "DuetRAG Collaborative Retrieval-Augmented Generation": {
        "filename": "DuetRAG Collaborative Retrieval-Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA"
            ],
            "base_models": [
                "LLaMA2-7B"
            ]
        }
    },
    "Learning How Hard to Think Input-Adaptive Allocation of LM Computation": {
        "filename": "Learning How Hard to Think Input-Adaptive Allocation of LM Computation.pdf",
        "analysis": {
            "benchmarks": [
                "TACO",
                "Numina-COT",
                "LMSYS-Chat",
                "Anthropic-HH"
            ],
            "base_models": [
                "Starcoder-15B",
                "Mathstral-7B",
                "Gemma-7B-it",
                "Gemma-2B-it",
                "Llama-2 7B"
            ]
        }
    },
    "Visualizationary Automating Design Feedback for Visualization Designers using LLMs": {
        "filename": "Visualizationary Automating Design Feedback for Visualization Designers using LLMs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Data-Copilot Bridging Billions of Data and Humans with Autonomous Workflow": {
        "filename": "Data-Copilot Bridging Billions of Data and Humans with Autonomous Workflow.pdf",
        "analysis": {
            "benchmarks": [
                "Chinese financial data (stocks, funds, news)"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An AIC-based approach for articulating unpredictable problems in open complex environments": {
        "filename": "An AIC-based approach for articulating unpredictable problems in open complex environments.pdf",
        "analysis": {
            "benchmarks": [
                "AVOIDDS: Aircraft Vision-based Intruder Detection Dataset and Simulator"
            ],
            "base_models": []
        }
    },
    "MagicLens Self-Supervised Image Retrieval with Open-Ended Instructions": {
        "filename": "MagicLens Self-Supervised Image Retrieval with Open-Ended Instructions.pdf",
        "analysis": {
            "benchmarks": [
                "CIRCO",
                "Domain Transfer ImageNet (DTIN)",
                "GeneCIS",
                "FIQ",
                "CIRR"
            ],
            "base_models": [
                "PaLM2",
                "PaLI",
                "CLIP-B",
                "CLIP-L",
                "CoCa-B",
                "CoCa-L"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Text2CAD Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts": {
        "filename": "Text2CAD Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "DeepCAD"
            ],
            "base_models": [
                "Mistral-50B",
                "LLaVA-NeXT",
                "GPT-4",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Citation A Key to Building Responsible and Accountable Large Language Models": {
        "filename": "Citation A Key to Building Responsible and Accountable Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT/GPT-4"
            ]
        }
    },
    "Aligning Large Language Models for Enhancing Psychiatric Interviews through Symptom Delineation and Summarization": {
        "filename": "Aligning Large Language Models for Enhancing Psychiatric Interviews through Symptom Delineation and Summarization.pdf",
        "analysis": {
            "benchmarks": [
                "Custom interview transcript dataset of North Korean defectors"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "GPT-3.5 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning in Large Language Models A Geometric Perspective": {
        "filename": "Reasoning in Large Language Models A Geometric Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K-Zero"
            ],
            "base_models": [
                "GPT-4",
                "Llama 3 (8B)",
                "Llama 3 (70B)"
            ]
        }
    },
    "SeqMate A Novel Large Language Model Pipeline for Automating RNA Sequencing": {
        "filename": "SeqMate A Novel Large Language Model Pipeline for Automating RNA Sequencing.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "gpt-3.5-turbo-0125"
            ]
        }
    },
    "Large Language Models can Learn Rules": {
        "filename": "Large Language Models can Learn Rules.pdf",
        "analysis": {
            "benchmarks": [
                "CLUTRR",
                "Arithmetic",
                "List Functions"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning": {
        "filename": "Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "AerialVLN-S"
            ],
            "base_models": [
                "GPT-4V",
                "GPT-4o"
            ]
        }
    },
    "Caption Anything Interactive Image Description with Diverse Multimodal Controls": {
        "filename": "Caption Anything Interactive Image Description with Diverse Multimodal Controls.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "FLAN-T5",
                "BLIP2",
                "ChatGPT",
                "LLaMA"
            ]
        }
    },
    "A Survey of Confidence Estimation and Calibration in Large Language Models": {
        "filename": "A Survey of Confidence Estimation and Calibration in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (Brown et al., 2020b)",
                "GPT-3.5",
                "GPT-4",
                "OPT (Zhang et al., 2022)",
                "Anthropic LLM (Bai et al., 2022)",
                "Vicuna (Chiang et al., 2023)",
                "LLaMA (Touvron et al., 2023a)",
                "Falcon (Penedo et al., 2023)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Synthesis of Mathematical programs from Natural Language Specifications": {
        "filename": "Synthesis of Mathematical programs from Natural Language Specifications.pdf",
        "analysis": {
            "benchmarks": [
                "NL4OPT"
            ],
            "base_models": [
                "CodeT5-base",
                "Codex",
                "ChatGPT",
                "BART-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Refine Iterative Refinement with Self-Feedback": {
        "filename": "Self-Refine Iterative Refinement with Self-Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "Dialogue Response Generation (Mehri and Eskenazi, 2020)",
                "Code Optimization (Madaan et al., 2023)",
                "Code Readability Improvement (Puri et al., 2021)",
                "Math Reasoning (Cobbe et al., 2021)",
                "Sentiment Reversal (Zhang et al., 2015)",
                "Acronym Generation (custom dataset)",
                "Constrained Generation (custom dataset)"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003 and gpt-3.5-turbo)",
                "GPT-4",
                "Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NoFunEval Funny How Code LMs Falter on Requirements Beyond Functional Correctness": {
        "filename": "NoFunEval Funny How Code LMs Falter on Requirements Beyond Functional Correctness.pdf",
        "analysis": {
            "benchmarks": [
                "NoFunEval",
                "HumanEval",
                "HumanEvalFix",
                "HumanEvalClassify"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "CodeLlama-34B",
                "Phind-CodeLlama-34B",
                "WizardCoder-Py-34B",
                "Deepseek-33B",
                "WizardCoder-15B",
                "Starcoder-15B",
                "CodeLlama-13B",
                "CodeLlama-7B",
                "Mistral-7B",
                "Deepseek-6.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Conversational Search and Applications in Biomedicine": {
        "filename": "A Survey on Conversational Search and Applications in Biomedicine.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Guide-LLM An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments": {
        "filename": "Guide-LLM An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments.pdf",
        "analysis": {
            "benchmarks": [
                "iGibson simulator"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "Can a large language model be a gaslighter": {
        "filename": "Can a large language model be a gaslighter.pdf",
        "analysis": {
            "benchmarks": [
                "DangerousQA",
                "MT-Bench"
            ],
            "base_models": [
                "Llama2-7b-Chat",
                "Vicuna-7b-v1.5",
                "Mistral-7b-Instruct-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Which Examples to Annotate for In-Context Learning Towards Effective and Efficient Selection": {
        "filename": "Which Examples to Annotate for In-Context Learning Towards Effective and Efficient Selection.pdf",
        "analysis": {
            "benchmarks": [
                "AGNews",
                "TREC",
                "SST2",
                "Amazon",
                "RTE",
                "MRPC",
                "MNLI",
                "XSUM",
                "GSM8K"
            ],
            "base_models": [
                "GPT-J (6B)",
                "Mosaic (7B)",
                "Falcon (40B)",
                "LLaMa (65B)",
                "GPT-Neo (1.3B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AVA Towards Autonomous Visualization Agents through Visual PerceptionDriven DecisionMaking": {
        "filename": "AVA Towards Autonomous Visualization Agents through Visual PerceptionDriven DecisionMaking.pdf",
        "analysis": {
            "benchmarks": [
                "Boston Teapot dataset",
                "Visible Male dataset",
                "Diamond data",
                "Out5D data",
                "RNA sequence data"
            ],
            "base_models": [
                "GPT-4 Vision"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GAPS Geometry-Aware Problem Solver": {
        "filename": "GAPS Geometry-Aware Problem Solver.pdf",
        "analysis": {
            "benchmarks": [
                "UniGeo",
                "PGPS9K",
                "Geometry3K"
            ],
            "base_models": [
                "VL-T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompted LLMs as Chatbot Modules for Long Open-domain Conversation": {
        "filename": "Prompted LLMs as Chatbot Modules for Long Open-domain Conversation.pdf",
        "analysis": {
            "benchmarks": [
                "Multi-Session Chat dataset",
                "PersonaChat"
            ],
            "base_models": [
                "GPT-3",
                "PaLM",
                "OPT-30B",
                "OPT-66B",
                "GPT-JT-6B",
                "BLOOM-176B",
                "Blenderbot3 (BB3-30B)",
                "Blenderbot3 (BB3-175B)"
            ]
        }
    },
    "Beyond Numeric Awards In-Context Dueling Bandits with LLM Agents": {
        "filename": "Beyond Numeric Awards In-Context Dueling Bandits with LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Easy instance",
                "Hard instance"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4",
                "GPT-4 Turbo",
                "LLAMA 3.1",
                "O1-PREVIEW"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language models show human-like content effects on reasoning": {
        "filename": "Language models show human-like content effects on reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Language Inference (NLI)",
                "Syllogisms",
                "Wason Selection Task"
            ],
            "base_models": [
                "Chinchilla (70B)",
                "PaLM 2-M",
                "PaLM 2-L",
                "Flan-PaLM 2",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Plot2Code A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots": {
        "filename": "Plot2Code A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots.pdf",
        "analysis": {
            "benchmarks": [
                "Plot2Code"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini-Pro",
                "Claude-3",
                "Mini-Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RCAgent Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models": {
        "filename": "RCAgent Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Real-time Compute Platform for Apache Flink of Alibaba Cloud"
            ],
            "base_models": [
                "Vicuna-13B-V1.5-16K"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Looped Transformers are Better at Learning Learning Algorithms": {
        "filename": "Looped Transformers are Better at Learning Learning Algorithms.pdf",
        "analysis": {
            "benchmarks": [
                "linear regression task",
                "sparse linear functions",
                "decision trees",
                "2-layer neural networks"
            ],
            "base_models": [
                "GPT-2 (12 layers)",
                "GPT-2 (1 layer)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Explaining Tree Model Decisions in Natural Language for Network Intrusion Detection": {
        "filename": "Explaining Tree Model Decisions in Natural Language for Network Intrusion Detection.pdf",
        "analysis": {
            "benchmarks": [
                "NF-BoT"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Pricing and Competition for Generative AI": {
        "filename": "Pricing and Competition for Generative AI.pdf",
        "analysis": {
            "benchmarks": [
                "Chatbot Arena",
                "Anthropic HH"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Captioning and Retrieving Remote Sensing Images": {
        "filename": "Large Language Models for Captioning and Retrieving Remote Sensing Images.pdf",
        "analysis": {
            "benchmarks": [
                "RSICD",
                "Sydney-Captions",
                "UCM-Captions",
                "NWPU-Captions"
            ],
            "base_models": [
                "LLamaV2-7B",
                "CLIP ViT-L/14"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models": {
        "filename": "Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "IMDB",
                "WikiData (Books and Movies)",
                "Opendatasoft (Nobel Winners)"
            ],
            "base_models": [
                "GPT-J-6B",
                "Mistral-7B",
                "Qwen-7B",
                "SFR-Embedding-Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Taxonomy for Human-LLM Interaction Modes An Initial Exploration": {
        "filename": "A Taxonomy for Human-LLM Interaction Modes An Initial Exploration.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "Claude",
                "Gemini",
                "Llama 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What Did I Do Wrong Quantifying LLMs Sensitivity and Consistency to Prompt Engineering": {
        "filename": "What Did I Do Wrong Quantifying LLMs Sensitivity and Consistency to Prompt Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "TREC",
                "CommittmentBank (CB)",
                "RTE",
                "DBPedia",
                "Web of Science (WoS)"
            ],
            "base_models": [
                "Llama-3-70B-Instruct",
                "Mixtral-8x7B-Instruct-v0.1",
                "GPT-3.5-turbo-0125",
                "GPT-4o-2024-08-06"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Process Reward Model with Q-Value Rankings": {
        "filename": "Process Reward Model with Q-Value Rankings.pdf",
        "analysis": {
            "benchmarks": [
                "MATH500",
                "GSM-Plus"
            ],
            "base_models": [
                "Llama-3-70B-Instruct",
                "MetaMath-Mistral-7B",
                "MuggleMath-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Semantic anomaly detection with large language models": {
        "filename": "Semantic anomaly detection with large language models.pdf",
        "analysis": {
            "benchmarks": [
                "CARLA simulator"
            ],
            "base_models": [
                "text-davinci-003",
                "OWL-ViT",
                "YOLOv8",
                "DETR"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "XRICL Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing": {
        "filename": "XRICL Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing.pdf",
        "analysis": {
            "benchmarks": [
                "XSPIDER",
                "XKAGGLE-DBQA"
            ],
            "base_models": [
                "GPT-3",
                "Codex"
            ]
        }
    },
    "Is It Safe to Cross Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing": {
        "filename": "Is It Safe to Cross Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing.pdf",
        "analysis": {
            "benchmarks": [
                "custom outdoor street crossing dataset"
            ],
            "base_models": [
                "GPT-4V"
            ]
        }
    },
    "Self-Supervised Multimodal Learning A Survey": {
        "filename": "Self-Supervised Multimodal Learning A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AMOR A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback": {
        "filename": "AMOR A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "PubMedQA",
                "QASPER"
            ],
            "base_models": [
                "LLAMA-2-7B-Chat",
                "LLAMA-2-13B-Chat",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Non Verbis Sed Rebus Large Language Models are Weak Solvers of Italian Rebuses": {
        "filename": "Non Verbis Sed Rebus Large Language Models are Weak Solvers of Italian Rebuses.pdf",
        "analysis": {
            "benchmarks": [
                "EurekaRebus"
            ],
            "base_models": [
                "LLaMA-3 70B",
                "GPT-4o",
                "Claude-3.5 Sonnet",
                "Qwen-2 72B",
                "Phi-3 Mini 3.8B"
            ]
        }
    },
    "Hide and Seek Fingerprinting Large Language Models with Evolutionary Learning": {
        "filename": "Hide and Seek Fingerprinting Large Language Models with Evolutionary Learning.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Llama-3-8B",
                "Mistral-7B-instruct-0.3",
                "Gemma-2-9B",
                "Phi-2.7B",
                "Mixtral-8x22B",
                "Llama-3-70B",
                "Gemma-2-27B",
                "Qwen2-72B"
            ]
        }
    },
    "Understanding Graphical Perception in Data Visualization through Zero-shot Prompting of Vision-Language Models": {
        "filename": "Understanding Graphical Perception in Data Visualization through Zero-shot Prompting of Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Graphical perception tasks from Cleveland and McGill (1984)",
                "Heer and Bostock (2010) replication study"
            ],
            "base_models": [
                "GPT-4o-mini"
            ]
        }
    },
    "REFINER Reasoning Feedback on Intermediate Representations": {
        "filename": "REFINER Reasoning Feedback on Intermediate Representations.pdf",
        "analysis": {
            "benchmarks": [
                "SVAMP",
                "GSM8K",
                "Synthetic Natural Language Reasoning (sNLR)",
                "Moral Stories (MS)"
            ],
            "base_models": [
                "GPT-3.5",
                "ChatGPT",
                "UnifiedQA-T5-base (220M)",
                "UnifiedQA-T5-large (770M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Non-myopic Generation of Language Models for Reasoning and Planning": {
        "filename": "Non-myopic Generation of Language Models for Reasoning and Planning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AlfWorld",
                "MATH",
                "HumanEval",
                "MBPP",
                "PDDL"
            ],
            "base_models": [
                "GPT-4",
                "Llama3-8B",
                "Mistral-v0.3",
                "Deepseek-Coder",
                "GPT-3.5 Turbo",
                "Llama3.1-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Robust and Interpretable Medical Image Classifiers via Concept Bottleneck Models": {
        "filename": "Robust and Interpretable Medical Image Classifiers via Concept Bottleneck Models.pdf",
        "analysis": {
            "benchmarks": [
                "NIH-gender",
                "NIH-age",
                "NIH-agemix",
                "Covid-mix",
                "NIH-CXR",
                "Covid-QU",
                "Pneumonia",
                "Open-i"
            ],
            "base_models": [
                "GPT-4",
                "BioViL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Agents as Optimizable Graphs": {
        "filename": "Language Agents as Optimizable Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "Mini CrossWords",
                "HumanEval",
                "GAIA"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Novice Learner and Expert Tutor Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions": {
        "filename": "Novice Learner and Expert Tutor Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "NumGLUE",
                "Eedi's platform dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Towards More Effective Table-to-Text Generation Assessing In-Context Learning and Self-Evaluation with Open-Source Models": {
        "filename": "Towards More Effective Table-to-Text Generation Assessing In-Context Learning and Self-Evaluation with Open-Source Models.pdf",
        "analysis": {
            "benchmarks": [
                "WikiBio",
                "ToTTo",
                "Recent Wikipedia pages",
                "MaRDI"
            ],
            "base_models": [
                "Llama 3 (70B)",
                "Phi-3 (14B)"
            ]
        }
    },
    "On Enhancing Root Cause Analysis with SQL Summaries for Failures in Database Workload Replays at SAP HANA": {
        "filename": "On Enhancing Root Cause Analysis with SQL Summaries for Failures in Database Workload Replays at SAP HANA.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset from SAP HANA workload replays"
            ],
            "base_models": [
                "GPT-4-Turbo"
            ]
        }
    },
    "Adaptive Activation Steering A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories": {
        "filename": "Adaptive Activation Steering A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA"
            ],
            "base_models": [
                "LLaMA (7B, 13B, 33B, 65B)",
                "LLaMA2",
                "Alpaca",
                "Vicuna",
                "LLaMA2-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SmartInv Multimodal Learning for Smart Contract Invariant Inference": {
        "filename": "SmartInv Multimodal Learning for Smart Contract Invariant Inference.pdf",
        "analysis": {
            "benchmarks": [
                "Etherscan dataset (89,621 real-world contracts)",
                "Custom annotated smart contract invariant dataset (2,173 samples)"
            ],
            "base_models": [
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TextGrad Automatic Differentiation via Text": {
        "filename": "TextGrad Automatic Differentiation via Text.pdf",
        "analysis": {
            "benchmarks": [
                "Google-Proof Question Answering",
                "LeetCode Hard",
                "MMLU-Machine Learning",
                "MMLU-College Physics"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-3.5-turbo-0125"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The New Agronomists Language Models are Experts in Crop Management": {
        "filename": "The New Agronomists Language Models are Experts in Crop Management.pdf",
        "analysis": {
            "benchmarks": [
                "Florida maize crop simulation",
                "Zaragoza maize crop simulation"
            ],
            "base_models": [
                "DistilBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Potential and Limitations of LLMs in Capturing Structured Semantics A Case Study on SRL": {
        "filename": "Potential and Limitations of LLMs in Capturing Structured Semantics A Case Study on SRL.pdf",
        "analysis": {
            "benchmarks": [
                "CoNLL-2005",
                "CoNLL-2012"
            ],
            "base_models": [
                "Llama2-7B-Chat",
                "ChatGLM2-6B",
                "GPT-3 (text-ada-001, 350M)",
                "GPT-3 (text-babbage-001, 1.3B)",
                "GPT-3 (text-curie-001, 6.7B)",
                "GPT-3 (text-davinci-001, 175B)",
                "ChatGPT"
            ]
        }
    },
    "Large sequence models for sequential decision-making a survey": {
        "filename": "Large sequence models for sequential decision-making a survey.pdf",
        "analysis": {
            "benchmarks": [
                "Gato",
                "Video Pre-Training (VPT)"
            ],
            "base_models": [
                "GPT-3",
                "Swin Transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What Are They Doing Joint Audio-Speech Co-Reasoning": {
        "filename": "What Are They Doing Joint Audio-Speech Co-Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "What Are They Doing dataset",
                "Open-ASQA dataset"
            ],
            "base_models": [
                "Vicuna LLM",
                "LLaMa-2",
                "WavLM",
                "Whisper"
            ]
        }
    },
    "SWAG Storytelling With Action Guidance": {
        "filename": "SWAG Storytelling With Action Guidance.pdf",
        "analysis": {
            "benchmarks": [
                "Writing Prompts"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "Llama-2-7B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation": {
        "filename": "Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation.pdf",
        "analysis": {
            "benchmarks": [
                "Wizard of Wikipedia",
                "Holl-E"
            ],
            "base_models": [
                "T5 (60M, 222M, 737M, 3B, 11B)",
                "DialoGPT (124M, 355M, 774M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TIFA Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering": {
        "filename": "TIFA Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "TIFA v1.0",
                "MSCOCO validation set",
                "DrawBench",
                "PartiPrompts",
                "PaintSkill"
            ],
            "base_models": [
                "GPT-3",
                "UnifiedQA",
                "mPLUG-large",
                "BLIP-2 FlanT5-XL",
                "GIT-large",
                "VILT-B/32",
                "OFA-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Agent Design Pattern Catalogue A Collection of Architectural Patterns for Foundation Model based Agents": {
        "filename": "Agent Design Pattern Catalogue A Collection of Architectural Patterns for Foundation Model based Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "Claude",
                "Llama",
                "Mistral",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Consensus Game Language Model Generation via Equilibrium Search": {
        "filename": "The Consensus Game Language Model Generation via Equilibrium Search.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "ARC",
                "RACE",
                "HHH",
                "TruthfulQA",
                "GSM8K"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-65B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Scaling Data-Constrained Language Models": {
        "filename": "Scaling Data-Constrained Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WebNLG",
                "bAbI"
            ],
            "base_models": [
                "GPT-2 (up to 8.7B parameters)",
                "PaLM",
                "Gopher"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Large Language Models on the GMAT Implications for the Future of Business Education": {
        "filename": "Evaluating Large Language Models on the GMAT Implications for the Future of Business Education.pdf",
        "analysis": {
            "benchmarks": [
                "GMAT"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4",
                "GPT-4 Turbo",
                "Claude 2",
                "Claude 2.1",
                "PaLM 2",
                "Gemini 1.0 Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CPSDBench A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain": {
        "filename": "CPSDBench A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain.pdf",
        "analysis": {
            "benchmarks": [
                "CPSDBench"
            ],
            "base_models": [
                "GPT-4",
                "ChatGLM-4",
                "Atom (LLaMA-2-Chinese)",
                "XVerse (13B, 65B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-Context Learning for Knowledge Base Question Answering for Unmanned Systems based on Large Language Models": {
        "filename": "In-Context Learning for Knowledge Base Question Answering for Unmanned Systems based on Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CCKS 2023 Question Answering with Knowledge Graph Inference for Unmanned Systems"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0613)"
            ]
        }
    },
    "ScatterShot Interactive In-context Example Curation for Text Transformation": {
        "filename": "ScatterShot Interactive In-context Example Curation for Text Transformation.pdf",
        "analysis": {
            "benchmarks": [
                "TimeBank",
                "TweeTime"
            ],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SSSD Simply-Scalable Speculative Decoding": {
        "filename": "SSSD Simply-Scalable Speculative Decoding.pdf",
        "analysis": {
            "benchmarks": [
                "MT-Bench",
                "GSM8k",
                "Dolly-15k",
                "Natural Questions",
                "PG-19"
            ],
            "base_models": [
                "Llama2-7b",
                "Llama3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Why Larger Language Models Do In-context Learning Differently": {
        "filename": "Why Larger Language Models Do In-context Learning Differently.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE (glue-rte, glue-sst2, glue-qqp, glue-wnli)",
                "Subj"
            ],
            "base_models": [
                "Llama-2-3B",
                "Llama-2-7B",
                "Llama-2-13B",
                "Llama-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models A Case Study on ChatGPT": {
        "filename": "Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models A Case Study on ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "WMT22 metrics shared task"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "Llama2-70B-Chat",
                "Mixtral-8x7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SmallToLarge S2L Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models": {
        "filename": "SmallToLarge S2L Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "MIMIC-III"
            ],
            "base_models": [
                "Pythia-70M",
                "Pythia-410M",
                "Pythia-2.8B",
                "Pythia-6.9B",
                "Phi-2",
                "Llama-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OpenICL An Open-Source Framework for In-context Learning": {
        "filename": "OpenICL An Open-Source Framework for In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "WMT16 (de-en)",
                "GSM8K",
                "PiQA",
                "Gigaword"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-Neo (2.7B)",
                "XGLM (7.5B)",
                "GPT2-XL (1.5B)"
            ]
        }
    },
    "Chain-of-Scrutiny Detecting Backdoor Attacks for Large Language Models": {
        "filename": "Chain-of-Scrutiny Detecting Backdoor Attacks for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "CSQA",
                "ARC",
                "AQuA",
                "SST-2",
                "AG-NEWS"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Gemini-1.0-pro",
                "Llama3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AGENT-DRIVEN LARGE LANGUAGE MODELS FOR MANDARIN LYRIC GENERATION": {
        "filename": "AGENT-DRIVEN LARGE LANGUAGE MODELS FOR MANDARIN LYRIC GENERATION.pdf",
        "analysis": {
            "benchmarks": [
                "Mpop600"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ]
        }
    },
    "ReviewerGPT An Exploratory Study on Using Large Language Models for Paper Reviewing": {
        "filename": "ReviewerGPT An Exploratory Study on Using Large Language Models for Paper Reviewing.pdf",
        "analysis": {
            "benchmarks": [
                "13 short computer science papers with inserted errors",
                "15 NeurIPS 2022 papers with checklist questions",
                "10 pairs of abstracts for comparative evaluation"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-Assisted Content Analysis Using Large Language Models to Support Deductive Coding": {
        "filename": "LLM-Assisted Content Analysis Using Large Language Models to Support Deductive Coding.pdf",
        "analysis": {
            "benchmarks": [
                "Trump Tweets",
                "Contrarian Claims",
                "BBC News",
                "Ukraine Water Problems"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aligning LLMs to Be Robust Against Prompt Injection": {
        "filename": "Aligning LLMs to Be Robust Against Prompt Injection.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaFarm"
            ],
            "base_models": [
                "Llama-7B",
                "Mistral-7B",
                "Llama3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CALF Benchmarking Evaluation of LFQA Using Chinese Examinations": {
        "filename": "CALF Benchmarking Evaluation of LFQA Using Chinese Examinations.pdf",
        "analysis": {
            "benchmarks": [
                "CALF"
            ],
            "base_models": [
                "Llama-3-8B",
                "GPT-3.5-turbo-1106-preview"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Far Can Camels Go Exploring the State of Instruction Tuning on Open Resources": {
        "filename": "How Far Can Camels Go Exploring the State of Instruction Tuning on Open Resources.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM",
                "BBH",
                "TyDiQA",
                "Codex-Eval",
                "ToxiGen",
                "TruthfulQA",
                "AlpacaEval"
            ],
            "base_models": [
                "LLaMa (6.7B, 13B, 32.5B, 65.2B)",
                "LLaMa-2 (6.7B, 13B)",
                "OPT (6.7B)",
                "Pythia (6.9B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RE-GAINS  EnCHANT Intelligent Tool Manipulation Systems For Enhanced Query Responses": {
        "filename": "RE-GAINS  EnCHANT Intelligent Tool Manipulation Systems For Enhanced Query Responses.pdf",
        "analysis": {
            "benchmarks": [
                "API Bank",
                "ToolBench",
                "ToolQA",
                "APIBench",
                "ToolAlpaca"
            ],
            "base_models": [
                "OpenChat 3.5",
                "GPT-3.5",
                "GPT-4",
                "LLAMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Pushing the Limits of ChatGPT on NLP Tasks": {
        "filename": "Pushing the Limits of ChatGPT on NLP Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "SQuADv2",
                "TQA",
                "MRQA-OOD",
                "CSQA",
                "StrategyQA",
                "RTE",
                "CommitmentBank (CB)",
                "SST-2",
                "IMDB",
                "Yelp",
                "CoNLL 2003",
                "OntoNotes 5.0",
                "ACE2004",
                "ACE2005",
                "WSJ Treebank",
                "Tweets"
            ],
            "base_models": [
                "ChatGPT",
                "RoBERTa-Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LAMBADA Backward Chaining for Automated Reasoning in Natural Language": {
        "filename": "LAMBADA Backward Chaining for Automated Reasoning in Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "ProofWriter",
                "PrOntoQA",
                "ParaRules"
            ],
            "base_models": [
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting": {
        "filename": "Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "GSM",
                "ECQA",
                "E-SNLI",
                "STRATEGY QA"
            ],
            "base_models": [
                "code-davinci-002",
                "text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LeanQuant Accurate and Scalable Large Language Model Quantization with Loss-error-aware Grid": {
        "filename": "LeanQuant Accurate and Scalable Large Language Model Quantization with Loss-error-aware Grid.pdf",
        "analysis": {
            "benchmarks": [
                "ARC",
                "LAMBADA",
                "MMLU",
                "HellaSwag",
                "PIQA",
                "WinoGrande",
                "WikiText2",
                "C4"
            ],
            "base_models": [
                "Llama-3.1 405B",
                "Llama-3-8B",
                "Llama-2-7B",
                "Mistral-7B",
                "Mistral-Large-Instruct-2407 (123B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to reason over scene graphs a case study of finetuning GPT-2 into a robot language model for grounded task planning": {
        "filename": "Learning to reason over scene graphs a case study of finetuning GPT-2 into a robot language model for grounded task planning.pdf",
        "analysis": {
            "benchmarks": [
                "ALFRED"
            ],
            "base_models": [
                "GPT-2 (1.5B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Finite Data Towards Data-free Out-of-distribution Generalization via Extrapolation": {
        "filename": "Beyond Finite Data Towards Data-free Out-of-distribution Generalization via Extrapolation.pdf",
        "analysis": {
            "benchmarks": [
                "PACS",
                "VLCS",
                "OfficeHome",
                "DomainNet"
            ],
            "base_models": [
                "ResNet50",
                "GPT-4",
                "Stable Diffusion 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SpeechVerse A Large-scale Generalizable Audio Language Model": {
        "filename": "SpeechVerse A Large-scale Generalizable Audio Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Librispeech",
                "Mozilla Common Voice 5.1",
                "VoxPopuli",
                "SLURP",
                "EuroParl",
                "MSP-Podcast 1.11",
                "CoVost2",
                "Fisher",
                "In-house VAD"
            ],
            "base_models": [
                "WavLM Large",
                "Flan-T5-XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automating the Enterprise with Foundation Models": {
        "filename": "Automating the Enterprise with Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "WebArena"
            ],
            "base_models": [
                "GPT-4",
                "CogAgent (18B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Controllable Speaking Styles Using A Large Language Model": {
        "filename": "Controllable Speaking Styles Using A Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "LJSpeech"
            ],
            "base_models": [
                "InstructGPT (175 billion parameters)",
                "FastSpeech-2"
            ]
        }
    },
    "Anchored Alignment for Self-Explanations Enhancement": {
        "filename": "Anchored Alignment for Self-Explanations Enhancement.pdf",
        "analysis": {
            "benchmarks": [
                "AQuA-Rat",
                "ARC-Challenge",
                "LogiQA",
                "OpenbookQA"
            ],
            "base_models": [
                "Llama-3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models": {
        "filename": "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA2-7B",
                "LLaMA-13B",
                "LLaMA2-13B",
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Repository-Level Prompt Generation for Large Language Models of Code": {
        "filename": "Repository-Level Prompt Generation for Large Language Models of Code.pdf",
        "analysis": {
            "benchmarks": [
                "Google Code archives (custom dataset)"
            ],
            "base_models": [
                "Codex"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Massive Activations in Large Language Models": {
        "filename": "Massive Activations in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WikiText",
                "C4",
                "PG-19",
                "BoolQ",
                "PIQA",
                "WinoGrande",
                "Arc-Easy",
                "Arc-Challenge",
                "ImageNet"
            ],
            "base_models": [
                "LLaMA2-7B",
                "LLaMA2-13B",
                "LLaMA2-70B",
                "Mixtral-8x7B",
                "Phi-2",
                "Mistral-7B",
                "MPT-7B",
                "Falcon-7B",
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PaCE Parsimonious Concept Engineering for Large Language Models": {
        "filename": "PaCE Parsimonious Concept Engineering for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SafeEdit"
            ],
            "base_models": [
                "LLaMA2-7B-Chat",
                "LLaMA2-13B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Its not like Jarvis but its pretty close - Examining ChatGPTs Usage among Undergraduate Students in Computer Science": {
        "filename": "Its not like Jarvis but its pretty close - Examining ChatGPTs Usage among Undergraduate Students in Computer Science.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (GPT-3.5 and GPT-4)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PROMPTFUZZ Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs": {
        "filename": "PROMPTFUZZ Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "TensorTrust dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Identifying Inaccurate Descriptions in LLM-generated Code Comments via Test Execution": {
        "filename": "Identifying Inaccurate Descriptions in LLM-generated Code Comments via Test Execution.pdf",
        "analysis": {
            "benchmarks": [
                "Defects4J"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "StarCoder"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ComfyBench Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems": {
        "filename": "ComfyBench Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems.pdf",
        "analysis": {
            "benchmarks": [
                "ComfyBench"
            ],
            "base_models": [
                "GPT-4o",
                "Llama-3.1-70B",
                "Claude-3.5-Sonnet",
                "o1-mini",
                "o1-preview"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating the Reliability of Self-Explanations in Large Language Models": {
        "filename": "Evaluating the Reliability of Self-Explanations in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Food Recall Incidents dataset",
                "Movie Review Polarity dataset v2"
            ],
            "base_models": [
                "Gemma 1.1 Instruct (2B)",
                "Gemma 1.1 Instruct (7B)",
                "Llama 3 Instruct (8B)"
            ]
        }
    },
    "CAAP Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only": {
        "filename": "CAAP Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only.pdf",
        "analysis": {
            "benchmarks": [
                "MiniWoB++",
                "WebShop"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding Transformer Reasoning Capabilities via Graph Algorithms": {
        "filename": "Understanding Transformer Reasoning Capabilities via Graph Algorithms.pdf",
        "analysis": {
            "benchmarks": [
                "GraphQA"
            ],
            "base_models": [
                "T5-11B",
                "60M transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Configuration Validation with Large Language Models": {
        "filename": "Configuration Validation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Ctest dataset",
                "Synthesized misconfiguration datasets for Alluxio, Django, Etcd, HBase, Hadoop Common, HDFS, PostgreSQL, Redis, YARN, ZooKeeper"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "GPT-3.5-Turbo",
                "Claude-3-Opus",
                "Claude-3-Sonnet",
                "CodeLlama-7B",
                "CodeLlama-13B",
                "CodeLlama-34B",
                "DeepSeek-6.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Inference Scaling Laws An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models": {
        "filename": "Inference Scaling Laws An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH500"
            ],
            "base_models": [
                "Pythia (various sizes)",
                "Llemma-7B",
                "Llemma-34B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-FuncMapper Function Identification for Interpreting Complex Clauses in Building Codes via LLM": {
        "filename": "LLM-FuncMapper Function Identification for Interpreting Complex Clauses in Building Codes via LLM.pdf",
        "analysis": {
            "benchmarks": [
                "Chinese Code for fire protection design of buildings (GB 50016-2014)"
            ],
            "base_models": [
                "Claude"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Knowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever": {
        "filename": "Knowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever.pdf",
        "analysis": {
            "benchmarks": [
                "MathKnowCT"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-3.5-turbo",
                "Llama-3-70B",
                "Llama-3-8B",
                "Mistral-8x7B",
                "Mistral-7B",
                "Qwen1.5-72B",
                "Qwen1.5-7B"
            ]
        }
    },
    "Graph-enhanced Large Language Models in Asynchronous Plan Reasoning": {
        "filename": "Graph-enhanced Large Language Models in Asynchronous Plan Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "AsyncHow"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Cohere Command1",
                "LLaMA-2-70B-chat",
                "Mistral-7B-Instruct (v0.2)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving In-context Learning via Bidirectional Alignment": {
        "filename": "Improving In-context Learning via Bidirectional Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "LogiQA",
                "MMLU",
                "BBH",
                "HumanEval"
            ],
            "base_models": [
                "Llama 2-7B",
                "Llama 2-13B",
                "Llama 2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LaMPilot An Open Benchmark Dataset for Autonomous Driving with Language Model Programs": {
        "filename": "LaMPilot An Open Benchmark Dataset for Autonomous Driving with Language Model Programs.pdf",
        "analysis": {
            "benchmarks": [
                "LaMPilot-Bench"
            ],
            "base_models": [
                "Llama 2 (70B)",
                "PaLM 2",
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-4",
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VoxPoser Composable 3D Value Maps for Robotic Manipulation with Language Models": {
        "filename": "VoxPoser Composable 3D Value Maps for Robotic Manipulation with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom real-world everyday manipulation tasks",
                "Simulated block-world environment"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Automated Data Science Introducing CAAFE for Context-Aware Automated Feature Engineering": {
        "filename": "Large Language Models for Automated Data Science Introducing CAAFE for Context-Aware Automated Feature Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "airlines",
                "balance-scale",
                "breast-w",
                "cmc",
                "credit-g",
                "diabetes",
                "eucalyptus",
                "jungle_chess",
                "pc1",
                "tic-tac-toe",
                "health-insurance",
                "pharyngitis",
                "kidney-stone",
                "spaceship-titanic"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AceCoder Utilizing Existing Code to Enhance Code Generation": {
        "filename": "AceCoder Utilizing Existing Code to Enhance Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MBPP",
                "MBJP",
                "MBJSP"
            ],
            "base_models": [
                "CodeGeeX-13B",
                "CodeGen-6B",
                "InCoder-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Program Testing Ability of Large Language Models for Code": {
        "filename": "The Program Testing Ability of Large Language Models for Code.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval+",
                "MBPP (sanitized version)"
            ],
            "base_models": [
                "InCoder (1.3B)",
                "CodeGen2 (1B)",
                "CodeT5+ (770M)",
                "SantaCoder (1.1B)",
                "CodeGen2 (16B)",
                "CodeGen-Multi (16B)",
                "CodeGen-Mono (16B)",
                "StarCoder (15B)",
                "WizardCoder (15B)",
                "CodeGeeX2 (6B)",
                "GPT-3.5-turbo"
            ]
        }
    },
    "LanFL Differentially Private Federated Learning with Large Language Models using Synthetic Samples": {
        "filename": "LanFL Differentially Private Federated Learning with Large Language Models using Synthetic Samples.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "UCI Credit Card Default dataset"
            ],
            "base_models": [
                "PaLM 2",
                "Gemini-1.5-Flash",
                "Llama3.1-70B",
                "Mixtral-8x7B"
            ]
        }
    },
    "The System Model and the User Model Exploring AI Dashboard Design": {
        "filename": "The System Model and the User Model Exploring AI Dashboard Design.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "Artificial Intelligence and Aesthetic Judgment": {
        "filename": "Artificial Intelligence and Aesthetic Judgment.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Nugget Neural Agglomerative Embeddings of Text": {
        "filename": "Nugget Neural Agglomerative Embeddings of Text.pdf",
        "analysis": {
            "benchmarks": [
                "WMT19 English-to-Chinese subset",
                "PARABANK",
                "WikiText-103"
            ],
            "base_models": [
                "BART (12 layers, 602M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WARM On the Benefits of Weight Averaged Reward Models": {
        "filename": "WARM On the Benefits of Weight Averaged Reward Models.pdf",
        "analysis": {
            "benchmarks": [
                "TL;DR summarization benchmark"
            ],
            "base_models": [
                "GPT-3",
                "PaLM-L",
                "PaLM-XXS",
                "PaLM-XS",
                "T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game": {
        "filename": "Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game.pdf",
        "analysis": {
            "benchmarks": [
                "Werewolf game"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MetaRuleGPT Recursive Numerical Reasoning of Language Models Trained with Simple Rules": {
        "filename": "MetaRuleGPT Recursive Numerical Reasoning of Language Models Trained with Simple Rules.pdf",
        "analysis": {
            "benchmarks": [
                "gsm8k",
                "custom arithmetic test dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Llama2-7b",
                "Llama2-13b",
                "Llama2-70b",
                "Google-PaLM",
                "Qwen-72b-Chat",
                "MetaRuleGPT (30M)"
            ]
        }
    },
    "AgentMonitor A Plug-and-Play Framework for Predictive and Secure Multi-Agent Systems": {
        "filename": "AgentMonitor A Plug-and-Play Framework for Predictive and Secure Multi-Agent Systems.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MMLU",
                "GSM8K"
            ],
            "base_models": [
                "Llama3-8B",
                "Llama3-70B",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Mixture of Experts": {
        "filename": "A Survey on Mixture of Experts.pdf",
        "analysis": {
            "benchmarks": [
                "Wikitext",
                "T5-GLUE",
                "ResNet-DomainNet"
            ],
            "base_models": [
                "PaLM-540B",
                "LLaMA-2-70B",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What Makes Multimodal In-Context Learning Work": {
        "filename": "What Makes Multimodal In-Context Learning Work.pdf",
        "analysis": {
            "benchmarks": [
                "COCO",
                "Flickr30k",
                "CIFAR-100",
                "ImageNet",
                "Hateful Memes",
                "Rendered SST2",
                "VizWiz",
                "VQAv2",
                "OK-VQA",
                "TextVQA",
                "ScienceQA",
                "MMMU"
            ],
            "base_models": [
                "IDEFICS (9B)",
                "OpenFlamingo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Conceptual Engineering Using Large Language Models": {
        "filename": "Conceptual Engineering Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Wikidata knowledge graph"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLaMP Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation": {
        "filename": "LLaMP Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "Materials Project (MP)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DivCon Divide and Conquer for Progressive Text-to-Image Generation": {
        "filename": "DivCon Divide and Conquer for Progressive Text-to-Image Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HRS",
                "NSR-1K"
            ],
            "base_models": [
                "Stable Diffusion (v2.1)"
            ]
        }
    },
    "Large Language Models as Evolutionary Optimizers": {
        "filename": "Large Language Models as Evolutionary Optimizers.pdf",
        "analysis": {
            "benchmarks": [
                "Traveling Salesman Problems (TSPs) with up to 20 nodes"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "Monolingual or Multilingual Instruction Tuning Which Makes a Better Alpaca": {
        "filename": "Monolingual or Multilingual Instruction Tuning Which Makes a Better Alpaca.pdf",
        "analysis": {
            "benchmarks": [
                "OpenAssistant"
            ],
            "base_models": [
                "Baichuan-2 (7B)",
                "BLOOM (560M to 7.1B)",
                "LLaMA (7B)",
                "OpenLLaMA (7B)",
                "Pythia (70M to 12B)"
            ]
        }
    },
    "Sorting Out the Bad Seeds Automatic Classification of Cryptocurrency Abuse Reports": {
        "filename": "Sorting Out the Bad Seeds Automatic Classification of Cryptocurrency Abuse Reports.pdf",
        "analysis": {
            "benchmarks": [
                "BitcoinAbuse",
                "BBB ScamTracker"
            ],
            "base_models": [
                "gpt-4",
                "gpt-4o",
                "gpt-3.5",
                "llama3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MolX Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension": {
        "filename": "MolX Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension.pdf",
        "analysis": {
            "benchmarks": [
                "PubChem dataset",
                "MoleculeNet dataset",
                "ChEMBL-02",
                "USPTO-50k"
            ],
            "base_models": [
                "Llama-2 (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Applying Powerful Large AI Models in Classroom Teaching Opportunities Challenges and Prospects": {
        "filename": "Towards Applying Powerful Large AI Models in Classroom Teaching Opportunities Challenges and Prospects.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM",
                "Galactica",
                "LaMDA",
                "LLaMA"
            ]
        }
    },
    "A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER": {
        "filename": "A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER.pdf",
        "analysis": {
            "benchmarks": [
                "Few-NERD",
                "CrossNER"
            ],
            "base_models": [
                "BERT-base-uncased"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ReMI A Dataset for Reasoning with Multiple Images": {
        "filename": "ReMI A Dataset for Reasoning with Multiple Images.pdf",
        "analysis": {
            "benchmarks": [
                "ReMI"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "Claude 3 Sonnet",
                "Gemini Ultra",
                "Gemini Flash",
                "Gemini 1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automated Program Repair Emerging trends pose and expose problems for benchmarks": {
        "filename": "Automated Program Repair Emerging trends pose and expose problems for benchmarks.pdf",
        "analysis": {
            "benchmarks": [
                "Defects4J",
                "ManyBugs"
            ],
            "base_models": [
                "GPT (size not specified)",
                "CodeBERT (size not specified)",
                "CodeT5 (size not specified)",
                "PLBART (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Diversity Measures Domain-Independent Proxies for Failure in Language Model Queries": {
        "filename": "Diversity Measures Domain-Independent Proxies for Failure in Language Model Queries.pdf",
        "analysis": {
            "benchmarks": [
                "CSQA",
                "DRAW-1K",
                "LL"
            ],
            "base_models": [
                "GPT-3.5",
                "sentence-BERT"
            ]
        }
    },
    "Provable optimal transport with transformers The essence of depth and prompt engineering": {
        "filename": "Provable optimal transport with transformers The essence of depth and prompt engineering.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PlanBench An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change": {
        "filename": "PlanBench An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change.pdf",
        "analysis": {
            "benchmarks": [
                "PlanBench"
            ],
            "base_models": [
                "GPT-4",
                "Instruct-GPT3 (text-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bootstrap3D Improving Multi-view Diffusion Model with Synthetic Data": {
        "filename": "Bootstrap3D Improving Multi-view Diffusion Model with Synthetic Data.pdf",
        "analysis": {
            "benchmarks": [
                "Objaverse",
                "Objaverse-XL"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA",
                "DiT-XL/2",
                "Flan-T5-XXL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Does ChatGPT Have a Mind": {
        "filename": "Does ChatGPT Have a Mind.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mathematical Capabilities of ChatGPT": {
        "filename": "Mathematical Capabilities of ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "GHOSTS",
                "miniGHOSTS",
                "MATH"
            ],
            "base_models": [
                "ChatGPT (9-January-2023 version)",
                "ChatGPT (30-January-2023 version)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Weak-eval-Strong Evaluating and Eliciting Lateral Thinking of LLMs with Situation Puzzles": {
        "filename": "Weak-eval-Strong Evaluating and Eliciting Lateral Thinking of LLMs with Situation Puzzles.pdf",
        "analysis": {
            "benchmarks": [
                "SPLAT",
                "RiddleSense",
                "BrainTeaser"
            ],
            "base_models": [
                "WizardLM-2 (8x22B)",
                "Llama3-70B",
                "GPT-4",
                "GPT-4 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Eir Thai Medical Large Language Models": {
        "filename": "Eir Thai Medical Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "MedMCQA",
                "PubMedQA",
                "MMLU medical-subset"
            ],
            "base_models": [
                "LLaMA 3.1 Instruct-8B (8 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Planning with Large Language Models A Modular Agentic Architecture": {
        "filename": "Improving Planning with Large Language Models A Modular Agentic Architecture.pdf",
        "analysis": {
            "benchmarks": [
                "graph traversal (CogEval protocol)",
                "Tower of Hanoi",
                "PlanBench",
                "StrategyQA"
            ],
            "base_models": [
                "GPT-4",
                "Llama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Comprehensive Survey of Attack Techniques Implementation and Mitigation Strategies in Large Language Models": {
        "filename": "A Comprehensive Survey of Attack Techniques Implementation and Mitigation Strategies in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5 turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Discuss Before Moving Visual Language Navigation via Multi-expert Discussions": {
        "filename": "Discuss Before Moving Visual Language Navigation via Multi-expert Discussions.pdf",
        "analysis": {
            "benchmarks": [
                "R2R"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "InstructBLIP FlanT5 XL",
                "RAM-14M"
            ]
        }
    },
    "Toward Robust Evaluation A Comprehensive Taxonomy of Datasets and Metrics for Open Domain Question Answering in the Era of Large Language Models": {
        "filename": "Toward Robust Evaluation A Comprehensive Taxonomy of Datasets and Metrics for Open Domain Question Answering in the Era of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WebQuestions",
                "CuratedTREC",
                "WikiQA",
                "SQuAD",
                "MS Marco",
                "Quasar-T",
                "SearchQA",
                "TriviaQA",
                "BoolQ",
                "Natural Questions",
                "ELI5",
                "AMBIGNQ",
                "ASQA",
                "HotPotQA",
                "DROP",
                "2WikiMultiHopQA",
                "MultiSpanQA",
                "QAMPARI",
                "ConcurrentQA",
                "QuAC",
                "QBLink",
                "CoQA",
                "OR-QuAC",
                "QReCC",
                "TopiOCQA",
                "Topical-Chat",
                "XQA",
                "MLQA",
                "XQuAD",
                "TyDiQA",
                "XTREME",
                "XOR-TyDiQA",
                "MKQA",
                "GEN-TyDiQA",
                "SituatedQA",
                "TimeQA",
                "FreshQA",
                "ComQA",
                "Paraphrased-SQuAD",
                "CREPE",
                "TruthfulQA",
                "IfQA",
                "OK-VQA",
                "S3VQA",
                "MIMOQA",
                "A-OKVQA",
                "WebQA",
                "HybridQA",
                "OTT-QA",
                "ManyModalQA",
                "MultiModalQA",
                "MMConvQA"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "T5",
                "BART",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "High-Fidelity Lake Extraction Via Two-Stage Prompt Enhancement Establishing A Novel Baseline and Benchmark": {
        "filename": "High-Fidelity Lake Extraction Via Two-Stage Prompt Enhancement Establishing A Novel Baseline and Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "Surface Water dataset (SW dataset)",
                "Qinghai-Tibet Plateau Lake dataset (QTPL dataset)",
                "CVC-ClinicDB (CVC) dataset",
                "ISIC2018 dataset"
            ],
            "base_models": [
                "ResNet-101",
                "ViT-H",
                "LEFormer"
            ]
        }
    },
    "Stance detection a practical guide to classifying political beliefs in text": {
        "filename": "Stance detection a practical guide to classifying political beliefs in text.pdf",
        "analysis": {
            "benchmarks": [
                "Semeval 2016 test data set",
                "COVID-19 related tweets dataset"
            ],
            "base_models": [
                "GPT-4",
                "DeBERTaV3 Large",
                "RoBERTa",
                "BERTweet",
                "PoliBERTweet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Galactica A Large Language Model for Science": {
        "filename": "Galactica A Large Language Model for Science.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "MATH",
                "PubMedQA",
                "MedMCQA",
                "BIG-bench"
            ],
            "base_models": [
                "GPT-3",
                "Chinchilla",
                "PaLM-540B",
                "BLOOM",
                "OPT-175B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating LLMs Capabilities Towards Understanding Social Dynamics": {
        "filename": "Evaluating LLMs Capabilities Towards Understanding Social Dynamics.pdf",
        "analysis": {
            "benchmarks": [
                "Instagram sessions dataset",
                "4chan threads dataset"
            ],
            "base_models": [
                "Llama-2 7B",
                "Llama-2 13B",
                "ChatGPT (GPT-3.5)",
                "GPT-2"
            ]
        }
    },
    "OntoChatGPT Information System Ontology-Driven Structured Prompts for ChatGPT Meta-Learning": {
        "filename": "OntoChatGPT Information System Ontology-Driven Structured Prompts for ChatGPT Meta-Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Ukrainian version of the 'White Book on Physical and Rehabilitation Medicine in Europe'"
            ],
            "base_models": [
                "ChatGPT (based on OpenAI's GPT-3, GPT-3.5, and GPT-4)",
                "Google's Bard utilizing the PaLM 2 LLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ShapefileGPT A Multi-Agent Large Language Model Framework for Automated Shapefile Processing": {
        "filename": "ShapefileGPT A Multi-Agent Large Language Model Framework for Automated Shapefile Processing.pdf",
        "analysis": {
            "benchmarks": [
                "Shapefile task dataset"
            ],
            "base_models": [
                "GPT-4o-2024-05-13",
                "GPT-4o-Mini-2024-07-18",
                "GPT-3.5-Turbo-0125"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "One Prompt is not Enough Automated Construction of a Mixture-of-Expert Prompts": {
        "filename": "One Prompt is not Enough Automated Construction of a Mixture-of-Expert Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "Instruction-Induction",
                "Super Natural Instructions",
                "BIG-Bench-Hard"
            ],
            "base_models": [
                "GPT-3.5-Turbo-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews": {
        "filename": "The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews.pdf",
        "analysis": {
            "benchmarks": [
                "20 papers from a prior systematic review"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ArtWhisperer A Dataset for Characterizing Human-AI Interactions in Artistic Creations": {
        "filename": "ArtWhisperer A Dataset for Characterizing Human-AI Interactions in Artistic Creations.pdf",
        "analysis": {
            "benchmarks": [
                "ArtWhisperer",
                "ArtWhisperer-Validation"
            ],
            "base_models": [
                "Stable Diffusion v2.1",
                "Stable Diffusion v1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GITA Graph to Visual and Textual Integration for Vision-Language Graph Reasoning": {
        "filename": "GITA Graph to Visual and Textual Integration for Vision-Language Graph Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GVLQA",
                "ca-GrQc",
                "ca-HepTh",
                "PolBlogs",
                "Cora",
                "CiteSeer"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA-7B",
                "LLaVA-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multimodal Multi-Hop Question Answering Through a Conversation Between Tools and Efficiently Finetuned Large Language Models": {
        "filename": "Multimodal Multi-Hop Question Answering Through a Conversation Between Tools and Efficiently Finetuned Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MultiModalQA",
                "MMCoQA"
            ],
            "base_models": [
                "StableLM-7b",
                "Pathia-12b",
                "LLaMA-13b",
                "Falcon-40b",
                "ChatGPT"
            ]
        }
    },
    "Solving Math Word Problems by Combining Language Models With Symbolic Solvers": {
        "filename": "Solving Math Word Problems by Combining Language Models With Symbolic Solvers.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "ALGEBRA"
            ],
            "base_models": [
                "Codex (code-davinci-002)"
            ]
        }
    },
    "Code Detection for Hardware Acceleration Using Large Language Models": {
        "filename": "Code Detection for Hardware Acceleration Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom benchmark suite for code detection (GEMM, convolution, FFT)",
                "False positives benchmark (Parboil, Caffe, ACOTSP, cpufetch)"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning": {
        "filename": "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "ChartQA",
                "Beagle image dataset",
                "visual literacy assessment datasets"
            ],
            "base_models": [
                "GPT-4-Vision-Preview",
                "Qwen-VL-Max",
                "LLaVA-1.5",
                "CLIP-Vit",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SMART Self-learning Meta-strategy Agent for Reasoning Tasks": {
        "filename": "SMART Self-learning Meta-strategy Agent for Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "ASDiv"
            ],
            "base_models": [
                "Llama3 8B",
                "Gemma 7B",
                "Mistral 7B",
                "Qwen2 7B"
            ]
        }
    },
    "FACTIFY-5WQA 5W Aspect-based Fact Verification through Question Answering": {
        "filename": "FACTIFY-5WQA 5W Aspect-based Fact Verification through Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "FEVER",
                "LIAR",
                "PolitiFact",
                "FavIQ",
                "Hover",
                "X-Fact",
                "CREAK",
                "FEVEROUS",
                "FACTIFY-5WQA"
            ],
            "base_models": [
                "RoBERTa Large",
                "Pegasus",
                "T5 (T5-Large)",
                "GPT-3 (text-davinci-003 variant)",
                "BERT large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Octavius Mitigating Task Interference in MLLMs via LoRA-MoE": {
        "filename": "Octavius Mitigating Task Interference in MLLMs via LoRA-MoE.pdf",
        "analysis": {
            "benchmarks": [
                "PASCAL VOC",
                "ScienceQA",
                "CIFAR-10",
                "Flickr30K",
                "CelebA",
                "ShapeNet",
                "NR3D",
                "ScanNet"
            ],
            "base_models": [
                "LLaMA (size not specified)",
                "CLIP (ViT-L/14)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unlocking Historical Clinical Trial Data with ALIGN A Compositional Large Language Model System for Medical Coding": {
        "filename": "Unlocking Historical Clinical Trial Data with ALIGN A Compositional Large Language Model System for Medical Coding.pdf",
        "analysis": {
            "benchmarks": [
                "Anatomical Therapeutic Chemical (ATC) codes",
                "Medical Dictionary for Regulatory Activities (MedDRA) codes"
            ],
            "base_models": [
                "GPT-4o-mini",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLMs Reason in Music An Evaluation of LLMs Capability of Music Understanding and Generation": {
        "filename": "Can LLMs Reason in Music An Evaluation of LLMs Capability of Music Understanding and Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MusicPile",
                "MusicBench"
            ],
            "base_models": [
                "GPT-4",
                "Gemma-7B-it",
                "Llama2-7B-chat",
                "Qwen-7B-chat"
            ]
        }
    },
    "ChartGPT Leveraging LLMs to Generate Charts from Abstract Natural Language": {
        "filename": "ChartGPT Leveraging LLMs to Generate Charts from Abstract Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of abstract utterances and charts"
            ],
            "base_models": [
                "GPT-3",
                "FLAN-T5-XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Vision-Language-Action Models for Embodied AI": {
        "filename": "A Survey on Vision-Language-Action Models for Embodied AI.pdf",
        "analysis": {
            "benchmarks": [
                "Ravens",
                "RLBench"
            ],
            "base_models": [
                "CLIP-ResNet50",
                "ViT-B",
                "EfficientNet",
                "T5",
                "PaLM-E"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MAgIC Investigation of Large Language Model Powered Multi-Agent in Cognition Adaptability Rationality and Collaboration": {
        "filename": "MAgIC Investigation of Large Language Model Powered Multi-Agent in Cognition Adaptability Rationality and Collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "Chameleon",
                "Undercover",
                "Cost Sharing",
                "Multi-turn Prisoner's Dilemma",
                "Public Good"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Llama-2-70B",
                "PaLM 2",
                "Claude 2",
                "Cohere"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Compositional API Recommendation for Library-Oriented Code Generation": {
        "filename": "Compositional API Recommendation for Library-Oriented Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "RAPID",
                "LOCG"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "ada-embedding-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Traditional Teaching The Potential of Large Language Models and Chatbots in Graduate Engineering Education": {
        "filename": "Beyond Traditional Teaching The Potential of Large Language Models and Chatbots in Graduate Engineering Education.pdf",
        "analysis": {
            "benchmarks": [
                "Custom question bank from a graduate fluid mechanics course"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "ChatGPT-4",
                "ChatGPT-4 with Wolfram plugin"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Far Are We on the Decision-Making of LLMs Evaluating LLMs Gaming Ability in Multi-Agent Environments": {
        "filename": "How Far Are We on the Decision-Making of LLMs Evaluating LLMs Gaming Ability in Multi-Agent Environments.pdf",
        "analysis": {
            "benchmarks": [
                "GAMA-Bench"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Gemini-1.5-Pro",
                "LLaMA-3.1-70B",
                "Mixtral-8x22B",
                "Qwen-2-72B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Benchmarking Generative Models on Computational Thinking Tests in Elementary Visual Programming": {
        "filename": "Benchmarking Generative Models on Computational Thinking Tests in Elementary Visual Programming.pdf",
        "analysis": {
            "benchmarks": [
                "HOC (Hour of Code: Maze Challenge)",
                "ACE (Analyzing-Evaluating-Creating test)",
                "CT-TEST (Computational Thinking Test)"
            ],
            "base_models": [
                "GPT-4o",
                "Llama3-8B"
            ]
        }
    },
    "ESG Classification by Implicit Rule Learning via GPT-4": {
        "filename": "ESG Classification by Implicit Rule Learning via GPT-4.pdf",
        "analysis": {
            "benchmarks": [
                "Shared-Task ML-ESG-3"
            ],
            "base_models": [
                "GPT-4",
                "Yi-Ko-6B",
                "EEVE-Korean-10.8B"
            ]
        }
    },
    "On the application of Large Language Models for language teaching and assessment technology": {
        "filename": "On the application of Large Language Models for language teaching and assessment technology.pdf",
        "analysis": {
            "benchmarks": [
                "RACE",
                "SCDE",
                "CLOTH",
                "CEPOC",
                "Teacher-Student Chatroom Corpus",
                "CoNLL-2014",
                "JFLEG",
                "BEA-2019",
                "TOEFL11"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3",
                "BERT",
                "PaLM",
                "LaMDA",
                "LLaMA",
                "OPT",
                "Gopher",
                "T5",
                "BART",
                "DistilBERT",
                "ELECTRA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Voluminous yet Vacuous Semantic Capital in an Age of Large Language Models": {
        "filename": "Voluminous yet Vacuous Semantic Capital in an Age of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LC-LLM Explainable Lane-Change Intention and Trajectory Predictions with Large Language Models": {
        "filename": "LC-LLM Explainable Lane-Change Intention and Trajectory Predictions with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "highD dataset"
            ],
            "base_models": [
                "Llama-2-13B-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Automatic VQA Evaluation Using Large Language Models": {
        "filename": "Improving Automatic VQA Evaluation Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "VQAv2",
                "VG-QA",
                "OK-VQA"
            ],
            "base_models": [
                "Flan-T5-XXL",
                "Vicuna-v1.3-13B",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment": {
        "filename": "Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment.pdf",
        "analysis": {
            "benchmarks": [
                "SOCIAL CHEMISTRY",
                "Custom dataset from Zhihu"
            ],
            "base_models": [
                "GPT-3",
                "XLM-R"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Foundation Models for Weather and Climate Data Understanding A Comprehensive Survey": {
        "filename": "Foundation Models for Weather and Climate Data Understanding A Comprehensive Survey.pdf",
        "analysis": {
            "benchmarks": [
                "PANGU-WEATHER",
                "W-MAE"
            ],
            "base_models": [
                "Transformer",
                "CLIMAX (uses Transformer)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Large Language Models in Medicine Progress Application and Challenge": {
        "filename": "A Survey of Large Language Models in Medicine Progress Application and Challenge.pdf",
        "analysis": {
            "benchmarks": [
                "USMLE (MedQA)",
                "NCBI disease dataset"
            ],
            "base_models": [
                "PaLM (540B)",
                "GPT-4",
                "LLaMA-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Midas Touch Triggering the Capability of LLMs for RM-API Misuse Detection": {
        "filename": "The Midas Touch Triggering the Capability of LLMs for RM-API Misuse Detection.pdf",
        "analysis": {
            "benchmarks": [
                "FFmpeg",
                "Libevent",
                "Libexpat",
                "Libpcap",
                "Libzip",
                "OpenLdap"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Networking Applications Enabling Techniques and Challenges": {
        "filename": "Large Language Models for Networking Applications Enabling Techniques and Challenges.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "LLaMA"
            ]
        }
    },
    "ChatGPT and Beyond The Generative AI Revolution in Education": {
        "filename": "ChatGPT and Beyond The Generative AI Revolution in Education.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (based on GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning the meanings of function words from grounded language using a visual question answering model": {
        "filename": "Learning the meanings of function words from grounded language using a visual question answering model.pdf",
        "analysis": {
            "benchmarks": [
                "CLEVR"
            ],
            "base_models": [
                "MAC model (no specific size mentioned)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Small Language Models for Application Interactions A Case Study": {
        "filename": "Small Language Models for Application Interactions A Case Study.pdf",
        "analysis": {
            "benchmarks": [
                "Microsoft internal application for cloud supply chain fulfillment"
            ],
            "base_models": [
                "Phi-3 mini (3.8B)",
                "Mistral v0.2 (7B)",
                "Llama 3 (8B)",
                "GPT-3.5-turbo",
                "GPT-4-turbo"
            ]
        }
    },
    "The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task": {
        "filename": "The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task.pdf",
        "analysis": {
            "benchmarks": [
                "Winoground"
            ],
            "base_models": [
                "GPT-4V"
            ]
        }
    },
    "On the Roles of LLMs in Planning Embedding LLMs into Planning Graphs": {
        "filename": "On the Roles of LLMs in Planning Embedding LLMs into Planning Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "gripper",
                "miconic",
                "logistics",
                "movie",
                "blocks",
                "satellite",
                "zenotravel",
                "driverlog",
                "woodworking",
                "openstacks"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Context Awareness Gate For Retrieval Augmented Generation": {
        "filename": "Context Awareness Gate For Retrieval Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "CRSB"
            ],
            "base_models": [
                "Gemma 2 9B"
            ]
        }
    },
    "GEAR An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM": {
        "filename": "GEAR An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "AQuA",
                "BigBench Hard",
                "LongBench"
            ],
            "base_models": [
                "LLaMA2-7B",
                "LLaMA2-13B",
                "Mistral-7B",
                "LLaMA3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cleared for Takeoff Compositional  Conditional Reasoning may be the Achilles Heel to Flight-Booking Language Agents": {
        "filename": "Cleared for Takeoff Compositional  Conditional Reasoning may be the Achilles Heel to Flight-Booking Language Agents.pdf",
        "analysis": {
            "benchmarks": [
                "GroundCocoa"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "LLAMA 2-chat 7B",
                "Mistral 7B Instruct",
                "LLAMA 2-chat 13B",
                "Mixtral 8x7B-Instruct",
                "LLAMA 2-chat 70B",
                "Gemini Pro"
            ]
        }
    },
    "Towards Safe and Honest AI Agents with Neural Self-Other Overlap": {
        "filename": "Towards Safe and Honest AI Agents with Neural Self-Other Overlap.pdf",
        "analysis": {
            "benchmarks": [
                "MT-Bench"
            ],
            "base_models": [
                "Mistral-7B-Instruct-v0.2",
                "Gemma-2-27B-it",
                "CalmeRys-78B-Orpo-v0.1"
            ]
        }
    },
    "Exploring Length Generalization in Large Language Models": {
        "filename": "Exploring Length Generalization in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MATH dataset",
                "Archive of Formal Proofs"
            ],
            "base_models": [
                "LaMDA (244m, 422m, 1b, 64b, 128b)"
            ]
        }
    },
    "GraphEval2000 Benchmarking and Improving Large Language Models on Graph Datasets": {
        "filename": "GraphEval2000 Benchmarking and Improving Large Language Models on Graph Datasets.pdf",
        "analysis": {
            "benchmarks": [
                "GraphEval2000"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "GPT-4o",
                "Gemini-Pro",
                "Gemini-1.5",
                "Claude-3-Haiku",
                "Claude-3-Sonnet",
                "Claude-3-Opus",
                "LLaMA-3-70b",
                "Mixtral-8x7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LMTuner An user-friendly and highly-integrable Training Framework for fine-tuning Large Language Models": {
        "filename": "LMTuner An user-friendly and highly-integrable Training Framework for fine-tuning Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "LM-Medical-v1",
                "MedDialog"
            ],
            "base_models": [
                "GPT-4",
                "ChatGLM2-6B",
                "Llama-7B",
                "Llama2-13B",
                "GLM-130B"
            ]
        }
    },
    "ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality": {
        "filename": "ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality.pdf",
        "analysis": {
            "benchmarks": [
                "eXclusivi platform (custom dataset)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models": {
        "filename": "The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ARC",
                "AGIEval",
                "HellaSwag",
                "MedMCQA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Better Out-of-Distribution Generalization of Neural Algorithmic Reasoning Tasks": {
        "filename": "Towards Better Out-of-Distribution Generalization of Neural Algorithmic Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "CLRS"
            ],
            "base_models": [
                "MPNN (Gilmer et al., 2017)",
                "PGN (Veličković et al., 2020a)",
                "GAT (Veličković et al., 2018)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can large language models reason about medical questions": {
        "filename": "Can large language models reason about medical questions.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA-USMLE",
                "MedMCQA",
                "PubMedQA"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama-2 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Easily do Irrelevant Inputs Skew the Responses of Large Language Models": {
        "filename": "How Easily do Irrelevant Inputs Skew the Responses of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "POPQA",
                "ENTITY QUESTIONS"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "GPT-3.5 Turbo",
                "Gemini Pro",
                "Llama2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TorchQL A Programming Framework for Integrity Constraints in Machine Learning": {
        "filename": "TorchQL A Programming Framework for Integrity Constraints in Machine Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Cityscapes validation set"
            ],
            "base_models": [
                "OneFormer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance": {
        "filename": "Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance.pdf",
        "analysis": {
            "benchmarks": [
                "COLIEE 2022"
            ],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "Towards Responsible Generative AI A Reference Architecture for Designing Foundation Model Based Agents": {
        "filename": "Towards Responsible Generative AI A Reference Architecture for Designing Foundation Model Based Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "text-davinci-003"
            ]
        }
    },
    "CRUD-RAG A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models": {
        "filename": "CRUD-RAG A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CRUD-RAG (includes text continuation, question answering, hallucination modification, and multi-document summarization)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "ChatGLM2-6B",
                "Baichuan2-13B",
                "Qwen-7B",
                "Qwen-14B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLaMA-Berry Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning": {
        "filename": "LLaMA-Berry Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "AIME24",
                "AMC23",
                "GSM8K",
                "MATH",
                "OlympiadBench",
                "College Math",
                "MMLU STEM"
            ],
            "base_models": [
                "LLaMA-3.1-8B",
                "GPT-4 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Guided Stream of Search Learning to Better Search with Language Models via Optimal Path Guidance": {
        "filename": "Guided Stream of Search Learning to Better Search with Language Models via Optimal Path Guidance.pdf",
        "analysis": {
            "benchmarks": [
                "Countdown"
            ],
            "base_models": [
                "GPT-2 (250M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ContextIQ A Multimodal Expert-Based Video Retrieval System for Contextual Advertising": {
        "filename": "ContextIQ A Multimodal Expert-Based Video Retrieval System for Contextual Advertising.pdf",
        "analysis": {
            "benchmarks": [
                "MSR-VTT",
                "Condensed Movies",
                "Val-1"
            ],
            "base_models": [
                "BLIP2 Qformer",
                "CLAP",
                "MPNet",
                "YOLOv5",
                "ResNet50",
                "VideoMAE2",
                "RoBERTa",
                "LLAMA 3 8B",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Question Answering as Programming for Solving Time-Sensitive Questions": {
        "filename": "Question Answering as Programming for Solving Time-Sensitive Questions.pdf",
        "analysis": {
            "benchmarks": [
                "TimeQA",
                "TempQuestions",
                "TimeQuestions"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VQA Training Sets are Self-play Environments for Generating Few-shot Pools": {
        "filename": "VQA Training Sets are Self-play Environments for Generating Few-shot Pools.pdf",
        "analysis": {
            "benchmarks": [
                "ChartQA",
                "PlotQA v2",
                "InfographicVQA",
                "DocVQA"
            ],
            "base_models": [
                "Gemini 1.5 Pro",
                "ScreenAI (5B parameters)"
            ]
        }
    },
    "WizardMath Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct": {
        "filename": "WizardMath Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "MATH"
            ],
            "base_models": [
                "Llama-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Correcting LLM-Controlled Diffusion Models": {
        "filename": "Self-Correcting LLM-Controlled Diffusion Models.pdf",
        "analysis": {
            "benchmarks": [
                "LMD benchmark"
            ],
            "base_models": [
                "Stable Diffusion",
                "DALL-E 3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data": {
        "filename": "Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "True Detective A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4": {
        "filename": "True Detective A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4.pdf",
        "analysis": {
            "benchmarks": [
                "5 Minute Mystery"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "GPT-4"
            ]
        }
    },
    "Language Models are Spacecraft Operators": {
        "filename": "Language Models are Spacecraft Operators.pdf",
        "analysis": {
            "benchmarks": [
                "Kerbal Space Program Differential Games (KSPDG)"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "Automatic Macro Mining from Interaction Traces at Scale": {
        "filename": "Automatic Macro Mining from Interaction Traces at Scale.pdf",
        "analysis": {
            "benchmarks": [
                "RICO",
                "MoTIF",
                "random crawls of apps"
            ],
            "base_models": [
                "PaLM2-Bison"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "T2 of Thoughts Temperature Tree Elicits Reasoning in Large Language Models": {
        "filename": "T2 of Thoughts Temperature Tree Elicits Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Game of 24",
                "Creative Writing"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Natural Language Reinforcement Learning": {
        "filename": "Natural Language Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Frozen-Lake",
                "Text Gridworld"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Textbooks Are All You Need II phi-15 technical report": {
        "filename": "Textbooks Are All You Need II phi-15 technical report.pdf",
        "analysis": {
            "benchmarks": [
                "WinoGrande",
                "ARC-Easy",
                "ARC-Challenge",
                "BoolQ",
                "SIQA",
                "PIQA",
                "HellaSwag",
                "MMLU",
                "OpenbookQA",
                "SQUAD",
                "GSM8K",
                "HumanEval",
                "MBPP"
            ],
            "base_models": [
                "Vicuna-13B",
                "Llama 2-7B",
                "Llama-7B",
                "Falcon-RW-1.3B",
                "phi-1.5 (1.3B)",
                "phi-1.5-web (1.3B)"
            ]
        }
    },
    "Image First or Text First Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks": {
        "filename": "Image First or Text First Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "M3Exam",
                "M3COTS"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini-1.5 Flash",
                "Claude-3-Haiku"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Collaborative Evolving Strategy for Automatic Data-Centric Development": {
        "filename": "Collaborative Evolving Strategy for Automatic Data-Centric Development.pdf",
        "analysis": {
            "benchmarks": [
                "RD2Bench"
            ],
            "base_models": [
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unlocking the Capabilities of Thought A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought": {
        "filename": "Unlocking the Capabilities of Thought A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "BIGGSM",
                "HotpotQA"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "LLaMA (various versions)",
                "PaLM (various versions)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Optimization via Adversarial In-Context Learning": {
        "filename": "Prompt Optimization via Adversarial In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BIG-bench Hard (BBH)",
                "GSM8K",
                "SVAMP",
                "XSUM",
                "CNN/Daily Mail",
                "WebNLG",
                "E2E NLG",
                "LIRO",
                "TED Talks",
                "YELP-5",
                "COPA",
                "WSC"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0613)",
                "text-davinci-002",
                "Vicuna-13B v1.5",
                "LLaMa-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DeFT Decoding with Flash Tree-attention for Efficient Tree-structured LLM Inference": {
        "filename": "DeFT Decoding with Flash Tree-attention for Efficient Tree-structured LLM Inference.pdf",
        "analysis": {
            "benchmarks": [
                "APPS",
                "Graph of Thoughts (GoT)"
            ],
            "base_models": [
                "Llama2-7B",
                "Codellama-34B",
                "Codellama-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMLingua Compressing Prompts for Accelerated Inference of Large Language Models": {
        "filename": "LLMLingua Compressing Prompts for Accelerated Inference of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "BBH",
                "ShareGPT",
                "Arxiv-March23"
            ],
            "base_models": [
                "GPT-3.5-Turbo-0301",
                "Claude-v1.3",
                "Alpaca-7B",
                "GPT2-Alpaca"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Buffer of Thoughts Thought-Augmented Reasoning with Large Language Models": {
        "filename": "Buffer of Thoughts Thought-Augmented Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Game of 24",
                "Geometric Shapes",
                "Checkmate-in-One",
                "BIG-Bench Hard (BBH) tasks",
                "Python Programming Puzzles (P3)",
                "Multilingual Grade School Math (MGSM)",
                "Shakespearean Sonnet Writing"
            ],
            "base_models": [
                "GPT-4",
                "Llama3-8B",
                "Llama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SynthAI A Multi Agent Generative AI Framework for Automated Modular HLS Design Generation": {
        "filename": "SynthAI A Multi Agent Generative AI Framework for Automated Modular HLS Design Generation.pdf",
        "analysis": {
            "benchmarks": [
                "VerilogEval",
                "custom datasets for hardware design defects"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4-Turbo",
                "GPT-4o"
            ]
        }
    },
    "Limits of Transformer Language Models on Learning to Compose Algorithms": {
        "filename": "Limits of Transformer Language Models on Learning to Compose Algorithms.pdf",
        "analysis": {
            "benchmarks": [
                "Pointer Execution's Neighbor (PEN)",
                "Pointer Execution Reverse Multicount (PERM)",
                "Highest Subsequence Sum (HSS)",
                "Multiplication (MUL)"
            ],
            "base_models": [
                "LLaMA (150M parameters)",
                "GPT-4",
                "Gemini-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LlamaCare A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing": {
        "filename": "LlamaCare A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing.pdf",
        "analysis": {
            "benchmarks": [
                "PubMedQA",
                "USMLE-step-1-3"
            ],
            "base_models": [
                "LLaMA-2-13B"
            ]
        }
    },
    "SelfIE Self-Interpretation of Large Language Model Embeddings": {
        "filename": "SelfIE Self-Interpretation of Large Language Model Embeddings.pdf",
        "analysis": {
            "benchmarks": [
                "TextWorld"
            ],
            "base_models": [
                "LLaMA-2-70B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When IoT Meet LLMs Applications and Challenges": {
        "filename": "When IoT Meet LLMs Applications and Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "AdvertiseGen",
                "MMLU",
                "WikiText",
                "WikiTableQA",
                "TabFact",
                "DeepSense 6G",
                "MIT-BIH Arrhythmia",
                "MULTIIOT",
                "LCCC dataset"
            ],
            "base_models": [
                "RoBERTa",
                "BERT",
                "GPT-4",
                "PaLM",
                "Mistral GPT",
                "TinyBERT",
                "DistilBERT",
                "MobileBERT",
                "LLaMA2 Chat",
                "Gemini nano",
                "mBERT",
                "CodeGen",
                "PaLM2",
                "ChatGLM-6B",
                "LLaMA-7B",
                "LLaMA-13B",
                "BLOOM-7B",
                "Gemma Phi-2",
                "LLaMA2-7B",
                "LLaMA2-13B",
                "LLaMA2-70B",
                "text-embedding-ada-350M",
                "E5-large-v2-2.8B",
                "instructor-large-500M",
                "all-MiniLM-L6-v2-22M",
                "DaVinci-175B",
                "Babbage-1.3B",
                "GPT-3",
                "OPT-6.7B",
                "BLOOM-176B",
                "GPT-NeoX-20B",
                "OPT-30B",
                "Claude-3.5-70B",
                "Mixtral-8x7B",
                "Mistral-7B",
                "DeepSeek-67B",
                "DeepSeek-7B"
            ]
        }
    },
    "Visualization Literacy of Multimodal Large Language Models A Comparative Study": {
        "filename": "Visualization Literacy of Multimodal Large Language Models A Comparative Study.pdf",
        "analysis": {
            "benchmarks": [
                "VLAT",
                "mini-VLAT"
            ],
            "base_models": [
                "GPT4-o",
                "Claude 3 Opus",
                "Gemini 1.5 Pro"
            ]
        }
    },
    "Knowledge-enhanced Neural Machine Reasoning A Review": {
        "filename": "Knowledge-enhanced Neural Machine Reasoning A Review.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175 billion parameters)"
            ]
        }
    },
    "THRONE An Object-Based Hallucination Benchmark for the Free-Form Generations of Large Vision-Language Models": {
        "filename": "THRONE An Object-Based Hallucination Benchmark for the Free-Form Generations of Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "COCO",
                "Objects365"
            ],
            "base_models": [
                "FLAN-T5-Base (250M)",
                "FLAN-T5-Large (780M)",
                "FLAN-T5-XL (3B)",
                "LLaVA-v1.3",
                "LLaVA-v1.5",
                "LLaVA-Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Empowering Visual Creativity A Vision-Language Assistant to Image Editing Recommendations": {
        "filename": "Empowering Visual Creativity A Vision-Language Assistant to Image Editing Recommendations.pdf",
        "analysis": {
            "benchmarks": [
                "Custom edit-instruction dataset for IER"
            ],
            "base_models": [
                "GPT-4",
                "LLaVA-7B"
            ]
        }
    },
    "Causal Parrots Large Language Models May Talk Causality But Are Not Causal": {
        "filename": "Causal Parrots Large Language Models May Talk Causality But Are Not Causal.pdf",
        "analysis": {
            "benchmarks": [
                "altitude",
                "health",
                "recovery",
                "driving",
                "cancer",
                "earthquake"
            ],
            "base_models": [
                "GPT-3",
                "Luminous",
                "OPT-30B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoManual Generating Instruction Manuals by LLM Agents via Interactive Environmental Learning": {
        "filename": "AutoManual Generating Instruction Manuals by LLM Agents via Interactive Environmental Learning.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "MiniWoB++"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Theoretical Understanding of Chain-of-Thought Coherent Reasoning and Error-Aware Demonstration": {
        "filename": "A Theoretical Understanding of Chain-of-Thought Coherent Reasoning and Error-Aware Demonstration.pdf",
        "analysis": {
            "benchmarks": [
                "BBH (Disambiguation QA, Tracking Shuffled Objects, Date Understanding, Penguins in a Table)",
                "GSM8k"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4o-mini",
                "Gemini Pro",
                "DeepSeek 67B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Potential and Value of AI Chatbot in Personalized Cognitive Training": {
        "filename": "The Potential and Value of AI Chatbot in Personalized Cognitive Training.pdf",
        "analysis": {
            "benchmarks": [
                "Life Recall Puzzle",
                "Guessing Word Puzzle"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Auxiliary task demands mask the capabilities of smaller language models": {
        "filename": "Auxiliary task demands mask the capabilities of smaller language models.pdf",
        "analysis": {
            "benchmarks": [
                "LAMBADA",
                "BLiMP",
                "Webb et al. (2023) dataset for analogical reasoning",
                "Hagendorff et al. (2023) dataset for reflective reasoning"
            ],
            "base_models": [
                "Pythia (1B, 1.4B, 2.8B, 6.9B, 12B)",
                "OLMo (1B, 7B)",
                "Gemma (2B, 7B)",
                "Llama-2 (7B, 13B, 70B)",
                "Mistral (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reading Users Minds from What They Say An Investigation into LLM-based Empathic Mental Inference": {
        "filename": "Reading Users Minds from What They Say An Investigation into LLM-based Empathic Mental Inference.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 24 user comments with baseline goals and FPN interpretations",
                "Benchmark dataset of 120 designer inferences"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "Industrial Engineering with Large Language Models A Case Study of ChatGPTs Performance on Oil  Gas Problems": {
        "filename": "Industrial Engineering with Large Language Models A Case Study of ChatGPTs Performance on Oil  Gas Problems.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "Extracting Victim Counts from Text": {
        "filename": "Extracting Victim Counts from Text.pdf",
        "analysis": {
            "benchmarks": [
                "World Atrocities Dataset (WAD)",
                "Non-violent and Violent Campaigns and Outcomes 3.0 (NAVCO)",
                "European Media Monitor (EMM)"
            ],
            "base_models": [
                "NT5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Gemma Open Models Based on Gemini Research and Technology": {
        "filename": "Gemma Open Models Based on Gemini Research and Technology.pdf",
        "analysis": {
            "benchmarks": [
                "ARC",
                "CommonsenseQA",
                "Big Bench Hard",
                "AGI Eval",
                "MMLU",
                "HellaSwag",
                "PIQA",
                "SIQA",
                "Boolq",
                "Winogrande",
                "CQA",
                "OBQA",
                "ARC-e",
                "ARC-c",
                "TriviaQA",
                "NQ",
                "HumanEval",
                "MBPP",
                "GSM8K",
                "MATH",
                "TruthfulQA",
                "Winobias",
                "Toxigen"
            ],
            "base_models": [
                "Gemini (base for Gemma models)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Foundation Models for Music Understanding": {
        "filename": "A Survey of Foundation Models for Music Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "AudioSet",
                "MusicCaps"
            ],
            "base_models": [
                "Qwen-7B",
                "LLaMA-7B",
                "Vicuna LLM",
                "LLaMA 2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models": {
        "filename": "Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Chen et al. (2020-2022) political tweets dataset"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "RoBERTa-Large"
            ]
        }
    },
    "Bailicai A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications": {
        "filename": "Bailicai A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "MedMCQA",
                "MMLU-Med",
                "PubMedQA",
                "BioASQ"
            ],
            "base_models": [
                "Meta-Llama-3-70B",
                "Meta-Llama-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection": {
        "filename": "Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection.pdf",
        "analysis": {
            "benchmarks": [
                "SPIDER"
            ],
            "base_models": [
                "deepseek-coder-6.7b",
                "CodeLlama-7b-Instruct",
                "CodeLlama-13b-Instruct",
                "WizardCoder-15B-V1.0",
                "Baichuan2-7B-Chat"
            ]
        }
    },
    "Large Language Models Are Reasoning Teachers": {
        "filename": "Large Language Models Are Reasoning Teachers.pdf",
        "analysis": {
            "benchmarks": [
                "SingleEq",
                "AddSub",
                "MultiArith",
                "GSM8K",
                "SVAMP",
                "Date Understanding",
                "Tracking Shuffled Objects",
                "Last Letter Concatenation",
                "Coin Flip",
                "CommonSenseQA",
                "StrategyQA"
            ],
            "base_models": [
                "GPT-3 175B",
                "GPT-3 6.7B",
                "GPT-2 Small",
                "GPT-2 Medium",
                "GPT-2 Large",
                "T5 Small",
                "T5 Base",
                "T5 Large",
                "Flan-T5 Small",
                "Flan-T5 Base",
                "Flan-T5 Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FLM-101B An Open LLM and How to Train It with 100K Budget": {
        "filename": "FLM-101B An Open LLM and How to Train It with 100K Budget.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "C-Eval",
                "ARC",
                "HellaSwag",
                "TruthfulQA",
                "SuperGLUE-IQ",
                "CLUE-IQ",
                "babi-20"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GLM-130B",
                "FreeLM (based on GPT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Empirical Study on Low Code Programming using Traditional vs Large Language Model Support": {
        "filename": "An Empirical Study on Low Code Programming using Traditional vs Large Language Model Support.pdf",
        "analysis": {
            "benchmarks": [
                "Stack Overflow dataset (custom)"
            ],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Controlling Large Language Model-based Agents for Large-Scale Decision-Making An Actor-Critic Approach": {
        "filename": "Controlling Large Language Model-based Agents for Large-Scale Decision-Making An Actor-Critic Approach.pdf",
        "analysis": {
            "benchmarks": [
                "system resource allocation",
                "robot grid transportation"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Towards Controllable Speech Synthesis in the Era of Large Language Models A Survey": {
        "filename": "Towards Controllable Speech Synthesis in the Era of Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "Llama"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automatic Data Repair Are We Ready to Deploy": {
        "filename": "Automatic Data Repair Are We Ready to Deploy.pdf",
        "analysis": {
            "benchmarks": [
                "Hospital",
                "Flights",
                "Beers",
                "Rayyan",
                "Tax"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Planned-Behaviour Workflow Elicits Few-Shot Mobility Generation in LLMs": {
        "filename": "Chain-of-Planned-Behaviour Workflow Elicits Few-Shot Mobility Generation in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Tencent",
                "ChinaMobile"
            ],
            "base_models": [
                "GPT-4-turbo",
                "LLaMA3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Explicit CoT to Implicit CoT Learning to Internalize CoT Step by Step": {
        "filename": "From Explicit CoT to Implicit CoT Learning to Internalize CoT Step by Step.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "9-by-9 multiplication"
            ],
            "base_models": [
                "GPT-2 Small",
                "Mistral 7B"
            ]
        }
    },
    "Video Token Sparsification for Efficient Multimodal LLMs in Autonomous Driving": {
        "filename": "Video Token Sparsification for Efficient Multimodal LLMs in Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "DRAMA",
                "LingoQA"
            ],
            "base_models": [
                "InternVL2-8B",
                "InternVL2-2B"
            ]
        }
    },
    "Logic Contrastive Reasoning with Lightweight Large Language Model for Math Word Problems": {
        "filename": "Logic Contrastive Reasoning with Lightweight Large Language Model for Math Word Problems.pdf",
        "analysis": {
            "benchmarks": [
                "SVAMP",
                "GSM8K"
            ],
            "base_models": [
                "Mistral-7B",
                "LLaMA2-7B",
                "ChatGPT-3.5 Turbo (175B)"
            ]
        }
    },
    "Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations": {
        "filename": "Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "αNLI",
                "Sen-Making",
                "δ-NLI",
                "WinoWhy"
            ],
            "base_models": [
                "BART-large",
                "GPT-Neo",
                "GPT3 (text-davinci-002)"
            ]
        }
    },
    "BRAINTEASER Lateral Thinking Puzzles for Large Language Models": {
        "filename": "BRAINTEASER Lateral Thinking Puzzles for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BRAIN TEASER",
                "PIQA",
                "RiddleSense"
            ],
            "base_models": [
                "ChatGPT",
                "FlanT5 (780M, 3B, 11B)",
                "T0 (11B)",
                "T0P (11B)",
                "T0PP (11B)",
                "RoBERTa-L",
                "RoBERTa-L (CSKG)",
                "CAR"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GraphInsight Unlocking Insights in Large Language Models for Graph Structure Understanding": {
        "filename": "GraphInsight Unlocking Insights in Large Language Models for Graph Structure Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "GraphSQA"
            ],
            "base_models": [
                "Mistral-7B",
                "Llama-3-8B",
                "Qwen2-7B",
                "Llama-3-8B-262K",
                "Vicuna-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models": {
        "filename": "Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Indoor 1",
                "Indoor 2",
                "Outdoor 1",
                "Outdoor 2",
                "Outdoor 3"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OR-Bench An Over-Refusal Benchmark for Large Language Models": {
        "filename": "OR-Bench An Over-Refusal Benchmark for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "OR-Bench-80K",
                "OR-Bench-Hard-1K",
                "OR-Bench-Toxic"
            ],
            "base_models": [
                "Llama-2-7b",
                "Llama-2-13b",
                "Claude-2.1",
                "Claude-3-haiku",
                "Claude-3-sonnet",
                "Claude-3-opus",
                "Gemma-7b",
                "Gemini-1.0-pro",
                "Gemini-1.5-flash",
                "GPT-3.5-turbo-0301",
                "GPT-3.5-turbo-0613",
                "GPT-3.5-turbo-0125",
                "GPT-4-0125-preview",
                "GPT-4-turbo-2024-04-09",
                "GPT-4o",
                "Llama-2-70b",
                "Llama-3-8b",
                "Llama-3-70b",
                "Mistral-small-latest",
                "Mistral-medium-latest",
                "Mistral-large-latest",
                "Qwen-1.5-7B",
                "Qwen-1.5-32B",
                "Qwen-1.5-72B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PARSE-Ego4D Personal Action Recommendation Suggestions for Egocentric Videos": {
        "filename": "PARSE-Ego4D Personal Action Recommendation Suggestions for Egocentric Videos.pdf",
        "analysis": {
            "benchmarks": [
                "Ego4D",
                "PARSE-Ego4D"
            ],
            "base_models": [
                "Gemini Pro"
            ]
        }
    },
    "Simulating Human Strategic Behavior Comparing Single and Multi-agent LLMs": {
        "filename": "Simulating Human Strategic Behavior Comparing Single and Multi-agent LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Ultimatum Game"
            ],
            "base_models": [
                "GPT-3.5 (gpt-3.5-turbo)",
                "GPT-4 (gpt-4-1106-preview)"
            ]
        }
    },
    "Entropic Distribution Matching in Supervised Fine-tuning of LLMs Less Overfitting and Better Diversity": {
        "filename": "Entropic Distribution Matching in Supervised Fine-tuning of LLMs Less Overfitting and Better Diversity.pdf",
        "analysis": {
            "benchmarks": [
                "IFEval",
                "GSM8K",
                "HumanEval",
                "MBPP",
                "MetaMathQA",
                "MagicCoder-OSS-Instruct"
            ],
            "base_models": [
                "Llama-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "To CoT or not to CoT Chain-of-thought helps mainly on math and symbolic reasoning": {
        "filename": "To CoT or not to CoT Chain-of-thought helps mainly on math and symbolic reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8K",
                "MATH",
                "BIG-Bench Hard (BBH)",
                "CommonsenseQA",
                "MuSR",
                "BiGGen Bench"
            ],
            "base_models": [
                "Llama 3.1",
                "GPT-4",
                "Claude 3",
                "Mistral 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Empirical Categorization of Prompting Techniques for Large Language Models A Practitioners Guide": {
        "filename": "An Empirical Categorization of Prompting Techniques for Large Language Models A Practitioners Guide.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT (Brown et al., 2020; Ouyang et al., 2022)",
                "LaMDA (Thoppilan et al., 2022)",
                "PaLM (Chowdhery et al., 2023)",
                "LLaMa (Touvron et al., 2023)",
                "Mistral (Jiang et al., 2023)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DyVal 2 Dynamic Evaluation of Large Language Models by Meta Probing Agents": {
        "filename": "DyVal 2 Dynamic Evaluation of Large Language Models by Meta Probing Agents.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8K",
                "BBH",
                "ARC-C"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "GPT-3.5-Turbo",
                "Gemini-Pro",
                "Llama2-70b-chat",
                "Yi-34b-chat",
                "Mixtral-8x7b-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VideoTetris Towards Compositional Text-to-Video Generation": {
        "filename": "VideoTetris Towards Compositional Text-to-Video Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Panda-70M"
            ],
            "base_models": [
                "VideoCrafter2",
                "StreamingT2V",
                "ModelScope",
                "Animatediff"
            ]
        }
    },
    "A Study of Situational Reasoning for Traffic Understanding": {
        "filename": "A Study of Situational Reasoning for Traffic Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "BDD-QA",
                "TV-QA",
                "HDT-QA"
            ],
            "base_models": [
                "RoBERTa-large",
                "T5-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SheetAgent Towards A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models": {
        "filename": "SheetAgent Towards A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SheetRM",
                "SheetCopilot",
                "WikiTableQuestions",
                "FeTaQA",
                "TabFact"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Qwen-1.5 (14b-chat)",
                "Llama 3 (8b-instruct)",
                "Claude 3 (Sonnet)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Adaptive-Solver Framework for Dynamic Strategy Selection in Large Language Model Reasoning": {
        "filename": "Adaptive-Solver Framework for Dynamic Strategy Selection in Large Language Model Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "AQuA",
                "AddSub",
                "SingleEq",
                "MultiArith",
                "CSQA",
                "LLC"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Characterizing Large Language Model Geometry Helps Solve Toxicity Detection and Generation": {
        "filename": "Characterizing Large Language Model Geometry Helps Solve Toxicity Detection and Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Omni-Toxic dataset",
                "Jigsaw dataset"
            ],
            "base_models": [
                "Llama2-7B",
                "Llama2-70B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can ChatGPT Replace Traditional KBQA Models An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family": {
        "filename": "Can ChatGPT Replace Traditional KBQA Models An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family.pdf",
        "analysis": {
            "benchmarks": [
                "WebQuestionSP",
                "ComplexWebQuestions",
                "GraphQ",
                "QALD-9",
                "KQApro",
                "GrailQA",
                "MKQA",
                "LC-quad2.0"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5 v2",
                "GPT-3.5 v3",
                "ChatGPT",
                "GPT-4",
                "FLAN-T5 (11B)"
            ]
        }
    },
    "Supervised Knowledge Makes Large Language Models Better In-context Learners": {
        "filename": "Supervised Knowledge Makes Large Language Models Better In-context Learners.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE-X",
                "SQuAD 2.0"
            ],
            "base_models": [
                "ChatGPT",
                "Llama2-7B-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cognitive Architectures for Language Agents": {
        "filename": "Cognitive Architectures for Language Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using ChatGPT for Thematic Analysis": {
        "filename": "Using ChatGPT for Thematic Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "UN policy documents 2017-2024"
            ],
            "base_models": [
                "ChatGPT (GPT model)"
            ]
        }
    },
    "GameBench Evaluating Strategic Reasoning Abilities of LLM Agents": {
        "filename": "GameBench Evaluating Strategic Reasoning Abilities of LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Air, Land, Sea (ALS)",
                "Arctic Scavengers (ARC)",
                "Are You the Traitor? (AYT)",
                "Codenames (CN)",
                "Hive (HV)",
                "Pit (PT)",
                "Santorini (SN)",
                "Two Rooms and a Boom (TRB)",
                "Sea Battle (SB)"
            ],
            "base_models": [
                "GPT-3 (gpt-3.5-turbo-1106)",
                "GPT-4 (gpt-4-1106-preview)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations A Pilot Study": {
        "filename": "User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations A Pilot Study.pdf",
        "analysis": {
            "benchmarks": [
                "Movielens-1M"
            ],
            "base_models": [
                "Llama 2 70B Chat",
                "GPT-4",
                "GPT-3.5-turbo"
            ]
        }
    },
    "Advanced System Integration Analyzing OpenAPI Chunking for Retrieval-Augmented Generation": {
        "filename": "Advanced System Integration Analyzing OpenAPI Chunking for Retrieval-Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "RestBench"
            ],
            "base_models": [
                "GPT-4 (128,000 tokens context size)",
                "OpenAI's text-embedding-3-large",
                "BAAI/bge-small-en-v1.5",
                "NV-Embed-v1"
            ]
        }
    },
    "Doubly Right Object Recognition A Why Prompt for Visual Rationales": {
        "filename": "Doubly Right Object Recognition A Why Prompt for Visual Rationales.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR-10+",
                "CIFAR-100+",
                "Food101+",
                "Caltech101+",
                "SUN+",
                "ImageNet+"
            ],
            "base_models": [
                "CLIP-Res50",
                "CLIP-Res101",
                "CLIP-B/32",
                "CLIP-B/16",
                "CLIP-L/14",
                "FLAVA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Depression Diagnosis with Chain-of-Thought Prompting": {
        "filename": "Enhancing Depression Diagnosis with Chain-of-Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "DAIC-WOZ"
            ],
            "base_models": [
                "GPT-3.5 turbo",
                "BERT"
            ]
        }
    },
    "RGD Multi-LLM Based Agent Debugger via Refinement and Generation Guidance": {
        "filename": "RGD Multi-LLM Based Agent Debugger via Refinement and Generation Guidance.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "HumanEval-ET",
                "MBPP",
                "MBPP-ET",
                "APPS"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o-mini"
            ]
        }
    },
    "LLMs for Relational Reasoning How Far are We": {
        "filename": "LLMs for Relational Reasoning How Far are We.pdf",
        "analysis": {
            "benchmarks": [
                "Inductive Logic Programming (ILP)",
                "Family Tree Reasoning",
                "General Graph Reasoning"
            ],
            "base_models": [
                "GPT-3.5 Turbo (175B)",
                "GPT-4 (estimated 100T)",
                "GPT-4 Turbo",
                "Llama 2 (7B)",
                "Llama 2 (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Synthetic Dataset for Personal Attribute Inference": {
        "filename": "A Synthetic Dataset for Personal Attribute Inference.pdf",
        "analysis": {
            "benchmarks": [
                "SynthPAI"
            ],
            "base_models": [
                "GPT-4",
                "Llama-2-7b",
                "Llama-2-13b",
                "Llama-2-70b",
                "Llama-3-8b",
                "Llama-3-70b",
                "Gemma-7B",
                "Mistral-7B",
                "Mixtral-8x7B",
                "Mixtral-8x22B",
                "Claude-3-Haiku",
                "Claude-3-Sonnet",
                "Claude-3-Opus",
                "Yi-34B",
                "Gemini-Pro",
                "Gemini-1.5-Pro",
                "Qwen1.5-110B",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Video In-context Learning": {
        "filename": "Video In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Something-Something v2 (SSv2)"
            ],
            "base_models": [
                "LLaMA (300M, 700M, 1.1B)"
            ]
        }
    },
    "Are Large Language Models Good Statisticians": {
        "filename": "Are Large Language Models Good Statisticians.pdf",
        "analysis": {
            "benchmarks": [
                "StatQA"
            ],
            "base_models": [
                "GPT-4o",
                "LLaMA-3-8B",
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Internet of Agents Weaving a Web of Heterogeneous Agents for Collaborative Intelligence": {
        "filename": "Internet of Agents Weaving a Web of Heterogeneous Agents for Collaborative Intelligence.pdf",
        "analysis": {
            "benchmarks": [
                "GAIA benchmark",
                "open-ended instruction benchmark",
                "RoCoBench",
                "retrieval-augmented generation (RAG) tasks"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo-0125"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VisIT-Bench A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use": {
        "filename": "VisIT-Bench A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use.pdf",
        "analysis": {
            "benchmarks": [
                "VisIT-Bench",
                "VQAv2",
                "COCO"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-13B",
                "LLaV A-13B",
                "InstructBLIP-13B",
                "MiniGPT4-7B",
                "mPLUG-Owl-7B",
                "LlamaAdapter-v2-7B",
                "PandaGPT-13B",
                "VisualChatGPT",
                "Multimodal GPT",
                "OpenFlamingo v1",
                "Otter v1",
                "Lynx (8B)",
                "idefics (9B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DoLa Decoding by Contrasting Layers Improves Factuality in Large Language Models": {
        "filename": "DoLa Decoding by Contrasting Layers Improves Factuality in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "FACTOR",
                "StrategyQA",
                "GSM8K",
                "Vicuna QA"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-33B",
                "LLaMA-65B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Corex Pushing the Boundaries of Complex Reasoning through Multi-Model Collaboration": {
        "filename": "Corex Pushing the Boundaries of Complex Reasoning through Multi-Model Collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "GSM-Hard",
                "StrategyQA",
                "BigBench",
                "FinQA",
                "ConvFinQA"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "Claude-Instant-1.2",
                "LLaMA-2-Chat(7B/13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assessing LLMs in Malicious Code Deobfuscation of Real-world Malware Campaigns": {
        "filename": "Assessing LLMs in Malicious Code Deobfuscation of Real-world Malware Campaigns.pdf",
        "analysis": {
            "benchmarks": [
                "Emotet malware campaign dataset"
            ],
            "base_models": [
                "GPT-4",
                "Gemini Pro",
                "Code Llama Instruct (34B)",
                "Mixtral 8x7B Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning": {
        "filename": "Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "BoardgameQA (BGQA)",
                "SNLI",
                "MNLI",
                "race@Middle",
                "race@High"
            ],
            "base_models": [
                "Llama2-7B",
                "Codellama-7B",
                "Glactica-6.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Wisdom of Partisan Crowds Comparing Collective Intelligence in Humans and LLM-based Agents": {
        "filename": "The Wisdom of Partisan Crowds Comparing Collective Intelligence in Humans and LLM-based Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Becker et al. (2019) dataset"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "Vicuna-33B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Disentangling Memory and Reasoning Ability in Large Language Models": {
        "filename": "Disentangling Memory and Reasoning Ability in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "CommonsenseQA",
                "TruthfulQA"
            ],
            "base_models": [
                "Qwen2.5-7B",
                "LLaMA-3.1-8B",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning from Feedback Semantic Enhancement for Object SLAM Using Foundation Models": {
        "filename": "Learning from Feedback Semantic Enhancement for Object SLAM Using Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "SEO-SLAM dataset"
            ],
            "base_models": [
                "GPT-4 (gpt-4o version)",
                "GroundingDINO large model (swinb cogcoor)",
                "SAM with ViT-H model",
                "RAM++ large model (plus swin large)"
            ]
        }
    },
    "When to Make Exceptions Exploring Language Models as Accounts of Human Moral Judgment": {
        "filename": "When to Make Exceptions Exploring Language Models as Accounts of Human Moral Judgment.pdf",
        "analysis": {
            "benchmarks": [
                "MoralExceptQA"
            ],
            "base_models": [
                "InstructGPT",
                "GPT-3",
                "BERT-base",
                "BERT-large",
                "RoBERTa-large",
                "ALBERT-xxlarge"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting Strategies for Enabling Large Language Models to Infer Causation from Correlation": {
        "filename": "Prompting Strategies for Enabling Large Language Models to Infer Causation from Correlation.pdf",
        "analysis": {
            "benchmarks": [
                "CORR2CAUSE"
            ],
            "base_models": [
                "Gemini Pro 1.0",
                "Gemini Ultra 1.0",
                "PaLM 2 L",
                "GPT-3.5-turbo",
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Domain Adaptation of Visual Policies with a Single Demonstration": {
        "filename": "Domain Adaptation of Visual Policies with a Single Demonstration.pdf",
        "analysis": {
            "benchmarks": [
                "Distracting Control Suite",
                "UR5 robot tasks (simulation and real-world)"
            ],
            "base_models": [
                "Transformer"
            ]
        }
    },
    "AFSPP Agent Framework for Shaping Preference and Personality with Large Language Models": {
        "filename": "AFSPP Agent Framework for Shaping Preference and Personality with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Myers-Briggs Type Indicator (MBTI)",
                "Short Dark Triad (SD3)"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "UltraFeedback Boosting Language Models with High-quality Feedback": {
        "filename": "UltraFeedback Boosting Language Models with High-quality Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaEval",
                "Evol-Instruct",
                "UltraChat"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA2-13B",
                "LLaMA2-70B",
                "UltraLM-13B",
                "UltraLM-13B-PPO",
                "WizardLM-13B-v1.2",
                "Vicuna-33B-v1.3",
                "MPT-30B-Chat",
                "Falcon-40B-Instruct",
                "Pythia-12B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Determinants of LLM-assisted Decision-Making": {
        "filename": "Determinants of LLM-assisted Decision-Making.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Traffic Scene Generation from Natural Language Description for Autonomous Vehicles with Large Language Model": {
        "filename": "Traffic Scene Generation from Natural Language Description for Autonomous Vehicles with Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "nuScenes",
                "Waymo",
                "SafeBench"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "DetGPT Detect What You Need via Reasoning": {
        "filename": "DetGPT Detect What You Need via Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "COCO dataset"
            ],
            "base_models": [
                "Vicuna-13B",
                "BLIP-2",
                "Grounding-DINO"
            ]
        }
    },
    "RAH RecSysAssistantHuman A Human-Centered Recommendation Framework With LLM Agents": {
        "filename": "RAH RecSysAssistantHuman A Human-Centered Recommendation Framework With LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Movies (Amazon domain)",
                "Books (Amazon domain)",
                "Video Games (Amazon domain)"
            ],
            "base_models": [
                "GPT-4-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Trade-off Between Efficiency and Consistency for Removal-based Explanations": {
        "filename": "Trade-off Between Efficiency and Consistency for Removal-based Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "IMDb",
                "ImageNet"
            ],
            "base_models": [
                "ResNet-101"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Active Retrieval Augmented Generation": {
        "filename": "Active Retrieval Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "2WikiMultihopQA",
                "StrategyQA",
                "ASQA",
                "WikiAsp"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "REV Information-Theoretic Evaluation of Free-Text Rationales": {
        "filename": "REV Information-Theoretic Evaluation of Free-Text Rationales.pdf",
        "analysis": {
            "benchmarks": [
                "ECQA",
                "CoS-E",
                "QuaRTz",
                "e-SNLI"
            ],
            "base_models": [
                "T5 Large",
                "T5-3B",
                "BART Large",
                "GPT-2 Large",
                "GPT-3",
                "LaMDA 137B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TextGenSHAP Scalable Post-hoc Explanations in Text Generation with Long Documents": {
        "filename": "TextGenSHAP Scalable Post-hoc Explanations in Text Generation with Long Documents.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions (NQ)",
                "MIRACL (English subset)"
            ],
            "base_models": [
                "T5-large",
                "T5-XXL",
                "T5-FiD"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GLOV Guided Large Language Models as Implicit Optimizers for Vision Language Models": {
        "filename": "GLOV Guided Large Language Models as Implicit Optimizers for Vision Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "ImageNetV2",
                "Caltech101",
                "ImageNetR",
                "ImageNetS",
                "ImageNetA",
                "OxfordFlowers",
                "OxfordPets",
                "StanfordCars",
                "DescribableTextures",
                "Food101",
                "FGVCAircraft",
                "SUN397",
                "UCF101",
                "RESISC45",
                "EuroSAT"
            ],
            "base_models": [
                "CLIP ViT-B/32",
                "LLaVa One Vision (Qwen2-7B)",
                "Llama-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards a Robust Retrieval-Based Summarization System": {
        "filename": "Towards a Robust Retrieval-Based Summarization System.pdf",
        "analysis": {
            "benchmarks": [
                "LogicSumm"
            ],
            "base_models": [
                "GPT-3.5",
                "Claude 2",
                "Jurassic",
                "LLaMa2-13B",
                "Mistral-7B Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ActiveLLM Large Language Model-based Active Learning for Textual Few-Shot Scenarios": {
        "filename": "ActiveLLM Large Language Model-based Active Learning for Textual Few-Shot Scenarios.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "AGNews",
                "SST-2"
            ],
            "base_models": [
                "GPT-4",
                "Llama 3 70B",
                "Mistral Large",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Why is this misleading Detecting News Headline Hallucinations with Explanations": {
        "filename": "Why is this misleading Detecting News Headline Hallucinations with Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset with 6270 labeled ⟨article, headline⟩ pairs",
                "MNBM",
                "FRANK",
                "QAGS",
                "SummEval",
                "FEVER",
                "Vitamin-C"
            ],
            "base_models": [
                "BERT-base",
                "T5-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Hallucinations in Chinese Large Language Models": {
        "filename": "Evaluating Hallucinations in Chinese Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HalluQA",
                "TruthfulQA"
            ],
            "base_models": [
                "GLM-130B",
                "ChatGPT",
                "GPT-4",
                "ERNIE-Bot",
                "Baichuan2",
                "ChatGLM",
                "Qwen",
                "SparkDesk",
                "Llama2-7B",
                "Llama2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interpreting and Improving Large Language Models in Arithmetic Calculation": {
        "filename": "Interpreting and Improving Large Language Models in Arithmetic Calculation.pdf",
        "analysis": {
            "benchmarks": [
                "SVAMP"
            ],
            "base_models": [
                "LLaMA2-7B",
                "LLaMA2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Preble Efficient Distributed Prompt Scheduling for LLM Serving": {
        "filename": "Preble Efficient Distributed Prompt Scheduling for LLM Serving.pdf",
        "analysis": {
            "benchmarks": [
                "Tool use",
                "Embodied agent in a virtual environment",
                "Software program generation",
                "Video QA",
                "Long document QA",
                "Azure LLM usage trace"
            ],
            "base_models": [
                "Mistral 7B",
                "Llama-3 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PromptExp Multi-granularity Prompt Explanation of Large Language Models": {
        "filename": "PromptExp Multi-granularity Prompt Explanation of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Stanford-Sentiment-Treebank (SST)"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama-2-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Efficient Causal Graph Discovery Using Large Language Models": {
        "filename": "Efficient Causal Graph Discovery Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Asia",
                "Child",
                "Neuropathic Pain"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Tabular Representation Noisy Operators and Impacts on Table Structure Understanding Tasks in LLMs": {
        "filename": "Tabular Representation Noisy Operators and Impacts on Table Structure Understanding Tasks in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "AirQuality",
                "HousingData",
                "Diabetes",
                "Wine Testing",
                "Iris",
                "Titanic"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)"
            ]
        }
    },
    "NEOLAF an LLM-powered neural-symbolic cognitive architecture": {
        "filename": "NEOLAF an LLM-powered neural-symbolic cognitive architecture.pdf",
        "analysis": {
            "benchmarks": [
                "MATH dataset",
                "AIME Math Competitions",
                "USAMO Math Competitions"
            ],
            "base_models": [
                "ChatGPT 3.5",
                "ChatGPT 4.0"
            ]
        }
    },
    "A Survey on Multimodal Large Language Models for Autonomous Driving": {
        "filename": "A Survey on Multimodal Large Language Models for Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "KITTI",
                "nuScenes",
                "Waymo Open"
            ],
            "base_models": [
                "GPT-4",
                "PaLM-2",
                "LLaMA-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ZeroNLG Aligning and Autoencoding Domains for Zero-Shot Multimodal and Multilingual Natural Language Generation": {
        "filename": "ZeroNLG Aligning and Autoencoding Domains for Zero-Shot Multimodal and Multilingual Natural Language Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MS-COCO",
                "MSR-VTT",
                "VATEX-Zh",
                "Flickr30k-Zh",
                "Flickr30k-De",
                "Flickr30k-Fr",
                "WMT16",
                "WMT17",
                "English-Chinese dataset"
            ],
            "base_models": [
                "CLIP (ViT-B/32)",
                "DistilBERT",
                "Transformer decoder (768 model dimensions, 12 attention heads, 3 layers)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cocobo Exploring Large Language Models as the Engine for End-User Robot Programming": {
        "filename": "Cocobo Exploring Large Language Models as the Engine for End-User Robot Programming.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama"
            ]
        }
    },
    "EDDA A Encoder-Decoder Data Augmentation Framework for Zero-Shot Stance Detection": {
        "filename": "EDDA A Encoder-Decoder Data Augmentation Framework for Zero-Shot Stance Detection.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval-2016 Task 6 (SEM16)",
                "VAST"
            ],
            "base_models": [
                "BERT-base",
                "GPT-3.5-turbo",
                "LLaMA2-70B"
            ]
        }
    },
    "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models": {
        "filename": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "WebShop",
                "HotPotQA",
                "MBPP",
                "Game of 24"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition": {
        "filename": "Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition.pdf",
        "analysis": {
            "benchmarks": [
                "CRAFT"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "ARB Advanced Reasoning Benchmark for Large Language Models": {
        "filename": "ARB Advanced Reasoning Benchmark for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ARB (Advanced Reasoning Benchmark)",
                "MATH",
                "GSM8K",
                "MMLU",
                "SVAMP",
                "ASDiv",
                "AQuA",
                "MAWPS",
                "MultiArith",
                "CSQA",
                "StrategyQA",
                "HotpotQA",
                "GPT-Planning Benchmark",
                "ALERT Reasoning Benchmark",
                "JEEBench"
            ],
            "base_models": [
                "GPT-4",
                "Claude",
                "GPT-3.5-turbo",
                "text-davinci-003",
                "PaLM",
                "Chinchilla"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GIFT A Framework for Global Interpretable Faithful Textual Explanations of Vision Classifiers": {
        "filename": "GIFT A Framework for Global Interpretable Faithful Textual Explanations of Vision Classifiers.pdf",
        "analysis": {
            "benchmarks": [
                "CLEVR",
                "CelebA",
                "BDD-OIA"
            ],
            "base_models": [
                "ViT-Small-Patch16-224",
                "ResNet-34",
                "DenseNet121"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Richelieu Self-Evolving LLM-Based Agents for AI Diplomacy": {
        "filename": "Richelieu Self-Evolving LLM-Based Agents for AI Diplomacy.pdf",
        "analysis": {
            "benchmarks": [
                "Diplomacy game platform by Paquette et al. [2019]"
            ],
            "base_models": [
                "GPT-4.0",
                "Llama 3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fast and Accurate Task Planning using Neuro-Symbolic Language Models and Multi-level Goal Decomposition": {
        "filename": "Fast and Accurate Task Planning using Neuro-Symbolic Language Models and Multi-level Goal Decomposition.pdf",
        "analysis": {
            "benchmarks": [
                "Barman-new",
                "Blocksworld-new",
                "Gripper-new"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Sequential Monte Carlo Steering of Large Language Models using Probabilistic Programs": {
        "filename": "Sequential Monte Carlo Steering of Large Language Models using Probabilistic Programs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "LLaMA (family of models)"
            ]
        }
    },
    "SAGraph A Large-scale Text-Rich Social Graph Dataset for Advertising Campaigns": {
        "filename": "SAGraph A Large-scale Text-Rich Social Graph Dataset for Advertising Campaigns.pdf",
        "analysis": {
            "benchmarks": [
                "SAGraph"
            ],
            "base_models": [
                "GPT-4",
                "Kimi"
            ]
        }
    },
    "A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges": {
        "filename": "A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "US Medical Licensing Exam-style questions"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BeHonest Benchmarking Honesty in Large Language Models": {
        "filename": "BeHonest Benchmarking Honesty in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BEHONEST",
                "SelfAware",
                "UnknownBench",
                "TrustLLM",
                "Sycophancy-Intervention",
                "TruthfulQA",
                "Burglar Deception Dataset",
                "Werewolf Dataset",
                "Natural Instructions",
                "Big-Bench Hard",
                "CommonSenseQA"
            ],
            "base_models": [
                "GPT-4o",
                "ChatGPT",
                "Llama3-70b",
                "Llama3-8b",
                "Llama2-70b",
                "Llama2-13b",
                "Llama2-7b",
                "Mistral-7b",
                "Qwen1.5-14b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Adaptive In-conversation Team Building for Language Model Agents": {
        "filename": "Adaptive In-conversation Team Building for Language Model Agents.pdf",
        "analysis": {
            "benchmarks": [
                "MATH (Hendrycks et al., 2021a)",
                "HumanEval (Chen et al., 2021)",
                "DABench (Hu et al., 2024a)",
                "GAIA (Mialon et al., 2023)",
                "SciBench (Wang et al., 2023b)"
            ],
            "base_models": [
                "gpt-4-0125-preview",
                "LLaMA-3-70B-Instruct",
                "LLaMA-3-8B-Instruct",
                "gpt-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MATHSENSEI A Tool-Augmented Large Language Model for Mathematical Reasoning": {
        "filename": "MATHSENSEI A Tool-Augmented Large Language Model for Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM-8K",
                "AQUA-RAT",
                "MMLU-Math"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "GPT-4",
                "Llama 2",
                "text-davinci-002",
                "text-davinci-003",
                "Phind-CodeLlama-34B-V2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SayTap Language to Quadrupedal Locomotion": {
        "filename": "SayTap Language to Quadrupedal Locomotion.pdf",
        "analysis": {
            "benchmarks": [
                "Unitree A1"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tree of Thoughts Deliberate Problem Solving with Large Language Models": {
        "filename": "Tree of Thoughts Deliberate Problem Solving with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Game of 24",
                "Creative Writing",
                "Mini Crosswords"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Incentive Compatibility for AI Alignment in Sociotechnical Systems Positions and Prospects": {
        "filename": "Incentive Compatibility for AI Alignment in Sociotechnical Systems Positions and Prospects.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The CLRS-Text Algorithmic Reasoning Language Benchmark": {
        "filename": "The CLRS-Text Algorithmic Reasoning Language Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "CLRS-Text"
            ],
            "base_models": [
                "Gemma 2B"
            ]
        }
    },
    "Tuning Language Models by Mixture-of-Depths Ensemble": {
        "filename": "Tuning Language Models by Mixture-of-Depths Ensemble.pdf",
        "analysis": {
            "benchmarks": [
                "ARC",
                "AQuA",
                "GSM8K",
                "BoolQ",
                "OBQA",
                "MMLU"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA2-7B"
            ]
        }
    },
    "VoxelPrompt A Vision-Language Agent for Grounded Medical Image Analysis": {
        "filename": "VoxelPrompt A Vision-Language Agent for Grounded Medical Image Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "BraTS",
                "ISLES",
                "ATLAS",
                "WMH",
                "Radiopaedia"
            ],
            "base_models": [
                "LLaMA (16 transformer layers, hidden size 512, 32 attention heads)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models in Medicine The Potentials and Pitfalls": {
        "filename": "Large Language Models in Medicine The Potentials and Pitfalls.pdf",
        "analysis": {
            "benchmarks": [
                "MedMCQA",
                "PubMedQA",
                "MultiMedBench"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "BioGPT (based on GPT-2)",
                "BioMedLM 2.7B (formerly PubMedGPT)",
                "BERT",
                "BioBERT (based on BERT)",
                "PubMedBERT (based on BERT)",
                "ClinicalBERT (based on BERT)",
                "Flan-PaLM",
                "Med-PaLM",
                "PMC-LLaMA (based on LLaMA)"
            ]
        }
    },
    "Weakly Supervised Data Augmentation Through Prompting for Dialogue Understanding": {
        "filename": "Weakly Supervised Data Augmentation Through Prompting for Dialogue Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "DAILY DIALOG",
                "FACEBOOK MULTILINGUAL TASK-ORIENTED DIALOGUE"
            ],
            "base_models": [
                "GPT-J (6B)",
                "Alexa Teacher Model (20B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do Androids Laugh at Electric Sheep Humor Understanding Benchmarks from The New Yorker Caption Contest": {
        "filename": "Do Androids Laugh at Electric Sheep Humor Understanding Benchmarks from The New Yorker Caption Contest.pdf",
        "analysis": {
            "benchmarks": [
                "New Yorker Cartoon Caption Contest"
            ],
            "base_models": [
                "CLIP ViT-L/14@336px",
                "OFA-Huge",
                "T5-Large (770M)",
                "T5-11B (11.3B)",
                "GPT-3 (175B)",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Application of Large Language Models in Automated Question Generation A Case Study on ChatGLMs Structured Questions for National Teacher Certification Exams": {
        "filename": "Application of Large Language Models in Automated Question Generation A Case Study on ChatGLMs Structured Questions for National Teacher Certification Exams.pdf",
        "analysis": {
            "benchmarks": [
                "National Teacher Certification Exams (NTCE)"
            ],
            "base_models": [
                "ChatGLM"
            ]
        }
    },
    "CoT-BERT Enhancing Unsupervised Sentence Representation through Chain-of-Thought": {
        "filename": "CoT-BERT Enhancing Unsupervised Sentence Representation through Chain-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "STS12",
                "STS13",
                "STS14",
                "STS15",
                "STS16",
                "STS-B",
                "SICK-R"
            ],
            "base_models": [
                "BERT base",
                "RoBERTa base"
            ]
        }
    },
    "DKPROMPT Domain Knowledge Prompting Vision-Language Models for Open-World Planning": {
        "filename": "DKPROMPT Domain Knowledge Prompting Vision-Language Models for Open-World Planning.pdf",
        "analysis": {
            "benchmarks": [
                "OmniGibson simulator"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LMEye An Interactive Perception Network for Large Language Models": {
        "filename": "LMEye An Interactive Perception Network for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMBench",
                "SEED-Bench",
                "VCR",
                "VQAv2",
                "OK-VQA"
            ],
            "base_models": [
                "LLaMA-7b",
                "LLaMA-13b",
                "OPT-iml-1.3b",
                "Bloomz-7b1",
                "BLIP-2 (FlanT5 XL)"
            ]
        }
    },
    "LASER LLM Agent with State-Space Exploration for Web Navigation": {
        "filename": "LASER LLM Agent with State-Space Exploration for Web Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "WebShop",
                "amazon.com"
            ],
            "base_models": [
                "GPT-4-0613",
                "FlanT5-XL",
                "PaLM"
            ]
        }
    },
    "When Large Language Models Meet Optical Networks Paving the Way for Automation": {
        "filename": "When Large Language Models Meet Optical Networks Paving the Way for Automation.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset for network alarm analysis",
                "custom dataset for autonomous network optimization"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models": {
        "filename": "Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Bloom AI tutor conversations"
            ],
            "base_models": [
                "GPT-4 (32k version)"
            ]
        }
    },
    "Beyond Graphs Can Large Language Models Comprehend Hypergraphs": {
        "filename": "Beyond Graphs Can Large Language Models Comprehend Hypergraphs.pdf",
        "analysis": {
            "benchmarks": [
                "LLM4Hypergraph"
            ],
            "base_models": [
                "ERNIE-Lite-8K",
                "ERNIE-Speed-128K",
                "Qwen-Long",
                "LLaMA3-8B",
                "GPT-3.5-Turbo",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Conditionally Combining Robot Skills using Large Language Models": {
        "filename": "Conditionally Combining Robot Skills using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Language-World (extension of Meta-World)"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5",
                "PaLM 2"
            ]
        }
    },
    "C-Eval A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models": {
        "filename": "C-Eval A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "C-E VAL",
                "C-E VAL HARD"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "Claude-v1.3",
                "Claude-instant-v1.0",
                "Bloomz-mt (176B)",
                "LLaMA-65B",
                "GLM-130B",
                "ChatGLM-6B",
                "Chinese-LLaMA-13B",
                "Chinese-Alpaca-13B",
                "MOSS (16B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OmniDrive A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception Reasoning and Planning": {
        "filename": "OmniDrive A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception Reasoning and Planning.pdf",
        "analysis": {
            "benchmarks": [
                "OmniDrive-nuScenes"
            ],
            "base_models": [
                "LLaVA-1.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Uncertainty of Thoughts Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models": {
        "filename": "Uncertainty of Thoughts Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "20 Questions (Common and Things datasets)",
                "Medical Diagnosis (DX and MedDG datasets)",
                "Troubleshooting (FloDial dataset)"
            ],
            "base_models": [
                "Llama-3-70B-Instruct",
                "Mistral-Large",
                "Gemini-1.5-Pro",
                "Claude-3-Opus",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring the Mystery of Influential Data for Mathematical Reasoning": {
        "filename": "Exploring the Mystery of Influential Data for Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "AQuA-RAT",
                "NumGLUE",
                "Mathematics",
                "MMLU-Math",
                "SAT-Math",
                "SimulEq",
                "SVAMP"
            ],
            "base_models": [
                "GPT-4",
                "Gemini",
                "LLaMA-2-7B",
                "Mistral-7B",
                "DeepSeekMath-Base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Next-Generation Database Interfaces A Survey of LLM-based Text-to-SQL": {
        "filename": "Next-Generation Database Interfaces A Survey of LLM-based Text-to-SQL.pdf",
        "analysis": {
            "benchmarks": [
                "BIRD",
                "Spider",
                "Spider-Realistic",
                "Spider-SYN"
            ],
            "base_models": [
                "GPT-4",
                "Codex",
                "ChatGPT",
                "PaLM-2",
                "StarCoder"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Effective Generative AI The Human-Algorithm Centaur": {
        "filename": "Effective Generative AI The Human-Algorithm Centaur.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RESPROMPT Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models": {
        "filename": "RESPROMPT Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQUA-RAT",
                "MathQA",
                "SVAMP",
                "SCONE-Alchemy",
                "StrategyQA"
            ],
            "base_models": [
                "LLaMA-65B",
                "LLaMA2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model Prompt Chaining for Long Legal Document Classification": {
        "filename": "Large Language Model Prompt Chaining for Long Legal Document Classification.pdf",
        "analysis": {
            "benchmarks": [
                "LexGLUE",
                "ECHR",
                "SCOTUS"
            ],
            "base_models": [
                "GPT-NeoX (20B)",
                "Flan-UL2 (20B)",
                "BRIO (based on BART)",
                "PRIMERA"
            ]
        }
    },
    "Learning Universal Predictors": {
        "filename": "Learning Universal Predictors.pdf",
        "analysis": {
            "benchmarks": [
                "Variable-order Markov Sources (VOMS)",
                "Chomsky Hierarchy (CH) Tasks",
                "Universal Turing Machine Data"
            ],
            "base_models": [
                "Transformers",
                "LSTMs",
                "RNNs",
                "Stack-RNNs",
                "Tape-RNNs"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Prompts to Guide Large Language Models in Imitating a Real Persons Language Style": {
        "filename": "Using Prompts to Guide Large Language Models in Imitating a Real Persons Language Style.pdf",
        "analysis": {
            "benchmarks": [
                "Dataset 1 (Elon Musk interview)",
                "Dataset 2 (Tom Holland interview)",
                "Dataset 3 (Elon Musk interview)"
            ],
            "base_models": [
                "GPT-4",
                "Llama 3",
                "Gemini 1.5"
            ]
        }
    },
    "Enhancing Computer Programming Education with LLMs A Study on Effective Prompt Engineering for Python Code Generation": {
        "filename": "Enhancing Computer Programming Education with LLMs A Study on Effective Prompt Engineering for Python Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "LeetCode",
                "USACO"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4o",
                "Llama3-8b",
                "Mixtral-8x7b"
            ]
        }
    },
    "A Mechanism for Sample-Efficient In-Context Learning for Sparse Retrieval Tasks": {
        "filename": "A Mechanism for Sample-Efficient In-Context Learning for Sparse Retrieval Tasks.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An LLM Compiler for Parallel Function Calling": {
        "filename": "An LLM Compiler for Parallel Function Calling.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "Movie Recommendation",
                "ParallelQA",
                "Game of 24",
                "WebShop"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "LLaMA-2 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Network Management Using Code Generated by Large Language Models": {
        "filename": "Enhancing Network Management Using Code Generated by Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "NeMoEval"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3",
                "Text-davinci-003",
                "Google Bard"
            ]
        }
    },
    "Lets Do a Thought Experiment Using Counterfactuals to Improve Moral Reasoning": {
        "filename": "Lets Do a Thought Experiment Using Counterfactuals to Improve Moral Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU Moral Scenarios"
            ],
            "base_models": [
                "Flan-PaLM (540B)"
            ]
        }
    },
    "Enhancing Legal Document Retrieval A Multi-Phase Approach with Large Language Models": {
        "filename": "Enhancing Legal Document Retrieval A Multi-Phase Approach with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "COLIEE 2023"
            ],
            "base_models": [
                "GPT-3.5-turbo-instruct",
                "GPT-3.5-turbo-1106",
                "GPT-4-1106-preview",
                "BERT (Multilingual-BERT)"
            ]
        }
    },
    "Watson A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents": {
        "filename": "Watson A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents.pdf",
        "analysis": {
            "benchmarks": [
                "SWE-bench-lite"
            ],
            "base_models": [
                "GPT-3.5-turbo-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VRPTEST Evaluating Visual Referring Prompting in Large Multimodal Models": {
        "filename": "VRPTEST Evaluating Visual Referring Prompting in Large Multimodal Models.pdf",
        "analysis": {
            "benchmarks": [
                "VRPTEST"
            ],
            "base_models": [
                "GPT-4V",
                "mPLUG-OWL-LLaMA",
                "miniGPT-4-Vicuna-7B",
                "InstructBLIP-7B",
                "LLaVA-7B",
                "LLaVA-13B",
                "CogVLM"
            ]
        }
    },
    "ClickDiffusion Harnessing LLMs for Interactive Precise Image Editing": {
        "filename": "ClickDiffusion Harnessing LLMs for Interactive Precise Image Editing.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-Turbo"
            ]
        }
    },
    "Temporal and Semantic Evaluation Metrics for Foundation Models in Post-Hoc Analysis of Robotic Sub-tasks": {
        "filename": "Temporal and Semantic Evaluation Metrics for Foundation Models in Post-Hoc Analysis of Robotic Sub-tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Robosuite environments (Open a door, Lift a cube, Move a can, Stack two cubes)"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini Pro",
                "Gemini Pro Vision",
                "Video-LLaVa"
            ]
        }
    },
    "Probabilistic Adaptation of Text-to-Video Models": {
        "filename": "Probabilistic Adaptation of Text-to-Video Models.pdf",
        "analysis": {
            "benchmarks": [
                "Bridge Data",
                "Ego4D"
            ],
            "base_models": [
                "Pretrained Text-to-Video Model (5.6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Model Agents State-of-the-Art Cooperation Paradigms Security and Privacy and Future Trends": {
        "filename": "Large Model Agents State-of-the-Art Cooperation Paradigms Security and Privacy and Future Trends.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "PaLM-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NavGPT Explicit Reasoning in Vision-and-Language Navigation with Large Language Models": {
        "filename": "NavGPT Explicit Reasoning in Vision-and-Language Navigation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "R2R-VLN dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Principled Bayesian Optimisation in Collaboration with Human Experts": {
        "filename": "Principled Bayesian Optimisation in Collaboration with Human Experts.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic tasks in designing lithium-ion batteries"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Constructing and Optimizing Machine Learning Workflows A Survey": {
        "filename": "Large Language Models for Constructing and Optimizing Machine Learning Workflows A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "MLE-Bench",
                "MLAgentBench"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning": {
        "filename": "Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "gym_cards"
            ],
            "base_models": [
                "LLaVA-v1.6-mistral-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual Prompt Selection for In-Context Learning Segmentation": {
        "filename": "Visual Prompt Selection for In-Context Learning Segmentation.pdf",
        "analysis": {
            "benchmarks": [
                "PASCAL-5i",
                "COCO-20i",
                "iSALD-5i"
            ],
            "base_models": [
                "SegGPT",
                "MAE-VQGAN"
            ]
        }
    },
    "Larger Language Models Dont Care How You Think Why Chain-of-Thought Prompting Fails in Subjective Tasks": {
        "filename": "Larger Language Models Dont Care How You Think Why Chain-of-Thought Prompting Fails in Subjective Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MFRC",
                "GoEmotions"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "Meta-LLaMA-3-8B",
                "LLaMA-2-70B",
                "Meta-LLaMA-3-70B",
                "GPT-3.5 Turbo",
                "GPT-4o mini"
            ]
        }
    },
    "You Only Look at Screens Multimodal Chain-of-Action Agents": {
        "filename": "You Only Look at Screens Multimodal Chain-of-Action Agents.pdf",
        "analysis": {
            "benchmarks": [
                "AITW"
            ],
            "base_models": [
                "Llama-2-7B",
                "PaLM 2",
                "ChatGPT (turbo-3.5)",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "QAmeleon Multilingual QA with Only 5 Examples": {
        "filename": "QAmeleon Multilingual QA with Only 5 Examples.pdf",
        "analysis": {
            "benchmarks": [
                "TYDIQA-GOLDP",
                "MLQA"
            ],
            "base_models": [
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Combating Online Misinformation Videos Characterization Detection and Future Directions": {
        "filename": "Combating Online Misinformation Videos Characterization Detection and Future Directions.pdf",
        "analysis": {
            "benchmarks": [
                "FakeSV",
                "COVID-VTS"
            ],
            "base_models": [
                "BERT",
                "VGG-19",
                "ResNet50",
                "S3D",
                "ViT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Think Step by Step Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos": {
        "filename": "Think Step by Step Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos.pdf",
        "analysis": {
            "benchmarks": [
                "JIGSAWS"
            ],
            "base_models": [
                "ResNet-50",
                "CLIP ViT-B32"
            ]
        }
    },
    "Data Poisoning for In-context Learning": {
        "filename": "Data Poisoning for In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE-SST2",
                "Cola",
                "Emo",
                "AG's new corpus",
                "Poem Sentiment"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA2-7B",
                "Pythia-2.8B",
                "Pythia-6.9B",
                "Falcon-7B",
                "GPT-J-6B",
                "MPT-7B",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ExploreSelf Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models": {
        "filename": "ExploreSelf Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Achieving97 on GSM8K Deeply Understanding the Problems Makes LLMs Better Solvers for Math Word Problems": {
        "filename": "Achieving97 on GSM8K Deeply Understanding the Problems Makes LLMs Better Solvers for Math Word Problems.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "MultiArith",
                "AddSub",
                "AQuA",
                "SingleEq",
                "Last Letters",
                "Coin Flip",
                "StrategyQA",
                "CommonsenseQA"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "LLaMA2-Chat-70B",
                "LLaMA-2-Chat-13B",
                "CodeLLaMA-Instruct-13B",
                "CodeLLaMA-Instruct-34B"
            ]
        }
    },
    "Open-domain Implicit Format Control for Large Language Model Generation": {
        "filename": "Open-domain Implicit Format Control for Large Language Model Generation.pdf",
        "analysis": {
            "benchmarks": [
                "OIFC test set",
                "ShareGPT"
            ],
            "base_models": [
                "AF-7B (7B parameters)",
                "FLM-2-52B (52B parameters)"
            ]
        }
    },
    "Understanding Emergent Abilities of Language Models from the Loss Perspective": {
        "filename": "Understanding Emergent Abilities of Language Models from the Loss Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "TriviaQA",
                "HellaSwag",
                "RACE",
                "WinoGrande",
                "MMLU",
                "GSM8K",
                "NLPCC-KBQA",
                "ClozeT",
                "CLUEWSC",
                "C3",
                "C-Eval",
                "GSM8K-Chinese"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-33B",
                "LLaMA-65B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Is ChatGPT a General-Purpose Natural Language Processing Task Solver": {
        "filename": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith",
                "GSM8K",
                "AddSub",
                "AQUA-RAT",
                "SingleEq",
                "SVAMP",
                "CSQA",
                "StrategyQA",
                "COPA",
                "Last Letter Concatenation",
                "Coin Flip",
                "Date Understanding",
                "Tracking Shuffled Objects",
                "RTE",
                "CB",
                "BoolQ",
                "MuTual",
                "SAMSum",
                "CoNLL03",
                "SST2"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-3.5 (text-davinci-003)",
                "FLAN",
                "T0",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors": {
        "filename": "Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors.pdf",
        "analysis": {
            "benchmarks": [
                "TACRED",
                "RETACRED",
                "TACREV",
                "SemEval 2010 Task 8"
            ],
            "base_models": [
                "FLAN-T5 XXL (11B)",
                "text-davinci-003 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision": {
        "filename": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "BIG-bench HHH Eval"
            ],
            "base_models": [
                "LLaMA-65B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Do Large Language Models Capture the Ever-changing World Knowledge A Review of Recent Advances": {
        "filename": "How Do Large Language Models Capture the Ever-changing World Knowledge A Review of Recent Advances.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2",
                "GPT-3 (175B)",
                "GPT-3.5 (175B)",
                "GPT-4",
                "GPT-J (6B)",
                "GPT-NeoX (20B)",
                "Gopher (280B)",
                "PaLM (540B)",
                "RoBERTa (0.3B)",
                "T0 (3B)",
                "T5 (0.7B)",
                "T5 (11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Broken Neural Scaling Laws": {
        "filename": "Broken Neural Scaling Laws.pdf",
        "analysis": {
            "benchmarks": [
                "Birds 200",
                "Caltech101",
                "CIFAR-100",
                "ImageNet",
                "BIG-Bench (BB)"
            ],
            "base_models": [
                "BiT/101/3",
                "BiT/50/1",
                "MiX/B/16",
                "MiX/L/16",
                "ViT/B/16",
                "ViT/S/16",
                "2.62e+8 Param",
                "1.07e+9 Param",
                "4.53e+8 Param",
                "1.34e+8 Param",
                "1.68e+7 Param"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-Modal Hallucination Control by Visual Information Grounding": {
        "filename": "Multi-Modal Hallucination Control by Visual Information Grounding.pdf",
        "analysis": {
            "benchmarks": [
                "MS COCO",
                "POPE VQA"
            ],
            "base_models": [
                "LLaVA 7B",
                "LLaVA 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MDAgents An Adaptive Collaboration of LLMs for Medical Decision-Making": {
        "filename": "MDAgents An Adaptive Collaboration of LLMs for Medical Decision-Making.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "PubMedQA",
                "DDXPlus",
                "SymCat",
                "JAMA",
                "MedBullets",
                "Path-VQA",
                "PMC-VQA",
                "MIMIC-CXR",
                "MedVidQA"
            ],
            "base_models": [
                "GPT-4",
                "Gemini-Pro (Vision)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Column Type Annotation using ChatGPT": {
        "filename": "Column Type Annotation using ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "SOTAB benchmark"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0301)",
                "RoBERTa"
            ]
        }
    },
    "DDCoT Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models": {
        "filename": "DDCoT Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "ChatGPT (175B)",
                "UnifiedQA (223M)",
                "LLaMA (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Grammar-based Game Description Generation using Large Language Models": {
        "filename": "Grammar-based Game Description Generation using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Ludii"
            ],
            "base_models": [
                "Llama3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "JailbreakEval An Integrated Toolkit for Evaluating Jailbreak Attempts Against Large Language Models": {
        "filename": "JailbreakEval An Integrated Toolkit for Evaluating Jailbreak Attempts Against Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench",
                "SafeBench"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-Generated Black-box Explanations Can Be Adversarially Helpful": {
        "filename": "LLM-Generated Black-box Explanations Can Be Adversarially Helpful.pdf",
        "analysis": {
            "benchmarks": [
                "ECQA",
                "SNLI"
            ],
            "base_models": [
                "Chat-3.5-Turbo",
                "GPT-4 (gpt-4-0613)",
                "Claude (Amazon Bedrock version)",
                "Cohere Command"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ProCoT Stimulating Critical Thinking and Writing of Students through Engagement with Large Language Models LLMs": {
        "filename": "ProCoT Stimulating Critical Thinking and Writing of Students through Engagement with Large Language Models LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "FEVER",
                "ClaimBuster"
            ],
            "base_models": [
                "ChatGPT (v3.5)",
                "Phind (v8)",
                "BingAI"
            ]
        }
    },
    "MoCa Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks": {
        "filename": "MoCa Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from 24 cognitive science papers on causal and moral judgments"
            ],
            "base_models": [
                "GPT-2",
                "RoBERTa-large",
                "ALBERT-xxlarge",
                "Electra-gen-large",
                "GPT3-babbage-v1 (6.7B)",
                "GPT3-curie-v1 (6.7B)",
                "GPT3.5-davinci-v2",
                "GPT3.5-davinci-v3",
                "Alpaca-7B",
                "Anthropic-claude-v1",
                "GPT3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Contrastive Reasoners": {
        "filename": "Large Language Models are Contrastive Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQUA-RAT",
                "SingleEq",
                "AddSub",
                "MultiArith",
                "SVAMP",
                "CommonsenseQA",
                "StrategyQA",
                "Last Letter Concatenation",
                "Coin Flip",
                "Date Understanding",
                "Tracking Shuffled Objects"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA3-8B",
                "LLaMA3-70B",
                "ChatGLM3-6B",
                "Qwen1.5-72B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do-Not-Answer A Dataset for Evaluating Safeguards in LLMs": {
        "filename": "Do-Not-Answer A Dataset for Evaluating Safeguards in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Do-Not-Answer"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT (gpt-3.5-turbo-0613)",
                "Claude (v1)",
                "LLaMA-2 (7B)",
                "ChatGLM2 (7B)",
                "Vicuna (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning": {
        "filename": "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "WIKI",
                "YAGO",
                "ICEWS14",
                "ICEWS18",
                "ACLED-CD22"
            ],
            "base_models": [
                "EleutherAI gpt-j-6b (6B)",
                "EleutherAI gpt-neox-20b (20B)",
                "OpenAI text-ada-001 (350M)",
                "OpenAI text-babbage-001 (1.3B)",
                "OpenAI text-curie-001 (6.7B)",
                "OpenAI text-davinci-003 (175B)",
                "OpenAI gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SMARTFEAT Efficient Feature Construction through Feature-Level Foundation Model Interactions": {
        "filename": "SMARTFEAT Efficient Feature Construction through Feature-Level Foundation Model Interactions.pdf",
        "analysis": {
            "benchmarks": [
                "Diabetes",
                "Heart",
                "Bank",
                "Adult",
                "Housing",
                "Lawschool",
                "West Nile Virus",
                "Tennis"
            ],
            "base_models": [
                "BERT",
                "PaLM",
                "GPT-3",
                "GPT-3.5-turbo",
                "GPT-4",
                "RoBERTa"
            ]
        }
    },
    "Harmful Speech Detection by Language Models Exhibits Gender-Queer Dialect Bias": {
        "filename": "Harmful Speech Detection by Language Models Exhibits Gender-Queer Dialect Bias.pdf",
        "analysis": {
            "benchmarks": [
                "QueerReclaimLex"
            ],
            "base_models": [
                "GPT-3.5",
                "LLaMA-2 (13 billion parameters)",
                "Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT-Neo for commonsense reasoning-a theoretical and practical lens": {
        "filename": "GPT-Neo for commonsense reasoning-a theoretical and practical lens.pdf",
        "analysis": {
            "benchmarks": [
                "Piqa",
                "Winogrande",
                "Hellaswag",
                "Storycloze",
                "BoolQ",
                "OpenBookQA"
            ],
            "base_models": [
                "GPT-Neo",
                "GPT-3",
                "Llama-2",
                "MPT",
                "Falcon"
            ]
        }
    },
    "Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models": {
        "filename": "Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 10 IFRS-compliant reports"
            ],
            "base_models": [
                "GPT-4",
                "SentenceBERT",
                "BERT"
            ]
        }
    },
    "Benchmarking a foundation LLM on its ability to re-label structure names in accordance with the AAPM TG-263 report": {
        "filename": "Benchmarking a foundation LLM on its ability to re-label structure names in accordance with the AAPM TG-263 report.pdf",
        "analysis": {
            "benchmarks": [
                "Prostate dataset (custom)",
                "Head and neck dataset (custom)",
                "Thorax dataset (custom)"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automating Chapter-Level Classification for Electronic Theses and Dissertations": {
        "filename": "Automating Chapter-Level Classification for Electronic Theses and Dissertations.pdf",
        "analysis": {
            "benchmarks": [
                "ETD-SGT",
                "PQDT",
                "ETD-CL"
            ],
            "base_models": [
                "BERT",
                "SciBERT",
                "Llama-2 (13B)",
                "Llama-3 (8B)"
            ]
        }
    },
    "LLM Multi-Agent Systems Challenges and Open Problems": {
        "filename": "LLM Multi-Agent Systems Challenges and Open Problems.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "Integrating Hierarchical Semantic into Iterative Generation Model for Entailment Tree Explanation": {
        "filename": "Integrating Hierarchical Semantic into Iterative Generation Model for Entailment Tree Explanation.pdf",
        "analysis": {
            "benchmarks": [
                "EntailmentBank",
                "eOBQA",
                "eQASC"
            ],
            "base_models": [
                "T5-11B",
                "T5-large",
                "albert-xxlarge-v2"
            ]
        }
    },
    "GREAT Geometry-Intention Collaborative Inference for Open-Vocabulary 3D Object Affordance Grounding": {
        "filename": "GREAT Geometry-Intention Collaborative Inference for Open-Vocabulary 3D Object Affordance Grounding.pdf",
        "analysis": {
            "benchmarks": [
                "PIADv2"
            ],
            "base_models": [
                "InternVL"
            ]
        }
    },
    "Networks of Networks Complexity Class Principles Applied to Compound AI Systems Design": {
        "filename": "Networks of Networks Complexity Class Principles Applied to Compound AI Systems Design.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "synthetic tasks (e.g., prime factorization)"
            ],
            "base_models": [
                "GPT-4-Turbo"
            ]
        }
    },
    "Tree-of-Table Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding": {
        "filename": "Tree-of-Table Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTQ",
                "TableFact",
                "FeTaQA",
                "BIRD"
            ],
            "base_models": [
                "GPT-3.5",
                "PaLM 2",
                "LLaMA 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Pushing Mixture of Experts to the Limit Extremely Parameter Efficient MoE for Instruction Tuning": {
        "filename": "Pushing Mixture of Experts to the Limit Extremely Parameter Efficient MoE for Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "ANLI",
                "HellaSwag",
                "WinoGrande",
                "Super Glue"
            ],
            "base_models": [
                "T5-770M",
                "T5-3B",
                "T5-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Gaining Wisdom from Setbacks Aligning Large Language Models via Mistake Analysis": {
        "filename": "Gaining Wisdom from Setbacks Aligning Large Language Models via Mistake Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "PKU-SafeRLHF",
                "AlpacaFarm"
            ],
            "base_models": [
                "Alpaca-7B",
                "GPT-3 (175B)",
                "GPT-3.5",
                "ChatGLM-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model Programs": {
        "filename": "Large Language Model Programs.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA"
            ],
            "base_models": [
                "OPT-175B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DeTeCtive Detecting AI-generated Text via Multi-Level Contrastive Learning": {
        "filename": "DeTeCtive Detecting AI-generated Text via Multi-Level Contrastive Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Deepfake",
                "M4",
                "TuringBench"
            ],
            "base_models": [
                "BERT-based",
                "T5-based",
                "SimCSE-RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Playing NetHack with LLMs Potential  Limitations as Zero-Shot Agents": {
        "filename": "Playing NetHack with LLMs Potential  Limitations as Zero-Shot Agents.pdf",
        "analysis": {
            "benchmarks": [
                "NetHack",
                "NetHack Learning Environment (NLE)",
                "MiniHack"
            ],
            "base_models": [
                "GPT-4-Turbo"
            ]
        }
    },
    "MiniGPT-3D Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors": {
        "filename": "MiniGPT-3D Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors.pdf",
        "analysis": {
            "benchmarks": [
                "ModelNet40",
                "Objaverse"
            ],
            "base_models": [
                "MiniGPT-3D (2.7B)",
                "ShapeLLM (13B)",
                "PointLLM (13B)",
                "LLaVA (13B)",
                "InstructBLIP (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Argumentative Large Language Models for Explainable and Contestable Decision-Making": {
        "filename": "Argumentative Large Language Models for Explainable and Contestable Decision-Making.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulClaim (adapted from TruthfulQA)",
                "StrategyClaim (adapted from StrategyQA)",
                "MedClaim (adapted from MedQA)"
            ],
            "base_models": [
                "Mistral-7B-Instruct-v0.2",
                "Mixtral-8x7B-Instruct-v0.1",
                "Gemma-7B",
                "GPT-3.5-turbo",
                "GPT-4-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dissecting Chain-of-Thought A Study on Compositional In-Context Learning of MLPs": {
        "filename": "Dissecting Chain-of-Thought A Study on Compositional In-Context Learning of MLPs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2 (Standard)",
                "GPT-2 (Small)",
                "GPT-2 (Tiny)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Universal Length Generalization with Turing Programs": {
        "filename": "Universal Length Generalization with Turing Programs.pdf",
        "analysis": {
            "benchmarks": [
                "Addition",
                "Multiplication",
                "SGD"
            ],
            "base_models": [
                "GPT-NeoX (150M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FLARE Faithful Logic-Aided Reasoning and Exploration": {
        "filename": "FLARE Faithful Logic-Aided Reasoning and Exploration.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "MultiArith",
                "ASDiv",
                "AQuA",
                "StrategyQA",
                "Date",
                "Sport",
                "CLUTRR"
            ],
            "base_models": [
                "Llama-3.1-8B",
                "CmDR-30B",
                "CmDR+-100B",
                "GPT-3.5 (100B+)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OCEAN Offline Chain-of-thought Evaluation and Alignment in Large Language Models": {
        "filename": "OCEAN Offline Chain-of-thought Evaluation and Alignment in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ARC",
                "PubMedQA",
                "SciQA",
                "HotpotQA",
                "MuSiQue",
                "StrategyQA",
                "CSQA",
                "CSQA-2",
                "CSQA-COT1000",
                "OpenBookQA",
                "WinoGrande"
            ],
            "base_models": [
                "Gemma-2 (2B)",
                "Llama-3 (8B)",
                "Phi-3.5-mini (3.8B)",
                "Mistral-0.2 (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cost-Efficient Prompt Engineering for Unsupervised Entity Resolution": {
        "filename": "Cost-Efficient Prompt Engineering for Unsupervised Entity Resolution.pdf",
        "analysis": {
            "benchmarks": [
                "Web Data Commons (WDC)",
                "Amazon-Google Products (AG)"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Not All Languages Are Created Equal in LLMs Improving Multilingual Capability by Cross-Lingual-Thought Prompting": {
        "filename": "Not All Languages Are Created Equal in LLMs Improving Multilingual Capability by Cross-Lingual-Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "MGSM",
                "XCOPA",
                "XNLI",
                "PAWS-X",
                "MKQA",
                "XL-Sum*",
                "FLORES*"
            ],
            "base_models": [
                "text-davinci-003",
                "gpt-3.5-turbo",
                "LLaMA-2-70b-chat-hf"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DLAP A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection": {
        "filename": "DLAP A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection.pdf",
        "analysis": {
            "benchmarks": [
                "Chrome",
                "Linux",
                "Android",
                "Qemu"
            ],
            "base_models": [
                "GPT-3.5-turbo-0125",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Q-Probe A Lightweight Approach to Reward Maximization for Language Models": {
        "filename": "Q-Probe A Lightweight Approach to Reward Maximization for Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MBPP",
                "HumanEval",
                "GSM-8K"
            ],
            "base_models": [
                "Code-LLaMA-7B",
                "CodeLlama-70b-Python",
                "gpt-3.5-turbo-1106",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-Assist Enhancing Closed-Loop Planning with Language-Based Reasoning": {
        "filename": "LLM-Assist Enhancing Closed-Loop Planning with Language-Based Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "nuPlan"
            ],
            "base_models": [
                "GPT-4",
                "Llama2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Search-Based LLMs for Code Optimization": {
        "filename": "Search-Based LLMs for Code Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "PIE dataset (Python and C++)"
            ],
            "base_models": [
                "CodeLlama-34B",
                "Gemini",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Answering Ambiguous Questions via Iterative Prompting": {
        "filename": "Answering Ambiguous Questions via Iterative Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "AmbigQA",
                "WebQSP"
            ],
            "base_models": [
                "T5-Base"
            ]
        }
    },
    "Think Outside the Code Brainstorming Boosts Large Language Models in Code Generation": {
        "filename": "Think Outside the Code Brainstorming Boosts Large Language Models in Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CodeContests",
                "APPS",
                "LeetCode Contests"
            ],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "Evaluating Explanations Through LLMs Beyond Traditional User Studies": {
        "filename": "Evaluating Explanations Through LLMs Beyond Traditional User Studies.pdf",
        "analysis": {
            "benchmarks": [
                "Celar and Byrne user study dataset"
            ],
            "base_models": [
                "Llama 3 (8B and 70B)",
                "Qwen 2 (7B and 72B)",
                "Mistral 7B",
                "Mistral Nemo",
                "GPT-4o Mini"
            ]
        }
    },
    "Hierarchical Video-Moment Retrieval and Step-Captioning": {
        "filename": "Hierarchical Video-Moment Retrieval and Step-Captioning.pdf",
        "analysis": {
            "benchmarks": [
                "HIREST"
            ],
            "base_models": [
                "CLIP (ViT-B/32)",
                "EVA-CLIP (ViT-G/14)",
                "Frozen-in-Time",
                "MIL-NCE (S3D)",
                "BMT",
                "SwinBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DRBENCH Diagnostic Reasoning Benchmark for Clinical Natural Language Processing": {
        "filename": "DRBENCH Diagnostic Reasoning Benchmark for Clinical Natural Language Processing.pdf",
        "analysis": {
            "benchmarks": [
                "MedNLI",
                "EmrQA",
                "SOAP Labeling",
                "Assessment and Plan Relation Labeling (AP)",
                "MedQA",
                "Problem Summarization (Summ-Assmt and Summ-Note)"
            ],
            "base_models": [
                "T5-Base (220M parameters)",
                "T5-Large (770M parameters)",
                "SciFive-Base",
                "SciFive-Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Discovering Latent Knowledge in Language Models Without Supervision": {
        "filename": "Discovering Latent Knowledge in Language Models Without Supervision.pdf",
        "analysis": {
            "benchmarks": [
                "IMDB",
                "Amazon",
                "AG-News",
                "DBpedia-14",
                "RTE",
                "QNLI",
                "COPA",
                "Story-Cloze",
                "BoolQ",
                "PIQA"
            ],
            "base_models": [
                "T5",
                "UnifiedQA",
                "T0",
                "GPT-J",
                "RoBERTa",
                "DeBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CharED Character-wise Ensemble Decoding for Large Language Models": {
        "filename": "CharED Character-wise Ensemble Decoding for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "GSM8K",
                "ToxiGen"
            ],
            "base_models": [
                "Llama 2 Chat (7B)",
                "WizardMath (7B)",
                "DeepSeek Coder (7B)"
            ]
        }
    },
    "Mix-CPT A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment": {
        "filename": "Mix-CPT A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "NaturalQuestion (NQ)",
                "TrivialQA (TQ)",
                "WikiQA (WQ)",
                "GSM8K",
                "MATH",
                "MBPP",
                "HumanEval",
                "RACE-Hard",
                "OpenBookQA",
                "HellaSwag",
                "CSQA",
                "PIQA",
                "MMLU",
                "BBH",
                "ARC-Challenge",
                "C-EVAL",
                "MT-Bench"
            ],
            "base_models": [
                "LLaMA3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leftover Lunch Advantage-based Offline Reinforcement Learning for Language Models": {
        "filename": "Leftover Lunch Advantage-based Offline Reinforcement Learning for Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Helpful and Harmless Assistant (HHA)",
                "Commonsense Reasoning",
                "Reddit response generation",
                "Faithful knowledge-grounded dialog"
            ],
            "base_models": [
                "LLaMA-7B",
                "DialoGPT-medium (355M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WALL-E World Alignment by Rule Learning Improves World Model-based LLM Agents": {
        "filename": "WALL-E World Alignment by Rule Learning Improves World Model-based LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Minecraft",
                "ALFWorld"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prose-to-P4 Leveraging High Level Languages": {
        "filename": "Prose-to-P4 Leveraging High Level Languages.pdf",
        "analysis": {
            "benchmarks": [
                "Lucid"
            ],
            "base_models": [
                "ChatGPT 4",
                "Gemini Ultra"
            ]
        }
    },
    "iToT An Interactive System for Customized Tree-of-Thought Generation": {
        "filename": "iToT An Interactive System for Customized Tree-of-Thought Generation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4",
                "GPT-4o"
            ]
        }
    },
    "ViperGPT Visual Inference via Python Execution for Reasoning": {
        "filename": "ViperGPT Visual Inference via Python Execution for Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "RefCOCO",
                "RefCOCO+",
                "GQA",
                "OK-VQA",
                "NExT-QA"
            ],
            "base_models": [
                "GPT-3 Codex",
                "GLIP",
                "X-VLM",
                "MiDaS",
                "BLIP-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BeSimulator A Large Language Model Powered Text-based Behavior Simulator": {
        "filename": "BeSimulator A Large Language Model Powered Text-based Behavior Simulator.pdf",
        "analysis": {
            "benchmarks": [
                "BTSIMBENCH"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3",
                "Deepseek-V2-Chat",
                "Qwen2-72B-Instruct",
                "Llama3.1-70B-Instruct"
            ]
        }
    },
    "Distilling Algorithmic Reasoning from LLMs via Explaining Solution Programs": {
        "filename": "Distilling Algorithmic Reasoning from LLMs via Explaining Solution Programs.pdf",
        "analysis": {
            "benchmarks": [
                "CodeContests",
                "CF Prob"
            ],
            "base_models": [
                "GPT-4-0613",
                "GPT-3.5-turbo-1106",
                "Deepseek Coder 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Reasoning in Large Language Models A Survey": {
        "filename": "Towards Reasoning in Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "Math",
                "MathQA",
                "SVAMP",
                "ASDiv",
                "AQuA",
                "MAWPS",
                "CSQA",
                "StrategyQA",
                "ARC",
                "Last Letter Concatenation",
                "Coin Flip",
                "BIG-bench",
                "SCAN",
                "WikiTableQA",
                "FetaQA",
                "CommonGen",
                "Open Relation Modeling"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM",
                "Codex",
                "RoBERTa",
                "T5",
                "OPT",
                "BERT",
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Baichuan Alignment Technical Report": {
        "filename": "Baichuan Alignment Technical Report.pdf",
        "analysis": {
            "benchmarks": [
                "ArenaHard",
                "MTBench",
                "HumanEval",
                "BBH",
                "MATH",
                "FollowBench",
                "IFEval",
                "CFBench",
                "SysBench",
                "FB-Bench",
                "MixEval-Hard",
                "Alpaca-Eval2.0",
                "GPQA"
            ],
            "base_models": [
                "Qwen2-72B",
                "Llama-3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MaxMI A Maximal Mutual Information Criterion for Manipulation Concept Discovery": {
        "filename": "MaxMI A Maximal Mutual Information Criterion for Manipulation Concept Discovery.pdf",
        "analysis": {
            "benchmarks": [
                "ManiSkill2",
                "Franka Kitchen"
            ],
            "base_models": [
                "CLIP",
                "BLIP",
                "BLIP2",
                "FLAVA"
            ]
        }
    },
    "Accuracy and Consistency of LLMs in the Registered Dietitian Exam The Impact of Prompt Engineering and Knowledge Retrieval": {
        "filename": "Accuracy and Consistency of LLMs in the Registered Dietitian Exam The Impact of Prompt Engineering and Knowledge Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "Registered Dietitian (RD) exam",
                "MMLU",
                "GPQA",
                "DROP"
            ],
            "base_models": [
                "GPT-4o",
                "Claude 3.5 Sonnet",
                "Gemini 1.5 Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MQM-APE Toward High-Quality Error Annotation Predictors with Automatic Post-Editing in LLM Translation Evaluators": {
        "filename": "MQM-APE Toward High-Quality Error Annotation Predictors with Automatic Post-Editing in LLM Translation Evaluators.pdf",
        "analysis": {
            "benchmarks": [
                "WMT22 test set",
                "IndicMT test set"
            ],
            "base_models": [
                "Llama3-8b-inst",
                "Llama3-70b-inst",
                "Mixtral-8x7b-inst",
                "Mixtral-8x22b-inst",
                "Qwen1.5-14b-chat",
                "Qwen1.5-72b-chat",
                "Tower-7b-inst",
                "Tower-13b-inst"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the use of Large Language Models in Model-Driven Engineering": {
        "filename": "On the use of Large Language Models in Model-Driven Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "ModelSet dataset",
                "EMF-based metamodels dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Codex",
                "ChatGPT",
                "RoBERTa",
                "GPT-2 (fine-tuned as SLGPT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Training Language Models with Language Feedback at Scale": {
        "filename": "Training Language Models with Language Feedback at Scale.pdf",
        "analysis": {
            "benchmarks": [
                "TL;DR dataset (adapted from Völske et al., 2017)"
            ],
            "base_models": [
                "GPT-3 (175B parameters)",
                "OPT-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Simple and Provable Scaling Law for the Test-Time Compute of Large Language Models": {
        "filename": "A Simple and Provable Scaling Law for the Test-Time Compute of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU-Pro"
            ],
            "base_models": [
                "Llama3.1-70B-Instruct",
                "Qwen2.5-72B-Instruct"
            ]
        }
    },
    "Large Language Models and Foundation Models in Smart Agriculture Basics Opportunities and Challenges": {
        "filename": "Large Language Models and Foundation Models in Smart Agriculture Basics Opportunities and Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "Microsoft COCO",
                "PlantCLEF2022"
            ],
            "base_models": [
                "BERT (110M and 340M parameters)",
                "PaLM (540B parameters)",
                "LLAMA",
                "GPT-2 (1.5B parameters)",
                "GPT-3 (175B parameters)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aligning Teacher with Student Preferences for Tailored Training Data Generation": {
        "filename": "Aligning Teacher with Student Preferences for Tailored Training Data Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Big-Bench-Hard",
                "PIQA",
                "CommonsenseQA",
                "ARC-Easy",
                "ARC-Challenge",
                "GSM8K"
            ],
            "base_models": [
                "Llama-3-70B-Instruction",
                "Gemma-2B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RL-STaR Theoretical Analysis of Reinforcement Learning Frameworks for Self-Taught Reasoner": {
        "filename": "RL-STaR Theoretical Analysis of Reinforcement Learning Frameworks for Self-Taught Reasoner.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LINGOLY A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low-Resource and Extinct Languages": {
        "filename": "LINGOLY A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low-Resource and Extinct Languages.pdf",
        "analysis": {
            "benchmarks": [
                "LINGOLY"
            ],
            "base_models": [
                "Gemma 7B",
                "Llama 2 70B",
                "Llama 3 70B",
                "Aya 23 35B",
                "Llama 3 8B",
                "Mixtral 8x7B",
                "GPT-3.5",
                "GPT-4",
                "GPT-4o",
                "Claude Opus",
                "Gemini 1.5 Pro",
                "Command R+"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Systematic Human Learning and Generalization From a Brief Tutorial With Explanatory Feedback": {
        "filename": "Systematic Human Learning and Generalization From a Brief Tutorial With Explanatory Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "hidden single puzzles"
            ],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "REFLECT Summarizing Robot Experiences for Failure Explanation and Correction": {
        "filename": "REFLECT Summarizing Robot Experiences for Failure Explanation and Correction.pdf",
        "analysis": {
            "benchmarks": [
                "RoboFail"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Computational Experiments Meet Large Language Model Based Agents A Survey and Perspective": {
        "filename": "Computational Experiments Meet Large Language Model Based Agents A Survey and Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "S3 system (emotion, attitude, and interaction behaviors)",
                "GAEA (massive AI-driven NPC system)"
            ],
            "base_models": [
                "AutoGPT",
                "BabyAGI",
                "GenerativeAgents",
                "MetaGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Step-DPO Step-wise Preference Optimization for Long-chain Reasoning of LLMs": {
        "filename": "Step-DPO Step-wise Preference Optimization for Long-chain Reasoning of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K"
            ],
            "base_models": [
                "Qwen2-72B-Instruct",
                "Llama-3-70B-Instruct",
                "DeepSeekMath-7B-Base",
                "Qwen1.5-32B-SFT"
            ]
        }
    },
    "Zero-Shot Visual Reasoning by Vision-Language Models Benchmarking and Analysis": {
        "filename": "Zero-Shot Visual Reasoning by Vision-Language Models Benchmarking and Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "CLEVR",
                "PTR"
            ],
            "base_models": [
                "GPT-3.5-Turbo (175B)",
                "GPT-4",
                "Flan-T5-XL (3B)",
                "Flan-T5-XXL (11B)",
                "BLIP2-Flan-T5-XL (3B)",
                "BLIP2-Flan-T5-XXL (11B)",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fine-tuning LLMs for Autonomous Spacecraft Control A Case Study Using Kerbal Space Program": {
        "filename": "Fine-tuning LLMs for Autonomous Spacecraft Control A Case Study Using Kerbal Space Program.pdf",
        "analysis": {
            "benchmarks": [
                "Kerbal Space Program Differential Games suite (KSPDG)"
            ],
            "base_models": [
                "GPT-3.5",
                "LLaMA-3-8B"
            ]
        }
    },
    "ConceptThread Visualizing Threaded Concepts in MOOC Videos": {
        "filename": "ConceptThread Visualizing Threaded Concepts in MOOC Videos.pdf",
        "analysis": {
            "benchmarks": [
                "Coursera MOOC videos"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model-Based Agents for Software Engineering A Survey": {
        "filename": "Large Language Model-Based Agents for Software Engineering A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "BigBench",
                "SySeVR",
                "CWE-Bench-Java",
                "Rnd-300"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generating with Confidence Uncertainty Quantification for Black-box Large Language Models": {
        "filename": "Generating with Confidence Uncertainty Quantification for Black-box Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CoQA",
                "TriviaQA",
                "Natural Questions"
            ],
            "base_models": [
                "OPT-13B",
                "LLaMA-13B",
                "LLaMA2-13B",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AttriPrompter Auto-Prompting with Attribute Semantics for Zero-shot Nuclei Detection via Visual-Language Pre-trained Models": {
        "filename": "AttriPrompter Auto-Prompting with Attribute Semantics for Zero-shot Nuclei Detection via Visual-Language Pre-trained Models.pdf",
        "analysis": {
            "benchmarks": [
                "MoNuSeg",
                "CoNSeP"
            ],
            "base_models": [
                "GLIP",
                "BLIP",
                "GPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SymbolicAI A framework for logic-based approaches combining generative models and solvers": {
        "filename": "SymbolicAI A framework for logic-based approaches combining generative models and solvers.pdf",
        "analysis": {
            "benchmarks": [
                "VERTEX score",
                "custom benchmark for complex workflows"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4 Turbo",
                "Gemini-Pro",
                "LLaMA2-Chat 13B",
                "LLaMA3-Chat 8B",
                "LLaMA3-Chat 70B",
                "Mistral 7B",
                "Zephyr 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Textual Aesthetics in Large Language Models": {
        "filename": "Textual Aesthetics in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaEval",
                "Arena-Hard"
            ],
            "base_models": [
                "LLaMA-3.1-8B",
                "LLaMA-3.1-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MindAgent Emergent Gaming Interaction": {
        "filename": "MindAgent Emergent Gaming Interaction.pdf",
        "analysis": {
            "benchmarks": [
                "CUISINE WORLD"
            ],
            "base_models": [
                "GPT-4",
                "Claude",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WorkArena How Capable Are Web Agents at Solving Common Knowledge Work Tasks": {
        "filename": "WorkArena How Capable Are Web Agents at Solving Common Knowledge Work Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "WorkArena",
                "MiniWoB",
                "WebArena"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-3.5",
                "Llama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cost-Aware Uncertainty Reduction in Schema Matching with GPT-4 The Prompt-Matcher Framework": {
        "filename": "Cost-Aware Uncertainty Reduction in Schema Matching with GPT-4 The Prompt-Matcher Framework.pdf",
        "analysis": {
            "benchmarks": [
                "DeepMDatasets",
                "Fabricated-Datasets"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Investigating Symbolic Capabilities of Large Language Models": {
        "filename": "Investigating Symbolic Capabilities of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom symbolic tasks dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Gemini",
                "Claude",
                "Llamma 2 (13B)",
                "Llemma (7B)",
                "Deepseek (7B)",
                "MetaMath (7B)"
            ]
        }
    },
    "Chain of Hindsight Aligns Language Models with Feedback": {
        "filename": "Chain of Hindsight Aligns Language Models with Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "TL;DR summarization dataset",
                "Anthropic's Helpful and Harmless (HH) dataset"
            ],
            "base_models": [
                "GPT-J 6B",
                "OPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Causal Reasoning of Entities and Events in Procedural Texts": {
        "filename": "Causal Reasoning of Entities and Events in Procedural Texts.pdf",
        "analysis": {
            "benchmarks": [
                "CREPE"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "Codex (175B)",
                "T5 (3B)",
                "T0 (11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Are Not Robust Multiple Choice Selectors": {
        "filename": "Large Language Models Are Not Robust Multiple Choice Selectors.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "ARC-Challenge",
                "CommonsenseQA"
            ],
            "base_models": [
                "llama-7B",
                "llama-13B",
                "llama-30B",
                "llama-65B",
                "llama-2-7B",
                "llama-2-13B",
                "llama-2-70B",
                "llama-2-chat-7B",
                "llama-2-chat-13B",
                "llama-2-chat-70B",
                "vicuna-v1.3-7B",
                "vicuna-v1.3-13B",
                "vicuna-v1.3-33B",
                "vicuna-v1.5-7B",
                "vicuna-v1.5-13B",
                "falcon-7B",
                "falcon-40B",
                "falcon-inst-7B",
                "falcon-inst-40B",
                "gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EchoNarrator Generating Natural Text Explanations for Ejection Fraction Predictions": {
        "filename": "EchoNarrator Generating Natural Text Explanations for Ejection Fraction Predictions.pdf",
        "analysis": {
            "benchmarks": [
                "EchoNet-Dynamic"
            ],
            "base_models": [
                "LLaMA (size not specified)",
                "GPT-4 (used for data augmentation)"
            ]
        }
    },
    "Boosted Prompt Ensembles for Large Language Models": {
        "filename": "Boosted Prompt Ensembles for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQUA",
                "MMLU570",
                "CMATH420",
                "SVAMP"
            ],
            "base_models": [
                "code-davinci-002",
                "text-davinci-003",
                "gpt-3.5-turbo",
                "text-curie-001"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MATATA A weakly-supervised MAthematical Tool-Assisted reasoning for Tabular Applications": {
        "filename": "MATATA A weakly-supervised MAthematical Tool-Assisted reasoning for Tabular Applications.pdf",
        "analysis": {
            "benchmarks": [
                "FinQA",
                "TAT-QA",
                "TabMWP"
            ],
            "base_models": [
                "Phi-3-mini-4k-instruct 3.8B",
                "Ministral-8B-Instruct-2410"
            ]
        }
    },
    "Towards A Better Metric for Text-to-Video Generation": {
        "filename": "Towards A Better Metric for Text-to-Video Generation.pdf",
        "analysis": {
            "benchmarks": [
                "TVGE dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "Otter",
                "Video-LLaMA",
                "mPLUG-OWL2-V",
                "InstructBLIP",
                "mPLUG-OWL2-I",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Q-Instruct Improving Low-Level Visual Abilities for Multi-Modality Foundation Models": {
        "filename": "Q-Instruct Improving Low-Level Visual Abilities for Multi-Modality Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "LLVisionQA-test",
                "KonIQ-10k",
                "SPAQ",
                "LIVE-FB",
                "LIVE-itw",
                "AGIQA-3K",
                "CGIQA-6K",
                "KADID-10K",
                "KonViD-1k"
            ],
            "base_models": [
                "LLaVA-v1.5-7B",
                "LLaVA-v1.5-13B",
                "mPLUG-Owl-2",
                "InternLM-XComposer-VL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieving Evidence from EHRs with LLMs Possibilities and Challenges": {
        "filename": "Retrieving Evidence from EHRs with LLMs Possibilities and Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-III dataset",
                "EHR notes of patients admitted to the Emergency Room of Brigham and Women’s Hospital (BWH)"
            ],
            "base_models": [
                "Flan-T5 XXL (11.3B parameters)",
                "Mistral-Instruct (7B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CAMEL Communicative Agents for Mind Exploration of Large Language Model Society": {
        "filename": "CAMEL Communicative Agents for Mind Exploration of Large Language Model Society.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "HumanEval+"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "GPT-4",
                "LLaMA-7B",
                "Vicuna-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-stage Large Language Model Correction for Speech Recognition": {
        "filename": "Multi-stage Large Language Model Correction for Speech Recognition.pdf",
        "analysis": {
            "benchmarks": [
                "LibriSpeech",
                "Common Voice",
                "TED-LIUM 3",
                "Multilingual LibriSpeech"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "GPT-J"
            ]
        }
    },
    "Reference Trustable Decoding A Training-Free Augmentation Paradigm for Large Language Models": {
        "filename": "Reference Trustable Decoding A Training-Free Augmentation Paradigm for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Massive Multitask Language Understanding (MMLU)",
                "AI2 Reasoning Challenge (ARC)",
                "Reasoning about Physical Commonsense in Natural Language (PIQA)",
                "Open Book Question Answering (OBQA)",
                "Massive Multitask Language Understanding in Chinese (C-MMLU)"
            ],
            "base_models": [
                "LLaMA2-7B",
                "LLaMA2-70B",
                "LLaMA3-8B",
                "MPT-7B",
                "GLM3-6B",
                "Yi-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Answering Questions by Meta-Reasoning over Multiple Chains of Thought": {
        "filename": "Answering Questions by Meta-Reasoning over Multiple Chains of Thought.pdf",
        "analysis": {
            "benchmarks": [
                "STRATEGY QA",
                "FERMI",
                "QUARTZ",
                "HOTPOT QA",
                "2WIKIMQA",
                "BAMBOOGLE",
                "FEVEROUS"
            ],
            "base_models": [
                "code-davinci-002",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BYOC Personalized Few-Shot Classification with Co-Authored Class Descriptions": {
        "filename": "BYOC Personalized Few-Shot Classification with Co-Authored Class Descriptions.pdf",
        "analysis": {
            "benchmarks": [
                "Web of Science dataset"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AcademicGPT Empowering Academic Research": {
        "filename": "AcademicGPT Empowering Academic Research.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "CEval",
                "PubMedQA",
                "SCIEval",
                "ComputerScienceQA"
            ],
            "base_models": [
                "LLaMA2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tactics Techniques and Procedures TTPs in Interpreted Malware A Zero-Shot Generation with Large Language Models": {
        "filename": "Tactics Techniques and Procedures TTPs in Interpreted Malware A Zero-Shot Generation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "dataset with ground truth labels",
                "large dataset in the wild"
            ],
            "base_models": [
                "GPT-4.0",
                "GPT-3.5",
                "LLaMA2",
                "QWen",
                "Gemini Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Effectively Detecting and Explaining Vulnerabilities Using Large Language Models": {
        "filename": "Towards Effectively Detecting and Explaining Vulnerabilities Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SeVC",
                "DiverseVul"
            ],
            "base_models": [
                "CodeLlama-13B-Instruct",
                "CodeLlama-7B-Instruct",
                "Llama3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Logic-of-Thought Injecting Logic into Contexts for Full Reasoning in Large Language Models": {
        "filename": "Logic-of-Thought Injecting Logic into Contexts for Full Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ReClor",
                "LogiQA",
                "ProofWriter"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Metaphors We Learn By": {
        "filename": "Metaphors We Learn By.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "GSM8K"
            ],
            "base_models": [
                "PaLM (size not specified)",
                "auto-regressive models (size not specified)"
            ]
        }
    },
    "Is GPT-3 a Good Data Annotator": {
        "filename": "Is GPT-3 a Good Data Annotator.pdf",
        "analysis": {
            "benchmarks": [
                "SST2",
                "FewRel",
                "CrossNER (AI Domain Split)",
                "ASTE (laptop domain split)"
            ],
            "base_models": [
                "GPT-3",
                "BERT BASE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs as Factual Reasoners Insights from Existing Benchmarks and Beyond": {
        "filename": "LLMs as Factual Reasoners Insights from Existing Benchmarks and Beyond.pdf",
        "analysis": {
            "benchmarks": [
                "SUMM EDITS",
                "FactCC",
                "AggreFact",
                "DialSummEval"
            ],
            "base_models": [
                "GPT-4",
                "Claude V1.3",
                "Bard",
                "PaLM2-Bison",
                "GPT3.5-turbo",
                "LLaMa-13B",
                "Alpaca-13B",
                "Dolly-v2-12B",
                "MPT-7B-Chat",
                "Vicuna-13B",
                "Cohere-CMD-XL",
                "Davinci-001",
                "Davinci-002",
                "Davinci-003",
                "Ada001",
                "Babbage001",
                "Curie001"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Img2Loc Revisiting Image Geolocalization using Multi-modality Foundation Models and Image-based Retrieval-Augmented Generation": {
        "filename": "Img2Loc Revisiting Image Geolocalization using Multi-modality Foundation Models and Image-based Retrieval-Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Im2GPS3k",
                "YFCC4k"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA"
            ]
        }
    },
    "Structure-informed Language Models Are Protein Designers": {
        "filename": "Structure-informed Language Models Are Protein Designers.pdf",
        "analysis": {
            "benchmarks": [
                "CATH 4.2",
                "CATH 4.3"
            ],
            "base_models": [
                "ESM-1b (650M)",
                "ESM-2 series (up to 3B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Requirements Engineering using Generative AI Prompts and Prompting Patterns": {
        "filename": "Requirements Engineering using Generative AI Prompts and Prompting Patterns.pdf",
        "analysis": {
            "benchmarks": [
                "PROMISE dataset",
                "PURE dataset"
            ],
            "base_models": [
                "GPT-3.5 turbo"
            ]
        }
    },
    "Integrating Cognitive AI with Generative Models for Enhanced Question Answering in Skill-based Learning": {
        "filename": "Integrating Cognitive AI with Generative Models for Enhanced Question Answering in Skill-based Learning.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5 Turbo"
            ]
        }
    },
    "Generative Design of Functional Metal Complexes Utilizing the Internal Knowledge of Large Language Models": {
        "filename": "Generative Design of Functional Metal Complexes Utilizing the Internal Knowledge of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "1.37M TMC space"
            ],
            "base_models": [
                "claude-3.5-sonnet",
                "o1-preview",
                "gpt-4o",
                "o1-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Teaching Language Models to Hallucinate Less with Synthetic Tasks": {
        "filename": "Teaching Language Models to Hallucinate Less with Synthetic Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MS MARCO",
                "QMSum",
                "ACI-Bench"
            ],
            "base_models": [
                "Vicuna v1.1 (13B)",
                "Orca (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Long-Context Language Models Subsume Retrieval RAG SQL and More": {
        "filename": "Can Long-Context Language Models Subsume Retrieval RAG SQL and More.pdf",
        "analysis": {
            "benchmarks": [
                "LOFT",
                "ArguAna",
                "FEVER",
                "FIQA",
                "MS MARCO",
                "NQ",
                "Quora",
                "SciFact",
                "Touché-2020",
                "TopiOCQA",
                "HotPotQA",
                "MuSiQue",
                "QAMPARI",
                "QUEST",
                "Flickr30k",
                "MS COCO",
                "OVEN",
                "MSR-VTT",
                "FLEURS-en",
                "FLEURS-es",
                "FLEURS-fr",
                "FLEURS-hi",
                "FLEURS-zh",
                "Spider",
                "SParC",
                "BBH-date",
                "BBH-salient",
                "BBH-tracking7",
                "BBH-web",
                "LIB-dialogue"
            ],
            "base_models": [
                "Gemini 1.5 Pro",
                "GPT-4o",
                "Claude 3 Opus"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NSP A Neuro-Symbolic Natural Language Navigational Planner": {
        "filename": "NSP A Neuro-Symbolic Natural Language Navigational Planner.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of 1500 natural language path planning scenarios"
            ],
            "base_models": [
                "GPT-4o-mini"
            ]
        }
    },
    "Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning": {
        "filename": "Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "ARC-C",
                "SciQ"
            ],
            "base_models": [
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Human-GenAI Value Loop in Human-Centered Innovation Beyond the Magical Narrative": {
        "filename": "The Human-GenAI Value Loop in Human-Centered Innovation Beyond the Magical Narrative.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A qualitative assessment of using ChatGPT as large language model for scientific workflow development": {
        "filename": "A qualitative assessment of using ChatGPT as large language model for scientific workflow development.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "LLaMA",
                "Bloom"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias": {
        "filename": "Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias.pdf",
        "analysis": {
            "benchmarks": [
                "Invasion Game With Distraction",
                "Deceptive Invasion Game",
                "Computer Maintenance environment"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tele-FLM Technical Report": {
        "filename": "Tele-FLM Technical Report.pdf",
        "analysis": {
            "benchmarks": [
                "Open LLM Leaderboard",
                "HumanEval",
                "BIG-Bench Hard",
                "C-Eval",
                "CMMLU",
                "C3",
                "CHID",
                "CSL"
            ],
            "base_models": [
                "Llama2-70B",
                "Llama-65B",
                "Llama3-70B",
                "Qwen1.5-72B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Code Generation by Training with Natural Language Feedback": {
        "filename": "Improving Code Generation by Training with Natural Language Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "Mostly Basic Python Problems (MBPP)"
            ],
            "base_models": [
                "CODEGEN-MONO 6.1B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Opportunities and Challenges of Generative-AI in Finance": {
        "filename": "Opportunities and Challenges of Generative-AI in Finance.pdf",
        "analysis": {
            "benchmarks": [
                "FinQA",
                "ConvFinQA"
            ],
            "base_models": [
                "BloombergGPT (50B)",
                "Llama2"
            ]
        }
    },
    "Goat Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks": {
        "filename": "Goat Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-bench arithmetic sub-task"
            ],
            "base_models": [
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Effective Prompt Extraction from Language Models": {
        "filename": "Effective Prompt Extraction from Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Unnatural Instructions",
                "ShareGPT",
                "Awesome-ChatGPT-Prompts"
            ],
            "base_models": [
                "GPT-4",
                "Llama-2-chat-70B",
                "Vicuna 1.3-33B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TeleChat Technical Report": {
        "filename": "TeleChat Technical Report.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "CMMLU",
                "C-Eval",
                "GAOKAO-Bench",
                "AGIEVAL",
                "CSL",
                "EPRSTMT",
                "CHID",
                "GSM8K",
                "Math",
                "HumanEval"
            ],
            "base_models": [
                "GPT-3",
                "LLaMA (various versions)",
                "BLOOM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BloombergGPT A Large Language Model for Finance": {
        "filename": "BloombergGPT A Large Language Model for Finance.pdf",
        "analysis": {
            "benchmarks": [],
            "models": [],
            "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
        }
    },
    "NADER Neural Architecture Design via Multi-Agent Collaboration": {
        "filename": "NADER Neural Architecture Design via Multi-Agent Collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR10",
                "CIFAR100",
                "ImageNet16-120"
            ],
            "base_models": [
                "ResNet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Action Faithful and Multimodal Question Answering through Large Language Models": {
        "filename": "Chain-of-Action Faithful and Multimodal Question Answering through Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WebQuestions QA",
                "General Knowledge",
                "Social QA",
                "Truth QA",
                "Strategy QA",
                "FEVER"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "Diversity Helps Jailbreak Large Language Models": {
        "filename": "Diversity Helps Jailbreak Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Harmbench",
                "Advbench"
            ],
            "base_models": [
                "GPT-4",
                "Gemini",
                "Llama-2",
                "GPT-4o-mini",
                "Mistral-7B",
                "Qwen2-7B",
                "Vicuna-13B",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interactive Planning Using Large Language Models for Partially Observable Robotic Tasks": {
        "filename": "Interactive Planning Using Large Language Models for Partially Observable Robotic Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "IsaacGym simulation environment",
                "Real-world robot experiments"
            ],
            "base_models": [
                "GPT-4",
                "Llama2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WISE Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models": {
        "filename": "WISE Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ZsRE",
                "SelfCheckGPT",
                "Temporal"
            ],
            "base_models": [
                "GPT-J-6B",
                "LLaMA-2-7B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Sirens Song in the AI Ocean A Survey on Hallucination in Large Language Models": {
        "filename": "Sirens Song in the AI Ocean A Survey on Hallucination in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "FActScore",
                "HaluEval",
                "FACTOR",
                "FactualityPrompt",
                "KoLA-KC"
            ],
            "base_models": [
                "GPT-3 (300B tokens)",
                "LLaMA (1.4T tokens)",
                "Llama 2 (2T tokens)",
                "GLM",
                "BLOOM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoMM A Coherent Interleaved Image-Text Dataset for Multimodal Understanding and Generation": {
        "filename": "CoMM A Coherent Interleaved Image-Text Dataset for Multimodal Understanding and Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MMC4",
                "OBELICS",
                "COCO",
                "Flickr30k",
                "VQAv2",
                "OKVQA",
                "TextVQA",
                "VizWiz",
                "HatefulMemes"
            ],
            "base_models": [
                "GPT-4",
                "Stable Diffusion XL",
                "Llama3",
                "CLIP",
                "MiniGPT-5 (7B)",
                "SEED-Llama (8B)",
                "SEED-Llama (14B)",
                "Emu2 (33B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning Circuits Few-shot Multi-hop Question Generation with Structured Rationales": {
        "filename": "Reasoning Circuits Few-shot Multi-hop Question Generation with Structured Rationales.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA"
            ],
            "base_models": [
                "T5-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization": {
        "filename": "Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization.pdf",
        "analysis": {
            "benchmarks": [
                "VisSpeech",
                "ASCEND",
                "SEAME",
                "CoVOST2",
                "MuST-C V1",
                "Libri-Trans"
            ],
            "base_models": [
                "Whisper (39M to 1.55B)"
            ]
        }
    },
    "Negotiating with LLMS Prompt Hacks Skill Gaps and Reasoning Deficits": {
        "filename": "Negotiating with LLMS Prompt Hacks Skill Gaps and Reasoning Deficits.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT Turbo 3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Elephants Never Forget Testing Language Models for Memorization of Tabular Data": {
        "filename": "Elephants Never Forget Testing Language Models for Memorization of Tabular Data.pdf",
        "analysis": {
            "benchmarks": [
                "IRIS",
                "Wine",
                "Kaggle Titanic",
                "OpenML Diabetes",
                "Adult Income",
                "California Housing",
                "Scikit-learn Diabetes",
                "FICO HELIOCv1",
                "Kaggle Spaceship Titanic",
                "Pneumonia"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Agent Security Bench ASB Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents": {
        "filename": "Agent Security Bench ASB Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Agent Security Bench (ASB)"
            ],
            "base_models": [
                "Gemma2-9B",
                "Gemma2-27B",
                "LLaMA3-8B",
                "LLaMA3-70B",
                "LLaMA3.1-8B",
                "LLaMA3.1-70B",
                "Mixtral-8x7B",
                "Qwen2-7B",
                "Qwen2-72B",
                "Claude3.5 Sonnet",
                "GPT-3.5 Turbo",
                "GPT-4o",
                "GPT-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instruction Tuning with GPT-4": {
        "filename": "Instruction Tuning with GPT-4.pdf",
        "analysis": {
            "benchmarks": [
                "User-Oriented-Instructions-2522",
                "Vicuna-Instructions-803",
                "Unnatural Instructions"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-7B",
                "GPT-3.5",
                "OPT-IML"
            ]
        }
    },
    "EvEval A Comprehensive Evaluation of Event Semantics for Large Language Models": {
        "filename": "EvEval A Comprehensive Evaluation of Event Semantics for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "EVEVAL",
                "DTFit",
                "HardSim",
                "ECARE",
                "TRACIE",
                "TIMETRAVEL",
                "SocialIQA",
                "MCNC",
                "SCT"
            ],
            "base_models": [
                "LLAMA",
                "BLOOM",
                "GPT series",
                "ChatGPT",
                "BLOOMZ",
                "Flan-T5 (11B)"
            ]
        }
    },
    "RQ-RAG Learning to Refine Queries for Retrieval Augmented Generation": {
        "filename": "RQ-RAG Learning to Refine Queries for Retrieval Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Arc-Challenge",
                "PopQA",
                "OpenbookQA",
                "HotpotQA",
                "2WikiMultiHopQA",
                "Musique"
            ],
            "base_models": [
                "Llama2-7B"
            ]
        }
    },
    "Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model": {
        "filename": "Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "FOLIO",
                "ReClor",
                "HumanEval",
                "MBPP"
            ],
            "base_models": [
                "LLaMA3-8B-Instruct",
                "Mistral-7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ArgMed-Agents Explainable Clinical Decision Reasoning with LLM Disscusion via Argumentation Schemes": {
        "filename": "ArgMed-Agents Explainable Clinical Decision Reasoning with LLM Disscusion via Argumentation Schemes.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "PubMedQA"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "Online Joint Fine-tuning of Multi-Agent Flows": {
        "filename": "Online Joint Fine-tuning of Multi-Agent Flows.pdf",
        "analysis": {
            "benchmarks": [
                "Musique"
            ],
            "base_models": [
                "mistralai/Mistral-7B-Instruct-v0.2",
                "meta-llama/Meta-Llama-3-8B-Instruct",
                "Qwen/Qwen1.5-32B-Chat",
                "microsoft/Phi-3-medium-128k-instruct"
            ]
        }
    },
    "MIND Math Informed syNthetic Dialogues for Pretraining LLMs": {
        "filename": "MIND Math Informed syNthetic Dialogues for Pretraining LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "GSM 8K",
                "MATH",
                "MMLU",
                "MMLU-STEM",
                "GENERAL REASONING"
            ],
            "base_models": [
                "LLAMA3-70B-INSTRUCT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LIDA A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models": {
        "filename": "LIDA A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "vega datasets repository"
            ],
            "base_models": [
                "OpenAI GPT-3.5-turbo-x"
            ]
        }
    },
    "Towards Dataset-Scale and Feature-Oriented Evaluation of Text Summarization in Large Language Model Prompts": {
        "filename": "Towards Dataset-Scale and Feature-Oriented Evaluation of Text Summarization in Large Language Model Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "news article dataset"
            ],
            "base_models": [
                "GPT (OpenAI)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FakeBench Probing Explainable Fake Image Detection via Large Multimodal Models": {
        "filename": "FakeBench Probing Explainable Fake Image Detection via Large Multimodal Models.pdf",
        "analysis": {
            "benchmarks": [
                "FakeBench"
            ],
            "base_models": [
                "GPT-4V",
                "InstructBLIP (7B)",
                "Claude3 Haiku",
                "IDEFICS-Instruct (7B)",
                "Claude3 Sonnet",
                "InternLM-XC.2-vl (7B)",
                "LLaVA-v1.5 (7B)",
                "Q-Instruct (7B)",
                "Qwen-VL (7B)",
                "mPLUG-Owl2 (7B)",
                "Visual-GLM (6B)",
                "GeminiPro",
                "Kosmos-2 (1B)",
                "Otter (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception": {
        "filename": "Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception.pdf",
        "analysis": {
            "benchmarks": [
                "DimEval",
                "Q-MWP",
                "N-MWP"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "InstructGPT (175B)",
                "PaLM-2 (540B)",
                "LLaMa-2 (70B)",
                "LLaMa-2 (13B)",
                "OpenChat (13B)",
                "Flan-T5 (11B)",
                "T0++ (11B)",
                "ChatGLM-2 (6B)",
                "DimPerc (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retaining Key Information under High Compression Ratios Query-Guided Compressor for LLMs": {
        "filename": "Retaining Key Information under High Compression Ratios Query-Guided Compressor for LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "NaturalQuestions",
                "TriviaQA",
                "HotpotQA"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2-7B",
                "LongChat-13B-16K"
            ]
        }
    },
    "Large Language Model Cascades with Mixture of Thoughts Representations for Cost-efficient Reasoning": {
        "filename": "Large Language Model Cascades with Mixture of Thoughts Representations for Cost-efficient Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "ASDIV",
                "TabMWP",
                "BIG-Bench Hard (DATE, Navigate)",
                "CREPE"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FERMAT An Alternative to Accuracy for Numerical Reasoning": {
        "filename": "FERMAT An Alternative to Accuracy for Numerical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "FERMAT",
                "GSM8K",
                "Illinois",
                "CommonCore"
            ],
            "base_models": [
                "Minerva (540B)",
                "GPT-3 (175B)",
                "PaLM (540B)",
                "Codex (175B)",
                "T0 (3B)",
                "FLAN-XL (3B)",
                "BHASKARA (2.7B)",
                "FLAN-large (770M)",
                "FLAN-base (220M)",
                "T5-base (220M)",
                "BART-base (140M)",
                "NT5 (3M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Jais and Jais-chat Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models": {
        "filename": "Jais and Jais-chat Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "models": [],
            "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
        }
    },
    "Are Large Language Models Ready for Healthcare A Comparative Study on Clinical Language Understanding": {
        "filename": "Are Large Language Models Ready for Healthcare A Comparative Study on Clinical Language Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "NCBI-Disease",
                "BC5CDR-Chemical",
                "i2b2 2010-Relation",
                "SemEval 2013-DDI",
                "BIOSSES",
                "MedNLI",
                "i2b2 2006-Smoking",
                "bioASQ 10b-Factoid"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Bard"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How well do Large Language Models perform in Arithmetic tasks": {
        "filename": "How well do Large Language Models perform in Arithmetic tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MATH 401"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "InstructGPT (175B)",
                "Galactica (120B)",
                "LLaMA (65B)",
                "OPT (175B)",
                "GPT-Neox (20B)",
                "GLM (130B)",
                "BloomZ (176B)",
                "Bloom (176B)",
                "T0++ (11B)",
                "Flan-T5 (11B)"
            ]
        }
    },
    "STALL Boosting LLM-based Repository-level Code Completion with Static Analysis": {
        "filename": "STALL Boosting LLM-based Repository-level Code Completion with Static Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "CrossCodeEval"
            ],
            "base_models": [
                "DeepSeek-Coder-6.7B",
                "StarCoderBase-7B",
                "CodeLlama-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The SocialAI School Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents": {
        "filename": "The SocialAI School Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents.pdf",
        "analysis": {
            "benchmarks": [
                "SiQA",
                "ToMi",
                "SocialAI school"
            ],
            "base_models": [
                "GPT (unspecified size)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Transcending Scaling Laws with 01 Extra Compute": {
        "filename": "Transcending Scaling Laws with 01 Extra Compute.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench",
                "GSM8K",
                "MGSM",
                "TydiQA",
                "MMLU",
                "SuperGLUE",
                "TriviaQA",
                "Natural Questions",
                "Lambada",
                "BoolQ",
                "PIQA",
                "HellaSWAG",
                "Winogrande",
                "CommonsenseQA"
            ],
            "base_models": [
                "PaLM-8B",
                "PaLM-62B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AgentVerse Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors": {
        "filename": "AgentVerse Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors.pdf",
        "analysis": {
            "benchmarks": [
                "FED",
                "Commongen Challenge",
                "MGSM",
                "Logic Grid Puzzles",
                "Humaneval"
            ],
            "base_models": [
                "GPT-3.5-Turbo-0613",
                "GPT-4-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Toward Adaptive Reasoning in Large Language Models with Thought Rollback": {
        "filename": "Toward Adaptive Reasoning in Large Language Models with Thought Rollback.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "SVAMP",
                "AQUA-RAT",
                "TheoremQA",
                "MMLU",
                "Game of 24"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Llama2-13b",
                "Llama2-70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GlitchBench Can Large Multimodal Models Detect Video Game Glitches": {
        "filename": "GlitchBench Can Large Multimodal Models Detect Video Game Glitches.pdf",
        "analysis": {
            "benchmarks": [
                "Glitch Bench"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA-1.5 (7B and 13B)",
                "SPHINX (7B and 13B)",
                "InstructBLIP (7B and 13B)",
                "Qwen-VL-Chat (10B)",
                "MiniGPT-v2 (7B)",
                "OtterHD",
                "Fuyo (8B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Auto-Regressive Next-Token Predictors are Universal Learners": {
        "filename": "Auto-Regressive Next-Token Predictors are Universal Learners.pdf",
        "analysis": {
            "benchmarks": [
                "TinyStories"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "LaMDA",
                "Goat (7B-parameter transformer)",
                "MLP (775M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Requirements are All You Need From Requirements to Code with LLMs": {
        "filename": "Requirements are All You Need From Requirements to Code with LLMs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "Prompt Risk Control A Rigorous Framework for Responsible Deployment of Large Language Models": {
        "filename": "Prompt Risk Control A Rigorous Framework for Responsible Deployment of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MBPP code generation dataset",
                "Anthropic Helpfulness and Harmlessness (HH) dataset",
                "MeQSum dataset"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "Claude",
                "CodeLlama-7b",
                "Flan-T5-XXL (11.3B)",
                "Falcon Instruct (40B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chat-Edit-3D Interactive 3D Scene Editing via Text Prompts": {
        "filename": "Chat-Edit-3D Interactive 3D Scene Editing via Text Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "LLFF",
                "TanksAndTemples",
                "IBRNet-collect",
                "CE3D-collect"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "TensoRF",
                "Gaussian-Splatting"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Parameter-Efficient Tuning Helps Language Model Alignment": {
        "filename": "Parameter-Efficient Tuning Helps Language Model Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "Anthropic/HH-RLHF",
                "OpenAI/Summary"
            ],
            "base_models": [
                "GPT-Neo 1.3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation": {
        "filename": "Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation.pdf",
        "analysis": {
            "benchmarks": [
                "WebQuestions",
                "PathQuestions",
                "GrailQA"
            ],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Look Before You Leap Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models": {
        "filename": "Look Before You Leap Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "SingleEq",
                "SVAMP",
                "AQuA",
                "GSMIC-1k"
            ],
            "base_models": [
                "GPT-3.5",
                "ChatGPT (gpt-3.5-turbo-0125)",
                "LLama2-7B",
                "LLama2-13B",
                "Mistral-7B",
                "Mistral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Emerging Synergies in Causality and Deep Generative Models A Survey": {
        "filename": "Emerging Synergies in Causality and Deep Generative Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "CelebA",
                "MNIST",
                "ImageNet",
                "Adult",
                "Census",
                "Cabs",
                "Loan",
                "News",
                "Kings",
                "Credit",
                "Pendulum",
                "ObjectNet",
                "ImageNet-C",
                "ImageNet-V2",
                "FFHQ",
                "Morpho-MNIST",
                "brain MRI scans",
                "Chest X-ray",
                "YELP",
                "BIOS corpus",
                "BraTS",
                "Tubingen cause-effect",
                "EEG",
                "Sachs",
                "cancer genome",
                "IHDP",
                "Jobs",
                "Twins",
                "TCGA",
                "MIMIC III",
                "PACS",
                "OfficeHome",
                "e-CARE",
                "COPA",
                "EventStoryLine",
                "Causal-TimeBank",
                "MAVEN-ERE",
                "Asia",
                "CHILD",
                "Insurance",
                "corr2cause",
                "cladder"
            ],
            "base_models": [
                "GPT (size not specified)",
                "LLaMA (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "UFO A UI-Focused Agent for Windows OS Interaction": {
        "filename": "UFO A UI-Focused Agent for Windows OS Interaction.pdf",
        "analysis": {
            "benchmarks": [
                "WindowsBench"
            ],
            "base_models": [
                "GPT-Vision"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reflection of Thought Inversely Eliciting Numerical Reasoning in Language Models via Solving Linear Systems": {
        "filename": "Reflection of Thought Inversely Eliciting Numerical Reasoning in Language Models via Solving Linear Systems.pdf",
        "analysis": {
            "benchmarks": [
                "DROP",
                "AddSub",
                "MultiArith"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "T5 (350M)",
                "BART (350M)"
            ]
        }
    },
    "LLMatDesign Autonomous Materials Discovery with Large Language Models": {
        "filename": "LLMatDesign Autonomous Materials Discovery with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Materials Project"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini-1.0-pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGPT Exhibits Gender and Racial Biases in Acute Coronary Syndrome Management": {
        "filename": "ChatGPT Exhibits Gender and Racial Biases in Acute Coronary Syndrome Management.pdf",
        "analysis": {
            "benchmarks": [
                "Custom ACS case prompts"
            ],
            "base_models": [
                "ChatGPT-3.5"
            ]
        }
    },
    "LASER Script Execution by Autonomous Agents for On-demand Traffic Simulation": {
        "filename": "LASER Script Execution by Autonomous Agents for On-demand Traffic Simulation.pdf",
        "analysis": {
            "benchmarks": [
                "CARLA simulator"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Large Language Model based Multi-Agents A Survey of Progress and Challenges": {
        "filename": "Large Language Model based Multi-Agents A Survey of Progress and Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "SoftwareDev",
                "RoCoBench",
                "Communicative Watch-And-Help (C-WAH)",
                "ThreeDWorld Multi-Agent Transport (TDW-MAT)",
                "HM3D v0.2",
                "MMLU",
                "MedQA",
                "PubMedQA",
                "GSM8K",
                "StrategyQA",
                "Chess Move Validity",
                "SOTOPIA",
                "Gender Discrimination",
                "Nuclear Energy",
                "Werewolf",
                "Avalon",
                "Welfare Diplomacy",
                "Layout in the Overcooked-AI environment",
                "Chameleon",
                "Undercover",
                "Ultimatum Game TE",
                "Garden Path TE",
                "Wisdom of Crowds TE",
                "MovieLens-1M",
                "Amazon review dataset",
                "Board Connectivity Evaluation"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Controllable Navigation Instruction Generation with Chain of Thought Prompting": {
        "filename": "Controllable Navigation Instruction Generation with Chain of Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "R2R",
                "REVERIE",
                "RxR",
                "UrbanWalk"
            ],
            "base_models": [
                "LLaMA-Adapter (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SynArtifact Classifying and Alleviating Artifacts in Synthetic Images via Vision-Language Model": {
        "filename": "SynArtifact Classifying and Alleviating Artifacts in Synthetic Images via Vision-Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "SynArtifact-1K"
            ],
            "base_models": [
                "LLaVA-v1.5-7B"
            ]
        }
    },
    "Causal Interventions on Causal Paths Mapping GPT-2s Reasoning From Syntax to Semantics": {
        "filename": "Causal Interventions on Causal Paths Mapping GPT-2s Reasoning From Syntax to Semantics.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic dataset of causal sentences"
            ],
            "base_models": [
                "GPT-2 small (12-layer)"
            ]
        }
    },
    "Mind Your Step by Step Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse": {
        "filename": "Mind Your Step by Step Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse.pdf",
        "analysis": {
            "benchmarks": [
                "SNLI",
                "MNLI",
                "Synthetic LLM-generated dataset"
            ],
            "base_models": [
                "OpenAI o1-preview",
                "GPT-4o",
                "Claude 3.5 Sonnet",
                "Claude 3 Opus",
                "Gemini 1.5 Pro",
                "Llama 3.1 70B Instruct",
                "InternVL2 26B",
                "InternVL2 Llama3 76B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Qwen Technical Report": {
        "filename": "Qwen Technical Report.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "HumanEvalPack",
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "QWEN-7B",
                "QWEN-14B",
                "QWEN-1.8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ASSISTGUI Task-Oriented Desktop Graphical User Interface Automation": {
        "filename": "ASSISTGUI Task-Oriented Desktop Graphical User Interface Automation.pdf",
        "analysis": {
            "benchmarks": [
                "ASSIST GUI"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models": {
        "filename": "Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 31,549 tweets related to the 2022 Russian invasion of Ukraine, the 2021 US Capitol insurrection, and the COVID-19 pandemic"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BioPlanner Automatic Evaluation of LLMs on Protocol Planning in Biology": {
        "filename": "BioPlanner Automatic Evaluation of LLMs on Protocol Planning in Biology.pdf",
        "analysis": {
            "benchmarks": [
                "BIOPROT"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoStudio Crafting Consistent Subjects in Multi-turn Interactive Image Generation": {
        "filename": "AutoStudio Crafting Consistent Subjects in Multi-turn Interactive Image Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CMIGBench"
            ],
            "base_models": [
                "Stable Diffusion",
                "Parallel-UNet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Clover Closed-Loop Verifiable Code Generation": {
        "filename": "Clover Closed-Loop Verifiable Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CloverBench",
                "MBPP-DFY-50"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Large Language Models on Spatial Tasks A Multi-Task Benchmarking Study": {
        "filename": "Evaluating Large Language Models on Spatial Tasks A Multi-Task Benchmarking Study.pdf",
        "analysis": {
            "benchmarks": [
                "custom multi-task spatial evaluation dataset"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4o",
                "gpt-4-turbo-2024-04-09",
                "claude-3-sonnet-20240229",
                "moonshot-v1-8k",
                "glm-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SEAL SEmantic-Augmented Imitation Learning via Language Model": {
        "filename": "SEAL SEmantic-Augmented Imitation Learning via Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "KeyDoor",
                "Grid-World"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reward-RAG Enhancing RAG with Reward Driven Supervision": {
        "filename": "Reward-RAG Enhancing RAG with Reward Driven Supervision.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions (NQ)",
                "TriviaQA",
                "FEVER",
                "PubMedQA",
                "BioASQ",
                "MMLU-med",
                "MedMCQA",
                "MedQA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Llama-3.1-8B-Instruct",
                "E5-large-unsupervised"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EvoPrompting Language Models for Code-Level Neural Architecture Search": {
        "filename": "EvoPrompting Language Models for Code-Level Neural Architecture Search.pdf",
        "analysis": {
            "benchmarks": [
                "MNIST-1D",
                "CLRS Algorithmic Reasoning Benchmark"
            ],
            "base_models": [
                "PaLM (62B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Harms from Increasingly Agentic Algorithmic Systems": {
        "filename": "Harms from Increasingly Agentic Algorithmic Systems.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can 3D Vision-Language Models Truly Understand Natural Language": {
        "filename": "Can 3D Vision-Language Models Truly Understand Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "ScanRefer",
                "NR3D",
                "ScanQA",
                "3D Language Robustness Dataset (3D-LR)"
            ],
            "base_models": [
                "BERT",
                "3D-LLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Length Generalization in Arithmetic Transformers": {
        "filename": "Length Generalization in Arithmetic Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset for arithmetic tasks (5-digit numbers for training, up to 20-digit for addition and 35-digit for multiplication)"
            ],
            "base_models": [
                "BERT (Base: 6 layers, 512 dimensions, 8 attention heads)",
                "BERT (Large: 10 layers, 1024 dimensions, 16 attention heads)",
                "ALBERT (Base: 6 layers, 512 dimensions, 8 attention heads)",
                "ALBERT (Large: 10 layers, 1024 dimensions, 16 attention heads)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models as Zero-Shot Conversational Recommenders": {
        "filename": "Large Language Models as Zero-Shot Conversational Recommenders.pdf",
        "analysis": {
            "benchmarks": [
                "ReDIAL",
                "INSPIRED",
                "Reddit-Movie"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "BAIZE (based on LLAMA-13B)",
                "Vicuna (based on LLAMA-13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Open-Ended Visual Recognition with Large Language Model": {
        "filename": "Towards Open-Ended Visual Recognition with Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "COCO panoptic segmentation",
                "ADE20K panoptic segmentation",
                "Cityscapes panoptic segmentation",
                "LVIS instance segmentation",
                "ADE-847 semantic segmentation",
                "PC-459 semantic segmentation"
            ],
            "base_models": [
                "CLIP",
                "InstructBLIP (uses EV A-ViT-g/224 as vision encoder, Vicuna-7B as LLM)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models": {
        "filename": "A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PET",
                "DECON",
                "ATDP"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4-2024-04-09",
                "GPT-4-0125-preview",
                "GPT-3.5-0125",
                "Claude 3 Opus",
                "Claude 3 Sonnet",
                "Llama 3 70B Instruct",
                "Qwen1.5 72B Chat"
            ]
        }
    },
    "Autoregressive Large Language Models are Computationally Universal": {
        "filename": "Autoregressive Large Language Models are Computationally Universal.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "gemini-1.5-pro-001"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models": {
        "filename": "Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Eedi's content repository"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT (gpt-3.5-turbo-1106)",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reinforcing Language Agents via Policy Optimization with Action Decomposition": {
        "filename": "Reinforcing Language Agents via Policy Optimization with Action Decomposition.pdf",
        "analysis": {
            "benchmarks": [
                "Overcooked",
                "VirtualHome",
                "DataSciCoding"
            ],
            "base_models": [
                "LLaMA2-7B",
                "CodeLLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "IrokoBench A New Benchmark for African Languages in the Age of Large Language Models": {
        "filename": "IrokoBench A New Benchmark for African Languages in the Age of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "IrokoBench",
                "AfriXNLI",
                "AfriMGSM",
                "AfriMMLU"
            ],
            "base_models": [
                "Aya-101 (13B)",
                "Flan-T5-XXL (11B)",
                "mT0-XXL-MT (13B)",
                "BLOOMZ 7B (7B)",
                "Gemma 7B (7B)",
                "LLaMa 2 7B (7B)",
                "LLaMa 3 8B (8B)",
                "LLaMa 3 70B (70B)",
                "Command R (35B)",
                "Command R+ (104B)",
                "Claude OPUS (UNK)",
                "GPT-3.5 Turbo (UNK)",
                "GPT-4-Turbo (UNK)",
                "GPT-4o (UNK)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EMPOWER Embodied Multi-role Open-vocabulary Planning with Online Grounding and Execution": {
        "filename": "EMPOWER Embodied Multi-role Open-vocabulary Planning with Online Grounding and Execution.pdf",
        "analysis": {
            "benchmarks": [
                "six different real-life scenarios using a TIAGo robot"
            ],
            "base_models": [
                "GPT-4V",
                "GPT-4"
            ]
        }
    },
    "Emotional Theory of Mind Bridging Fast Visual Processing with Slow Linguistic Reasoning": {
        "filename": "Emotional Theory of Mind Bridging Fast Visual Processing with Slow Linguistic Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "EMOTIC"
            ],
            "base_models": [
                "CLIP",
                "GPT-4",
                "LLaVA",
                "GPT-Vision"
            ]
        }
    },
    "Can Small Language Models be Good Reasoners for Sequential Recommendation": {
        "filename": "Can Small Language Models be Good Reasoners for Sequential Recommendation.pdf",
        "analysis": {
            "benchmarks": [
                "Amazon Review - Video Games",
                "Amazon Review - Grocery and Gourmet Food",
                "Amazon Review - Home and Kitchen"
            ],
            "base_models": [
                "LLaMA2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting in the Wild An Empirical Study of Prompt Evolution in Software Repositories": {
        "filename": "Prompting in the Wild An Empirical Study of Prompt Evolution in Software Repositories.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on LLM-generated Text Detection Necessity Methods and Future Directions": {
        "filename": "A Survey on LLM-generated Text Detection Necessity Methods and Future Directions.pdf",
        "analysis": {
            "benchmarks": [
                "TuringBench",
                "MGTBench"
            ],
            "base_models": [
                "GPT-3.5",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AnnoLLM Making Large Language Models to Be Better Crowdsourced Annotators": {
        "filename": "AnnoLLM Making Large Language Models to Be Better Crowdsourced Annotators.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "WiC",
                "QK"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)",
                "ChatGPT (GPT-3.5-turbo)",
                "PaLM 540B",
                "T5 11B",
                "ST-MoE 32B",
                "LLaMA 65B",
                "Gopher 280B",
                "Chinchilla 70B",
                "GPT-3 175B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Generative Pre-trained Transformers GPT Pass Assessments in Higher Education Programming Courses": {
        "filename": "Can Generative Pre-trained Transformers GPT Pass Assessments in Higher Education Programming Courses.pdf",
        "analysis": {
            "benchmarks": [
                "Statutory Interpretation Data Set"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Language Models Can Reduce Asymmetry in Information Markets": {
        "filename": "Language Models Can Reduce Asymmetry in Information Markets.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 725 research papers on LLMs sourced from ArXiv"
            ],
            "base_models": [
                "Llama 2 (70B)",
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Small Language Models Learn Enhanced Reasoning Skills from Medical Textbooks": {
        "filename": "Small Language Models Learn Enhanced Reasoning Skills from Medical Textbooks.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "USMLE sample test",
                "Medbullets-4",
                "Medbullets-5",
                "MedMCQA",
                "MMLU-Medical",
                "NEJM Case Challenges",
                "K-QA"
            ],
            "base_models": [
                "Mistral-7B",
                "LLaMA-3-8B",
                "LLaMA-3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion": {
        "filename": "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion.pdf",
        "analysis": {
            "benchmarks": [
                "Binary Successor Task",
                "Tree Traversal Task"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "T5-small",
                "T5-base",
                "CodeT5-small",
                "ByT5-small",
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language to Code Generation in Interactive Data Science Notebooks": {
        "filename": "Natural Language to Code Generation in Interactive Data Science Notebooks.pdf",
        "analysis": {
            "benchmarks": [
                "ARCADE"
            ],
            "base_models": [
                "PACHINCO (62B)",
                "PaLM (62B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Powerful are Decoder-Only Transformer Neural Models": {
        "filename": "How Powerful are Decoder-Only Transformer Neural Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2",
                "GPT-3",
                "GPT-4"
            ]
        }
    },
    "Developing a Llama-Based Chatbot for CICD Question Answering A Case Study at Ericsson": {
        "filename": "Developing a Llama-Based Chatbot for CICD Question Answering A Case Study at Ericsson.pdf",
        "analysis": {
            "benchmarks": [
                "72 CI/CD questions and answers at Ericsson"
            ],
            "base_models": [
                "Llama 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Closed-Loop Long-Horizon Robotic Planning via Equilibrium Sequence Modeling": {
        "filename": "Closed-Loop Long-Horizon Robotic Planning via Equilibrium Sequence Modeling.pdf",
        "analysis": {
            "benchmarks": [
                "VirtualHome-Env"
            ],
            "base_models": [
                "Llama 3 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MindScope Exploring Cognitive Biases in Large Language Models Through Multi-Agent Systems": {
        "filename": "MindScope Exploring Cognitive Biases in Large Language Models Through Multi-Agent Systems.pdf",
        "analysis": {
            "benchmarks": [
                "MindScope"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo-16k",
                "Gemini-Pro",
                "Llama2-7B",
                "Llama2-70B",
                "Vicuna-7B",
                "Vicuna-33B",
                "ChatGLM-6B"
            ]
        }
    },
    "Knowledge Graph Based Agent for Complex Knowledge-Intensive QA in Medicine": {
        "filename": "Knowledge Graph Based Agent for Complex Knowledge-Intensive QA in Medicine.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU-Med",
                "MedQA-US",
                "PubMedQA*",
                "BioASQ-Y/N",
                "MedDDx-Basic",
                "MedDDx-Intermediate",
                "MedDDx-Expert"
            ],
            "base_models": [
                "LLaMA3-8B",
                "LLaMA3.1-8B",
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rephrase Augment Reason Visual Grounding of Questions for Vision-Language Models": {
        "filename": "Rephrase Augment Reason Visual Grounding of Questions for Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "VQAv2",
                "A-OKVQA",
                "VizWiz"
            ],
            "base_models": [
                "GPT-4",
                "BLIP-2",
                "Flamingo",
                "MiniGPT-4",
                "LLaVA-1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are Human-generated Demonstrations Necessary for In-context Learning": {
        "filename": "Are Human-generated Demonstrations Necessary for In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "MMLU",
                "HumanEval"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama2 34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "KnowHalu Hallucination Detection via Multi-Form Knowledge Based Factual Checking": {
        "filename": "KnowHalu Hallucination Detection via Multi-Form Knowledge Based Factual Checking.pdf",
        "analysis": {
            "benchmarks": [
                "HaluEval"
            ],
            "base_models": [
                "GPT-4",
                "Starling-7B",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exact Conversion of In-Context Learning to Model Weights in Linearized-Attention Transformers": {
        "filename": "Exact Conversion of In-Context Learning to Model Weights in Linearized-Attention Transformers.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "User-in-the-loop Evaluation of Multimodal LLMs for Activity Assistance": {
        "filename": "User-in-the-loop Evaluation of Multimodal LLMs for Activity Assistance.pdf",
        "analysis": {
            "benchmarks": [
                "Ego4D",
                "CrossTask"
            ],
            "base_models": [
                "Llama2-13B",
                "Llama2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MultiTool-CoT GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting": {
        "filename": "MultiTool-CoT GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "NumGLUE Task 2"
            ],
            "base_models": [
                "GPT-3 (175B)"
            ]
        }
    },
    "Developing an End-to-End Framework for Predicting the Social Communication Severity Scores of Children with Autism Spectrum Disorder": {
        "filename": "Developing an End-to-End Framework for Predicting the Social Communication Severity Scores of Children with Autism Spectrum Disorder.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of speech data from 168 children with ASD and 40 typically developing (TD) children"
            ],
            "base_models": [
                "wav2vec2-xls-r-300m",
                "whisper-large-v2",
                "KR-BERT",
                "KLUE/roberta-base",
                "KR-ELECTRA-Discriminator"
            ]
        }
    },
    "ITCMA A Generative Agent Based on a Computational Consciousness Structure": {
        "filename": "ITCMA A Generative Agent Based on a Computational Consciousness Structure.pdf",
        "analysis": {
            "benchmarks": [
                "Alfworld",
                "Quadruped Robot in the Real World"
            ],
            "base_models": [
                "ChatGLM3-6B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dualformer Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces": {
        "filename": "Dualformer Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces.pdf",
        "analysis": {
            "benchmarks": [
                "Maze navigation",
                "Sokoban",
                "Aug-MATH"
            ],
            "base_models": [
                "Llama-3.1-70B-Instruct",
                "Mistral-7B",
                "Llama-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rethinking STS and NLI in Large Language Models": {
        "filename": "Rethinking STS and NLI in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "STS-B",
                "MNLI",
                "BIOSSES",
                "EBMSASS",
                "MedSTS",
                "N2C2-STS",
                "USTS",
                "ChaosNLI",
                "MedNLI"
            ],
            "base_models": [
                "ChatGPT",
                "Claude",
                "LLaMA-2 (7B, 13B)",
                "BERT-base",
                "RoBERTa-large",
                "GPT-3.5 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Test-Driven Development and LLM-based Code Generation": {
        "filename": "Test-Driven Development and LLM-based Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MBPP",
                "HumanEval",
                "CodeChef"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "Llama 3 70B Instruct"
            ]
        }
    },
    "GuardAgent Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning": {
        "filename": "GuardAgent Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "EICU-AC",
                "Mind2Web-SC"
            ],
            "base_models": [
                "GPT-4",
                "Llama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond A Better Planning with Transformers via Search Dynamics Bootstrapping": {
        "filename": "Beyond A Better Planning with Transformers via Search Dynamics Bootstrapping.pdf",
        "analysis": {
            "benchmarks": [
                "Sokoban puzzles"
            ],
            "base_models": [
                "T5 (with RoPE)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Building a Large Japanese Web Corpus for Large Language Models": {
        "filename": "Building a Large Japanese Web Corpus for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "JCommonsenseQA",
                "JEMHopQA",
                "NIILC",
                "JSQuAD",
                "XL-Sum",
                "MGSM",
                "WMT 2020"
            ],
            "base_models": [
                "Llama 2 7B",
                "Llama 2 13B",
                "Llama 2 70B",
                "Mistral 7B v0.1",
                "Mixtral 8x7B Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering": {
        "filename": "Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "KQA Pro",
                "Musique"
            ],
            "base_models": [
                "BART-base",
                "RoBERTa-large",
                "Longformer-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Steering Language Models With Activation Engineering": {
        "filename": "Steering Language Models With Activation Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "RealToxicityPrompts",
                "Stanford IMDb"
            ],
            "base_models": [
                "LLaMA-3 (8B)",
                "OPT (6.7B)",
                "GPT-2-XL (1.5B)",
                "GPT-J (6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Flextron Many-in-One Flexible Large Language Model": {
        "filename": "Flextron Many-in-One Flexible Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "ARC-easy",
                "LAMBADA",
                "PIQA",
                "WinoGrande",
                "MMLU",
                "HellaSwag"
            ],
            "base_models": [
                "GPT-3 (2B, 8B)",
                "LLaMA-2 (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-eXplainable AI for Medical Image Analysis A Survey and New Outlooks": {
        "filename": "Self-eXplainable AI for Medical Image Analysis A Survey and New Outlooks.pdf",
        "analysis": {
            "benchmarks": [
                "SLAKE",
                "Med-VQA"
            ],
            "base_models": [
                "GPT-3",
                "CLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating LLMs at Detecting Errors in LLM Responses": {
        "filename": "Evaluating LLMs at Detecting Errors in LLM Responses.pdf",
        "analysis": {
            "benchmarks": [
                "ReaLMistake"
            ],
            "base_models": [
                "GPT-4 (0613)",
                "Llama 2 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Personality Alignment of Large Language Models": {
        "filename": "Personality Alignment of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PAPI dataset"
            ],
            "base_models": [
                "Llama-3-8B",
                "Llama-3-70B",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AgentTuning Enabling Generalized Agent Abilities for LLMs": {
        "filename": "AgentTuning Enabling Generalized Agent Abilities for LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "AgentBench",
                "MMLU",
                "GSM8K",
                "HumanEval",
                "MT-Bench"
            ],
            "base_models": [
                "Llama 2 (7B, 13B, 70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evolving Code with A Large Language Model": {
        "filename": "Evolving Code with A Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "APPS",
                "MultiPL-E",
                "GSM8K"
            ],
            "base_models": [
                "GPT-3.5-turbo (unknown size)",
                "Code Llama (various sizes)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ManipLLM Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation": {
        "filename": "ManipLLM Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "PartNet-Mobility dataset"
            ],
            "base_models": [
                "LLaMA-7B"
            ]
        }
    },
    "Leveraging Zero-Shot Prompting for Efficient Language Model Distillation": {
        "filename": "Leveraging Zero-Shot Prompting for Efficient Language Model Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "ANLI1",
                "Commonsense Question-Answering (CQA)"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "T5 (77M, 250M, 800M, 3B)"
            ]
        }
    },
    "A Survey on Hallucination in Large Language Models Principles Taxonomy Challenges and Open Questions": {
        "filename": "A Survey on Hallucination in Large Language Models Principles Taxonomy Challenges and Open Questions.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "HalluQA",
                "HaluEval-2.0",
                "SelfCheckGPT-Wikibio",
                "HaluEval",
                "FELM"
            ],
            "base_models": [
                "LLaMA",
                "Claude",
                "Gemini",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FLamE Few-shot Learning from Natural Language Explanations": {
        "filename": "FLamE Few-shot Learning from Natural Language Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "e-SNLI",
                "e-HANS"
            ],
            "base_models": [
                "GPT-3 Babbage (1.3B)",
                "GPT-3 Davinci (175B)",
                "RoBERTa-Large (355M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Teaching Large Language Models to Self-Debug": {
        "filename": "Teaching Large Language Models to Self-Debug.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "TransCoder",
                "MBPP"
            ],
            "base_models": [
                "code-davinci-002",
                "gpt-3.5-turbo",
                "gpt-4",
                "StarCoder (15.5B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PromptRobust Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts": {
        "filename": "PromptRobust Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "CoLA",
                "QQP",
                "MRPC",
                "MNLI",
                "QNLI",
                "RTE",
                "WNLI",
                "MMLU",
                "SQuAD V2",
                "UN Multi",
                "IWSLT 2017",
                "Mathematics"
            ],
            "base_models": [
                "Flan-T5-large (0.8B)",
                "Dolly-6B",
                "Vicuna-13B",
                "Llama2-13b-chat",
                "Cerebras-GPT-13B",
                "GPT-NEOX-20B",
                "Flan-UL2 (20B)",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Constrained Reasoning Chains for Enhancing Theory-of-Mind in Large Language Models": {
        "filename": "Constrained Reasoning Chains for Enhancing Theory-of-Mind in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BigToM",
                "FANTOM"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "Llama-2 Chat 70B",
                "Mistral Instruct 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Escape Sky-high Cost Early-stopping Self-Consistency for Multi-step Reasoning": {
        "filename": "Escape Sky-high Cost Early-stopping Self-Consistency for Multi-step Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "StrategyQA",
                "CommonsenseQA",
                "Coin Flip",
                "Last Letters"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "LLaMA-2 7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ReCEval Evaluating Reasoning Chains via Correctness and Informativeness": {
        "filename": "ReCEval Evaluating Reasoning Chains via Correctness and Informativeness.pdf",
        "analysis": {
            "benchmarks": [
                "Entailment Bank",
                "GSM-8K",
                "DROP"
            ],
            "base_models": [
                "T5-large",
                "GPT-2 XL (1.5B)",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ReMEmbR Building and Reasoning Over Long-Horizon Spatio-Temporal Memory for Robot Navigation": {
        "filename": "ReMEmbR Building and Reasoning Over Long-Horizon Spatio-Temporal Memory for Robot Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "NaVQA"
            ],
            "base_models": [
                "GPT-4o",
                "Codestral",
                "Command-R",
                "Llama3.1-8b"
            ]
        }
    },
    "Large Language ModelsLLMs on Tabular Data Prediction Generation and Understanding - A Survey": {
        "filename": "Large Language ModelsLLMs on Tabular Data Prediction Generation and Understanding - A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "OpenML",
                "Kaggle API",
                "Combo",
                "UCI ML",
                "DDX"
            ],
            "base_models": [
                "GPT-3",
                "GPT-J",
                "T0",
                "Flan-T5",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Developmental Scaffolding with Large Language Models": {
        "filename": "Developmental Scaffolding with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom tabletop object manipulation environment"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "Enhancing LLMs Cognition via Structurization": {
        "filename": "Enhancing LLMs Cognition via Structurization.pdf",
        "analysis": {
            "benchmarks": [
                "LongBench",
                "AttrScore",
                "FactScore",
                "BEIR"
            ],
            "base_models": [
                "LLaMA2-70B",
                "GPT-3.5-Turbo",
                "StruXGPT-7B (based on LLaMA2-7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Reason and Memorize with Self-Notes": {
        "filename": "Learning to Reason and Memorize with Self-Notes.pdf",
        "analysis": {
            "benchmarks": [
                "Toy-Story",
                "Algorithmic",
                "Boolean Variable",
                "Chess Piecetype",
                "Chess Move",
                "MultiArith",
                "GSM8K"
            ],
            "base_models": [
                "GPT-2 base",
                "GPT-J 6B",
                "GPT-3 175B",
                "Llama 2 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Design and Analysis of LLM-Based Algorithms": {
        "filename": "On the Design and Analysis of LLM-Based Algorithms.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Llama-3-8B",
                "Llama-3-70B",
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Effective Large Language Model Debugging with Best-first Tree Search": {
        "filename": "Effective Large Language Model Debugging with Best-first Tree Search.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "APPS"
            ],
            "base_models": [
                "GPT-4",
                "deepseek-coder-33b-instruct",
                "Meta-Llama-3-70B-Instruct"
            ]
        }
    },
    "Instruction Tuning-free Visual Token Complement for Multimodal LLMs": {
        "filename": "Instruction Tuning-free Visual Token Complement for Multimodal LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "LVLM-eHub",
                "MME",
                "DEMON"
            ],
            "base_models": [
                "BLIP-2",
                "MiniGPT-4",
                "InstructBLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EPA Easy Prompt Augmentation on Large Language Models via Multiple Sources and Multiple Targets": {
        "filename": "EPA Easy Prompt Augmentation on Large Language Models via Multiple Sources and Multiple Targets.pdf",
        "analysis": {
            "benchmarks": [
                "FLORES-200",
                "SAMSum",
                "Quora Question Pairs (QQP)",
                "SNLI",
                "MNLI"
            ],
            "base_models": [
                "GPT-3.5-TURBO"
            ]
        }
    },
    "LLM-Assisted Light Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments": {
        "filename": "LLM-Assisted Light Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments.pdf",
        "analysis": {
            "benchmarks": [
                "Synthetic dataset (3-Way and 4-Way intersections)",
                "Real-world dataset (Chenta Road, Songjiang District, Shanghai)"
            ],
            "base_models": [
                "GPT-4 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "THaMES An End-to-End Tool for Hallucination Mitigation and Evaluation in Large Language Models": {
        "filename": "THaMES An End-to-End Tool for Hallucination Mitigation and Evaluation in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HaluEval",
                "DelucionQA"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o-mini",
                "Llama-3.1-8B-Instruct",
                "Mistral-Nemo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SoK Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency": {
        "filename": "SoK Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "PaLM-540B",
                "BERT",
                "Code LLaMA (34B)",
                "CodeGen (16.1B)",
                "StarCoder (15.5B)",
                "PanGu-Coder (2.6B)",
                "PanGu-Coder2 (15B)",
                "WizardCoder (15B)",
                "Code-Davinci-001 (GPT3, 175B)",
                "Code-Davinci-002 (GPT3.5, 175B)",
                "CodeT5+ (16B)",
                "InstructCodeT5+ (16B)",
                "GPT-4 with Reflexion (1.76T*)",
                "Santa-Coder (1.1B)",
                "AlphaCode (1.1B)",
                "Codex-12B (12B)",
                "code-cushman-001 (12B)",
                "InCoder 6B (6.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OpenBias Open-Set Bias Detection in Text-to-Image Generative Models": {
        "filename": "OpenBias Open-Set Bias Detection in Text-to-Image Generative Models.pdf",
        "analysis": {
            "benchmarks": [
                "Flickr30k",
                "COCO"
            ],
            "base_models": [
                "Stable Diffusion 1.5",
                "Stable Diffusion 2",
                "Stable Diffusion XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Design and Engineering Introduction and Advanced Methods": {
        "filename": "Prompt Design and Engineering Introduction and Advanced Methods.pdf",
        "analysis": {
            "benchmarks": [],
            "models": [],
            "error": "Encountered text corresponding to disallowed special token '<|endofprompt|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endofprompt|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endofprompt|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
        }
    },
    "Self-ICL Zero-Shot In-Context Learning with Self-Generated Demonstrations": {
        "filename": "Self-ICL Zero-Shot In-Context Learning with Self-Generated Demonstrations.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench Hard (BBH)"
            ],
            "base_models": [
                "InstructGPT (text-davinci-003)",
                "PaLM-2 (text-bison-001)",
                "GPT-3.5 (gpt-3.5-turbo-instruct)"
            ]
        }
    },
    "A Review on Generative AI Models for Synthetic Medical Text Time Series and Longitudinal Data": {
        "filename": "A Review on Generative AI Models for Synthetic Medical Text Time Series and Longitudinal Data.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC III",
                "MIMIC IV",
                "eICU",
                "HiRID",
                "Pile",
                "E3C",
                "INPCR",
                "Administrative Health Records",
                "PPMI",
                "NACC",
                "Evotion",
                "SEER",
                "Human Activity Sensing Archive",
                "UCR Time Series Archive",
                "Autonomic Aging",
                "PTB-XL",
                "AF Classification Challenge",
                "UniMiB",
                "PAMAP2",
                "MIT-BIH Arrhythmia",
                "MIT-BIH Normal Sinus Rhythm (NSR)",
                "Sleep-EDF (Expanded)",
                "The National Sleep Research Resource",
                "UCI EEG Dataset",
                "PhysioNet Challenge 2015",
                "PPG-DB",
                "UCI ML Repository",
                "PhysioNet"
            ],
            "base_models": [
                "GPT-3",
                "GPT-2",
                "BERT",
                "Sequence GAN",
                "cGAN",
                "Variational Auto-Encoder (VAE)",
                "Diffusion model"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Representations Can be What Recommenders Need Findings and Potentials": {
        "filename": "Language Representations Can be What Recommenders Need Findings and Potentials.pdf",
        "analysis": {
            "benchmarks": [
                "Movies & TV (Ni et al., 2019)",
                "Video Games",
                "Books"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "Llama2-7B",
                "Mistral-7B",
                "text-embedding-ada-v2",
                "text-embeddings-3-large",
                "SFR-Embedding-Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InstructEval Systematic Evaluation of Instruction Selection Methods": {
        "filename": "InstructEval Systematic Evaluation of Instruction Selection Methods.pdf",
        "analysis": {
            "benchmarks": [
                "AG News",
                "ANLI",
                "BoolQ",
                "IMDB",
                "TweetEval Emotion",
                "CosmosQA",
                "HellaSwag",
                "NQ-Open",
                "TriviaQA"
            ],
            "base_models": [
                "BLOOM (1.1B, 1.7B, 3B, 7.1B)",
                "GPT Neo (1.3B, 2.7B, 20B)",
                "LLaMA (7B, 13B)",
                "OPT (1.3B, 2.7B, 6.7B, 13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An LLM can Fool Itself A Prompt-Based Adversarial Attack": {
        "filename": "An LLM can Fool Itself A Prompt-Based Adversarial Attack.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "AdvGLUE",
                "AdvGLUE++"
            ],
            "base_models": [
                "Llama2-7B",
                "Llama2-13B",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Best in TauLLMJudge Criteria-Based Relevance Evaluation with Llama3": {
        "filename": "Best in TauLLMJudge Criteria-Based Relevance Evaluation with Llama3.pdf",
        "analysis": {
            "benchmarks": [
                "LLMJudge challenge",
                "TREC Deep Learning 2023"
            ],
            "base_models": [
                "Llama-3-8B"
            ]
        }
    },
    "Cultural Evolution of Cooperation among LLM Agents": {
        "filename": "Cultural Evolution of Cooperation among LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Donor Game"
            ],
            "base_models": [
                "Claude 3.5 Sonnet",
                "Gemini 1.5 Flash",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language Deduction with Incomplete Information": {
        "filename": "Natural Language Deduction with Incomplete Information.pdf",
        "analysis": {
            "benchmarks": [
                "EntailmentBank",
                "Everyday Norms: Why Not?"
            ],
            "base_models": [
                "T5 3B",
                "DeBERTa-v3 Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Flow of ReasoningTraining LLMs for Divergent Problem Solving with Minimal Examples": {
        "filename": "Flow of ReasoningTraining LLMs for Divergent Problem Solving with Minimal Examples.pdf",
        "analysis": {
            "benchmarks": [
                "BlocksWorld",
                "Game24",
                "Rubik's Cube",
                "1D-ARC",
                "PrOntoQA"
            ],
            "base_models": [
                "Llama-2-13B",
                "Llama-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Human-centered In-building Embodied Delivery Benchmark": {
        "filename": "Human-centered In-building Embodied Delivery Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "PRS Challenge"
            ],
            "base_models": [
                "GPT-4",
                "GLM-4",
                "GLM-4V"
            ]
        }
    },
    "GameTraversalBenchmark Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps": {
        "filename": "GameTraversalBenchmark Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps.pdf",
        "analysis": {
            "benchmarks": [
                "GameTraversalBenchmark (GTB)"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "GPT-4",
                "GPT-3.5",
                "Claude-3-Opus",
                "Claude-3-Haiku",
                "LLaMa-3-8B",
                "LLaMa-3-70B",
                "Gemma-7B",
                "Mixtral-8x7B",
                "o1"
            ]
        }
    },
    "SADL An Effective In-Context Learning Method for Compositional Visual QA": {
        "filename": "SADL An Effective In-Context Learning Method for Compositional Visual QA.pdf",
        "analysis": {
            "benchmarks": [
                "GQA",
                "GQA-OOD",
                "CLEVR",
                "CRIC"
            ],
            "base_models": [
                "OpenFlamingo"
            ]
        }
    },
    "Language Models Are Greedy Reasoners A Systematic Formal Analysis of Chain-of-Thought": {
        "filename": "Language Models Are Greedy Reasoners A Systematic Formal Analysis of Chain-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "PRONTOQA"
            ],
            "base_models": [
                "INSTRUCT GPT (text-davinci-002)",
                "GPT-3 (text-ada-001, text-babbage-001, text-curie-001, davinci, text-davinci-001)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EPiC Cost-effective Search-based Prompt Engineering of LLMs for Code Generation": {
        "filename": "EPiC Cost-effective Search-based Prompt Engineering of LLMs for Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP"
            ],
            "base_models": [
                "GPT-4o",
                "MagicCoder (6.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CurricuLLM Automatic Task Curricula Design for Learning Complex Robot Skills using Large Language Models": {
        "filename": "CurricuLLM Automatic Task Curricula Design for Learning Complex Robot Skills using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Fetch-Slide",
                "Fetch-Push",
                "AntMaze-UMaze",
                "Berkeley Humanoid"
            ],
            "base_models": [
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Divide and Translate Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning": {
        "filename": "Divide and Translate Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "AR-LSAT",
                "ZebraLogic",
                "Logic grid puzzle",
                "Symbol interpretation",
                "Logical deduction",
                "FOLIO",
                "ProofWriter"
            ],
            "base_models": [
                "gpt-4o",
                "gpt-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reframing Tax Law Entailment as Analogical Reasoning": {
        "filename": "Reframing Tax Law Entailment as Analogical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "SARA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "T5-Large",
                "bert-base-cased"
            ]
        }
    },
    "Managing AI Risks in an Era of Rapid Progress": {
        "filename": "Managing AI Risks in an Era of Rapid Progress.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Controllable Mixed-Initiative Dialogue Generation through Prompting": {
        "filename": "Controllable Mixed-Initiative Dialogue Generation through Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "Emotional Support Conversations (ESC)",
                "PersuasionForGood (P4G)"
            ],
            "base_models": [
                "GPT-3",
                "InstructGPT (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Balanced and Explainable Social Media Analysis for Public Health with Large Language Models": {
        "filename": "Balanced and Explainable Social Media Analysis for Public Health with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SMM4H 2023 Task 1",
                "SMM4H 2023 Task 2",
                "SMM4H 2023 Task 4"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "XLNet",
                "BERTweet",
                "CT-BERT (v2)",
                "GPT-3.5"
            ]
        }
    },
    "UI Layout Generation with LLMs Guided by UI Grammar": {
        "filename": "UI Layout Generation with LLMs Guided by UI Grammar.pdf",
        "analysis": {
            "benchmarks": [
                "CLAY",
                "SCREEN2WORDS"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Wait thats not an option LLMs Robustness with Incorrect Multiple-Choice Options": {
        "filename": "Wait thats not an option LLMs Robustness with Incorrect Multiple-Choice Options.pdf",
        "analysis": {
            "benchmarks": [
                "Basic Arithmetic Dataset (BAD)",
                "MMLU (Massive Multitask Language Understanding)"
            ],
            "base_models": [
                "GPT-4o",
                "o1-mini",
                "Claude 3 Opus",
                "Llama 3.1-8B",
                "Llama 3.1-70B",
                "Llama 3.1-405B",
                "Qwen2.5-7B",
                "Qwen2.5-14B",
                "Qwen2.5-32B",
                "DeepSeekMath-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can ChatGPT Overcome Behavioral Biases in the Financial Sector Classify-and-Rethink Multi-Step Zero-Shot Reasoning in the Gold Investment": {
        "filename": "Can ChatGPT Overcome Behavioral Biases in the Financial Sector Classify-and-Rethink Multi-Step Zero-Shot Reasoning in the Gold Investment.pdf",
        "analysis": {
            "benchmarks": [
                "Shanghai Gold Exchange spot gold index (Au9999.SGE)",
                "Chinese gold news dataset from http://www.dyhjw.com/"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-turbo)"
            ]
        }
    },
    "C3 Zero-shot Text-to-SQL with ChatGPT": {
        "filename": "C3 Zero-shot Text-to-SQL with ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "Spider"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-Turbo-0301)"
            ]
        }
    },
    "Innovations in Neural Data-to-text Generation": {
        "filename": "Innovations in Neural Data-to-text Generation.pdf",
        "analysis": {
            "benchmarks": [
                "RoboCup",
                "WeatherGov",
                "BAGEL",
                "E2E",
                "WebNLG",
                "WikiBio",
                "RotoWire",
                "TabFact",
                "ToTTo",
                "LogicNLG",
                "WikiTableT",
                "AGENDA",
                "Chart-to-text"
            ],
            "base_models": [
                "LSTM",
                "GRU",
                "Transformer",
                "GPT-2",
                "T5",
                "BERT",
                "GPT-3",
                "BART"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hierarchical Continual Reinforcement Learning via Large Language Model": {
        "filename": "Hierarchical Continual Reinforcement Learning via Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "MiniGrid"
            ],
            "base_models": [
                "GPT (OpenAI)"
            ]
        }
    },
    "Chat Bankman-Fried an Exploration of LLM Alignment in Finance": {
        "filename": "Chat Bankman-Fried an Exploration of LLM Alignment in Finance.pdf",
        "analysis": {
            "benchmarks": [
                "Custom simulation environment based on the collapse of the cryptoasset exchange FTX"
            ],
            "base_models": [
                "o1-preview (size unspecified)",
                "o1-mini (size unspecified)",
                "phi-3.5-mini (size unspecified)",
                "llama-3.1-8b (8B)",
                "gpt-4o-mini (size unspecified)",
                "claude-3.5-sonnet (size unspecified)",
                "gpt-4o (size unspecified)",
                "claude-3-haiku (size unspecified)",
                "gpt-4-turbo (size unspecified)",
                "gpt-3.5-turbo (size unspecified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "V-LoL A Diagnostic Dataset for Visual Logical Learning": {
        "filename": "V-LoL A Diagnostic Dataset for Visual Logical Learning.pdf",
        "analysis": {
            "benchmarks": [
                "V-LoL",
                "V-LoL-Trains",
                "V-LoL-Blocks"
            ],
            "base_models": [
                "ResNet18",
                "EfficientNet",
                "Vision Transformer (ViT)",
                "Llama2",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ALI-Agent Assessing LLMs Alignment with Human Values via Agent-based Evaluation": {
        "filename": "ALI-Agent Assessing LLMs Alignment with Human Values via Agent-based Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "CrowS-Pairs",
                "ETHICS",
                "DecodingTrust",
                "Social Chemistry 101",
                "Singapore Rapid Transit Systems Regulations",
                "AdvBench"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Gemini-Pro",
                "ChatGLM3",
                "Vicuna-7B",
                "Vicuna-13B",
                "Vicuna-33B",
                "Llama 2-7B",
                "Llama 2-13B",
                "Llama 2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do As I Can Not As I Say Grounding Language in Robotic Affordances": {
        "filename": "Do As I Can Not As I Say Grounding Language in Robotic Affordances.pdf",
        "analysis": {
            "benchmarks": [
                "real-world robotic tasks in a kitchen environment"
            ],
            "base_models": [
                "PaLM-540B",
                "FLAN-137B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GameVLM A Decision-making Framework for Robotic Task Planning Based on Visual Language Models and Zero-sum Games": {
        "filename": "GameVLM A Decision-making Framework for Robotic Task Planning Based on Visual Language Models and Zero-sum Games.pdf",
        "analysis": {
            "benchmarks": [
                "real-world robotic tasks"
            ],
            "base_models": [
                "GPT-4V",
                "YOLO-World"
            ]
        }
    },
    "Puzzle Distillation-Based NAS for Inference-Optimized LLMs": {
        "filename": "Puzzle Distillation-Based NAS for Inference-Optimized LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Winogrande",
                "ARC Challenge",
                "MMLU",
                "HellaSwag",
                "GSM8K",
                "TruthfulQA",
                "XLSum English",
                "MMLU Chat",
                "GSM8K Chat",
                "Instruct HumanEval",
                "MT-Bench",
                "RULER"
            ],
            "base_models": [
                "Llama-3.1-70B-Instruct",
                "Llama-3.1-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition": {
        "filename": "How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "HumanEval",
                "MT-Bench"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-33B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Far Are We from Intelligent Visual Deductive Reasoning": {
        "filename": "How Far Are We from Intelligent Visual Deductive Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Mensa IQ test",
                "IntelligenceTest",
                "RAVEN"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini-pro",
                "Qwen-VL-Max",
                "LLaVA-1.5-13B",
                "LLaVA-1.6-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Zero Shot Hypothesis Proposers": {
        "filename": "Large Language Models are Zero Shot Hypothesis Proposers.pdf",
        "analysis": {
            "benchmarks": [
                "Unseen dataset (200 pairs from August 2023)",
                "Seen dataset (2700 pairs from before January 2023)"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Llama-2-70b-chat",
                "WizardLM-13B-V1.2",
                "PMC-LLaMA-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoRRPUS Code-based Structured Prompting for Neurosymbolic Story Understanding": {
        "filename": "CoRRPUS Code-based Structured Prompting for Neurosymbolic Story Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "bAbI Task 2",
                "Re3"
            ],
            "base_models": [
                "Codex",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "UFO Unified Fact Obtaining for Commonsense Question Answering": {
        "filename": "UFO Unified Fact Obtaining for Commonsense Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA 2.0",
                "OpenBookQA",
                "QASC",
                "Social IQA"
            ],
            "base_models": [
                "GPT-3 Davinci (175B)",
                "GPT-3 Curie (6.7B)",
                "GPT-Neo (2.7B)",
                "DeBERTa-v3 Large (418M)"
            ]
        }
    },
    "Neuro-Symbolic Causal Reasoning Meets Signaling Game for Emergent Semantic Communications": {
        "filename": "Neuro-Symbolic Causal Reasoning Meets Signaling Game for Emergent Semantic Communications.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Ask Me Anything A simple strategy for prompting language models": {
        "filename": "Ask Me Anything A simple strategy for prompting language models.pdf",
        "analysis": {
            "benchmarks": [
                "SuperGLUE (CB, RTE, WSC)",
                "DBPedia",
                "AGNews",
                "BoolQ",
                "COPA",
                "MultiRC",
                "ReCoRD",
                "WiC",
                "ANLI R1",
                "ANLI R2",
                "ANLI R3",
                "StoryCloze",
                "SST",
                "DROP",
                "NQ",
                "RealTimeQA",
                "WebQs"
            ],
            "base_models": [
                "EleutherAI (125M-175B)",
                "BLOOM",
                "OPT",
                "T0",
                "GPT-J-6B",
                "GPT3-175B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Better Chain-of-Thought Prompting Strategies A Survey": {
        "filename": "Towards Better Chain-of-Thought Prompting Strategies A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "mathematical reasoning",
                "symbolic reasoning",
                "table QA"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM (540B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Camels in a Changing Climate Enhancing LM Adaptation with Tulu 2": {
        "filename": "Camels in a Changing Climate Enhancing LM Adaptation with Tulu 2.pdf",
        "analysis": {
            "benchmarks": [
                "MT-Bench",
                "AlpacaEval"
            ],
            "base_models": [
                "LLAMA-2 (7B, 13B, 70B)",
                "CODE LLAMA (7B, 13B, 34B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting GPT-3 To Be Reliable": {
        "filename": "Prompting GPT-3 To Be Reliable.pdf",
        "analysis": {
            "benchmarks": [
                "MRQA",
                "AdvGLUE",
                "Contrast Sets",
                "HANS",
                "PAWS",
                "WinoBias",
                "BBQ",
                "NQ",
                "TriviaQA",
                "HotpotQA",
                "SQuAD"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "Code-Davinci-002 (also known as Codex or GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot": {
        "filename": "Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot.pdf",
        "analysis": {
            "benchmarks": [
                "Schema-Guided Dialogue (SGD)",
                "MultiWOZ2.0",
                "MultiWOZ2.4"
            ],
            "base_models": [
                "LLaMA-8B",
                "GPT-3.5",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers": {
        "filename": "A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT-4",
                "Cohere",
                "Copilot",
                "Llama 2 70B",
                "Mistral 7B",
                "Gemini",
                "ChatGPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning with Language Model Prompting A Survey": {
        "filename": "Reasoning with Language Model Prompting A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "CommonsenseQA"
            ],
            "base_models": [
                "GPT-3 175B",
                "Codex",
                "LaMDA-68B",
                "LaMDA-137B",
                "PaLM-62B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RoboVQA Multimodal Long-Horizon Reasoning for Robotics": {
        "filename": "RoboVQA Multimodal Long-Horizon Reasoning for Robotics.pdf",
        "analysis": {
            "benchmarks": [
                "RoboVQA dataset",
                "long-horizon planning benchmark"
            ],
            "base_models": [
                "RoboVQA-VideoCoCa (383M)",
                "PaLM-E-562B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-augmented Preference Learning from Natural Language": {
        "filename": "LLM-augmented Preference Learning from Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "Compsent-19",
                "College Confidential"
            ],
            "base_models": [
                "LLaMa-2-13B",
                "LLaMa-2-70B (4-bit quantized)",
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval Head Mechanistically Explains Long-Context Factuality": {
        "filename": "Retrieval Head Mechanistically Explains Long-Context Factuality.pdf",
        "analysis": {
            "benchmarks": [
                "Needle-in-a-Haystack"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "Mistral-7B-v0.2",
                "Mixtral-8x7B-v0.1",
                "Yi-6B",
                "Yi-34B",
                "Qwen1.5-14B"
            ]
        }
    },
    "Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers": {
        "filename": "Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "ReClor",
                "Commonsense QA",
                "ARC",
                "PIQA",
                "HellaSwag",
                "Abductive NLI",
                "HotpotQA",
                "WikiHop",
                "MuTual",
                "DREAM",
                "RACE"
            ],
            "base_models": [
                "T5-base"
            ]
        }
    },
    "AgentAvatar Disentangling Planning Driving and Rendering for Photorealistic Avatar Agents": {
        "filename": "AgentAvatar Disentangling Planning Driving and Rendering for Photorealistic Avatar Agents.pdf",
        "analysis": {
            "benchmarks": [
                "DailyDialogue",
                "EnvPersona"
            ],
            "base_models": [
                "Llama 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Power of Adaptation Boosting In-Context Learning through Adaptive Prompting": {
        "filename": "The Power of Adaptation Boosting In-Context Learning through Adaptive Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "AQuA",
                "StrategyQA",
                "CSQA",
                "Letter Concat"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4o Mini",
                "LLaMA3-8B"
            ]
        }
    },
    "UniBias Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation": {
        "filename": "UniBias Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "SST2",
                "AGnews",
                "MNLI",
                "WiC",
                "COPA",
                "CR",
                "AGNews",
                "MR",
                "RTE",
                "SST-5",
                "TREC",
                "ARC",
                "MMLU"
            ],
            "base_models": [
                "Llama-2 7B",
                "Llama-2 13B",
                "GPT-J",
                "GPT2-XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generate Transform Answer Question Specific Tool Synthesis for Tabular Data": {
        "filename": "Generate Transform Answer Question Specific Tool Synthesis for Tabular Data.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTableQuestions",
                "WikiSQL",
                "WikiTableQuestions-Filter"
            ],
            "base_models": [
                "T5",
                "PaLM",
                "GPT-3",
                "BART",
                "TapEx (based on BART)",
                "Omnitab (based on TapEx)",
                "UnifiedSKG (based on T5)",
                "FlanT5",
                "GPT-3"
            ]
        }
    },
    "Empowering Time Series Analysis with Large Language Models A Survey": {
        "filename": "Empowering Time Series Analysis with Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC III",
                "NYU Langone EHR database"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "LLaMA-2",
                "BERT",
                "ClinicalBERT",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Simplifying Multimodality Unimodal Approach to Multimodal Challenges in Radiology with General-Domain Large Language Model": {
        "filename": "Simplifying Multimodality Unimodal Approach to Multimodal Challenges in Radiology with General-Domain Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-CXR"
            ],
            "base_models": [
                "Flan-T5-xl (3B)"
            ]
        }
    },
    "Attention Is All You Need for LLM-based Code Vulnerability Localization": {
        "filename": "Attention Is All You Need for LLM-based Code Vulnerability Localization.pdf",
        "analysis": {
            "benchmarks": [
                "Big-Vul",
                "CVEFixes-C"
            ],
            "base_models": [
                "GPT",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SAM-E Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation": {
        "filename": "SAM-E Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "RLBench"
            ],
            "base_models": [
                "Segment Anything Model (SAM)",
                "R3M",
                "CLIP",
                "DINO"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Foundation Models Help Us Achieve Perfect Secrecy": {
        "filename": "Can Foundation Models Help Us Achieve Perfect Secrecy.pdf",
        "analysis": {
            "benchmarks": [
                "Sentiment140",
                "20News",
                "CelebA",
                "CIFAR10",
                "Federated EMNIST",
                "Reddit",
                "MRQA"
            ],
            "base_models": [
                "T0 (3B and 11B parameters)",
                "GPT-3 (125M, 1.3B, 2.7B, 6.7B, and 175B parameters)",
                "MPNet-base (110M parameters)",
                "CLIP (150M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RVISA Reasoning and Verification for Implicit Sentiment Analysis": {
        "filename": "RVISA Reasoning and Verification for Implicit Sentiment Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval-2014 Restaurant",
                "SemEval-2014 Laptop"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Vicuna-13B",
                "Flan-T5-XXL (13B)",
                "Flan-T5-Large",
                "Flan-T5-Base (250M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "World Models for Math Story Problems": {
        "filename": "World Models for Math Story Problems.pdf",
        "analysis": {
            "benchmarks": [
                "MAWPS",
                "ASD IV-A",
                "SVAMP"
            ],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Pre-trained Language Models Can be Fully Zero-Shot Learners": {
        "filename": "Pre-trained Language Models Can be Fully Zero-Shot Learners.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "AG News",
                "DBPedia",
                "IMDB",
                "Amazon",
                "CommonsenseQA"
            ],
            "base_models": [
                "BERT (base and large)",
                "RoBERTa (base and large)",
                "GPT-3",
                "ChatGPT",
                "T5-base",
                "GPT2-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DrLLM Prompt-Enhanced Distributed Denial-of-Service Resistance Method with Large Language Models": {
        "filename": "DrLLM Prompt-Enhanced Distributed Denial-of-Service Resistance Method with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CICD-DoS2019"
            ],
            "base_models": [
                "GPT-4o-mini",
                "Llama3-70b",
                "Deepseek-chat-v2",
                "Qwen2-57b-a14b-instruct"
            ]
        }
    },
    "AGI for Agriculture": {
        "filename": "AGI for Agriculture.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VELOCITI Can Video-Language Models Bind Semantic Concepts through Time": {
        "filename": "VELOCITI Can Video-Language Models Bind Semantic Concepts through Time.pdf",
        "analysis": {
            "benchmarks": [
                "VidSitu",
                "VELOCITI"
            ],
            "base_models": [
                "CLIP",
                "EV A-CLIP",
                "SigLIP",
                "NegCLIP",
                "CLIP-ViP",
                "ViFi-CLIP",
                "mPLUG-Owl-Video",
                "PLLaV A",
                "Video-LLaV A",
                "Owl-Con",
                "Gemini 1.5 Flash"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Parsel Algorithmic Reasoning with Language Models by Composing Decompositions": {
        "filename": "Parsel Algorithmic Reasoning with Language Models by Composing Decompositions.pdf",
        "analysis": {
            "benchmarks": [
                "APPS",
                "HumanEval",
                "VirtualHome"
            ],
            "base_models": [
                "AlphaCode",
                "Codex",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DRESS  Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback": {
        "filename": "DRESS  Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "LLaVA-Eval",
                "LLaVA-Bench",
                "VLSafe"
            ],
            "base_models": [
                "EVA-CLIP-Giant (1.3B)",
                "Vicuna-13b-v1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence": {
        "filename": "Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence.pdf",
        "analysis": {
            "benchmarks": [
                "CORTEX BENCH"
            ],
            "base_models": [
                "ViT-B (86M parameters)",
                "ViT-L (307M parameters)",
                "CLIP (ViT-B)",
                "R3M (ResNet-50)",
                "MVP (ViT-B and ViT-L)",
                "VIP (ResNet-50)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reprompting Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling": {
        "filename": "Reprompting Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling.pdf",
        "analysis": {
            "benchmarks": [
                "Big-Bench Hard (BBH)",
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "InstructGPT (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Thought Unfaithfulness as Disguised Accuracy": {
        "filename": "Chain-of-Thought Unfaithfulness as Disguised Accuracy.pdf",
        "analysis": {
            "benchmarks": [
                "AQuA-RAT",
                "ARC-Challenge",
                "ARC-Easy",
                "HellaSwag",
                "LogiQA",
                "MMLU",
                "OpenBookQA",
                "TruthfulQA",
                "Addition Task (custom dataset)"
            ],
            "base_models": [
                "Llama 2 (7B, 13B, 70B)",
                "FLAN-T5 (77M, 248M, 783M, 2.85B, 11.3B, 20B)",
                "FLAN-UL2",
                "Pythia DPO (70M, 160M, 410M, 1B, 1.4B, 2.8B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Internet-augmented language models through few-shot prompting for open-domain question answering": {
        "filename": "Internet-augmented language models through few-shot prompting for open-domain question answering.pdf",
        "analysis": {
            "benchmarks": [
                "NQ",
                "HOTPOT QA",
                "STRATEGY QA",
                "FEVER"
            ],
            "base_models": [
                "Gopher-280B",
                "Gopher-7B",
                "Gopher-1B",
                "Gopher-400M",
                "Gopher-117M",
                "Gopher-44M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Generic LLMs Help Analyze Child-adult Interactions Involving Children with Autism in Clinical Observation": {
        "filename": "Can Generic LLMs Help Analyze Child-adult Interactions Involving Children with Autism in Clinical Observation.pdf",
        "analysis": {
            "benchmarks": [
                "Remote-NLS",
                "ADOSMod3"
            ],
            "base_models": [
                "Mistral-7B V0.2 Instruction",
                "LLaMa 2-7B Chat",
                "LLaMa 2-13B Chat",
                "LLaMa 3-8B Instruct",
                "Qwen1.5-7B Chat",
                "Qwen1.5-14B Chat"
            ]
        }
    },
    "SciInstruct a Self-Reflective Instruction Annotated Dataset for Training Scientific Language Models": {
        "filename": "SciInstruct a Self-Reflective Instruction Annotated Dataset for Training Scientific Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CEval-Sci",
                "SciEval",
                "SciBench",
                "MATH",
                "SAT-Math"
            ],
            "base_models": [
                "ChatGLM3 (6B and 32B)",
                "Llama3-8B-Instruct",
                "Mistral-7B: MetaMath"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Promptify Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models": {
        "filename": "Promptify Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Automatic1111"
            ],
            "base_models": [
                "GPT-3.5",
                "Stable Diffusion"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering": {
        "filename": "Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "MSQA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Privacy in Large Language Models Attacks Defenses and Future Directions": {
        "filename": "Privacy in Large Language Models Attacks Defenses and Future Directions.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Claude 2",
                "Llama 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CLEVA Chinese Language Models EVAluation Platform": {
        "filename": "CLEVA Chinese Language Models EVAluation Platform.pdf",
        "analysis": {
            "benchmarks": [
                "C-Eval",
                "M3KE",
                "CMMLU",
                "GAOKAO-Bench",
                "MMCU",
                "OpenCompass",
                "FlagEval"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "BLOOMZ-176B-mt",
                "GLM-130B",
                "LLaMA-65B",
                "BLOOMZ-mt-7B",
                "BLOOM-7B1",
                "BLOOM-176B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Q How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks A Self-Train on Unlabeled Images": {
        "filename": "Q How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks A Self-Train on Unlabeled Images.pdf",
        "analysis": {
            "benchmarks": [
                "VQAv2",
                "A-OKVQA",
                "ArtVQA",
                "PathVQA",
                "RSVQA"
            ],
            "base_models": [
                "BLIP (ViT-B/16)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OSCAR Operating System Control via State-Aware Reasoning and Re-Planning": {
        "filename": "OSCAR Operating System Control via State-Aware Reasoning and Re-Planning.pdf",
        "analysis": {
            "benchmarks": [
                "GAIA",
                "OSWorld",
                "AndroidWorld"
            ],
            "base_models": [
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VSP Assessing the dual challenges of perception and reasoning in spatial planning tasks for VLMs": {
        "filename": "VSP Assessing the dual challenges of perception and reasoning in spatial planning tasks for VLMs.pdf",
        "analysis": {
            "benchmarks": [
                "VSP"
            ],
            "base_models": [
                "Gemini-1.0-Pro-Vision",
                "GPT-4 Turbo with vision",
                "Claude-3",
                "GPT-4o",
                "LLaVA-V1.6-VICUNA-7B",
                "InternLM-XComposer2-7b",
                "InternLM-XComposer2-vl-7b",
                "InstructBLIP",
                "SPHINX-v2-1k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DiLu A Knowledge-Driven Approach to Autonomous Driving with Large Language Models": {
        "filename": "DiLu A Knowledge-Driven Approach to Autonomous Driving with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Highway-env",
                "CitySim"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Factuality and Reasoning in Language Models through Multiagent Debate": {
        "filename": "Improving Factuality and Reasoning in Language Models through Multiagent Debate.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MMLU",
                "Chess Move Validity",
                "Biographies"
            ],
            "base_models": [
                "chatGPT",
                "Bard"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent": {
        "filename": "Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4o-mini",
                "Llama3.1-8B",
                "Llama3.1-70B"
            ]
        }
    },
    "Can Large Language Models Provide Security  Privacy Advice Measuring the Ability of LLMs to Refute Misconceptions": {
        "filename": "Can Large Language Models Provide Security  Privacy Advice Measuring the Ability of LLMs to Refute Misconceptions.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 122 S&P misconceptions"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "Bard (based on Google's LaMDA)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Progressive-Hint Prompting Improves Reasoning in Large Language Models": {
        "filename": "Progressive-Hint Prompting Improves Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SVAMP",
                "GSM8K",
                "AQuA",
                "MATH",
                "AddSub",
                "MultiArith",
                "SingleEQ"
            ],
            "base_models": [
                "text-davinci-002",
                "text-davinci-003",
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TrustGPT A Benchmark for Trustworthy and Responsible Large Language Models": {
        "filename": "TrustGPT A Benchmark for Trustworthy and Responsible Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SOCIAL CHEMISTRY 101"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "LLaMA (13B)",
                "Vicuna (13B)",
                "FastChat (13B)",
                "ChatGLM (6B)",
                "Oasst (12B)",
                "Alpaca (13B)",
                "Koala (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Capture the Flag Uncovering Data Insights with Large Language Models": {
        "filename": "Capture the Flag Uncovering Data Insights with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Adidas Sales Dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "How Does In-Context Learning Help Prompt Tuning": {
        "filename": "How Does In-Context Learning Help Prompt Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "ToTTo",
                "DART",
                "Logic2Text",
                "Spider",
                "MTOP"
            ],
            "base_models": [
                "BLOOM-1.1B",
                "OPT-1.3B",
                "GPT-2-XL-1.5B"
            ]
        }
    },
    "MedGPTEval A Dataset and Benchmark to Evaluate Responses of Large Language Models in Medicine": {
        "filename": "MedGPTEval A Dataset and Benchmark to Evaluate Responses of Large Language Models in Medicine.pdf",
        "analysis": {
            "benchmarks": [
                "27 medical dialogues",
                "7 case reports"
            ],
            "base_models": [
                "ChatGPT",
                "ERNIE Bot",
                "Doctor PuJiang (Dr. PJ)"
            ]
        }
    },
    "Be My Donor Transfer the NLP Datasets Between the Languages Using LLM": {
        "filename": "Be My Donor Transfer the NLP Datasets Between the Languages Using LLM.pdf",
        "analysis": {
            "benchmarks": [
                "DEFT corpus"
            ],
            "base_models": [
                "ChatGPT-3.5-turbo",
                "Llama-3.1-8B",
                "BERT-base-multilingual",
                "RuBERT-base-cased",
                "RoBerta-base"
            ]
        }
    },
    "Large Language Models are Diverse Role-Players for Summarization Evaluation": {
        "filename": "Large Language Models are Diverse Role-Players for Summarization Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "CNN2022",
                "BBC2022",
                "SummEval"
            ],
            "base_models": [
                "GPT-3 (175B)"
            ]
        }
    },
    "FINCH Prompt-guided Key-Value Cache Compression for Large Language Models": {
        "filename": "FINCH Prompt-guided Key-Value Cache Compression for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD v2",
                "LongBench"
            ],
            "base_models": [
                "Llama 2 7B-chat",
                "Mistral 7B-Instruct-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can AI with High Reasoning Ability Replicate Human-like Decision Making in Economic Experiments": {
        "filename": "Can AI with High Reasoning Ability Replicate Human-like Decision Making in Economic Experiments.pdf",
        "analysis": {
            "benchmarks": [
                "MobLab dataset (Lin et al. 2020)"
            ],
            "base_models": [
                "gpt-3.5-turbo-0613",
                "gpt-4-1106-preview"
            ]
        }
    },
    "POEM Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models": {
        "filename": "POEM Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CMU-MOSEI",
                "WTaG"
            ],
            "base_models": [
                "LLaVA (13B)",
                "GPT-4V(ision)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mixture-of-Experts Meets Instruction Tuning A Winning Combination for Large Language Models": {
        "filename": "Mixture-of-Experts Meets Instruction Tuning A Winning Combination for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BBH",
                "Reasoning",
                "QA"
            ],
            "base_models": [
                "FLAN-MOE32B",
                "FLAN-PALM 62B",
                "FLAN-T5 (various sizes)",
                "PaLM (various sizes)",
                "Switch Transformer (various sizes)",
                "GShard (various sizes)",
                "ST-MoE 32B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Multitask Multilingual Multimodal Evaluation of ChatGPT on Reasoning Hallucination and Interactivity": {
        "filename": "A Multitask Multilingual Multimodal Evaluation of ChatGPT on Reasoning Hallucination and Interactivity.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/DM",
                "SAMSum",
                "FLoRes-200",
                "NusaX",
                "bAbI task",
                "EntailmentBank",
                "CLUTRR",
                "StepGame",
                "Pep-3k",
                "COVID-Social",
                "COVID-Scientific",
                "MultiWOZ2.2",
                "OpenDialKG",
                "CommonsenseQA",
                "PIQA",
                "TruthfulQA",
                "SpartQA",
                "Timedial",
                "Math"
            ],
            "base_models": [
                "ChatGPT (based on InstructGPT)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InfoCon Concept Discovery with Generative and Discriminative Informativeness": {
        "filename": "InfoCon Concept Discovery with Generative and Discriminative Informativeness.pdf",
        "analysis": {
            "benchmarks": [
                "ManiSkill2"
            ],
            "base_models": [
                "VQ-VAE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Pose Priors from Language Models": {
        "filename": "Pose Priors from Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Hi4D",
                "Flickr Close Interactions 3D (FlickrCI3D)",
                "CHI3D",
                "MOYO"
            ],
            "base_models": [
                "GPT-4 Vision (GPT4-V)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Calibrating Reasoning in Language Models with Internal Consistency": {
        "filename": "Calibrating Reasoning in Language Models with Internal Consistency.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "CoinFlip",
                "PrOntoQA",
                "ProofWriter"
            ],
            "base_models": [
                "Llama-2-7B",
                "Llama-2-13B",
                "Mistral-7B",
                "Mixtral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Revisiting Relation Extraction in the era of Large Language Models": {
        "filename": "Revisiting Relation Extraction in the era of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ADE",
                "CoNLL",
                "NYT",
                "DocRED"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "Flan-T5 large (760M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Wisdom of Hindsight Makes Language Models Better Instruction Followers": {
        "filename": "The Wisdom of Hindsight Makes Language Models Better Instruction Followers.pdf",
        "analysis": {
            "benchmarks": [
                "BigBench"
            ],
            "base_models": [
                "FLAN-T5-Large",
                "FLAN-T5-Base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Object Hallucination in Large Vision-Language Models": {
        "filename": "Evaluating Object Hallucination in Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MSCOCO"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-7B",
                "LLaMA-13B",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Multilingual Information Retrieval in Mixed Human Resources Environments A RAG Model Implementation for Multicultural Enterprise": {
        "filename": "Enhancing Multilingual Information Retrieval in Mixed Human Resources Environments A RAG Model Implementation for Multicultural Enterprise.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 200 documents including HR SOPs and QA documents"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-4",
                "LLaMA2",
                "LAMBADA",
                "PALM"
            ]
        }
    },
    "Auctions with LLM Summaries": {
        "filename": "Auctions with LLM Summaries.pdf",
        "analysis": {
            "benchmarks": [
                "Synthetic dataset for ad summarization"
            ],
            "base_models": [
                "Gemini 1.0 Pro"
            ]
        }
    },
    "AgentStore Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant": {
        "filename": "AgentStore Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant.pdf",
        "analysis": {
            "benchmarks": [
                "OSWorld",
                "APPAgent"
            ],
            "base_models": [
                "GPT-4o",
                "InternVL2-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DisasterQA A Benchmark for Assessing the performance of LLMs in Disaster Response": {
        "filename": "DisasterQA A Benchmark for Assessing the performance of LLMs in Disaster Response.pdf",
        "analysis": {
            "benchmarks": [
                "DisasterQA"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4 Turbo",
                "GPT-4o",
                "Llama 3.1-8B Instruct",
                "Gemini 1.5 Flash"
            ]
        }
    },
    "LLM as BT-Planner Leveraging LLMs for Behavior Tree Generation in Robot Task Planning": {
        "filename": "LLM as BT-Planner Leveraging LLMs for Behavior Tree Generation in Robot Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "Siemens Robot Assembly Challenge",
                "Furniture Assembly Benchmark"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Mistral-7B",
                "Llama2-13B-chat"
            ]
        }
    },
    "ChatGPT4PCG 2 Competition Prompt Engineering for Science Birds Level Generation": {
        "filename": "ChatGPT4PCG 2 Competition Prompt Engineering for Science Birds Level Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Science Birds dataset (custom)"
            ],
            "base_models": [
                "gpt-3.5-turbo-0125"
            ]
        }
    },
    "Adapting LLM Agents with Universal Feedback in Communication": {
        "filename": "Adapting LLM Agents with Universal Feedback in Communication.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "HotpotQA",
                "Chameleon",
                "GSM8k"
            ],
            "base_models": [
                "Llama-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lifelong Robot Learning with Human Assisted Language Planners": {
        "filename": "Lifelong Robot Learning with Human Assisted Language Planners.pdf",
        "analysis": {
            "benchmarks": [
                "Real-world tasks on Franka Panda robot",
                "Simulation tasks in PyBullet"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLMs Replace Manual Annotation of Software Engineering Artifacts": {
        "filename": "Can LLMs Replace Manual Annotation of Software Engineering Artifacts.pdf",
        "analysis": {
            "benchmarks": [
                "Code Summarization (from LeClair et al.)",
                "Name-Value Inconsistencies (from Patra and Pradel)",
                "Causality (from Fischbach et al.)",
                "Semantic Similarity (from Kamp et al.)",
                "Static Analysis Warning (from Kang et al.)"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3.5-Sonnet",
                "Gemini-1.5-Pro",
                "GPT-3.5",
                "Llama3 (70B)",
                "Mixtral (8x22B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When Brain-inspired AI Meets AGI": {
        "filename": "When Brain-inspired AI Meets AGI.pdf",
        "analysis": {
            "benchmarks": [
                "VQA dataset"
            ],
            "base_models": [
                "BERT",
                "GPT-2",
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment": {
        "filename": "Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaFarm",
                "Anthropic's hh-rlhf"
            ],
            "base_models": [
                "Mistral-7B",
                "Dolly-v2-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SuperCorrect Supervising and Correcting Language Models with Error-Driven Insights": {
        "filename": "SuperCorrect Supervising and Correcting Language Models with Error-Driven Insights.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K"
            ],
            "base_models": [
                "GPT-4",
                "PaLM",
                "LLaMA",
                "Llama-3-8B",
                "DeepSeekMath-Base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathDial A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems": {
        "filename": "MathDial A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems.pdf",
        "analysis": {
            "benchmarks": [
                "MATHDIAL"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT (gpt-3.5-turbo)",
                "InstructGPT (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CyberPalAI Empowering LLMs with Expert-Driven Cybersecurity Instructions": {
        "filename": "CyberPalAI Empowering LLMs with Expert-Driven Cybersecurity Instructions.pdf",
        "analysis": {
            "benchmarks": [
                "SecKnowledge-Eval",
                "CyberBench"
            ],
            "base_models": [
                "Llama-3 instruct 8B",
                "Mistral instruct 7B v0.3",
                "Phi-3-medium-4k-instruct (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large AI Models in Health Informatics Applications Challenges and the Future": {
        "filename": "Large AI Models in Health Informatics Applications Challenges and the Future.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "CASP14"
            ],
            "base_models": [
                "GPT-4",
                "LLaMa (65B)",
                "PaLM (540B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "APIGen Generative API Method Recommendation": {
        "filename": "APIGen Generative API Method Recommendation.pdf",
        "analysis": {
            "benchmarks": [
                "APIBENCH-Q",
                "BIKER-Dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dont Add dont Miss Effective Content Preserving Generation from Pre-Selected Text Spans": {
        "filename": "Dont Add dont Miss Effective Content Preserving Generation from Pre-Selected Text Spans.pdf",
        "analysis": {
            "benchmarks": [
                "DUC summarization dataset"
            ],
            "base_models": [
                "Flan-T5 large",
                "Longformer Encoder-Decoder large (LED large)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "STREET A Multi-Task Structured Reasoning and Explanation Benchmark": {
        "filename": "STREET A Multi-Task Structured Reasoning and Explanation Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "STREET",
                "GSM8K",
                "AR-LSAT"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "T5 (770M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "D3 Data Diversity Design for Systematic Generalization in Visual Question Answering": {
        "filename": "D3 Data Diversity Design for Systematic Generalization in Visual Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "CLEVR",
                "TallyQA",
                "GQA"
            ],
            "base_models": [
                "MAC",
                "FiLM",
                "VectorNMN",
                "VectorNMN GT",
                "GPT-2",
                "MiniGPT-v2 (Llama-2 Chat 7b)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Are Latent Variable Models Explaining and Finding Good Demonstrations for In-Context Learning": {
        "filename": "Large Language Models Are Latent Variable Models Explaining and Finding Good Demonstrations for In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SST2",
                "FPB",
                "COLA",
                "DBpedia",
                "EmoC",
                "ETHOS-SO",
                "ETHOS-R"
            ],
            "base_models": [
                "GPT2-large",
                "GPT3 (various sizes)",
                "GPT-J (6B)",
                "OPT (6-7B)",
                "LLaMA (6-7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EchoAtt Attend Copy then Adjust for More Efficient Large Language Models": {
        "filename": "EchoAtt Attend Copy then Adjust for More Efficient Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "IMDB",
                "mmlu",
                "winogrande",
                "swag",
                "hellaswag",
                "xnli_en",
                "agieval_en",
                "TruthfulQA_mc1",
                "TruthfulQA_mc2"
            ],
            "base_models": [
                "TinyLLaMA-1.1B",
                "Pythia-1B",
                "LLaMA1-7B",
                "LLaMA2-7B",
                "LLaMA2-7B Chat",
                "LLaMA2-13B",
                "LLaMA-160m"
            ]
        }
    },
    "Arithmetic Control of LLMs for Diverse User Preferences Directional Preference Alignment with Multi-Objective Rewards": {
        "filename": "Arithmetic Control of LLMs for Diverse User Preferences Directional Preference Alignment with Multi-Objective Rewards.pdf",
        "analysis": {
            "benchmarks": [
                "UltraFeedback"
            ],
            "base_models": [
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language models in molecular discovery": {
        "filename": "Language models in molecular discovery.pdf",
        "analysis": {
            "benchmarks": [
                "MoleculeNet"
            ],
            "base_models": [
                "GPT (size not specified)",
                "BERT (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms": {
        "filename": "Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms.pdf",
        "analysis": {
            "benchmarks": [
                "Traveling Salesman Problem (TSP)",
                "Bin-Packing Problem"
            ],
            "base_models": [
                "GPT-4",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Autonomous Agents Adaptive-planning Reasoning and Acting in Language Models": {
        "filename": "Towards Autonomous Agents Adaptive-planning Reasoning and Acting in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld"
            ],
            "base_models": [
                "gemma-2-9b-it",
                "PaLM-540B",
                "GPT-3 text-davinci-002"
            ]
        }
    },
    "CoPa General Robotic Manipulation through Spatial Constraints of Parts with Foundation Models": {
        "filename": "CoPa General Robotic Manipulation through Spatial Constraints of Parts with Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "Real-world manipulation tasks"
            ],
            "base_models": [
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT-Driver Learning to Drive with GPT": {
        "filename": "GPT-Driver Learning to Drive with GPT.pdf",
        "analysis": {
            "benchmarks": [
                "nuScenes"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "Towards Better Few-Shot and Finetuning Performance with Forgetful Causal Language Models": {
        "filename": "Towards Better Few-Shot and Finetuning Performance with Forgetful Causal Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SuperGLUE",
                "LAMBADA",
                "StoryCloze",
                "PIQA",
                "ARC-e",
                "ARC-c",
                "OpenBookQA",
                "Winograd",
                "WinoGrande",
                "Adversarial NLI (ANIL)"
            ],
            "base_models": [
                "PaLM (1B, 8B)",
                "GPT-3 (13B, 175B)",
                "T5-XXL (11B)",
                "UL2 (20B)",
                "ST-MoE (269B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BWArea Model Learning World Model Inverse Dynamics and Policy for Controllable Language Generation": {
        "filename": "BWArea Model Learning World Model Inverse Dynamics and Policy for Controllable Language Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "DROP",
                "BBH",
                "TruthfulQA",
                "TextWorld",
                "BigBench Hard"
            ],
            "base_models": [
                "Tinyllama (1.1B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Simple synthetic data reduces sycophancy in large language models": {
        "filename": "Simple synthetic data reduces sycophancy in large language models.pdf",
        "analysis": {
            "benchmarks": [
                "NLP survey questions",
                "philosophy survey questions",
                "political typology quiz questions",
                "simple addition statements"
            ],
            "base_models": [
                "PaLM-8B",
                "PaLM-62B",
                "PaLM-540B",
                "Flan-PaLM-8B",
                "Flan-PaLM-62B",
                "Flan-PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InfiMM-Eval Complex Open-Ended Reasoning Evaluation For Multi-Modal Large Language Models": {
        "filename": "InfiMM-Eval Complex Open-Ended Reasoning Evaluation For Multi-Modal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "InfiMM-Eval",
                "MM-Vet"
            ],
            "base_models": [
                "Flamingo",
                "Palm-e",
                "RT-2",
                "GPT-4V(ision)",
                "MiniGPT-4",
                "LLaVA",
                "IDEFICS"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Efficient Inference for Large Language Models": {
        "filename": "A Survey on Efficient Inference for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-1",
                "GPT-2",
                "GPT-3",
                "OPT",
                "LLaMA",
                "LLaMA 2",
                "Baichuan 2",
                "Vicuna",
                "LongChat",
                "BLOOM",
                "FALCON",
                "GLM",
                "Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Transformers Learn to Solve Problems Recursively": {
        "filename": "Can Transformers Learn to Solve Problems Recursively.pdf",
        "analysis": {
            "benchmarks": [
                "Binary Successor Function",
                "Tree Traversal"
            ],
            "base_models": [
                "Transformer (small, unspecified size)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large language models encode clinical knowledge": {
        "filename": "Large language models encode clinical knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA (USMLE)",
                "MedMCQA",
                "PubMedQA",
                "MMLU clinical topics",
                "LiveQA",
                "MedicationQA",
                "HealthSearchQA"
            ],
            "base_models": [
                "PaLM (540B)",
                "Flan-PaLM (540B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GeoReasoner Geo-localization with Reasoning in Street Views using a Large Vision-Language Model": {
        "filename": "GeoReasoner Geo-localization with Reasoning in Street Views using a Large Vision-Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of 70K high-locatability GSV images",
                "10K Flickr images"
            ],
            "base_models": [
                "Qwen-VL (Qwen-7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Agent-Oriented Planning in Multi-Agent Systems": {
        "filename": "Agent-Oriented Planning in Multi-Agent Systems.pdf",
        "analysis": {
            "benchmarks": [
                "numerical reasoning dataset (Kim et al., 2024)"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Explaining Competitive-Level Programming Solutions using LLMs": {
        "filename": "Explaining Competitive-Level Programming Solutions using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "CodeContests"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HandsOnVLM Vision-Language Models for Hand-Object Interaction Prediction": {
        "filename": "HandsOnVLM Vision-Language Models for Hand-Object Interaction Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "Epic-Kitchen-55",
                "Epic-Kitchen-100",
                "H2O",
                "FPHA",
                "Ego4D"
            ],
            "base_models": [
                "CLIP-L-14",
                "Vicuna (7B and 13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Thought Flow Nets From Single Predictions to Trains of Model Thought": {
        "filename": "Thought Flow Nets From Single Predictions to Trains of Model Thought.pdf",
        "analysis": {
            "benchmarks": [
                "HOTPOT QA"
            ],
            "base_models": [
                "Longformer-large (435M parameters)"
            ]
        }
    },
    "What does it take to catch a Chinchilla Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring": {
        "filename": "What does it take to catch a Chinchilla Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fact-checking based fake news detection a review": {
        "filename": "Fact-checking based fake news detection a review.pdf",
        "analysis": {
            "benchmarks": [
                "FEVER",
                "HOVER",
                "TabFact",
                "InfoTabs",
                "FEVEROUS",
                "FACTIFY-5WQA",
                "FactKG",
                "PolitiFact",
                "LIAR",
                "Verify",
                "MultiFC",
                "Snopes",
                "RAWFC",
                "LIAR-RAW",
                "X-Fact",
                "MOCHEG",
                "CHEF",
                "MR2",
                "FAVIQ",
                "COVIDLies",
                "COVID-Fact",
                "Check-COVID",
                "NewsCLIPings"
            ],
            "base_models": [
                "DistilBERT",
                "T5",
                "GPT"
            ]
        }
    },
    "Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification": {
        "filename": "Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification.pdf",
        "analysis": {
            "benchmarks": [
                "Health Advice",
                "Causal Relation"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo (20B)",
                "GPT-Davinci-003 (175B)",
                "BioBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VisionGPT Vision-Language Understanding Agent Using Generalized Multimodal Framework": {
        "filename": "VisionGPT Vision-Language Understanding Agent Using Generalized Multimodal Framework.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "LLaMA-2"
            ]
        }
    },
    "Using LLMs in Software Requirements Specifications An Empirical Evaluation": {
        "filename": "Using LLMs in Software Requirements Specifications An Empirical Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "university club management system SRS"
            ],
            "base_models": [
                "GPT-4",
                "CodeLlama-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy": {
        "filename": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy.pdf",
        "analysis": {
            "benchmarks": [
                "NASA Astrophysics Data System (custom dataset of 1000 papers)"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors": {
        "filename": "Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors.pdf",
        "analysis": {
            "benchmarks": [
                "GameBugDescriptions"
            ],
            "base_models": [
                "InstructGPT (ada, babbage, curie, davinci)",
                "OPT (66B, 175B)"
            ]
        }
    },
    "Large Knowledge Model Perspectives and Challenges": {
        "filename": "Large Knowledge Model Perspectives and Challenges.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Orchestrating Bimanual Robots": {
        "filename": "Large Language Models for Orchestrating Bimanual Robots.pdf",
        "analysis": {
            "benchmarks": [
                "ServeWater",
                "ServeFruit"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "OpenMathInstruct-1 A 18 Million Math Instruction Tuning Dataset": {
        "filename": "OpenMathInstruct-1 A 18 Million Math Instruction Tuning Dataset.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "Mixtral 8x7B",
                "Mistral-7B",
                "Llama 2",
                "CodeLlama-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RestGPT Connecting Large Language Models with Real-World RESTful APIs": {
        "filename": "RestGPT Connecting Large Language Models with Real-World RESTful APIs.pdf",
        "analysis": {
            "benchmarks": [
                "RestBench"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)",
                "ChatGPT (gpt-3.5-turbo-0301)",
                "Llama2-13B",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Math Problem Solving in Large Language Models Through Categorization and Strategy Tailoring": {
        "filename": "Improving Math Problem Solving in Large Language Models Through Categorization and Strategy Tailoring.pdf",
        "analysis": {
            "benchmarks": [
                "AIME 2015",
                "custom dataset of 25 AIME-like problems"
            ],
            "base_models": [
                "Deepseek-Math"
            ]
        }
    },
    "Locking Down the Finetuned LLMs Safety": {
        "filename": "Locking Down the Finetuned LLMs Safety.pdf",
        "analysis": {
            "benchmarks": [
                "HEx-PHI",
                "AdvBench"
            ],
            "base_models": [
                "Llama-3-8B Instruct",
                "Llama-3-70B Instruct",
                "Mistral-Large-2 123B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Making the Most of ChatGPT for Machine Translation": {
        "filename": "Towards Making the Most of ChatGPT for Machine Translation.pdf",
        "analysis": {
            "benchmarks": [
                "Flores-200",
                "WMT19 News",
                "WMT19 Bio",
                "WMT22 E-Commerce"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0301)"
            ]
        }
    },
    "Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving": {
        "filename": "Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving.pdf",
        "analysis": {
            "benchmarks": [
                "CARLA"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Large Language Models are Fixated by Red Herrings Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset": {
        "filename": "Large Language Models are Fixated by Red Herrings Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset.pdf",
        "analysis": {
            "benchmarks": [
                "Only Connect Wall (OCW) dataset",
                "OCW-Randomized",
                "OCW-WordNet"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "BERT BASE (110M)",
                "BERT LARGE (340M)",
                "RoBERTa LARGE (355M)",
                "DistilBERT BASE (66M)",
                "ELMo LARGE (94M)",
                "all-mpnet BASE (110M)",
                "E5 BASE (110M)",
                "E5 LARGE (340M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Zero-shot Temporal Relation Extraction with ChatGPT": {
        "filename": "Zero-shot Temporal Relation Extraction with ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "TB-Dense",
                "MATRES",
                "TDDMan"
            ],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "Hippocrates An Open-Source Framework for Advancing Large Language Models in Healthcare": {
        "filename": "Hippocrates An Open-Source Framework for Advancing Large Language Models in Healthcare.pdf",
        "analysis": {
            "benchmarks": [
                "MedMCQA",
                "PubMedQA",
                "MedQA",
                "USMLE-step1",
                "USMLE-step2",
                "USMLE-step3"
            ],
            "base_models": [
                "LLaMA2 7B",
                "Mistral 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on the Honesty of Large Language Models": {
        "filename": "A Survey on the Honesty of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "HotpotQA",
                "TriviaQA",
                "SelfAware",
                "KUQ",
                "UnknownBench",
                "HoneSet",
                "BeHonest"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MultiTalk Introspective and Extrospective Dialogue for Human-Environment-LLM Alignment": {
        "filename": "MultiTalk Introspective and Extrospective Dialogue for Human-Environment-LLM Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "YCB dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training": {
        "filename": "Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "A-OKVQA"
            ],
            "base_models": [
                "UnifiedQA Base (223M)",
                "UnifiedQA Large (738M)",
                "FLAN-T5 Base (248M)",
                "FLAN-T5 Large (783M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RoT Enhancing Large Language Models with Reflection on Search Trees": {
        "filename": "RoT Enhancing Large Language Models with Reflection on Search Trees.pdf",
        "analysis": {
            "benchmarks": [
                "Blocksworld",
                "GSM8k",
                "CraigslistBargain"
            ],
            "base_models": [
                "phi-2 (2.7B)",
                "mistral-7b (7B)",
                "mixtral-8x7b (8x7B)",
                "chatgpt",
                "gpt-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Regulatable AI Systems Technical Gaps and Policy Opportunities": {
        "filename": "Towards Regulatable AI Systems Technical Gaps and Policy Opportunities.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rethinking ChatGPTs Success Usability and Cognitive Behaviors Enabled by Auto-regressive LLMs Prompting": {
        "filename": "Rethinking ChatGPTs Success Usability and Cognitive Behaviors Enabled by Auto-regressive LLMs Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE"
            ],
            "base_models": [
                "GPT series",
                "BERT"
            ]
        }
    },
    "Exploring and Benchmarking the Planning Capabilities of Large Language Models": {
        "filename": "Exploring and Benchmarking the Planning Capabilities of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BlocksWorld",
                "Logistics",
                "Mini-Grid",
                "Trip Planning",
                "Calendar Scheduling"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "Gemini 1.5 Pro",
                "Gemini 1.5 Flash",
                "Gemma 2 27b",
                "Gemini 1.0 S"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Large Language Models for Student-Code Guided Test Case Generation in Computer Science Education": {
        "filename": "Using Large Language Models for Student-Code Guided Test Case Generation in Computer Science Education.pdf",
        "analysis": {
            "benchmarks": [
                "CSEDM Challenge dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Transcrib3D 3D Referring Expression Resolution through Large Language Models": {
        "filename": "Transcrib3D 3D Referring Expression Resolution through Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ReferIt3D",
                "ScanRefer"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Speech Translation with Large Language Models An Industrial Practice": {
        "filename": "Speech Translation with Large Language Models An Industrial Practice.pdf",
        "analysis": {
            "benchmarks": [
                "GigaST",
                "MuST-C v2",
                "CoVoST2",
                "LibriSpeech"
            ],
            "base_models": [
                "Whisper-Large-V2",
                "GPT-3 13B"
            ]
        }
    },
    "TorchOpera A Compound AI System for LLM Safety": {
        "filename": "TorchOpera A Compound AI System for LLM Safety.pdf",
        "analysis": {
            "benchmarks": [
                "Jigsaw Unintended-Bias Data",
                "Hotpot QA",
                "Truthful QA"
            ],
            "base_models": [
                "Llama2-7B",
                "BERT",
                "RoBERTa",
                "Custom base model (1.6B parameters)"
            ]
        }
    },
    "Can LLMs Solve longer Math Word Problems Better": {
        "filename": "Can LLMs Solve longer Math Word Problems Better.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "E-GSM",
                "MAWPS",
                "SVAMP",
                "GSM-IC"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "LLaMA-2-70B",
                "Mistral-7B",
                "WizardMath-70B",
                "MAmmoTH-70B",
                "MetaMath-70B",
                "Claude-3-opus",
                "Gemini-pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Cannot Explain Themselves": {
        "filename": "Large Language Models Cannot Explain Themselves.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Frontier AI Regulation Managing Emerging Risks to Public Safety": {
        "filename": "Frontier AI Regulation Managing Emerging Risks to Public Safety.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Repairing the Cracked Foundation A Survey of Obstacles in Evaluation Practices for Generated Text": {
        "filename": "Repairing the Cracked Foundation A Survey of Obstacles in Evaluation Practices for Generated Text.pdf",
        "analysis": {
            "benchmarks": [
                "CNN-DailyMail (CNNDM)",
                "XSum"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Collecting Qualitative Data at Scale with Large Language Models A Case Study": {
        "filename": "Collecting Qualitative Data at Scale with Large Language Models A Case Study.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-based LLMs (OpenAI)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Psychometric Alignment Capturing Human Knowledge Distributions via Language Models": {
        "filename": "Psychometric Alignment Capturing Human Knowledge Distributions via Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WORDBANK",
                "DUOLINGO",
                "EEDI"
            ],
            "base_models": [
                "Mistral-7b",
                "Llama-8b",
                "Llama-70b",
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "MemeCap A Dataset for Captioning and Interpreting Memes": {
        "filename": "MemeCap A Dataset for Captioning and Interpreting Memes.pdf",
        "analysis": {
            "benchmarks": [
                "MEMECAP"
            ],
            "base_models": [
                "OpenFlamingo-9B (LLaMA 7B and CLIP ViT/L-14)",
                "MiniGPT4 (Vicuna based on LLaMA-13B and BLIP-2)",
                "LLaMA-7B"
            ]
        }
    },
    "A Stitch in Time Saves Nine Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation": {
        "filename": "A Stitch in Time Saves Nine Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation.pdf",
        "analysis": {
            "benchmarks": [
                "article generation task",
                "multi-hop questions",
                "false premise questions"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LANCAR Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments": {
        "filename": "LANCAR Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments.pdf",
        "analysis": {
            "benchmarks": [
                "spot-mini-mini robot simulator v.2.1.0"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "ViEva LLM A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations": {
        "filename": "ViEva LLM A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations.pdf",
        "analysis": {
            "benchmarks": [
                "NvBench"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Llama2-70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatMOF An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks": {
        "filename": "ChatMOF An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks.pdf",
        "analysis": {
            "benchmarks": [
                "CoREMOF",
                "QMOF",
                "MOF key",
                "DigiMOF"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "MOFTransformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ReConcile Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs": {
        "filename": "ReConcile Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "CommonsenseQA",
                "GSM8K",
                "AQuA",
                "MATH",
                "Date Understanding",
                "ANLI"
            ],
            "base_models": [
                "ChatGPT",
                "Bard",
                "Claude2",
                "GPT-4",
                "LLaMA-2-70B",
                "DeepSeekMath"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ProcBench Benchmark for Multi-Step Reasoning and Following Procedure": {
        "filename": "ProcBench Benchmark for Multi-Step Reasoning and Following Procedure.pdf",
        "analysis": {
            "benchmarks": [
                "ProcBench"
            ],
            "base_models": [
                "Claude-3.5-sonnet",
                "Mistral-large",
                "Gemini-1.5-Pro",
                "GPT-4o",
                "GPT-4o-mini",
                "o1-mini",
                "o1-preview"
            ]
        }
    },
    "Captioning Visualizations with Large Language Models CVLLM A Tutorial": {
        "filename": "Captioning Visualizations with Large Language Models CVLLM A Tutorial.pdf",
        "analysis": {
            "benchmarks": [
                "Chart-to-text",
                "VisText"
            ],
            "base_models": [
                "GPT-4V"
            ]
        }
    },
    "AutoBreach Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization": {
        "filename": "AutoBreach Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench"
            ],
            "base_models": [
                "Claude-3",
                "GPT-3.5",
                "GPT-4 Turbo",
                "Llama-2-7B-chat",
                "Vicuna-13B-v1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InterAct Exploring the Potentials of ChatGPT as a Cooperative Agent": {
        "filename": "InterAct Exploring the Potentials of ChatGPT as a Cooperative Agent.pdf",
        "analysis": {
            "benchmarks": [
                "AlfWorld"
            ],
            "base_models": [
                "ChatGPT",
                "InstructGPT (text-davinci-002)"
            ]
        }
    },
    "Unified View of Grokking Double Descent and Emergent Abilities A Perspective from Circuits Competition": {
        "filename": "Unified View of Grokking Double Descent and Emergent Abilities A Perspective from Circuits Competition.pdf",
        "analysis": {
            "benchmarks": [
                "Modular Addition Task"
            ],
            "base_models": [
                "1-layer simplified decoder-only transformer (hidden size varies)",
                "8-layer transformer (hidden size varies)"
            ]
        }
    },
    "AutoRNet Automatically Optimizing Heuristics for Robust Network Design via Large Language Models": {
        "filename": "AutoRNet Automatically Optimizing Heuristics for Robust Network Design via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "scale-free networks with varying sizes and densities",
                "EU power grid network"
            ],
            "base_models": [
                "GPT-4 Turbo"
            ]
        }
    },
    "BatchPrompt Accomplish more with less": {
        "filename": "BatchPrompt Accomplish more with less.pdf",
        "analysis": {
            "benchmarks": [
                "Boolq",
                "QQP",
                "RTE",
                "GSM8K"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Critique-out-Loud Reward Models": {
        "filename": "Critique-out-Loud Reward Models.pdf",
        "analysis": {
            "benchmarks": [
                "RewardBench",
                "ArenaHard"
            ],
            "base_models": [
                "Llama-3-8B",
                "Llama-3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning": {
        "filename": "Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning.pdf",
        "analysis": {
            "benchmarks": [
                "ANLI",
                "ReCoRD",
                "HellaSwag",
                "MMLU",
                "ARC",
                "WiC",
                "WinoGrande",
                "OpenBookQA",
                "MultiRC",
                "CommonSenseQA",
                "BoolQ",
                "COPA",
                "RTE",
                "WSC"
            ],
            "base_models": [
                "Llama 2 (7B and 13B)",
                "Mistral (7B)",
                "Yi (6B)",
                "Bloom (3B)",
                "Phi-2 (2B)",
                "Gemma (2B)",
                "TinyLlama (1B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Game-theoretic LLM Agent Workflow for Negotiation Games": {
        "filename": "Game-theoretic LLM Agent Workflow for Negotiation Games.pdf",
        "analysis": {
            "benchmarks": [
                "Prisoner's Dilemma",
                "Stag Hunt",
                "Battle of the Sexes",
                "Wait-Go Game",
                "Duopolistic Competition",
                "Escalation Game",
                "Monopoly Game",
                "Hot-cold Game",
                "Draco Game",
                "TriGame"
            ],
            "base_models": [
                "Claude-3.5 Sonnet",
                "Claude-3 Opus",
                "GPT-4o",
                "o1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Imitation Learning Key Reasoning Steps from Dual Chain-of-Thoughts in Reasoning Distillation": {
        "filename": "Beyond Imitation Learning Key Reasoning Steps from Dual Chain-of-Thoughts in Reasoning Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench Hard (BBH)",
                "BIG-Bench Sub (BB-sub)",
                "AGIEval",
                "AI2 Reasoning Challenge (ARC)"
            ],
            "base_models": [
                "LLaMA2-7B",
                "ChatGPT (gpt-3.5-turbo-0613)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MASSW A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows": {
        "filename": "MASSW A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows.pdf",
        "analysis": {
            "benchmarks": [
                "MASSW"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Mixtral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CogniDual Framework Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks": {
        "filename": "CogniDual Framework Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "ReClor",
                "LogiQA 2.0"
            ],
            "base_models": [
                "Vicuna (7B, 13B, 30B)",
                "Llama2 (7B, 13B)"
            ]
        }
    },
    "Rational Metareasoning for Large Language Models": {
        "filename": "Rational Metareasoning for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ARC",
                "CommonsenseQA",
                "GSM8K",
                "ProofWriter",
                "MMLU"
            ],
            "base_models": [
                "Microsoft Phi-2",
                "Meta Llama-3-8B",
                "Mistral-7B-v0.3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MoS Unleashing Parameter Efficiency of Low-Rank Adaptation with Mixture of Shards": {
        "filename": "MoS Unleashing Parameter Efficiency of Low-Rank Adaptation with Mixture of Shards.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BBH",
                "GSM8K",
                "TyDi QA",
                "HumanEval"
            ],
            "base_models": [
                "LLaMA2-7B",
                "LLaMA2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities": {
        "filename": "Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities.pdf",
        "analysis": {
            "benchmarks": [
                "OWASP",
                "SARD Juliet (C/C++)",
                "SARD Juliet (Java)",
                "CVEFixes (C/C++)",
                "CVEFixes (Java)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Gemini-1.5-Flash",
                "CodeLlama-7B",
                "CodeLlama-13B",
                "CodeLlama-34B",
                "Llama-3.1-8B",
                "Llama-3.1-70B",
                "Qwen-2.5-14B",
                "Qwen-2.5-32B",
                "DeepSeekCoder-7B",
                "DeepSeekCoder-33B",
                "Mistral-Codestral-22B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Effective Distillation of Table-based Reasoning Ability from LLMs": {
        "filename": "Effective Distillation of Table-based Reasoning Ability from LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "SciGen"
            ],
            "base_models": [
                "Flan-T5-base (220M)",
                "T5-base (220M)",
                "T5-large (770M)",
                "BART-large (400M)",
                "gpt-3.5-turbo (175B)",
                "text-davinci-002 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Versatile Graph Learning Approach from the Perspective of Large Language Models": {
        "filename": "Towards Versatile Graph Learning Approach from the Perspective of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GraphText",
                "NLGraph"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "PaLM 62B",
                "RoBERTa",
                "LLaMA"
            ]
        }
    },
    "Large Language Models Can Self-Improve": {
        "filename": "Large Language Models Can Self-Improve.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "DROP",
                "OpenBookQA",
                "ANLI-A3",
                "AQUA",
                "StrategyQA",
                "MNLI"
            ],
            "base_models": [
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Expert-Level Medical Question Answering with Large Language Models": {
        "filename": "Towards Expert-Level Medical Question Answering with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA (USMLE)",
                "MedMCQA",
                "PubMedQA",
                "MMLU clinical topics",
                "MultiMedQA 140",
                "MultiMedQA 1066",
                "Adversarial (General)",
                "Adversarial (Health equity)"
            ],
            "base_models": [
                "PaLM 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FreshLLMs Refreshing Large Language Models with Search Engine Augmentation": {
        "filename": "FreshLLMs Refreshing Large Language Models with Search Engine Augmentation.pdf",
        "analysis": {
            "benchmarks": [
                "FRESH QA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "T5 (770M to 540B)",
                "PaLM",
                "FLAN-T5",
                "FLAN-PaLM",
                "Codex"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Compress Prompts with Gist Tokens": {
        "filename": "Learning to Compress Prompts with Gist Tokens.pdf",
        "analysis": {
            "benchmarks": [
                "Alpaca+",
                "Human validation split"
            ],
            "base_models": [
                "LLaMA-7B (~7B parameters)",
                "FLAN-T5-XXL (11B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models on Graphs A Comprehensive Survey": {
        "filename": "Large Language Models on Graphs A Comprehensive Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "BERT",
                "T5",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HiGPT Heterogeneous Graph Language Model": {
        "filename": "HiGPT Heterogeneous Graph Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "IMDB",
                "DBLP",
                "ACM"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Think-on-Graph Deep and Responsible Reasoning of Large Language Model on Knowledge Graph": {
        "filename": "Think-on-Graph Deep and Responsible Reasoning of Large Language Model on Knowledge Graph.pdf",
        "analysis": {
            "benchmarks": [
                "CWQ",
                "WebQSP",
                "GrailQA",
                "QALD10-en",
                "Simple Questions",
                "WebQuestions",
                "T-REx",
                "Zero-Shot RE",
                "Creak"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "Llama-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InferFix End-to-End Program Repair with LLMs": {
        "filename": "InferFix End-to-End Program Repair with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "InferredBugs"
            ],
            "base_models": [
                "Codex Cushman (12 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large language models surpass human experts in predicting neuroscience results": {
        "filename": "Large language models surpass human experts in predicting neuroscience results.pdf",
        "analysis": {
            "benchmarks": [
                "BrainBench"
            ],
            "base_models": [
                "Llama2-7B",
                "Mistral-7B",
                "Galactica-6.7B",
                "Galactica-30B",
                "Galactica-120B",
                "Falcon-40B",
                "Falcon-180B",
                "Llama-2-13B",
                "Llama-2-70B",
                "Mistral-7B (instruct)",
                "Phi-3 (3.8B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Personalized Visual Instruction Tuning": {
        "filename": "Personalized Visual Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "P-Bench"
            ],
            "base_models": [
                "LLaVA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BlenderAlchemy Editing 3D Graphics with Vision-Language Models": {
        "filename": "BlenderAlchemy Editing 3D Graphics with Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4V",
                "LLaVA",
                "Gemini",
                "DallE-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AI-Assisted Generation of Difficult Math Questions": {
        "filename": "AI-Assisted Generation of Difficult Math Questions.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "MATH2"
            ],
            "base_models": [
                "GPT-4 Omni",
                "Claude 3.5 Sonnet",
                "GPT-4 Turbo",
                "Gemini-1.5-Pro",
                "Claude-3 Opus",
                "Llama-3.1-70B-Instruct",
                "Llama-3-70B-Instruct",
                "MetaMath-70B",
                "MAmmoTH-70B",
                "Mixtral-8×7B-Instruct",
                "MetaMath-13B",
                "MAmmoTH-13B",
                "deepseek-math-7b-instruct",
                "Llama-3.1-8B-Instruct",
                "Llama-3-8B-Instruct",
                "gemma-1.1-7b-Instruct",
                "MetaMath-7B",
                "MAmmoTH-7B",
                "Phi-3-mini-128k-instruct",
                "gemma-1.1-2b-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Object-Centric Instruction Augmentation for Robotic Manipulation": {
        "filename": "Object-Centric Instruction Augmentation for Robotic Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "Franka Kitchen",
                "Real-Robot"
            ],
            "base_models": [
                "ViT-L/14 from CLIP",
                "LLaMA-2-7B"
            ]
        }
    },
    "Beyond Positive Scaling How Negation Impacts Scaling Trends of Language Models": {
        "filename": "Beyond Positive Scaling How Negation Impacts Scaling Trends of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "NeQA",
                "NegatedLAMA",
                "OBQA",
                "SQuAD"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3 Text Series",
                "Cohere",
                "Jurassic"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distilling Reasoning Capabilities into Smaller Language Models": {
        "filename": "Distilling Reasoning Capabilities into Smaller Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "StrategyQA",
                "SVAMP"
            ],
            "base_models": [
                "GPT-2 large",
                "GPT-3 6B"
            ]
        }
    },
    "CodeGen An Open Large Language Model for Code with Multi-Turn Program Synthesis": {
        "filename": "CodeGen An Open Large Language Model for Code with Multi-Turn Program Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "Multi-Turn Programming Benchmark (MTPB)"
            ],
            "base_models": [
                "CODEGEN (350M, 2.7B, 6.1B, 16.1B)",
                "GPT-Neo (350M, 2.7B)",
                "GPT-J (6B)",
                "Codex (300M, 2.5B, 12B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RetICL Sequential Retrieval of In-Context Examples with Reinforcement Learning": {
        "filename": "RetICL Sequential Retrieval of In-Context Examples with Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "TabMWP",
                "GSM8K",
                "QASC"
            ],
            "base_models": [
                "Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MaScQA A Question Answering Dataset for Investigating Materials Science Knowledge of Large Language Models": {
        "filename": "MaScQA A Question Answering Dataset for Investigating Materials Science Knowledge of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MaScQA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Language Conditioned Traffic Generation": {
        "filename": "Language Conditioned Traffic Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Waymo Open Dataset",
                "Crash Report dataset"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Comprehensive Study of GPT-4Vs Multimodal Capabilities in Medical Imaging": {
        "filename": "A Comprehensive Study of GPT-4Vs Multimodal Capabilities in Medical Imaging.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-CXR",
                "VQA-RAD",
                "MS-CXR"
            ],
            "base_models": [
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Recommender Systems with Large Language Model Reasoning Graphs": {
        "filename": "Enhancing Recommender Systems with Large Language Model Reasoning Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "ML-1M",
                "Amazon Beauty",
                "Amazon Clothing"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Opportunities for Large Language Models and Discourse in Engineering Design": {
        "filename": "Opportunities for Large Language Models and Discourse in Engineering Design.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2",
                "GPT-3",
                "BERT"
            ]
        }
    },
    "The Landscape of Emerging AI Agent Architectures for Reasoning Planning and Tool Calling A Survey": {
        "filename": "The Landscape of Emerging AI Agent Architectures for Reasoning Planning and Tool Calling A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude",
                "Llama",
                "Qwen",
                "Baichuan"
            ]
        }
    },
    "HouseLLM LLM-Assisted Two-Phase Text-to-Floorplan Generation": {
        "filename": "HouseLLM LLM-Assisted Two-Phase Text-to-Floorplan Generation.pdf",
        "analysis": {
            "benchmarks": [
                "RPlan"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "On Large Visual Language Models for Medical Imaging Analysis An Empirical Study": {
        "filename": "On Large Visual Language Models for Medical Imaging Analysis An Empirical Study.pdf",
        "analysis": {
            "benchmarks": [
                "BTD",
                "ALL-IDB2",
                "CX-Ray"
            ],
            "base_models": [
                "BiomedCLIP (ViT-B/16)",
                "OpenCLIP (ViT-G/14)",
                "LLaVA (ViT-L/14 & LLaMA-2-7B)",
                "ChatGPT-4 (GPT-4)",
                "OpenFlamingo (ViT-L/14 & INCITE-3B)"
            ]
        }
    },
    "One Language Many Gaps Evaluating Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks": {
        "filename": "One Language Many Gaps Evaluating Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "ReDial",
                "HumanEval",
                "GSM8K",
                "MBPP",
                "LogicBench",
                "Folio",
                "SVAMP",
                "AsyncHow"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4",
                "GPT-3.5-turbo",
                "LLaMA-3.1-70B-Instruct",
                "LLaMA-3-70B-Instruct",
                "LLaMA-3-8B-Instruct",
                "Mistral-7B-Instruct-v0.3",
                "Mixtral-8x7B-Instruct-v0.1",
                "Phi-3-Medium-128K-Instruct",
                "Phi-3-Small-128K-Instruct",
                "Phi-3-Mini-128K-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing SLM via ChatGPT and Dataset Augmentation": {
        "filename": "Enhancing SLM via ChatGPT and Dataset Augmentation.pdf",
        "analysis": {
            "benchmarks": [
                "ANLI"
            ],
            "base_models": [
                "ChatGPT-3.5-Turbo",
                "T5-Small"
            ]
        }
    },
    "AgentMD Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning": {
        "filename": "AgentMD Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning.pdf",
        "analysis": {
            "benchmarks": [
                "RiskQA",
                "MIMIC-III"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Reka Core Flash and Edge A Series of Powerful Multimodal Language Models": {
        "filename": "Reka Core Flash and Edge A Series of Powerful Multimodal Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMMU",
                "VQAv2",
                "MMLU",
                "GSM8K",
                "Perception-Test",
                "HumanEval",
                "GPQA",
                "XStoryCloze",
                "XCOPA",
                "XQuAD",
                "TydiQA",
                "Belebele",
                "MedMCQA",
                "PubMedQA",
                "MMLU (Medical)"
            ],
            "base_models": [
                "GPT-4",
                "Claude 3 Opus",
                "Claude 3 Sonnet",
                "Gemini Ultra",
                "Gemini Pro 1.0",
                "Llama 2 70B",
                "GPT-3.5 Turbo",
                "IDEFICS 80B",
                "Adept Fuyu 8B",
                "Meditron 70B",
                "Med-PaLM-2"
            ]
        }
    },
    "DART-Math Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving": {
        "filename": "DART-Math Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "CollegeMath",
                "DeepMind-Mathematics",
                "OlympiadBench-Math",
                "TheoremQA"
            ],
            "base_models": [
                "Mistral-7B",
                "DeepSeekMath-7B",
                "Llama3-8B",
                "Llama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Driven Occupancy Prediction": {
        "filename": "Language Driven Occupancy Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "Occ3D-nuScenes"
            ],
            "base_models": [
                "BEVDet (ResNet-50)",
                "BEVDet4D (ResNet-50)",
                "BEVFormer (ResNet-101)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic": {
        "filename": "Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic.pdf",
        "analysis": {
            "benchmarks": [
                "SNLI",
                "e-SNLI"
            ],
            "base_models": [
                "Sentence-BERT",
                "T5-small (60M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LaMI Large Language Models for Multi-Modal Human-Robot Interaction": {
        "filename": "LaMI Large Language Models for Multi-Modal Human-Robot Interaction.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Zero-Shot Prompting Approaches for LLM-based Graphical User Interface Generation": {
        "filename": "Zero-Shot Prompting Approaches for LLM-based Graphical User Interface Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Rico GUI repository"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation": {
        "filename": "Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQUA",
                "SVAMP",
                "StrategyQA",
                "LogicalDeduction",
                "Countries",
                "UMLS",
                "Kinship",
                "NELL-995",
                "FB15K-237"
            ],
            "base_models": [
                "GPT-2",
                "Llama 2 (7B)",
                "Llama 2 (13B)",
                "Yi (6B)",
                "Gemma (2B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SpacTor-T5 Pre-training T5 Models with Span Corruption and Replaced Token Detection": {
        "filename": "SpacTor-T5 Pre-training T5 Models with Span Corruption and Replaced Token Detection.pdf",
        "analysis": {
            "benchmarks": [
                "SuperGLUE",
                "SQuAD",
                "CNN/DailyMail"
            ],
            "base_models": [
                "T5 (Base and Large variants)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BEATS Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search": {
        "filename": "BEATS Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "SVAMP",
                "SimulEq",
                "NumGLUE"
            ],
            "base_models": [
                "Qwen2-7B-Instruct",
                "LLaMA3-8B",
                "Yi-1.5-6B"
            ]
        }
    },
    "BlendFilter Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering": {
        "filename": "BlendFilter Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering.pdf",
        "analysis": {
            "benchmarks": [
                "HotPotQA",
                "2WikiMultiHopQA",
                "StrategyQA"
            ],
            "base_models": [
                "GPT3.5-turbo-Instruct",
                "Vicuna 1.5-13b",
                "Qwen-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain of Thought Prompting Elicits Knowledge Augmentation": {
        "filename": "Chain of Thought Prompting Elicits Knowledge Augmentation.pdf",
        "analysis": {
            "benchmarks": [
                "CSQA",
                "StrategyQA",
                "Date Understanding",
                "Sports Understanding",
                "AQUA-RAT",
                "GSM8K",
                "SV AMP",
                "MultiArith",
                "SingleEq",
                "AddSub",
                "Last Letter Concatenation"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "ALBERT-large-v2",
                "DeBERTa-v3-large",
                "T5"
            ]
        }
    },
    "Furthest Reasoning with Plan Assessment Stable Reasoning Path with Retrieval-Augmented Large Language Models": {
        "filename": "Furthest Reasoning with Plan Assessment Stable Reasoning Path with Retrieval-Augmented Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HotPotQA",
                "2WikiMultiHopQA",
                "MuSiQue"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs as Visual Explainers Advancing Image Classification with Evolving Visual Descriptions": {
        "filename": "LLMs as Visual Explainers Advancing Image Classification with Evolving Visual Descriptions.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "EuroSAT",
                "UCF101",
                "SUN",
                "Caltech",
                "DTD",
                "CIFAR-10",
                "Flowers102",
                "CUB"
            ],
            "base_models": [
                "GPT-4",
                "CLIP ViT-B/32"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual Program Distillation Distilling Tools and Programmatic Reasoning into Vision-Language Models": {
        "filename": "Visual Program Distillation Distilling Tools and Programmatic Reasoning into Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMBench",
                "OK-VQA",
                "A-OKVQA",
                "TallyQA",
                "POPE",
                "Hateful Memes"
            ],
            "base_models": [
                "PaLI-X (55B)",
                "PaLI-3 (5B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "I Spy a Metaphor Large Language Models and Diffusion Models Co-Create Visual Metaphors": {
        "filename": "I Spy a Metaphor Large Language Models and Diffusion Models Co-Create Visual Metaphors.pdf",
        "analysis": {
            "benchmarks": [
                "HAIVMet",
                "SNLI-VE"
            ],
            "base_models": [
                "Instruct GPT-3 (davinci-002)",
                "DALL·E 2",
                "Stable Diffusion v2.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation": {
        "filename": "Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation.pdf",
        "analysis": {
            "benchmarks": [
                "SK-TOD",
                "MultiWoz 2.1"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT",
                "Flan-T5 (small, base, large)"
            ]
        }
    },
    "Improving Sample Efficiency of Reinforcement Learning with Background Knowledge from Large Language Models": {
        "filename": "Improving Sample Efficiency of Reinforcement Learning with Background Knowledge from Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Minigrid",
                "Crafter"
            ],
            "base_models": [
                "GPT-4",
                "Llama-2 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ER-Test Evaluating Explanation Regularization Methods for Language Models": {
        "filename": "ER-Test Evaluating Explanation Regularization Methods for Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SST",
                "Amazon",
                "Yelp",
                "Movies",
                "e-SNLI",
                "MNLI",
                "IMDb",
                "LIT"
            ],
            "base_models": [
                "BigBird-Base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Augmenting large language models with chemistry tools": {
        "filename": "Augmenting large language models with chemistry tools.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Blind Solvers to Logical Thinkers Benchmarking LLMs Logical Integrity on Faulty Mathematical Problems": {
        "filename": "From Blind Solvers to Logical Thinkers Benchmarking LLMs Logical Integrity on Faulty Mathematical Problems.pdf",
        "analysis": {
            "benchmarks": [
                "FAULTY MATH"
            ],
            "base_models": [
                "GPT-4",
                "Gemini-1.5-Pro",
                "Qwen-1.5-72B",
                "Claude-3-Opus",
                "Mixtral-8X22B-V0.1",
                "Deepseek-V2",
                "Yi-1.5-34B",
                "Deepseek-Math-7B-RL",
                "Llama-3-70B",
                "Internlm2-Math-20B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Clever Hans or Neural Theory of Mind Stress Testing Social Reasoning in Large Language Models": {
        "filename": "Clever Hans or Neural Theory of Mind Stress Testing Social Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Triangle COPA",
                "SocialIQa",
                "ToMi",
                "ToMi'",
                "epistemic_reasoning",
                "Adv-CSFB",
                "FauxPas-EAI"
            ],
            "base_models": [
                "FlanT5 (small, base, large, xl, xxl)",
                "FlanUl2",
                "GPT-3 (text-davinci-002, text-davinci-003)",
                "GPT-3.5 / ChatGPT (gpt-3.5-turbo-0301)",
                "GPT-4 (gpt-4-0314)",
                "Jurassic2 (j2-jumbo-instruct, j2-grande-instruct, j2-jumbo, j2-grande, j2-large)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Shape2Scene 3D Scene Representation Learning Through Pre-training on Shape Data": {
        "filename": "Shape2Scene 3D Scene Representation Learning Through Pre-training on Shape Data.pdf",
        "analysis": {
            "benchmarks": [
                "ScanObjectNN",
                "ShapeNetPart",
                "ModelNet40",
                "S3DIS",
                "ScanNet v2",
                "SemanticKITTI",
                "Synthia4D"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rethinking Data Selection at Scale Random Selection is Almost All You Need": {
        "filename": "Rethinking Data Selection at Scale Random Selection is Almost All You Need.pdf",
        "analysis": {
            "benchmarks": [
                "Big-Bench-Hard (BBH)",
                "Grade School Math (GSM)",
                "HumanEval",
                "Massive Multitask Language Understanding (MMLU)",
                "IFEval"
            ],
            "base_models": [
                "LLaMA3-8B",
                "Qwen2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TrustNavGPT Modeling Uncertainty to Improve Trustworthiness of Audio-Guided LLM-Based Robot Navigation": {
        "filename": "TrustNavGPT Modeling Uncertainty to Improve Trustworthiness of Audio-Guided LLM-Based Robot Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "Disfluent Navigational Instruction Audio Dataset",
                "RoboTHOR simulation environment"
            ],
            "base_models": [
                "GPT-4",
                "Gemini"
            ]
        }
    },
    "Are Large Language Models Good Prompt Optimizers": {
        "filename": "Are Large Language Models Good Prompt Optimizers.pdf",
        "analysis": {
            "benchmarks": [
                "BigBench (Object Counting, Navigate, Snarks, Question Selection)"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "Llama-2-70B-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CrossGLG LLM Guides One-shot Skeleton-based 3D Action Recognition in a Cross-level Manner": {
        "filename": "CrossGLG LLM Guides One-shot Skeleton-based 3D Action Recognition in a Cross-level Manner.pdf",
        "analysis": {
            "benchmarks": [
                "NTU RGB+D 60",
                "NTU RGB+D 120",
                "Kinetics"
            ],
            "base_models": [
                "ChatGPT",
                "DeBERTa-V2-Xlarge"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Eight challenges in developing theory of intelligence": {
        "filename": "Eight challenges in developing theory of intelligence.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT (size not specified)"
            ]
        }
    },
    "Prompted Contextual Vectors for Spear-Phishing Detection": {
        "filename": "Prompted Contextual Vectors for Spear-Phishing Detection.pdf",
        "analysis": {
            "benchmarks": [
                "Proprietary spear-phishing dataset",
                "Enron email dataset",
                "SpamAssassin dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Gemini Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Minimum Levels of Interpretability for Artificial Moral Agents": {
        "filename": "Minimum Levels of Interpretability for Artificial Moral Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175B)",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Everything of Thoughts Defying the Law of Penrose Triangle for Thought Generation": {
        "filename": "Everything of Thoughts Defying the Law of Penrose Triangle for Thought Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Game of 24",
                "8-Puzzle",
                "Pocket Cube"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ACER Automatic Language Model Context Extension via Retrieval": {
        "filename": "ACER Automatic Language Model Context Extension via Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Question (NQ)",
                "TriviaQA (TQA)",
                "NarrativeQA"
            ],
            "base_models": [
                "Llama-3-8B-Instruct",
                "Llama-3-8B-ProLong-Base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automatically Correcting Large Language Models Surveying the landscape of diverse self-correction strategies": {
        "filename": "Automatically Correcting Large Language Models Surveying the landscape of diverse self-correction strategies.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "Open-Domain QA"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unleashing Artificial Cognition Integrating Multiple AI Systems": {
        "filename": "Unleashing Artificial Cognition Integrating Multiple AI Systems.pdf",
        "analysis": {
            "benchmarks": [
                "Kaggle Lichess dataset",
                "Custom chess reasoning dataset"
            ],
            "base_models": [
                "Mistral 7B",
                "GPT-4o",
                "GPT-3.5 Turbo",
                "Gemma 7B Instruct",
                "Mistral 7B Instruct"
            ]
        }
    },
    "Large Language Model LLM as a System of Multiple Expert Agents An Approach to solve the Abstraction and Reasoning Corpus ARC Challenge": {
        "filename": "Large Language Model LLM as a System of Multiple Expert Agents An Approach to solve the Abstraction and Reasoning Corpus ARC Challenge.pdf",
        "analysis": {
            "benchmarks": [
                "Abstraction and Reasoning Corpus (ARC)"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual Adversarial Examples Jailbreak Aligned Large Language Models": {
        "filename": "Visual Adversarial Examples Jailbreak Aligned Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "RealToxicityPrompts"
            ],
            "base_models": [
                "MiniGPT-4 (13B)",
                "InstructBLIP (built upon Vicuna)",
                "LLaVA (built upon LLaMA-2-13B-Chat)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Black-box Uncertainty Quantification Method for LLM-as-a-Judge": {
        "filename": "Black-box Uncertainty Quantification Method for LLM-as-a-Judge.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "Reliance Study",
                "Summarization CNN/DM",
                "Feedback Collection",
                "FeedbackQA"
            ],
            "base_models": [
                "Mixtral-8x7B-Instruct-v01",
                "Llama-3-8B-Instruct",
                "Llama-3-70B-Instruct"
            ]
        }
    },
    "AI and Generative AI for Research Discovery and Summarization": {
        "filename": "AI and Generative AI for Research Discovery and Summarization.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Gemini Pro"
            ]
        }
    },
    "BMW Agents - A Framework For Task Automation Through Multi-Agent Collaboration": {
        "filename": "BMW Agents - A Framework For Task Automation Through Multi-Agent Collaboration.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When MOE Meets LLMs Parameter Efficient Fine-tuning for Multi-task Medical Applications": {
        "filename": "When MOE Meets LLMs Parameter Efficient Fine-tuning for Multi-task Medical Applications.pdf",
        "analysis": {
            "benchmarks": [
                "PromptCBLUE"
            ],
            "base_models": [
                "ChatGLM-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoReS Orchestrating the Dance of Reasoning and Segmentation": {
        "filename": "CoReS Orchestrating the Dance of Reasoning and Segmentation.pdf",
        "analysis": {
            "benchmarks": [
                "ReasonSeg",
                "refCOCO",
                "refCOCO+",
                "refCOCOg"
            ],
            "base_models": [
                "LLaVA-7B",
                "LLaVA-13B",
                "LLaVA-v1.5-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can ChatGPT Defend its Belief in Truth Evaluating LLM Reasoning via Debate": {
        "filename": "Can ChatGPT Defend its Belief in Truth Evaluating LLM Reasoning via Debate.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "PrOntoQA",
                "StrategyQA",
                "CommonsenseQA 2.0",
                "Creak",
                "BIG-Bench"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language Interfaces for Tabular Data Querying and Visualization A Survey": {
        "filename": "Natural Language Interfaces for Tabular Data Querying and Visualization A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "nvBench"
            ],
            "base_models": [
                "BERT",
                "T5",
                "GPT",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Evolution for Evading Social Media Regulation via LLM-Based Multi-Agent Simulation": {
        "filename": "Language Evolution for Evading Social Media Regulation via LLM-Based Multi-Agent Simulation.pdf",
        "analysis": {
            "benchmarks": [
                "Guess the Number Game",
                "Illegal Pet Trading",
                "Nuclear Wastewater Discharge"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses": {
        "filename": "Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses.pdf",
        "analysis": {
            "benchmarks": [
                "TiMoS (Tropes in Movie Synopses)"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "LLaMa-2-7B"
            ]
        }
    },
    "ERBench An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models": {
        "filename": "ERBench An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Movie",
                "Soccer",
                "Airport",
                "Music",
                "Book"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama2-70B-Chat",
                "Gemini-Pro",
                "Claude-3-Sonnet",
                "Mistral-7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Image2Struct Benchmarking Structure Extraction for Vision-Language Models": {
        "filename": "Image2Struct Benchmarking Structure Extraction for Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Image2Struct (Webpages, LaTeX, Musical Scores)"
            ],
            "base_models": [
                "Claude 3 Opus",
                "Claude 3 Sonnet",
                "Claude 3.5 Sonnet",
                "Gemini 1.0 Pro Vision",
                "Gemini 1.5 Pro",
                "GPT-4 Omni",
                "GPT-4 Vision",
                "LLaVA",
                "LLaVA NeXT",
                "IDEFICS Instruct 9B",
                "IDEFICS Instruct 80B",
                "IDEFICS2 8B",
                "Palmyra Vision 003",
                "Qwen-VL Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Large Language Models in Process Mining Capabilities Benchmarks Evaluation Strategies and Future Challenges": {
        "filename": "Evaluating Large Language Models in Process Mining Capabilities Benchmarks Evaluation Strategies and Future Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "AGIEval",
                "MT-Bench",
                "SPIDER",
                "SPIDER-realistic",
                "MMBench",
                "MM-Vet"
            ],
            "base_models": [
                "GPT-4",
                "Google Bard/Gemini"
            ]
        }
    },
    "Testing the Depth of ChatGPTs Comprehension via Cross-Modal Tasks Based on ASCII-Art GPT35s Abilities in Regard to Recognizing and Generating ASCII-Art Are Not Totally Lacking": {
        "filename": "Testing the Depth of ChatGPTs Comprehension via Cross-Modal Tasks Based on ASCII-Art GPT35s Abilities in Regard to Recognizing and Generating ASCII-Art Are Not Totally Lacking.pdf",
        "analysis": {
            "benchmarks": [
                "Custom ASCII-art dataset"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SimLayerKV A Simple Framework for Layer-Level KV Cache Reduction": {
        "filename": "SimLayerKV A Simple Framework for Layer-Level KV Cache Reduction.pdf",
        "analysis": {
            "benchmarks": [
                "LongBench",
                "Ruler"
            ],
            "base_models": [
                "LLaMA2-7B",
                "LLaMA3-8B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoT-TL Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning": {
        "filename": "CoT-TL Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "drone planning",
                "CleanUp World",
                "pick-and-place"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3",
                "Mistral-7B",
                "Starcoder"
            ]
        }
    },
    "Next-Generation Simulation Illuminates Scientific Problems of Organised Complexity": {
        "filename": "Next-Generation Simulation Illuminates Scientific Problems of Organised Complexity.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "LLaMA-2-7B-chat",
                "LLaMA-2-13B-chat"
            ]
        }
    },
    "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models": {
        "filename": "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Admissible Set (A(15,10))",
                "Online Bin Packing (OR dataset)",
                "Online Bin Packing (Weibull dataset)",
                "Traveling Salesman Problem (TSP100 instances)"
            ],
            "base_models": [
                "CodeLlama-7B",
                "CodeLlama-34B",
                "DeepSeek-Coder-6.7B",
                "DeepSeek-Coder-33B",
                "GPT-3.5",
                "GPT-4",
                "Claude 3 Opus"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fox-1 Technical Report": {
        "filename": "Fox-1 Technical Report.pdf",
        "analysis": {
            "benchmarks": [
                "ARC Challenge (25-shot)",
                "HellaSwag (10-shot)",
                "TruthfulQA (0-shot)",
                "MMLU (5-shot)",
                "Winogrande (5-shot)",
                "GSM8k (5-shot)"
            ],
            "base_models": [
                "Fox-1-1.6B (1.6B parameters)",
                "Fox-1-1.6B-Instruct-v0.1 (1.6B parameters)"
            ]
        }
    },
    "Knowledge Solver Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs": {
        "filename": "Knowledge Solver Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "OpenbookQA",
                "MedQA-USMLE"
            ],
            "base_models": [
                "GPT-3.5",
                "LLaMA-7B",
                "LLaMA 2-7B"
            ]
        }
    },
    "Reducing Hallucinations Enhancing VQA for Flood Disaster Damage Assessment with Visual Contexts": {
        "filename": "Reducing Hallucinations Enhancing VQA for Flood Disaster Damage Assessment with Visual Contexts.pdf",
        "analysis": {
            "benchmarks": [
                "FFD-IQA"
            ],
            "base_models": [
                "Flan-Alpaca"
            ]
        }
    },
    "Short Film Dataset SFD A Benchmark for Story-Level Video Understanding": {
        "filename": "Short Film Dataset SFD A Benchmark for Story-Level Video Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "Short Film Dataset (SFD)",
                "MovieQA",
                "LVU"
            ],
            "base_models": [
                "Gemma 2B",
                "Mistral 7B",
                "LLaMA 38B",
                "GPT-3.5",
                "Mixtral 8x7B",
                "Claude 3 Haiku",
                "Claude 3 Sonnet",
                "LLaMA 370B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Unlocking Spell on Base LLMs Rethinking Alignment via In-Context Learning": {
        "filename": "The Unlocking Spell on Base LLMs Rethinking Alignment via In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "just-eval-instruct"
            ],
            "base_models": [
                "Llama-2-7b",
                "Llama-2-70b",
                "Mistral-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Augmented Language Models a Survey": {
        "filename": "Augmented Language Models a Survey.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "BBH",
                "MMLU"
            ],
            "base_models": [
                "GPT-3 175B",
                "PaLM 540B",
                "LaMDA",
                "Codex",
                "Chinchilla 7B",
                "Chinchilla 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can ChatGPT Detect DeepFakes A Study of Using Multimodal Large Language Models for Media Forensics": {
        "filename": "Can ChatGPT Detect DeepFakes A Study of Using Multimodal Large Language Models for Media Forensics.pdf",
        "analysis": {
            "benchmarks": [
                "FFHQ dataset",
                "DF3 dataset"
            ],
            "base_models": [
                "GPT4V (175 billion parameters)",
                "Gemini 1.0 Pro"
            ]
        }
    },
    "Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs": {
        "filename": "Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "BBQ",
                "Multi-Role Debate dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-2",
                "Qwen1.5-7B",
                "Llama2-7B",
                "ChatGLM3-6B",
                "Baichuan2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Context Matter Data-Efficient Augmentation of Large Language Models for Scientific Applications": {
        "filename": "Context Matter Data-Efficient Augmentation of Large Language Models for Scientific Applications.pdf",
        "analysis": {
            "benchmarks": [
                "AGIEval",
                "ChemLLMBench",
                "SCIEval",
                "HaluEval"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ROSE A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning": {
        "filename": "ROSE A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "Stanford Human Preference (SHP)",
                "Stack Exchange (SE)",
                "HH-RLHF"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "LLaMA-3.1-8B",
                "LLaMA-3.1-8B-INS.",
                "Mistral-7B-V0.3",
                "Mistral-7B-INS.-V0.3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Navigating Hallucinations for Reasoning of Unintentional Activities": {
        "filename": "Navigating Hallucinations for Reasoning of Unintentional Activities.pdf",
        "analysis": {
            "benchmarks": [
                "OOPs",
                "UCF-Crimes"
            ],
            "base_models": [
                "Video ChatGPT",
                "Video LLaMA",
                "Video Chat",
                "Video LLaMAv2",
                "Open Flamingo"
            ]
        }
    },
    "BlendRL A Framework for Merging Symbolic and Neural Policy Learning": {
        "filename": "BlendRL A Framework for Merging Symbolic and Neural Policy Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Atari Learning Environments (Kangaroo, Seaquest, Donkey Kong)"
            ],
            "base_models": [
                "None specified"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving medical reasoning through retrieval and self-reflection with retrieval-augmented large language models": {
        "filename": "Improving medical reasoning through retrieval and self-reflection with retrieval-augmented large language models.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "MedMCQA",
                "MMLU",
                "LiveQA",
                "MedicationQA"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA2 (7B)",
                "Self-RAG (based on LLaMA2)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Thought Predictive Control": {
        "filename": "Chain-of-Thought Predictive Control.pdf",
        "analysis": {
            "benchmarks": [
                "Moving Maze",
                "Franka-Kitchen",
                "ManiSkill2"
            ],
            "base_models": [
                "Transformer-based model",
                "Behavior Transformer (BeT)",
                "Decision Transformer (DT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Optima Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System": {
        "filename": "Optima Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "2WikiMultiHopQA",
                "TriviaQA",
                "CBT",
                "GSM8K",
                "MATH",
                "ARC-C",
                "MMLU"
            ],
            "base_models": [
                "Llama 3 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Federated Foundation Models Scalable Dataset Pipelines for Group-Structured Learning": {
        "filename": "Towards Federated Foundation Models Scalable Dataset Pipelines for Group-Structured Learning.pdf",
        "analysis": {
            "benchmarks": [
                "FedC4",
                "FedWiki",
                "FedBookCO",
                "FedCCnews"
            ],
            "base_models": [
                "Decoder-only transformer (100M parameters)",
                "Decoder-only transformer (1B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-planning Code Generation with Large Language Models": {
        "filename": "Self-planning Code Generation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MBPP-sanitized",
                "HumanEval",
                "HumanEval-X",
                "MBPP-ET",
                "HumanEval-ET"
            ],
            "base_models": [
                "code-davinci-002",
                "text-davinci-002",
                "text-davinci-003",
                "code-cushman-001",
                "text-curie-001",
                "text-babbage-001",
                "text-ada-001"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards a Theoretical Understanding of the Reversal Curse via Training Dynamics": {
        "filename": "Towards a Theoretical Understanding of the Reversal Curse via Training Dynamics.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Boosting of Thoughts Trial-and-Error Problem Solving with Large Language Models": {
        "filename": "Boosting of Thoughts Trial-and-Error Problem Solving with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQuA",
                "Game of 24"
            ],
            "base_models": [
                "GPT-4",
                "Llama2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Toolink Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model": {
        "filename": "Toolink Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-bench"
            ],
            "base_models": [
                "ChatGPT",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Talk like a Graph Encoding Graphs for Large Language Models": {
        "filename": "Talk like a Graph Encoding Graphs for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GraphQA"
            ],
            "base_models": [
                "PaLM 62B",
                "PaLM 2-XXS",
                "PaLM 2-XS",
                "PaLM 2-S",
                "PaLM 2-L"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Life Cycle of Knowledge in Big Language Models A Survey": {
        "filename": "The Life Cycle of Knowledge in Big Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "LAMA",
                "oLMpics"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "ALBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers": {
        "filename": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers.pdf",
        "analysis": {
            "benchmarks": [
                "RefCOCO",
                "RefCOCO+",
                "GQA",
                "NExT-QA"
            ],
            "base_models": [
                "PaLM 2 code-bison",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatScratch An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12": {
        "filename": "ChatScratch An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12.pdf",
        "analysis": {
            "benchmarks": [
                "None specified"
            ],
            "base_models": [
                "Stable Diffusion",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Stochastic Parrots or ICU Experts Large Language Models in Critical Care Medicine A Scoping Review": {
        "filename": "Stochastic Parrots or ICU Experts Large Language Models in Critical Care Medicine A Scoping Review.pdf",
        "analysis": {
            "benchmarks": [
                "Spanish Medical Residency Entrance Examination",
                "Japanese Emergency Medicine Board Certification Examinations",
                "American Board of Surgery In-Training Examination"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "GPT-4",
                "Claude-2",
                "BioMed-RoBERTa",
                "ELMo",
                "BERT",
                "Bard",
                "Gemini",
                "Bing"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Complex Reading Comprehension Through Question Decomposition": {
        "filename": "Complex Reading Comprehension Through Question Decomposition.pdf",
        "analysis": {
            "benchmarks": [
                "DROP",
                "BREAK"
            ],
            "base_models": [
                "T5-base (220M)",
                "Bart-base (140M)",
                "GPT-3 (175B)"
            ]
        }
    },
    "SpeechGen Unlocking the Generative Power of Speech Language Models with Prompts": {
        "filename": "SpeechGen Unlocking the Generative Power of Speech Language Models with Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "CoVOST2 Es-En",
                "LibriSpeech",
                "LJSpeech"
            ],
            "base_models": [
                "Unit mBART"
            ]
        }
    },
    "Wearable intelligent throat enables natural speech in stroke patients with dysarthria": {
        "filename": "Wearable intelligent throat enables natural speech in stroke patients with dysarthria.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset from 5 stroke patients with dysarthria"
            ],
            "base_models": [
                "GPT-4o-mini"
            ]
        }
    },
    "MM-Narrator Narrating Long-form Videos with Multimodal In-Context Learning": {
        "filename": "MM-Narrator Narrating Long-form Videos with Multimodal In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "MAD-eval dataset"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation": {
        "filename": "Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation.pdf",
        "analysis": {
            "benchmarks": [
                "COCO Caption",
                "Visual Genome Caption",
                "VQA v2",
                "OK-VQA",
                "A-OKVQA",
                "OVEN",
                "Encyclopedic-VQA"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA (size not specified)",
                "CLIP-ViT-Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SimpleLLM4AD An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving": {
        "filename": "SimpleLLM4AD An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "DriveLM-nuScenes"
            ],
            "base_models": [
                "InternViT-6B",
                "Vicuna-13B"
            ]
        }
    },
    "Beyond LLMs Advancing the Landscape of Complex Reasoning": {
        "filename": "Beyond LLMs Advancing the Landscape of Complex Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Projecto dataset",
                "RTW itineraries",
                "Classpath transcripts"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Learning Reward for Robot Skills Using Large Language Models via Self-Alignment": {
        "filename": "Learning Reward for Robot Skills Using Large Language Models via Self-Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "ManiSkill2",
                "Isaac Gym"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Bayesian Approach to Data Point Selection": {
        "filename": "A Bayesian Approach to Data Point Selection.pdf",
        "analysis": {
            "benchmarks": [
                "MNIST",
                "CIFAR-10",
                "WebNLG",
                "MMLU",
                "ARC-challenge",
                "ARC-easy",
                "HellaSwag"
            ],
            "base_models": [
                "LeNet5",
                "ResNet32",
                "T5-small",
                "OpenLLaMA 3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training": {
        "filename": "Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training.pdf",
        "analysis": {
            "benchmarks": [
                "WikiText2",
                "Colossal Clean Common Crawl (C4)",
                "Penn Treebank (PTB)",
                "Recognizing Textual Entailment (RTE)",
                "WinoGrande",
                "BoolQ",
                "HellaSwag",
                "ARC-e",
                "ARC-c",
                "OBQA"
            ],
            "base_models": [
                "Phi-2",
                "LLama-1 7B",
                "LLama-2 7B",
                "Mistral 7B",
                "OPT 6.7B",
                "LLama-1 13B",
                "LLama-2 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LayoutLLM-T2I Eliciting Layout Guidance from LLM for Text-to-Image Generation": {
        "filename": "LayoutLLM-T2I Eliciting Layout Guidance from LLM for Text-to-Image Generation.pdf",
        "analysis": {
            "benchmarks": [
                "COCO2014"
            ],
            "base_models": [
                "ChatGPT",
                "Stable Diffusion (SD)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking": {
        "filename": "Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking.pdf",
        "analysis": {
            "benchmarks": [
                "MultiWOZ 2.1",
                "MultiWOZ 2.4"
            ],
            "base_models": [
                "gpt-3.5-turbo-0301",
                "text-davinci-003"
            ]
        }
    },
    "SilVar Speech Driven Multimodal Model for Reasoning Visual Question Answering and Object Localization": {
        "filename": "SilVar Speech Driven Multimodal Model for Reasoning Visual Question Answering and Object Localization.pdf",
        "analysis": {
            "benchmarks": [
                "MMMU",
                "ScienceQA"
            ],
            "base_models": [
                "CLIP",
                "Whisper",
                "LLaMA 3.1-8B"
            ]
        }
    },
    "Large Language Model-Powered Smart Contract Vulnerability Detection New Perspectives": {
        "filename": "Large Language Model-Powered Smart Contract Vulnerability Detection New Perspectives.pdf",
        "analysis": {
            "benchmarks": [
                "Common Vulnerabilities and Exposures (CVEs) database"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automatic Behavior Tree Expansion with LLMs for Robotic Manipulation": {
        "filename": "Automatic Behavior Tree Expansion with LLMs for Robotic Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "LLM-OBTEA dataset"
            ],
            "base_models": [
                "GPT-4-1106"
            ]
        }
    },
    "KNIFE Distilling Reasoning Knowledge From Free-Text Rationales": {
        "filename": "KNIFE Distilling Reasoning Knowledge From Free-Text Rationales.pdf",
        "analysis": {
            "benchmarks": [
                "OpenBookQA",
                "StrategyQA",
                "ECQA",
                "QuaRTz"
            ],
            "base_models": [
                "T5-Base (220M)",
                "T5-Large (770M)",
                "GPT-NeoX (20B)",
                "GPT-3 (text-davinci-003, 175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoFeedback An LLM-based Framework for Efficient and Accurate API Request Generation": {
        "filename": "AutoFeedback An LLM-based Framework for Efficient and Accurate API Request Generation.pdf",
        "analysis": {
            "benchmarks": [
                "API-Bank",
                "MP-API",
                "ToolAlpaca-single",
                "ToolAlpaca-mix"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4 Turbo",
                "LLaMA-2-7B",
                "Mistral-V0.2-7B",
                "ToolAlpaca-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BlockFound Customized blockchain foundation model for anomaly detection": {
        "filename": "BlockFound Customized blockchain foundation model for anomaly detection.pdf",
        "analysis": {
            "benchmarks": [
                "Ethereum transactions",
                "Solana transactions"
            ],
            "base_models": [
                "BERT-base (100 million parameters)",
                "BERT-large (300 million parameters)"
            ]
        }
    },
    "A Survey on Text-guided 3D Visual Grounding Elements Recent Advances and Future Directions": {
        "filename": "A Survey on Text-guided 3D Visual Grounding Elements Recent Advances and Future Directions.pdf",
        "analysis": {
            "benchmarks": [
                "ScanRefer",
                "ReferIt3D",
                "ARKitSceneRefer"
            ],
            "base_models": [
                "PointNet++",
                "Transformer",
                "CLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SAGE Bridging Semantic and Actionable Parts for GEneralizable Manipulation of Articulated Objects": {
        "filename": "SAGE Bridging Semantic and Actionable Parts for GEneralizable Manipulation of Articulated Objects.pdf",
        "analysis": {
            "benchmarks": [
                "ManiSkill benchmark",
                "custom simulation environments"
            ],
            "base_models": [
                "GPT-4V",
                "GAPartNet"
            ]
        }
    },
    "ConvFinQA Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering": {
        "filename": "ConvFinQA Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "CONV FINQA"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-2 (medium)",
                "T5 (large)",
                "BERT-base",
                "BERT-large",
                "RoBERTa-base",
                "RoBERTa-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain of Preference Optimization Improving Chain-of-Thought Reasoning in LLMs": {
        "filename": "Chain of Preference Optimization Improving Chain-of-Thought Reasoning in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Bamboogle",
                "WikiMultiHopQA",
                "HotpotQA",
                "Fever",
                "Feverous",
                "Vitaminc",
                "SVAMP"
            ],
            "base_models": [
                "LLaMA2-7B",
                "LLaMA2-13B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-Assisted Code Cleaning For Training Accurate Code Generators": {
        "filename": "LLM-Assisted Code Cleaning For Training Accurate Code Generators.pdf",
        "analysis": {
            "benchmarks": [
                "APPS",
                "CODE-CONTESTS"
            ],
            "base_models": [
                "CODELLAMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT as Psychologist Preliminary Evaluations for GPT-4V on Visual Affective Computing": {
        "filename": "GPT as Psychologist Preliminary Evaluations for GPT-4V on Visual Affective Computing.pdf",
        "analysis": {
            "benchmarks": [
                "DISFA",
                "RAF-DB",
                "CASME2",
                "iMiGUE",
                "Real-Life Trial"
            ],
            "base_models": [
                "GPT-4V"
            ]
        }
    },
    "Harnessing Business and Media Insights with Large Language Models": {
        "filename": "Harnessing Business and Media Insights with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Global 500",
                "Fortune 1000"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instance-adaptive Zero-shot Chain-of-Thought Prompting": {
        "filename": "Instance-adaptive Zero-shot Chain-of-Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MMLU",
                "Causal Judgement",
                "Tracking Shuffled Objects",
                "CommonsenseQA",
                "SVAMP"
            ],
            "base_models": [
                "LLaMA-2-13B-Chat",
                "LLaMA-3-8B-Instruct",
                "Qwen-14B-Chat",
                "LLaMA-3-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Expressive Power of a Variant of the Looped Transformer": {
        "filename": "On the Expressive Power of a Variant of the Looped Transformer.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2 (12-layer)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Route Among Specialized Experts for Zero-Shot Generalization": {
        "filename": "Learning to Route Among Specialized Experts for Zero-Shot Generalization.pdf",
        "analysis": {
            "benchmarks": [
                "T0HO",
                "BIG-bench Hard (BBH)",
                "BIG-bench Lite (BBL)"
            ],
            "base_models": [
                "T5.1.1 XL (3B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Advancing LLM Reasoning Generalists with Preference Trees": {
        "filename": "Advancing LLM Reasoning Generalists with Preference Trees.pdf",
        "analysis": {
            "benchmarks": [
                "LeetCode",
                "TheoremQA"
            ],
            "base_models": [
                "Mistral-7B",
                "CodeLLaMA-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT-4 as an Agronomist Assistant Answering Agriculture Exams Using Large Language Models": {
        "filename": "GPT-4 as an Agronomist Assistant Answering Agriculture Exams Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Certified Crop Adviser (CCA) Exam",
                "EMBRAPA Dataset",
                "AgriExams Questions"
            ],
            "base_models": [
                "Llama2-13B",
                "Llama2-70B",
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Evaluating the World Model Implicit in a Generative Model": {
        "filename": "Evaluating the World Model Implicit in a Generative Model.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of taxi rides in New York City",
                "Othello game transcripts",
                "Logic puzzles (seating arrangement)"
            ],
            "base_models": [
                "GPT-2 (89.3M parameters)",
                "GPT-2 (1.5B parameters)",
                "Llama-2 (70B)",
                "Llama-3 (8B)",
                "Llama-3 (70B)",
                "Mixtral-8x22B",
                "Qwen 1.5 (72B)",
                "Qwen 1.5 (110B)",
                "GPT-3.5 (turbo)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PerceptionCLIP Visual Classification by Inferring and Conditioning on Contexts": {
        "filename": "PerceptionCLIP Visual Classification by Inferring and Conditioning on Contexts.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "ImageNetV2",
                "ImageNet-R",
                "ImageNet-A",
                "ImageNet-Sketch",
                "Waterbirds",
                "CelebA",
                "CUB200",
                "EuroSAT",
                "Places365",
                "Flowers102",
                "Food101",
                "Oxford Pets"
            ],
            "base_models": [
                "CLIP (ViT-B/16)",
                "CLIP (ViT-B/32)",
                "CLIP (ViT-L/14)",
                "CLIP (RN50)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "JustiLM Few-shot Justification Generation for Explainable Fact-Checking of Real-world Claims": {
        "filename": "JustiLM Few-shot Justification Generation for Explainable Fact-Checking of Real-world Claims.pdf",
        "analysis": {
            "benchmarks": [
                "ExClaim"
            ],
            "base_models": [
                "Flan-T5 (11B)",
                "Llama2 (70B)",
                "GPT-4",
                "Atlas (3B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Thinking Before Looking Improving Multimodal LLM Reasoning via Mitigating Visual Hallucination": {
        "filename": "Thinking Before Looking Improving Multimodal LLM Reasoning via Mitigating Visual Hallucination.pdf",
        "analysis": {
            "benchmarks": [
                "MMVP",
                "HallusionBench",
                "POPE",
                "MME",
                "MathVista",
                "SEED-Bench"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "Gemini 1.5 Pro",
                "GPT-4o mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Thinking LLMs General Instruction Following with Thought Generation": {
        "filename": "Thinking LLMs General Instruction Following with Thought Generation.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaEval",
                "Arena-Hard"
            ],
            "base_models": [
                "Llama-3-8B-Instruct",
                "GPT-4 (06/13)",
                "Llama-3-70b-instruct",
                "Mistral Large (24/02)",
                "Qwen2 72B Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation": {
        "filename": "Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MultiDoc2Dial"
            ],
            "base_models": [
                "RoBERTa",
                "T5 base"
            ]
        }
    },
    "How Secure Are Large Language Models LLMs for Navigation in Urban Environments": {
        "filename": "How Secure Are Large Language Models LLMs for Navigation in Urban Environments.pdf",
        "analysis": {
            "benchmarks": [
                "Touchdown",
                "Map2Seq"
            ],
            "base_models": [
                "GPT-3.5 Turbo (175B)",
                "GPT-4 Turbo",
                "LLaMa (7B)",
                "LLaMa2 (7B)",
                "LLaMa-7b (fine-tuned)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Compositional Semantic Parsing with Large Language Models": {
        "filename": "Compositional Semantic Parsing with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CFQ",
                "COGS"
            ],
            "base_models": [
                "Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Limitations of Language Models in Arithmetic and Symbolic Induction": {
        "filename": "Limitations of Language Models in Arithmetic and Symbolic Induction.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith",
                "GSM8k"
            ],
            "base_models": [
                "GPT-3",
                "T5",
                "PaLM-540B"
            ]
        }
    },
    "MMLU-Pro Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs": {
        "filename": "MMLU-Pro Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU-Pro+",
                "MMLU-Pro",
                "IFEval",
                "BBH (Big-Bench Hard)",
                "MATH",
                "GPQA",
                "MUSR",
                "GLUE",
                "SuperGLUE",
                "SQuAD"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini-1.5-Pro",
                "Llama-405B-Ins",
                "O1-preview",
                "Qwen2-72B-Ins",
                "Sonnet-3.5"
            ]
        }
    },
    "LLM for Test Script Generation and Migration Challenges Capabilities and Opportunities": {
        "filename": "LLM for Test Script Generation and Migration Challenges Capabilities and Opportunities.pdf",
        "analysis": {
            "benchmarks": [
                "Outlook",
                "QQ Mail",
                "NetEase Mail",
                "Fliggy",
                "Ctrip",
                "Mafengwo"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM for SoC Security A Paradigm Shift": {
        "filename": "LLM for SoC Security A Paradigm Shift.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MetaMath Integrating Natural Language and Code for Enhanced Mathematical Reasoning in Large Language Models": {
        "filename": "MetaMath Integrating Natural Language and Code for Enhanced Mathematical Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "Algebra",
                "AIME",
                "MATH"
            ],
            "base_models": [
                "GPT-4o-mini",
                "LLama-3.1-8b-Turbo"
            ]
        }
    },
    "Iteration of Thought Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning": {
        "filename": "Iteration of Thought Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GPQA",
                "Game of 24",
                "Mini Crosswords",
                "HotpotQA"
            ],
            "base_models": [
                "GPT-3",
                "PaLM",
                "GPT-4",
                "Gemini",
                "LLaMA",
                "Claude"
            ]
        }
    },
    "Recursive Visual Programming": {
        "filename": "Recursive Visual Programming.pdf",
        "analysis": {
            "benchmarks": [
                "VSR",
                "COVR",
                "GQA",
                "NextQA"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPTScore Evaluate as You Desire": {
        "filename": "GPTScore Evaluate as You Desire.pdf",
        "analysis": {
            "benchmarks": [
                "text summarization",
                "data-to-text",
                "machine translation",
                "dialogue response generation"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-2",
                "OPT",
                "FLAN-T5-small (80M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Insights into Alignment Evaluating DPO and its Variants Across Multiple Tasks": {
        "filename": "Insights into Alignment Evaluating DPO and its Variants Across Multiple Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MT-Bench",
                "Big Bench",
                "Open LLM Leaderboard",
                "ARC",
                "HellaSwag",
                "Winogrande",
                "Big Bench Sports Understanding",
                "Big Bench Causal Judgment",
                "Big Bench Formal Fallacies",
                "PIQA",
                "GSM8K",
                "TruthfulQA",
                "MMLU",
                "OpenBookQA",
                "BoolQ"
            ],
            "base_models": [
                "Mistral-7B-v0.1",
                "Mistral-instruct-7B-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Stop Reasoning When Multimodal LLM with Chain-of-Thought Reasoning Meets Adversarial Image": {
        "filename": "Stop Reasoning When Multimodal LLM with Chain-of-Thought Reasoning Meets Adversarial Image.pdf",
        "analysis": {
            "benchmarks": [
                "A-OKVQA",
                "ScienceQA"
            ],
            "base_models": [
                "MiniGPT4-7B",
                "MiniGPT4-13B",
                "OpenFlamingo-9B",
                "LLaVA-1.5-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generating API Parameter Security Rules with LLM for API Misuse Detection": {
        "filename": "Generating API Parameter Security Rules with LLM for API Misuse Detection.pdf",
        "analysis": {
            "benchmarks": [
                "APIMU4C",
                "Comparison dataset (Dcomp)"
            ],
            "base_models": [
                "GPT-3.5-turbo-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RNR Teaching Large Language Models to Follow Roles and Rules": {
        "filename": "RNR Teaching Large Language Models to Follow Roles and Rules.pdf",
        "analysis": {
            "benchmarks": [
                "RNR-Expert",
                "RNR-Awesome",
                "RNR-AlpacaFarm"
            ],
            "base_models": [
                "Llama-2-7B",
                "Llama-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aligning Large Language Models to a Domain-specific Graph Database": {
        "filename": "Aligning Large Language Models to a Domain-specific Graph Database.pdf",
        "analysis": {
            "benchmarks": [
                "FinGQL",
                "MediGQL"
            ],
            "base_models": [
                "ChatGPT",
                "Baichuan2-13B-Chat",
                "Chatglm3-6B",
                "Qwen-14B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Correctness Comparison of ChatGPT4 Gemini Claude3 and Copilot for Spatial Tasks": {
        "filename": "Correctness Comparison of ChatGPT4 Gemini Claude3 and Copilot for Spatial Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "GeoQuestions201",
                "GeoAnQu",
                "GeoQuestions1089"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3",
                "Gemini",
                "Copilot"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Bare Queries Open-Vocabulary Object Grounding with 3D Scene Graph": {
        "filename": "Beyond Bare Queries Open-Vocabulary Object Grounding with 3D Scene Graph.pdf",
        "analysis": {
            "benchmarks": [
                "Replica",
                "ScanNet",
                "Sr3D+",
                "Nr3D",
                "ScanRefer"
            ],
            "base_models": [
                "DINOv2",
                "LLaMA3-8B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "D-RMGPT Robot-assisted collaborative tasks driven by large multimodal models": {
        "filename": "D-RMGPT Robot-assisted collaborative tasks driven by large multimodal models.pdf",
        "analysis": {
            "benchmarks": [
                "Yale-CMU-Berkeley object and model dataset"
            ],
            "base_models": [
                "GPT-4V(ision)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGPT Alternative Solutions Large Language Models Survey": {
        "filename": "ChatGPT Alternative Solutions Large Language Models Survey.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith",
                "GSM8k",
                "HumanEval",
                "MBPP",
                "MMLU",
                "ARC-C",
                "ARC-E",
                "HellaSwag",
                "BoolQ",
                "WinoGrande"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM-540B",
                "LLaMA-65B",
                "LLaMA-13B",
                "GPT-NeoX-20B",
                "BLOOM-176B",
                "Alpaca (based on LLaMA 7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Explore then Determine A GNN-LLM Synergy Framework for Reasoning over Knowledge Graph": {
        "filename": "Explore then Determine A GNN-LLM Synergy Framework for Reasoning over Knowledge Graph.pdf",
        "analysis": {
            "benchmarks": [
                "WebQSP",
                "CWQ",
                "MetaQA"
            ],
            "base_models": [
                "Llama2-13B",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-driven Imitation of Subrational Behavior  Illusion or Reality": {
        "filename": "LLM-driven Imitation of Subrational Behavior  Illusion or Reality.pdf",
        "analysis": {
            "benchmarks": [
                "Ultimatum Game",
                "Stanford Marshmallow Experiment",
                "Double or Nothing Gamble",
                "Procrastination Experiment"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-step planning with learned effects of partial action executions": {
        "filename": "Multi-step planning with learned effects of partial action executions.pdf",
        "analysis": {
            "benchmarks": [
                "lever-up action dataset",
                "CoppeliaSim simulation dataset"
            ],
            "base_models": [
                "Conditional Neural Processes",
                "LSTM"
            ]
        }
    },
    "Seq-VCR Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning": {
        "filename": "Seq-VCR Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "5x5 integer multiplication task",
                "Arithmetic Expression",
                "Longest Increasing Subsequence (LIS)"
            ],
            "base_models": [
                "GPT-2 Small",
                "minGPT"
            ]
        }
    },
    "Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow": {
        "filename": "Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow.pdf",
        "analysis": {
            "benchmarks": [
                "North American Universe",
                "European Universe",
                "Emerging Markets Universe"
            ],
            "base_models": [
                "DeBERTa",
                "Mistral-7B",
                "Llama3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Models to Improve REST API Testing": {
        "filename": "Leveraging Large Language Models to Improve REST API Testing.pdf",
        "analysis": {
            "benchmarks": [
                "FDIC Bank Data",
                "Genome Nexus",
                "LanguageTool",
                "OCVN",
                "OhSome",
                "OMDb",
                "REST Countries",
                "Spotify",
                "YouTube"
            ],
            "base_models": [
                "GPT-3.5 Turbo"
            ]
        }
    },
    "Professional Agents - Evolving Large Language Models into Autonomous Experts with Human-Level Competencies": {
        "filename": "Professional Agents - Evolving Large Language Models into Autonomous Experts with Human-Level Competencies.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "PaLM",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HAMMR HierArchical MultiModal React agents for generic VQA": {
        "filename": "HAMMR HierArchical MultiModal React agents for generic VQA.pdf",
        "analysis": {
            "benchmarks": [
                "PointQA",
                "EncyclopedicVQA",
                "NLVR2",
                "GQA",
                "TallyQA",
                "TextVQA"
            ],
            "base_models": [
                "PaLM 2",
                "BLIP-2 T5-XXL",
                "PaLI-X 55B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bot or Human Detecting ChatGPT Imposters with A Single Question": {
        "filename": "Bot or Human Detecting ChatGPT Imposters with A Single Question.pdf",
        "analysis": {
            "benchmarks": [
                "Counting Dataset",
                "Substitution Dataset",
                "Random Editing Dataset",
                "Searching Dataset",
                "ASCII Art Reasoning Dataset",
                "Memorization Dataset",
                "Computation Dataset"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2-13b",
                "LLaMA-2-70b",
                "Vicuna-13b",
                "GPT-3",
                "GPT-3.5"
            ]
        }
    },
    "Tool Learning with Foundation Models": {
        "filename": "Tool Learning with Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "Custom dataset with 18 representative tools"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bootstrapping Multilingual Semantic Parsers using Large Language Models": {
        "filename": "Bootstrapping Multilingual Semantic Parsers using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MTOP",
                "MASSIVE"
            ],
            "base_models": [
                "PaLM-8B",
                "PaLM-62B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SelfEvolve A Code Evolution Framework via Large Language Models": {
        "filename": "SelfEvolve A Code Evolution Framework via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "DS-1000",
                "HumanEval",
                "TransCoder"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Recover A Neuro-Symbolic Framework for Failure Detection and Recovery": {
        "filename": "Recover A Neuro-Symbolic Framework for Failure Detection and Recovery.pdf",
        "analysis": {
            "benchmarks": [
                "OntoThor"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "How Far Are We to GPT-4V Closing the Gap to Commercial Multimodal Models with Open-Source Suites": {
        "filename": "How Far Are We to GPT-4V Closing the Gap to Commercial Multimodal Models with Open-Source Suites.pdf",
        "analysis": {
            "benchmarks": [
                "DocVQA",
                "ChartQA",
                "InfoVQA",
                "TextVQA",
                "OCRBench",
                "RealWorldQA",
                "AI2D",
                "MMMU",
                "MMBench-EN",
                "MMBench-CN",
                "CCBench",
                "MMVet",
                "SEED",
                "HallusionBench",
                "MathVista"
            ],
            "base_models": [
                "InternViT-6B",
                "InternLM2-20B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ArguGPT evaluating understanding and identifying argumentative essays generated by GPT models": {
        "filename": "ArguGPT evaluating understanding and identifying argumentative essays generated by GPT models.pdf",
        "analysis": {
            "benchmarks": [
                "ArguGPT corpus",
                "Out-of-Distribution (OOD) test set"
            ],
            "base_models": [
                "GPT2-XL",
                "text-babbage-001",
                "text-curie-001",
                "text-davinci-001",
                "text-davinci-002",
                "text-davinci-003",
                "gpt-3.5-turbo",
                "gpt-4",
                "claude-instant",
                "bloomz-7b",
                "flan-t5-11b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Words to Wheels Vision-Based Autonomous Driving Understanding Human Language Instructions Using Foundation Models": {
        "filename": "Words to Wheels Vision-Based Autonomous Driving Understanding Human Language Instructions Using Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "RUGD",
                "RELLIS-3D"
            ],
            "base_models": [
                "GPT-4",
                "YOLO-World",
                "EfficientViT-SAM",
                "CLIP-ViT-B-32",
                "GANav"
            ]
        }
    },
    "Large Language Models are In-context Teachers for Knowledge Reasoning": {
        "filename": "Large Language Models are In-context Teachers for Knowledge Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "MedMCQA",
                "MedQA"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama2-7B",
                "Llama2-13B",
                "Mistral-7B",
                "Phi3-128k-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Persona to Personalization A Survey on Role-Playing Language Agents": {
        "filename": "From Persona to Personalization A Survey on Role-Playing Language Agents.pdf",
        "analysis": {
            "benchmarks": [
                "PDP",
                "Character-LLM",
                "ChatHaruhi",
                "RoleLLM",
                "HPD",
                "CharacterGLM",
                "PIPPA",
                "RoleEval",
                "CharacterEval",
                "DITTO",
                "RolePersonality",
                "MORTISE",
                "CroSS-MR",
                "SocialBench",
                "TimeChara",
                "LifeChoice",
                "MMRole",
                "InCharacter",
                "PersonaHub"
            ],
            "base_models": [
                "LaMDA",
                "GPT-3",
                "GPT-4",
                "BERT",
                "T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Images in Language Space Exploring the Suitability of Large Language Models for Vision  Language Tasks": {
        "filename": "Images in Language Space Exploring the Suitability of Large Language Models for Vision  Language Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MAMI",
                "HF",
                "MVSA",
                "OK-VQA",
                "NLVR2"
            ],
            "base_models": [
                "GPT-3",
                "Flan-T5 (xxl)",
                "T0pp",
                "OPT (2.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM as Dataset Analyst Subpopulation Structure Discovery with Large Language Model": {
        "filename": "LLM as Dataset Analyst Subpopulation Structure Discovery with Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Waterbirds",
                "Metashift",
                "Nico++",
                "ImageNet"
            ],
            "base_models": [
                "GPT-4",
                "LLaVA1.5"
            ]
        }
    },
    "Interlinking User Stories and GUI Prototyping A Semi-Automatic LLM-Based Approach": {
        "filename": "Interlinking User Stories and GUI Prototyping A Semi-Automatic LLM-Based Approach.pdf",
        "analysis": {
            "benchmarks": [
                "Rico GUI repository"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Social Learning Towards Collaborative Learning with Large Language Models": {
        "filename": "Social Learning Towards Collaborative Learning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SMS Spam",
                "Lambada",
                "BoolQ",
                "GSM8K",
                "Random Insertion"
            ],
            "base_models": [
                "PaLM 2-S",
                "OpenAI GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ThreatModeling-LLM Automating Threat Modeling using Large Language Models for Banking System": {
        "filename": "ThreatModeling-LLM Automating Threat Modeling using Large Language Models for Banking System.pdf",
        "analysis": {
            "benchmarks": [
                "Microsoft Threat Modeling Tool (TMT) generated dataset"
            ],
            "base_models": [
                "Llama-3.1-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Zero-shot Sequential Neuro-symbolic Reasoning for Automatically Generating Architecture Schematic Designs": {
        "filename": "Zero-shot Sequential Neuro-symbolic Reasoning for Automatically Generating Architecture Schematic Designs.pdf",
        "analysis": {
            "benchmarks": [
                "real-world buildings"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Detecting Phishing Sites Using ChatGPT": {
        "filename": "Detecting Phishing Sites Using ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset"
            ],
            "base_models": [
                "GPT-4V",
                "GPT-4",
                "GPT-3.5",
                "Llama-2-70B",
                "Gemini Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Meet NL2Code A Survey": {
        "filename": "Large Language Models Meet NL2Code A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP"
            ],
            "base_models": [
                "Codex (12B)",
                "AlphaCode (41.1B)",
                "InCoder (6.7B)",
                "CodeGen (16.1B)",
                "PaLM-Coder (540B)",
                "SantaCoder (1.1B)",
                "GPT-NeoX (20B)",
                "BLOOM (176B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning in Transformers - Mitigating Spurious Correlations and Reasoning Shortcuts": {
        "filename": "Reasoning in Transformers - Mitigating Spurious Correlations and Reasoning Shortcuts.pdf",
        "analysis": {
            "benchmarks": [
                "SimpleLogic",
                "SimpleLogicPS"
            ],
            "base_models": [
                "BART",
                "BERT"
            ]
        }
    },
    "Real-World Robot Applications of Foundation Models A Review": {
        "filename": "Real-World Robot Applications of Foundation Models A Review.pdf",
        "analysis": {
            "benchmarks": [
                "Ego4D",
                "ImageNet",
                "EPIC-KITCHENS"
            ],
            "base_models": [
                "GPT-3",
                "LLaMA",
                "CLIP",
                "BERT",
                "RoBERTa",
                "PaLM-E",
                "RT-1",
                "RT-2",
                "R3M",
                "VC-1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Reason via Program Generation Emulation and Search": {
        "filename": "Learning to Reason via Program Generation Emulation and Search.pdf",
        "analysis": {
            "benchmarks": [
                "CoLA",
                "Emotion",
                "SST2",
                "CommonsenseQA",
                "Social IQa",
                "Word Sorting",
                "SVAMP",
                "Coin Flip",
                "Number Summing"
            ],
            "base_models": [
                "Llama-2 7B",
                "Llama-2 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PathOCl Path-Based Prompt Augmentation for OCL Generation with GPT-4": {
        "filename": "PathOCl Path-Based Prompt Augmentation for OCL Generation with GPT-4.pdf",
        "analysis": {
            "benchmarks": [
                "Royal & Loyal domain model"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "ManiTweet A New Benchmark for Identifying Manipulation of News on Social Media": {
        "filename": "ManiTweet A New Benchmark for Identifying Manipulation of News on Social Media.pdf",
        "analysis": {
            "benchmarks": [
                "MANITWEET"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-turbo)",
                "Vicuna (LLaMA-based)",
                "LED (LongFormer-Encoder-Decoder)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Model for Automatic Evolving of Industrial Data-Centric RD Cycle": {
        "filename": "Leveraging Large Language Model for Automatic Evolving of Industrial Data-Centric RD Cycle.pdf",
        "analysis": {
            "benchmarks": [
                "Qlib"
            ],
            "base_models": [
                "GPT-4-32K"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When Qualitative Research Meets Large Language Model Exploring the Potential of QualiGPT as a Tool for Qualitative Coding": {
        "filename": "When Qualitative Research Meets Large Language Model Exploring the Potential of QualiGPT as a Tool for Qualitative Coding.pdf",
        "analysis": {
            "benchmarks": [
                "simulated focus group dataset on transitioning to remote work",
                "real social media dataset from a public Discord channel"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "GPT-4o",
                "Claude 3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MindStar Enhancing Math Reasoning in Pre-trained LLMs at Inference Time": {
        "filename": "MindStar Enhancing Math Reasoning in Pre-trained LLMs at Inference Time.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "Llama-2-13B",
                "Mistral-7B",
                "GPT-3.5",
                "Grok-1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Baldur Whole-Proof Generation and Repair with Large Language Models": {
        "filename": "Baldur Whole-Proof Generation and Repair with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PISA dataset"
            ],
            "base_models": [
                "Minerva-8B",
                "Minerva-62B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evolving AI Collectives to Enhance Human Diversity and Enable Self-Regulation": {
        "filename": "Evolving AI Collectives to Enhance Human Diversity and Enable Self-Regulation.pdf",
        "analysis": {
            "benchmarks": [
                "Public Goods Game"
            ],
            "base_models": [
                "Claude-2.1",
                "Claude-3-Opus",
                "Gemini Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Making Network Configuration Human Friendly": {
        "filename": "Making Network Configuration Human Friendly.pdf",
        "analysis": {
            "benchmarks": [
                "Kathará network emulator"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "ChipGPT How far are we from natural language hardware design": {
        "filename": "ChipGPT How far are we from natural language hardware design.pdf",
        "analysis": {
            "benchmarks": [
                "matrix multiplication",
                "4x1 multiplexer",
                "3-to-8 decoder",
                "button count",
                "vector matrix multiplication",
                "add multiply tree",
                "accumulator",
                "simple CPU"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Words to Wheels Automated Style-Customized Policy Generation for Autonomous Driving": {
        "filename": "From Words to Wheels Automated Style-Customized Policy Generation for Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "HighD dataset"
            ],
            "base_models": [
                "GPT-4o-2024-08-06"
            ]
        }
    },
    "Do NOT Think That Much for 23 On the Overthinking of o1-Like LLMs": {
        "filename": "Do NOT Think That Much for 23 On the Overthinking of o1-Like LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH500",
                "GPQA",
                "AIME",
                "ASDIV"
            ],
            "base_models": [
                "QwQ-32B-Preview",
                "DeepSeek-R1-Preview",
                "Llama-3.3-70B",
                "Qwen2.5-Math-72B",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EMMA End-to-End Multimodal Model for Autonomous Driving": {
        "filename": "EMMA End-to-End Multimodal Model for Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "nuScenes",
                "Waymo Open Motion Dataset (WOMD)",
                "Waymo Open Dataset (WOD)"
            ],
            "base_models": [
                "Gemini 1.0 Nano-1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Model-based Room-Object Relationships Knowledge for Enhancing Multimodal-Input Object Goal Navigation": {
        "filename": "Leveraging Large Language Model-based Room-Object Relationships Knowledge for Enhancing Multimodal-Input Object Goal Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "Habitat simulator",
                "real-world house-like environment"
            ],
            "base_models": [
                "GPT-4",
                "Swin-Unet",
                "CLIP (ViT-B/32)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "UL2 Unifying Language Learning Paradigms": {
        "filename": "UL2 Unifying Language Learning Paradigms.pdf",
        "analysis": {
            "benchmarks": [
                "SuperGLUE",
                "GEM benchmark (including XSUM, ToTTo, Schema Guided Dialog)"
            ],
            "base_models": [
                "T5",
                "GPT-like (Causal Language Model)",
                "UniLM",
                "UL2 (20B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Know Your Contextual Search Intent A Prompting Framework for Conversational Search": {
        "filename": "Large Language Models Know Your Contextual Search Intent A Prompting Framework for Conversational Search.pdf",
        "analysis": {
            "benchmarks": [
                "CAsT-19",
                "CAsT-20",
                "CAsT-21"
            ],
            "base_models": [
                "GPT-3.5-turbo-16k"
            ]
        }
    },
    "Deepfake definitions performance metrics and standards datasets and a meta-review": {
        "filename": "Deepfake definitions performance metrics and standards datasets and a meta-review.pdf",
        "analysis": {
            "benchmarks": [
                "FaceForensics++",
                "Celeb-DF v2"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Compact Language Models via Pruning and Knowledge Distillation": {
        "filename": "Compact Language Models via Pruning and Knowledge Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "HumanEval",
                "Arc-C",
                "HellaSwag",
                "TruthfulQA",
                "WinoGrande",
                "XL-Sum English"
            ],
            "base_models": [
                "Nemotron-4 15B",
                "LLaMa-2 7B",
                "Mistral 7B",
                "Gemma 7B",
                "Llama-3 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CLAIM Your Data Enhancing Imputation Accuracy with Contextual Large Language Models": {
        "filename": "CLAIM Your Data Enhancing Imputation Accuracy with Contextual Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "UCI Wine dataset",
                "Glass Identification",
                "Seeds",
                "Wine Quality"
            ],
            "base_models": [
                "LLaMA 2 (7B)"
            ]
        }
    },
    "ROSE Revolutionizing Open-Set Dense Segmentation with Patch-Wise Perceptual Large Multimodal Model": {
        "filename": "ROSE Revolutionizing Open-Set Dense Segmentation with Patch-Wise Perceptual Large Multimodal Model.pdf",
        "analysis": {
            "benchmarks": [
                "ADE-20k",
                "COCO",
                "RefCOCO",
                "RefCOCO+",
                "RefCOCOg"
            ],
            "base_models": [
                "LLaVA-OneVision-7B",
                "ViT-H SAM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Investigation of Large Language Models for Real-World Hate Speech Detection": {
        "filename": "An Investigation of Large Language Models for Real-World Hate Speech Detection.pdf",
        "analysis": {
            "benchmarks": [
                "HateXplain",
                "COVID-HATE",
                "CallMeSexist",
                "USElectionHate",
                "SWSR"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-turbo, 175 billion parameters)",
                "BERT-base",
                "RoBERTa"
            ]
        }
    },
    "Blocks as Probes Dissecting Categorization Ability of Large Multimodal Models": {
        "filename": "Blocks as Probes Dissecting Categorization Ability of Large Multimodal Models.pdf",
        "analysis": {
            "benchmarks": [
                "ComBo"
            ],
            "base_models": [
                "CLIP",
                "GPT-4V",
                "Gemini-1.5-Pro",
                "LLaVA-v1.5-13B",
                "Qwen-VL-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When Scaling Meets LLM Finetuning The Effect of Data Model and Finetuning Method": {
        "filename": "When Scaling Meets LLM Finetuning The Effect of Data Model and Finetuning Method.pdf",
        "analysis": {
            "benchmarks": [
                "WMT14 En-De",
                "WMT19 En-Zh",
                "MLSum"
            ],
            "base_models": [
                "GPT-4",
                "PaLM 2",
                "En-De LLM (1B to 16B)",
                "En-Zh LLM (1B to 16B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathVC An LLM-Simulated Multi-Character Virtual Classroom for Mathematics Education": {
        "filename": "MathVC An LLM-Simulated Multi-Character Virtual Classroom for Mathematics Education.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "MAP (Mathematics Assessment Project)"
            ],
            "base_models": [
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLM Find the Green Circle Investigation and Human-Guided Tool Manipulation for Compositional Generalization": {
        "filename": "Can LLM Find the Green Circle Investigation and Human-Guided Tool Manipulation for Compositional Generalization.pdf",
        "analysis": {
            "benchmarks": [
                "ReaSCAN",
                "GSRR"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ]
        }
    },
    "AI Robustness a Human-Centered Perspective on Technological Challenges and Opportunities": {
        "filename": "AI Robustness a Human-Centered Perspective on Technological Challenges and Opportunities.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Synergize with Automated Machine Learning": {
        "filename": "Large Language Models Synergize with Automated Machine Learning.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "CIFAR-10",
                "CIFAR-100",
                "IMDb Reviews",
                "AG News"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "PaLM 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Empathy-Based Sandbox Approach to Bridge the Privacy Gap among Attitudes Goals Knowledge and Behaviors": {
        "filename": "An Empathy-Based Sandbox Approach to Bridge the Privacy Gap among Attitudes Goals Knowledge and Behaviors.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LARP Language-Agent Role Play for Open-World Games": {
        "filename": "LARP Language-Agent Role Play for Open-World Games.pdf",
        "analysis": {
            "benchmarks": [
                "Minecraft"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "UDA A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis": {
        "filename": "UDA A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "UDA"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "Llama-3-8B",
                "Llama-3-70B",
                "Qwen-1.5-32B",
                "Qwen-1.5-7B",
                "Mixtral-8x7B",
                "Mistral-7B",
                "CodeLlama-7B",
                "CodeLlama-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Quantitative and Qualitative Evaluation of LLM-Based Explainable Fault Localization": {
        "filename": "A Quantitative and Qualitative Evaluation of LLM-Based Explainable Fault Localization.pdf",
        "analysis": {
            "benchmarks": [
                "Defects4J",
                "BugsInPy"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4": {
        "filename": "A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-3.5",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LiP-LLM Integrating Linear Programming and Dependency Graph With Large Language Models for Multi-Robot Task Planning": {
        "filename": "LiP-LLM Integrating Linear Programming and Dependency Graph With Large Language Models for Multi-Robot Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "AWS RoboMaker Small House World ROS package"
            ],
            "base_models": [
                "GPT-4-0613",
                "text-davinci-003"
            ]
        }
    },
    "MedFuzz Exploring the Robustness of Large Language Models in Medical Question Answering": {
        "filename": "MedFuzz Exploring the Robustness of Large Language Models in Medical Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-3.5",
                "OpenBioLLM-70B",
                "Meditron-70B",
                "BioMistral-7B",
                "Medllama3-v20"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Healthcare Copilot Eliciting the Power of General LLMs for Medical Consultation": {
        "filename": "Healthcare Copilot Eliciting the Power of General LLMs for Medical Consultation.pdf",
        "analysis": {
            "benchmarks": [
                "USMLE",
                "MedMCQA",
                "PubMedQA",
                "MedDialog"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "LLaMA-2",
                "ChatGLM3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors": {
        "filename": "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors.pdf",
        "analysis": {
            "benchmarks": [
                "FewRel",
                "Wiki-ZSL"
            ],
            "base_models": [
                "GPT-2 (117M)",
                "GPT-2-large (770M)",
                "GPT-2-XL (1.5B)",
                "T5-base (220M)",
                "T5-large (770M)",
                "T5-3B",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MetaGPT Meta Programming for A Multi-Agent Collaborative Framework": {
        "filename": "MetaGPT Meta Programming for A Multi-Agent Collaborative Framework.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "SoftwareDev"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MUSTARD Mastering Uniform Synthesis of Theorem and Proof Data": {
        "filename": "MUSTARD Mastering Uniform Synthesis of Theorem and Proof Data.pdf",
        "analysis": {
            "benchmarks": [
                "MUSTARD SAUCE",
                "GSM8K",
                "Mathlib",
                "miniF2F"
            ],
            "base_models": [
                "Llama 2-7B",
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLaMA Rider Spurring Large Language Models to Explore the Open World": {
        "filename": "LLaMA Rider Spurring Large Language Models to Explore the Open World.pdf",
        "analysis": {
            "benchmarks": [
                "MineDojo (Minecraft)"
            ],
            "base_models": [
                "LLaMA-2-70B-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OlaGPT Empowering LLMs With Human-like Problem-Solving Abilities": {
        "filename": "OlaGPT Empowering LLMs With Human-like Problem-Solving Abilities.pdf",
        "analysis": {
            "benchmarks": [
                "AQuA",
                "E-KAR (Chinese)"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RAGBench Explainable Benchmark for Retrieval-Augmented Generation Systems": {
        "filename": "RAGBench Explainable Benchmark for Retrieval-Augmented Generation Systems.pdf",
        "analysis": {
            "benchmarks": [
                "RAGBench",
                "CovidQA",
                "PubmedQA",
                "HotpotQA",
                "MS Marco",
                "CUAD",
                "EManual",
                "TechQA",
                "FinQA",
                "TAT-QA",
                "ExpertQA",
                "HAGRID",
                "DelucionQA"
            ],
            "base_models": [
                "RoBERTa",
                "DeBERTa-large",
                "GPT-3.5",
                "Claude 3 Haiku"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generating Explanations in Medical Question-Answering by Expectation Maximization Inference over Evidence": {
        "filename": "Generating Explanations in Medical Question-Answering by Expectation Maximization Inference over Evidence.pdf",
        "analysis": {
            "benchmarks": [
                "MQAE-diag",
                "MQAE"
            ],
            "base_models": [
                "BART (base)"
            ]
        }
    },
    "BayesPrompt Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction": {
        "filename": "BayesPrompt Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval 2010 Task 8",
                "TACRED",
                "TACREV",
                "ReTACRED"
            ],
            "base_models": [
                "KnowPrompt",
                "RetrievalRE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatABL Abductive Learning via Natural Language Interaction with ChatGPT": {
        "filename": "ChatABL Abductive Learning via Natural Language Interaction with ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "variable-length handwritten equation deciphering task"
            ],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SPARQL Generation an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph": {
        "filename": "SPARQL Generation an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph.pdf",
        "analysis": {
            "benchmarks": [
                "Bgee gene expression knowledge graph",
                "KQA Pro dataset"
            ],
            "base_models": [
                "OpenLLaMA_7b_v2 (7 billion parameters)"
            ]
        }
    },
    "Language-Conditioned Robotic Manipulation with Fast and Slow Thinking": {
        "filename": "Language-Conditioned Robotic Manipulation with Fast and Slow Thinking.pdf",
        "analysis": {
            "benchmarks": [
                "VIMA-Bench",
                "custom real-world dataset with nine tasks"
            ],
            "base_models": [
                "Distil-RoBERTa",
                "LLaMA-2-7B",
                "ViT-L/14 from CLIP"
            ]
        }
    },
    "ComposerX Multi-Agent Symbolic Music Composition with LLMs": {
        "filename": "ComposerX Multi-Agent Symbolic Music Composition with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Irishman",
                "KernScores"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-4-0314",
                "GPT-3.5-turbo"
            ]
        }
    },
    "Verify-and-Edit A Knowledge-Enhanced Chain-of-Thought Framework": {
        "filename": "Verify-and-Edit A Knowledge-Enhanced Chain-of-Thought Framework.pdf",
        "analysis": {
            "benchmarks": [
                "Adversarial HotpotQA",
                "2WikiMultihop",
                "Fever"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Thought Prompt Distillation for Multimodal Named Entity Recognition and Multimodal Relation Extraction": {
        "filename": "Chain-of-Thought Prompt Distillation for Multimodal Named Entity Recognition and Multimodal Relation Extraction.pdf",
        "analysis": {
            "benchmarks": [
                "Twitter2015",
                "Twitter2017",
                "SNAP",
                "WikiDiverse",
                "MNRE"
            ],
            "base_models": [
                "BERT-base-uncased",
                "XLM-RoBERTa-large",
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-4"
            ]
        }
    },
    "Enhancing Text Annotation through Rationale-Driven Collaborative Few-Shot Prompting": {
        "filename": "Enhancing Text Annotation through Rationale-Driven Collaborative Few-Shot Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "SST-5",
                "AG News",
                "DBPedia"
            ],
            "base_models": [
                "Qwen-72B",
                "Qwen-14B",
                "Qwen-7B",
                "LLaMA3-70B",
                "LLaMA3-8B"
            ]
        }
    },
    "UVLLM An Automated Universal RTL Verification Framework using LLMs": {
        "filename": "UVLLM An Automated Universal RTL Verification Framework using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "RTLLM dataset",
                "custom error dataset with 331 code instances"
            ],
            "base_models": [
                "GPT-4-turbo"
            ]
        }
    },
    "Learning and Forgetting Unsafe Examples in Large Language Models": {
        "filename": "Learning and Forgetting Unsafe Examples in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BBQ",
                "Pile",
                "HarmfulQA",
                "SQuAD"
            ],
            "base_models": [
                "LLaMA-7B",
                "GPT2-XL (1.5B)",
                "GPT2-L (774M)",
                "GPT2-M (334M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Deciphering Human Mobility Inferring Semantics of Trajectories with Large Language Models": {
        "filename": "Deciphering Human Mobility Inferring Semantics of Trajectories with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Shenzhen individual trajectory dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "BRIGHT A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval": {
        "filename": "BRIGHT A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "BRIGHT"
            ],
            "base_models": [
                "SFR-Embedding-Mistral (7.1B)",
                "GritLM (7.1B)",
                "gte-Qwen1.5 (7.7B)",
                "Instructor-XL (1.5B)",
                "E5-Mistral (7.1B)",
                "Cohere",
                "Voyage",
                "OpenAI",
                "Google (1.2B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment": {
        "filename": "Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "WoW",
                "CMU_DoG"
            ],
            "base_models": [
                "GPT2-Medium",
                "GPT2-Large",
                "GPT2-XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models can Achieve Social Balance": {
        "filename": "Large Language Models can Achieve Social Balance.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Llama 3 70B",
                "Llama 3 8B",
                "Mistral 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Step-Controlled DPO Leveraging Stepwise Error for Enhanced Mathematical Reasoning": {
        "filename": "Step-Controlled DPO Leveraging Stepwise Error for Enhanced Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "InternLM2-20B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Can Recommender Systems Benefit from Large Language Models A Survey": {
        "filename": "How Can Recommender Systems Benefit from Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Joint Estimation and Prediction of City-wide Delivery Demand A Large Language Model Empowered Graph-based Learning Approach": {
        "filename": "Joint Estimation and Prediction of City-wide Delivery Demand A Large Language Model Empowered Graph-based Learning Approach.pdf",
        "analysis": {
            "benchmarks": [
                "real-world delivery datasets from eight cities in China and the US"
            ],
            "base_models": [
                "Llama (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing In-context Learning via Linear Probe Calibration": {
        "filename": "Enhancing In-context Learning via Linear Probe Calibration.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "SST-5",
                "AGNews",
                "TREC",
                "DBPedia",
                "RTE",
                "Subj",
                "OpenML datasets"
            ],
            "base_models": [
                "GPT-2-XL (1.5B)",
                "GPT-J (6B)",
                "Llama-2 (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding LLMs Requires More Than Statistical Generalization": {
        "filename": "Understanding LLMs Requires More Than Statistical Generalization.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175B)",
                "LLaMA (various sizes)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course": {
        "filename": "Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course.pdf",
        "analysis": {
            "benchmarks": [
                "custom robotics course test dataset"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "LLaMA-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Successive Prompting for Decomposing Complex Questions": {
        "filename": "Successive Prompting for Decomposing Complex Questions.pdf",
        "analysis": {
            "benchmarks": [
                "DROP",
                "HotpotQA"
            ],
            "base_models": [
                "GPT-J (6B)",
                "T5-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of NL2SQL with Large Language Models Where are we and where are we going": {
        "filename": "A Survey of NL2SQL with Large Language Models Where are we and where are we going.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "BIRD",
                "BULL"
            ],
            "base_models": [
                "GPT-4",
                "StarCoder"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Large Language Models in Cybersecurity": {
        "filename": "A Survey of Large Language Models in Cybersecurity.pdf",
        "analysis": {
            "benchmarks": [
                "Capture-The-Flag Challenges",
                "Cisco certifications"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM 2",
                "Prometheus",
                "ChatGPT-3.5-turbo",
                "LaMDA",
                "code-cushman-001",
                "code-davinci-001",
                "code-davinci-002",
                "j1-jumbo",
                "j1-large",
                "polycoder",
                "gpt2-csrc",
                "RoBERTa",
                "SecureBERT",
                "FalconLLM",
                "BERT",
                "DistilBERT",
                "CodeBERT",
                "GPT-2",
                "MegatronBERT",
                "MegatronGPT-2",
                "GPT-J",
                "CodeT5"
            ]
        }
    },
    "Suspicion-Agent Playing Imperfect Information Games with Theory of Mind Aware GPT-4": {
        "filename": "Suspicion-Agent Playing Imperfect Information Games with Theory of Mind Aware GPT-4.pdf",
        "analysis": {
            "benchmarks": [
                "Leduc Hold'em"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs as Potential Brainstorming Partners for Math and Science Problems": {
        "filename": "LLMs as Potential Brainstorming Partners for Math and Science Problems.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Combining Ontological Knowledge and Large Language Model for User-Friendly Service Robots": {
        "filename": "Combining Ontological Knowledge and Large Language Model for User-Friendly Service Robots.pdf",
        "analysis": {
            "benchmarks": [
                "bring-me tasks (custom dataset)"
            ],
            "base_models": [
                "Llama 2 (13B)"
            ]
        }
    },
    "Dynamic Universal Approximation Theory The Basic Theory for Transformer-based Large Language Models": {
        "filename": "Dynamic Universal Approximation Theory The Basic Theory for Transformer-based Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "Llama",
                "PaLM-540B",
                "GPT-3 (175 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CursorCore Assist Programming through Aligning Anything": {
        "filename": "CursorCore Assist Programming through Aligning Anything.pdf",
        "analysis": {
            "benchmarks": [
                "APEval (Assist Programming Eval)"
            ],
            "base_models": [
                "Deepseek-Coder-1.3B",
                "Yi-Coder-9B",
                "Qwen2.5-Coder-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Engineer Too Many Simple Features For Tabular Data": {
        "filename": "Large Language Models Engineer Too Many Simple Features For Tabular Data.pdf",
        "analysis": {
            "benchmarks": [
                "ada",
                "adult",
                "amazon_employee_access",
                "australian",
                "bank-marketing",
                "blood-transfusion-service-center",
                "car",
                "churn",
                "click_prediction_small",
                "cmc",
                "connect-4",
                "credit-g",
                "eucalyptus",
                "first-order-theorem-proving",
                "gesturephasesegmentationprocessed",
                "jannis",
                "jungle_chess_2pcs_raw_endgame_complete",
                "kc1",
                "kick",
                "kr-vs-kp",
                "numerai28.6",
                "okcupid-stem",
                "ozone-level.8hr",
                "pc4",
                "phishingwebsites",
                "phoneme",
                "qsar-biodeg"
            ],
            "base_models": [
                "GPT-4o-mini",
                "Gemini-1.5-flash",
                "Llama3.1-8B",
                "Mistral7B-v0.3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Marco-o1 Towards Open Reasoning Models for Open-Ended Solutions": {
        "filename": "Marco-o1 Towards Open Reasoning Models for Open-Ended Solutions.pdf",
        "analysis": {
            "benchmarks": [
                "MGSM (English)",
                "MGSM (Chinese)"
            ],
            "base_models": [
                "Qwen2-7B-Instruct"
            ]
        }
    },
    "Benchmarking Large Language Model Capabilities for Conditional Generation": {
        "filename": "Benchmarking Large Language Model Capabilities for Conditional Generation.pdf",
        "analysis": {
            "benchmarks": [
                "E2E",
                "WebNLG",
                "ToTTo",
                "Czech Restaurant",
                "XSum",
                "WikiLingua",
                "MLSum",
                "XL-Sum"
            ],
            "base_models": [
                "PaLM (8B and 540B)",
                "GPT-3.5 (175B)",
                "ST-MoE (269B)",
                "LaMDA (137B)",
                "T5-XXL (11B)",
                "mT5-XXL (11B)",
                "LongT5 (3B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Foundation Model Sherpas Guiding Foundation Models through Knowledge and Reasoning": {
        "filename": "Foundation Model Sherpas Guiding Foundation Models through Knowledge and Reasoning.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "InfeRE Step-by-Step Regex Generation via Chain of Inference": {
        "filename": "InfeRE Step-by-Step Regex Generation via Chain of Inference.pdf",
        "analysis": {
            "benchmarks": [
                "NL-RX-Turk",
                "KB13"
            ],
            "base_models": [
                "T5-base",
                "T5-small",
                "BART-base",
                "BART-small",
                "GPT2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations": {
        "filename": "Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations.pdf",
        "analysis": {
            "benchmarks": [
                "DoQA",
                "QuAC"
            ],
            "base_models": [
                "FALCON-40B",
                "FLAN-UL2-20B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DrICL Demonstration-Retrieved In-context Learning": {
        "filename": "DrICL Demonstration-Retrieved In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "NQ",
                "ANLI-r3",
                "GSM8k",
                "AQuA",
                "StrategyQA"
            ],
            "base_models": [
                "PaLM-540B",
                "Flan-PaLM-540B"
            ]
        }
    },
    "Fine-tune Language Models to Approximate Unbiased In-context Learning": {
        "filename": "Fine-tune Language Models to Approximate Unbiased In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "numerical dataset"
            ],
            "base_models": [
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Human-Computer Collaborative Tool for Training a Single Large Language Model Agent into a Network through Few Examples": {
        "filename": "A Human-Computer Collaborative Tool for Training a Single Large Language Model Agent into a Network through Few Examples.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ModelGPT Unleashing LLMs Capabilities for Tailored Model Generation": {
        "filename": "ModelGPT Unleashing LLMs Capabilities for Tailored Model Generation.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE Benchmark",
                "Office-31",
                "UCI Machine Learning Repository"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "Distil-BERT base",
                "ResNet-50"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs Killed the Script Kiddie How Agents Supported by Large Language Models Change the Landscape of Network Threat Testing": {
        "filename": "LLMs Killed the Script Kiddie How Agents Supported by Large Language Models Change the Landscape of Network Threat Testing.pdf",
        "analysis": {
            "benchmarks": [
                "Metasploitable 2"
            ],
            "base_models": [
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Let Models Speak Ciphers Multiagent Debate through Embeddings": {
        "filename": "Let Models Speak Ciphers Multiagent Debate through Embeddings.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "Arithmetic",
                "MMLU Formal Logic",
                "MMLU High School Math",
                "MMLU Professional Psychology"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-v1.3",
                "LLaMA2-70B",
                "LLaMA-65B",
                "Falcon-40B-Instruct",
                "MPT-30B",
                "WizardMath-70B-V1.0"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "T2I-CompBench A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation": {
        "filename": "T2I-CompBench A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation.pdf",
        "analysis": {
            "benchmarks": [
                "T2I-CompBench"
            ],
            "base_models": [
                "Stable Diffusion v2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Public Large Language Models to Synthesize Data for Private On-device Applications": {
        "filename": "Prompt Public Large Language Models to Synthesize Data for Private On-device Applications.pdf",
        "analysis": {
            "benchmarks": [
                "Gboard (real user data)"
            ],
            "base_models": [
                "PaLM 2-S"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RAFT Reward rAnked FineTuning for Generative Foundation Model Alignment": {
        "filename": "RAFT Reward rAnked FineTuning for Generative Foundation Model Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "HH-RLHF dataset"
            ],
            "base_models": [
                "LLaMA-7B",
                "GPT-Neo-2.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-Assisted Visual Analytics Opportunities and Challenges": {
        "filename": "LLM-Assisted Visual Analytics Opportunities and Challenges.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ]
        }
    },
    "ChatSchema A pipeline of extracting structured information with Large Multimodal Models based on schema": {
        "filename": "ChatSchema A pipeline of extracting structured information with Large Multimodal Models based on schema.pdf",
        "analysis": {
            "benchmarks": [
                "Peking University First Hospital medical reports"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini 1.5 Pro"
            ]
        }
    },
    "SDS - See it Do it Sorted Quadruped Skill Synthesis from Single Video Demonstration": {
        "filename": "SDS - See it Do it Sorted Quadruped Skill Synthesis from Single Video Demonstration.pdf",
        "analysis": {
            "benchmarks": [
                "Unitree Go1 robot experiments"
            ],
            "base_models": [
                "GPT-4V(ision)"
            ]
        }
    },
    "MaxMind A Memory Loop Network to Enhance Software Productivity based on Large Language Models": {
        "filename": "MaxMind A Memory Loop Network to Enhance Software Productivity based on Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SheetCopilot test suite (221 tasks)"
            ],
            "base_models": [
                "llama3.1-70B",
                "llama3-70B",
                "llama3-405B",
                "GPT4o"
            ]
        }
    },
    "MedG-KRP Medical Graph Knowledge Representation Probing": {
        "filename": "MedG-KRP Medical Graph Knowledge Representation Probing.pdf",
        "analysis": {
            "benchmarks": [
                "BIOS"
            ],
            "base_models": [
                "GPT-4",
                "Llama3-70b",
                "PalmyraMed-70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Three-Phases SFT Hybrid Model Integrated Strong Prior Module and Data Overlap Estimation in the Eduation Context": {
        "filename": "A Three-Phases SFT Hybrid Model Integrated Strong Prior Module and Data Overlap Estimation in the Eduation Context.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MMLU",
                "C-Eval",
                "AGIEval"
            ],
            "base_models": [
                "LLAMA2-34B"
            ]
        }
    },
    "The Capacity for Moral Self-Correction in Large Language Models": {
        "filename": "The Capacity for Moral Self-Correction in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BBQ",
                "Winogender",
                "Custom racial discrimination benchmark"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-3 (22B)",
                "GPT-3 (52B)",
                "GPT-3 (13B)",
                "GPT-3 (6.4B)",
                "GPT-3 (3.5B)",
                "GPT-3 (1.6B)",
                "GPT-3 (810M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LiveBench A Challenging Contamination-Free LLM Benchmark": {
        "filename": "LiveBench A Challenging Contamination-Free LLM Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "LiveBench",
                "Big-Bench Hard",
                "AMPS",
                "IFEval",
                "AMC12",
                "AIME",
                "USAMO",
                "IMO",
                "SMC",
                "Leetcode",
                "AtCoder",
                "Kaggle",
                "Socrata"
            ],
            "base_models": [
                "GPT-4 (various versions)",
                "GPT-3.5-turbo (various versions)",
                "Claude-3 (various versions)",
                "Mistral (various versions)",
                "Gemini-1.5 (various versions)",
                "Meta-LLaMA-3 (70B)",
                "DeepSeek (various versions)",
                "Qwen (various versions)",
                "Mixtral (various versions)",
                "Phi-3 (various versions)",
                "Zephyr (various versions)",
                "Starling-LM-7B-beta",
                "Teknium/OpenHermes-2.5-Mistral-7B",
                "Vicuna-7B-v1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GraphAgent Agentic Graph Language Assistant": {
        "filename": "GraphAgent Agentic Graph Language Assistant.pdf",
        "analysis": {
            "benchmarks": [
                "IMDB",
                "ACM",
                "Arxiv-Papers",
                "ICLR-Peer Reviews",
                "GovReport"
            ],
            "base_models": [
                "LLaMA-8B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Bias to Balance Detecting Facial Expression Recognition Biases in Large Multimodal Foundation Models": {
        "filename": "From Bias to Balance Detecting Facial Expression Recognition Biases in Large Multimodal Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "RADIATE",
                "Tarr",
                "Chicago Face"
            ],
            "base_models": [
                "GPT-4o",
                "PaliGemma (3B)",
                "Gemini 1.5 Flash",
                "Gemini 1.5 Pro",
                "CLIP"
            ]
        }
    },
    "Diffusion-ES Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following": {
        "filename": "Diffusion-ES Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following.pdf",
        "analysis": {
            "benchmarks": [
                "nuPlan"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Crystal Introspective Reasoners Reinforced with Self-Feedback": {
        "filename": "Crystal Introspective Reasoners Reinforced with Self-Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "OpenBookQA",
                "ARC (easy and hard splits)",
                "AI2Science (elementary and middle splits)",
                "CommonsenseQA",
                "QASC",
                "PhysicalIQA",
                "SocialIQA",
                "Winogrande",
                "Com2Sense",
                "SciQ",
                "QuaRel",
                "QuaRTz",
                "CycIC",
                "ComVE",
                "Winograd Schema Challenge",
                "COPA",
                "NumerSense",
                "PROST",
                "SWAG",
                "HellaSwag",
                "CODAH",
                "Story Cloze Test",
                "αNLI"
            ],
            "base_models": [
                "T5-large (770M)",
                "T5-3b (3B)",
                "T5-11b (11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering": {
        "filename": "Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "WebQuestionsSP",
                "Mintaka"
            ],
            "base_models": [
                "T5 (0.8B, 3B, 11B)",
                "T0 (3B, 11B)",
                "OPT (2.7B, 6.7B, 13B)",
                "GPT-3 (6.7B, 175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Images to Textual Prompts Zero-shot Visual Question Answering with Frozen Large Language Models": {
        "filename": "From Images to Textual Prompts Zero-shot Visual Question Answering with Frozen Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "VQAv2",
                "OK-VQA",
                "A-OKVQA"
            ],
            "base_models": [
                "OPT-6.7B",
                "OPT-13B",
                "OPT-30B",
                "OPT-66B",
                "OPT-175B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Personalized Autonomous Driving with Large Language Models Field Experiments": {
        "filename": "Personalized Autonomous Driving with Large Language Models Field Experiments.pdf",
        "analysis": {
            "benchmarks": [
                "LaMPilot"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Extracting Heuristics from Large Language Models for Reward Shaping in Reinforcement Learning": {
        "filename": "Extracting Heuristics from Large Language Models for Reward Shaping in Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "BabyAI environment suite",
                "Household",
                "Mario",
                "Minecraft"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude",
                "Llama 3 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference": {
        "filename": "Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference.pdf",
        "analysis": {
            "benchmarks": [
                "aNLI",
                "HellaSwag",
                "PIQA",
                "SocialIQA"
            ],
            "base_models": [
                "RoBERTa-large Ensemble",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Verbalized Machine Learning Revisiting Machine Learning with Language Models": {
        "filename": "Verbalized Machine Learning Revisiting Machine Learning with Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Llama-3 70B",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Intern VL Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks": {
        "filename": "Intern VL Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet-1K",
                "ADE20K",
                "Kinetics-400",
                "Kinetics-600",
                "Kinetics-700",
                "Flickr30K",
                "COCO",
                "MSR-VTT",
                "NoCaps",
                "MME",
                "POPE",
                "Tiny LVLM"
            ],
            "base_models": [
                "LLaMA-7B",
                "Vicuna-13B",
                "InternLM",
                "InternViT-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Minimalist Dataset for Systematic Generalization of Perception Syntax and Semantics": {
        "filename": "A Minimalist Dataset for Systematic Generalization of Perception Syntax and Semantics.pdf",
        "analysis": {
            "benchmarks": [
                "HINT"
            ],
            "base_models": [
                "RNNs",
                "Transformers",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Secrets of RLHF in Large Language Models Part I PPO": {
        "filename": "Secrets of RLHF in Large Language Models Part I PPO.pdf",
        "analysis": {
            "benchmarks": [
                "HH-RLHF dataset (evaluation subset)",
                "Custom Chinese dataset (evaluation subset)"
            ],
            "base_models": [
                "LLaMA-7B",
                "OpenChineseLLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models": {
        "filename": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HuggingFace Open LLM Leaderboard",
                "MT-Bench",
                "Big-Bench"
            ],
            "base_models": [
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoGuide Automated Generation and Selection of Context-Aware Guidelines for Large Language Model Agents": {
        "filename": "AutoGuide Automated Generation and Selection of Context-Aware Guidelines for Large Language Model Agents.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "WebShop",
                "WebArena",
                "Real-world multi-modal websites (GitHub, Google Flights, Coursera)"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Give us the Facts Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling": {
        "filename": "Give us the Facts Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Thinking Like an Expert Multimodal Hypergraph-of-Thought HoT Reasoning to boost Foundation Modals": {
        "filename": "Thinking Like an Expert Multimodal Hypergraph-of-Thought HoT Reasoning to boost Foundation Modals.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA"
            ],
            "base_models": [
                "T5-base",
                "T5-large",
                "GPT-3.5",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BLINK Multimodal Large Language Models Can See but Not Perceive": {
        "filename": "BLINK Multimodal Large Language Models Can See but Not Perceive.pdf",
        "analysis": {
            "benchmarks": [
                "Blink"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini",
                "LLaVA-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Negative Object Presence Evaluation NOPE to Measure Object Hallucination in Vision-Language Models": {
        "filename": "Negative Object Presence Evaluation NOPE to Measure Object Hallucination in Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "NOPE",
                "VQAv2",
                "Visual7W",
                "AdVQA",
                "R-VQA",
                "TDIUC",
                "TextVQA",
                "VizWiz",
                "VQA-Rephrasings",
                "VQAv1 Abstract Scenes"
            ],
            "base_models": [
                "OFA (929M)",
                "BLIP (385M)",
                "BLIP CapFilt-L (385M)",
                "ALBEF (628M)",
                "GITLARGE (347M)",
                "InstructBLIP FLAN XL (3.8B)",
                "PromptCap BASE (696M)",
                "PromptCap (3B)",
                "BLIP-2 (3.8B)",
                "OpenFlamingo (9B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ADAM An Embodied Causal Agent in Open-World Environments": {
        "filename": "ADAM An Embodied Causal Agent in Open-World Environments.pdf",
        "analysis": {
            "benchmarks": [
                "Modified Minecraft games"
            ],
            "base_models": [
                "GPT-4-turbo (size not specified)",
                "LLaVA-v1.5-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Methods to Estimate Large Language Model Confidence": {
        "filename": "Methods to Estimate Large Language Model Confidence.pdf",
        "analysis": {
            "benchmarks": [
                "New England Journal of Medicine (NEJM) Case Records series"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Solving and Generating NPR Sunday Puzzles with Large Language Models": {
        "filename": "Solving and Generating NPR Sunday Puzzles with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PUZZLEQA"
            ],
            "base_models": [
                "GPT-3 Davinci",
                "GPT-3.5",
                "GPT-J",
                "LLaMA"
            ]
        }
    },
    "An X-Ray Is Worth 15 Features Sparse Autoencoders for Interpretable Radiology Report Generation": {
        "filename": "An X-Ray Is Worth 15 Features Sparse Autoencoders for Interpretable Radiology Report Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-CXR"
            ],
            "base_models": [
                "Rad-DINO (vision transformer)",
                "Claude 3.5 Sonnet (language model)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TART A plug-and-play Transformer module for task-agnostic reasoning": {
        "filename": "TART A plug-and-play Transformer module for task-agnostic reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "RAFT Benchmark",
                "SST",
                "Rotten Tomatoes",
                "SMS Spam",
                "IMDB",
                "Civil Comments",
                "AGNews",
                "DBPedia",
                "Youtube dataset",
                "MNIST",
                "CIFAR-10",
                "Speech Commands"
            ],
            "base_models": [
                "GPT-Neo (125M)",
                "Pythia (160M)",
                "Bloom (560M)",
                "GPT-J (6B)",
                "OPT (175B)",
                "Bloom (176B)",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models Replace Data Scientists in Clinical Research": {
        "filename": "Can Large Language Models Replace Data Scientists in Clinical Research.pdf",
        "analysis": {
            "benchmarks": [
                "CliniDSBench"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o-mini",
                "Sonnet",
                "Opus",
                "Gemini-pro",
                "Gemini-flash"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Making Language Models Better Reasoners with Step-Aware Verifier": {
        "filename": "Making Language Models Better Reasoners with Step-Aware Verifier.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AsDiv",
                "MultiArith",
                "SVAMP",
                "SingleEq",
                "CommonsenseQA",
                "StrategyQA",
                "CLUTRR"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM (540B)",
                "davinci",
                "text-davinci-002",
                "code-davinci-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lean-STaR Learning to Interleave Thinking and Proving": {
        "filename": "Lean-STaR Learning to Interleave Thinking and Proving.pdf",
        "analysis": {
            "benchmarks": [
                "miniF2F-test"
            ],
            "base_models": [
                "InternLM2-7b",
                "InternLM2-7b-plus"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Empowering biomedical discovery with AI agents": {
        "filename": "Empowering biomedical discovery with AI agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Statler State-Maintaining Language Models for Embodied Reasoning": {
        "filename": "Statler State-Maintaining Language Models for Embodied Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "three-cups-and-a-ball",
                "Pick-and-Place",
                "Block Disinfection",
                "Relative Weight Reasoning"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Emergency Department Decision Support using Clinical Pseudo-notes": {
        "filename": "Emergency Department Decision Support using Clinical Pseudo-notes.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-IV",
                "Institutional EHR database"
            ],
            "base_models": [
                "MedBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cant make an Omelette without Breaking some Eggs Plausible Action Anticipation using Large Video-Language Models": {
        "filename": "Cant make an Omelette without Breaking some Eggs Plausible Action Anticipation using Large Video-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Ego4D",
                "EPIC-Kitchens-100"
            ],
            "base_models": [
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distributed Rule Vectors is A Key Mechanism in Large Language Models In-Context Learning": {
        "filename": "Distributed Rule Vectors is A Key Mechanism in Large Language Models In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "knowledge task (capital of a country)",
                "categorization task (string length, digit, 2-D data)"
            ],
            "base_models": [
                "LLaMA-7B"
            ]
        }
    },
    "Visual ChatGPT Talking Drawing and Editing with Visual Foundation Models": {
        "filename": "Visual ChatGPT Talking Drawing and Editing with Visual Foundation Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "BLIP",
                "Stable Diffusion",
                "ControlNet",
                "Pix2Pix"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Causal Language Modeling Can Elicit Search and Reasoning Capabilities on Logic Puzzles": {
        "filename": "Causal Language Modeling Can Elicit Search and Reasoning Capabilities on Logic Puzzles.pdf",
        "analysis": {
            "benchmarks": [
                "Sudoku puzzles",
                "Zebra puzzles"
            ],
            "base_models": [
                "GPT-2 (42M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Powered Context-aware Motion Prediction in Autonomous Driving": {
        "filename": "Large Language Models Powered Context-aware Motion Prediction in Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "Waymo Open Motion Dataset (WOMD)"
            ],
            "base_models": [
                "GPT4-V"
            ]
        }
    },
    "Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine Knowledge": {
        "filename": "Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine Knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "TCM-QA"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)"
            ]
        }
    },
    "MathViz-E A Case-study in Domain-Specialized Tool-Using Agents": {
        "filename": "MathViz-E A Case-study in Domain-Specialized Tool-Using Agents.pdf",
        "analysis": {
            "benchmarks": [
                "utterance-focused dataset",
                "textbook-focused dataset",
                "multi-turn dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "WESE Weak Exploration to Strong Exploitation for LLM Agents": {
        "filename": "WESE Weak Exploration to Strong Exploitation for LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "ScienceWorld",
                "HotPotQA",
                "FEVER"
            ],
            "base_models": [
                "Llama-2-7B",
                "text-davinci-003 (with probably more than 175 billion parameters)"
            ]
        }
    },
    "Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models A Study on Prompt Design Strategies": {
        "filename": "Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models A Study on Prompt Design Strategies.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "Spider-Syn",
                "Spider-DK",
                "Spider-Realistic"
            ],
            "base_models": [
                "Codex (code-davinci-002)",
                "ChatGPT (gpt-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MinT Boosting Generalization in Mathematical Reasoning via Multi-view Fine-tuning": {
        "filename": "MinT Boosting Generalization in Mathematical Reasoning via Multi-view Fine-tuning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MathQA",
                "Ape210K",
                "CM17K",
                "MAWPS"
            ],
            "base_models": [
                "LLaMA-7B",
                "BLOOMz-7B"
            ]
        }
    },
    "Practically implementing an LLM-supported collaborative vulnerability remediation process A team-based approach": {
        "filename": "Practically implementing an LLM-supported collaborative vulnerability remediation process A team-based approach.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "Monica (GPT-4)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lemur Integrating Large Language Models in Automated Program Verification": {
        "filename": "Lemur Integrating Large Language Models in Automated Program Verification.pdf",
        "analysis": {
            "benchmarks": [
                "Code2Inv",
                "SV-COMP"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PromptCrafter Crafting Text-to-Image Prompt through Mixed-Initiative Dialogue with LLM": {
        "filename": "PromptCrafter Crafting Text-to-Image Prompt through Mixed-Initiative Dialogue with LLM.pdf",
        "analysis": {
            "benchmarks": [
                "DALL-E2"
            ],
            "base_models": [
                "GPT-3"
            ]
        }
    },
    "DANA Domain-Aware Neurosymbolic Agents for Consistency and Accuracy": {
        "filename": "DANA Domain-Aware Neurosymbolic Agents for Consistency and Accuracy.pdf",
        "analysis": {
            "benchmarks": [
                "FinanceBench"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "A Review on Language Models as Knowledge Bases": {
        "filename": "A Review on Language Models as Knowledge Bases.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT",
                "GPT-3",
                "BART",
                "T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Ability of Large Language Models to Evaluate Constraint-satisfaction in Agent Responses to Open-ended Requests": {
        "filename": "The Ability of Large Language Models to Evaluate Constraint-satisfaction in Agent Responses to Open-ended Requests.pdf",
        "analysis": {
            "benchmarks": [
                "Arithmetic Constraint-Satisfaction (ACS)"
            ],
            "base_models": [
                "Gemini 1.5 Pro",
                "Gemini 1.5 Flash",
                "Gemini 1.0 Pro",
                "GPT-4o",
                "Llama-3-70b-chat",
                "Llama-3-8b-chat",
                "Mixtral-8x7b-instruct-v0.1",
                "Mistral-7b-instruct-v0.2"
            ]
        }
    },
    "LIFT Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks": {
        "filename": "LIFT Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MNIST",
                "Fashion-MNIST",
                "Iris",
                "OpenML datasets (e.g., Customers, Pollution, Spambase, Hill-Valley, TAE, CMC, Wine, Vehicle, LED, OPT, Mfeat, Margin, Texture)"
            ],
            "base_models": [
                "GPT-J",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RouterBench A Benchmark for Multi-LLM Routing System": {
        "filename": "RouterBench A Benchmark for Multi-LLM Routing System.pdf",
        "analysis": {
            "benchmarks": [
                "Hellaswag",
                "Winogrande",
                "ARC Challenge",
                "MMLU",
                "MT-Bench",
                "GSM8K",
                "MBPP",
                "RAG Dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Claude-instant-v1",
                "Claude-v1",
                "Claude-v2",
                "Llama-70B-chat",
                "Mixtral-8x7B-chat",
                "Yi-34B-chat",
                "Code Llama-34B",
                "Mistral-7B-chat",
                "WizardLM-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Trust in LLM-Generated Code Summaries with Calibrated Confidence Scores": {
        "filename": "Enhancing Trust in LLM-Generated Code Summaries with Calibrated Confidence Scores.pdf",
        "analysis": {
            "benchmarks": [
                "CodeXGLUE"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "Code-Llama-70B",
                "DeepSeek-Coder-33B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HuatuoGPT-o1 Towards Medical Complex Reasoning with LLMs": {
        "filename": "HuatuoGPT-o1 Towards Medical Complex Reasoning with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA (USMLE test set)",
                "MedMCQA (validation set)",
                "PubMedQA (test set)",
                "MMLU-Pro (health and biology tracks)",
                "GPQA (genetics and molecular biology tracks)"
            ],
            "base_models": [
                "LLaMA-3.1-8B-Instruct",
                "LLaMA-3.1-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Graph-of-Thought Utilizing Large Language Models to Solve Complex and Dynamic Business Problems": {
        "filename": "Graph-of-Thought Utilizing Large Language Models to Solve Complex and Dynamic Business Problems.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Microsoft's Large Language Model"
            ]
        }
    },
    "An Intelligent Agentic System for Complex Image Restoration Problems": {
        "filename": "An Intelligent Agentic System for Complex Image Restoration Problems.pdf",
        "analysis": {
            "benchmarks": [
                "MiO100"
            ],
            "base_models": [
                "GPT-4",
                "DepictQA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models as Zero-Shot Trajectory Generators": {
        "filename": "Language Models as Zero-Shot Trajectory Generators.pdf",
        "analysis": {
            "benchmarks": [
                "30 real-world language-based tasks from recent robotics papers"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Measuring and Narrowing the Compositionality Gap in Language Models": {
        "filename": "Measuring and Narrowing the Compositionality Gap in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Compositional Celebrities (CC)",
                "2WikiMultiHopQA",
                "Musique",
                "Bamboogle"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-3 (davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs": {
        "filename": "What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "CSN-Java",
                "TLC",
                "B2Fsmall",
                "B2Fmedium",
                "CoNaLa"
            ],
            "base_models": [
                "CodeBERT",
                "PLBART",
                "CodeT5",
                "GPT-3",
                "PALM-E (562B)",
                "AlphaCode (41B)",
                "Codex",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InfiMM-WebMath-40B Advancing Multimodal Pre-Training for Enhanced Mathematical Reasoning": {
        "filename": "InfiMM-WebMath-40B Advancing Multimodal Pre-Training for Enhanced Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MathVerse",
                "We-Math"
            ],
            "base_models": [
                "DeepSeek-Coder-1.3B",
                "DeepSeek-Coder-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Maintaining Informative Coherence Migrating Hallucinations in Large Language Models via Absorbing Markov Chains": {
        "filename": "Maintaining Informative Coherence Migrating Hallucinations in Large Language Models via Absorbing Markov Chains.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "FACTOR",
                "HaluEval"
            ],
            "base_models": [
                "LLaMa2-7B-chat",
                "LLaMa2-13B-chat",
                "LLaMa3-8B",
                "Qwen2-7B"
            ]
        }
    },
    "SimSAM Zero-Shot Medical Image Segmentation via Simulated Interaction": {
        "filename": "SimSAM Zero-Shot Medical Image Segmentation via Simulated Interaction.pdf",
        "analysis": {
            "benchmarks": [
                "Breast Ultrasound Scan Images (BUSI)",
                "CVC-ClinicDB",
                "ISIC-2016"
            ],
            "base_models": [
                "Segment Anything Model (SAM) with 94M parameters"
            ]
        }
    },
    "Efficient Human-AI Coordination via Preparatory Language-based Convention": {
        "filename": "Efficient Human-AI Coordination via Preparatory Language-based Convention.pdf",
        "analysis": {
            "benchmarks": [
                "Overcooked-AI"
            ],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Native vs Non-Native Language Prompting A Comparative Analysis": {
        "filename": "Native vs Non-Native Language Prompting A Comparative Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "OSACT 2020",
                "ASAD",
                "CLEF CheckThat!",
                "WANLP22",
                "ANS",
                "OffensEval2020"
            ],
            "base_models": [
                "GPT-4o",
                "Llama-3.1-8b-Instruct",
                "Jais-13b-chat"
            ]
        }
    },
    "Large Language Model Enhanced Multi-Agent Systems for 6G Communications": {
        "filename": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications.pdf",
        "analysis": {
            "benchmarks": [
                "Cornell Movie-Dialogs Corpus"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "AI-assisted Automated Short Answer Grading of Handwritten University Level Mathematics Exams": {
        "filename": "AI-assisted Automated Short Answer Grading of Handwritten University Level Mathematics Exams.pdf",
        "analysis": {
            "benchmarks": [
                "mock mathematical exam"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding": {
        "filename": "Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "ScienceQA",
                "HotpotQA"
            ],
            "base_models": [
                "LLaMa2-7B",
                "LLaMa2-13B"
            ]
        }
    },
    "AutoAttacker A Large Language Model Guided System to Implement Automatic Cyber-attacks": {
        "filename": "AutoAttacker A Large Language Model Guided System to Implement Automatic Cyber-attacks.pdf",
        "analysis": {
            "benchmarks": [
                "Custom benchmark with 14 different attacks covering various attack stages"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama2-7B-chat",
                "Llama2-70B-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models": {
        "filename": "Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "CSQA",
                "Letter Concatenation",
                "AQuA",
                "AddSub",
                "SingleEq",
                "SVAMP",
                "ASDiv",
                "StrategyQA",
                "Date Understanding"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "Llama-2-70B-Chat",
                "Llama-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Uni-NLX Unifying Textual Explanations for Vision and Vision-Language Tasks": {
        "filename": "Uni-NLX Unifying Textual Explanations for Vision and Vision-Language Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "VQA-X",
                "A-OKVQA",
                "VQA-ParaX",
                "ImageNetX",
                "ACT-X",
                "e-SNLI-VE",
                "VCR"
            ],
            "base_models": [
                "Distilled-GPT-2",
                "CLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Construction contract risk identification based on knowledge-augmented language model": {
        "filename": "Construction contract risk identification based on knowledge-augmented language model.pdf",
        "analysis": {
            "benchmarks": [
                "real construction contracts"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Face4RAG Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese": {
        "filename": "Face4RAG Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese.pdf",
        "analysis": {
            "benchmarks": [
                "Face4RAG Synthetic Dataset",
                "Face4RAG Real-world Dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Baichuan2-13B-Chat",
                "ChatGLM3",
                "Qwen-14B-Chat",
                "Chinese-Alpaca-2-13B-16k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation": {
        "filename": "Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "TriviaQA",
                "SciQ",
                "AmbigQA",
                "DateUnd",
                "Biz-Ethics"
            ],
            "base_models": [
                "Mistral-7B",
                "GPT-3.5-turbo",
                "Cohere-Commend"
            ]
        }
    },
    "Knowledge Graph Large Language Model KG-LLM for Link Prediction": {
        "filename": "Knowledge Graph Large Language Model KG-LLM for Link Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "WN18RR",
                "NELL-995",
                "FB15k-237",
                "YAGO3-10"
            ],
            "base_models": [
                "Flan-T5",
                "Llama2",
                "Gemma"
            ]
        }
    },
    "MiLoRA Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning": {
        "filename": "MiLoRA Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "PIQA",
                "SIQA",
                "HellaSwag",
                "WinoGrande",
                "ARC-e",
                "ARC-c",
                "OBQA",
                "GSM8K",
                "MATH",
                "VQAv2",
                "GQA",
                "VisWiz",
                "SQA",
                "VQAT",
                "POPE",
                "MMBench"
            ],
            "base_models": [
                "LLaMA2-7B",
                "LLaMA3-8B",
                "LLaVA1.5-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ProgPrompt Generating Situated Robot Task Plans using Large Language Models": {
        "filename": "ProgPrompt Generating Situated Robot Task Plans using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "VirtualHome"
            ],
            "base_models": [
                "GPT-3",
                "Codex",
                "Davinci"
            ]
        }
    },
    "Stress-Testing Capability Elicitation With Password-Locked Models": {
        "filename": "Stress-Testing Capability Elicitation With Password-Locked Models.pdf",
        "analysis": {
            "benchmarks": [
                "APPS",
                "MBPP",
                "MATH",
                "MMLU"
            ],
            "base_models": [
                "Deepseek-7B-Coder",
                "Pythia-1B",
                "Mistral-7B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Minimal Self in Humanoid Robot Alter3 Driven by Large Language Model": {
        "filename": "Minimal Self in Humanoid Robot Alter3 Driven by Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "mirror self-recognition test",
                "rubber hand illusion test"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "CodeHelp Using Large Language Models with Guardrails for Scalable Support in Programming Classes": {
        "filename": "CodeHelp Using Large Language Models with Guardrails for Scalable Support in Programming Classes.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset from a first-year computer and data science course with 52 students"
            ],
            "base_models": [
                "GPT-3.5-turbo-0301",
                "text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhance Reasoning for Large Language Models in the Game Werewolf": {
        "filename": "Enhance Reasoning for Large Language Models in the Game Werewolf.pdf",
        "analysis": {
            "benchmarks": [
                "FanLang-9"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "ChatGLM-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Fabrication of Reality and Fantasy Scene Generation with LLM-Assisted Prompt Interpretation": {
        "filename": "The Fabrication of Reality and Fantasy Scene Generation with LLM-Assisted Prompt Interpretation.pdf",
        "analysis": {
            "benchmarks": [
                "Realistic-Fantasy Benchmark (RFBench)"
            ],
            "base_models": [
                "Stable Diffusion (version 1.4 and 2.1)"
            ]
        }
    },
    "CHATATC Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management": {
        "filename": "CHATATC Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management.pdf",
        "analysis": {
            "benchmarks": [
                "Ground Delay Program (GDP) dataset"
            ],
            "base_models": [
                "GPT-4",
                "Llama 2"
            ]
        }
    },
    "Solving Math Word Problems via Cooperative Reasoning induced Language Models": {
        "filename": "Solving Math Word Problems via Cooperative Reasoning induced Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "ASDiv-A",
                "SingleOp",
                "SingleEq",
                "MultiArith"
            ],
            "base_models": [
                "GPT-J 6B",
                "DeBERTa-large (0.4B)"
            ]
        }
    },
    "Chaining Simultaneous Thoughts for Numerical Reasoning": {
        "filename": "Chaining Simultaneous Thoughts for Numerical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MathQA",
                "SVAMP",
                "DROP num",
                "DROP"
            ],
            "base_models": [
                "RoBERTa base",
                "RoBERTa large",
                "GPT-3 (175B)",
                "PaLM-62B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LeTI Learning to Generate from Textual Interactions": {
        "filename": "LeTI Learning to Generate from Textual Interactions.pdf",
        "analysis": {
            "benchmarks": [
                "MBPP",
                "HumanEval"
            ],
            "base_models": [
                "CodeGen-mono-350M",
                "CodeGen-mono-2B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning": {
        "filename": "Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "E-SNLI",
                "ANLI-R1",
                "ANLI-R2",
                "ANLI-R3",
                "ECQA",
                "OpenbookQA",
                "StrategyQA"
            ],
            "base_models": [
                "PaLM 2-S",
                "PaLM 2-L",
                "FLAN-UL2 (20B)",
                "Llama-2 (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGPT or Grammarly Evaluating ChatGPT on Grammatical Error Correction Benchmark": {
        "filename": "ChatGPT or Grammarly Evaluating ChatGPT on Grammatical Error Correction Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "CoNLL2014"
            ],
            "base_models": [
                "ChatGPT (based on InstructGPT)"
            ]
        }
    },
    "NaVid Video-based VLM Plans the Next Step for Vision-and-Language Navigation": {
        "filename": "NaVid Video-based VLM Plans the Next Step for Vision-and-Language Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "VLN-CE R2R",
                "VLN-CE RxR"
            ],
            "base_models": [
                "LLaMA-VID",
                "Vicuna-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reason out Your Layout Evoking the Layout Master from Large Language Models for Text-to-Image Synthesis": {
        "filename": "Reason out Your Layout Evoking the Layout Master from Large Language Models for Text-to-Image Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "Flickr30K",
                "COCO2017"
            ],
            "base_models": [
                "Stable Diffusion",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What Formal Languages Can Transformers Express A Survey": {
        "filename": "What Formal Languages Can Transformers Express A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Program of Thoughts Prompting Disentangling Computation from Reasoning for Numerical Reasoning Tasks": {
        "filename": "Program of Thoughts Prompting Disentangling Computation from Reasoning for Numerical Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQuA",
                "SVAMP",
                "TabMWP",
                "MultiArith",
                "FinQA",
                "ConvFinQA",
                "TATQA"
            ],
            "base_models": [
                "Codex (175B)",
                "GPT-3 (175B)",
                "PaLM (540B)",
                "LaMDA (137B)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Diffusion Model-Based Image Editing A Survey": {
        "filename": "Diffusion Model-Based Image Editing A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "EditEval"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting Is Programming A Query Language for Large Language Models": {
        "filename": "Prompting Is Programming A Query Language for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2 Medium",
                "EleutherAI GPT-J-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Meta-prompting Optimized Retrieval-augmented Generation": {
        "filename": "Meta-prompting Optimized Retrieval-augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA"
            ],
            "base_models": [
                "Llama-2-70b",
                "Llama-2-70b-chat"
            ]
        }
    },
    "Universal Self-adaptive Prompting": {
        "filename": "Universal Self-adaptive Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "winogrande",
                "piqa",
                "storycloze",
                "anlir1",
                "anlir2",
                "anlir3",
                "boolq",
                "copa",
                "rte",
                "wic",
                "wsc",
                "arc_e",
                "arc_c",
                "raceh",
                "racem",
                "lambada",
                "web_questions",
                "natural_questions",
                "triviaqa_wiki",
                "squad",
                "xsum",
                "wikilingua (en)",
                "BIG-bench Hard (BBH)"
            ],
            "base_models": [
                "PaLM-62B",
                "PaLM-540B",
                "PaLM 2-M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Orca Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models": {
        "filename": "Orca Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Gulf of Mexico buoy data from National Data Buoy Center (NDBC)",
                "Global Wave Database (GWD)"
            ],
            "base_models": [
                "GPT-2"
            ]
        }
    },
    "Rationale-Enhanced Language Models are Better Continual Relation Learners": {
        "filename": "Rationale-Enhanced Language Models are Better Continual Relation Learners.pdf",
        "analysis": {
            "benchmarks": [
                "FewRel",
                "TACRED"
            ],
            "base_models": [
                "T5"
            ]
        }
    },
    "Human-AI Safety A Descendant of Generative AI and Control Systems Safety": {
        "filename": "Human-AI Safety A Descendant of Generative AI and Control Systems Safety.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How to Train Data-Efficient LLMs": {
        "filename": "How to Train Data-Efficient LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "Super-GLUE",
                "CNN/DM",
                "SQuAD",
                "MMLU",
                "BBH"
            ],
            "base_models": [
                "T5-Large (800M)",
                "T5-Small (60M)",
                "FLAN-T5-XL",
                "FLAN-T5-Small"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FiDeLiS Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering": {
        "filename": "FiDeLiS Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "WebQSP",
                "CWQ",
                "CR-LT"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SAIL Search-Augmented Instruction Learning": {
        "filename": "SAIL Search-Augmented Instruction Learning.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "OpenbookQA",
                "ARC-Challenge",
                "UniLC",
                "Climate-Fever",
                "PubHealth",
                "Hate Speech Detection",
                "Social Bias Frame"
            ],
            "base_models": [
                "LLaMA-7B",
                "Vicuna-7B",
                "Vicuna-13B",
                "GPT-3.5-Turbo",
                "GPT-4"
            ]
        }
    },
    "Recommender Systems in the Era of Large Language Models LLMs": {
        "filename": "Recommender Systems in the Era of Large Language Models LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "IMDB",
                "Netflix"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "LLaMA",
                "T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Organizing Unstructured Image Collections using Natural Language": {
        "filename": "Organizing Unstructured Image Collections using Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "COCO-4c",
                "Food-4c"
            ],
            "base_models": [
                "LLaVA-NeXT-7B",
                "Llama-3.1-8B",
                "BLIP-2 Flan-T5 XXL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reason-before-Retrieve One-Stage Reflective Chain-of-Thoughts for Training-Free Zero-Shot Composed Image Retrieval": {
        "filename": "Reason-before-Retrieve One-Stage Reflective Chain-of-Thoughts for Training-Free Zero-Shot Composed Image Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "CIRCO",
                "CIRR",
                "FashionIQ",
                "GeneCIS"
            ],
            "base_models": [
                "CLIP",
                "GPT-4",
                "LLaVA",
                "MiniGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Adapting a Foundation Model for Space-based Tasks": {
        "filename": "Adapting a Foundation Model for Space-based Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "AI4Mars"
            ],
            "base_models": [
                "LLaVA v1.5 13B"
            ]
        }
    },
    "What does a platypus look like Generating customized prompts for zero-shot image classification": {
        "filename": "What does a platypus look like Generating customized prompts for zero-shot image classification.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "Describable Textures Dataset (DTD)",
                "Stanford Cars",
                "SUN397",
                "Food101",
                "FGVC Aircraft",
                "Oxford Pets",
                "Caltech101",
                "Flowers 102",
                "UCF101",
                "Kinetics-700",
                "RESISC45",
                "CIFAR-10",
                "CIFAR-100",
                "Birdsnap"
            ],
            "base_models": [
                "CLIP (ViT-L/14)",
                "GPT-3 (DaVinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting Is All You Need Automated Android Bug Replay with Large Language Models": {
        "filename": "Prompting Is All You Need Automated Android Bug Replay with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ReCDroid dataset",
                "ANDROR2+ dataset",
                "Themis dataset"
            ],
            "base_models": [
                "ChatGPT (based on GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Grounding LLMs For Robot Task Planning Using Closed-loop State Feedback": {
        "filename": "Grounding LLMs For Robot Task Planning Using Closed-loop State Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "VirtualHome",
                "Franka Research 3 robotic arm"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "PaLM 2 text-bison-001"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning": {
        "filename": "Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "IWSLT",
                "WMT"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B"
            ]
        }
    },
    "AllHands Ask Me Anything on Large-scale Verbatim Feedback via Large Language Models": {
        "filename": "AllHands Ask Me Anything on Large-scale Verbatim Feedback via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GoogleStoreApp",
                "ForumPost",
                "MSearch"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Long-Horizon Vision-Language Navigation Platform Benchmark and Method": {
        "filename": "Towards Long-Horizon Vision-Language Navigation Platform Benchmark and Method.pdf",
        "analysis": {
            "benchmarks": [
                "LHPR-VLN"
            ],
            "base_models": [
                "GPT-4",
                "Vicuna 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Software Testing With Large Language Models Survey Landscape and Vision": {
        "filename": "Software Testing With Large Language Models Survey Landscape and Vision.pdf",
        "analysis": {
            "benchmarks": [
                "Defects4J",
                "CodeSearchNet",
                "HumanEval",
                "SF110"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT",
                "Codex",
                "T5",
                "BART"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TART An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning": {
        "filename": "TART An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTableQuestion (WTQ)",
                "HiTab (HIT)",
                "TabMWP (TMP)",
                "FinQA (FQA)",
                "TAT-QA (TAT)",
                "HybridQA (HYQ)",
                "TabFact (TAF)",
                "SCITAB (SCT)",
                "PubHealthTab (PHT)"
            ],
            "base_models": [
                "CodeLlama-7B",
                "Llama2-7B",
                "Llama3-8B",
                "Deepseek-Coder-7B-Instruct-V1.5",
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Recent Advances in Multi-Choice Machine Reading Comprehension A Survey on Methods and Datasets": {
        "filename": "Recent Advances in Multi-Choice Machine Reading Comprehension A Survey on Methods and Datasets.pdf",
        "analysis": {
            "benchmarks": [
                "CBT",
                "MovieQA",
                "WDW",
                "BookTest",
                "Quasar-S",
                "WikiHop",
                "RACE",
                "SciQ",
                "RecipeQA-text",
                "CliCR",
                "CLOTH",
                "ReCoRD",
                "BioRead",
                "MultiRC",
                "ARC",
                "MedQA",
                "MCScript",
                "MCScript2.0",
                "RACE-C",
                "DREAM",
                "CosmosQA",
                "Shmoop",
                "BioMRC",
                "ReClor",
                "QuAIL",
                "QASC",
                "LogiQA",
                "ExpMRC-RACE+",
                "LogiQA2.0",
                "RULE"
            ],
            "base_models": [
                "RoBERTa",
                "ERNIE",
                "T5",
                "DeBERTa",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language as Reality A Co-Creative Storytelling Game Experience in 1001 Nights using Generative AI": {
        "filename": "Language as Reality A Co-Creative Storytelling Game Experience in 1001 Nights using Generative AI.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Stable Diffusion"
            ]
        }
    },
    "Multi-Agent Consensus Seeking via Large Language Models": {
        "filename": "Multi-Agent Consensus Seeking via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-turbo-0613"
            ]
        }
    },
    "Language Models as Knowledge Bases for Visual Word Sense Disambiguation": {
        "filename": "Language Models as Knowledge Bases for Visual Word Sense Disambiguation.pdf",
        "analysis": {
            "benchmarks": [
                "COCO",
                "Flickr30k"
            ],
            "base_models": [
                "CLIP-L (ViT large encoder)",
                "CLIP LAION (ViT-H/14)",
                "ALIGN",
                "BLIP C (ViT base/large)",
                "BLIP F (ViT base/large)",
                "GPT-3 (175B)",
                "GPT-3.5-turbo",
                "GPT2-XL (1.5B)",
                "BLOOMZ-1.7B",
                "BLOOMZ-3B",
                "OPT-2.7B",
                "OPT-6.7B",
                "Galactica 6.7B",
                "LLAMA-7B",
                "Vicuna 7B",
                "Vicuna 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ContextGPT Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models": {
        "filename": "ContextGPT Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models.pdf",
        "analysis": {
            "benchmarks": [
                "DOMINO",
                "ExtraSensory"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "N-Critics Self-Refinement of Large Language Models with Ensemble of Critics": {
        "filename": "N-Critics Self-Refinement of Large Language Models with Ensemble of Critics.pdf",
        "analysis": {
            "benchmarks": [
                "REALTOXICITYPROMPTS",
                "AmbigNQ",
                "TriviaQA",
                "HotpotQA"
            ],
            "base_models": [
                "LLaMA-70b",
                "WizardLM-70b",
                "WizardLM-13b",
                "Koala-13b",
                "Vicuna-13b"
            ]
        }
    },
    "Question Suggestion for Conversational Shopping Assistants Using Product Metadata": {
        "filename": "Question Suggestion for Conversational Shopping Assistants Using Product Metadata.pdf",
        "analysis": {
            "benchmarks": [
                "Amazon Reviews Dataset"
            ],
            "base_models": [
                "Claude-2",
                "Flan-T5-xxl (11B)"
            ]
        }
    },
    "Retrieval-Augmented Chain-of-Thought in Semi-structured Domains": {
        "filename": "Retrieval-Augmented Chain-of-Thought in Semi-structured Domains.pdf",
        "analysis": {
            "benchmarks": [
                "FinQA",
                "SARA"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "LLaMA-2 (7B, 13B, 70B)"
            ]
        }
    },
    "PharmacyGPT The AI Pharmacist": {
        "filename": "PharmacyGPT The AI Pharmacist.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from the University of North Carolina Health System ICU"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MINTQA A Multi-Hop Question Answering Benchmark for Evaluating LLMs on New and Tail Knowledge": {
        "filename": "MINTQA A Multi-Hop Question Answering Benchmark for Evaluating LLMs on New and Tail Knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "MINTQA-POP",
                "MINTQA-TI"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4o",
                "GPT-4o-mini",
                "LLaMA-3.1-8B",
                "LLaMA-3.1-70B",
                "LLaMA-3.2-1B",
                "LLaMA-3.2-3B",
                "Qwen2.5-1.5B",
                "Qwen2.5-3B",
                "Qwen2.5-7B",
                "Qwen2.5-14B",
                "Qwen2.5-32B",
                "Qwen2.5-72B",
                "Gemma-2-2B",
                "Gemma-2-9B",
                "Gemma-2-27B",
                "Phi-3-mini",
                "Phi-3-small",
                "Phi-3-medium",
                "Mistral-7B-v0.3",
                "Mixtral-8x7B-v0.1",
                "Ministral-8B-2410"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Critical-Questions-of-Thought Steering LLM reasoning with Argumentative Querying": {
        "filename": "Critical-Questions-of-Thought Steering LLM reasoning with Argumentative Querying.pdf",
        "analysis": {
            "benchmarks": [
                "MT-Bench Reasoning",
                "MT-Bench Math"
            ],
            "base_models": [
                "Claude 3.5 Sonnet",
                "GPT-4o",
                "Gemini 1.5-pro-001",
                "Llama 3.1-70b-Instruct",
                "Nemotron-51b-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval  Fine-Tuning for In-Context Tabular Models": {
        "filename": "Retrieval  Fine-Tuning for In-Context Tabular Models.pdf",
        "analysis": {
            "benchmarks": [
                "TabZilla (95 datasets from OpenML)"
            ],
            "base_models": [
                "TabPFN"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluation is all you need Prompting Generative Large Language Models for Annotation Tasks in the Social Sciences A Primer using Open Models": {
        "filename": "Evaluation is all you need Prompting Generative Large Language Models for Annotation Tasks in the Social Sciences A Primer using Open Models.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval-2017 Task 4 - Subtask A",
                "National Child Development Study: Age 11, Sweep 2, Sample of Essays"
            ],
            "base_models": [
                "neural-chat-7b-v3-2 (7B)",
                "Starling-LM-7B-alpha (7B)",
                "openchat_3.5",
                "zephyr-7b-alpha (7B)",
                "zephyr-7b-beta (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Explanation Regeneration via Information Bottleneck": {
        "filename": "Explanation Regeneration via Information Bottleneck.pdf",
        "analysis": {
            "benchmarks": [
                "ECQA",
                "e-SNLI"
            ],
            "base_models": [
                "OPT-13B",
                "GPT-2 Small"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Devil Is in the Errors Leveraging Large Language Models for Fine-grained Machine Translation Evaluation": {
        "filename": "The Devil Is in the Errors Leveraging Large Language Models for Fine-grained Machine Translation Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "WMT'22 Metrics Shared Task",
                "WMT'19 Metrics Shared Task"
            ],
            "base_models": [
                "PaLM (540B)",
                "PaLM-2 BISON",
                "PaLM-2 UNICORN"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AgentsCoDriver Large Language Model Empowered Collaborative Driving with Lifelong Learning": {
        "filename": "AgentsCoDriver Large Language Model Empowered Collaborative Driving with Lifelong Learning.pdf",
        "analysis": {
            "benchmarks": [
                "V2X-SIM",
                "OPV2V",
                "DAIR-V2X"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Redefining Qualitative Analysis in the AI Era Utilizing ChatGPT for Efficient Thematic Analysis": {
        "filename": "Redefining Qualitative Analysis in the AI Era Utilizing ChatGPT for Efficient Thematic Analysis.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (based on GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unlocking Large Language Models Planning Capabilities with Maximum Diversity Fine-tuning": {
        "filename": "Unlocking Large Language Models Planning Capabilities with Maximum Diversity Fine-tuning.pdf",
        "analysis": {
            "benchmarks": [
                "Blocksworld",
                "Logistics"
            ],
            "base_models": [
                "GPT-3.5-turbo-0125",
                "Llama-3-8b",
                "Llama-2-7b"
            ]
        }
    },
    "Towards Graph Foundation Models A Survey and Beyond": {
        "filename": "Towards Graph Foundation Models A Survey and Beyond.pdf",
        "analysis": {
            "benchmarks": [
                "None specified"
            ],
            "base_models": [
                "GCN",
                "GAT",
                "GraphSAGE",
                "HGT",
                "GIN",
                "Graph Transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations": {
        "filename": "Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations.pdf",
        "analysis": {
            "benchmarks": [
                "HaluSum2130",
                "HaluQA4170",
                "FactCC503",
                "SummEval",
                "QAGS-CNNDM",
                "QAGS-XSUM"
            ],
            "base_models": [
                "GPT-3.5-TURBO-16K",
                "GPT-4-32K"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How to Determine the Preferred Image Distribution of a Black-Box Vision-Language Model": {
        "filename": "How to Determine the Preferred Image Distribution of a Black-Box Vision-Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "CAD-VQA"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "LiveMind Low-latency Large Language Models with Simultaneous Inference": {
        "filename": "LiveMind Low-latency Large Language Models with Simultaneous Inference.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "MMLU-Pro"
            ],
            "base_models": [
                "Llama-3-70B-Instruct",
                "Llama-3-8B-Instruct",
                "GPT-4o"
            ]
        }
    },
    "Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health": {
        "filename": "Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health.pdf",
        "analysis": {
            "benchmarks": [
                "CLPsych15",
                "Depression_Reddit",
                "Dreaddit",
                "SAD",
                "T-SID",
                "UMD",
                "SWMH",
                "CAMS"
            ],
            "base_models": [
                "XLNet",
                "Longformer"
            ]
        }
    },
    "An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing": {
        "filename": "An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing.pdf",
        "analysis": {
            "benchmarks": [
                "Clinical Abbreviation Sense Inventories (CASI)",
                "EBM-NLP"
            ],
            "base_models": [
                "GPT-3.5",
                "BARD (based on PaLM-2)",
                "LLAMA2"
            ]
        }
    },
    "Adapting Large Multimodal Models to Distribution Shifts The Role of In-Context Learning": {
        "filename": "Adapting Large Multimodal Models to Distribution Shifts The Role of In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Camelyon17",
                "HAM10000",
                "NIH Chest",
                "COVID"
            ],
            "base_models": [
                "GPT-4V",
                "Claude",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models Hallucinate but May Excel at Fact Verification": {
        "filename": "Language Models Hallucinate but May Excel at Fact Verification.pdf",
        "analysis": {
            "benchmarks": [
                "FEVER",
                "BoolQ-FV",
                "FM2",
                "PubMedQA",
                "XsumFaith",
                "SummEval",
                "SciFact"
            ],
            "base_models": [
                "GPT-3.5",
                "FLAN-T5 11B",
                "LLama 30B",
                "LLama 65B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Models to Detect npm Malicious Packages": {
        "filename": "Leveraging Large Language Models to Detect npm Malicious Packages.pdf",
        "analysis": {
            "benchmarks": [
                "MalwareBench"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can GPT-3 Perform Statutory Reasoning": {
        "filename": "Can GPT-3 Perform Statutory Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "SARA (StAtutory Reasoning Assessment)"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "QualiGPT GPT as an easy-to-use tool for qualitative coding": {
        "filename": "QualiGPT GPT as an easy-to-use tool for qualitative coding.pdf",
        "analysis": {
            "benchmarks": [
                "simulated dataset on transitioning to remote work",
                "real-world social media dataset from a public Discord channel"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Stealing Attacks Against Large Language Models": {
        "filename": "Prompt Stealing Attacks Against Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "RetrievalQA",
                "Alpaca-GPT4"
            ],
            "base_models": [
                "ChatGPT",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bridging Today and the Future of Humanity AI Safety in 2024 and Beyond": {
        "filename": "Bridging Today and the Future of Humanity AI Safety in 2024 and Beyond.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Review of Generative AI Methods in Cybersecurity": {
        "filename": "Review of Generative AI Methods in Cybersecurity.pdf",
        "analysis": {
            "benchmarks": [
                "CyberMetric"
            ],
            "base_models": [
                "GPT-4",
                "Google's Gemini",
                "YandexGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dissecting Dissonance Benchmarking Large Multimodal Models Against Self-Contradictory Instructions": {
        "filename": "Dissecting Dissonance Benchmarking Large Multimodal Models Against Self-Contradictory Instructions.pdf",
        "analysis": {
            "benchmarks": [
                "Self-Contradictory Instructions (SCI)"
            ],
            "base_models": [
                "Claude 3",
                "Gemini 1.5 Pro",
                "GPT-4",
                "LLaVA-1.5",
                "LLaMA-Adapter V2",
                "BLIP-2",
                "SPHINX-v2",
                "ChatGLM",
                "ChatGPT",
                "GLM-4",
                "Llama 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MobileSafetyBench Evaluating Safety of Autonomous Agents in Mobile Device Control": {
        "filename": "MobileSafetyBench Evaluating Safety of Autonomous Agents in Mobile Device Control.pdf",
        "analysis": {
            "benchmarks": [
                "MobileSafetyBench"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini-1.5-Pro",
                "Claude-3.5-Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Human-in-the-Loop through Chain-of-Thought": {
        "filename": "Human-in-the-Loop through Chain-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "AddSub",
                "MultiArith",
                "SingleEq",
                "SingleOp",
                "ASDiv",
                "AQuA",
                "SVAMP",
                "GSM8K",
                "CommonsensQA",
                "StrategyQA",
                "Last Letter Concatenation",
                "Coinflip"
            ],
            "base_models": [
                "GPT-3 (175-billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them": {
        "filename": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench Hard (BBH)"
            ],
            "base_models": [
                "PaLM-540B",
                "Codex (code-davinci-002)",
                "InstructGPT (text-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LyricWhiz Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT": {
        "filename": "LyricWhiz Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "Jamendo",
                "Hansen",
                "MUSDB18",
                "DSing"
            ],
            "base_models": [
                "Whisper",
                "GPT-4"
            ]
        }
    },
    "The importance of visual modelling languages in generative software engineering": {
        "filename": "The importance of visual modelling languages in generative software engineering.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Understanding the planning of LLM agents A survey": {
        "filename": "Understanding the planning of LLM agents A survey.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "ScienceWorld",
                "HotPotQA",
                "FEVER"
            ],
            "base_models": [
                "GPT-2",
                "GPT-3 (text-davinci-003)",
                "LLaMA"
            ]
        }
    },
    "From Models to Microtheories Distilling a Models Topical Knowledge for Grounded Question Answering": {
        "filename": "From Models to Microtheories Distilling a Models Topical Knowledge for Grounded Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "ARC",
                "MedQA"
            ],
            "base_models": [
                "GPT-4",
                "Mixtral-8x22B-Instruct-v0.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Text2Reward Reward Shaping with Language Models for Reinforcement Learning": {
        "filename": "Text2Reward Reward Shaping with Language Models for Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "MANISKILL 2",
                "METAWORLD",
                "MUJOCO"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Compresso Structured Pruning with Collaborative Prompting Learns Compact Large Language Models": {
        "filename": "Compresso Structured Pruning with Collaborative Prompting Learns Compact Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "commonsense reasoning",
                "reading comprehension",
                "MMLU",
                "BBH"
            ],
            "base_models": [
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are Emergent Abilities in Large Language Models just In-Context Learning": {
        "filename": "Are Emergent Abilities in Large Language Models just In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Social IQA",
                "GSM8K",
                "BIG-bench"
            ],
            "base_models": [
                "GPT-2 (117M)",
                "GPT-2-XL (1.6B)",
                "GPT-J (6.7B)",
                "davinci (175B)",
                "T5-small (60M)",
                "T5-large (770M)",
                "Falcon-7B (7B)",
                "Falcon-40B (40B)",
                "LLaMA-7B (7B)",
                "LLaMA-13B (13B)",
                "LLaMA-30B (30B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding the Interplay between Parametric and Contextual Knowledge for Large Language Models": {
        "filename": "Understanding the Interplay between Parametric and Contextual Knowledge for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ECHOQA"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o-mini",
                "Llama 3.1-70B",
                "Llama 3.1-8B",
                "Qwen 2-7B",
                "OpenAI o1-preview"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Factor-Conditioned Speaking-Style Captioning": {
        "filename": "Factor-Conditioned Speaking-Style Captioning.pdf",
        "analysis": {
            "benchmarks": [
                "PromptTTS"
            ],
            "base_models": [
                "LLaMA-2 7B-chat",
                "Whisper large-v3"
            ]
        }
    },
    "Video as the New Language for Real-World Decision Making": {
        "filename": "Video as the New Language for Real-World Decision Making.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Words2Contact Identifying Support Contacts from Verbal Instructions Using Foundation Models": {
        "filename": "Words2Contact Identifying Support Contacts from Verbal Instructions Using Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset for contact prediction"
            ],
            "base_models": [
                "GPT-3.5",
                "Calme-7b-Instruct",
                "mixtao-7bx2-moe",
                "Florence-2",
                "GroundingDINO",
                "CLIPSeg",
                "CLIP Surgery"
            ]
        }
    },
    "From Artificial Needles to Real Haystacks Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data": {
        "filename": "From Artificial Needles to Real Haystacks Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data.pdf",
        "analysis": {
            "benchmarks": [
                "MDQA",
                "FLenQA",
                "MMLU",
                "HellaSwag",
                "TriviaQA",
                "NQ-Open"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "Mistral 7B"
            ]
        }
    },
    "Can Separators Improve Chain-of-Thought Prompting": {
        "filename": "Can Separators Improve Chain-of-Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQuA",
                "CSQA"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "LLaMA-2 7B"
            ]
        }
    },
    "Understanding LLMs A Comprehensive Overview from Training to Inference": {
        "filename": "Understanding LLMs A Comprehensive Overview from Training to Inference.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Guiding Enumerative Program Synthesis with Large Language Models": {
        "filename": "Guiding Enumerative Program Synthesis with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Syntax-Guided Synthesis (SyGuS) competition"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Generate Train PGT Few-shot Domain Adaption of Retrieval Augmented Generation Models for Open Book Question-Answering": {
        "filename": "Prompt Generate Train PGT Few-shot Domain Adaption of Retrieval Augmented Generation Models for Open Book Question-Answering.pdf",
        "analysis": {
            "benchmarks": [
                "proprietary collection of text documents"
            ],
            "base_models": [
                "GPT-4",
                "Flan-T5 XXL",
                "ColBERTv2",
                "BERT"
            ]
        }
    },
    "Agent Skill Acquisition for Large Language Models via CycleQD": {
        "filename": "Agent Skill Acquisition for Large Language Models via CycleQD.pdf",
        "analysis": {
            "benchmarks": [
                "AgentBench"
            ],
            "base_models": [
                "LLaMA 3-8B-INSTRUCT",
                "GPT-3.5-TURBO"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Decoding ChatGPT A Taxonomy of Existing Research Current Challenges and Possible Future Directions": {
        "filename": "Decoding ChatGPT A Taxonomy of Existing Research Current Challenges and Possible Future Directions.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoD Towards an Interpretable Medical Agent using Chain of Diagnosis": {
        "filename": "CoD Towards an Interpretable Medical Agent using Chain of Diagnosis.pdf",
        "analysis": {
            "benchmarks": [
                "Muzhi Dataset",
                "Dxy Dataset",
                "DxBench"
            ],
            "base_models": [
                "GPT-4",
                "Yi-34B-Base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Best Defense is a Good Offense Countering LLM-Powered Cyberattacks": {
        "filename": "The Best Defense is a Good Offense Countering LLM-Powered Cyberattacks.pdf",
        "analysis": {
            "benchmarks": [
                "custom-built CTF machines"
            ],
            "base_models": [
                "GPT-4o",
                "Claude Sonnet 3.5",
                "Gemini Pro 1.5",
                "LLaMA 3.1 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Does Reasoning Emerge Examining the Probabilities of Causation in Large Language Models": {
        "filename": "Does Reasoning Emerge Examining the Probabilities of Causation in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Divisibility by 6 (Div6)",
                "Even sum of integers (EvenSum)",
                "Candy party (CandyParty)"
            ],
            "base_models": [
                "GPT-2",
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distilling Script Knowledge from Large Language Models for Constrained Language Planning": {
        "filename": "Distilling Script Knowledge from Large Language Models for Constrained Language Planning.pdf",
        "analysis": {
            "benchmarks": [
                "CoScript"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "InstructGPT (175B)",
                "PaLM",
                "T5 (3B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Summarization Programs Interpretable Abstractive Summarization with Neural Modular Trees": {
        "filename": "Summarization Programs Interpretable Abstractive Summarization with Neural Modular Trees.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/DailyMail",
                "XSum"
            ],
            "base_models": [
                "BART-large",
                "PEGASUS"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AnalogCoder Analog Circuit Design via Training-Free Code Generation": {
        "filename": "AnalogCoder Analog Circuit Design via Training-Free Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "AnalogCoder benchmark"
            ],
            "base_models": [
                "Llama 3-70B",
                "GPT 3.5",
                "GPT 4",
                "GPT 4o",
                "WizardCoder-33B",
                "CodeQwen-7B",
                "Llama 2-70B",
                "CodeLlama-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "UGIF UI Grounded Instruction Following": {
        "filename": "UGIF UI Grounded Instruction Following.pdf",
        "analysis": {
            "benchmarks": [
                "UGIF-DataSet"
            ],
            "base_models": [
                "PaLM (540B)",
                "GPT-3 (175B)",
                "T5 (11B)",
                "UL2 (20B)"
            ]
        }
    },
    "Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation": {
        "filename": "Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation.pdf",
        "analysis": {
            "benchmarks": [
                "LogicNLI",
                "FOLIO"
            ],
            "base_models": [
                "LLaMA-7B",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Resolving Crash Bugs via Large Language Models An Empirical Study": {
        "filename": "Resolving Crash Bugs via Large Language Models An Empirical Study.pdf",
        "analysis": {
            "benchmarks": [
                "QuixBugs",
                "Custom dataset from Stack Overflow"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "Claude",
                "CodeLlama-34b",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lets reward step by step Step-Level reward model as the Navigators for Reasoning": {
        "filename": "Lets reward step by step Step-Level reward model as the Navigators for Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "MBPP",
                "HumanEval"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "WizardMath-13B",
                "Code-LLaMA-Python-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From News to Forecast Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection": {
        "filename": "From News to Forecast Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection.pdf",
        "analysis": {
            "benchmarks": [
                "Traffic (traffic volume)",
                "Exchange (exchange rate)",
                "Bitcoin (Bitcoin price)",
                "Electricity (Australian electricity demand)"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "LLaMa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SpatialVLM Endowing Vision-Language Models with Spatial Reasoning Capabilities": {
        "filename": "SpatialVLM Endowing Vision-Language Models with Spatial Reasoning Capabilities.pdf",
        "analysis": {
            "benchmarks": [
                "WebLI"
            ],
            "base_models": [
                "GPT-4V",
                "PaLM-E 12B",
                "PaLM2-S"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction": {
        "filename": "Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction.pdf",
        "analysis": {
            "benchmarks": [
                "NUCLE",
                "CoNLL2013",
                "CoNLL2014"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT"
            ]
        }
    },
    "MSCoTDet Language-driven Multi-modal Fusion for Improved Multispectral Pedestrian Detection": {
        "filename": "MSCoTDet Language-driven Multi-modal Fusion for Improved Multispectral Pedestrian Detection.pdf",
        "analysis": {
            "benchmarks": [
                "FLIR",
                "CVC-14",
                "ROTX-MP"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "ChatGPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Validation of the Scientific Literature via Chemputation Augmented by Large Language Models": {
        "filename": "Validation of the Scientific Literature via Chemputation Augmented by Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "10 scientific publications",
                "organic chemistry PhD thesis",
                "German undergraduate practical transcript"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA"
            ]
        }
    },
    "Fix the Tests Augmenting LLMs to Repair Test Cases with Static Collector and Neural Reranker": {
        "filename": "Fix the Tests Augmenting LLMs to Repair Test Cases with Static Collector and Neural Reranker.pdf",
        "analysis": {
            "benchmarks": [
                "custom benchmark dataset with 136 samples of obsolete tests caused by syntactic breaking changes"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoPRM Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition": {
        "filename": "AutoPRM Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "StrategyQA"
            ],
            "base_models": [
                "GPT-4",
                "PaLM-2",
                "GPT-3",
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MotionLLaMA A Unified Framework for Motion Synthesis and Comprehension": {
        "filename": "MotionLLaMA A Unified Framework for Motion Synthesis and Comprehension.pdf",
        "analysis": {
            "benchmarks": [
                "MotionHub"
            ],
            "base_models": [
                "LLaMA-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Is ChatGPT a Good Sentiment Analyzer A Preliminary Study": {
        "filename": "Is ChatGPT a Good Sentiment Analyzer A Preliminary Study.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "SemEval 2014-ABSA Challenge Datasets",
                "Camera dataset",
                "Emotion Cause Dataset"
            ],
            "base_models": [
                "ChatGPT (based on GPT-3.5-turbo-0301)",
                "BERT (base version)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TAROT Targeted Data Selection via Optimal Transport": {
        "filename": "TAROT Targeted Data Selection via Optimal Transport.pdf",
        "analysis": {
            "benchmarks": [
                "Cityscapes",
                "GTA5",
                "nuScenes",
                "Waymo Open Motion Dataset",
                "Argoverse 2",
                "nuPlan",
                "MMLU",
                "BBH"
            ],
            "base_models": [
                "ResNet-9",
                "DeepLabV3 with ResNet50",
                "AutoBots (1.5M parameters)",
                "Wayformer (15M parameters)",
                "LLAMA-3.1-8B",
                "QWEN-2.5-7B"
            ]
        }
    },
    "Exploring Question Decomposition for Zero-Shot VQA": {
        "filename": "Exploring Question Decomposition for Zero-Shot VQA.pdf",
        "analysis": {
            "benchmarks": [
                "VQA-Introspect",
                "Winoground",
                "A-OKVQA",
                "ArtVQA",
                "OK-VQA",
                "SLAKE",
                "PathVQA",
                "VQA Rad"
            ],
            "base_models": [
                "BLIP-2 (3B and 11B based on FLAN-T5)",
                "FLAN-T5 (80M, 250M, 780M, 3B, 7B, 11B)",
                "Galactica (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Redefining crowdsourced test report prioritization An innovative approach with large language model": {
        "filename": "Redefining crowdsourced test report prioritization An innovative approach with large language model.pdf",
        "analysis": {
            "benchmarks": [
                "MoocTest dataset containing 1,417 crowdsourced test reports from 20 mobile apps"
            ],
            "base_models": [
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Consistent Language Models Using Declarative Constraints": {
        "filename": "Towards Consistent Language Models Using Declarative Constraints.pdf",
        "analysis": {
            "benchmarks": [
                "CommonGen"
            ],
            "base_models": [
                "Llama-2 (7 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "V-RECS a Low-Cost LLM4VIS Recommender with Explanations Captioning and Suggestions": {
        "filename": "V-RECS a Low-Cost LLM4VIS Recommender with Explanations Captioning and Suggestions.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Llama-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval Meets Reasoning Even High-school Textbook Knowledge Benefits Multimodal Reasoning": {
        "filename": "Retrieval Meets Reasoning Even High-school Textbook Knowledge Benefits Multimodal Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "A-OKVQA",
                "MMBench",
                "SEED-Bench",
                "ScienceQA"
            ],
            "base_models": [
                "LLaVA-1.5 (13B)",
                "Qwen-VL",
                "InternLM-XComposer2-VL",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bias and Fairness in Large Language Models A Survey": {
        "filename": "Bias and Fairness in Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "CrowS-Pairs",
                "HONEST"
            ],
            "base_models": [
                "GPT-3",
                "BERT",
                "RoBERTa",
                "XLM-R",
                "BART",
                "T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TAIA Large Language Models are Out-of-Distribution Data Learners": {
        "filename": "TAIA Large Language Models are Out-of-Distribution Data Learners.pdf",
        "analysis": {
            "benchmarks": [
                "MMedBench",
                "CMExam",
                "CoT-Collection",
                "MATH",
                "BBH",
                "CommonsenseQA",
                "LogiQA",
                "SVAMP",
                "MMLU"
            ],
            "base_models": [
                "Qwen1.5-1.8B",
                "Qwen1.5-7B",
                "LLaMA2-7B",
                "LLaMA3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Theory of Emergent In-Context Learning as Implicit Structure Induction": {
        "filename": "A Theory of Emergent In-Context Learning as Implicit Structure Induction.pdf",
        "analysis": {
            "benchmarks": [
                "Function Evaluation",
                "Propositional",
                "Composed",
                "Binary Classification"
            ],
            "base_models": [
                "GPT2-like (14M, 21M, 42M, 85M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Querying Large Language Models with SQL": {
        "filename": "Querying Large Language Models with SQL.pdf",
        "analysis": {
            "benchmarks": [
                "Spider corpus"
            ],
            "base_models": [
                "Flan-T5-large (783M)",
                "TK-instruct-large (783M)",
                "InstructGPT-3 (175B)",
                "GPT-3.5-turbo (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning with Language Model is Planning with World Model": {
        "filename": "Reasoning with Language Model is Planning with World Model.pdf",
        "analysis": {
            "benchmarks": [
                "Blocksworld",
                "GSM8K",
                "PrOntoQA"
            ],
            "base_models": [
                "LLaMA-33B",
                "GPT-4",
                "Llama-2 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt-Enhanced Software Vulnerability Detection Using ChatGPT": {
        "filename": "Prompt-Enhanced Software Vulnerability Detection Using ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "Software Assurance Reference Dataset (SARD)",
                "National Vulnerability Database (NVD)"
            ],
            "base_models": [
                "ChatGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distill or Annotate Cost-Efficient Fine-Tuning of Compact Models": {
        "filename": "Distill or Annotate Cost-Efficient Fine-Tuning of Compact Models.pdf",
        "analysis": {
            "benchmarks": [
                "WLP",
                "STANCEOSAURUS",
                "FEVER",
                "MULTI PIT Id",
                "MULTI PIT Gen",
                "NATURAL QUESTIONS"
            ],
            "base_models": [
                "T5-XXL (11B)",
                "T5-Small (60M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TAGCOS Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data": {
        "filename": "TAGCOS Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data.pdf",
        "analysis": {
            "benchmarks": [
                "TydiQA",
                "MMLU",
                "BBH"
            ],
            "base_models": [
                "Llama-2-7B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Paralinguistics-Aware Speech-Empowered Large Language Models for Natural Conversation": {
        "filename": "Paralinguistics-Aware Speech-Empowered Large Language Models for Natural Conversation.pdf",
        "analysis": {
            "benchmarks": [
                "DailyTalk"
            ],
            "base_models": [
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Specializing Smaller Language Models towards Multi-Step Reasoning": {
        "filename": "Specializing Smaller Language Models towards Multi-Step Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MultiArith",
                "ASDiv",
                "SVAMP",
                "BigBench Hard"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "FlanT5 (250M, 760M, 3B, 11B)"
            ]
        }
    },
    "Robust Planning with LLM-Modulo Framework Case Study in Travel Planning": {
        "filename": "Robust Planning with LLM-Modulo Framework Case Study in Travel Planning.pdf",
        "analysis": {
            "benchmarks": [
                "Travel Planning Benchmark"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4-Turbo"
            ]
        }
    },
    "BadRobot Manipulating Embodied LLMs in the Physical World": {
        "filename": "BadRobot Manipulating Embodied LLMs in the Physical World.pdf",
        "analysis": {
            "benchmarks": [
                "custom benchmark of malicious physical action queries"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-3.5-turbo",
                "GPT4o",
                "Yi-vision",
                "Llava-1.5-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks": {
        "filename": "Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA-USMLE",
                "StrategyQA",
                "OpenbookQA"
            ],
            "base_models": [
                "T5 (250M, 780M, 3B)",
                "OPT (350M, 1.3B-IML)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Looped Transformers as Programmable Computers": {
        "filename": "Looped Transformers as Programmable Computers.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175B parameters)",
                "PaLM (540B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Combining Cognitive and Generative AI for Self-Explanation in Interactive AI Agents": {
        "filename": "Combining Cognitive and Generative AI for Self-Explanation in Interactive AI Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 66 questions derived from earlier work"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5 Turbo)"
            ]
        }
    },
    "The Sound of Healthcare Improving Medical Transcription ASR Accuracy with Large Language Models": {
        "filename": "The Sound of Healthcare Improving Medical Transcription ASR Accuracy with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PriMock57"
            ],
            "base_models": [
                "Google Cloud's Gemini Pro",
                "Google Cloud's Gemini Ultra",
                "Google Cloud's Text Bison 32k",
                "Anthropic's Claude V2",
                "OpenAI's GPT-4",
                "Meta's LLaMA 2 (Chat 70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards the Scalable Evaluation of Cooperativeness in Language Models": {
        "filename": "Towards the Scalable Evaluation of Cooperativeness in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of 786 scenarios based on game-theoretic structures"
            ],
            "base_models": [
                "UnifiedQA",
                "GPT-3 (various sizes including instruct-tuned variants)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "forallutoexistsval Autonomous Assessment of LLMs in Formal Synthesis and Interpretation Tasks": {
        "filename": "forallutoexistsval Autonomous Assessment of LLMs in Formal Synthesis and Interpretation Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Propositional Logic",
                "First-order Logic",
                "Regular Expressions",
                "3-SAT"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-3.5-turbo",
                "Claude Sonnet",
                "LLama-3-8B-Instruct",
                "Mistral-v0.2-7B-Instruct",
                "Phi-3-medium-4k-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A criterion for Artificial General Intelligence hypothetic-deductive reasoning tested on ChatGPT": {
        "filename": "A criterion for Artificial General Intelligence hypothetic-deductive reasoning tested on ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "Neuron diagrams from Paul and Hall 2013"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Is In-Context Learning in Large Language Models Bayesian A Martingale Perspective": {
        "filename": "Is In-Context Learning in Large Language Models Bayesian A Martingale Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "Bernoulli experiment",
                "Gaussian experiment",
                "Synthetic natural language experiment"
            ],
            "base_models": [
                "Llama-2-7B",
                "Mistral-7B",
                "GPT-3 (2.7B and 170B)",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RAT Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation": {
        "filename": "RAT Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "HumanEval+",
                "MBPP",
                "MBPP+",
                "GSM8K",
                "GSMHard",
                "MC-TextWorld"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "CodeLLaMA-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Soft Contrastive Learning-Based Prompt Model for Few-Shot Sentiment Analysis": {
        "filename": "A Soft Contrastive Learning-Based Prompt Model for Few-Shot Sentiment Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "GoEmotions"
            ],
            "base_models": [
                "BERT base"
            ]
        }
    },
    "Large Language Models Are Also Good Prototypical Commonsense Reasoners": {
        "filename": "Large Language Models Are Also Good Prototypical Commonsense Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "ProtoQA",
                "StrategyQA",
                "CommonsenseQA2.0"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude",
                "Bard",
                "PaLM-2"
            ]
        }
    },
    "Is ChatGPT a Good Causal Reasoner A Comprehensive Evaluation": {
        "filename": "Is ChatGPT a Good Causal Reasoner A Comprehensive Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "EventStoryLine v0.9 (ESC)",
                "Causal-TimeBank (CTB)",
                "MA VEN-ERE",
                "COPA",
                "e-CARE"
            ],
            "base_models": [
                "text-davinci-002",
                "text-davinci-003",
                "gpt-3.5-turbo",
                "gpt-4",
                "BERT-Base",
                "RoBERTa-Base",
                "LLaMA 7B",
                "FLAN-T5 11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Shaky Foundations of Clinical Foundation Models A Survey of Large Language Models and Foundation Models for EMRs": {
        "filename": "The Shaky Foundations of Clinical Foundation Models A Survey of Large Language Models and Foundation Models for EMRs.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-III",
                "PubMed"
            ],
            "base_models": [
                "ehrBERT",
                "UCSF-Bert",
                "GatorTron"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Table Evolving Tables in the Reasoning Chain for Table Understanding": {
        "filename": "Chain-of-Table Evolving Tables in the Reasoning Chain for Table Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTQ",
                "FeTaQA",
                "TabFact"
            ],
            "base_models": [
                "PaLM 2",
                "GPT-3.5",
                "LLaMA 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Biomolecule and Natural Language through Multi-Modal Learning A Survey": {
        "filename": "Leveraging Biomolecule and Natural Language through Multi-Modal Learning A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "PubMed",
                "BBBP"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unnatural Instructions Tuning Language Models with Almost No Human Labor": {
        "filename": "Unnatural Instructions Tuning Language Models with Almost No Human Labor.pdf",
        "analysis": {
            "benchmarks": [
                "Super-Natural Instructions",
                "BIG-bench Hard",
                "LMentry"
            ],
            "base_models": [
                "T5-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Instructed Reinforcement Learning for Human-AI Coordination": {
        "filename": "Language Instructed Reinforcement Learning for Human-AI Coordination.pdf",
        "analysis": {
            "benchmarks": [
                "Hanabi",
                "Say-Select"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "GPT-J (6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Few-Shot Identification of Morality Frames using In-Context Learning": {
        "filename": "Towards Few-Shot Identification of Morality Frames using In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Roy et al. (2021) dataset"
            ],
            "base_models": [
                "GPT-J-6B",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Embodied LLM Agents Learn to Cooperate in Organized Teams": {
        "filename": "Embodied LLM Agents Learn to Cooperate in Organized Teams.pdf",
        "analysis": {
            "benchmarks": [
                "VirtualHome-Social"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Llama2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ICLEF In-Context Learning with Expert Feedback for Explainable Style Transfer": {
        "filename": "ICLEF In-Context Learning with Expert Feedback for Explainable Style Transfer.pdf",
        "analysis": {
            "benchmarks": [
                "E-GYAFC",
                "E-WNC"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "ChatGPT-4",
                "LLaMA-7B",
                "Alpaca-7B",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Legislative Models Towards Efficient AI Policymaking in Economic Simulations": {
        "filename": "Large Legislative Models Towards Efficient AI Policymaking in Economic Simulations.pdf",
        "analysis": {
            "benchmarks": [
                "Commons Harvest Open",
                "Clean Up",
                "Contextual Escape Room (CER)"
            ],
            "base_models": [
                "GPT-4o mini",
                "Gemini-1.5 flash"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automating Dataset Updates Towards Reliable and Timely Evaluation of Large Language Models": {
        "filename": "Automating Dataset Updates Towards Reliable and Timely Evaluation of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BIG-Bench"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT (gpt-3.5-turbo)",
                "Claude-3",
                "Llama-2-7b-chat",
                "Llama-2-13b-chat",
                "Llama-3-8b-Instruction",
                "Mistral-7B-Instruct-v0.2",
                "Mixtral-8x7B-Instruct-v0.1",
                "Yi-6b-chat",
                "Yi-34b-chat",
                "Claude2",
                "Gemini-pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How far is Language Model from 100 Few-shot Named Entity Recognition in Medical Domain": {
        "filename": "How far is Language Model from 100 Few-shot Named Entity Recognition in Medical Domain.pdf",
        "analysis": {
            "benchmarks": [
                "BC5CDR",
                "NCBI"
            ],
            "base_models": [
                "GPT-4",
                "BERT",
                "ClinicalBERT",
                "BioBERT",
                "GatorTron"
            ]
        }
    },
    "AI Safety in Generative AI Large Language Models A Survey": {
        "filename": "AI Safety in Generative AI Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "Measuring Massive Multitask Language Understanding (MMLU)",
                "Bias Benchmark for Question Answering (BBQ)",
                "Holistic Evaluation of Language Models (HELM)",
                "BigBench",
                "TruthfulQA"
            ],
            "base_models": [
                "GPT-4",
                "BLOOM",
                "Bard",
                "ChatGPT",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Breaking Language Barriers with a LEAP Learning Strategies for Polyglot LLMs": {
        "filename": "Breaking Language Barriers with a LEAP Learning Strategies for Polyglot LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "IndicQA",
                "TyDiQA"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)",
                "GPT3.5 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AlphaIntegrator Transformer Action Search for Symbolic Integration Proofs": {
        "filename": "AlphaIntegrator Transformer Action Search for Symbolic Integration Proofs.pdf",
        "analysis": {
            "benchmarks": [
                "custom step-by-step integration dataset"
            ],
            "base_models": [
                "GPT-style transformer (10M parameters)"
            ]
        }
    },
    "VaQuitA Enhancing Alignment in LLM-Assisted Video Understanding": {
        "filename": "VaQuitA Enhancing Alignment in LLM-Assisted Video Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "MSVD-QA",
                "MSRVTT-QA",
                "Activity Net-QA"
            ],
            "base_models": [
                "Llama 2 (7B)",
                "LLaMA (with weight initialization from LLaV A-1.5)"
            ]
        }
    },
    "Conformer LLMs - Convolution Augmented Large Language Models": {
        "filename": "Conformer LLMs - Convolution Augmented Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "YouTubeMix",
                "text8"
            ],
            "base_models": [
                "Transformer (128 embedding size)"
            ]
        }
    },
    "APPL A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts": {
        "filename": "APPL A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Justice or Prejudice Quantifying Biases in LLM-as-a-Judge": {
        "filename": "Justice or Prejudice Quantifying Biases in LLM-as-a-Judge.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "ScienceQA",
                "OpenOrca",
                "emerton_dpo",
                "Common-senseQA",
                "TruthfulQA"
            ],
            "base_models": [
                "GPT-4",
                "Llama3-8B",
                "Llama3-70B",
                "Mistral-7B",
                "Mixtral-8x22B",
                "ChatGPT",
                "GPT-4o",
                "Qwen-72b",
                "GLM-4",
                "Claude-3.5-Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGPT Beginning of an End of Manual Linguistic Data Annotation Use Case of Automatic Genre Identification": {
        "filename": "ChatGPT Beginning of an End of Manual Linguistic Data Annotation Use Case of Automatic Genre Identification.pdf",
        "analysis": {
            "benchmarks": [
                "EN-GINCO",
                "GINCO"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "XLM-RoBERTa"
            ]
        }
    },
    "Benchmarking Agentic Workflow Generation": {
        "filename": "Benchmarking Agentic Workflow Generation.pdf",
        "analysis": {
            "benchmarks": [
                "WORFBENCH"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-3.5",
                "O1",
                "Llama-3.1-8B",
                "Llama-3.1-70B",
                "Llama-2-13B",
                "Vicuna-13B",
                "WizardLM-13B",
                "WizardLM-70B",
                "Qwen-2-7B",
                "Qwen-2-72B",
                "Qwen-1.5-14B",
                "Mistral-7B",
                "Mixtral-8x7B",
                "Phi-3-small",
                "Phi-3-medium",
                "GLM-4-9B",
                "InternLM-2.5-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PET-SQL A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency": {
        "filename": "PET-SQL A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency.pdf",
        "analysis": {
            "benchmarks": [
                "Spider"
            ],
            "base_models": [
                "CodeLlama-34B",
                "SQLCoder-34B",
                "InternLM-70B",
                "SenseChat-70B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Verbalized Graph Representation Learning A Fully Interpretable Graph Model Based on Large Language Models Throughout the Entire Process": {
        "filename": "Verbalized Graph Representation Learning A Fully Interpretable Graph Model Based on Large Language Models Throughout the Entire Process.pdf",
        "analysis": {
            "benchmarks": [
                "Cora"
            ],
            "base_models": [
                "Llama3.1 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DEAL Disentangle and Localize Concept-level Explanations for VLMs": {
        "filename": "DEAL Disentangle and Localize Concept-level Explanations for VLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "CUB",
                "Food101",
                "Oxford-Pets",
                "EuroSAT"
            ],
            "base_models": [
                "CLIP (151M)",
                "FLAVA (241M)",
                "DeCLIP (186M)",
                "PyramidCLIP (153M)",
                "CLIPpy (196M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Coin3D Controllable and Interactive 3D Assets Generation with Proxy-Guided Conditioning": {
        "filename": "Coin3D Controllable and Interactive 3D Assets Generation with Proxy-Guided Conditioning.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InputSnatch Stealing Input in LLM Services via Timing Side-Channel Attacks": {
        "filename": "InputSnatch Stealing Input in LLM Services via Timing Side-Channel Attacks.pdf",
        "analysis": {
            "benchmarks": [
                "GPTCache"
            ],
            "base_models": [
                "GPT-4o-mini",
                "LLaMA-2 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EcomGPT Instruction-tuning Large Language Models with Chain-of-Task Tasks for E-commerce": {
        "filename": "EcomGPT Instruction-tuning Large Language Models with Chain-of-Task Tasks for E-commerce.pdf",
        "analysis": {
            "benchmarks": [
                "Lenove (Named Entity Recognition, Entity Span Detection)",
                "Reddit (Extractive QA)",
                "ABSA (Review Topic Classification)",
                "MEPA VE (Attribute Value Recognition, Attribute Value Detection)",
                "Multi-CPR (Product Select)",
                "OpenBG (Product Align, Title Attribute Matching, Fine-grain Product Classify, Coarse-grain Product Classify, Title Generate)"
            ],
            "base_models": [
                "BLOOMZ (560m, 1.7b, 3b, 7.1b)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Code Pretraining Improves Entity Tracking Abilities of Language Models": {
        "filename": "Code Pretraining Improves Entity Tracking Abilities of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ProPara",
                "bAbI tasks"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-3",
                "Llama 2 (7B–70B)",
                "DeepSeek (7B)",
                "Gemma (8B)",
                "Mistral (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distributed agency in second language learning and teaching through generative AI": {
        "filename": "Distributed agency in second language learning and teaching through generative AI.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "LaMDA",
                "GPT-4",
                "GPT 4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Promptor A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques": {
        "filename": "Promptor A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques.pdf",
        "analysis": {
            "benchmarks": [
                "KWickChat"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "V-STaR Training Verifiers for Self-Taught Reasoners": {
        "filename": "V-STaR Training Verifiers for Self-Taught Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH subset",
                "MBPP",
                "HumanEval"
            ],
            "base_models": [
                "LLaMA2 (7B, 13B)",
                "CodeLLaMA (7B, 13B)"
            ]
        }
    },
    "Anchoring Bias in Large Language Models An Experimental Study": {
        "filename": "Anchoring Bias in Large Language Models An Experimental Study.pdf",
        "analysis": {
            "benchmarks": [
                "Experimental dataset designed by Taha Yasseri"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Harmful Fine-tuning Attacks and Defenses for Large Language Models A Survey": {
        "filename": "Harmful Fine-tuning Attacks and Defenses for Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "SST2"
            ],
            "base_models": [
                "Llama2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Human IO Towards a Unified Approach to Detecting Situational Impairments": {
        "filename": "Human IO Towards a Unified Approach to Detecting Situational Impairments.pdf",
        "analysis": {
            "benchmarks": [
                "Ego4D"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "GPT-3 text-curie-001",
                "BLIP-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MindLLM Pre-training Lightweight Large Language Model from Scratch Evaluations and Domain Applications": {
        "filename": "MindLLM Pre-training Lightweight Large Language Model from Scratch Evaluations and Domain Applications.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "AGIEval",
                "C-Eval",
                "CMMLU",
                "Arithmetic",
                "GSM8K",
                "MATH",
                "HellaSwag",
                "WinoGrande",
                "LogiQA",
                "PubMedQA",
                "PIQA",
                "MathQA",
                "BBH",
                "Flores-101",
                "TruthfulQA",
                "ToxiGen",
                "Ethics"
            ],
            "base_models": [
                "MindLLM-1.3B (1.3 billion parameters)",
                "MindLLM-3B (3 billion parameters)",
                "GPT-Neo-1.3B",
                "GPT-J-6B",
                "Bloom-3B",
                "Bloom-7B",
                "MPT-7B",
                "MOSS-Base-16B",
                "Falcon-7B",
                "LLaMA-7B",
                "LLaMA-2-7B",
                "Open-LLaMA-3B",
                "Open-LLaMA-7B",
                "Baichuan2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VividDreamer Towards High-Fidelity and Efficient Text-to-3D Generation": {
        "filename": "VividDreamer Towards High-Fidelity and Efficient Text-to-3D Generation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Stable Diffusion",
                "Latent Consistency Model"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Test-Time Fairness and Robustness in Large Language Models": {
        "filename": "Test-Time Fairness and Robustness in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Toxic Comments (civilcomments)",
                "Bios",
                "Amazon fashion reviews",
                "Discrimination (synthetic dataset)",
                "Clinical (MIMIC-III)"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4-turbo",
                "LLAMA-3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tree Search for Language Model Agents": {
        "filename": "Tree Search for Language Model Agents.pdf",
        "analysis": {
            "benchmarks": [
                "VisualWebArena",
                "WebArena"
            ],
            "base_models": [
                "GPT-4o",
                "Llama-3-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI An Exploratory Analysis": {
        "filename": "Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI An Exploratory Analysis.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "PaLM 2"
            ]
        }
    },
    "Forward-Backward Reasoning in Large Language Models for Mathematical Verification": {
        "filename": "Forward-Backward Reasoning in Large Language Models for Mathematical Verification.pdf",
        "analysis": {
            "benchmarks": [
                "AddSub",
                "MultiArith",
                "SingleEQ",
                "SVAMP",
                "GSM8K",
                "AQuA"
            ],
            "base_models": [
                "text-davinci-003",
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Automated Startup Evaluation Pipeline Startup Success Forecasting Framework SSFF": {
        "filename": "An Automated Startup Evaluation Pipeline Startup Success Forecasting Framework SSFF.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AgentDojo A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents": {
        "filename": "AgentDojo A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "AgentDojo"
            ],
            "base_models": [
                "Llama 3 70B",
                "GPT-3.5 Turbo",
                "GPT-4 Turbo",
                "GPT-4o",
                "Claude 3 Opus",
                "Claude 3 Sonnet",
                "Claude 3.5 Sonnet",
                "Gemini 1.5 Flash",
                "Gemini 1.5 Pro",
                "Command-R+"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Building Cooperative Embodied Agents Modularly with Large Language Models": {
        "filename": "Building Cooperative Embodied Agents Modularly with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "C-WAH",
                "TDW-MAT"
            ],
            "base_models": [
                "GPT-4",
                "LLAMA-2-13b-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models": {
        "filename": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SCAN",
                "GSM8K",
                "DROP"
            ],
            "base_models": [
                "GPT-3 code-davinci-002",
                "GPT-3 text-davinci-002",
                "GPT-3 code-davinci-001"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-Context Learning Enables Robot Action Prediction in LLMs": {
        "filename": "In-Context Learning Enables Robot Action Prediction in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "RL-Bench simulation",
                "Franka Emika Panda real-world tasks"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "Claude-3.5",
                "Llama-3.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MAmmoTH2 Scaling Instructions from the Web": {
        "filename": "MAmmoTH2 Scaling Instructions from the Web.pdf",
        "analysis": {
            "benchmarks": [
                "TheoremQA",
                "GSM8K",
                "MATH",
                "ARC-C",
                "MMLU-STEM",
                "GPQA",
                "BBH"
            ],
            "base_models": [
                "Mistral-7B",
                "Llama3-8B",
                "Mixtral-8x7B",
                "Yi-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "End-to-End Ontology Learning with Large Language Models": {
        "filename": "End-to-End Ontology Learning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Wikipedia",
                "arXiv"
            ],
            "base_models": [
                "Mistral 7B v0.2",
                "REBEL-large (406M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Fine-grained Sentiment Analysis of App Reviews using Large Language Models An Evaluation Study": {
        "filename": "A Fine-grained Sentiment Analysis of App Reviews using Large Language Models An Evaluation Study.pdf",
        "analysis": {
            "benchmarks": [
                "Dabrowski et al. review dataset"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "LLama-2-7B",
                "LLama-2-13B",
                "LLama-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Robust Prompt Optimization for Large Language Models Against Distribution Shifts": {
        "filename": "Robust Prompt Optimization for Large Language Models Against Distribution Shifts.pdf",
        "analysis": {
            "benchmarks": [
                "Yelp",
                "Flipkart",
                "IMDB",
                "Amazon",
                "MNLI",
                "ANLI",
                "RTE",
                "HANS",
                "SocialIQA",
                "PIQA",
                "OpenbookQA",
                "DSTC7",
                "Ubuntu Dialog",
                "MuTual",
                "DROP"
            ],
            "base_models": [
                "gpt-3.5-turbo-0301"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Simultaneous Computation and Memory Efficient Zeroth-Order Optimizer for Fine-Tuning Large Language Models": {
        "filename": "Simultaneous Computation and Memory Efficient Zeroth-Order Optimizer for Fine-Tuning Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SuperGLUE",
                "SQuAD",
                "DROP"
            ],
            "base_models": [
                "OPT-13B",
                "OPT-1.3B",
                "OPT-30B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PINTO Faithful Language Reasoning Using Prompt-Generated Rationales": {
        "filename": "PINTO Faithful Language Reasoning Using Prompt-Generated Rationales.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "StrategyQA",
                "OpenBookQA",
                "QASC"
            ],
            "base_models": [
                "GPT-NeoX-20B",
                "T5-base (220M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AVI-Talking Learning Audio-Visual Instructions for Expressive 3D Talking Face Generation": {
        "filename": "AVI-Talking Learning Audio-Visual Instructions for Expressive 3D Talking Face Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MeadText",
                "RAVDESS"
            ],
            "base_models": [
                "LLaMA-7b",
                "HuBERT",
                "Wav2Vec 2.0"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Refining Decompiled C Code with Large Language Models": {
        "filename": "Refining Decompiled C Code with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Code Contest dataset"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Classification-Based Automatic HDL Code Generation Using LLMs": {
        "filename": "Classification-Based Automatic HDL Code Generation Using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "VerilogEval-human",
                "VerilogEval-machine"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Analyzing and Mitigating Object Hallucination in Large Vision-Language Models": {
        "filename": "Analyzing and Mitigating Object Hallucination in Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MSCOCO",
                "CHAIR"
            ],
            "base_models": [
                "MiniGPT-4 (Vicuna 13B)",
                "LLaVa (LLaMA 13B)",
                "MMGPT (LLaMA 7B)",
                "LLaMA-Adapter (LLaMA 7B)",
                "mPLUG-Owl (LLaMA 7B)",
                "InstructBLIP (Vicuna 7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Binary Code Summarization Benchmarking ChatGPTGPT-4 and Other Large Language Models": {
        "filename": "Binary Code Summarization Benchmarking ChatGPTGPT-4 and Other Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BinSum"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT (GPT-3.5)",
                "Llama 2 (7B)",
                "Llama 2 (13B)",
                "Code Llama (7B)",
                "Code Llama (13B)",
                "BinT5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Iterative Motion Editing with Natural Language": {
        "filename": "Iterative Motion Editing with Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "AMASS dataset"
            ],
            "base_models": [
                "ChatGPT-4",
                "MDM (Human Motion Diffusion Model)",
                "MoMask"
            ]
        }
    },
    "TidyBot Personalized Robot Assistance with Large Language Models": {
        "filename": "TidyBot Personalized Robot Assistance with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "publicly released benchmark dataset for evaluating generalization of receptacle selection preferences",
                "real-world test scenarios with TidyBot"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003 variant)",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoWebGLM A Large Language Model-based Web Navigating Agent": {
        "filename": "AutoWebGLM A Large Language Model-based Web Navigating Agent.pdf",
        "analysis": {
            "benchmarks": [
                "AutoWebBench",
                "Mind2Web",
                "MiniWob++",
                "WebArena"
            ],
            "base_models": [
                "ChatGLM3-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Solution toward Transparent and Practical AI Regulation Privacy Nutrition Labels for Open-source Generative AI-based Applications": {
        "filename": "A Solution toward Transparent and Practical AI Regulation Privacy Nutrition Labels for Open-source Generative AI-based Applications.pdf",
        "analysis": {
            "benchmarks": [
                "manual annotation dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Ernie"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Submodular Minimax Optimization Finding Effective Sets": {
        "filename": "Submodular Minimax Optimization Finding Effective Sets.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset for prompt engineering in question answering",
                "custom dataset for prompt engineering in dialog state tracking",
                "custom dataset for ride-sharing optimization",
                "custom dataset for adversarial image finding"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Better Reasoners with Self-Verification": {
        "filename": "Large Language Models are Better Reasoners with Self-Verification.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SingleEq",
                "AddSub",
                "MultiArith",
                "AQUA-RAT",
                "SVAMP",
                "CommonsenseQA (CSQA)",
                "Date Understanding (DU)"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "Instruct-GPT (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tackling Vision Language Tasks Through Learning Inner Monologues": {
        "filename": "Tackling Vision Language Tasks Through Learning Inner Monologues.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "SNLI-VE"
            ],
            "base_models": [
                "Vicuna-7B",
                "BLIP-2"
            ]
        }
    },
    "From Words to Molecules A Survey of Large Language Models in Chemistry": {
        "filename": "From Words to Molecules A Survey of Large Language Models in Chemistry.pdf",
        "analysis": {
            "benchmarks": [
                "USPTO 50k",
                "PubChemSTM"
            ],
            "base_models": [
                "BERT",
                "GPT-3",
                "RoBERTa",
                "T5",
                "SciBERT",
                "XLNet"
            ]
        }
    },
    "Learning Interpretable Concepts Unifying Causal Representation Learning and Foundation Models": {
        "filename": "Learning Interpretable Concepts Unifying Causal Representation Learning and Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA"
            ],
            "base_models": [
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Structured Chain-of-Thought Prompting for Code Generation": {
        "filename": "Structured Chain-of-Thought Prompting for Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "MBCPP"
            ],
            "base_models": [
                "ChatGPT",
                "Codex (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Solving Math Word Problems with Reexamination": {
        "filename": "Solving Math Word Problems with Reexamination.pdf",
        "analysis": {
            "benchmarks": [
                "Math23k",
                "MathQA",
                "MAWPS"
            ],
            "base_models": [
                "BERT",
                "Roberta-Base",
                "ChatGPT (gpt-3.5-turbo)"
            ]
        }
    },
    "LLAssist Simple Tools for Automating Literature Review Using Large Language Models": {
        "filename": "LLAssist Simple Tools for Automating Literature Review Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "IEEE Xplore Database",
                "Scopus Database"
            ],
            "base_models": [
                "Llama 3:8B",
                "Gemma 2:9B",
                "GPT-3.5-turbo-0125",
                "GPT-4o-2024-05-13"
            ]
        }
    },
    "Aligning Medical LLMs for Counterfactual Fairness": {
        "filename": "Aligning Medical LLMs for Counterfactual Fairness.pdf",
        "analysis": {
            "benchmarks": [
                "Q-Pain",
                "Treatment Recommendation",
                "Triage"
            ],
            "base_models": [
                "Llama 3.1 (8B)",
                "Gemma 2 (9B)",
                "Meditron (7B)",
                "Llama 3-OpenBioLLM (8B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ImposterAI Adversarial Attacks with Hidden Intentions towards Aligned Large Language Models": {
        "filename": "ImposterAI Adversarial Attacks with Hidden Intentions towards Aligned Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HarmfulQ dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "Llama2-13b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Grounded Decoding Guiding Text Generation with Grounded Models for Embodied Agents": {
        "filename": "Grounded Decoding Guiding Text Generation with Grounded Models for Embodied Agents.pdf",
        "analysis": {
            "benchmarks": [
                "RAVENS (custom set of 20 tasks)",
                "MiniGrid 2D Maze",
                "real-world kitchen mobile manipulation"
            ],
            "base_models": [
                "CLIPort",
                "PPO",
                "BERT",
                "CLIP",
                "owl-vit"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Faithful Chain-of-Thought Reasoning": {
        "filename": "Faithful Chain-of-Thought Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "MultiArith",
                "ASDiv",
                "AQuA",
                "StrategyQA",
                "Date Understanding (BIG-bench)",
                "Sports Understanding (BIG-bench)",
                "SayCan",
                "CLUTRR"
            ],
            "base_models": [
                "GPT-4",
                "Codex"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BoardgameQA A Dataset for Natural Language Reasoning with Contradictory Information": {
        "filename": "BoardgameQA A Dataset for Natural Language Reasoning with Contradictory Information.pdf",
        "analysis": {
            "benchmarks": [
                "BoardgameQA"
            ],
            "base_models": [
                "BERT Large",
                "T5 XXL",
                "PaLM 62B",
                "PaLM 540B",
                "FLAN PaLM 540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automate Knowledge Concept Tagging on Math Questions with LLMs": {
        "filename": "Automate Knowledge Concept Tagging on Math Questions with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MathKnowCT"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "LLAMA2-70B-Chat",
                "Mixtral-8*7B-Instruct",
                "Qwen1.5-72B-Chat",
                "InternLM2-20B-Chat",
                "InternLM2-20B-Math"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Whats the Magic Word A Control Theory of LLM Prompting": {
        "filename": "Whats the Magic Word A Control Theory of LLM Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "Wikitext"
            ],
            "base_models": [
                "Falcon-7b",
                "Llama-7b",
                "Falcon-40b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FELM Benchmarking Factuality Evaluation of Large Language Models": {
        "filename": "FELM Benchmarking Factuality Evaluation of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "FELM"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are few1-shot Table Reasoners": {
        "filename": "Large Language Models are few1-shot Table Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTableQuestions",
                "FetaQA",
                "TabFact",
                "FEVEROUS"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "Codex (Davinci-code-002)"
            ]
        }
    },
    "Generating Executable Action Plans with Environmentally-Aware Language Models": {
        "filename": "Generating Executable Action Plans with Environmentally-Aware Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "VirtualHome",
                "ActivityPrograms knowledge base"
            ],
            "base_models": [
                "GPT2-large",
                "all-roberta-large-v1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters": {
        "filename": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters.pdf",
        "analysis": {
            "benchmarks": [
                "MATH"
            ],
            "base_models": [
                "PaLM 2-S*"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Your Context Is Not an Array Unveiling Random Access Limitations in Transformers": {
        "filename": "Your Context Is Not an Array Unveiling Random Access Limitations in Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "binary parity task",
                "multi-digit addition task"
            ],
            "base_models": [
                "BLOOMZ-560M",
                "Pythia-410M",
                "OPT-350M",
                "Llama2-7B"
            ]
        }
    },
    "V-IRL Grounding Virtual Intelligence in Real Life": {
        "filename": "V-IRL Grounding Virtual Intelligence in Real Life.pdf",
        "analysis": {
            "benchmarks": [
                "V-IRL Place Detection",
                "V-IRL Place Recognition and VQA"
            ],
            "base_models": [
                "GPT-4",
                "LLaVA-1.5-13B",
                "CLIP (ViT-L/14@336px)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Model Compression for Large Language Models": {
        "filename": "A Survey on Model Compression for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WikiText-2",
                "C4",
                "PTB",
                "LAMBADA",
                "PIQA",
                "OpenBookQA",
                "GSM8K",
                "CommonsenseQA",
                "StrategyQA",
                "BIG-Bench (BBH)",
                "Vicuna-Instructions",
                "User-Oriented-Instructions",
                "EleutherAI LM Harness"
            ],
            "base_models": [
                "GPT-175B",
                "LLaMA-30B",
                "LLaMA2-13B",
                "LLaMA-13B",
                "LLaMA-65B",
                "LLaMA2-70B",
                "OPT-175B",
                "GPT-J-6B",
                "OPT-13B",
                "BLOOM-7B",
                "GPT-2",
                "T5",
                "FlanT5",
                "CodeT5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On Improving Summarization Factual Consistency from Natural Language Feedback": {
        "filename": "On Improving Summarization Factual Consistency from Natural Language Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "XSum",
                "DeFacto"
            ],
            "base_models": [
                "PEGASUS",
                "T5-3B",
                "T0-3B",
                "T0pp",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Conversational Disease Diagnosis via External Planner-Controlled Large Language Models": {
        "filename": "Conversational Disease Diagnosis via External Planner-Controlled Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-IV"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "Llama3-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automated Knowledge Concept Annotation and Question Representation Learning for Knowledge Tracing": {
        "filename": "Automated Knowledge Concept Annotation and Question Representation Learning for Knowledge Tracing.pdf",
        "analysis": {
            "benchmarks": [
                "XES3G5M",
                "Eedi"
            ],
            "base_models": [
                "GPT-4",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Neuron Patching Semantic-based Neuron-level Language Model Repair for Code Generation": {
        "filename": "Neuron Patching Semantic-based Neuron-level Language Model Repair for Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CoNaLa",
                "IA32",
                "TLDR",
                "custom benchmark for generalization and specificity"
            ],
            "base_models": [
                "StarCoder 2-3B",
                "CodeLlama-7B",
                "CodeGen-2B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Meta-Evaluation of Faithfulness Metrics for Long-Form Hospital-Course Summarization": {
        "filename": "A Meta-Evaluation of Faithfulness Metrics for Long-Form Hospital-Course Summarization.pdf",
        "analysis": {
            "benchmarks": [
                "HIV patient cohort dataset"
            ],
            "base_models": [
                "Longformer Encoder-Decoder (LED)",
                "BART-Large",
                "RoBERTA-Large",
                "SciFIVE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VLM See Robot Do Human Demo Video to Robot Action Plan via Vision Language Model": {
        "filename": "VLM See Robot Do Human Demo Video to Robot Action Plan via Vision Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "vegetable organization",
                "garments organization",
                "wooden block stacking"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bridging Low-level Geometry to High-level Concepts in Visual Servoing of Robot Manipulation Task Using Event Knowledge Graphs and Vision-Language Models": {
        "filename": "Bridging Low-level Geometry to High-level Concepts in Visual Servoing of Robot Manipulation Task Using Event Knowledge Graphs and Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "CLIP (ViT-B/16)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "THaLLE Text Hyperlocally Augmented Large Language Extension - Technical Report": {
        "filename": "THaLLE Text Hyperlocally Augmented Large Language Extension - Technical Report.pdf",
        "analysis": {
            "benchmarks": [
                "Flare CFA",
                "Internal Mock CFA Exam"
            ],
            "base_models": [
                "Llama3-8B",
                "Qwen2-7B",
                "Gemma-7B",
                "Llama-2-7B",
                "GPT-3.5-turbo",
                "GPT-4o",
                "Gemini-1.5-Flash",
                "Gemini-1.5-Pro"
            ]
        }
    },
    "Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation": {
        "filename": "Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Devign",
                "BigCloneBench",
                "ATLAS",
                "CodeSearchNet"
            ],
            "base_models": [
                "LLaMA (6B to 16B)",
                "Pythia (7B to 12B)",
                "GLM (6B)",
                "StarCoder (15B)",
                "CodeGen-multi (16B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mixture of Parrots Experts improve memorization more than reasoning": {
        "filename": "Mixture of Parrots Experts improve memorization more than reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "TriviaQA",
                "Natural Questions",
                "HellaSwag",
                "WinoGrande",
                "Hendrycks-MATH",
                "GSM8k"
            ],
            "base_models": [
                "Mistral",
                "Mixtral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DAWN Designing Distributed Agents in a Worldwide Network": {
        "filename": "DAWN Designing Distributed Agents in a Worldwide Network.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FactBench A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation": {
        "filename": "FactBench A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "FACTBENCH"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini1.5-Pro",
                "Llama3.1-70B-Instruct",
                "Llama3.1-405B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can ChatGPT Understand Too A Comparative Study on ChatGPT and Fine-tuned BERT": {
        "filename": "Can ChatGPT Understand Too A Comparative Study on ChatGPT and Fine-tuned BERT.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE"
            ],
            "base_models": [
                "ChatGPT",
                "BERT-base",
                "BERT-large",
                "RoBERTa-base",
                "RoBERTa-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "REEF A Framework for Collecting Real-World Vulnerabilities and Fixes": {
        "filename": "REEF A Framework for Collecting Real-World Vulnerabilities and Fixes.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset collected by REEF"
            ],
            "base_models": [
                "GPT-Neo (2.7B)",
                "Llama-7B",
                "Llama-13B",
                "ChatGLM (6B)",
                "Vicuna (13B)",
                "ChatGPT",
                "Tongyi",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automated Design of Agentic Systems": {
        "filename": "Automated Design of Agentic Systems.pdf",
        "analysis": {
            "benchmarks": [
                "ARC (Abstraction and Reasoning Corpus)",
                "DROP",
                "MGSM",
                "GSM8K",
                "GSM-Hard",
                "SVAMP",
                "ASDiv",
                "MMLU",
                "GPQA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude-Haiku",
                "Claude-Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM4Vis Explainable Visualization Recommendation using ChatGPT": {
        "filename": "LLM4Vis Explainable Visualization Recommendation using ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "VizML"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-16k)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GraphText Graph Reasoning in Text Space": {
        "filename": "GraphText Graph Reasoning in Text Space.pdf",
        "analysis": {
            "benchmarks": [
                "Cora",
                "Citeseer",
                "Texas",
                "Wisconsin",
                "Cornell"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "Llama-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distributed Speculative Inference of Large Language Models": {
        "filename": "Distributed Speculative Inference of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CNN-DM",
                "Alpaca",
                "HumanEval",
                "MBPP"
            ],
            "base_models": [
                "GPT-4",
                "Vicuna-13B",
                "Vicuna-7B",
                "Starcoder-15B",
                "Phi3-14B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cocoon Semantic Table Profiling Using Large Language Models": {
        "filename": "Cocoon Semantic Table Profiling Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Synthea Patient table"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Leveraging Large Language Models for Automated Web-Form-Test Generation An Empirical Study": {
        "filename": "Leveraging Large Language Models for Automated Web-Form-Test Generation An Empirical Study.pdf",
        "analysis": {
            "benchmarks": [
                "146 web forms from 30 open-source Java web applications"
            ],
            "base_models": [
                "GPT-4",
                "GLM-4",
                "Baichuan2",
                "GPT-3.5",
                "GLM-3",
                "GLM-4V",
                "LLaMa2-7B",
                "LLaMa2-13B",
                "LLaMa2-70B",
                "Spark-3",
                "Spark-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Concept Induction Analyzing Unstructured Text with High-Level Concepts Using LLooM": {
        "filename": "Concept Induction Analyzing Unstructured Text with High-Level Concepts Using LLooM.pdf",
        "analysis": {
            "benchmarks": [
                "toxic online comments dataset",
                "political social media content dataset",
                "HCI paper abstracts dataset",
                "NeurIPS 2020 broader impact statements dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models": {
        "filename": "A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TravelPlanner"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "GPT-3.5-Turbo",
                "Mistral-7B-32K",
                "Mixtral-8×7B-MoE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CourseGPT-zh an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization": {
        "filename": "CourseGPT-zh an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "custom QA dataset derived from examination papers and web pages in the field of communication principles"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "LLaMA",
                "ChatGLM3-6B"
            ]
        }
    },
    "Multimodal Grounding for Embodied AI via Augmented Reality Headsets for Natural Language Driven Task Planning": {
        "filename": "Multimodal Grounding for Embodied AI via Augmented Reality Headsets for Natural Language Driven Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "REVERIE",
                "R2R"
            ],
            "base_models": [
                "GPT-3",
                "PaLM",
                "ViLBERT"
            ]
        }
    },
    "Revisiting Large Language Models as Zero-shot Relation Extractors": {
        "filename": "Revisiting Large Language Models as Zero-shot Relation Extractors.pdf",
        "analysis": {
            "benchmarks": [
                "FewRel",
                "Wiki-ZSL",
                "TACRED",
                "TACREV",
                "Re-TACRED",
                "NYT"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-turbo)",
                "GPT-J-6B",
                "BLOOM-7.1B",
                "T0pp-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Compressed Chain of Thought Efficient Reasoning Through Dense Representations": {
        "filename": "Compressed Chain of Thought Efficient Reasoning Through Dense Representations.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "LLAMA 2-7B-CHAT"
            ]
        }
    },
    "Enabling Large Language Models to Perform Power System Simulations with Previously Unseen Tools A Case of Daline": {
        "filename": "Enabling Large Language Models to Perform Power System Simulations with Previously Unseen Tools A Case of Daline.pdf",
        "analysis": {
            "benchmarks": [
                "DALINE"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-3.5-Turbo"
            ]
        }
    },
    "Situated Natural Language Explanations": {
        "filename": "Situated Natural Language Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "CoS-E"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "Cohere command",
                "Llama2-7B",
                "Pythia-2.8B",
                "GPT2-base",
                "GPT2-medium",
                "GPT2-large"
            ]
        }
    },
    "Deception abilities emerged in large language models": {
        "filename": "Deception abilities emerged in large language models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "BLOOM",
                "FLAN-T5",
                "GPT-3 text-davinci-003",
                "GPT-2 XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Jailbreaking Black Box Large Language Models in Twenty Queries": {
        "filename": "Jailbreaking Black Box Large Language Models in Twenty Queries.pdf",
        "analysis": {
            "benchmarks": [
                "JailbreakBench",
                "AdvBench"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Vicuna-13B",
                "Llama-2-7B-chat",
                "Claude-1",
                "Claude-2",
                "Gemini-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Establishing Trustworthiness Rethinking Tasks and Model Evaluation": {
        "filename": "Establishing Trustworthiness Rethinking Tasks and Model Evaluation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "ChatGPT"
            ]
        }
    },
    "Inference-Time Intervention Eliciting Truthful Answers from a Language Model": {
        "filename": "Inference-Time Intervention Eliciting Truthful Answers from a Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA"
            ],
            "base_models": [
                "LLaMA-7B",
                "Alpaca (based on LLaMA)",
                "Vicuna (based on LLaMA)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cooperation Competition and Maliciousness LLM-Stakeholders Interactive Negotiation": {
        "filename": "Cooperation Competition and Maliciousness LLM-Stakeholders Interactive Negotiation.pdf",
        "analysis": {
            "benchmarks": [
                "custom negotiation games"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Llama2-13b",
                "Llama2-70b",
                "Llama3-70b",
                "Mixtral 8x7B",
                "Gemini Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4": {
        "filename": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4.pdf",
        "analysis": {
            "benchmarks": [
                "Aliyun",
                "Catak",
                "GraphMal",
                "VirusSample",
                "VirusShare"
            ],
            "base_models": [
                "GPT-4",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Android in the Wild A Large-Scale Dataset for Android Device Control": {
        "filename": "Android in the Wild A Large-Scale Dataset for Android Device Control.pdf",
        "analysis": {
            "benchmarks": [
                "AndroidEnv"
            ],
            "base_models": [
                "PaLM 2",
                "Transformer-based Behavioral Cloning (BC)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing LLMs for Power System Simulations A Feedback-driven Multi-agent Framework": {
        "filename": "Enhancing LLMs for Power System Simulations A Feedback-driven Multi-agent Framework.pdf",
        "analysis": {
            "benchmarks": [
                "DALINE",
                "MATPOWER"
            ],
            "base_models": [
                "ChatGPT 4o",
                "o1-preview"
            ]
        }
    },
    "Grace Language Models Meet Code Edits": {
        "filename": "Grace Language Models Meet Code Edits.pdf",
        "analysis": {
            "benchmarks": [
                "overwatch",
                "c3po"
            ],
            "base_models": [
                "codex-davinci-002",
                "CodeT5 (220M params)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Elephants Never Forget Memorization and Learning of Tabular Data in Large Language Models": {
        "filename": "Elephants Never Forget Memorization and Learning of Tabular Data in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Iris",
                "Wine",
                "Adult",
                "Housing",
                "OpenML Diabetes",
                "Kaggle Titanic",
                "ACS Income",
                "ACS Travel",
                "Spaceship Titanic",
                "FICO",
                "ICU"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "OLMo 7B",
                "Gemma2 27B",
                "Llama3 70B",
                "Qwen1.5 72B",
                "Llama3.1 405B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring generative AI assisted feedback writing for students written responses to a physics conceptual question with prompt engineering and few-shot learning": {
        "filename": "Exploring generative AI assisted feedback writing for students written responses to a physics conceptual question with prompt engineering and few-shot learning.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of student responses to a physics conceptual question"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "Seek and Solve Reasoning for Table Question Answering": {
        "filename": "Seek and Solve Reasoning for Table Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "HiTab",
                "WikiTableQuestions (WikiTQ)"
            ],
            "base_models": [
                "Mistral-7B-Instruct-v0.2",
                "Mixtral-8x7B-Instruct-v0.1",
                "Llama-3.1-8B-Instruct",
                "Llama-3.1-70B-Instruct"
            ]
        }
    },
    "Towards an Understanding of Stepwise Inference in Transformers A Synthetic Graph Navigation Model": {
        "filename": "Towards an Understanding of Stepwise Inference in Transformers A Synthetic Graph Navigation Model.pdf",
        "analysis": {
            "benchmarks": [
                "Synthetic Graph Navigation Task"
            ],
            "base_models": [
                "GPT architecture (2-layer Transformer)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rethinking VLMs and LLMs for Image Classification": {
        "filename": "Rethinking VLMs and LLMs for Image Classification.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR-100",
                "OOD-CV",
                "Weather",
                "Skin Cancer",
                "Hateful Memes",
                "ScienceQA",
                "Visual Genome Attribution",
                "Visual Genome Relation",
                "Abstract Scenes VQA",
                "Binary Abstract Scenes"
            ],
            "base_models": [
                "CLIP",
                "Flamingo (3B and 9B parameters)",
                "BLIP",
                "PNP-VQA (UnifiedQA)",
                "LiT-B/16 (BERT-base with 110M parameters)",
                "LiT-L/16 (BERT-large with 340M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CodeMMLU A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs": {
        "filename": "CodeMMLU A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs.pdf",
        "analysis": {
            "benchmarks": [
                "CodeMMLU",
                "HumanEval"
            ],
            "base_models": [
                "GPT-4",
                "Meta-Llama-3-70B",
                "Claude-3-sonnet",
                "Mixtral-8x7B-Instruct",
                "DeepSeek-moe-16b-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Vision Language Model-Empowered Contract Theory for AIGC Task Allocation in Teleoperation": {
        "filename": "Vision Language Model-Empowered Contract Theory for AIGC Task Allocation in Teleoperation.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from Unity3-based Teleoperation project"
            ],
            "base_models": [
                "LLaVA (based on LLaMA)",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Words A Mathematical Framework for Interpreting Large Language Models": {
        "filename": "Beyond Words A Mathematical Framework for Interpreting Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "PaLM",
                "GPT-4",
                "LLaMA"
            ]
        }
    },
    "ChatGPT Dont Tell Me What to Do Designing AI for Context Analysis in Humanitarian Frontline Negotiations": {
        "filename": "ChatGPT Dont Tell Me What to Do Designing AI for Context Analysis in Humanitarian Frontline Negotiations.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Graph Meets Large Language Model Progress and Future Directions": {
        "filename": "A Survey of Graph Meets Large Language Model Progress and Future Directions.pdf",
        "analysis": {
            "benchmarks": [
                "Cora",
                "Ogbn-Arxiv"
            ],
            "base_models": [
                "BERT",
                "GPT-3",
                "PaLM",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InternGPT Solving Vision-Centric Tasks by Interacting with Chatbots Beyond Language": {
        "filename": "InternGPT Solving Vision-Centric Tasks by Interacting with Chatbots Beyond Language.pdf",
        "analysis": {
            "benchmarks": [
                "COCO validation images"
            ],
            "base_models": [
                "ChatGPT-3.5-turbo",
                "GPT-4",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Proactive Agent Shifting LLM Agents from Reactive Responses to Active Assistance": {
        "filename": "Proactive Agent Shifting LLM Agents from Reactive Responses to Active Assistance.pdf",
        "analysis": {
            "benchmarks": [
                "ProactiveBench"
            ],
            "base_models": [
                "LLaMA-3.1-8B-Instruct",
                "Qwen2-7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Few-shot In-context Learning on Knowledge Base Question Answering": {
        "filename": "Few-shot In-context Learning on Knowledge Base Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "WebQSP",
                "GrailQA",
                "GraphQA",
                "MetaQA"
            ],
            "base_models": [
                "Codex"
            ]
        }
    },
    "Husky A Unified Open-Source Language Agent for Multi-Step Reasoning": {
        "filename": "Husky A Unified Open-Source Language Agent for Multi-Step Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "DROP*",
                "IIRC*",
                "HUSKY QA",
                "GSM-8K",
                "MATH",
                "Google DeepMind Mathematics",
                "MathQA",
                "TabMWP",
                "FinQA",
                "TAT-QA",
                "MultimodalQA",
                "Bamboogle",
                "HotpotQA",
                "StrategyQA"
            ],
            "base_models": [
                "Llama-2-7B",
                "Llama-2-13B",
                "Llama-3-8B",
                "DeepSeekCoder-7B-Instruct-v1.5",
                "DeepSeekMath-7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SPINE Online Semantic Planning for Missions with Incomplete Natural Language Specifications in Unstructured Environments": {
        "filename": "SPINE Online Semantic Planning for Missions with Incomplete Natural Language Specifications in Unstructured Environments.pdf",
        "analysis": {
            "benchmarks": [
                "Custom outdoor environments (20,000m2 area)"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RepairAgent An Autonomous LLM-Based Agent for Program Repair": {
        "filename": "RepairAgent An Autonomous LLM-Based Agent for Program Repair.pdf",
        "analysis": {
            "benchmarks": [
                "Defects4J",
                "GitBug-Java"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Long Is More for Alignment A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning": {
        "filename": "Long Is More for Alignment A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaEval 2.0",
                "Open LLM"
            ],
            "base_models": [
                "Llama-2-7B",
                "Llama-2-13B",
                "Mistral-7B-v0.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Zero-Shot Language Agent for Computer Control with Structured Reflection": {
        "filename": "A Zero-Shot Language Agent for Computer Control with Structured Reflection.pdf",
        "analysis": {
            "benchmarks": [
                "MINIWOB++"
            ],
            "base_models": [
                "PaLM2"
            ]
        }
    },
    "Capabilities of GPT-4 on Medical Challenge Problems": {
        "filename": "Capabilities of GPT-4 on Medical Challenge Problems.pdf",
        "analysis": {
            "benchmarks": [
                "USMLE Sample Exam",
                "USMLE Self Assessments",
                "MedQA",
                "PubMedQA",
                "MedMCQA",
                "MMLU"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Flan-PaLM 540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An In-depth Look at Geminis Language Abilities": {
        "filename": "An In-depth Look at Geminis Language Abilities.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BIG-Bench-Hard",
                "GSM8K",
                "SVAMP",
                "ASDIV",
                "MAWPS",
                "HumanEval",
                "ODEX",
                "FLORES",
                "WebArena"
            ],
            "base_models": [
                "Gemini Pro",
                "GPT 3.5 Turbo",
                "GPT 4 Turbo",
                "Mixtral (mistralai/Mixtral-8x7b-Instruct-v0.1)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Infant Agent A Tool-Integrated Logic-Driven Agent with Cost-Effective API Usage": {
        "filename": "Infant Agent A Tool-Integrated Logic-Driven Agent with Cost-Effective API Usage.pdf",
        "analysis": {
            "benchmarks": [
                "SWE-bench-lite",
                "AIME2024",
                "GPQA Diamond",
                "Codeforce contests"
            ],
            "base_models": [
                "GPT-4o",
                "Qwen2.5-72B-Instruct"
            ]
        }
    },
    "Can Pretrained Language Models Yet Reason Deductively": {
        "filename": "Can Pretrained Language Models Yet Reason Deductively.pdf",
        "analysis": {
            "benchmarks": [
                "Leap of Thought (LoT)",
                "WikiData (WD)"
            ],
            "base_models": [
                "BERT (base)",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM as a Mastermind A Survey of Strategic Reasoning with Large Language Models": {
        "filename": "LLM as a Mastermind A Survey of Strategic Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BigToM",
                "SOTOPIA",
                "UGI",
                "OpenToM",
                "Avalonbench",
                "Welfare diplomacy",
                "Cicero",
                "MAgIC",
                "γ-Bench"
            ],
            "base_models": [
                "GPT-4",
                "ChessGPT",
                "PokerGPT",
                "LLaMAC"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Power of Question Translation Training in Multilingual Reasoning Broadened Scope and Deepened Insights": {
        "filename": "The Power of Question Translation Training in Multilingual Reasoning Broadened Scope and Deepened Insights.pdf",
        "analysis": {
            "benchmarks": [
                "MGSM",
                "MSVAMP",
                "XCSQA",
                "XNLI"
            ],
            "base_models": [
                "LLaMA2-7B",
                "LLaMA2-13B",
                "LLaMA2-70B",
                "LLaMA3-8B",
                "CodeLLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Data Augmentation for Sparse Multidimensional Learning Performance Data Using Generative AI": {
        "filename": "Data Augmentation for Sparse Multidimensional Learning Performance Data Using Generative AI.pdf",
        "analysis": {
            "benchmarks": [
                "AutoTutor Adult Reading Comprehension (ARC) dataset"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "14 examples of how LLMs can transform materials science and chemistry a reflection on a large language model hackathon": {
        "filename": "14 examples of how LLMs can transform materials science and chemistry a reflection on a large language model hackathon.pdf",
        "analysis": {
            "benchmarks": [
                "QM9-G4MP2 dataset",
                "Open Reaction Database (ORD)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "GPT-2 (medium)",
                "T5",
                "text-davinci-003",
                "GPT-2-LoRA",
                "ScholarBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GLM-130B An Open Bilingual Pre-trained Model": {
        "filename": "GLM-130B An Open Bilingual Pre-trained Model.pdf",
        "analysis": {
            "benchmarks": [
                "LAMBADA",
                "MMLU",
                "CLUE",
                "FewCLUE",
                "Pile",
                "BIG-bench-lite"
            ],
            "base_models": [
                "GPT-3 175B",
                "PaLM 540B",
                "OPT-175B",
                "BLOOM-176B",
                "ERNIE TITAN 3.0 260B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding and Predicting Human Label Variation in Natural Language Inference through Explanation": {
        "filename": "Understanding and Predicting Human Label Variation in Natural Language Inference through Explanation.pdf",
        "analysis": {
            "benchmarks": [
                "MNLI",
                "LIVENLI"
            ],
            "base_models": [
                "GPT-3"
            ]
        }
    },
    "Large Language Models and Knowledge Graphs Opportunities and Challenges": {
        "filename": "Large Language Models and Knowledge Graphs Opportunities and Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "LAMA",
                "KAMEL"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "GPT-3",
                "GPT-4",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Risk Taxonomy Mitigation and Assessment Benchmarks of Large Language Model Systems": {
        "filename": "Risk Taxonomy Mitigation and Assessment Benchmarks of Large Language Model Systems.pdf",
        "analysis": {
            "benchmarks": [
                "None specified"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-3",
                "GPT-3.5",
                "GPT-4",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Autoregression Discrete Diffusion for Complex Reasoning and Planning": {
        "filename": "Beyond Autoregression Discrete Diffusion for Complex Reasoning and Planning.pdf",
        "analysis": {
            "benchmarks": [
                "Countdown",
                "Sudoku",
                "Boolean Satisfiability Problem (SAT)"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-7B",
                "LLaMA-13B",
                "GPT-2 (6M, 85M, 303M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan A Multi-Player Cooperative Game under Imperfect Information": {
        "filename": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan A Multi-Player Cooperative Game under Imperfect Information.pdf",
        "analysis": {
            "benchmarks": [
                "Guandan"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "GPT-3.5-Turbo",
                "Baichuan2-7B-Chat",
                "Baichuan2-13B-Chat",
                "chatglm3-6b-32k",
                "Qwen1.5-7B-Chat",
                "Qwen1.5-14B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Process-Driven Autoformalization in Lean 4": {
        "filename": "Process-Driven Autoformalization in Lean 4.pdf",
        "analysis": {
            "benchmarks": [
                "FORM L4"
            ],
            "base_models": [
                "GPT-4",
                "Gemini-Pro-1.5",
                "Mistral-v0.3-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Is GPT Powerful Enough to Analyze the Emotions of Memes": {
        "filename": "Is GPT Powerful Enough to Analyze the Emotions of Memes.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval-2020 Task 8",
                "Facebook Hateful Memes"
            ],
            "base_models": [
                "GPT-3.5-Turbo"
            ]
        }
    },
    "ZeFaV Boosting Large Language Models for Zero-Shot Fact Verification": {
        "filename": "ZeFaV Boosting Large Language Models for Zero-Shot Fact Verification.pdf",
        "analysis": {
            "benchmarks": [
                "HoVer",
                "FEVEROUS-S"
            ],
            "base_models": [
                "Meta-Llama-3-70B-Instruct"
            ]
        }
    },
    "RSL-SQL Robust Schema Linking in Text-to-SQL Generation": {
        "filename": "RSL-SQL Robust Schema Linking in Text-to-SQL Generation.pdf",
        "analysis": {
            "benchmarks": [
                "BIRD",
                "Spider"
            ],
            "base_models": [
                "GPT-4o",
                "DeepSeek"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "System 2 Attention is something you might need too": {
        "filename": "System 2 Attention is something you might need too.pdf",
        "analysis": {
            "benchmarks": [
                "modified TriviaQA from SycophancyEval",
                "GSM-IC"
            ],
            "base_models": [
                "LLaMA-2-70B-chat"
            ]
        }
    },
    "RLPrompt Optimizing Discrete Text Prompts with Reinforcement Learning": {
        "filename": "RLPrompt Optimizing Discrete Text Prompts with Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "Yelp Polarity",
                "MR",
                "CR",
                "SST-5",
                "Yelp",
                "AG's News"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "GPT-2",
                "distilGPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LayoutLLM Layout Instruction Tuning with Large Language Models for Document Understanding": {
        "filename": "LayoutLLM Layout Instruction Tuning with Large Language Models for Document Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "DocVQA",
                "VisualMRC",
                "FUNSD",
                "CORD",
                "SROIE"
            ],
            "base_models": [
                "LayoutLMv3-large",
                "Vicuna-7B-v1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The effect of source disclosure on evaluation of AI-generated messages A two-part study": {
        "filename": "The effect of source disclosure on evaluation of AI-generated messages A two-part study.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset: Vaping prevention messages"
            ],
            "base_models": [
                "GPT-4",
                "Bloom (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A dataset and benchmark for hospital course summarization with adapted large language models": {
        "filename": "A dataset and benchmark for hospital course summarization with adapted large language models.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-IV-BHC"
            ],
            "base_models": [
                "Clinical-T5-Large",
                "Llama2-13B",
                "FLAN-UL2",
                "GPT-3.5 (175B)",
                "GPT-4"
            ]
        }
    },
    "Hypothesis Generation with Large Language Models": {
        "filename": "Hypothesis Generation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SHOE SALES",
                "DECEPTIVE REVIEWS",
                "HEADLINE POPULARITY",
                "TWEET POPULARITY"
            ],
            "base_models": [
                "RoBERTa",
                "Llama-2-7B",
                "GPT-3.5-turbo",
                "Mixtral",
                "Claude-2.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ARN Analogical Reasoning on Narratives": {
        "filename": "ARN Analogical Reasoning on Narratives.pdf",
        "analysis": {
            "benchmarks": [
                "ARN (Analogical Reasoning on Narratives)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "UnifiedQA-11B",
                "Llama-2-13B",
                "FlanT5-xxl",
                "Macaw-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AiBAT Artificial IntelligenceInstructions for Build Assembly and Test": {
        "filename": "AiBAT Artificial IntelligenceInstructions for Build Assembly and Test.pdf",
        "analysis": {
            "benchmarks": [
                "Custom JPL assembly drawing documents",
                "Custom IBAT documents"
            ],
            "base_models": [
                "Mistral 7B"
            ]
        }
    },
    "Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning": {
        "filename": "Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Overcooked",
                "MiniRTS"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Contextual Emotion Recognition using Large Vision Language Models": {
        "filename": "Contextual Emotion Recognition using Large Vision Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "EMOTIC"
            ],
            "base_models": [
                "GPT-4",
                "CLIP",
                "LLaVA",
                "Mistral 7B",
                "GPT-4 Vision"
            ]
        }
    },
    "The Good the Bad and the Hulk-like GPT Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games": {
        "filename": "The Good the Bad and the Hulk-like GPT Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games.pdf",
        "analysis": {
            "benchmarks": [
                "Ultimatum Game",
                "Dictator Game",
                "Prisoner's Dilemma",
                "Battle of the Sexes"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Labyrinth of Links Navigating the Associative Maze of Multi-modal LLMs": {
        "filename": "The Labyrinth of Links Navigating the Associative Maze of Multi-modal LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Object Concept Learning (OCL)",
                "Pangea"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini-1.5-Flash",
                "LLaVA-OneVision",
                "Qwen2-VL",
                "mPLUG-Owl3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chinese Metaphor Recognition Using a Multi-stage Prompting Large Language Model": {
        "filename": "Chinese Metaphor Recognition Using a Multi-stage Prompting Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "NLPCC-2024 Shared Task 9"
            ],
            "base_models": [
                "DeBERTa",
                "Qwen2-plus"
            ]
        }
    },
    "Maieutic Prompting Logically Consistent Reasoning with Recursive Explanations": {
        "filename": "Maieutic Prompting Logically Consistent Reasoning with Recursive Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "Com2Sense",
                "CSQA 2.0",
                "CREAK"
            ],
            "base_models": [
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "S3HQA A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering": {
        "filename": "S3HQA A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "HybridQA"
            ],
            "base_models": [
                "BERT-base-uncased",
                "Deberta-base",
                "BART-large",
                "GPT-3.5"
            ]
        }
    },
    "Auto MC-Reward Automated Dense Reward Design with Large Language Models for Minecraft": {
        "filename": "Auto MC-Reward Automated Dense Reward Design with Large Language Models for Minecraft.pdf",
        "analysis": {
            "benchmarks": [
                "Exploring diamond ore underground",
                "Approaching tree in plains biome",
                "Approaching specific animal in plains biome",
                "Obtaining diamond"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The gene function prediction challenge Large language models and knowledge graphs to the rescue": {
        "filename": "The gene function prediction challenge Large language models and knowledge graphs to the rescue.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT",
                "GPT",
                "BioGPT",
                "BioBERT",
                "SciBERT",
                "scGPT",
                "AgroNT"
            ]
        }
    },
    "PentestGPT An LLM-empowered Automatic Penetration Testing Tool": {
        "filename": "PentestGPT An LLM-empowered Automatic Penetration Testing Tool.pdf",
        "analysis": {
            "benchmarks": [
                "HackTheBox",
                "VulnHub",
                "picoMini CTF"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Bard"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "D-Bot Database Diagnosis System using Large Language Models": {
        "filename": "D-Bot Database Diagnosis System using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "real benchmarks (including 539 anomalies of six typical applications)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Llama 2",
                "CodeLlama",
                "Baichuan 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RoboScript Code Generation for Free-Form Manipulation Tasks across Real and Simulation": {
        "filename": "RoboScript Code Generation for Free-Form Manipulation Tasks across Real and Simulation.pdf",
        "analysis": {
            "benchmarks": [
                "RobotScript Benchmark"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MMAU A Holistic Benchmark of Agent Capabilities Across Diverse Domains": {
        "filename": "MMAU A Holistic Benchmark of Agent Capabilities Across Diverse Domains.pdf",
        "analysis": {
            "benchmarks": [
                "MMAU",
                "CodeContest",
                "Kaggle",
                "DeepMind-Math"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4-Turbo",
                "GPT-3.5-Turbo",
                "Gemini-1.5-pro",
                "Gemini-1.0-pro",
                "Claude3 Opus",
                "Claude3 Sonnet",
                "Claude3 Haiku",
                "Mixtral-8x22B-v0.1",
                "Mixtral-8x7B-v0.1",
                "Mistral-7B-v0.2",
                "Phi-3-mini4K-instruct",
                "Openfunctions-v2",
                "Hermes-2-Pro-Mistral-7B",
                "Command R",
                "LLama2-70B",
                "Llama2-13B",
                "Llama2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Principled Instructions Are All You Need for Questioning LLaMA-12 GPT-354": {
        "filename": "Principled Instructions Are All You Need for Questioning LLaMA-12 GPT-354.pdf",
        "analysis": {
            "benchmarks": [
                "ATLAS"
            ],
            "base_models": [
                "LLaMA-1 (7B, 13B)",
                "LLaMA-2 (7B, 13B, 70B)",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "R2-Bench Benchmarking the Robustness of Referring Perception Models under Perturbations": {
        "filename": "R2-Bench Benchmarking the Robustness of Referring Perception Models under Perturbations.pdf",
        "analysis": {
            "benchmarks": [
                "RefCOCO",
                "RefCOCO+",
                "RefCOCOg",
                "DAVIS",
                "YTVOS",
                "Ref-DAVIS",
                "Ref-YTVOS",
                "AVS-s4",
                "AVS-ms3",
                "ScanNet",
                "ICL"
            ],
            "base_models": [
                "Gemini-Vision-Pro",
                "PolyFormer",
                "LAVT",
                "X-Decoder",
                "ETRIS",
                "SEEM",
                "AOT",
                "DeAOT",
                "XMem",
                "DEVA",
                "Cutie",
                "MTTR",
                "SgMg",
                "ReferFormer",
                "OnlineRefer",
                "R2-VOS",
                "AVS",
                "CATR",
                "AVSegFormer",
                "QSD"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Location is Key Leveraging Large Language Model for Functional Bug Localization in Verilog": {
        "filename": "Location is Key Leveraging Large Language Model for Functional Bug Localization in Verilog.pdf",
        "analysis": {
            "benchmarks": [
                "RTLLM-based testset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude-3.5-Sonnet",
                "Deepseek-coder-V2-Lite-base-16B"
            ]
        }
    },
    "Benchmarking and Explaining Large Language Model-based Code Generation A Causality-Centric Approach": {
        "filename": "Benchmarking and Explaining Large Language Model-based Code Generation A Causality-Centric Approach.pdf",
        "analysis": {
            "benchmarks": [
                "CodeSearchNet",
                "HumanEval"
            ],
            "base_models": [
                "GPT-Neo (2.7B)",
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Comparing Foundation Models using Data Kernels": {
        "filename": "Comparing Foundation Models using Data Kernels.pdf",
        "analysis": {
            "benchmarks": [
                "DBPedia14"
            ],
            "base_models": [
                "BERT"
            ]
        }
    },
    "Towards the Effect of Examples on In-Context Learning A Theoretical Case Study": {
        "filename": "Towards the Effect of Examples on In-Context Learning A Theoretical Case Study.pdf",
        "analysis": {
            "benchmarks": [
                "SST2"
            ],
            "base_models": [
                "GPT-2",
                "Pythia-6.9B",
                "Llama2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MALMM Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation": {
        "filename": "MALMM Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "RLBench"
            ],
            "base_models": [
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Meta-Reasoning Semantics-Symbol Deconstruction For Large Language Models": {
        "filename": "Meta-Reasoning Semantics-Symbol Deconstruction For Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith",
                "GSM8K",
                "AddSub",
                "Last Letter Concatenation",
                "Coin Flip",
                "Web of Lies",
                "Tracking Shuffled Objects",
                "Hi-ToM"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "ChatGPT (GPT-3.5-Turbo)",
                "Codex (175B)",
                "PaLM (540B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models with Rationality": {
        "filename": "Language Models with Rationality.pdf",
        "analysis": {
            "benchmarks": [
                "EntailmentBank",
                "OBQA",
                "QuaRTz"
            ],
            "base_models": [
                "T5-11B"
            ]
        }
    },
    "Evaluation of ChatGPTs Smart Contract Auditing Capabilities Based on Chain of Thought": {
        "filename": "Evaluation of ChatGPTs Smart Contract Auditing Capabilities Based on Chain of Thought.pdf",
        "analysis": {
            "benchmarks": [
                "SolidiFI-benchmark"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Knowledge-aware Alert Aggregation in Large-scale Cloud Systems a Hybrid Approach": {
        "filename": "Knowledge-aware Alert Aggregation in Large-scale Cloud Systems a Hybrid Approach.pdf",
        "analysis": {
            "benchmarks": [
                "Dataset A",
                "Dataset B",
                "Dataset C"
            ],
            "base_models": [
                "Internal LLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hints-In-Browser Benchmarking Language Models for Programming Feedback Generation": {
        "filename": "Hints-In-Browser Benchmarking Language Models for Programming Feedback Generation.pdf",
        "analysis": {
            "benchmarks": [
                "BASIC ALGO",
                "INTRO PYNUS",
                "KAREL ALGO"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Llama-3-8B",
                "Phi-3-3.8B"
            ]
        }
    },
    "GraphRouter A Graph-based Router for LLM Selections": {
        "filename": "GraphRouter A Graph-based Router for LLM Selections.pdf",
        "analysis": {
            "benchmarks": [
                "Alpaca",
                "GSM8K",
                "SQUAD",
                "Multi-News"
            ],
            "base_models": [
                "LLaMA-3 (7b)",
                "Mixtral-8x7B (56b)",
                "NousResearch (34b)",
                "LLaMA-2 (7b)",
                "Mistral-7b",
                "LLaMA-3 (70b)",
                "LLaMA-3-Turbo (8b)",
                "LLaMA-3-Turbo (70b)",
                "Llama-3.1-Turbo (70b)",
                "Qwen-1.5 (72b)"
            ]
        }
    },
    "Programming Every Example Lifting Pre-training Data Quality like Experts at Scale": {
        "filename": "Programming Every Example Lifting Pre-training Data Quality like Experts at Scale.pdf",
        "analysis": {
            "benchmarks": [
                "ARC-C",
                "ARC-E",
                "CSQA",
                "HellaSwag",
                "MMLU",
                "OBQA",
                "PIQA",
                "SIQA",
                "WinoGrande",
                "SciQA"
            ],
            "base_models": [
                "LLAMA-2-7B",
                "CODELLAMA-7B",
                "MISTRAL-7B",
                "TinyLLaMA-1.1B",
                "Pythia-1.4B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large Language Models Reasoning": {
        "filename": "Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large Language Models Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "ASDiv",
                "MAWPS",
                "Cluttr",
                "List Functions",
                "Babi-Induction",
                "Babi-Deduction",
                "First Letter Concatenation",
                "Last Letter Concatenation",
                "Reverse List",
                "Coin Flip"
            ],
            "base_models": [
                "Llama-1",
                "Llama-2",
                "Llama-3",
                "Mistral",
                "Qwen-1.5",
                "Gemma"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Gödel Agent A Self-Referential Agent Framework for Recursive Self-Improvement": {
        "filename": "Gödel Agent A Self-Referential Agent Framework for Recursive Self-Improvement.pdf",
        "analysis": {
            "benchmarks": [
                "DROP",
                "MGSM",
                "MMLU",
                "GPQA"
            ],
            "base_models": [
                "GPT-4 (OpenAI et al., 2024)",
                "LLaMA3 (Dubey et al., 2024)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PROMPT-SAW Leveraging Relation-Aware Graphs for Textual Prompt Compression": {
        "filename": "PROMPT-SAW Leveraging Relation-Aware Graphs for Textual Prompt Compression.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K-aug",
                "NaturalQuestions",
                "ShareGPT"
            ],
            "base_models": [
                "GPT3.5-turbo",
                "LLaMA2-7B-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Labels Aligning Large Language Models with Human-like Reasoning": {
        "filename": "Beyond Labels Aligning Large Language Models with Human-like Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "DFAR",
                "ETHOS"
            ],
            "base_models": [
                "Llama-2 (7B)",
                "Mistral (7B)"
            ]
        }
    },
    "A Personalised Learning Tool for Physics Undergraduate Students Built On a Large Language Model for Symbolic Regression": {
        "filename": "A Personalised Learning Tool for Physics Undergraduate Students Built On a Large Language Model for Symbolic Regression.pdf",
        "analysis": {
            "benchmarks": [
                "Feynman's lectures on physics"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "AutoGPTP Affordance-based Task Planning with Large Language Models": {
        "filename": "AutoGPTP Affordance-based Task Planning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SayCan instruction set",
                "newly created dataset with 150 scenarios"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-3.5-turbo-0613",
                "GPT-4-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Exploratory Learning through Exploratory Search with the Emergence of Large Language Models": {
        "filename": "Enhancing Exploratory Learning through Exploratory Search with the Emergence of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "Do LLMs Exhibit Human-like Response Biases A Case Study in Survey Design": {
        "filename": "Do LLMs Exhibit Human-like Response Biases A Case Study in Survey Design.pdf",
        "analysis": {
            "benchmarks": [
                "Pew Research's American Trends Panel (ATP)"
            ],
            "base_models": [
                "Llama2-7b",
                "Llama2-13b",
                "Llama2-70b",
                "Solar (instruction fine-tuned Llama2-70b)",
                "Llama2-7b-chat",
                "Llama2-13b-chat",
                "Llama2-70b-chat",
                "GPT-3.5 turbo",
                "GPT-3.5 turbo instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Empowering Autonomous Driving with Large Language Models A Safety Perspective": {
        "filename": "Empowering Autonomous Driving with Large Language Models A Safety Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "HighwayEnv"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Can Language Models Learn to Skip Steps": {
        "filename": "Can Language Models Learn to Skip Steps.pdf",
        "analysis": {
            "benchmarks": [
                "Analog of Algebra",
                "Multi-digit Addition",
                "Directional Reasoning"
            ],
            "base_models": [
                "Llama 2 (7B)",
                "phi-3-mini (3.8B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Model Self-improvement by Reinforcement Learning Contemplation": {
        "filename": "Language Model Self-improvement by Reinforcement Learning Contemplation.pdf",
        "analysis": {
            "benchmarks": [
                "CommonGen",
                "Bigbench-hard",
                "CNN/Daily Mail",
                "BBC",
                "IWSLT 2017"
            ],
            "base_models": [
                "FLAN-T5-Large (780M)",
                "FLAN-T5-XL (3B)",
                "FLAN-T5-XXL (11B)",
                "FLAN-T5-Small (80M)",
                "FLAN-T5-Base (250M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tool-Augmented Reward Modeling": {
        "filename": "Tool-Augmented Reward Modeling.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "Retarded-bar"
            ],
            "base_models": [
                "Gopher 280B",
                "Vicuna-7B",
                "Vicuna-33B",
                "Bert-Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EnvGen Generating and Adapting Environments via LLMs for Training Embodied Agents": {
        "filename": "EnvGen Generating and Adapting Environments via LLMs for Training Embodied Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Crafter",
                "Heist"
            ],
            "base_models": [
                "GPT-4",
                "Codex"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evidence from counterfactual tasks supports emergent analogical reasoning in large language models": {
        "filename": "Evidence from counterfactual tasks supports emergent analogical reasoning in large language models.pdf",
        "analysis": {
            "benchmarks": [
                "Digit Matrices",
                "Letter-string analogy variants"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ]
        }
    },
    "2AFC Prompting of Large Multimodal Models for Image Quality Assessment": {
        "filename": "2AFC Prompting of Large Multimodal Models for Image Quality Assessment.pdf",
        "analysis": {
            "benchmarks": [
                "CSIQ",
                "KADID-10k",
                "MM21",
                "CLIVE",
                "KonIQ-10k",
                "SPAQ",
                "KADIS-700k",
                "SQAD"
            ],
            "base_models": [
                "IDEFICS-Instruct (based on LLaMA-9B)",
                "mPLUG-Owl (based on LLaMA-7B)",
                "XComposer-VL (based on InternLM-7B)",
                "Q-Instruct (based on LLaVA v1.5-7B)",
                "GPT-4V"
            ]
        }
    },
    "TrojanRobot Backdoor Attacks Against LLM-based Embodied Robots in the Physical World": {
        "filename": "TrojanRobot Backdoor Attacks Against LLM-based Embodied Robots in the Physical World.pdf",
        "analysis": {
            "benchmarks": [
                "custom physical-world experiments"
            ],
            "base_models": [
                "Yi-large",
                "Yi-vision language model",
                "moondream2 (4B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Decompose Hypothetical Question Decomposition Based on Comparable Texts": {
        "filename": "Learning to Decompose Hypothetical Question Decomposition Based on Comparable Texts.pdf",
        "analysis": {
            "benchmarks": [
                "Overnight",
                "TORQUE",
                "HotpotQA",
                "StrategyQA"
            ],
            "base_models": [
                "T5-large (770M parameters)",
                "GPT-3 (175B parameters)"
            ]
        }
    },
    "Why think step-by-step Reasoning emerges from the locality of experience": {
        "filename": "Why think step-by-step Reasoning emerges from the locality of experience.pdf",
        "analysis": {
            "benchmarks": [
                "custom synthetic Bayes nets"
            ],
            "base_models": [
                "GPT-2 (10 layers, 8 attention heads, 512-dimensional embeddings)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs": {
        "filename": "Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Letter Concatenation",
                "Date Understanding",
                "Math401",
                "AddSub",
                "Math10k"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-7B"
            ]
        }
    },
    "How Good Or Bad Are LLMs at Detecting Misleading Visualizations": {
        "filename": "How Good Or Bad Are LLMs at Detecting Misleading Visualizations.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of misleading charts from the internet"
            ],
            "base_models": [
                "ChatGPT (gpt-4-1106-vision-preview)",
                "Copilot (model name not specified)",
                "Gemini (gemini-pro-vision)",
                "LLaVA-NeXT (llava-v1.6-mistral-7b-hf, 7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mitigating Copy Bias in In-Context Learning through Neuron Pruning": {
        "filename": "Mitigating Copy Bias in In-Context Learning through Neuron Pruning.pdf",
        "analysis": {
            "benchmarks": [
                "SST2",
                "SST5",
                "BBH Object Counting"
            ],
            "base_models": [
                "GPT2-Small",
                "Bloom-560M",
                "OPT-1.3B",
                "LLaMA-2",
                "LLaMA-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PAL Program-aided Language Models": {
        "filename": "PAL Program-aided Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM 8K",
                "SVAMP",
                "ASDIV",
                "MAWPS",
                "BIG-Bench Hard",
                "GSM-HARD"
            ],
            "base_models": [
                "CODEX (code-davinci-002)",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Raising the Bar Investigating the Values of Large Language Models via Generative Evolving Testing": {
        "filename": "Raising the Bar Investigating the Values of Large Language Models via Generative Evolving Testing.pdf",
        "analysis": {
            "benchmarks": [
                "REALTOXICITY PROMPTS",
                "HARMFUL QA",
                "ETHICS",
                "BBQ",
                "REDDIT BIAS"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "Gemini-1.0-Pro",
                "Mistral-Medium",
                "Mistral-7B-Instruct",
                "LLaMA-2-70B",
                "LLaMA-2-7B-Chat",
                "Orca-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Response Uncertainty in MLLMs An Empirical Evaluation under Misleading Scenarios": {
        "filename": "Exploring Response Uncertainty in MLLMs An Empirical Evaluation under Misleading Scenarios.pdf",
        "analysis": {
            "benchmarks": [
                "MME",
                "MMB",
                "MMMU",
                "MathVista",
                "ScienceQA",
                "ConBench",
                "SEED",
                "MMStar",
                "AI2D",
                "Multimodal Uncertainty Benchmark (MUB)"
            ],
            "base_models": [
                "GPT-4o",
                "GLM-4v",
                "Gemini",
                "Qwen-VL",
                "Claude3",
                "Llava",
                "Deepseek",
                "Phi-3-vision",
                "MiniCPM-v-v2",
                "Yi-VL-6b",
                "Qwen-VL-Chat",
                "Deepseek-VL-7b-Chat",
                "LLaVA-NeXT-7b-vicuna",
                "MiniCPM-Llama3-v2.5",
                "GLM4V-9B-chat",
                "CogVLM-chat",
                "InternVL-Chat-V1-5",
                "LLaVA-Next-34b",
                "Yi-VL-34b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Toward Interactive Dictation": {
        "filename": "Toward Interactive Dictation.pdf",
        "analysis": {
            "benchmarks": [
                "TERTiUS"
            ],
            "base_models": [
                "T5-base",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Harnessing the power of LLMs for normative reasoning in MASs": {
        "filename": "Harnessing the power of LLMs for normative reasoning in MASs.pdf",
        "analysis": {
            "benchmarks": [
                "Social-Chem-101",
                "Moral Stories",
                "Scruples",
                "Moral Integrity Corpus",
                "NormBank",
                "NormDial"
            ],
            "base_models": [
                "ChatGPT",
                "Delphi"
            ]
        }
    },
    "Skill Learning Using Process Mining for Large Language Model Plan Generation": {
        "filename": "Skill Learning Using Process Mining for Large Language Model Plan Generation.pdf",
        "analysis": {
            "benchmarks": [
                "TaskBench",
                "ProcessTBench"
            ],
            "base_models": [
                "GPT-4-0613"
            ]
        }
    },
    "CoA Chain-of-Action for Generative Semantic Labels": {
        "filename": "CoA Chain-of-Action for Generative Semantic Labels.pdf",
        "analysis": {
            "benchmarks": [
                "VOC",
                "COCO",
                "NUS"
            ],
            "base_models": [
                "LLaVA-1.5-7B",
                "LLaVA-1.5-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can AI Understand Human Personality - Comparing Human Experts and AI Systems at Predicting Personality Correlations": {
        "filename": "Can AI Understand Human Personality - Comparing Human Experts and AI Systems at Predicting Personality Correlations.pdf",
        "analysis": {
            "benchmarks": [
                "SAPA Personality Inventory"
            ],
            "base_models": [
                "GPT-4o",
                "Claude 3 Opus",
                "PersonalityMap (custom model)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AviationGPT A Large Language Model for the Aviation Domain": {
        "filename": "AviationGPT A Large Language Model for the Aviation Domain.pdf",
        "analysis": {
            "benchmarks": [
                "DATIS",
                "National Traffic Management Log (NTML)"
            ],
            "base_models": [
                "LLaMA-2 (7B, 13B, 70B)",
                "Mistral (7B)"
            ]
        }
    },
    "GPT-4 Is Too Smart To Be Safe Stealthy Chat with LLMs via Cipher": {
        "filename": "GPT-4 Is Too Smart To Be Safe Stealthy Chat with LLMs via Cipher.pdf",
        "analysis": {
            "benchmarks": [
                "Chinese safety assessment benchmark (Sun et al., 2023)"
            ],
            "base_models": [
                "GPT-3.5-Turbo-0613",
                "GPT-4-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model LLM for Telecommunications A Comprehensive Survey on Principles Key Techniques and Opportunities": {
        "filename": "Large Language Model LLM for Telecommunications A Comprehensive Survey on Principles Key Techniques and Opportunities.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BloombergGPT (50B)",
                "Med-PaLM2",
                "GPT-4",
                "LLaMA-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How to Protect Copyright Data in Optimization of Large Language Models": {
        "filename": "How to Protect Copyright Data in Optimization of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "Llama",
                "BERT",
                "BARD",
                "PaLM",
                "OPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant A Review": {
        "filename": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant A Review.pdf",
        "analysis": {
            "benchmarks": [
                "USMLE",
                "MultiMedQA",
                "MultiMedBench",
                "VQA-RAD",
                "SLAKE"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "Claude",
                "PaLM",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Plum Prompt Learning using Metaheuristic": {
        "filename": "Plum Prompt Learning using Metaheuristic.pdf",
        "analysis": {
            "benchmarks": [
                "Natural-Instructions datasets v2.6"
            ],
            "base_models": [
                "GPT2-large",
                "GPT3-babbage"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Empirical Study of Retrieval Augmented Generation with Chain-of-Thought": {
        "filename": "An Empirical Study of Retrieval Augmented Generation with Chain-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "PubMedQA",
                "DuReader robust"
            ],
            "base_models": [
                "LLaMA2-7B-chat",
                "Qwen-1.5-7B-chat"
            ]
        }
    },
    "A Neural Rewriting System to Solve Algorithmic Problems": {
        "filename": "A Neural Rewriting System to Solve Algorithmic Problems.pdf",
        "analysis": {
            "benchmarks": [
                "ListOps",
                "Arithmetic",
                "Algebra"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Building blocks for complex tasks Robust generative event extraction for radiology reports under domain shifts": {
        "filename": "Building blocks for complex tasks Robust generative event extraction for radiology reports under domain shifts.pdf",
        "analysis": {
            "benchmarks": [
                "Annotated corpus of radiology reports from MRI, PET, and CT modalities"
            ],
            "base_models": [
                "T5-base",
                "T5-large",
                "ClinicalT5"
            ]
        }
    },
    "Llama Guard LLM-based Input-Output Safeguard for Human-AI Conversations": {
        "filename": "Llama Guard LLM-based Input-Output Safeguard for Human-AI Conversations.pdf",
        "analysis": {
            "benchmarks": [
                "OpenAI Moderation Evaluation dataset",
                "ToxicChat"
            ],
            "base_models": [
                "Llama2-7b"
            ]
        }
    },
    "LLM-Enhanced Data Management": {
        "filename": "LLM-Enhanced Data Management.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Semantic Parsing for Complex Data Retrieval Targeting Query Plans vs SQL for No-Code Access to Relational Databases": {
        "filename": "Semantic Parsing for Complex Data Retrieval Targeting Query Plans vs SQL for No-Code Access to Relational Databases.pdf",
        "analysis": {
            "benchmarks": [
                "Spider"
            ],
            "base_models": [
                "T5-Large (770M)",
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "dZiner Rational Inverse Design of Materials with AI Agents": {
        "filename": "dZiner Rational Inverse Design of Materials with AI Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Surfactant Design and Critical Micelle Concentration Inference",
                "Drug Design and Targeted Docking Inference",
                "MOF Organic Linker Design and CO2 Adsorption Capacity Inference"
            ],
            "base_models": [
                "Claude 3.5 Sonnet",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Brainstorming Brings Power to Large Language Models of Knowledge Reasoning": {
        "filename": "Brainstorming Brings Power to Large Language Models of Knowledge Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM",
                "ARC-easy",
                "ARC-challenge"
            ],
            "base_models": [
                "ChatGPT",
                "Gemini Pro",
                "Qianwen1.5-7B",
                "Baichuan2-7B",
                "Mistral-7B",
                "GPT-3.5"
            ]
        }
    },
    "Designing for Human-Agent Alignment Understanding what humans want from their agents": {
        "filename": "Designing for Human-Agent Alignment Understanding what humans want from their agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "Why Does ChatGPT Fall Short in Providing Truthful Answers": {
        "filename": "Why Does ChatGPT Fall Short in Providing Truthful Answers.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "BoolQ"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Mixture of insighTful Experts MoTE The Synergy of Thought Chains and Expert Mixtures in Self-Alignment": {
        "filename": "Mixture of insighTful Experts MoTE The Synergy of Thought Chains and Expert Mixtures in Self-Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "PKU-SafeRLHF",
                "HH-RLHF"
            ],
            "base_models": [
                "Alpaca-7B",
                "Wizard-Vicuna-Uncensored 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HRoT Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering": {
        "filename": "HRoT Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "MultiHiertt"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)",
                "DeBERTa"
            ]
        }
    },
    "Question-focused Summarization by Decomposing Articles into Facts and Opinions and Retrieving Entities": {
        "filename": "Question-focused Summarization by Decomposing Articles into Facts and Opinions and Retrieving Entities.pdf",
        "analysis": {
            "benchmarks": [
                "Economist dataset (2017-2019)",
                "Wikipedia data for contextual embeddings"
            ],
            "base_models": [
                "GPT-3.5 turbo"
            ]
        }
    },
    "Moral Alignment for LLM Agents": {
        "filename": "Moral Alignment for LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Iterated Prisoner's Dilemma (IPD)"
            ],
            "base_models": [
                "Gemma2-2b-it"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Autonomous Agents through the Lens of Large Language Models A Review": {
        "filename": "Exploring Autonomous Agents through the Lens of Large Language Models A Review.pdf",
        "analysis": {
            "benchmarks": [
                "AgentBench",
                "WebArena",
                "ToolBench"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "T5",
                "BART",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SemioLLM Assessing Large Language Models for Semiological Analysis in Epilepsy Research": {
        "filename": "SemioLLM Assessing Large Language Models for Semiological Analysis in Epilepsy Research.pdf",
        "analysis": {
            "benchmarks": [
                "Semio2Brain"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Mixtral 8x7B",
                "Qwen-72B"
            ]
        }
    },
    "Prompt-In-Prompt Learning for Universal Image Restoration": {
        "filename": "Prompt-In-Prompt Learning for Universal Image Restoration.pdf",
        "analysis": {
            "benchmarks": [
                "BSD68",
                "SOTS",
                "Rain100L",
                "GoPro",
                "LOL",
                "Rain100H"
            ],
            "base_models": [
                "Restormer",
                "NAFNet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Multimodal In-Context Learning for Vision  Language Models": {
        "filename": "Towards Multimodal In-Context Learning for Vision  Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SEED-Bench-2",
                "VL-Checklist",
                "Stanford Dogs",
                "CUB",
                "Flowers",
                "Food-101",
                "Stanford Cars"
            ],
            "base_models": [
                "LLaVA-1.5 13B",
                "LLaVA-next (1.6) 13B",
                "Vicuna-1.5-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Gradient Boosting Trees and Large Language Models for Tabular Data Few-Shot Learning": {
        "filename": "Gradient Boosting Trees and Large Language Models for Tabular Data Few-Shot Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Kaggle Titanic",
                "OpenML Diabetes",
                "Adult Income",
                "FICO",
                "Spaceship Titanic",
                "Pneumonia",
                "Bank",
                "Blood",
                "Credit-g",
                "Heart",
                "Income"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ]
        }
    },
    "Large Language Models can be Guided to Evade AI-Generated Text Detection": {
        "filename": "Large Language Models can be Guided to Evade AI-Generated Text Detection.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "Eli5",
                "Yelp"
            ],
            "base_models": [
                "GPT-3.5",
                "Vicuna-13B (based on LLaMa)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CompCodeVet A Compiler-guided Validation and Enhancement Approach for Code Dataset": {
        "filename": "CompCodeVet A Compiler-guided Validation and Enhancement Approach for Code Dataset.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP"
            ],
            "base_models": [
                "GPT (parameter size not specified)",
                "PaLM (parameter size not specified)",
                "Codex (12B)",
                "StarCoder (15B)",
                "Code Llama (7B, 13B, 34B)",
                "WizardCoder (parameter size not specified)",
                "Llama2-7b",
                "CodeLlama2-instruct-7b"
            ]
        }
    },
    "Empowering Large Language Model Agents through Action Learning": {
        "filename": "Empowering Large Language Model Agents through Action Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Robotic Planning",
                "AlfWorld"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rephrase and Respond Let Large Language Models Ask Better Questions for Themselves": {
        "filename": "Rephrase and Respond Let Large Language Models Ask Better Questions for Themselves.pdf",
        "analysis": {
            "benchmarks": [
                "MultiNLI",
                "CSQA",
                "Date Understanding",
                "Last Letter Concatenation",
                "Coin Flip",
                "Sports"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo-0613",
                "Vicuna-13b-v1.5 (based on LLaMA-2)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Annotation-Efficient Preference Optimization for Language Model Alignment": {
        "filename": "Annotation-Efficient Preference Optimization for Language Model Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaFarm",
                "Anthropic's Helpfulness",
                "Anthropic's Harmlessness"
            ],
            "base_models": [
                "Mistral-7B",
                "Dolly-v2-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Human-Language Model Interaction": {
        "filename": "Evaluating Human-Language Model Interaction.pdf",
        "analysis": {
            "benchmarks": [
                "EmpatheticDialogues",
                "CommonsenseDialogues",
                "MMLU"
            ],
            "base_models": [
                "GPT-3 TextDavinci",
                "GPT-3 TextBabbage",
                "GPT-3 Davinci",
                "Jurassic-1 Jumbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RLingua Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models": {
        "filename": "RLingua Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "panda_gym",
                "RLBench"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VISCO Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning": {
        "filename": "VISCO Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "VISCO"
            ],
            "base_models": [
                "LLaVA (7B, 13B, 34B, 72B)",
                "Molmo (7B, 72B)",
                "GPT-4o",
                "Claude-3.5",
                "InternVL2 (8B, 26B, 40B, 76B)",
                "Llama-3.2 (11B, 90B)",
                "DeepSeek-VL (7B)",
                "Qwen2-VL (7B, 72B)",
                "NVLM (72B)",
                "Prometheus-Vision (7B, 13B)",
                "LLaVA-Critic (7B, 72B)",
                "Gemini-1.5-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cooperative Resilience in Artificial Intelligence Multiagent Systems": {
        "filename": "Cooperative Resilience in Artificial Intelligence Multiagent Systems.pdf",
        "analysis": {
            "benchmarks": [
                "Melting Pot 2.0"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Exploring and Characterizing Large Language Models for Embedded System Development and Debugging": {
        "filename": "Exploring and Characterizing Large Language Models for Embedded System Development and Debugging.pdf",
        "analysis": {
            "benchmarks": [
                "Custom hardware-in-the-loop framework with sensor-actuator pairs"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How and Why LLMs Use Deprecated APIs in Code Completion An Empirical Study": {
        "filename": "How and Why LLMs Use Deprecated APIs in Code Completion An Empirical Study.pdf",
        "analysis": {
            "benchmarks": [
                "Numpy",
                "Pandas",
                "scikit-learn",
                "SciPy",
                "seaborn",
                "TensorFlow",
                "PyTorch",
                "Transformers"
            ],
            "base_models": [
                "CodeLlama-7b",
                "GPT-3.5",
                "CodeGen-350m",
                "CodeGen-2b",
                "CodeGen-6b",
                "DeepSeek-1.3b",
                "StarCoder2-3b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Workbench for Autograding RetrieveGenerate Systems": {
        "filename": "A Workbench for Autograding RetrieveGenerate Systems.pdf",
        "analysis": {
            "benchmarks": [
                "TREC DL 2020"
            ],
            "base_models": [
                "ChatGPT",
                "Llama2",
                "Mistral",
                "FLAN-T5"
            ]
        }
    },
    "Exploring Effective Factors for Improving Visual In-Context Learning": {
        "filename": "Exploring Effective Factors for Improving Visual In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "pascal-5i",
                "PASCAL VOC 2012"
            ],
            "base_models": [
                "MAE-VQGAN",
                "CLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AgentClinic a multimodal agent benchmark to evaluate AI in simulated clinical environments": {
        "filename": "AgentClinic a multimodal agent benchmark to evaluate AI in simulated clinical environments.pdf",
        "analysis": {
            "benchmarks": [
                "AgentClinic-MedQA",
                "AgentClinic-MIMIC-IV",
                "AgentClinic-NEJM"
            ],
            "base_models": [
                "Claude-3.5",
                "GPT-4",
                "GPT-4o",
                "Mixtral-8x7B",
                "GPT-3.5",
                "Llama 3 70B-Instruct",
                "Llama 2 70B-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Extractive Summarization via ChatGPT for Faithful Summary Generation": {
        "filename": "Extractive Summarization via ChatGPT for Faithful Summary Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/DM",
                "XSum",
                "PubMed",
                "Reddit"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)"
            ]
        }
    },
    "LTLBench Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models": {
        "filename": "LTLBench Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "LTLBench"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "Llama 3 (70B)",
                "Qwen (72B)",
                "Gemma (7B)",
                "Mistral (7B)",
                "Qwen (7B)"
            ]
        }
    },
    "A Survey on ChatGPT AIGenerated Contents Challenges and Solutions": {
        "filename": "A Survey on ChatGPT AIGenerated Contents Challenges and Solutions.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (variant of GPT)",
                "GPT-4 (large multimodal model)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual Sketchpad Sketching as a Visual Chain of Thought for Multimodal Language Models": {
        "filename": "Visual Sketchpad Sketching as a Visual Chain of Thought for Multimodal Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "V*Bench",
                "BLINK",
                "Geometry3K",
                "IsoBench"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4 Turbo",
                "LLaMA-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VLM Agents Generate Their Own Memories Distilling Experience into Embodied Programs of Thought": {
        "filename": "VLM Agents Generate Their Own Memories Distilling Experience into Embodied Programs of Thought.pdf",
        "analysis": {
            "benchmarks": [
                "TEACh",
                "VisualWebArena",
                "Ego4D"
            ],
            "base_models": [
                "GPT-4V",
                "GPT-4-1106-preview",
                "GPT3.5-turbo-1106"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Answering Complex Questions over Text by Hybrid Question Parsing and Execution": {
        "filename": "Answering Complex Questions over Text by Hybrid Question Parsing and Execution.pdf",
        "analysis": {
            "benchmarks": [
                "MuSiQue",
                "2WikiMultiHopQA",
                "HotpotQA",
                "NQ"
            ],
            "base_models": [
                "T5-large",
                "FiD (based on T5-large)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DeepSeekMath Pushing the Limits of Mathematical Reasoning in Open Language Models": {
        "filename": "DeepSeekMath Pushing the Limits of Mathematical Reasoning in Open Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MATH (Hendrycks et al., 2021)",
                "GSM8K (Cobbe et al., 2021)",
                "CMATH (Wei et al., 2023)",
                "MGSM-zh (Shi et al., 2023)",
                "Gaokao-MathCloze (Zhong et al., 2023)",
                "Gaokao-MathQA (Zhong et al., 2023)",
                "MMLU-STEM (Hendrycks et al., 2020)",
                "miniF2F (Zheng et al., 2021)"
            ],
            "base_models": [
                "DeepSeekMath-Base 7B",
                "DeepSeek-Coder-Base-v1.5 7B",
                "Minerva 540B",
                "Mistral 7B",
                "Llemma 34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Response Tuning Aligning Large Language Models without Instruction": {
        "filename": "Response Tuning Aligning Large Language Models without Instruction.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaEval",
                "JustEval",
                "MMLU",
                "OpenbookQA",
                "HellaSwag",
                "ARC",
                "GSM8K",
                "PIQA",
                "AdvBench",
                "MaliciousInstruct",
                "HarmBench",
                "XSTest"
            ],
            "base_models": [
                "Llama-3.1-8B",
                "Gemma-2-2B",
                "Gemma-2-9B",
                "Mistral-7B-v0.3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Faithful Model Explanation in NLP A Survey": {
        "filename": "Towards Faithful Model Explanation in NLP A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning Semantic Role Labeling from Compatible Label Sequences": {
        "filename": "Learning Semantic Role Labeling from Compatible Label Sequences.pdf",
        "analysis": {
            "benchmarks": [
                "CoNLL05"
            ],
            "base_models": [
                "BERT",
                "RoBERTa"
            ]
        }
    },
    "SCHEMA State CHangEs MAtter for Procedure Planning in Instructional Videos": {
        "filename": "SCHEMA State CHangEs MAtter for Procedure Planning in Instructional Videos.pdf",
        "analysis": {
            "benchmarks": [
                "CrossTask",
                "COIN",
                "NIV"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FastSwitch Optimizing Context Switching Efficiency in Fairness-aware Large Language Model Serving": {
        "filename": "FastSwitch Optimizing Context Switching Efficiency in Fairness-aware Large Language Model Serving.pdf",
        "analysis": {
            "benchmarks": [
                "ShareGPT"
            ],
            "base_models": [
                "LLaMA-8B",
                "Qwen-32B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RadAdapt Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models": {
        "filename": "RadAdapt Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-III",
                "MIMIC-CXR",
                "Stanford Hospital ultrasound dataset"
            ],
            "base_models": [
                "T5-base (223M)",
                "T5-large (738M)",
                "FLAN-T5",
                "SCIFIVE",
                "CLIN-T5-SCI",
                "CLIN-T5"
            ]
        }
    },
    "Glider Global and Local Instruction-Driven Expert Router": {
        "filename": "Glider Global and Local Instruction-Driven Expert Router.pdf",
        "analysis": {
            "benchmarks": [
                "T0 held-in",
                "T0 held-out",
                "BIG-bench lite",
                "BIG-bench hard"
            ],
            "base_models": [
                "T5-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DiPT Enhancing LLM reasoning through diversified perspective-taking": {
        "filename": "DiPT Enhancing LLM reasoning through diversified perspective-taking.pdf",
        "analysis": {
            "benchmarks": [
                "CosmosQA",
                "TruthfulQA",
                "RTE",
                "TREC",
                "SST-5",
                "AG News",
                "SVAMP"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "Mistral7B-Instruct-v0.1",
                "Llama3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cobblestone Iterative Automation for Formal Verification": {
        "filename": "Cobblestone Iterative Automation for Formal Verification.pdf",
        "analysis": {
            "benchmarks": [
                "CoqGym",
                "coq-wigderson"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large language models can accurately predict searcher preferences": {
        "filename": "Large language models can accurately predict searcher preferences.pdf",
        "analysis": {
            "benchmarks": [
                "TREC-Robust 2004"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Categorical Framework for Quantifying Emergent Effects in Network Topology": {
        "filename": "A Categorical Framework for Quantifying Emergent Effects in Network Topology.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Chain of AI-based Solutions for Resolving FQNs and Fixing Syntax Errors in Partial Code": {
        "filename": "A Chain of AI-based Solutions for Resolving FQNs and Fixing Syntax Errors in Partial Code.pdf",
        "analysis": {
            "benchmarks": [
                "Python dataset",
                "Java dataset"
            ],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language Deduction through Search over Statement Compositions": {
        "filename": "Natural Language Deduction through Search over Statement Compositions.pdf",
        "analysis": {
            "benchmarks": [
                "EntailmentBank"
            ],
            "base_models": [
                "T5-3b",
                "DeBERTa Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Very Large-Scale Multi-Agent Simulation in AgentScope": {
        "filename": "Very Large-Scale Multi-Agent Simulation in AgentScope.pdf",
        "analysis": {
            "benchmarks": [
                "guess 2/3 of the average game"
            ],
            "base_models": [
                "GPT-4",
                "Claude3.5",
                "Qwen2",
                "Llama3",
                "GLM",
                "MistralAI"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions": {
        "filename": "Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions.pdf",
        "analysis": {
            "benchmarks": [
                "Defects4J-Nl2fix"
            ],
            "base_models": [
                "code-davinci-002",
                "code-davinci-edit-001",
                "gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dialectical Alignment Resolving the Tension of 3H and Security Threats of LLMs": {
        "filename": "Dialectical Alignment Resolving the Tension of 3H and Security Threats of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "MS-MARCO",
                "Natural Questions"
            ],
            "base_models": [
                "TinyDolphin-2.8-1.1B",
                "Mistral-7B-Instruct-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Social Outcomes and Priorities centered SOP Framework for AI policy": {
        "filename": "A Social Outcomes and Priorities centered SOP Framework for AI policy.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Need Holistically Thought in Medical Conversational QA": {
        "filename": "Large Language Models Need Holistically Thought in Medical Conversational QA.pdf",
        "analysis": {
            "benchmarks": [
                "MedDialog",
                "COVID",
                "CMDD"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "Instruct-GPT (175B)",
                "GLM (130B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DialogGen Multi-modal Interactive Dialogue System for Multi-turn Text-to-Image Generation": {
        "filename": "DialogGen Multi-modal Interactive Dialogue System for Multi-turn Text-to-Image Generation.pdf",
        "analysis": {
            "benchmarks": [
                "DialogBen"
            ],
            "base_models": [
                "GPT-4",
                "Qwen-VL",
                "Stable Diffusion v1.5",
                "Stable Diffusion v2.1",
                "Hunyuan T2I"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Log Parsing How Far Can ChatGPT Go": {
        "filename": "Log Parsing How Far Can ChatGPT Go.pdf",
        "analysis": {
            "benchmarks": [
                "LogPai benchmark"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)"
            ]
        }
    },
    "Implicit Chain of Thought Reasoning via Knowledge Distillation": {
        "filename": "Implicit Chain of Thought Reasoning via Knowledge Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-bench multi-digit multiplication",
                "GSM8K"
            ],
            "base_models": [
                "GPT-2 Small",
                "GPT-2 Medium",
                "GPT-2 Large",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoAD-Zero A Training-Free Framework for Zero-Shot Audio Description": {
        "filename": "AutoAD-Zero A Training-Free Framework for Zero-Shot Audio Description.pdf",
        "analysis": {
            "benchmarks": [
                "MAD-Eval",
                "CMD-AD",
                "TV-AD"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4v",
                "VideoLLaMA2-7B",
                "LLaMA3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Skill Set Optimization Reinforcing Language Model Behavior via Transferable Skills": {
        "filename": "Skill Set Optimization Reinforcing Language Model Behavior via Transferable Skills.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceWorld",
                "custom NetHack task"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Speech-Copilot Leveraging Large Language Models for Speech Processing via Task Decomposition Modularization and Program Generation": {
        "filename": "Speech-Copilot Leveraging Large Language Models for Speech Processing via Task Decomposition Modularization and Program Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Dynamic-SUPERB"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Whisper-large-v3",
                "Qwen-Audio-Chat"
            ]
        }
    },
    "Recursive Introspection Teaching Language Model Agents How to Self-Improve": {
        "filename": "Recursive Introspection Teaching Language Model Agents How to Self-Improve.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "SVAMP"
            ],
            "base_models": [
                "Llama2-7B",
                "Llama3-8B",
                "Mistral-7B",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cost-effective Instruction Learning for Pathology Vision and Language Analysis": {
        "filename": "Cost-effective Instruction Learning for Pathology Vision and Language Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "PathVQA",
                "QUILT-VQA"
            ],
            "base_models": [
                "GPT-3.5",
                "BLIP-2",
                "FlanT5XL",
                "Vicuna 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning": {
        "filename": "Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Tracking Shuffled Objects",
                "Dyck Language",
                "Word Sorting",
                "Chinese Remainder Theorem",
                "Scheduling Meeting",
                "GSM-Hard",
                "Game of 24",
                "StrategyQA",
                "TruthfulQA",
                "VicunaQA",
                "SST2",
                "Cola",
                "Emotion-Classification",
                "Amazon Review",
                "Hate-Speech",
                "Social Bias Frame"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "CodeLlama-7b",
                "CodeLlama-13b",
                "Claude-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DePlot One-shot visual language reasoning by plot-to-table translation": {
        "filename": "DePlot One-shot visual language reasoning by plot-to-table translation.pdf",
        "analysis": {
            "benchmarks": [
                "ChartQA",
                "PlotQA"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM (540B)",
                "FlanPaLM (540B)",
                "Codex (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large language models leverage external knowledge to extend clinical insight beyond language boundaries": {
        "filename": "Large language models leverage external knowledge to extend clinical insight beyond language boundaries.pdf",
        "analysis": {
            "benchmarks": [
                "CNMLE-2022"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "GPT-4",
                "Baichuan2-7B",
                "Baichuan2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Guiding Large Language Models via Directional Stimulus Prompting": {
        "filename": "Guiding Large Language Models via Directional Stimulus Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/Daily Mail",
                "MultiWOZ"
            ],
            "base_models": [
                "ChatGPT",
                "Codex",
                "InstructGPT",
                "GPT-4",
                "PaLM",
                "Flan-T5-Large (750M)",
                "T5-Base (220M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Optimizing with Large Language Models": {
        "filename": "Towards Optimizing with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic datasets with dimensions {3, 6, 12, 24, 48}"
            ],
            "base_models": [
                "GPT-turbo-3.5",
                "GPT-4"
            ]
        }
    },
    "A Theory for Length Generalization in Learning to Reason": {
        "filename": "A Theory for Length Generalization in Learning to Reason.pdf",
        "analysis": {
            "benchmarks": [
                "arithmetic in F7",
                "parity-[2-line]",
                "addition-[1-line]",
                "addition-[2-line]",
                "addition-[3-line]",
                "multiplication-[1-line]",
                "multiplication-[8-line]"
            ],
            "base_models": [
                "vanilla Transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Energy-Efficient Code Emerging Results and Future Directions": {
        "filename": "Large Language Models for Energy-Efficient Code Emerging Results and Future Directions.pdf",
        "analysis": {
            "benchmarks": [
                "Energy-Language"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "Lets Verify Step by Step": {
        "filename": "Lets Verify Step by Step.pdf",
        "analysis": {
            "benchmarks": [
                "MATH dataset",
                "PRM800K"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "ChatLLM Network More brains More intelligence": {
        "filename": "ChatLLM Network More brains More intelligence.pdf",
        "analysis": {
            "benchmarks": [
                "digital mode classification",
                "sentiment reversal"
            ],
            "base_models": [
                "ChatGPT-3.5"
            ]
        }
    },
    "Making Large Vision Language Models to be Good Few-shot Learners": {
        "filename": "Making Large Vision Language Models to be Good Few-shot Learners.pdf",
        "analysis": {
            "benchmarks": [
                "MiniImageNet",
                "CIFAR-FS",
                "TieredImageNet",
                "CUB",
                "Stanford Dogs",
                "FGVC-Aircraft",
                "Oxford 102 Flower",
                "Stanford Cars"
            ],
            "base_models": [
                "GPT-4V",
                "Qwen-VL (Qwen-7B with ViT-bigG)"
            ]
        }
    },
    "Language Model Cascades": {
        "filename": "Language Model Cascades.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-bench (Twenty Questions task)"
            ],
            "base_models": [
                "GPT-3",
                "PaLM",
                "LaMDA 137B"
            ]
        }
    },
    "T-cell receptor binding prediction A machine learning revolution": {
        "filename": "T-cell receptor binding prediction A machine learning revolution.pdf",
        "analysis": {
            "benchmarks": [
                "VDJdb",
                "McPas-TCR",
                "MIRA dataset"
            ],
            "base_models": [
                "GPT (Generative pre-trained Transformer)",
                "BERT (Bidirectional Encoder Representations from Transformers)",
                "ProtBERT",
                "TCR-BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Library Learning Doesnt The Curious Case of the Single-Use Library": {
        "filename": "Library Learning Doesnt The Curious Case of the Single-Use Library.pdf",
        "analysis": {
            "benchmarks": [
                "miniF2F",
                "MATH"
            ],
            "base_models": [
                "GPT-4o-mini",
                "CodeLlama-7b-Instruct-hf"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-Eval Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models": {
        "filename": "LLM-Eval Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "DSTC10 Hidden Set",
                "TopicalChat-USR",
                "PersonaChat-USR",
                "ConvAI2-GRADE",
                "DailyDialog-GRADE",
                "EmpatheticDialogue-GRADE",
                "DSTC6",
                "DailyDialog-PredictiveEngagement",
                "FED",
                "DSTC9"
            ],
            "base_models": [
                "Anthropic Claude (claude-v1.3)",
                "OpenAI ChatGPT (gpt-3.5-turbo-0301)",
                "Anthropic Claude-instant (claude-instantv1.0)",
                "OpenAI GPT-3.5 (text-davinci-003)"
            ]
        }
    },
    "PyGen A Collaborative Human-AI Approach to Python Package Creation": {
        "filename": "PyGen A Collaborative Human-AI Approach to Python Package Creation.pdf",
        "analysis": {
            "benchmarks": [
                "Human Evaluation",
                "LLM-based evaluation",
                "CodeBLEU"
            ],
            "base_models": [
                "Google DeepMind's Gemini",
                "Meta's Llama"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph": {
        "filename": "Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph.pdf",
        "analysis": {
            "benchmarks": [
                "Open Research Knowledge Graph (ORKG)"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama 2",
                "Mistral"
            ]
        }
    },
    "Towards Proactive Interactions for In-Vehicle Conversational Assistants Utilizing Large Language Models": {
        "filename": "Towards Proactive Interactions for In-Vehicle Conversational Assistants Utilizing Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "In-Car dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models PhenoBCBERT and PhenoGPT": {
        "filename": "Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models PhenoBCBERT and PhenoGPT.pdf",
        "analysis": {
            "benchmarks": [
                "BiolarkGSC+",
                "ID-68"
            ],
            "base_models": [
                "Bio+Clinical BERT",
                "GPT-J (6B)",
                "Falcon (7B)",
                "LLaMA (7B)",
                "GPT-3 (175B)",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-Of-Thought Prompting Under Streaming Batch A Case Study": {
        "filename": "Chain-Of-Thought Prompting Under Streaming Batch A Case Study.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MultiArith",
                "StrategyQA",
                "Letter"
            ],
            "base_models": [
                "text-davinci-002"
            ]
        }
    },
    "Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM": {
        "filename": "Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM.pdf",
        "analysis": {
            "benchmarks": [
                "WebQuestions",
                "LLaMA-Questions"
            ],
            "base_models": [
                "LLaMA-7B",
                "PaLM 2 (350M and 1B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting": {
        "filename": "Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "BBQ dataset"
            ],
            "base_models": [
                "LLaMA-7B",
                "Alpaca-7B",
                "Koala-7B",
                "LLaMA-13B",
                "Alpaca-13B",
                "Koala-13B"
            ]
        }
    },
    "BBox-Adapter Lightweight Adapting for Black-Box Large Language Models": {
        "filename": "BBox-Adapter Lightweight Adapting for Black-Box Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "StrategyQA",
                "TruthfulQA",
                "ScienceQA"
            ],
            "base_models": [
                "GPT-4",
                "Gemini",
                "GPT-3.5",
                "PaLM-2",
                "Mixtral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Pyramid Coder Hierarchical Code Generator for Compositional Visual Question Answering": {
        "filename": "Pyramid Coder Hierarchical Code Generator for Compositional Visual Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "GQA",
                "VQAv2",
                "NLVR2"
            ],
            "base_models": [
                "StarCoder-Base",
                "CodeLlama-7b-Python"
            ]
        }
    },
    "Unveiling the Safety of GPT-4o An Empirical Study using Jailbreak Attacks": {
        "filename": "Unveiling the Safety of GPT-4o An Empirical Study using Jailbreak Attacks.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench",
                "RedTeam-2K",
                "SafeBench",
                "MM-SafetyBench"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4V",
                "Llama2 (llama-2-7b-chat)"
            ]
        }
    },
    "Towards Unified Alignment Between Agents Humans and Environment": {
        "filename": "Towards Unified Alignment Between Agents Humans and Environment.pdf",
        "analysis": {
            "benchmarks": [
                "WebShop (retrofitted version)"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Polish Enhance Reasoning in Large Language Models via Problem Refinement": {
        "filename": "Self-Polish Enhance Reasoning in Large Language Models via Problem Refinement.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQuA",
                "SVAMP",
                "MultiArith",
                "MathQA"
            ],
            "base_models": [
                "Text-davinci-002",
                "Text-davinci-003",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Interaction Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts": {
        "filename": "Chain-of-Interaction Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts.pdf",
        "analysis": {
            "benchmarks": [
                "MISC-coded data"
            ],
            "base_models": [
                "Llama2-13B-Chat",
                "Falcon-7B-Instruct",
                "Mistral-7B-Instruct",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Well Can Transformers Emulate In-context Newtons Method": {
        "filename": "How Well Can Transformers Emulate In-context Newtons Method.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset for linear regression",
                "Custom dataset for logistic regression"
            ],
            "base_models": [
                "Transformer with linear attention"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ROMAS A Role-Based Multi-Agent System for Database monitoring and Planning": {
        "filename": "ROMAS A Role-Based Multi-Agent System for Database monitoring and Planning.pdf",
        "analysis": {
            "benchmarks": [
                "FAMMA",
                "HotpotQA"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DeepTagger Knowledge Enhanced Named Entity Recognition for Web-Based Ads Queries": {
        "filename": "DeepTagger Knowledge Enhanced Named Entity Recognition for Web-Based Ads Queries.pdf",
        "analysis": {
            "benchmarks": [
                "CoNLL2003",
                "self-collected dataset"
            ],
            "base_models": [
                "BERT-base",
                "multilingual BERT-base",
                "ChatGPT",
                "GPT-4"
            ]
        }
    },
    "RecMind Large Language Model Powered Agent For Recommendation": {
        "filename": "RecMind Large Language Model Powered Agent For Recommendation.pdf",
        "analysis": {
            "benchmarks": [
                "Amazon Reviews (Beauty, Sports & Outdoors, Toys & Games)",
                "Yelp"
            ],
            "base_models": [
                "GPT-3.5-turbo-16k",
                "Llama2 70b",
                "GPT-4",
                "text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Integration of large language models and federated learning": {
        "filename": "Integration of large language models and federated learning.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Empirical Study on the Robustness of the Segment Anything Model SAM": {
        "filename": "An Empirical Study on the Robustness of the Segment Anything Model SAM.pdf",
        "analysis": {
            "benchmarks": [
                "Forest Aerial",
                "Water Bodies",
                "Road Extraction",
                "Breast Ultrasound",
                "Chest X-Ray",
                "Fish",
                "Fire",
                "Crack",
                "TikTok Dancing"
            ],
            "base_models": [
                "Vision Transformer (ViT-H)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LogParser-LLM Advancing Efficient Log Parsing with Large Language Models": {
        "filename": "LogParser-LLM Advancing Efficient Log Parsing with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Loghub-2k",
                "LogPub"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "Llama-2-13b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Extracting user needs with Chat-GPT for dialogue recommendation": {
        "filename": "Extracting user needs with Chat-GPT for dialogue recommendation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "A call for embodied AI": {
        "filename": "A call for embodied AI.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Google's Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "rLLM Relational Table Learning with LLMs": {
        "filename": "rLLM Relational Table Learning with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "TML1M",
                "TLF2K",
                "TACM12K"
            ],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "Making Large Language Models Better Reasoners with Alignment": {
        "filename": "Making Large Language Models Better Reasoners with Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQUA-RAT",
                "ECQA",
                "GSM8K-RANK"
            ],
            "base_models": [
                "LLama-7B",
                "LLama-13B",
                "LLama2-7B",
                "LLama2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-critiquing models for assisting human evaluators": {
        "filename": "Self-critiquing models for assisting human evaluators.pdf",
        "analysis": {
            "benchmarks": [
                "topic-based summarization dataset",
                "synthetic tasks dataset"
            ],
            "base_models": [
                "GPT-3 (size not specified)",
                "InstructGPT (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Neuro-Symbolic Execution of Generic Source Code": {
        "filename": "Neuro-Symbolic Execution of Generic Source Code.pdf",
        "analysis": {
            "benchmarks": [
                "Py150",
                "CuBERT"
            ],
            "base_models": [
                "CodeBERT",
                "CodeGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NapSS Paragraph-level Medical Text Simplification via Narrative Prompting and Sentence-matching Summarization": {
        "filename": "NapSS Paragraph-level Medical Text Simplification via Narrative Prompting and Sentence-matching Summarization.pdf",
        "analysis": {
            "benchmarks": [
                "Cochrane dataset"
            ],
            "base_models": [
                "BART",
                "BioBART"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InsightSee Advancing Multi-agent Vision-Language Models for Enhanced Visual Understanding": {
        "filename": "InsightSee Advancing Multi-agent Vision-Language Models for Enhanced Visual Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "SEED-Bench"
            ],
            "base_models": [
                "GPT-4V"
            ]
        }
    },
    "X-InstructBLIP A Framework for aligning X-Modal instruction-aware representations to LLMs and Emergent Cross-modal Reasoning": {
        "filename": "X-InstructBLIP A Framework for aligning X-Modal instruction-aware representations to LLMs and Emergent Cross-modal Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "DisCRn",
                "ModelNet40",
                "ESC50",
                "ClothoAQA",
                "Clotho",
                "MusicAVQA",
                "VATEX",
                "NoCaps",
                "VizWiz",
                "GQA",
                "MME",
                "MMVET"
            ],
            "base_models": [
                "Vicuna-7b",
                "Vicuna-13b",
                "BLIP-2",
                "EVA-CLIP-ViT-G/14",
                "BEATs iter3+",
                "ULIP-2 [PointBERT backbone]"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatCAD Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models": {
        "filename": "ChatCAD Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-CXR",
                "CheXpert"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-3 (text-davinci-003)"
            ]
        }
    },
    "No Train Still Gain Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function": {
        "filename": "No Train Still Gain Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "AQUA-RAT"
            ],
            "base_models": [
                "Llama 2-7B",
                "RFT-7B",
                "RFT-13B",
                "WizardMath-7B",
                "WizardMath-13B",
                "Qwen-7B",
                "AFT-7B",
                "AFT-13B"
            ]
        }
    },
    "CABINET Content Relevance based Noise Reduction for Table Question Answering": {
        "filename": "CABINET Content Relevance based Noise Reduction for Table Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTQ",
                "FeTaQA",
                "WikiSQL"
            ],
            "base_models": [
                "GPT-3",
                "BERT",
                "T5",
                "OmniTab (BART-Large)",
                "Flan T5-xl"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Autonomous Evaluation and Refinement of Digital Agents": {
        "filename": "Autonomous Evaluation and Refinement of Digital Agents.pdf",
        "analysis": {
            "benchmarks": [
                "WebArena",
                "Android-in-the-Wild (AitW)"
            ],
            "base_models": [
                "GPT-4V",
                "QWen-VL-chat",
                "Mixtral",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AskIt Unified Programming Interface for Programming with Large Language Models": {
        "filename": "AskIt Unified Programming Interface for Programming with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Patterns of Creativity How User Input Shapes AI-Generated Visual Diversity": {
        "filename": "Patterns of Creativity How User Input Shapes AI-Generated Visual Diversity.pdf",
        "analysis": {
            "benchmarks": [
                "DiffusionDB",
                "Civiverse"
            ],
            "base_models": [
                "Stable Diffusion"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LangNav Language as a Perceptual Representation for Navigation": {
        "filename": "LangNav Language as a Perceptual Representation for Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "R2R",
                "ALFRED"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-7B",
                "LLaMA2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Knowledge Guided Retrieval Augmentation for Large Language Models": {
        "filename": "Self-Knowledge Guided Retrieval Augmentation for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TemporalQA",
                "CommonsenseQA",
                "TabularQA",
                "StrategyQA",
                "TruthfulQA"
            ],
            "base_models": [
                "InstructGPT (text-davinci-003)",
                "ChatGPT (gpt-3.5-turbo-0301)"
            ]
        }
    },
    "Empowering Language Models with Active Inquiry for Deeper Understanding": {
        "filename": "Empowering Language Models with Active Inquiry for Deeper Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "StrategyQA",
                "2WikiMultiHopQA",
                "MuSiQue",
                "IIRC",
                "QMSum"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "GPT-4",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond ChatBots ExploreLLM for Structured Thoughts and Personalized Model Responses": {
        "filename": "Beyond ChatBots ExploreLLM for Structured Thoughts and Personalized Model Responses.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LgTS Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents": {
        "filename": "LgTS Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Gridworld based DoorKey domain",
                "Search-and-rescue inspired domain"
            ],
            "base_models": [
                "LLAMA2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Matching to Generation A Survey on Generative Information Retrieval": {
        "filename": "From Matching to Generation A Survey on Generative Information Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "MS MARCO",
                "NQ",
                "TriviaQA",
                "KILT",
                "TREC DL 19 & 20",
                "DynamicIR",
                "MMLU",
                "BIG-bench",
                "LLM-Eval",
                "API-Bank",
                "ToolBench",
                "TruthfulQA",
                "ALCE",
                "HaluEval",
                "RealTime QA",
                "FreshQA",
                "SafetyBench",
                "TrustGPT",
                "TrustLLM"
            ],
            "base_models": [
                "T5",
                "BART",
                "GPT-3 (175B)",
                "BLOOM",
                "LLaMA",
                "PaLM",
                "Mixtral 8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-agent Planning using Visual Language Models": {
        "filename": "Multi-agent Planning using Visual Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ALFRED"
            ],
            "base_models": [
                "GPT-4V",
                "GPT-4"
            ]
        }
    },
    "GenAINet Enabling Wireless Collective Intelligence via Knowledge Transfer and Reasoning": {
        "filename": "GenAINet Enabling Wireless Collective Intelligence via Knowledge Transfer and Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "TeleQnA"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Llama-7B"
            ]
        }
    },
    "Tool Learning with Large Language Models A Survey": {
        "filename": "Tool Learning with Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "API-Bank",
                "APIBench",
                "ToolBench1",
                "ToolAlpaca",
                "RestBench",
                "ToolBench2",
                "MetaTool",
                "TaskBench",
                "T-Eval",
                "ToolEyes"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Diagram of Thought": {
        "filename": "On the Diagram of Thought.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "EvalYaks Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts": {
        "filename": "EvalYaks Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts.pdf",
        "analysis": {
            "benchmarks": [
                "CEFR B2 English speaking assessment",
                "CEFR-SP WikiAuto dataset"
            ],
            "base_models": [
                "Mistral Instruct 7B v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V": {
        "filename": "Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V.pdf",
        "analysis": {
            "benchmarks": [
                "RefCOCOg",
                "COCO",
                "ADE20K",
                "Flickr30K",
                "DAVIS2017"
            ],
            "base_models": [
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Measurement in the Age of LLMs An Application to Ideological Scaling": {
        "filename": "Measurement in the Age of LLMs An Application to Ideological Scaling.pdf",
        "analysis": {
            "benchmarks": [
                "DW-NOMINATE",
                "CFScores",
                "Text-based ideal points (TBIP)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Jointly Extracting Interventions Outcomes and Findings from RCT Reports with LLMs": {
        "filename": "Jointly Extracting Interventions Outcomes and Findings from RCT Reports with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Evidence Inference dataset",
                "160 RCT abstracts with manual annotations"
            ],
            "base_models": [
                "Flan-T5-base",
                "Flan-T5-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Steering LLMs Towards Unbiased Responses A Causality-Guided Debiasing Framework": {
        "filename": "Steering LLMs Towards Unbiased Responses A Causality-Guided Debiasing Framework.pdf",
        "analysis": {
            "benchmarks": [
                "WinoBias",
                "Discrim-Eval"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5",
                "GPT-4",
                "Claude 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond the Black Box A Statistical Model for LLM Reasoning and Inference": {
        "filename": "Beyond the Black Box A Statistical Model for LLM Reasoning and Inference.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Llama (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Medical Large Language Models Technology Application Trustworthiness and Future Directions": {
        "filename": "A Survey on Medical Large Language Models Technology Application Trustworthiness and Future Directions.pdf",
        "analysis": {
            "benchmarks": [
                "USMLE",
                "MedMCQA",
                "PubMedQA",
                "MultiMedQA",
                "MIMIC-CXR",
                "BC5CDR",
                "NCBI",
                "CADEC",
                "MedNLI",
                "MultiCochrane"
            ],
            "base_models": [
                "BERT",
                "T5",
                "GPT-4",
                "BioBERT",
                "ClinicalBERT",
                "BioMegatron",
                "PubMedBERT",
                "GatorTron",
                "Codex-Med",
                "Med-PaLM",
                "GPT-4-Med",
                "ChatDoctor",
                "MedAlpaca",
                "PMC-LLaMA",
                "Visual Med-Alpaca",
                "Med-PaLM 2",
                "GatorTronGPT",
                "HuatuoGPT",
                "ClinicalGPT",
                "MedAGI",
                "LLaVA-Med",
                "OphGLM",
                "SoulChat",
                "Med-Flamingo",
                "BioGPT",
                "ChiMed-GPT",
                "DISC-MedLLM",
                "IvyGPT",
                "CareGPT",
                "ShenNong-TCM-LLM",
                "MedicalGPT",
                "ChatMed",
                "QiZhenGPT",
                "Med-ChatGLM",
                "HuatuoGPT-II",
                "WiNGPT",
                "Taiyi-LLM",
                "Zhongjing",
                "Med-Gemini",
                "Health-LLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ToRA A Tool-Integrated Reasoning Agent for Mathematical Problem Solving": {
        "filename": "ToRA A Tool-Integrated Reasoning Agent for Mathematical Problem Solving.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8k",
                "GSM-Hard",
                "SVAMP",
                "ASDIV",
                "TabMWP",
                "SingleEQ",
                "SingleOP",
                "AddSub",
                "MultiArith"
            ],
            "base_models": [
                "LLaMA-2 (7B to 70B)",
                "CodeLLaMA (7B to 34B)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual Programming Compositional visual reasoning without training": {
        "filename": "Visual Programming Compositional visual reasoning without training.pdf",
        "analysis": {
            "benchmarks": [
                "GQA",
                "NLVR V2",
                "custom dataset for knowledge tagging",
                "custom dataset for image editing"
            ],
            "base_models": [
                "GPT-3",
                "CLIP",
                "ViLT",
                "Stable Diffusion"
            ]
        }
    },
    "Learning diverse attacks on large language models for robust red-teaming and safety tuning": {
        "filename": "Learning diverse attacks on large language models for robust red-teaming and safety tuning.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2",
                "dolly-v2-7b",
                "Gemma-2b-it",
                "Llama-2-7b-chat",
                "Llama-2-13b-chat",
                "Llama-2-70b-chat",
                "Llama-3-8b-instruct",
                "Llama-3-70b-instruct",
                "Starling-7b-beta",
                "Mistral-7b-instruct-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Novel Preprocessing Technique for Data Embedding in Engineering Code Generation Using Large Language Model": {
        "filename": "Novel Preprocessing Technique for Data Embedding in Engineering Code Generation Using Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "RedHawk-SC"
            ],
            "base_models": [
                "GPT-4",
                "Llama2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Genshin General Shield for Natural Language Processing with Large Language Models": {
        "filename": "Genshin General Shield for Natural Language Processing with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "stanfordnlp/sst2",
                "dair-ai/emotion",
                "Deysi/spam-detection-dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "BERT-base",
                "RoBERTa-base"
            ]
        }
    },
    "Exploring the Potential of Llama Models in Automated Code Refinement A Replication Study": {
        "filename": "Exploring the Potential of Llama Models in Automated Code Refinement A Replication Study.pdf",
        "analysis": {
            "benchmarks": [
                "Code Review dataset (CR)",
                "Code Review New dataset (CRN)"
            ],
            "base_models": [
                "Llama 2 (7B)",
                "CodeLlama (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EcoAct Economic Agent Determines When to Register What Action": {
        "filename": "EcoAct Economic Agent Determines When to Register What Action.pdf",
        "analysis": {
            "benchmarks": [
                "ToolBench"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-4o"
            ]
        }
    },
    "HalluciDoctor Mitigating Hallucinatory Toxicity in Visual Instruction Data": {
        "filename": "HalluciDoctor Mitigating Hallucinatory Toxicity in Visual Instruction Data.pdf",
        "analysis": {
            "benchmarks": [
                "LLaVA-Instruction-158K",
                "MiniGPT4-Instruction"
            ],
            "base_models": [
                "MiniGPT-4 (7B)",
                "mPLUG-Owl (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Explicitly Encoding Structural Symmetry is Key to Length Generalization in Arithmetic Tasks": {
        "filename": "Explicitly Encoding Structural Symmetry is Key to Length Generalization in Arithmetic Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset for arithmetic tasks (addition and multiplication)"
            ],
            "base_models": [
                "BERT-based encoder-only attention model"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RAFT Adapting Language Model to Domain Specific RAG": {
        "filename": "RAFT Adapting Language Model to Domain Specific RAG.pdf",
        "analysis": {
            "benchmarks": [
                "PubMed",
                "HotpotQA",
                "Gorilla datasets (HuggingFace Hub, Torch Hub, Tensorflow Hub)"
            ],
            "base_models": [
                "LLaMA2-7B"
            ]
        }
    },
    "GIT-Mol A Multi-modal Large Language Model for Molecular Science with Graph Image and Text": {
        "filename": "GIT-Mol A Multi-modal Large Language Model for Molecular Science with Graph Image and Text.pdf",
        "analysis": {
            "benchmarks": [
                "ChEBI-20",
                "MoleculeNet (Tox21, ToxCast, Sider, ClinTox, Bace, BBBP)"
            ],
            "base_models": [
                "MolT5",
                "SciBERT",
                "Swin Transformer",
                "GIN (from MoMu)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models": {
        "filename": "A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Ragni et al. (2019) dataset"
            ],
            "base_models": [
                "PaLM 2 (XXS, XS, S, L)",
                "Llama 2 (7B, 13B, 70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Investigating Recurrent Transformers with Dynamic Halt": {
        "filename": "Investigating Recurrent Transformers with Dynamic Halt.pdf",
        "analysis": {
            "benchmarks": [
                "Long Range Arena (LRA)",
                "flip-flop language modeling",
                "ListOps",
                "Logical Inference"
            ],
            "base_models": [
                "Universal Transformer",
                "Temporal Latent Bottleneck"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DynaMath A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models": {
        "filename": "DynaMath A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "DYNAMATH"
            ],
            "base_models": [
                "GPT-4o",
                "Claude-3.5 Sonnet",
                "Gemini Pro",
                "InternVL2 series",
                "LLaV A-v1.6 series",
                "Qwen2-VL",
                "DeepSeek-VL",
                "Llama 3.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Grounding Large Language Models In Embodied Environment With Imperfect World Models": {
        "filename": "Grounding Large Language Models In Embodied Environment With Imperfect World Models.pdf",
        "analysis": {
            "benchmarks": [
                "Agent World",
                "Urban Driving"
            ],
            "base_models": [
                "LLaMA-3-8B",
                "LLaMA-3-70B",
                "LLaMA-2-13B",
                "OPT-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SBI-RAG Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation": {
        "filename": "SBI-RAG Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 Turbo",
                "Ollama Llama 3.1"
            ]
        }
    },
    "GPT-ology Computational Models Silicon Sampling How should we think about LLMs in Cognitive Science": {
        "filename": "GPT-ology Computational Models Silicon Sampling How should we think about LLMs in Cognitive Science.pdf",
        "analysis": {
            "benchmarks": [
                "World Values Survey",
                "standard cognitive psychology tasks"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ]
        }
    },
    "DORIS-MAE Scientific Document Retrieval using Multi-level Aspect-based Queries": {
        "filename": "DORIS-MAE Scientific Document Retrieval using Multi-level Aspect-based Queries.pdf",
        "analysis": {
            "benchmarks": [
                "DORIS-MAE"
            ],
            "base_models": [
                "ChatGPT-3.5-turbo-0301",
                "E5-large-v2",
                "RocketQA-v2",
                "ColBERT-v2",
                "SimLM",
                "SPLADE-v2",
                "SPECTER",
                "TSAspire",
                "OTAspire",
                "Sentence-BERT",
                "ANCE FirstP",
                "LLAMA",
                "BM25",
                "TF-IDF",
                "ERNIE",
                "SciBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OpenFedLLM Training Large Language Models on Decentralized Private Data via Federated Learning": {
        "filename": "OpenFedLLM Training Large Language Models on Decentralized Private Data via Federated Learning.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BBH",
                "DROP",
                "HumanEval",
                "CRASS",
                "Vicuna-Bench",
                "MT-Bench",
                "FPB",
                "FIQA-SA",
                "TFNS",
                "NWGI",
                "MedQA",
                "PubMedQA",
                "MedMCQA",
                "GSM8K"
            ],
            "base_models": [
                "Llama2-7B",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Alfred A System for Prompted Weak Supervision": {
        "filename": "Alfred A System for Prompted Weak Supervision.pdf",
        "analysis": {
            "benchmarks": [
                "YouTube spam detection dataset",
                "Oxford-IIIT Pet dataset"
            ],
            "base_models": [
                "T0++ (11 billion parameters)",
                "CLIP-ViT/L-14"
            ]
        }
    },
    "On the Modeling Capabilities of Large Language Models for Sequential Decision Making": {
        "filename": "On the Modeling Capabilities of Large Language Models for Sequential Decision Making.pdf",
        "analysis": {
            "benchmarks": [
                "MiniWob",
                "NetHack",
                "Wordle",
                "MetaWorld",
                "POPE",
                "GQA",
                "AI2D",
                "MMMU"
            ],
            "base_models": [
                "GPT-4o",
                "Llama 3",
                "PaliGemma"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks": {
        "filename": "Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench Subset",
                "OpenAI and Anthropic Red Teaming Dataset",
                "MasterKey dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude 2",
                "Llama-2-7b",
                "Vicuna-7b",
                "Mixtral 8 ×7b",
                "Llama-3",
                "Wizardlm-70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-grounded Diffusion Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models": {
        "filename": "LLM-grounded Diffusion Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "COCO"
            ],
            "base_models": [
                "Stable Diffusion XL",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Creative Agents Empowering Agents with Imagination for Creative Tasks": {
        "filename": "Creative Agents Empowering Agents with Imagination for Creative Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Minecraft"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4V",
                "Stable Diffusion"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Contrastive Decoding Improves Reasoning in Large Language Models": {
        "filename": "Contrastive Decoding Improves Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HellaSwag",
                "GSM8K",
                "CommonsenseQA",
                "StrategyQA",
                "AI2 Reasoning Challenge",
                "BoolQ",
                "MMLU",
                "PIQA",
                "SIQA",
                "WinoGrande",
                "AQuA",
                "ASDiv",
                "SVAMP",
                "MATH"
            ],
            "base_models": [
                "LLaMA-65B",
                "LLaMA-2",
                "GPT-3.5",
                "PaLM 2-L",
                "PaLM-540B",
                "FLAN-T5-XXL (11B)",
                "FLAN-T5-Small (80M)"
            ]
        }
    },
    "Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs": {
        "filename": "Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval-X"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multimodal Chain-of-Thought Reasoning in Language Models": {
        "filename": "Multimodal Chain-of-Thought Reasoning in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "A-OKVQA"
            ],
            "base_models": [
                "T5 (770M)",
                "T5 (200M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CPSeg Finer-grained Image Semantic Segmentation via Chain-of-Thought Language Prompting": {
        "filename": "CPSeg Finer-grained Image Semantic Segmentation via Chain-of-Thought Language Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "FloodPrompt",
                "LoveDA"
            ],
            "base_models": [
                "CLIP",
                "Vision Transformer (ViT)"
            ]
        }
    },
    "Large Language Models as Commonsense Knowledge for Large-Scale Task Planning": {
        "filename": "Large Language Models as Commonsense Knowledge for Large-Scale Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "VirtualHome"
            ],
            "base_models": [
                "GPT-2",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Latent Logic Tree Extraction for Event Sequence Explanation from LLMs": {
        "filename": "Latent Logic Tree Extraction for Event Sequence Explanation from LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-3",
                "EPIC-100",
                "StackOverflow"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "Opt-125M",
                "Opt-1.5B",
                "Opt-6.7B",
                "Zephyr-3B",
                "Mistral-7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Calibration and Correctness of Language Models for Code": {
        "filename": "Calibration and Correctness of Language Models for Code.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "DyPyBench",
                "Defects4J",
                "ManySStubs4J"
            ],
            "base_models": [
                "GPT-3.5",
                "Codex",
                "CodeGen2-16B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Watermarked LLMs be Identified by Users via Crafted Prompts": {
        "filename": "Can Watermarked LLMs be Identified by Users via Crafted Prompts.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Qwen2.5-1.5B",
                "OPT-2.7B",
                "Llama-3.2-3B",
                "Qwen2.5-3B",
                "Llama2-7B",
                "Mixtral-7B",
                "Qwen2.5-7B",
                "Llama-3.1-8B",
                "Llama2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SaySelf Teaching LLMs to Express Confidence with Self-Reflective Rationales": {
        "filename": "SaySelf Teaching LLMs to Express Confidence with Self-Reflective Rationales.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "TruthfulQA",
                "StrategyQA",
                "FEVER",
                "HaluEval",
                "ParaRel"
            ],
            "base_models": [
                "Mistral-7B",
                "Llama 3 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "mABC multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture": {
        "filename": "mABC multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture.pdf",
        "analysis": {
            "benchmarks": [
                "AIOps challenge dataset",
                "Train-Ticket dataset"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4-Turbo",
                "Llama-3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Planning-Driven Programming A Large Language Model Programming Workflow": {
        "filename": "Planning-Driven Programming A Large Language Model Programming Workflow.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "APPS",
                "CodeContests"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-3.5",
                "Llama-3 (70B)",
                "Phi-3 (14B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aladdin Zero-Shot Hallucination of Stylized 3D Assets from Abstract Scene Descriptions": {
        "filename": "Aladdin Zero-Shot Hallucination of Stylized 3D Assets from Abstract Scene Descriptions.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "CLIP",
                "Diffusion models"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLMs Understand Time Series Anomalies": {
        "filename": "Can LLMs Understand Time Series Anomalies.pdf",
        "analysis": {
            "benchmarks": [
                "Time-MMD",
                "Custom time series datasets (point, range, frequency, trend)"
            ],
            "base_models": [
                "GPT-3",
                "LLaMA-2",
                "GPT-2",
                "Qwen-VL-Chat",
                "InternVL2-Llama3-76B",
                "GPT-4o-mini",
                "Gemini-1.5-Flash"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GameEval Evaluating LLMs on Conversational Games": {
        "filename": "GameEval Evaluating LLMs on Conversational Games.pdf",
        "analysis": {
            "benchmarks": [
                "Cifar-100"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT (gpt-3.5-turbo)",
                "Text-Davinci-003"
            ]
        }
    },
    "UrbanKGent A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction": {
        "filename": "UrbanKGent A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction.pdf",
        "analysis": {
            "benchmarks": [
                "NYC-Instruct",
                "CHI-Instruct"
            ],
            "base_models": [
                "GPT-4",
                "Llama-2-7B",
                "Llama-2-13B",
                "Llama-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models are Bounded Pragmatic Speakers Understanding RLHF from a Bayesian Cognitive Modeling Perspective": {
        "filename": "Language Models are Bounded Pragmatic Speakers Understanding RLHF from a Bayesian Cognitive Modeling Perspective.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (Brown et al., 2020)",
                "PaLM (Chowdhery et al., 2022)",
                "Chinchilla (Hoffmann et al., 2022)",
                "OPT (Zhang et al., 2022a)",
                "BLOOM (Scao et al., 2022)",
                "LLaMA (Touvron et al., 2023)"
            ]
        }
    },
    "Long-Horizon Planning for Multi-Agent Robots in Partially Observable Environments": {
        "filename": "Long-Horizon Planning for Multi-Agent Robots in Partially Observable Environments.pdf",
        "analysis": {
            "benchmarks": [
                "MAP-THOR"
            ],
            "base_models": [
                "GPT-4V",
                "IDEFICS-2",
                "LLaVA",
                "CogVLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLM be a Good Path Planner based on Prompt Engineering Mitigating the Hallucination for Path Planning": {
        "filename": "Can LLM be a Good Path Planner based on Prompt Engineering Mitigating the Hallucination for Path Planning.pdf",
        "analysis": {
            "benchmarks": [
                "custom maze datasets (5x5, 7x7, 10x10 mazes)"
            ],
            "base_models": [
                "ERNIE-Bot 4.0"
            ]
        }
    },
    "MedThink Explaining Medical Visual Question Answering via Multimodal Decision-Making Rationale": {
        "filename": "MedThink Explaining Medical Visual Question Answering via Multimodal Decision-Making Rationale.pdf",
        "analysis": {
            "benchmarks": [
                "R-RAD",
                "R-SLAKE",
                "R-Path"
            ],
            "base_models": [
                "T5-base (223M)"
            ]
        }
    },
    "Distilling LLMs Decomposition Abilities into Compact Language Models": {
        "filename": "Distilling LLMs Decomposition Abilities into Compact Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K-AI-SubQ"
            ],
            "base_models": [
                "GPT-4",
                "Claude 22",
                "Gemini",
                "GPT-2 (various sizes)",
                "DistilGPT",
                "LLaMA 7B",
                "LLaMA 13B",
                "Mistral 7B"
            ]
        }
    },
    "State of What Art A Call for Multi-Prompt LLM Evaluation": {
        "filename": "State of What Art A Call for Multi-Prompt LLM Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "LM ENTRY",
                "BIG-bench Lite (BBL)",
                "BIG-bench Hard (BBH)"
            ],
            "base_models": [
                "Flan-T5 (Small, Base 250M, Large 780M, XL 3B, XXL 11B)",
                "T0 (Small, T0pp 11B)",
                "Alpaca (Small LLaMA 7B, Big 13B)",
                "Vicuna (LLaMA 13B)",
                "Airoboros (LLaMA 13B)",
                "UltraLM (LLaMA 13B)",
                "Nous-Hermes (LLaMA 13B)",
                "Falcon-Instruct (Falcon 7B)",
                "MPT (MPT 7B)",
                "Minotaur (StarCoder Plus 15B)"
            ]
        }
    },
    "Despite super-human performance current LLMs are unsuited for decisions about ethics and safety": {
        "filename": "Despite super-human performance current LLMs are unsuited for decisions about ethics and safety.pdf",
        "analysis": {
            "benchmarks": [
                "ETHICS-C-S"
            ],
            "base_models": [
                "GPT-3 (smallest model, 2019)",
                "GPT-3 (largest model, 2019)",
                "GPT-3 (largest model, current)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Medprompt to o1 Exploration of Run-Time Strategies for Medical Challenge Problems and Beyond": {
        "filename": "From Medprompt to o1 Exploration of Run-Time Strategies for Medical Challenge Problems and Beyond.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "MedMCQA Dev",
                "MMLU Clinical Knowledge",
                "MMLU Anatomy",
                "MMLU Medical Genetics",
                "MMLU Professional Medicine",
                "MMLU College Biology",
                "MMLU College Medicine",
                "NCLEX",
                "JMLE-2024"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4 Turbo",
                "GPT-4o",
                "o1-preview"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A survey on multimodal large language models": {
        "filename": "A survey on multimodal large language models.pdf",
        "analysis": {
            "benchmarks": [
                "MME",
                "MMBench",
                "ScienceQA",
                "NoCaps",
                "Flickr30K"
            ],
            "base_models": [
                "GPT-4V",
                "LLaMA-2 (7B/13B/70B)",
                "Qwen (1.8B/7B/14B/72B)",
                "Flan-T5 (3B/11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Equation as a Better Intermediate Meaning Representation for Numerical Reasoning": {
        "filename": "Exploring Equation as a Better Intermediate Meaning Representation for Numerical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "Algebra"
            ],
            "base_models": [
                "Codex (code-davinci-002)",
                "GPT-3.5 (gpt-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs left right and center Assessing GPTs capabilities to label political bias from web domains": {
        "filename": "LLMs left right and center Assessing GPTs capabilities to label political bias from web domains.pdf",
        "analysis": {
            "benchmarks": [
                "Media Bias/Fact Check (MBFC)"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Plan of Thoughts Heuristic-Guided Problem Solving with Large Language Models": {
        "filename": "Plan of Thoughts Heuristic-Guided Problem Solving with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Game of 24"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "GPT-3.5-Turbo-Instruct"
            ]
        }
    },
    "How Aligned are Human Chart Takeaways and LLM Predictions A Case Study on Bar Charts with Varying Layouts": {
        "filename": "How Aligned are Human Chart Takeaways and LLM Predictions A Case Study on Bar Charts with Varying Layouts.pdf",
        "analysis": {
            "benchmarks": [
                "Xiong et al. datasets"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4V",
                "GPT-3.5",
                "Gemini 1.0 Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cognitive Modeling with Scaffolded LLMs A Case Study of Referential Expression Generation": {
        "filename": "Cognitive Modeling with Scaffolded LLMs A Case Study of Referential Expression Generation.pdf",
        "analysis": {
            "benchmarks": [
                "A3DS"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "Ever-Evolving Memory by Blending and Refining the Past": {
        "filename": "Ever-Evolving Memory by Blending and Refining the Past.pdf",
        "analysis": {
            "benchmarks": [
                "Multi-Session Chat (MSC)",
                "Conversation Chronicles (CC)"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "T5-base"
            ]
        }
    },
    "Seeing the Big through the Small Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations": {
        "filename": "Seeing the Big through the Small Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "Chaos NLI",
                "VariErr NLI"
            ],
            "base_models": [
                "Mixtral-8x7b-Instruct-v0.1",
                "Llama3-Chat-70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MARVEL Multidimensional Abstraction and Reasoning through Visual Evaluation and Learning": {
        "filename": "MARVEL Multidimensional Abstraction and Reasoning through Visual Evaluation and Learning.pdf",
        "analysis": {
            "benchmarks": [
                "MARVEL"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini",
                "Claude3 (Sonnet)",
                "Claude3 (Opus)",
                "InstructBLIP (Vicuna-13B)",
                "BLIP-2 (FlanT5 XXL-11B)",
                "Fuyu (8B)",
                "Qwen-VL (7B)",
                "LLaVA (Vicuna-13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are Hard Examples also Harder to Explain A Study with Human and Model-Generated Explanations": {
        "filename": "Are Hard Examples also Harder to Explain A Study with Human and Model-Generated Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "Winogrande"
            ],
            "base_models": [
                "GPT-3 (175B)"
            ]
        }
    },
    "OpenR An Open Source Framework for Advanced Reasoning with Large Language Models": {
        "filename": "OpenR An Open Source Framework for Advanced Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "MATH500"
            ],
            "base_models": [
                "Qwen2.5-Math-7B-Instruct",
                "Qwen2.5-1.5B-Math-Instruct"
            ]
        }
    },
    "TextMonkey An OCR-Free Large Multimodal Model for Understanding Document": {
        "filename": "TextMonkey An OCR-Free Large Multimodal Model for Understanding Document.pdf",
        "analysis": {
            "benchmarks": [
                "STVQA",
                "TextVQA",
                "OCRVQA",
                "DocVQA",
                "InfoVQA",
                "ChartVQA",
                "DeepForm",
                "Kleister Charity",
                "WikiTableQuestions",
                "FUNSD",
                "SROIE",
                "POIE",
                "OCRBench"
            ],
            "base_models": [
                "CLIP",
                "Qwen-VL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FinEval A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models": {
        "filename": "FinEval A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "FinEval"
            ],
            "base_models": [
                "Claude 3.5-Sonnet",
                "GPT-4o",
                "Qwen2.5-72B-Instruct",
                "XuanYuan3-70B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TR2MTL LLM based framework for Metric Temporal Logic Formalization of Traffic Rules": {
        "filename": "TR2MTL LLM based framework for Metric Temporal Logic Formalization of Traffic Rules.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of traffic rules from StVO and VCoRT"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "StarCoder",
                "Falcon-7b",
                "Bloomz"
            ]
        }
    },
    "LLM-based Robot Task Planning with Exceptional Handling for General Purpose Service Robots": {
        "filename": "LLM-based Robot Task Planning with Exceptional Handling for General Purpose Service Robots.pdf",
        "analysis": {
            "benchmarks": [
                "RoboCup@Home Command Generator"
            ],
            "base_models": [
                "ERNIE-Bot 4.0",
                "GPT-3",
                "Codex",
                "llama2 70b"
            ]
        }
    },
    "Explanation-based Finetuning Makes Models More Robust to Spurious Cues": {
        "filename": "Explanation-based Finetuning Makes Models More Robust to Spurious Cues.pdf",
        "analysis": {
            "benchmarks": [
                "ComVE",
                "CREAK",
                "e-SNLI",
                "SBIC"
            ],
            "base_models": [
                "GPT-3 (Davinci)",
                "T5 (base)",
                "BART (base)",
                "OPT (1.3b)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Incremental Learning in Large Language Models A Critical Review": {
        "filename": "Towards Incremental Learning in Large Language Models A Critical Review.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR100",
                "ImageNet100"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2 (7 billion parameters)",
                "Vicuna (7 billion parameters)",
                "BERT",
                "T5",
                "RoBERTa",
                "GPT-2 (110 million parameters)",
                "GPT-NeoX"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TPO Aligning Large Language Models with Multi-branch  Multi-step Preference Trees": {
        "filename": "TPO Aligning Large Language Models with Multi-branch  Multi-step Preference Trees.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "SVAMP",
                "ASDiv",
                "GSM-Plus",
                "HumanEval",
                "MBPP"
            ],
            "base_models": [
                "Qwen2-1.5B-Instruct",
                "Qwen2-7B-Instruct",
                "DeepSeekMath-7B-Instruct",
                "DeepSeekMath-7B-RL"
            ]
        }
    },
    "Scaling Laws for Predicting Downstream Performance in LLMs": {
        "filename": "Scaling Laws for Predicting Downstream Performance in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "RACE",
                "TriviaQA",
                "BigBench-Challenge (BBH)",
                "ARC-Challenge (ARC)",
                "Hellaswag",
                "HumanEval"
            ],
            "base_models": [
                "3B LLM",
                "7B LLM",
                "13B LLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "X-IQE eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models": {
        "filename": "X-IQE eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "COCO Captions",
                "DrawBench"
            ],
            "base_models": [
                "MiniGPT-4 (7B/13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-supervised Interpretable Concept-based Models for Text Classification": {
        "filename": "Self-supervised Interpretable Concept-based Models for Text Classification.pdf",
        "analysis": {
            "benchmarks": [
                "CEBaB",
                "MultiEmotions-IT",
                "Drug review",
                "Depression"
            ],
            "base_models": [
                "Mixtral 8x7B",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FoMo Rewards Can we cast foundation models as reward functions": {
        "filename": "FoMo Rewards Can we cast foundation models as reward functions.pdf",
        "analysis": {
            "benchmarks": [
                "VIMABench",
                "VIMA(Uni)"
            ],
            "base_models": [
                "ViT (300M parameters)",
                "Mosaic pretrained transformers (MPT-1B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards LogiGLUE A Brief Survey and A Benchmark for Analyzing Logical Reasoning Capabilities of Language Models": {
        "filename": "Towards LogiGLUE A Brief Survey and A Benchmark for Analyzing Logical Reasoning Capabilities of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "LOGIGLUE",
                "RuleTaker",
                "PrOntoQA",
                "WN18RR",
                "αARCT",
                "αNLI",
                "AbductionRule-Animal",
                "LogicNLI",
                "ProofWriter",
                "Rulebert-Union",
                "FOLIO",
                "ANLI",
                "CLUTTR-Robust",
                "LogiQA",
                "AbductionRule-person",
                "bAbi",
                "Bird-Electricity",
                "NatlLang",
                "Winologic",
                "WaNLI",
                "PrOntoQA",
                "BigBench",
                "ReClor",
                "LogiQA 2.0"
            ],
            "base_models": [
                "Flan-T5 (large)",
                "GPT-4",
                "GPT-3.5-turbo",
                "LLaMA-2-chat (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generative Type Inference for Python": {
        "filename": "Generative Type Inference for Python.pdf",
        "analysis": {
            "benchmarks": [
                "ManyTypes4Py"
            ],
            "base_models": [
                "GPT-Neo (1.3B)",
                "GPT-Neo (2.7B)",
                "GPT-J (6.7B)",
                "CodeGen (6B)",
                "GPT-3.5 (175B)",
                "ChatGPT (175B)",
                "InCoder (1.3B)",
                "InCoder (6.7B)",
                "UniXcoder (126M)",
                "CodeT5 (220M)",
                "CodeT5 (770M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Words into Action Learning Diverse Humanoid Robot Behaviors using Language Guided Iterative Motion Refinement": {
        "filename": "Words into Action Learning Diverse Humanoid Robot Behaviors using Language Guided Iterative Motion Refinement.pdf",
        "analysis": {
            "benchmarks": [
                "HumanML3D"
            ],
            "base_models": [
                "T2M-GPT",
                "ChatGPT-4"
            ]
        }
    },
    "Is Your Model Really A Good Math Reasoner Evaluating Mathematical Reasoning with Checklist": {
        "filename": "Is Your Model Really A Good Math Reasoner Evaluating Mathematical Reasoning with Checklist.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "GeoQA",
                "UniGeo",
                "Geometry3K",
                "MATHCHECK-GSM",
                "MATHCHECK-GEO"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4-Turbo-20240409",
                "GPT-3.5-Turbo",
                "Llama-3.1-70B-Instruct",
                "Claude-3.5-sonnet-20240620",
                "Qwen1.5-72B-Chat",
                "DeepSeek-Math-7B-RL",
                "MetaMath-LLama2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Capabilities of Large Language Models in Control Engineering A Benchmark Study on GPT-4 Claude 3 Opus and Gemini 10 Ultra": {
        "filename": "Capabilities of Large Language Models in Control Engineering A Benchmark Study on GPT-4 Claude 3 Opus and Gemini 10 Ultra.pdf",
        "analysis": {
            "benchmarks": [
                "ControlBench",
                "ControlBench-C"
            ],
            "base_models": [
                "GPT-4",
                "Claude 3 Opus",
                "Gemini 1.0 Ultra"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PointCLIP V2 Prompting CLIP and GPT for Powerful 3D Open-world Learning": {
        "filename": "PointCLIP V2 Prompting CLIP and GPT for Powerful 3D Open-world Learning.pdf",
        "analysis": {
            "benchmarks": [
                "ModelNet40",
                "ModelNet10",
                "ScanObjectNN"
            ],
            "base_models": [
                "CLIP",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-context Autoencoder for Context Compression in a Large Language Model": {
        "filename": "In-context Autoencoder for Context Compression in a Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "PWC dataset"
            ],
            "base_models": [
                "Llama-7b",
                "Llama-2-7b",
                "Llama-2-13b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language Understanding and Inference with MLLM in Visual Question Answering A Survey": {
        "filename": "Natural Language Understanding and Inference with MLLM in Visual Question Answering A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "VQA v1",
                "VQA v2",
                "A-OKVQA",
                "GQA",
                "VizWiz",
                "Visual7W",
                "CLEVER",
                "MovieQA",
                "COCO-QA",
                "DAQUAR"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "OPT-3 (66B)",
                "OPT-3 (175B)",
                "Chinchilla (70B)",
                "Chinchilla (71B)",
                "Chinchilla (72B)",
                "FlanT5 (XXL)",
                "Vicuna (7B)",
                "Qwen (7B)",
                "LLaMA-2 (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In": {
        "filename": "Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "PopQA"
            ],
            "base_models": [
                "Flan-T5 (250M, 780M, 3B)",
                "InstructGPT (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Table-GPT Table-tuned GPT for Diverse Table Tasks": {
        "filename": "Table-GPT Table-tuned GPT for Diverse Table Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Table-QA (T-3)",
                "Column type annotation (CTA) (T-4)"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MME A Comprehensive Evaluation Benchmark for Multimodal Large Language Models": {
        "filename": "MME A Comprehensive Evaluation Benchmark for Multimodal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MME"
            ],
            "base_models": [
                "GPT-4V",
                "LLaMA-Adapter-v2",
                "BLIP-2",
                "InstructBLIP",
                "MiniGPT-4",
                "PandaGPT",
                "Multimodal-GPT",
                "VisualGLM-6B",
                "ImageBind-LLM",
                "VPGTrans",
                "LaVIN",
                "mPLUG-Owl",
                "Octopus",
                "Muffin",
                "Otter",
                "LRV-Instruction",
                "Cheetor",
                "GIT2",
                "BLIVA",
                "Lynx",
                "MMICL",
                "Skywork-MM",
                "mPLUG-Owl2",
                "Qwen-VL-Chat",
                "XComposer-VL",
                "LLaVA",
                "Lion",
                "SPHINX",
                "InfMLLM",
                "WeMM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Susceptibility to Influence of Large Language Models": {
        "filename": "Susceptibility to Influence of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of ~200 novel statements for ITE",
                "15-country experiment data for PFN"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Autoregressive Search Engines Generating Substrings as Document Identifiers": {
        "filename": "Autoregressive Search Engines Generating Substrings as Document Identifiers.pdf",
        "analysis": {
            "benchmarks": [
                "KILT",
                "Natural Questions",
                "NQ320k"
            ],
            "base_models": [
                "BART-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large-scale text analysis using generative language models A case study in discovering public value expressions in AI patents": {
        "filename": "Large-scale text analysis using generative language models A case study in discovering public value expressions in AI patents.pdf",
        "analysis": {
            "benchmarks": [
                "BLEU scores",
                "topic modeling"
            ],
            "base_models": [
                "GPT-4",
                "BERT-base-uncased (110M)",
                "BERT-large-uncased (340M)",
                "DistilBERT (66M)",
                "RoBERTa-large (354M)",
                "ALBERT-xxl-v2 (223M)",
                "DeBERTa-xxl-v2 (1.5B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Make a Donut Hierarchical EMD-Space Planning for Zero-Shot Deformable Manipulation with Tools": {
        "filename": "Make a Donut Hierarchical EMD-Space Planning for Zero-Shot Deformable Manipulation with Tools.pdf",
        "analysis": {
            "benchmarks": [
                "dough manipulation tasks (Donut, Baguette, TwoPancakes)",
                "single-tool tasks (Spread, Cut, Arrange)"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Collaborative Human-AI Risk Annotation Co-Annotating Online Incivility with CHAIRA": {
        "filename": "Collaborative Human-AI Risk Annotation Co-Annotating Online Incivility with CHAIRA.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of 457 user comments"
            ],
            "base_models": [
                "GPT-3.5 Turbo"
            ]
        }
    },
    "Accelerating Clinical Evidence Synthesis with Large Language Models": {
        "filename": "Accelerating Clinical Evidence Synthesis with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TrialReviewBench"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation": {
        "filename": "A Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation.pdf",
        "analysis": {
            "benchmarks": [
                "FELM-Science",
                "FactCheckGPT"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Llama3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGPT as a Factual Inconsistency Evaluator for Text Summarization": {
        "filename": "ChatGPT as a Factual Inconsistency Evaluator for Text Summarization.pdf",
        "analysis": {
            "benchmarks": [
                "FactCC",
                "CoGenSumm",
                "XSumFaith",
                "SummEval",
                "FRANK",
                "Polytope"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-3",
                "InstructGPT",
                "PaLM",
                "BLOOM"
            ]
        }
    },
    "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet": {
        "filename": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet.pdf",
        "analysis": {
            "benchmarks": [
                "EMPTY map",
                "ROOM-32-32-4 map",
                "MAZE-32-32-2 map"
            ],
            "base_models": [
                "GPT-4-turbo (1106-preview)"
            ]
        }
    },
    "Analyzing the Generalization and Reliability of Steering Vectors": {
        "filename": "Analyzing the Generalization and Reliability of Steering Vectors.pdf",
        "analysis": {
            "benchmarks": [
                "Model-Written Evaluations (MWE) datasets",
                "TruthfulQA",
                "sycophancy dataset"
            ],
            "base_models": [
                "Llama-2-7b-Chat",
                "Qwen-1.5-14b-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models as Tool Makers": {
        "filename": "Large Language Models as Tool Makers.pdf",
        "analysis": {
            "benchmarks": [
                "Big-Bench tasks"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Characterizing Manipulation from AI Systems": {
        "filename": "Characterizing Manipulation from AI Systems.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Discussion of Large Language Models Symmetry of Agents and Interplay with Prompts": {
        "filename": "On the Discussion of Large Language Models Symmetry of Agents and Interplay with Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "FOLIO wiki curated"
            ],
            "base_models": [
                "GPT-3.5-Turbo-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Attention Prompting on Image for Large Vision-Language Models": {
        "filename": "Attention Prompting on Image for Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MM-Vet",
                "LLaVA-Wild",
                "LLaVA-Bench",
                "VisWiz",
                "TextVQA",
                "MMMU",
                "MME"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA-1.5",
                "CLIP",
                "CogVLM",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoEvo Continual Evolution of Symbolic Solutions Using Large Language Models": {
        "filename": "CoEvo Continual Evolution of Symbolic Solutions Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AI Feynman benchmark",
                "Oscillation 1",
                "Oscillation 2",
                "E. coli growth",
                "Stress-Strain"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4o-mini"
            ]
        }
    },
    "Enhancing text-based knowledge graph completion with zero-shot large language models A focus on semantic enhancement": {
        "filename": "Enhancing text-based knowledge graph completion with zero-shot large language models A focus on semantic enhancement.pdf",
        "analysis": {
            "benchmarks": [
                "FB15k-237",
                "WN18RR",
                "UMLS"
            ],
            "base_models": [
                "Qwen-7B-Chat-int4",
                "Qwen-7B-Chat",
                "LLaMA2-7B-Chat",
                "Qwen-turbo",
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "Follow the Rules Reasoning for Video Anomaly Detection with Large Language Models": {
        "filename": "Follow the Rules Reasoning for Video Anomaly Detection with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "UCSD Ped2",
                "CUHK Avenue",
                "ShanghaiTech",
                "UBnormal"
            ],
            "base_models": [
                "GPT-4-1106-Preview",
                "Mistral-7B-Instruct-v0.2",
                "CogVLM-17B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ROSCOE A Suite of Metrics for Scoring Step-by-Step Reasoning": {
        "filename": "ROSCOE A Suite of Metrics for Scoring Step-by-Step Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Entailment-Bank",
                "ProofWriter",
                "MATH",
                "ASDIV",
                "AQUA",
                "EQASC",
                "StrategyQA",
                "GSM8K",
                "DROP",
                "ESNLI",
                "COSMOS-QA",
                "SemEV AL"
            ],
            "base_models": [
                "GPT-3 (text-davinci-002)",
                "SimCSE (based on RoBERTa)",
                "BART",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ToolChain Efficient Action Space Navigation in Large Language Models with A Search": {
        "filename": "ToolChain Efficient Action Space Navigation in Large Language Models with A Search.pdf",
        "analysis": {
            "benchmarks": [
                "ToolBench",
                "GSM8K"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Code Soliloquies for Accurate Calculations in Large Language Models": {
        "filename": "Code Soliloquies for Accurate Calculations in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PHY300"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2-70b-chat"
            ]
        }
    },
    "Case-Based Reasoning with Language Models for Classification of Logical Fallacies": {
        "filename": "Case-Based Reasoning with Language Models for Classification of Logical Fallacies.pdf",
        "analysis": {
            "benchmarks": [
                "LOGIC",
                "LOGIC Climate"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "ELECTRA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Explainable artificial intelligence A survey of needs techniques applications and future direction": {
        "filename": "Explainable artificial intelligence A survey of needs techniques applications and future direction.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Token-Efficient Leverage Learning in Large Language Models": {
        "filename": "Token-Efficient Leverage Learning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HaluEval",
                "WMT-21"
            ],
            "base_models": [
                "LLaMA2-7B-Chat",
                "QWen-7B-Chat",
                "Gemma-7b-it"
            ]
        }
    },
    "3D-GPT Procedural 3D Modeling with Large Language Models": {
        "filename": "3D-GPT Procedural 3D Modeling with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset generated using ChatGPT for scene descriptions"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Where does In-context Translation Happen in Large Language Models": {
        "filename": "Where does In-context Translation Happen in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "FLORES"
            ],
            "base_models": [
                "GPTNeo-2.7B",
                "BLOOM-3B",
                "LLAMA-7B",
                "LLAMA-7B-CHAT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learnings from Data Integration for Augmented Language Models": {
        "filename": "Learnings from Data Integration for Augmented Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "Chain of Thought Imitation with Procedure Cloning": {
        "filename": "Chain of Thought Imitation with Procedure Cloning.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic maze navigation",
                "AntMaze",
                "bimanual sweeping task",
                "MinAtar"
            ],
            "base_models": [
                "transformer-like architecture",
                "GPT-like autoregressive model"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DataEnvGym Data Generation Agents in Teacher Environments with Student Feedback": {
        "filename": "DataEnvGym Data Generation Agents in Teacher Environments with Student Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "GQA",
                "MATH",
                "LiveCodeBench",
                "NaturalBench",
                "MnMs"
            ],
            "base_models": [
                "PaliGemma-3B",
                "Gemma-2-2B",
                "Llama-3-8B",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Predicting the Quality of Revisions in Argumentative Writing": {
        "filename": "Predicting the Quality of Revisions in Argumentative Writing.pdf",
        "analysis": {
            "benchmarks": [
                "annotated elementary essays",
                "college essays benchmark"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)"
            ]
        }
    },
    "Conditional and Modal Reasoning in Large Language Models": {
        "filename": "Conditional and Modal Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8K"
            ],
            "base_models": [
                "Llama 3.1 Instruct 405B",
                "GPT-4 Turbo (2024-04-09)",
                "Claude 3.5 Sonnet",
                "GPT-4 Turbo (1106)",
                "GPT-4 (0613)",
                "Llama 3.1 Instruct 70B",
                "Gemini 1.5 Pro",
                "GPT-4 (0314)",
                "GPT-4o (2024-05-13)",
                "GPT-4o mini",
                "Claude 3 Opus",
                "Gemini 1.5 Flash",
                "Mistral Large 2",
                "Mixtral 8x7B",
                "Llama 3 Instruct 70B",
                "Claude 3 Sonnet",
                "Claude 3 Haiku",
                "Mixtral 8x22B",
                "Gemma 2 27B",
                "Llama 3 Instruct 8B",
                "Code Llama 34B",
                "GPT-3.5 Turbo (0125)",
                "Llama 2 Chat 7B",
                "GPT-3.5 Turbo (1106)",
                "Llama 3.1 Instruct 8B",
                "Code Llama 7B",
                "Llama 2 Chat 13B",
                "Mistral 7B",
                "Code Llama 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data": {
        "filename": "Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data.pdf",
        "analysis": {
            "benchmarks": [
                "Dynamic-SUPERB",
                "AIR-Bench-Chat"
            ],
            "base_models": [
                "Llama3-8B-Instruct",
                "Whisper-small (244M parameters)"
            ]
        }
    },
    "TinyLlama An Open-Source Small Language Model": {
        "filename": "TinyLlama An Open-Source Small Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Hellaswag",
                "OpenBookQA",
                "WinoGrande",
                "ARC-Easy",
                "ARC-Challenge",
                "BoolQ",
                "PIQA",
                "MMLU",
                "BIG-Bench Hard (BBH)",
                "DROP",
                "HumanEval",
                "xwinograd_zh",
                "xstorycloze_zh",
                "xnli_zh",
                "xcopa_zh"
            ],
            "base_models": [
                "Llama 2",
                "OPT-1.3B",
                "Pythia-1.0B",
                "Pythia-1.4B"
            ]
        }
    },
    "Data-Centric Human Preference Optimization with Rationales": {
        "filename": "Data-Centric Human Preference Optimization with Rationales.pdf",
        "analysis": {
            "benchmarks": [
                "Orca DPO Pairs",
                "UltraFeedback",
                "TriviaQA"
            ],
            "base_models": [
                "Mistral-7B-v0.1",
                "Mistral-7B-Instruct-v0.2",
                "Zephyr-7B-Beta",
                "Llama3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "H3Fusion Helpful Harmless Honest Fusion of Aligned LLMs": {
        "filename": "H3Fusion Helpful Harmless Honest Fusion of Aligned LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Alpaca-Eval",
                "BeaverTails",
                "TruthfulQA"
            ],
            "base_models": [
                "LLaMA-2 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Two Timin Repairing Smart Contracts With A Two-Layered Approach": {
        "filename": "Two Timin Repairing Smart Contracts With A Two-Layered Approach.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 2,000 smart contracts"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "Llama-2-7B"
            ]
        }
    },
    "Strong and weak alignment of large language models with human values": {
        "filename": "Strong and weak alignment of large language models with human values.pdf",
        "analysis": {
            "benchmarks": [
                "Custom scenarios with ChatGPT, Gemini, and Copilot"
            ],
            "base_models": [
                "ChatGPT",
                "Gemini",
                "Copilot"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Transformers Provably Solve Parity Efficiently with Chain of Thought": {
        "filename": "Transformers Provably Solve Parity Efficiently with Chain of Thought.pdf",
        "analysis": {
            "benchmarks": [
                "Custom k-parity dataset"
            ],
            "base_models": [
                "One-layer transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GeomVerse A Systematic Evaluation of Large Models for Geometric Reasoning": {
        "filename": "GeomVerse A Systematic Evaluation of Large Models for Geometric Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GeomVerse",
                "Geometry3k"
            ],
            "base_models": [
                "PaLI (5B and 55B)",
                "GPT-4V",
                "PaLM 2 Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How is ChatGPTs behavior changing over time": {
        "filename": "How is ChatGPTs behavior changing over time.pdf",
        "analysis": {
            "benchmarks": [
                "US Medical License exams",
                "LangChain HotpotQA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Navigating the Landscape of Large Language Models A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies": {
        "filename": "Navigating the Landscape of Large Language Models A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies.pdf",
        "analysis": {
            "benchmarks": [
                "six text classification datasets"
            ],
            "base_models": [
                "BERT",
                "GPT-2",
                "GPT-3",
                "LLaMA",
                "OPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When do you need Chain-of-Thought Prompting for ChatGPT": {
        "filename": "When do you need Chain-of-Thought Prompting for ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith",
                "AddSub",
                "AQUA",
                "SVAMP",
                "GSM8K",
                "SingleOp",
                "CSQA",
                "StrategyQA",
                "Last Letter",
                "Coin-flip",
                "Date",
                "Object"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT"
            ]
        }
    },
    "AnalogXpert Automating Analog Topology Synthesis by Incorporating Circuit Design Expertise into Large Language Models": {
        "filename": "AnalogXpert Automating Analog Topology Synthesis by Incorporating Circuit Design Expertise into Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "real data benchmark",
                "synthetic data benchmark"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GuReT Distinguishing Guilt and Regret related Text": {
        "filename": "GuReT Distinguishing Guilt and Regret related Text.pdf",
        "analysis": {
            "benchmarks": [
                "Custom Guilt and Regret Dataset"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "ALBERT",
                "XLNet",
                "DistilBERT",
                "ELECTRA",
                "GPT-3.5-Turbo"
            ]
        }
    },
    "Mastering the ABCDs of Complex Questions Answer-Based Claim Decomposition for Fine-grained Self-Evaluation": {
        "filename": "Mastering the ABCDs of Complex Questions Answer-Based Claim Decomposition for Fine-grained Self-Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "TRIVIA QA",
                "HOTPOT QA",
                "OBSCURE QA"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "CHASE-SQL Multi-Path Reasoning and Preference Optimized Candidate Selection in Text-to-SQL": {
        "filename": "CHASE-SQL Multi-Path Reasoning and Preference Optimized Candidate Selection in Text-to-SQL.pdf",
        "analysis": {
            "benchmarks": [
                "BIRD",
                "Spider"
            ],
            "base_models": [
                "Gemini 1.5 Pro",
                "Claude-3.5-sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are Human Rules Necessary Generating Reusable APIs with CoT Reasoning and In-Context Learning": {
        "filename": "Are Human Rules Necessary Generating Reusable APIs with CoT Reasoning and In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Terragni et al. evaluation set (200 human-written APIs for SO code snippets)"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Spatio-Temporal Side Tuning Pre-trained Foundation Models for Video-based Pedestrian Attribute Recognition": {
        "filename": "Spatio-Temporal Side Tuning Pre-trained Foundation Models for Video-based Pedestrian Attribute Recognition.pdf",
        "analysis": {
            "benchmarks": [
                "MARS-Attribute",
                "DukeMTMC-VID-Attribute"
            ],
            "base_models": [
                "CLIP (ViT-B/16)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning": {
        "filename": "Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "MathQA"
            ],
            "base_models": [
                "LaMDA (137B)",
                "PaLM (540B)",
                "GPT-3 CoT (175B)",
                "Codex CoT (175B)",
                "Complex CoT (175B)",
                "PAL (175B)",
                "CodeGen (6B)"
            ]
        }
    },
    "Advancements in Scientific Controllable Text Generation Methods": {
        "filename": "Advancements in Scientific Controllable Text Generation Methods.pdf",
        "analysis": {
            "benchmarks": [
                "Sci-Cite dataset",
                "SciCCG dataset"
            ],
            "base_models": [
                "GPT-2",
                "SciBERT",
                "Galactica"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RAGent Retrieval-based Access Control Policy Generation": {
        "filename": "RAGent Retrieval-based Access Control Policy Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Cleaned document-folds",
                "Synthetic data"
            ],
            "base_models": [
                "BERT",
                "LLaMa 3 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CRITIC Large Language Models Can Self-Correct with Tool-Interactive Critiquing": {
        "filename": "CRITIC Large Language Models Can Self-Correct with Tool-Interactive Critiquing.pdf",
        "analysis": {
            "benchmarks": [
                "AmbigNQ",
                "TriviaQA",
                "HotpotQA",
                "GSM8k",
                "SVAMP",
                "TabMWP",
                "REALTOXICITY PROMPTS"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "Text-Davinci-003",
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "LLaMA-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Diversity-Rewarded CFG Distillation": {
        "filename": "Diversity-Rewarded CFG Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "MusicCaps"
            ],
            "base_models": [
                "MusicLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tokenization counts the impact of tokenization on arithmetic in frontier LLMs": {
        "filename": "Tokenization counts the impact of tokenization on arithmetic in frontier LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "few-shot arithmetic tasks"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LMC Large Model Collaboration with Cross-assessment for Training-Free Open-Set Object Recognition": {
        "filename": "LMC Large Model Collaboration with Cross-assessment for Training-Free Open-Set Object Recognition.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR10",
                "CIFAR+10",
                "CIFAR+50",
                "TinyImageNet"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-turbo)",
                "DALL-E",
                "CLIP (ViT-B/32)",
                "DINO (ViT-B/14)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatVis Automating Scientific Visualization with a Large Language Model": {
        "filename": "ChatVis Automating Scientific Visualization with a Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Marschner-Lobb benchmark dataset",
                "custom point cloud dataset from ParaView sample data"
            ],
            "base_models": [
                "GPT-4 (1.7 trillion parameters)"
            ]
        }
    },
    "Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning": {
        "filename": "Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning.pdf",
        "analysis": {
            "benchmarks": [
                "IWSLT14 DE→EN",
                "WMT14 EN→DE",
                "Gigaword-10K",
                "MMLU",
                "BBH-NLP",
                "TyDiQA"
            ],
            "base_models": [
                "XLM-R-BASE (86M)",
                "XLM-R-LARGE (304M)",
                "XLM-R-XL (2.8B)",
                "XLM-R-XXL (9.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Models for Solving Rare MIP Challenges": {
        "filename": "Leveraging Large Language Models for Solving Rare MIP Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "DiDi operational dataset (November 2016)"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA 3.1 (8B)"
            ]
        }
    },
    "FormulaReasoning A Dataset for Formula-Based Numerical Reasoning": {
        "filename": "FormulaReasoning A Dataset for Formula-Based Numerical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "FormulaReasoning",
                "GSM8K"
            ],
            "base_models": [
                "GPT-4 (unknown size)",
                "GPT-4-turbo (unknown size)",
                "GPT-3.5-turbo (unknown size)",
                "GLM-4-plus (>100B)",
                "GLM-4-flash (unknown size)",
                "Qwen-max (>100B)",
                "Qwen2.5-14B",
                "Qwen2.5-7B",
                "Llama3.1-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Demystifying Faulty Code with LLM Step-by-Step Reasoning for Explainable Fault Localization": {
        "filename": "Demystifying Faulty Code with LLM Step-by-Step Reasoning for Explainable Fault Localization.pdf",
        "analysis": {
            "benchmarks": [
                "Refactory dataset"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Operationalizing the Blueprint for an AI Bill of Rights Recommendations for Practitioners Researchers and Policy Makers": {
        "filename": "Operationalizing the Blueprint for an AI Bill of Rights Recommendations for Practitioners Researchers and Policy Makers.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RSPrompter Learning to Prompt for Remote Sensing Instance Segmentation Based on Visual Foundation Model": {
        "filename": "RSPrompter Learning to Prompt for Remote Sensing Instance Segmentation Based on Visual Foundation Model.pdf",
        "analysis": {
            "benchmarks": [
                "WHU building",
                "NWPU VHR-10",
                "SSDD"
            ],
            "base_models": [
                "SAM (Segment Anything Model)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Constrained-Based Causal Discovery": {
        "filename": "Large Language Models for Constrained-Based Causal Discovery.pdf",
        "analysis": {
            "benchmarks": [
                "cancer",
                "burglary",
                "asia",
                "sachs",
                "spurious",
                "bk-spv",
                "nao-dk-med"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "LLM-Coordination Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models": {
        "filename": "LLM-Coordination Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "LLM-Coordination Benchmark",
                "Hanabi Challenge",
                "Overcooked-AI",
                "Collab Capture",
                "Collab Escape"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-3.5-turbo",
                "Mixtral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models From Notes to Musical Form": {
        "filename": "Large Language Models From Notes to Musical Form.pdf",
        "analysis": {
            "benchmarks": [
                "Pond5"
            ],
            "base_models": [
                "GPT-4",
                "MusicGen"
            ]
        }
    },
    "SleepCoT A Lightweight Personalized Sleep Health Model via Chain-of-Thought Distillation": {
        "filename": "SleepCoT A Lightweight Personalized Sleep Health Model via Chain-of-Thought Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "SleepQA",
                "100 simulated sleep reports",
                "1,000 domain-specific questions"
            ],
            "base_models": [
                "GPT-4o",
                "Qwen-max",
                "Qwen2.5-1.5B"
            ]
        }
    },
    "Metacognitive Prompting Improves Understanding in Large Language Models": {
        "filename": "Metacognitive Prompting Improves Understanding in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SuperGLUE",
                "BLUE",
                "LexGLUE"
            ],
            "base_models": [
                "Llama2",
                "PaLM2",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generate rather than Retrieve Large Language Models are Strong Context Generators": {
        "filename": "Generate rather than Retrieve Large Language Models are Strong Context Generators.pdf",
        "analysis": {
            "benchmarks": [
                "TriviaQA",
                "WebQ",
                "NQ",
                "FEVER",
                "FM2",
                "WoW"
            ],
            "base_models": [
                "InstructGPT (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Surprising Effectiveness of Test-Time Training for Abstract Reasoning": {
        "filename": "The Surprising Effectiveness of Test-Time Training for Abstract Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Abstraction and Reasoning Corpus (ARC)"
            ],
            "base_models": [
                "Llama-3 8B",
                "Llama-3.2 1B",
                "Llama-3.2 3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Military to Healthcare Adopting and Expanding Ethical Principles for Generative Artificial Intelligence": {
        "filename": "From Military to Healthcare Adopting and Expanding Ethical Principles for Generative Artificial Intelligence.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Perturbed examples reveal invariances shared by language models": {
        "filename": "Perturbed examples reveal invariances shared by language models.pdf",
        "analysis": {
            "benchmarks": [
                "Stanford Sentiment Treebank (SST2)",
                "AG-News"
            ],
            "base_models": [
                "BERT-Base",
                "DistilBERT",
                "GPT-2",
                "InstructGPT (text-ada-001, text-babbage-001, text-curie-001, text-davinci-001, text-davinci-002, text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Synthetic continued pretraining": {
        "filename": "Synthetic continued pretraining.pdf",
        "analysis": {
            "benchmarks": [
                "QuALITY"
            ],
            "base_models": [
                "gpt-4-turbo",
                "Llama 3 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Task Arithmetic for Language Expansion in Speech Translation": {
        "filename": "Task Arithmetic for Language Expansion in Speech Translation.pdf",
        "analysis": {
            "benchmarks": [
                "MuST-C",
                "CoVoST-2"
            ],
            "base_models": [
                "SpeechGPT-7B-cm (7B parameters)"
            ]
        }
    },
    "Sparse MoE as the New Dropout Scaling Dense and Self-Slimmable Transformers": {
        "filename": "Sparse MoE as the New Dropout Scaling Dense and Self-Slimmable Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "ASDiv-A",
                "MAWPS",
                "SVAMP",
                "CSQA",
                "SST-2"
            ],
            "base_models": [
                "BERT",
                "Transformer-XL",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NPHardEval Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes": {
        "filename": "NPHardEval Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes.pdf",
        "analysis": {
            "benchmarks": [
                "NPHardEval"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "Claude 2",
                "GPT-3.5 Turbo",
                "Claude Instant",
                "PaLM 2",
                "Yi-34b",
                "Qwen-14b",
                "Mistral-7b",
                "Phi-2",
                "MPT-30b",
                "Vicuna-13b",
                "Phi-1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HippoRAG Neurobiologically Inspired Long-Term Memory for Large Language Models": {
        "filename": "HippoRAG Neurobiologically Inspired Long-Term Memory for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MuSiQue",
                "2WikiMultiHopQA",
                "HotpotQA"
            ],
            "base_models": [
                "GPT-3.5-turbo-1106",
                "Llama-3.1-8B-Instruct",
                "Llama-3.1-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An overview of domain-specific foundation model key technologies applications and challenges": {
        "filename": "An overview of domain-specific foundation model key technologies applications and challenges.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-1",
                "GPT-2",
                "GPT-3",
                "GPT-3.5 turbo",
                "BERT",
                "GLM",
                "LLaMA",
                "LLaMA-2",
                "iGPT",
                "LVM",
                "SAM",
                "BART",
                "T5",
                "Time-LLM",
                "UniTS",
                "ST-LLM",
                "CoDi",
                "CoDi-2",
                "Claude-3",
                "GPT-4",
                "LLaVA",
                "BriVL",
                "ImageBind",
                "NExT-GPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning Performance-Improving Code Edits": {
        "filename": "Learning Performance-Improving Code Edits.pdf",
        "analysis": {
            "benchmarks": [
                "PIE (Performance-Improving Edits) dataset"
            ],
            "base_models": [
                "CODELLAMA 13B",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding In-Context Learning from Repetitions": {
        "filename": "Understanding In-Context Learning from Repetitions.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8K"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-30B",
                "LLaMA-65B",
                "OPT (125M, 350M, 1.3B, 2.7B, 6.7B, 13B, 30B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A social path to human-like artificial intelligence": {
        "filename": "A social path to human-like artificial intelligence.pdf",
        "analysis": {
            "benchmarks": [
                "StarCraft II",
                "Diplomacy"
            ],
            "base_models": [
                "GPT-3",
                "PaLM"
            ]
        }
    },
    "AI-Assisted Causal Pathway Diagram for Human-Centered Design": {
        "filename": "AI-Assisted Causal Pathway Diagram for Human-Centered Design.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Jailbreaking Text-to-Image Models with LLM-Based Agents": {
        "filename": "Jailbreaking Text-to-Image Models with LLM-Based Agents.pdf",
        "analysis": {
            "benchmarks": [
                "NSFW-200",
                "Dog/Cat-100"
            ],
            "base_models": [
                "GPT-4",
                "Vicuna-13B",
                "LLaVA-13B",
                "ShareGPT4V-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Large Language Model Fine-tuning for Solving Math Problems": {
        "filename": "Improving Large Language Model Fine-tuning for Solving Math Problems.pdf",
        "analysis": {
            "benchmarks": [
                "MATH"
            ],
            "base_models": [
                "PaLM 2-S*",
                "PaLM 2-L"
            ]
        }
    },
    "Dont Trust Verify - Grounding LLM Quantitative Reasoning with Autoformalization": {
        "filename": "Dont Trust Verify - Grounding LLM Quantitative Reasoning with Autoformalization.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "MultiArith"
            ],
            "base_models": [
                "Minerva (8B, 62B, 540B)",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PD-Serve Serving Disaggregated Large Language Model at Scale": {
        "filename": "PD-Serve Serving Disaggregated Large Language Model at Scale.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Llama (size not specified)",
                "Pangu (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RTLRewriter Methodologies for Large Models aided RTL Code Optimization": {
        "filename": "RTLRewriter Methodologies for Large Models aided RTL Code Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "Large Rewriter Benchmark",
                "Small Rewriter Benchmark"
            ],
            "base_models": [
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Similarity-based Neighbor Selection for Graph LLMs": {
        "filename": "Similarity-based Neighbor Selection for Graph LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Cora",
                "PubMed",
                "CiteSeer",
                "Ogbn-arxiv",
                "Ogbn-products"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "V Guided Visual Search as a Core Mechanism in Multimodal LLMs": {
        "filename": "V Guided Visual Search as a Core Mechanism in Multimodal LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "V*Bench"
            ],
            "base_models": [
                "LLaVA (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Know Your Needs Better Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs": {
        "filename": "Know Your Needs Better Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "real-world datasets"
            ],
            "base_models": [
                "GPT-3.5",
                "ChatGLM2-6B-32K",
                "Baichuan2-13B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Semantic Mechanical Search with Large Vision and Language Models": {
        "filename": "Semantic Mechanical Search with Large Vision and Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "pharmacy domain",
                "kitchen domain",
                "office domain",
                "open-world environments dataset"
            ],
            "base_models": [
                "CLIP",
                "ViLD",
                "BLIP-2",
                "OpenAI Embedding Model"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Code Prompting a Neural Symbolic Method for Complex Reasoning in Large Language Models": {
        "filename": "Code Prompting a Neural Symbolic Method for Complex Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "last letter concatenation",
                "coin flip",
                "SingleEq",
                "AddSub",
                "MultiArith",
                "SVAMP",
                "GSM8K"
            ],
            "base_models": [
                "gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Language Model Prompting in Support of Semi-autonomous Task Learning": {
        "filename": "Improving Language Model Prompting in Support of Semi-autonomous Task Learning.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (text-davinci-001)"
            ]
        }
    },
    "Do Language Models Enjoy Their Own Stories Prompting Large Language Models for Automatic Story Evaluation": {
        "filename": "Do Language Models Enjoy Their Own Stories Prompting Large Language Models for Automatic Story Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "HANNA dataset"
            ],
            "base_models": [
                "GPT-3",
                "LaMDA",
                "PaLM",
                "LLaMA",
                "Llama-2-7b-chat-hf",
                "Platypus2-70B-instruct",
                "Llama-30b-instruct-2048",
                "StableBeluga-13B",
                "Mistral-7B-OpenOrca",
                "Gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Message Brokers for Generative AI Survey Challenges and Opportunities": {
        "filename": "Towards Message Brokers for Generative AI Survey Challenges and Opportunities.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Evaluation of Estimative Uncertainty in Large Language Models": {
        "filename": "An Evaluation of Estimative Uncertainty in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Fagen-Ulmschneider's survey",
                "Custom dataset involving different scenarios, controls, and WEPs"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "Llama-2-7B",
                "Llama-2-13B",
                "ERNIE-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning in Token Economies Budget-Aware Evaluation of LLM Reasoning Strategies": {
        "filename": "Reasoning in Token Economies Budget-Aware Evaluation of LLM Reasoning Strategies.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "TheoremQA",
                "CSQA",
                "HotpotQA",
                "Game of 24"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Understanding the Working Mechanism of Text-to-Image Diffusion Model": {
        "filename": "Towards Understanding the Working Mechanism of Text-to-Image Diffusion Model.pdf",
        "analysis": {
            "benchmarks": [
                "PromptSet",
                "S-PromptSet"
            ],
            "base_models": [
                "Stable Diffusion v1.5-Base",
                "Stable Diffusion v2.1-Base",
                "Pixart-Alpha"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "KnowPhish Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection": {
        "filename": "KnowPhish Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection.pdf",
        "analysis": {
            "benchmarks": [
                "TR-OP",
                "SG-SCAN"
            ],
            "base_models": [
                "XLM-RoBERTa",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models": {
        "filename": "Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AddSub",
                "MultiArith",
                "SingleEq",
                "AQUA-RAT",
                "SVAMP",
                "GSM8K",
                "CommonsenseQA (CSQA)",
                "StrategyQA (STQA)",
                "Last Letter Concatenation (Letter)",
                "Coin Flip (Coin)"
            ],
            "base_models": [
                "GPT-3.5-turbo (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Multilingual Alignment Prism Aligning Global and Local Preferences to Reduce Harm": {
        "filename": "The Multilingual Alignment Prism Aligning Global and Local Preferences to Reduce Harm.pdf",
        "analysis": {
            "benchmarks": [
                "Multilingual Dolly-200",
                "FLORES-200",
                "Aya Red-teaming dataset"
            ],
            "base_models": [
                "Aya 23 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Synergy-of-Thoughts Eliciting Efficient Reasoning in Hybrid Language Models": {
        "filename": "Synergy-of-Thoughts Eliciting Efficient Reasoning in Hybrid Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Game of 24",
                "Logic Grid Puzzle",
                "GSM8K",
                "Trivia Creative Writing",
                "Open-ended QA",
                "Constrained Generation"
            ],
            "base_models": [
                "GPT-4",
                "Mistral-7B",
                "LLaMA-13B",
                "Yi-34B",
                "GPT-3.5",
                "PaLM2",
                "Gemini1pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs": {
        "filename": "Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ADOS-2"
            ],
            "base_models": [
                "GPT-4-turbo",
                "Gemini1.5-Pro",
                "Claude3",
                "Llama3-8b",
                "Mixtral",
                "Qwen1.5",
                "Glm",
                "Yi-34b",
                "Kimi"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ClassActionPrediction A Challenging Benchmark for Legal Judgment Prediction of Class Action Cases in the US": {
        "filename": "ClassActionPrediction A Challenging Benchmark for Legal Judgment Prediction of Class Action Cases in the US.pdf",
        "analysis": {
            "benchmarks": [
                "US Class Action Cases"
            ],
            "base_models": [
                "Longformer",
                "BigBird",
                "BERT",
                "LegalBERT",
                "CaseLawBERT",
                "LegalRoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An In-Context Learning Agent for Formal Theorem-Proving": {
        "filename": "An In-Context Learning Agent for Formal Theorem-Proving.pdf",
        "analysis": {
            "benchmarks": [
                "miniF2F",
                "CompCert"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-3.5",
                "CodeLlama"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SheetCopilot Bringing Software Productivity to the Next Level through Large Language Models": {
        "filename": "SheetCopilot Bringing Software Productivity to the Next Level through Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 221 spreadsheet control tasks"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "Claude v1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Defining a New NLP Playground": {
        "filename": "Defining a New NLP Playground.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SuperGLUE",
                "MMLU",
                "Super-NaturalInstructions",
                "HELM",
                "AGIEval"
            ],
            "base_models": [
                "GPT variants"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Search Model Redefining Search Stack in the Era of LLMs": {
        "filename": "Large Search Model Redefining Search Stack in the Era of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MS MARCO passage ranking dataset",
                "TREC Deep Learning tracks"
            ],
            "base_models": [
                "LLaMA-7B"
            ]
        }
    },
    "Better to Ask in English Cross-Lingual Evaluation of Large Language Models for Healthcare Queries": {
        "filename": "Better to Ask in English Cross-Lingual Evaluation of Large Language Models for Healthcare Queries.pdf",
        "analysis": {
            "benchmarks": [
                "HealthQA",
                "LiveQA",
                "MedicationQA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Bard",
                "MedAlpaca (fine-tuned on medical documents)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What Makes Large Language Models Reason in Multi-Turn Code Generation": {
        "filename": "What Makes Large Language Models Reason in Multi-Turn Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CodeContests",
                "TACO"
            ],
            "base_models": [
                "Llama 3.0 (8B, 70B)",
                "Llama 3.1 (8B, 70B, 405B)",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training": {
        "filename": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "Game24",
                "PrOntoQA",
                "RLHF Alignment",
                "Chess Endgame"
            ],
            "base_models": [
                "LLaMA2-7B",
                "GPT-2-small (125M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Autoformulation of Mathematical Optimization Models Using LLMs": {
        "filename": "Autoformulation of Mathematical Optimization Models Using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "NL4OPT",
                "IndustryOR"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MOSS Enabling Code-Driven Evolution and Context Management for AI Agents": {
        "filename": "MOSS Enabling Code-Driven Evolution and Context Management for AI Agents.pdf",
        "analysis": {
            "benchmarks": [
                "SWEBench-lite"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks": {
        "filename": "Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA"
            ],
            "base_models": [
                "BERT",
                "T5",
                "GPT-3",
                "Gopher"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "E2LLM Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning": {
        "filename": "E2LLM Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "QMSum",
                "GovReport",
                "Quality",
                "NarrativeQA",
                "TriviaQA"
            ],
            "base_models": [
                "Llama2-7B",
                "GTE-Large-en"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Neuro-Symbolic Procedural Planning with Commonsense Prompting": {
        "filename": "Neuro-Symbolic Procedural Planning with Commonsense Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "WikiHow",
                "RobotHow"
            ],
            "base_models": [
                "GPT-3",
                "GPT-2",
                "BART"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NutriBench A Dataset for Evaluating Large Language Models on Nutrition Estimation from Meal Descriptions": {
        "filename": "NutriBench A Dataset for Evaluating Large Language Models on Nutrition Estimation from Meal Descriptions.pdf",
        "analysis": {
            "benchmarks": [
                "NUTRI BENCH"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o-mini",
                "Llama3.1-8B",
                "Llama3.1-70B",
                "Llama3.1-405B-FP8",
                "Llama3-8B",
                "Llama3-70B",
                "Qwen2-7B",
                "Qwen2-72B",
                "Gemma2-9B",
                "Gemma2-27B",
                "OpenBioLLM-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Training Nonlinear Transformers for Chain-of-Thought Inference A Theoretical Generalization Analysis": {
        "filename": "Training Nonlinear Transformers for Chain-of-Thought Inference A Theoretical Generalization Analysis.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "LLaMA",
                "Sora"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Tyranny of Possibilities in the Design of Task-Oriented LLM Systems A Scoping Survey": {
        "filename": "The Tyranny of Possibilities in the Design of Task-Oriented LLM Systems A Scoping Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "GPT-6"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Circuit Complexity Bounds for RoPE-based Transformer Architecture": {
        "filename": "Circuit Complexity Bounds for RoPE-based Transformer Architecture.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Claude",
                "LLaMA",
                "OpenAI's o1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SQA3D Situated Question Answering in 3D Scenes": {
        "filename": "SQA3D Situated Question Answering in 3D Scenes.pdf",
        "analysis": {
            "benchmarks": [
                "SQA3D"
            ],
            "base_models": [
                "ScanQA",
                "ClipBERT",
                "MCAN",
                "GPT-3",
                "Unified QA (Large variant)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "APOLLO An Optimized Training Approach for Long-form Numerical Reasoning": {
        "filename": "APOLLO An Optimized Training Approach for Long-form Numerical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "FinQA",
                "ConvFinQA"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "GPT-4",
                "RoBERTa-large",
                "DeBERTa-v3-large"
            ]
        }
    },
    "Generative Relevance Feedback with Large Language Models": {
        "filename": "Generative Relevance Feedback with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TREC Robust04",
                "CODEC",
                "TREC Deep Learning 19",
                "TREC Deep Learning 20"
            ],
            "base_models": [
                "GPT-3 (text-davinci-002)"
            ]
        }
    },
    "Can I understand what I create Self-Knowledge Evaluation of Large Language Models": {
        "filename": "Can I understand what I create Self-Knowledge Evaluation of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM-8k",
                "MMLU (college cs task)"
            ],
            "base_models": [
                "GPT-3.5 (gpt-3.5-turbo-1106)",
                "GPT-4 (gpt-4-0125-preview)",
                "Llama3-8B-Instruct",
                "Llama2-7B-Chat",
                "Mistral-7B-Instruct-v0.2",
                "Gemma-1.1-7B-Instruct",
                "Qwen1.5-7B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Solving Math Word Problem with Problem Type Classification": {
        "filename": "Solving Math Word Problem with Problem Type Classification.pdf",
        "analysis": {
            "benchmarks": [
                "NLPCC2023 Shared Task3",
                "Math23K"
            ],
            "base_models": [
                "Bert2Tree",
                "ChatGLM-6B"
            ]
        }
    },
    "ChatQA Surpassing GPT-4 on Conversational QA and RAG": {
        "filename": "ChatQA Surpassing GPT-4 on Conversational QA and RAG.pdf",
        "analysis": {
            "benchmarks": [
                "CHATRAG BENCH",
                "Doc2Dial",
                "QuAC",
                "QReCC",
                "TopiOCQA",
                "INSCIT",
                "CoQA",
                "DoQA",
                "ConvFinQA",
                "SQA",
                "HybriDial"
            ],
            "base_models": [
                "Llama2-70B",
                "Llama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FakeShield Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models": {
        "filename": "FakeShield Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CASIA1+",
                "IMD2020",
                "Columbia",
                "Coverage",
                "DSO",
                "Korus",
                "FFHQ",
                "FaceApp",
                "AIGC-Editing"
            ],
            "base_models": [
                "GPT-4o",
                "LLaVA-v1.5-13B",
                "InternVL2-26B",
                "Qwen2-VL-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Empowering Segmentation Ability to Multi-modal Large Language Models": {
        "filename": "Empowering Segmentation Ability to Multi-modal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ReasonSeg",
                "RefCOCO",
                "RefCOCO+",
                "RefCOCOg",
                "Refclef",
                "ADE20k",
                "COCO-Stuff",
                "PACO-LVIS",
                "PASCAL-Part"
            ],
            "base_models": [
                "LLaVA (based on LLaMA)",
                "LLaMA-2"
            ]
        }
    },
    "Robustness of Demonstration-based Learning Under Limited Data Scenario": {
        "filename": "Robustness of Demonstration-based Learning Under Limited Data Scenario.pdf",
        "analysis": {
            "benchmarks": [
                "CoNLL03",
                "OntoNotes 5.0",
                "CoNLL00"
            ],
            "base_models": [
                "BERT-base-cased",
                "Roberta-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoHint Automatic Prompt Optimization with Hint Generation": {
        "filename": "AutoHint Automatic Prompt Optimization with Hint Generation.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench Instruction Induction (BBII)"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "OWL A Large Language Model for IT Operations": {
        "filename": "OWL A Large Language Model for IT Operations.pdf",
        "analysis": {
            "benchmarks": [
                "Owl-Bench",
                "open IT-related benchmarks"
            ],
            "base_models": [
                "LLaMA2-13b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LGR2 Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning": {
        "filename": "LGR2 Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "maze navigation",
                "pick and place",
                "bin",
                "franka kitchen"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FVEval Understanding Language Model Capabilities in Formal Verification of Digital Hardware": {
        "filename": "FVEval Understanding Language Model Capabilities in Formal Verification of Digital Hardware.pdf",
        "analysis": {
            "benchmarks": [
                "NL2SVA-Human",
                "NL2SVA-Machine",
                "Design2SVA"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini-1.5-pro",
                "Gemini-1.5-flash",
                "Mixtral-8x22b",
                "Llama-3.1-70b",
                "Llama-3-70b",
                "Llama-3.1-8b",
                "Llama-3-8b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From PDFs to Structured Data Utilizing LLM Analysis in Sports Database Management": {
        "filename": "From PDFs to Structured Data Utilizing LLM Analysis in Sports Database Management.pdf",
        "analysis": {
            "benchmarks": [
                "Finnish Sports Clubs Database"
            ],
            "base_models": [
                "GPT-4",
                "Claude 3 Opus"
            ]
        }
    },
    "Revisiting Prompt Engineering via Declarative Crowdsourcing": {
        "filename": "Revisiting Prompt Engineering via Declarative Crowdsourcing.pdf",
        "analysis": {
            "benchmarks": [
                "DBLP-Google Scholar dataset",
                "Restaurants and Buy datasets"
            ],
            "base_models": [
                "GPT-4",
                "Claude",
                "gpt-3.5-turbo",
                "text-embedding-ada-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Systematic Evaluation of Large Language Models for Natural": {
        "filename": "A Systematic Evaluation of Large Language Models for Natural.pdf",
        "analysis": {
            "benchmarks": [
                "DailyDialog",
                "PersonaChat",
                "EmpatheticDialogue",
                "LCCC",
                "CNN/DailyMail",
                "XSum",
                "THUCNews",
                "LCSTS"
            ],
            "base_models": [
                "ChatGPT (175B)",
                "ChatGLM (6.2B)",
                "Flan-T5-XXL (13B)",
                "FastChat-T5 (3B)",
                "Open-LLaMA (7B)",
                "Vicuna (13B)",
                "Alpaca-Lora (7B)",
                "Chinese-Alpaca (13B)",
                "GPT4ALL (13B)",
                "Dolly (12B)",
                "Oasst-Pythia (12B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Toward Self-Improvement of LLMs via Imagination Searching and Criticizing": {
        "filename": "Toward Self-Improvement of LLMs via Imagination Searching and Criticizing.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "Llama-2-70b",
                "WizardMath-70B-V1.0"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning": {
        "filename": "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "TABMWP"
            ],
            "base_models": [
                "GPT-3",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rethinking Large Language Models in Mental Health Applications": {
        "filename": "Rethinking Large Language Models in Mental Health Applications.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT (110 million parameters)",
                "GPT-2 (1.5 billion parameters)",
                "GPT-3",
                "LLaMA",
                "BLOOM"
            ]
        }
    },
    "Chain of Thoughtlessness An Analysis of CoT in Planning": {
        "filename": "Chain of Thoughtlessness An Analysis of CoT in Planning.pdf",
        "analysis": {
            "benchmarks": [
                "Blocksworld",
                "Coin Flip",
                "Last Letter Concatenation",
                "multi-step arithmetic"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3-Opus",
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models Learn Independent Causal Mechanisms": {
        "filename": "Can Large Language Models Learn Independent Causal Mechanisms.pdf",
        "analysis": {
            "benchmarks": [
                "ACRE",
                "RAVEN"
            ],
            "base_models": [
                "LLaMA2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning": {
        "filename": "Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "Social Chemistry 101",
                "Toxicity"
            ],
            "base_models": [
                "PaLM-62B"
            ]
        }
    },
    "Mental-LLM": {
        "filename": "Mental-LLM.pdf",
        "analysis": {
            "benchmarks": [
                "Dreaddit",
                "DepSeverity",
                "SDCNL",
                "CSSRS-Suicide",
                "Red-Sam",
                "Twt-60Users",
                "SAD"
            ],
            "base_models": [
                "Alpaca (7B)",
                "Alpaca-LoRA (7B)",
                "FLAN-T5 (11B)",
                "LLaMA2 (70B)",
                "GPT-3.5 (175B)",
                "GPT-4 (1700B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Avalons Game of Thoughts Battle Against Deception through Recursive Contemplation": {
        "filename": "Avalons Game of Thoughts Battle Against Deception through Recursive Contemplation.pdf",
        "analysis": {
            "benchmarks": [
                "Avalon game"
            ],
            "base_models": [
                "ChatGPT",
                "Claude",
                "LLaMA-2-70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automating Human Tutor-Style Programming Feedback Leveraging GPT-4 Tutor Model for Hint Generation and GPT-35 Student Model for Hint Validation": {
        "filename": "Automating Human Tutor-Style Programming Feedback Leveraging GPT-4 Tutor Model for Hint Generation and GPT-35 Student Model for Hint Validation.pdf",
        "analysis": {
            "benchmarks": [
                "BasicAlgo",
                "DataRegex",
                "DataAnalysis"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Mamba Always Enjoy the Free Lunch": {
        "filename": "Can Mamba Always Enjoy the Free Lunch.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Transformers",
                "Mamba"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Transferring Procedural Knowledge across Commonsense Tasks": {
        "filename": "Transferring Procedural Knowledge across Commonsense Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "TRIP",
                "ROCStories",
                "PhysicalIQA",
                "aNLI",
                "CODAH"
            ],
            "base_models": [
                "RoBERTa-Large",
                "Codex"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathOdyssey Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data": {
        "filename": "MathOdyssey Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data.pdf",
        "analysis": {
            "benchmarks": [
                "MathOdyssey",
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "Llama-3",
                "DBRX-Instruct",
                "GPT-4",
                "GPT-3.5 Turbo",
                "Claude 3",
                "Gemini models"
            ]
        }
    },
    "Transformers and Large Language Models for Chemistry and Drug Discovery": {
        "filename": "Transformers and Large Language Models for Chemistry and Drug Discovery.pdf",
        "analysis": {
            "benchmarks": [
                "Open Reaction Database",
                "Therapeutics Data Commons"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PromptCARE Prompt Copyright Protection by Watermark Injection and Verification": {
        "filename": "PromptCARE Prompt Copyright Protection by Watermark Injection and Verification.pdf",
        "analysis": {
            "benchmarks": [
                "SST2",
                "IMDb",
                "AG_News",
                "QQP",
                "QNLI",
                "MNLI"
            ],
            "base_models": [
                "BERT (large-cased)",
                "RoBERTa (large)",
                "facebook OPT-1.3b",
                "LLaMA-3b",
                "LLaMA-7b",
                "LLaMA-13b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Is Not All You Need Aligning Perception with Language Models": {
        "filename": "Language Is Not All You Need Aligning Perception with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "StoryCloze",
                "HellaSwag",
                "Winograd",
                "Winogrande",
                "PIQA",
                "BoolQ",
                "CB",
                "COPA",
                "Rendered SST-2",
                "HatefulMemes",
                "RelativeSize",
                "MemoryColor",
                "ColorTerms",
                "Raven's Progressive Matrices",
                "COCO Caption",
                "Flickr30k",
                "VQAv2",
                "VizWiz",
                "WebSRC",
                "ImageNet",
                "CUB"
            ],
            "base_models": [
                "KOSMOS-1 (1.6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer": {
        "filename": "Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer.pdf",
        "analysis": {
            "benchmarks": [
                "tiny Shakespeare"
            ],
            "base_models": [
                "minGPT (3.6 million parameters)"
            ]
        }
    },
    "InstructNav Zero-shot System for Generic Instruction Navigation in Unexplored Environment": {
        "filename": "InstructNav Zero-shot System for Generic Instruction Navigation in Unexplored Environment.pdf",
        "analysis": {
            "benchmarks": [
                "R2R-CE",
                "Habitat ObjNav",
                "DDN"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4V"
            ]
        }
    },
    "Lost-in-Distance Impact of Contextual Proximity on LLM Performance in Graph Tasks": {
        "filename": "Lost-in-Distance Impact of Contextual Proximity on LLM Performance in Graph Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Erdős–Rényi (ER) graph generator"
            ],
            "base_models": [
                "Llama-3-8B",
                "Llama-3-70B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ECR-Chain Advancing Generative Language Models to Better Emotion-Cause Reasoners through Reasoning Chains": {
        "filename": "ECR-Chain Advancing Generative Language Models to Better Emotion-Cause Reasoners through Reasoning Chains.pdf",
        "analysis": {
            "benchmarks": [
                "RECCON"
            ],
            "base_models": [
                "ChatGPT",
                "Vicuna-7B (based on LLaMA)"
            ]
        }
    },
    "Finding Visual Task Vectors": {
        "filename": "Finding Visual Task Vectors.pdf",
        "analysis": {
            "benchmarks": [
                "Pascal-5i",
                "Computer Vision Figures",
                "ImageNet"
            ],
            "base_models": [
                "MAE-VQGAN",
                "Llama2 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Demonstration Notebook Finding the Most Suited In-Context Learning Example from Interactions": {
        "filename": "Demonstration Notebook Finding the Most Suited In-Context Learning Example from Interactions.pdf",
        "analysis": {
            "benchmarks": [
                "SingleEq",
                "MultiArith",
                "GSM8k",
                "SVAMP",
                "AQuA",
                "CSQA",
                "STQA",
                "Last Letter Concatenation",
                "Coin Flip",
                "Samsung Abstractive Messenger Summarization"
            ],
            "base_models": [
                "Llama3-8B",
                "GPT-3.5-turbo (175B)"
            ]
        }
    },
    "SayPlan Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning": {
        "filename": "SayPlan Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "large office floor environment with 37 rooms and 151 assets and objects",
                "three-storey house environment with 28 rooms and 112 objects"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Supporting Human Raters with the Detection of Harmful Content using Large Language Models": {
        "filename": "Supporting Human Raters with the Detection of Harmful Content using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 50,000 comments (40,000 violative and 10,000 non-violative)"
            ],
            "base_models": [
                "PaLM 2 text-bison",
                "PaLM 2 text-unicorn"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do LLMs Really Adapt to Domains An Ontology Learning Perspective": {
        "filename": "Do LLMs Really Adapt to Domains An Ontology Learning Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "WN-sweets",
                "WN-football",
                "WN-music"
            ],
            "base_models": [
                "GPT-3.5 (174B)",
                "GPT-4 (≥1T)",
                "Falcon-40B (40B)",
                "LLaMa2-13B (13B)",
                "Zephyr-7B-β (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Information Re-Organization Improves Reasoning in Large Language Models": {
        "filename": "Information Re-Organization Improves Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HOVER",
                "FEVEROUS",
                "SCIFACT",
                "2WikiMultiHopQA",
                "StrategyQA",
                "MuSiQue",
                "HotpotQA",
                "WIKIHOP"
            ],
            "base_models": [
                "Llama2-70B",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Does Self-Rationalization Improve Robustness to Spurious Correlations": {
        "filename": "Does Self-Rationalization Improve Robustness to Spurious Correlations.pdf",
        "analysis": {
            "benchmarks": [
                "HANS",
                "CAD",
                "TEST-HARD",
                "TEST-EASY",
                "TEST-HYP"
            ],
            "base_models": [
                "T5-base (220M)",
                "T5-large (770M)",
                "BART-base (140M)",
                "BART-large (400M)",
                "GPT2-medium (345M)",
                "GPT2-large (774M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "QACHECK A Demonstration System for Question-Guided Multi-Hop Fact-Checking": {
        "filename": "QACHECK A Demonstration System for Question-Guided Multi-Hop Fact-Checking.pdf",
        "analysis": {
            "benchmarks": [
                "HOVER",
                "FEVEROUS"
            ],
            "base_models": [
                "InstructGPT",
                "GPT-4",
                "FLAN-T5",
                "RoBERTa-large"
            ]
        }
    },
    "Failure Modes of LLMs for Causal Reasoning on Narratives": {
        "filename": "Failure Modes of LLMs for Causal Reasoning on Narratives.pdf",
        "analysis": {
            "benchmarks": [
                "CauseNet"
            ],
            "base_models": [
                "GPT-4o",
                "Claude 3.5 Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unleashing the Creative Mind Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving": {
        "filename": "Unleashing the Creative Mind Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving.pdf",
        "analysis": {
            "benchmarks": [
                "MATH"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs as Workers in Human-Computational Algorithms Replicating Crowdsourcing Pipelines with LLMs": {
        "filename": "LLMs as Workers in Human-Computational Algorithms Replicating Crowdsourcing Pipelines with LLMs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FacTool Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios": {
        "filename": "FacTool Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios.pdf",
        "analysis": {
            "benchmarks": [
                "FEVER-based",
                "FactCC",
                "QAGS-based",
                "WICE-based",
                "RARR",
                "FACTOOL"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When do Generative Query and Document Expansions Fail A Comprehensive Study Across Methods Retrievers and Datasets": {
        "filename": "When do Generative Query and Document Expansions Fail A Comprehensive Study Across Methods Retrievers and Datasets.pdf",
        "analysis": {
            "benchmarks": [
                "TREC DL 2019",
                "FiQA",
                "ArguAna",
                "GooAQ Technical",
                "NFCorpus",
                "Touché-2020",
                "SciFact Refute",
                "Tip of My Tongue",
                "TREC Clinical Trials 2021",
                "WikiQA",
                "Quora"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4-0613",
                "Claude V2",
                "Llama2 70b Chat",
                "DPR",
                "Contriever",
                "BM25",
                "E5 Base v2",
                "MPNet Base v2",
                "GTE Large",
                "MonoT5-Small",
                "MonoT5-Base",
                "MonoT5-3B",
                "ColBERTv2",
                "MiniLM-2-v2",
                "MiniLM-4-v2",
                "MiniLM-12-v2",
                "MonoT5-Large",
                "LLAMA",
                "LLAMAv2",
                "LLAMAv2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MALADE Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance": {
        "filename": "MALADE Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance.pdf",
        "analysis": {
            "benchmarks": [
                "OMOP Ground Truth table of ADEs"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Predicting Learning Performance with Large Language Models A Study in Adult Literacy": {
        "filename": "Predicting Learning Performance with Large Language Models A Study in Adult Literacy.pdf",
        "analysis": {
            "benchmarks": [
                "AutoTutor reading comprehension datasets"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The debate over understanding in AIs large language models": {
        "filename": "The debate over understanding in AIs large language models.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SuperGLUE",
                "Argument Reasoning Comprehension Task"
            ],
            "base_models": [
                "GPT-3 (175 billion parameters)",
                "PaLM (540 billion parameters)",
                "BERT"
            ]
        }
    },
    "EX-FEVER A Dataset for Multi-hop Explainable Fact Verification": {
        "filename": "EX-FEVER A Dataset for Multi-hop Explainable Fact Verification.pdf",
        "analysis": {
            "benchmarks": [
                "EX-FEVER"
            ],
            "base_models": [
                "BERT",
                "RoBERTa-base",
                "BART"
            ]
        }
    },
    "Language-Guided Music Recommendation for Video via Prompt Analogies": {
        "filename": "Language-Guided Music Recommendation for Video via Prompt Analogies.pdf",
        "analysis": {
            "benchmarks": [
                "YT8M-MusicVideo",
                "YT8M-MusicTextClips"
            ],
            "base_models": [
                "BLOOM-176B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GeneGPT Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information": {
        "filename": "GeneGPT Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information.pdf",
        "analysis": {
            "benchmarks": [
                "GeneTuring",
                "GeneHop"
            ],
            "base_models": [
                "Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generating Sequences by Learning to Self-Correct": {
        "filename": "Generating Sequences by Learning to Self-Correct.pdf",
        "analysis": {
            "benchmarks": [
                "Multiarith",
                "Multitask",
                "GSM8k",
                "COMMON GEN",
                "E2E",
                "REALTOXICITY PROMPTS"
            ],
            "base_models": [
                "GPT-Neo 1.3B",
                "GPT-3 (davinci, text-davinci-002)",
                "GPT-2 (Large, Medium)",
                "GPT-2 XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Almanac Retrieval-Augmented Language Models for Clinical Medicine": {
        "filename": "Almanac Retrieval-Augmented Language Models for Clinical Medicine.pdf",
        "analysis": {
            "benchmarks": [
                "ClinicalQA"
            ],
            "base_models": [
                "BioGPT",
                "SciBERT",
                "GatorTron",
                "Med-PaLM",
                "text-davinci-003",
                "text-embedding-ada-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Human Participants in AI Research Ethics and Transparency in Practice": {
        "filename": "Human Participants in AI Research Ethics and Transparency in Practice.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do Efficient Transformers Really Save Computation": {
        "filename": "Do Efficient Transformers Really Save Computation.pdf",
        "analysis": {
            "benchmarks": [
                "Arithmetic task",
                "Longest Increasing Subsequence (LIS)",
                "Edit Distance (ED)"
            ],
            "base_models": [
                "Sparse Transformer",
                "Linear Transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Can Automatically Engineer Features for Few-Shot Tabular Learning": {
        "filename": "Large Language Models Can Automatically Engineer Features for Few-Shot Tabular Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Adult",
                "Bank",
                "Blood",
                "Car",
                "Communities",
                "Credit-g",
                "Diabetes",
                "Heart",
                "Myocardial",
                "Cultivars",
                "NHANES",
                "Sequence-type",
                "Solution-mix"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ComperDial Commonsense Persona-grounded Dialogue Dataset and Benchmark": {
        "filename": "ComperDial Commonsense Persona-grounded Dialogue Dataset and Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "ComperDial"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Sparks of Large Audio Models A Survey and Outlook": {
        "filename": "Sparks of Large Audio Models A Survey and Outlook.pdf",
        "analysis": {
            "benchmarks": [
                "LibriSpeech",
                "CommonVoice 11",
                "VoxPopuli ASR",
                "CVSS",
                "YouTube ASR"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM (540B)",
                "GPT-4",
                "LLaMA-7B",
                "HuBERT",
                "AudioLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating and Inducing Personality in Pre-trained Language Models": {
        "filename": "Evaluating and Inducing Personality in Pre-trained Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Machine Personality Inventory (MPI)"
            ],
            "base_models": [
                "BART",
                "GPT-Neo 2.7B",
                "GPT-NeoX 20B",
                "T0++ 11B",
                "Alpaca 7B",
                "GPT-3.5 175B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Stay on topic with Classifier-Free Guidance": {
        "filename": "Stay on topic with Classifier-Free Guidance.pdf",
        "analysis": {
            "benchmarks": [
                "LAMBADA",
                "HumanEval"
            ],
            "base_models": [
                "Pythia",
                "GPT-2",
                "LLaMA-7B",
                "PaLM-540B",
                "GPT4All",
                "Falcon-7b-Base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AGILE A Novel Reinforcement Learning Framework of LLM Agents": {
        "filename": "AGILE A Novel Reinforcement Learning Framework of LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "ProductQA",
                "MedMCQA",
                "HotPotQA"
            ],
            "base_models": [
                "Vicuna-13b",
                "Meerkat-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Make LLMs better zero-shot reasoners Structure-orientated autonomous reasoning": {
        "filename": "Make LLMs better zero-shot reasoners Structure-orientated autonomous reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "HotPotQA",
                "Fever"
            ],
            "base_models": [
                "GPT-4",
                "Qwen-max",
                "Llama3-70B",
                "Qwen2-57B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Empirical Investigation of Neural Symbolic Reasoning Strategies": {
        "filename": "Empirical Investigation of Neural Symbolic Reasoning Strategies.pdf",
        "analysis": {
            "benchmarks": [
                "custom symbolic numerical reasoning dataset"
            ],
            "base_models": [
                "T5-base",
                "T5-large",
                "BART-base"
            ]
        }
    },
    "Physics of Language Models Part 32 Knowledge Manipulation": {
        "filename": "Physics of Language Models Part 32 Knowledge Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "bioS multi5+permute",
                "bioS multi5+fullname"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Working Memory Capacity of ChatGPT An Empirical Study": {
        "filename": "Working Memory Capacity of ChatGPT An Empirical Study.pdf",
        "analysis": {
            "benchmarks": [
                "verbal n-back task",
                "spatial n-back task"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-4",
                "Bloomz-7B",
                "Bloomz-7B1-mt",
                "ChatGLM-6B v1.0",
                "ChatGLM-6B v1.1",
                "Vicuna-7B",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An appraisal-based chain-of-emotion architecture for affective language model game agents": {
        "filename": "An appraisal-based chain-of-emotion architecture for affective language model game agents.pdf",
        "analysis": {
            "benchmarks": [
                "Situational Test of Emotional Understanding (STEU)"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Egocentric Vision Language Planning": {
        "filename": "Egocentric Vision Language Planning.pdf",
        "analysis": {
            "benchmarks": [
                "VirtualHome",
                "Habitat2.0"
            ],
            "base_models": [
                "GPT-4V",
                "InstructP2P (fine-tuned)"
            ]
        }
    },
    "Preconditioned Visual Language Inference with Weak Supervision": {
        "filename": "Preconditioned Visual Language Inference with Weak Supervision.pdf",
        "analysis": {
            "benchmarks": [
                "PVLIR human-verified test set"
            ],
            "base_models": [
                "FLAVA",
                "VisualBERT",
                "ViLBERT",
                "ViLT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OpenBA An Open-sourced 15B Bilingual Asymmetric seq2seq Model Pre-trained from Scratch": {
        "filename": "OpenBA An Open-sourced 15B Bilingual Asymmetric seq2seq Model Pre-trained from Scratch.pdf",
        "analysis": {
            "benchmarks": [
                "BELEBELE",
                "MMLU",
                "C-Eval",
                "SuperGLUE",
                "CMMLU",
                "BBH"
            ],
            "base_models": [
                "OpenBA-15B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model-Based Evolutionary Optimizer Reasoning with elitism": {
        "filename": "Large Language Model-Based Evolutionary Optimizer Reasoning with elitism.pdf",
        "analysis": {
            "benchmarks": [
                "Rosenbrock function",
                "Goldstein-Price function",
                "ZDT1",
                "ZDT3"
            ],
            "base_models": [
                "GPT-3.5 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Stop Uploading Test Data in Plain Text Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks": {
        "filename": "Stop Uploading Test Data in Plain Text Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench"
            ],
            "base_models": [
                "GPT series",
                "PaLM"
            ]
        }
    },
    "Post Hoc Explanations of Language Models Can Improve Language Models": {
        "filename": "Post Hoc Explanations of Language Models Can Improve Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Snarks",
                "Causal Judgment",
                "Ruin Names",
                "Formal Fallacies",
                "Salient Translation Error Detection",
                "CommonsenseQA",
                "Coin Flip"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-3.5",
                "GPT-2 (125M)",
                "BERT (110M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dynamic Open-Vocabulary 3D Scene Graphs for Long-term Language-Guided Mobile Manipulation": {
        "filename": "Dynamic Open-Vocabulary 3D Scene Graphs for Long-term Language-Guided Mobile Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "custom real-world indoor environments"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "On the Planning Abilities of Large Language Models A Critical Investigation with a Proposed Benchmark": {
        "filename": "On the Planning Abilities of Large Language Models A Critical Investigation with a Proposed Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "International Planning Competition domains",
                "Blocksworld"
            ],
            "base_models": [
                "GPT-3 (Davinci)",
                "Instruct-GPT3 (text-davinci-002)",
                "BLOOM (176B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AstroMLab 2 AstroLLaMA-2-70B Model and Benchmarking Specialised LLMs for Astronomy": {
        "filename": "AstroMLab 2 AstroLLaMA-2-70B Model and Benchmarking Specialised LLMs for Astronomy.pdf",
        "analysis": {
            "benchmarks": [
                "Annual Review of Astronomy and Astrophysics MCQ dataset"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "LLaMA-2-70B",
                "LLaMA-3-8B"
            ]
        }
    },
    "Holy Grail 20 From Natural Language to Constraint Models": {
        "filename": "Holy Grail 20 From Natural Language to Constraint Models.pdf",
        "analysis": {
            "benchmarks": [
                "NL4Opt competition dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "BART",
                "LLaMA"
            ]
        }
    },
    "Beyond Accuracy Investigating Error Types in GPT-4 Responses to USMLE Questions": {
        "filename": "Beyond Accuracy Investigating Error Types in GPT-4 Responses to USMLE Questions.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA-USMLE"
            ],
            "base_models": [
                "GPT-4",
                "Med-PaLM 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies": {
        "filename": "Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic single-line system",
                "real-world multi-line system"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Navigating Prompt Complexity for Zero-Shot Classification A Study of Large Language Models in Computational Social Science": {
        "filename": "Navigating Prompt Complexity for Zero-Shot Classification A Study of Large Language Models in Computational Social Science.pdf",
        "analysis": {
            "benchmarks": [
                "Complaint",
                "Vaccine Stance",
                "Bragging",
                "Rumour Stance",
                "Sarcasm",
                "Hate Speech"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "OpenAssistant-LLaMA (30B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Good Questions Help Zero-Shot Image Reasoning": {
        "filename": "Good Questions Help Zero-Shot Image Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "SNLI-VE",
                "Flowers102",
                "Oxford-IIIT Pet",
                "FGVCAircraft"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "InstructBLIP",
                "MiniGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LAMM Language-Assisted Multi-Modal Instruction-Tuning Dataset Framework and Benchmark": {
        "filename": "LAMM Language-Assisted Multi-Modal Instruction-Tuning Dataset Framework and Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR10",
                "VOC2012",
                "SQAimage",
                "AI2D",
                "flickr30k",
                "UCMerced",
                "FSC147",
                "SVT",
                "CelebA",
                "LSP",
                "ScanNet",
                "ScanRefer",
                "ScanQA"
            ],
            "base_models": [
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Matching Patients to Clinical Trials with Large Language Models": {
        "filename": "Matching Patients to Clinical Trials with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SIGIR 2016 cohort",
                "TREC 2021 CT cohort",
                "TREC 2022 CT cohort"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-contradictory Hallucinations of Large Language Models Evaluation Detection and Mitigation": {
        "filename": "Self-contradictory Hallucinations of Large Language Models Evaluation Detection and Mitigation.pdf",
        "analysis": {
            "benchmarks": [
                "PopQA"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT (gpt-3.5-turbo-0301)",
                "Llama2-70B-Chat",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations": {
        "filename": "Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations.pdf",
        "analysis": {
            "benchmarks": [
                "Japanese Medical Licensing Examinations (2018-2023)",
                "IGAKU QA"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)",
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChartAssisstant A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning": {
        "filename": "ChartAssisstant A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "ChartQA",
                "PlotQA",
                "OpenCQA",
                "ScigraphQA",
                "Vistext",
                "Chart-to-text",
                "ChartSumm",
                "RealCQA",
                "StructChart",
                "ChartLLM"
            ],
            "base_models": [
                "Donut (260M)",
                "SPHINX (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain of Agents Large Language Models Collaborating on Long-Context Tasks": {
        "filename": "Chain of Agents Large Language Models Collaborating on Long-Context Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "MuSiQue",
                "NarrativeQA",
                "Qasper",
                "QuALITY",
                "QMSum",
                "GovReport",
                "BookSum",
                "RepoBench-P"
            ],
            "base_models": [
                "PaLM 2",
                "Gemini 1.0",
                "Claude 3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Scaling Diffusion Language Models via Adaptation from Autoregressive Models": {
        "filename": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models.pdf",
        "analysis": {
            "benchmarks": [
                "TriviaQA",
                "Lambada",
                "HellaSwag",
                "Winogrande",
                "SIQA",
                "PIQA",
                "GSM8K",
                "ROCStories",
                "Humaneval",
                "MAWPS",
                "SATMath"
            ],
            "base_models": [
                "GPT2 (127M, 355M)",
                "LLaMA2 (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PDE Generalization of In-Context Operator Networks A Study on 1D Scalar Nonlinear Conservation Laws": {
        "filename": "PDE Generalization of In-Context Operator Networks A Study on 1D Scalar Nonlinear Conservation Laws.pdf",
        "analysis": {
            "benchmarks": [
                "1D scalar nonlinear conservation laws dataset"
            ],
            "base_models": [
                "ICON-LM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Efficient Prompting Methods for Large Language Models A Survey": {
        "filename": "Efficient Prompting Methods for Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Offline Training of Language Model Agents with Functions as Learnable Weights": {
        "filename": "Offline Training of Language Model Agents with Functions as Learnable Weights.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "TabMWP",
                "GAIA"
            ],
            "base_models": [
                "GPT-4+",
                "ReAct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval-Augmented Generation for Large Language Models A Survey": {
        "filename": "Retrieval-Augmented Generation for Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions (NQ)",
                "HotpotQA"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Memory GAPS Would LLMs pass the Tulving Test": {
        "filename": "Memory GAPS Would LLMs pass the Tulving Test.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "mistral-7b-instruct-v0"
            ]
        }
    },
    "Self-Supervised Open-Ended Classification with Small Visual Language Models": {
        "filename": "Self-Supervised Open-Ended Classification with Small Visual Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Real-Names miniImageNet",
                "Open-Ended miniImageNet",
                "Oxford-Pets",
                "Flowers102",
                "Food101",
                "CUBS-200",
                "SUN397"
            ],
            "base_models": [
                "GPT-Neo (1.3B parameters)",
                "GPT2-small (124M parameters)",
                "GPT2-medium (355M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "KS-LLM Knowledge Selection of Large Language Models with Evidence Document for Question Answering": {
        "filename": "KS-LLM Knowledge Selection of Large Language Models with Evidence Document for Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "TriviaQA-verified",
                "WebQ",
                "NQ"
            ],
            "base_models": [
                "Vicuna-13B",
                "Llama 2-13B",
                "Llama 2-7B"
            ]
        }
    },
    "Enhancing Robustness in Large Language Models Prompting for Mitigating the Impact of Irrelevant Information": {
        "filename": "Enhancing Robustness in Large Language Models Prompting for Mitigating the Impact of Irrelevant Information.pdf",
        "analysis": {
            "benchmarks": [
                "GSMIR"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-3.5-Turbo-16k"
            ]
        }
    },
    "Can only LLMs do Reasoning Potential of Small Language Models in Task Planning": {
        "filename": "Can only LLMs do Reasoning Potential of Small Language Models in Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "COST (COmmand-STeps dataset) for tabletop and kitchen environments"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "GPT-2-medium",
                "GPT-2-base"
            ]
        }
    },
    "A Survey of Large Language Models in Finance FinLLMs": {
        "filename": "A Survey of Large Language Models in Finance FinLLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Financial PhraseBank (FPB)",
                "FiQA SA",
                "SemEval-2017 (Task 5)",
                "StockEmotions",
                "Headline",
                "FedNLP",
                "FOMC",
                "Banking77",
                "FIN",
                "FiNER-139",
                "FiQA-QA",
                "FinQA",
                "ConvFinQA",
                "StockNet",
                "CIKM18",
                "BigData22",
                "ECTSum",
                "MultiLing 2019",
                "FinRED",
                "Event-Driven Trading (EDT)",
                "FinCausal20",
                "FinTabNet",
                "MAEC",
                "MONOPOLY",
                "MINDS-14",
                "MultiFin"
            ],
            "base_models": [
                "GPT-1 (110M)",
                "GPT-2 (1.5B)",
                "GPT-3 (175B)",
                "GPT-4 (estimated 1.7T)",
                "BERT (base-110M)",
                "LLaMA (7B, 13B, 33B, 65B)",
                "BLOOM (176B)",
                "ELECTRA",
                "FinBERT (based on BERT)",
                "FLANG (based on ELECTRA)",
                "BloombergGPT (based on BLOOM)",
                "FinMA (based on LLaMA)",
                "InvestLM (based on LLaMA)",
                "FinGPT (based on open-source LLMs)"
            ]
        }
    },
    "How Good Are GPT Models at Machine Translation A Comprehensive Evaluation": {
        "filename": "How Good Are GPT Models at Machine Translation A Comprehensive Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "WMT22",
                "WMT21"
            ],
            "base_models": [
                "ChatGPT",
                "GPT3.5 (text-davinci-003)",
                "text-davinci-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Language-driven Scientific AI": {
        "filename": "Towards Language-driven Scientific AI.pdf",
        "analysis": {
            "benchmarks": [
                "SciFact"
            ],
            "base_models": [
                "GPT-3",
                "T5",
                "SciBERT",
                "BioBERT",
                "SpaceRoBERTa"
            ]
        }
    },
    "A Principled Framework for Knowledge-enhanced Large Language Model": {
        "filename": "A Principled Framework for Knowledge-enhanced Large Language Model.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "CAVM Conditional Autoregressive Vision Model for Contrast-Enhanced Brain Tumor MRI Synthesis": {
        "filename": "CAVM Conditional Autoregressive Vision Model for Contrast-Enhanced Brain Tumor MRI Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "BraSyn-2023"
            ],
            "base_models": [
                "LLaMA-style Transformer"
            ]
        }
    },
    "Large Language Models A Survey": {
        "filename": "Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "Wikipedia QA",
                "XNLI"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-70B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PaLM 2 Technical Report": {
        "filename": "PaLM 2 Technical Report.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench",
                "SQuAD v2",
                "TyDi QA",
                "MATH",
                "GSM8K",
                "MGSM",
                "HumanEval",
                "MBPP",
                "ARCADE"
            ],
            "base_models": [
                "PaLM 2-S",
                "PaLM 2-M",
                "PaLM 2-L",
                "PaLM 2-S*"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Event Causality Identification with Rationale and Structure-Aware Causal Question Answering": {
        "filename": "Enhancing Event Causality Identification with Rationale and Structure-Aware Causal Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "EventStoryLine",
                "Causal-TimeBank"
            ],
            "base_models": [
                "Baichuan2-7B-Chat"
            ]
        }
    },
    "ThinkBot Embodied Instruction Following with Thought Chain Reasoning": {
        "filename": "ThinkBot Embodied Instruction Following with Thought Chain Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ALFRED"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "Complex Logical Reasoning over Knowledge Graphs using Large Language Models": {
        "filename": "Complex Logical Reasoning over Knowledge Graphs using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "FB15k",
                "FB15k-237",
                "NELL995"
            ],
            "base_models": [
                "Llama2-7B",
                "Llama2-13B",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Universal Self-Consistency for Large Language Model Generation": {
        "filename": "Universal Self-Consistency for Large Language Model Generation.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "BIRD-SQL",
                "ARCADE",
                "GovReport",
                "SummScreen",
                "TruthfulQA"
            ],
            "base_models": [
                "PaLM 2-L",
                "gpt-3.5-turbo"
            ]
        }
    },
    "Chain of Explanation New Prompting Method to Generate Quality Natural Language Explanation for Implicit Hate Speech": {
        "filename": "Chain of Explanation New Prompting Method to Generate Quality Natural Language Explanation for Implicit Hate Speech.pdf",
        "analysis": {
            "benchmarks": [
                "LatentHatred"
            ],
            "base_models": [
                "GPT-2",
                "GPT-Neo-125M",
                "OPT-125M",
                "BART-base",
                "T5-base"
            ]
        }
    },
    "Interpreting and Mitigating Hallucination in MLLMs through Multi-agent Debate": {
        "filename": "Interpreting and Mitigating Hallucination in MLLMs through Multi-agent Debate.pdf",
        "analysis": {
            "benchmarks": [
                "POPE",
                "POPE-R",
                "POPE-C"
            ],
            "base_models": [
                "Gemini-Pro-Vision",
                "GPT-4o"
            ]
        }
    },
    "Are Large Language Models Really Good Logical Reasoners A Comprehensive Evaluation and Beyond": {
        "filename": "Are Large Language Models Really Good Logical Reasoners A Comprehensive Evaluation and Beyond.pdf",
        "analysis": {
            "benchmarks": [
                "bAbI-15",
                "EntailmentBank",
                "RuleTaker",
                "FOLIO",
                "Leap-Of-Thought",
                "bAbI-16",
                "CLUTRR",
                "α-NLI",
                "α-NLG",
                "AbductiveRules",
                "D*-Ab",
                "ReClor",
                "LogiQA",
                "LogiQA 2.0",
                "LogiQA2NLI",
                "NeuLR"
            ],
            "base_models": [
                "text-davinci-003",
                "ChatGPT",
                "BARD",
                "LLaMA3.1-Chat",
                "Mistral-Instruct-v0.3",
                "Claude-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Model Decoding as LikelihoodUtility Alignment": {
        "filename": "Language Model Decoding as LikelihoodUtility Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "WMT14",
                "REBEL",
                "RTP",
                "SwissProt",
                "Sports"
            ],
            "base_models": [
                "BART",
                "mBART50",
                "GPT2",
                "ProtoGPT2",
                "MT-NLG 530B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distilling Step-by-Step Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes": {
        "filename": "Distilling Step-by-Step Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes.pdf",
        "analysis": {
            "benchmarks": [
                "e-SNLI",
                "ANLI",
                "CQA",
                "SVAMP"
            ],
            "base_models": [
                "T5-Base (220M)",
                "T5-Large (770M)",
                "T5-XXL (11B)",
                "PaLM (540B)",
                "GPT-NeoX (20B)"
            ]
        }
    },
    "AI-native Memory A Pathway from LLMs Towards AGI": {
        "filename": "AI-native Memory A Pathway from LLMs Towards AGI.pdf",
        "analysis": {
            "benchmarks": [
                "Mebot dataset"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4-turbo",
                "GPT-3.5-turbo",
                "Gemini 1.5",
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TeacherLM Teaching to Fish Rather Than Giving the Fish Language Modeling Likewise": {
        "filename": "TeacherLM Teaching to Fish Rather Than Giving the Fish Language Modeling Likewise.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU"
            ],
            "base_models": [
                "TeacherLM-7.1B",
                "OPT series",
                "BLOOM series"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual Reasoning and Multi-Agent Approach in Multimodal Large Language Models MLLMs Solving TSP and mTSP Combinatorial Challenges": {
        "filename": "Visual Reasoning and Multi-Agent Approach in Multimodal Large Language Models MLLMs Solving TSP and mTSP Combinatorial Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset with nodes sampled from a uniform distribution within a 5x5 square area"
            ],
            "base_models": [
                "ChatGPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AgentCoder Multi-Agent-based Code Generation with Iterative Testing and Optimisation": {
        "filename": "AgentCoder Multi-Agent-based Code Generation with Iterative Testing and Optimisation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "PaLM Coder",
                "Claude-instant-1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Addition is All You Need for Energy-efficient Language Models": {
        "filename": "Addition is All You Need for Energy-efficient Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Massive Multitask Language Understanding (MMLU)",
                "BigBench-Hard (BBH)",
                "ARC-Challenge",
                "CSQA",
                "OBQA",
                "PIQA",
                "SIQA",
                "VQAv2",
                "VizWiz",
                "TextVQA",
                "Llava-bench",
                "POPE",
                "GSM8k"
            ],
            "base_models": [
                "Llama-3.1-8b-Instruct",
                "Mistral-7b-v0.3-Instruct",
                "Gemma2-2b-It",
                "Llava-v1.5-7b"
            ]
        }
    },
    "Measuring Taiwanese Mandarin Language Understanding": {
        "filename": "Measuring Taiwanese Mandarin Language Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "TMLU"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-3.5",
                "Claude-3-Opus",
                "Claude-Instant-1.2",
                "Yi-34B-Chat",
                "Qwen-14B-Chat",
                "Gemini-Pro",
                "Breeze-7B-Instruct",
                "Taiwan-LLM-13B-Chat",
                "Taiwan-LLM-7B-Chat",
                "Baichuan2-13B-Chat",
                "Llama-2-13b-Chat",
                "Llama-2-7b-chat",
                "Falcon-7b-instruct",
                "Mistral-7B-Instruct",
                "OLMo-7B-Instruct",
                "Mixtral-8x7B-Instruct",
                "chatglm3-6b",
                "Yi-6B-Chat",
                "Qwen-0.5B-Chat",
                "Gemma-7b-it"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-Grounder Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent": {
        "filename": "LLM-Grounder Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent.pdf",
        "analysis": {
            "benchmarks": [
                "ScanRefer"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ]
        }
    },
    "Decoding In-Context Learning Neuroscience-inspired Analysis of Representations in Large Language Models": {
        "filename": "Decoding In-Context Learning Neuroscience-inspired Analysis of Representations in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "linear regression task",
                "reading comprehension task"
            ],
            "base_models": [
                "Llama-2 70B",
                "Vicuna 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Label-free Node Classification on Graphs with Large Language Models LLMS": {
        "filename": "Label-free Node Classification on Graphs with Large Language Models LLMS.pdf",
        "analysis": {
            "benchmarks": [
                "OGBN-PRODUCTS",
                "CORA",
                "CITESEER",
                "PUBMED",
                "OGBN-ARXIV",
                "WIKICS"
            ],
            "base_models": [
                "GPT-3.5-turbo-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Models to Generate Answer Set Programs": {
        "filename": "Leveraging Large Language Models to Generate Answer Set Programs.pdf",
        "analysis": {
            "benchmarks": [
                "Mitra and Baral 2015 logic puzzles dataset"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)",
                "GPT-4 (gpt-4-0314)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Conceptual and Unbiased Reasoning in Language Models": {
        "filename": "Conceptual and Unbiased Reasoning in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "CommonsenseQA",
                "HotpotQA",
                "StrategyQA"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Llama-70B-instruct",
                "Mixtral-8x7B"
            ]
        }
    },
    "Schema-learning and rebinding as mechanisms of in-context learning and emergence": {
        "filename": "Schema-learning and rebinding as mechanisms of in-context learning and emergence.pdf",
        "analysis": {
            "benchmarks": [
                "GINC",
                "LIALT"
            ],
            "base_models": [
                "None specified"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluation of ChatGPT Model for Vulnerability Detection": {
        "filename": "Evaluation of ChatGPT Model for Vulnerability Detection.pdf",
        "analysis": {
            "benchmarks": [
                "Custom GitHub Java dataset"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-3",
                "GPT-3.5-turbo",
                "text-davinci-003"
            ]
        }
    },
    "Data Augmentation with In-Context Learning and Comparative Evaluation in Math Word Problem Solving": {
        "filename": "Data Augmentation with In-Context Learning and Comparative Evaluation in Math Word Problem Solving.pdf",
        "analysis": {
            "benchmarks": [
                "MAWPS-Single",
                "SVAMP"
            ],
            "base_models": [
                "Llama-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT Can Solve Mathematical Problems Without a Calculator": {
        "filename": "GPT Can Solve Mathematical Problems Without a Calculator.pdf",
        "analysis": {
            "benchmarks": [
                "Ape210K",
                "K6 dataset"
            ],
            "base_models": [
                "GLM-10B",
                "ChatGLM-6B",
                "ChatGLM2-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on In-context Learning": {
        "filename": "A Survey on In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "SST5",
                "SST2",
                "Commonsense QA (CQA)",
                "SNLI",
                "AG News"
            ],
            "base_models": [
                "GPT-2",
                "GPT-J",
                "Qwen",
                "Llama"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models as Biomedical Hypothesis Generators A Comprehensive Evaluation": {
        "filename": "Large Language Models as Biomedical Hypothesis Generators A Comprehensive Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of background-hypothesis pairs from biomedical literature"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "LLaMA-65B",
                "Llama-2-70b-chat",
                "WizardLM-13B-V1.2",
                "WizardLM-70B-V1.0",
                "Vicuna-33b-v1.3",
                "Openchat-v3.2-super",
                "MedAlpaca-13B",
                "PMC-LLaMA-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Exploration to Mastery Enabling LLMs to Master Tools via Self-Driven Interactions": {
        "filename": "From Exploration to Mastery Enabling LLMs to Master Tools via Self-Driven Interactions.pdf",
        "analysis": {
            "benchmarks": [
                "ToolBench",
                "RestBench-TMDB",
                "RestBench-Spotify"
            ],
            "base_models": [
                "GPT-4o-mini",
                "Llama-3-70B",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ArthModel Enhance Arithmetic Skills to Large Language Model": {
        "filename": "ArthModel Enhance Arithmetic Skills to Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Arithmetic QA Datasets",
                "Alpace and Arithmetic QA Datasets"
            ],
            "base_models": [
                "LLaMA"
            ]
        }
    },
    "LightPAL Lightweight Passage Retrieval for Open Domain Multi-Document Summarization": {
        "filename": "LightPAL Lightweight Passage Retrieval for Open Domain Multi-Document Summarization.pdf",
        "analysis": {
            "benchmarks": [
                "ODSum",
                "LFRQA"
            ],
            "base_models": [
                "Qwen2.5-0.5B",
                "Qwen2.5-1.5B",
                "Qwen2.5-3B",
                "Meta-Llama-3.1-8B-Instruct",
                "MegaBeam-Mistral-7B-512k"
            ]
        }
    },
    "Generative Expressive Robot Behaviors using Large Language Models": {
        "filename": "Generative Expressive Robot Behaviors using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TelecomRAG Taming Telecom Standards with Retrieval Augmented Generation and LLMs": {
        "filename": "TelecomRAG Taming Telecom Standards with Retrieval Augmented Generation and LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "3GPP Release 16",
                "3GPP Release 18"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA"
            ]
        }
    },
    "Do Large Language Models Know What They Dont Know": {
        "filename": "Do Large Language Models Know What They Dont Know.pdf",
        "analysis": {
            "benchmarks": [
                "SelfAware",
                "SQuAD2.0",
                "NewsQA"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "InstructGPT",
                "LLaMA",
                "GPT-4"
            ]
        }
    },
    "Large Language Models Perform Diagnostic Reasoning": {
        "filename": "Large Language Models Perform Diagnostic Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "DDXPlus"
            ],
            "base_models": [
                "InstructGPT (text-davinci-003)"
            ]
        }
    },
    "COMPS Conceptual Minimal Pair Sentences for testing Robust Property Knowledge and its Inheritance in Pre-trained Language Models": {
        "filename": "COMPS Conceptual Minimal Pair Sentences for testing Robust Property Knowledge and its Inheritance in Pre-trained Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "COMPS"
            ],
            "base_models": [
                "ALBERT (various sizes)",
                "BERT (various sizes)",
                "ELECTRA (various sizes)",
                "RoBERTa (various sizes)",
                "GPT-2 (various sizes)",
                "GPT-Neo (various sizes)",
                "GPT-J (6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Grokked Transformers are Implicit Reasoners A Mechanistic Journey to the Edge of Generalization": {
        "filename": "Grokked Transformers are Implicit Reasoners A Mechanistic Journey to the Edge of Generalization.pdf",
        "analysis": {
            "benchmarks": [
                "test_inferred ID",
                "test_inferred OOD"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "Gemini-1.5-Pro",
                "GPT-2 (8 layers, 768 hidden dimensions, 12 attention heads)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Empirical Study of Instruction-tuning Large Language Models in Chinese": {
        "filename": "An Empirical Study of Instruction-tuning Large Language Models in Chinese.pdf",
        "analysis": {
            "benchmarks": [
                "Belle-eval",
                "MMCU"
            ],
            "base_models": [
                "LLaMA (6.7B, 33B, 65B)",
                "Bloom (7.1B, 176B)",
                "moss-base (16.1B)",
                "ChatGLM (6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SocialGPT Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization": {
        "filename": "SocialGPT Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "PIPA",
                "PISC"
            ],
            "base_models": [
                "GPT-3.5",
                "Vicuna-13B",
                "Llama2-7B",
                "Llama2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How AI Processing Delays Foster Creativity Exploring Research Question Co-Creation with an LLM-based Agent": {
        "filename": "How AI Processing Delays Foster Creativity Exploring Research Question Co-Creation with an LLM-based Agent.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-turbo-16k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tabular Transfer Learning via Prompting LLMs": {
        "filename": "Tabular Transfer Learning via Prompting LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Adult",
                "Credit-R",
                "Electricity",
                "Credit-g",
                "Heart-c",
                "Breast",
                "Haberman"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination": {
        "filename": "Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Consistency of Video Large Language Models in Temporal Comprehension": {
        "filename": "On the Consistency of Video Large Language Models in Temporal Comprehension.pdf",
        "analysis": {
            "benchmarks": [
                "Charades-CON",
                "ActivityNet-CON"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini",
                "TimeChat (Llama2-7B)",
                "VTimeLLM (Vicuna-7B)",
                "VTG-LLM (Llama2-7B)",
                "Video-LLaVA (Vicuna-7B)",
                "Video-ChatGPT (Vicuna-7B)",
                "Video-LLaMA2 (Mistral-7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DiversiGATE A Comprehensive Framework for Reliable Large Language Models": {
        "filename": "DiversiGATE A Comprehensive Framework for Reliable Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "GPT-3 Davinci-text-003"
            ]
        }
    },
    "Who is leading in AI An analysis of industry AI research": {
        "filename": "Who is leading in AI An analysis of industry AI research.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "LLaMA 2",
                "Claude 2",
                "Megatron-Turing NLG 530B",
                "PaLM (540B)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models Injecting Disguised Vulnerabilities against Strong Detection": {
        "filename": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models Injecting Disguised Vulnerabilities against Strong Detection.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "CodeGen-Multi-350M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoMA Compositional Human Motion Generation with Multi-modal Agents": {
        "filename": "CoMA Compositional Human Motion Generation with Multi-modal Agents.pdf",
        "analysis": {
            "benchmarks": [
                "HumanML3D"
            ],
            "base_models": [
                "GPT-4",
                "VideoChat2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Neuroformer Multimodal and Multitask Generative Pretraining for Brain Data": {
        "filename": "Neuroformer Multimodal and Multitask Generative Pretraining for Brain Data.pdf",
        "analysis": {
            "benchmarks": [
                "Simulated Dataset (Hub-net simulation)",
                "Two-photon calcium imaging datasets (Passive-Stim data, Visnav data)"
            ],
            "base_models": [
                "GPT (Generative Pretrained Transformer)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards autonomous system flexible modular production system enhanced with large language model agents": {
        "filename": "Towards autonomous system flexible modular production system enhanced with large language model agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (text-davinci-003)"
            ]
        }
    },
    "EPIC Effective Prompting for Imbalanced-Class Data Synthesis in Tabular Data Classification via Large Language Models": {
        "filename": "EPIC Effective Prompting for Imbalanced-Class Data Synthesis in Tabular Data Classification via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Travel",
                "Sick",
                "HELOC",
                "Income",
                "Diabetes",
                "Thyroid"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Mistral-7b-v0.1",
                "Llama-2-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models Empower Molecular Property Prediction": {
        "filename": "Can Large Language Models Empower Molecular Property Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "MUTAG",
                "PTC",
                "AIDS",
                "Sider",
                "ClinTox",
                "Bace",
                "BBBP",
                "Esol",
                "Lipophilicity"
            ],
            "base_models": [
                "ChatGPT",
                "RoBERTa",
                "DeBERTa"
            ]
        }
    },
    "Proof of Thought  Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning": {
        "filename": "Proof of Thought  Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "Reddit-OSHA Benchmark"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improve Mathematical Reasoning in Language Models by Automated Process Supervision": {
        "filename": "Improve Mathematical Reasoning in Language Models by Automated Process Supervision.pdf",
        "analysis": {
            "benchmarks": [
                "MATH500",
                "GSM8K"
            ],
            "base_models": [
                "Gemini Pro",
                "Gemma2 27B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Language Models Employ the Socratic Method Experiments with Code Debugging": {
        "filename": "Can Language Models Employ the Socratic Method Experiments with Code Debugging.pdf",
        "analysis": {
            "benchmarks": [
                "Custom Socratic debugging dataset"
            ],
            "base_models": [
                "Flan-T5",
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Releasing the CRaQAn Coreference Resolution in Question-Answering An open-source dataset and dataset creation methodology using instruction-following models": {
        "filename": "Releasing the CRaQAn Coreference Resolution in Question-Answering An open-source dataset and dataset creation methodology using instruction-following models.pdf",
        "analysis": {
            "benchmarks": [
                "CRaQAn",
                "Quoref",
                "HotpotQA"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "TextCoT Zoom In for Enhanced Multimodal Text-Rich Image Understanding": {
        "filename": "TextCoT Zoom In for Enhanced Multimodal Text-Rich Image Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "TextVQA",
                "STVQA",
                "DocVQA",
                "InfoVQA",
                "ChartQA",
                "POIE",
                "SROIE",
                "FUNSD"
            ],
            "base_models": [
                "LLaVA-1.5-7B",
                "LLaVA-1.5-13B",
                "SPHINX",
                "ShareGPT4V-7B",
                "Qwen-VL-Chat-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Test of Time A Benchmark for Evaluating LLMs on Temporal Reasoning": {
        "filename": "Test of Time A Benchmark for Evaluating LLMs on Temporal Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ToT-Semantic",
                "ToT-Arithmetic"
            ],
            "base_models": [
                "Claude-3-Sonnet",
                "GPT-4",
                "Gemini 1.5 Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lets Think Outside the Box Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation": {
        "filename": "Lets Think Outside the Box Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Oogiri-GO dataset"
            ],
            "base_models": [
                "Qwen-VL",
                "GPT-4",
                "CogVLM-17B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SynAsk unleashing the power of large language models in organic synthesis": {
        "filename": "SynAsk unleashing the power of large language models in organic synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "C-Eval",
                "GSM8K",
                "BBH",
                "CMMLU"
            ],
            "base_models": [
                "Qwen-14B",
                "LLaMA2-13B",
                "ChatGLM2-6B",
                "InterLM-20B",
                "Baichuan2-13B",
                "Yi-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ExpeL LLM Agents Are Experiential Learners": {
        "filename": "ExpeL LLM Agents Are Experiential Learners.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "ALFWorld",
                "WebShop",
                "FEVER"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RethinkMCTS Refining Erroneous Thoughts in Monte Carlo Tree Search for Code Generation": {
        "filename": "RethinkMCTS Refining Erroneous Thoughts in Monte Carlo Tree Search for Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "APPS"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4o-mini"
            ]
        }
    },
    "Can LLMs Perform Structured Graph Reasoning Tasks": {
        "filename": "Can LLMs Perform Structured Graph Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Custom graph traversal problems"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-2",
                "Llama-2",
                "Palm-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Autonomous Prompt Engineering in Large Language Models": {
        "filename": "Autonomous Prompt Engineering in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Checkmate in One",
                "Word-sorting",
                "Game of 24",
                "Geometric Shapes"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Complex QA and language models hybrid architectures Survey": {
        "filename": "Complex QA and language models hybrid architectures Survey.pdf",
        "analysis": {
            "benchmarks": [
                "HELM",
                "BLOOM",
                "BIG"
            ],
            "base_models": [
                "ChatGPT",
                "GALACTICA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language Commanding via Program Synthesis": {
        "filename": "Natural Language Commanding via Program Synthesis.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate": {
        "filename": "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate.pdf",
        "analysis": {
            "benchmarks": [
                "Common MT",
                "Counter-Intuitive AR"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "vicuna-7b-v1.5-16k",
                "vicuna-13b-v1.5-16k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GenCHiP Generating Robot Policy Code for High-Precision and Contact-Rich Manipulation Tasks": {
        "filename": "GenCHiP Generating Robot Policy Code for High-Precision and Contact-Rich Manipulation Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Functional Manipulation Benchmark (FMB)",
                "NIST Task Board Benchmarks",
                "IROS 2020 Robotic Grasping and Manipulation Competition (IROS RGMC)"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Conceptual Design Generation Using Large Language Models": {
        "filename": "Conceptual Design Generation Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Crowdsourced dataset from Goucher-Lambert et al."
            ],
            "base_models": [
                "GPT-3 (davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can formal argumentative reasoning enhance LLMs performances": {
        "filename": "Can formal argumentative reasoning enhance LLMs performances.pdf",
        "analysis": {
            "benchmarks": [
                "MT-Bench"
            ],
            "base_models": [
                "Mistral 7B (7 billion parameters)"
            ]
        }
    },
    "GUARD Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models": {
        "filename": "GUARD Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Vicuna-13B",
                "LongChat-7B",
                "Llama-2-7B",
                "ChatGPT (gpt-3.5-turbo-0603)",
                "MiniGPT-v2",
                "Gemini Vision Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From LLMs to Actions Latent Codes as Bridges in Hierarchical Robot Control": {
        "filename": "From LLMs to Actions Latent Codes as Bridges in Hierarchical Robot Control.pdf",
        "analysis": {
            "benchmarks": [
                "Language Table",
                "Calvin"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA (LLaMA-2 7B)"
            ]
        }
    },
    "Deductive Beam Search Decoding Deducible Rationale for Chain-of-Thought Reasoning": {
        "filename": "Deductive Beam Search Decoding Deducible Rationale for Chain-of-Thought Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "AQuA",
                "SingleEq",
                "MultiArith",
                "CommonsenseQA",
                "StrategyQA",
                "Coin Flip"
            ],
            "base_models": [
                "Llama2-7b",
                "Llama2-13b",
                "Llama2-70b",
                "ChatGPT (gpt-3.5-turbo-instruct)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FLEXTAF Enhancing Table Reasoning with Flexible Tabular Formats": {
        "filename": "FLEXTAF Enhancing Table Reasoning with Flexible Tabular Formats.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTableQuestions",
                "TabFact"
            ],
            "base_models": [
                "Llama3-8B",
                "Llama3-70B",
                "DeepSeek-Coder-6.7B",
                "DeepSeek-Coder-33B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RAP Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents": {
        "filename": "RAP Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "Webshop",
                "Franka Kitchen",
                "Meta World"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama2-13b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatRetriever Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval": {
        "filename": "ChatRetriever Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "QReCC",
                "TopiOCQA",
                "CAsT-19",
                "CAsT-20",
                "CAsT-21"
            ],
            "base_models": [
                "Qwen-7B-Chat",
                "LLaMA-2 (7B)",
                "Mistral (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Inner Monologue Embodied Reasoning through Planning with Language Models": {
        "filename": "Inner Monologue Embodied Reasoning through Planning with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Simulated Tabletop Rearrangement",
                "Real-World Tabletop Rearrangement",
                "Real-World Mobile Manipulation in a Kitchen Setting"
            ],
            "base_models": [
                "InstructGPT",
                "PALM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs are One-Shot URL Classifiers and Explainers": {
        "filename": "LLMs are One-Shot URL Classifiers and Explainers.pdf",
        "analysis": {
            "benchmarks": [
                "ISCX-2016 Dataset",
                "EBBU-2017 Dataset",
                "HISPAR-Phishstats (HP) Dataset"
            ],
            "base_models": [
                "GPT 4-Turbo",
                "Claude 3 Opus",
                "Gemini",
                "LLaMA 3",
                "LLaMA 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MANGO A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models": {
        "filename": "MANGO A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MANGO"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "Claude-instant-1",
                "Claude-2",
                "Llama-2 (13B)",
                "RWKV (14B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Reliable Common-Sense Reasoning Socialbot Built Using LLMs and Goal-Directed ASP": {
        "filename": "A Reliable Common-Sense Reasoning Socialbot Built Using LLMs and Goal-Directed ASP.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "GPT 3.5"
            ]
        }
    },
    "AnyTool Self-Reflective Hierarchical Agents for Large-Scale API Calls": {
        "filename": "AnyTool Self-Reflective Hierarchical Agents for Large-Scale API Calls.pdf",
        "analysis": {
            "benchmarks": [
                "ToolBench",
                "AnyToolBench"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Understanding the Capability of Large Language Models on Code Clone Detection A Survey": {
        "filename": "Towards Understanding the Capability of Large Language Models on Code Clone Detection A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "BigCloneBench",
                "CodeNet"
            ],
            "base_models": [
                "LLaMA-7B",
                "Alpaca-7B",
                "Vicuna-7B",
                "StarChat-16B",
                "Falcon-Instruct-7B",
                "MPT-Instruct-7B",
                "LLaMA2-7B",
                "LLaMA2-Chat-7B",
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Compositional Learning of AI Models Theoretical and Experimetnal Practices": {
        "filename": "A Survey on Compositional Learning of AI Models Theoretical and Experimetnal Practices.pdf",
        "analysis": {
            "benchmarks": [
                "CREPE",
                "SCAN",
                "gSCAN",
                "PCFG SET",
                "COGS",
                "ReaSCAN",
                "SQOOP",
                "CLUTRR",
                "KiloGram",
                "CompMCTG",
                "MIT-States",
                "Skill-Mix",
                "CFQ"
            ],
            "base_models": [
                "GPT (family models)",
                "LSTM",
                "CNN",
                "Transformer",
                "ResNet",
                "WReN",
                "PrediNet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Artificial Intelligence to Unlock Crowdfunding Success for Small Businesses": {
        "filename": "Using Artificial Intelligence to Unlock Crowdfunding Success for Small Businesses.pdf",
        "analysis": {
            "benchmarks": [
                "GoFundMe small-business-relief campaigns"
            ],
            "base_models": [
                "ChatGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models": {
        "filename": "Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "curated dataset tailored to precision-oriented LegalAI tasks",
                "real-world dataset of house prices"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude AI",
                "Google Bard with Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification": {
        "filename": "Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "MATH",
                "MATH500",
                "MBPP"
            ],
            "base_models": [
                "GPT-4o",
                "Qwen-72B-Instruct",
                "LLaMA2-7B-base",
                "Mistral-7B-v0.1",
                "Gemma-7B-it",
                "Phi-14B",
                "InternLM2-Math-7B",
                "LLaMA3-70B",
                "LLaMA3-8B-instruct",
                "Mistral-7B-v0.3",
                "CodeGemma-7B-it",
                "CodeQwen1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Vision-Language Instruction Tuning A Review and Analysis": {
        "filename": "Vision-Language Instruction Tuning A Review and Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "LLaVA-Instruct-150K",
                "MIMIC-IT"
            ],
            "base_models": [
                "LLaVA",
                "BLIP-2",
                "OpenFlamingo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do LLMs Have Political Correctness Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems": {
        "filename": "Do LLMs Have Political Correctness Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems.pdf",
        "analysis": {
            "benchmarks": [
                "JailBreakBench"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "GPT-4-o",
                "Llama2-7B",
                "Llama2-13B",
                "Llama3-7B",
                "Phi-mini-7B",
                "Qwen1.5",
                "Qwen2-7B"
            ]
        }
    },
    "Do Advanced Language Models Eliminate the Need for Prompt Engineering in Software Engineering": {
        "filename": "Do Advanced Language Models Eliminate the Need for Prompt Engineering in Software Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "CodeTrans",
                "CodeSearchNet"
            ],
            "base_models": [
                "GPT-4o",
                "o1-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models can Implement Policy Iteration": {
        "filename": "Large Language Models can Implement Policy Iteration.pdf",
        "analysis": {
            "benchmarks": [
                "chain",
                "distractor-chain",
                "maze",
                "mini-catch",
                "mini-invaders",
                "point-mass"
            ],
            "base_models": [
                "OPT-30B",
                "GPT-J (6 billion)",
                "Codex (code-davinci-001 variant)",
                "InCoder"
            ]
        }
    },
    "Large Language Models and Simple Stupid Bugs": {
        "filename": "Large Language Models and Simple Stupid Bugs.pdf",
        "analysis": {
            "benchmarks": [
                "ManySStuBs4J"
            ],
            "base_models": [
                "Codex (175B)",
                "PolyCoder (2.6B)",
                "CodeGen (16B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interactive Speculative Planning Enhance Agent Efficiency through Co-design of System and User Interface": {
        "filename": "Interactive Speculative Planning Enhance Agent Efficiency through Co-design of System and User Interface.pdf",
        "analysis": {
            "benchmarks": [
                "OpenAGI",
                "TravelPlanner"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLMs plan paths with extra hints from solvers": {
        "filename": "Can LLMs plan paths with extra hints from solvers.pdf",
        "analysis": {
            "benchmarks": [
                "10 handcrafted 2D path planning problems",
                "100 randomly generated 2D path planning problems"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini Pro 1.5",
                "Claude 3.5 Sonnet"
            ]
        }
    },
    "Integrating Planning into Single-Turn Long-Form Text Generation": {
        "filename": "Integrating Planning into Single-Turn Long-Form Text Generation.pdf",
        "analysis": {
            "benchmarks": [
                "SciNews",
                "Wikipedia (KILT-Wiki, FreshWiki)"
            ],
            "base_models": [
                "Gemini Pro",
                "Gemini 1.5 Flash"
            ]
        }
    },
    "Large Language Models can Share Images Too": {
        "filename": "Large Language Models can Share Images Too.pdf",
        "analysis": {
            "benchmarks": [
                "PHOTO CHAT++"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2-Chat-70B",
                "ChatGPT",
                "VICUNA 13B",
                "FALCON INSTRUCT 40B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Parse-Execute to Parse-Execute-Refine Improving Semantic Parser for Complex Question Answering over Knowledge Base": {
        "filename": "From Parse-Execute to Parse-Execute-Refine Improving Semantic Parser for Complex Question Answering over Knowledge Base.pdf",
        "analysis": {
            "benchmarks": [
                "KQAPro"
            ],
            "base_models": [
                "BART"
            ]
        }
    },
    "What Factors Affect Multi-Modal In-Context Learning An In-Depth Exploration": {
        "filename": "What Factors Affect Multi-Modal In-Context Learning An In-Depth Exploration.pdf",
        "analysis": {
            "benchmarks": [
                "M3IT",
                "M3CoT"
            ],
            "base_models": [
                "OpenFlamingo (9B)",
                "Otter (9B)",
                "Qwen-VL (10B)",
                "GPT4V (>100B)",
                "IDEFICS2 (8B)",
                "Gemini-Pro (>100B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distractor generation for multiple-choice questions with predictive prompting and large language models": {
        "filename": "Distractor generation for multiple-choice questions with predictive prompting and large language models.pdf",
        "analysis": {
            "benchmarks": [
                "Wezooz test data"
            ],
            "base_models": [
                "ChatGPT",
                "mT5"
            ]
        }
    },
    "Constitutional AI Harmlessness from AI Feedback": {
        "filename": "Constitutional AI Harmlessness from AI Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "PALMS",
                "InstructGPT",
                "LaMDA"
            ],
            "base_models": [
                "52B RL-CAI",
                "52B RLHF",
                "52B SL-CAI"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Numbers Creating Analogies to Enhance Data Comprehension and Communication with Generative AI": {
        "filename": "Beyond Numbers Creating Analogies to Enhance Data Comprehension and Communication with Generative AI.pdf",
        "analysis": {
            "benchmarks": [
                "Analogy dataset of 138 cases"
            ],
            "base_models": [
                "GPT-3.5",
                "Stable Diffusion"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Knowledge Distillation Using Frontier Open-source LLMs Generalizability and the Role of Synthetic Data": {
        "filename": "Knowledge Distillation Using Frontier Open-source LLMs Generalizability and the Role of Synthetic Data.pdf",
        "analysis": {
            "benchmarks": [
                "Griffin CoD",
                "GovReport",
                "BBCNews",
                "AQUA-RAT",
                "GSM8K",
                "MultiArith",
                "SVAMP",
                "ANLI",
                "ConjNLI",
                "ConTRoL",
                "HELP",
                "AI2_ARC",
                "CommonSense QA",
                "QASC",
                "RiddleSense"
            ],
            "base_models": [
                "Llama-3.1-405B-Instruct",
                "Llama-3.1-8B-Instruct",
                "Llama-3.1-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt to GPT-3 Step-by-Step Thinking Instructions for Humor Generation": {
        "filename": "Prompt to GPT-3 Step-by-Step Thinking Instructions for Humor Generation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3"
            ]
        }
    },
    "InferCept Efficient Intercept Support for Augmented Large Language Model Inference": {
        "filename": "InferCept Efficient Intercept Support for Augmented Large Language Model Inference.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K-XL",
                "Multihop QA Wikipedia",
                "ALFWorld",
                "ShareGPT"
            ],
            "base_models": [
                "GPT-J-6B",
                "Vicuna-13B",
                "Llama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-Context Impersonation Reveals Large Language Models Strengths and Biases": {
        "filename": "In-Context Impersonation Reveals Large Language Models Strengths and Biases.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "Caltech UCSD Birds (CUB)",
                "Stanford Cars"
            ],
            "base_models": [
                "Vicuna-13B (13 billion parameters)",
                "ChatGPT (gpt-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ProSLM A Prolog Synergized Language Model for explainable Domain Specific Knowledge Based Question Answering": {
        "filename": "ProSLM A Prolog Synergized Language Model for explainable Domain Specific Knowledge Based Question Answering.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "Brain-to-Text Decoding with Context-Aware Neural Representations and Large Language Models": {
        "filename": "Brain-to-Text Decoding with Context-Aware Neural Representations and Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Brain-to-Text 2024"
            ],
            "base_models": [
                "GPT3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Does the Most Sinfully Decadent Cake Ever Taste Good Answering YesNo Questions from Figurative Contexts": {
        "filename": "Does the Most Sinfully Decadent Cake Ever Taste Good Answering YesNo Questions from Figurative Contexts.pdf",
        "analysis": {
            "benchmarks": [
                "FigurativeQA"
            ],
            "base_models": [
                "BERT-based QA models",
                "GPT-3",
                "ChatGPT"
            ]
        }
    },
    "Bugs in Large Language Models Generated Code An Empirical Study": {
        "filename": "Bugs in Large Language Models Generated Code An Empirical Study.pdf",
        "analysis": {
            "benchmarks": [
                "CoderEval"
            ],
            "base_models": [
                "CodeGen (350M to 16.1B parameters)",
                "PanGu-Coder (317M and 2.6B parameters)",
                "Codex (12M to 12B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards More Unified In-Context Visual Understanding": {
        "filename": "Towards More Unified In-Context Visual Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "MS-COCO",
                "Visual Genome"
            ],
            "base_models": [
                "GPT-2 small"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Motif Intrinsic Motivation from Artificial Intelligence Feedback": {
        "filename": "Motif Intrinsic Motivation from Artificial Intelligence Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "NetHack Learning Environment (NLE)"
            ],
            "base_models": [
                "Llama 2 (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Concise and Organized Perception Facilitates Reasoning in Large Language Models": {
        "filename": "Concise and Organized Perception Facilitates Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ProofWriter",
                "PrOntoQA",
                "PrOntoQA-OOD",
                "FOLIO",
                "DI-GSM"
            ],
            "base_models": [
                "Llama-2-13B-Chat",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs Are In-Context Reinforcement Learners": {
        "filename": "LLMs Are In-Context Reinforcement Learners.pdf",
        "analysis": {
            "benchmarks": [
                "Banking-77",
                "Clinic-150",
                "NLU",
                "TREC",
                "TREC-fine"
            ],
            "base_models": [
                "Llama-3.1 8B",
                "Phi-3.5-mini 3.8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science": {
        "filename": "Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science.pdf",
        "analysis": {
            "benchmarks": [
                "Kaggle datasets",
                "public tabular benchmarks"
            ],
            "base_models": [
                "Llama-2 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Prompting-Based Representation Learning Method for Recommendation with Large Language Models": {
        "filename": "A Prompting-Based Representation Learning Method for Recommendation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Yelp2018",
                "Amazon-VideoGames"
            ],
            "base_models": [
                "GPT-3.5/4",
                "Llama-2-7b",
                "BERT"
            ]
        }
    },
    "Ghost in the Minecraft Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory": {
        "filename": "Ghost in the Minecraft Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory.pdf",
        "analysis": {
            "benchmarks": [
                "ObtainDiamond task",
                "Minecraft Overworld technology tree"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PatternGPT A Pattern-Driven Framework for Large Language Model Text Generation": {
        "filename": "PatternGPT A Pattern-Driven Framework for Large Language Model Text Generation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Black-Box Access is Insufficient for Rigorous AI Audits": {
        "filename": "Black-Box Access is Insufficient for Rigorous AI Audits.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book": {
        "filename": "Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book.pdf",
        "analysis": {
            "benchmarks": [
                "FLORES",
                "Machine Translation from One Book (MTOB) test set for Kalamang"
            ],
            "base_models": [
                "Gemini-1.5-Flash-001",
                "Llama-3.1-8B",
                "NLLB-1.3B-Distilled"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal Large Language Models": {
        "filename": "Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMBench",
                "MME",
                "MMVet"
            ],
            "base_models": [
                "GPT-4",
                "Gemini-Pro"
            ]
        }
    },
    "A Multi-Source Retrieval Question Answering Framework Based on RAG": {
        "filename": "A Multi-Source Retrieval Question Answering Framework Based on RAG.pdf",
        "analysis": {
            "benchmarks": [
                "2WikiMultiHopQA",
                "HotpotQA",
                "StrategyQA"
            ],
            "base_models": [
                "GPT-3.5",
                "LLaMa2-7B-Chat"
            ]
        }
    },
    "Interactive-Chain-Prompting Ambiguity Resolution for Crosslingual Conditional Generation with Interaction": {
        "filename": "Interactive-Chain-Prompting Ambiguity Resolution for Crosslingual Conditional Generation with Interaction.pdf",
        "analysis": {
            "benchmarks": [
                "AMBIG MT"
            ],
            "base_models": [
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-consistent Reasoning For Solving Math Word Problems": {
        "filename": "Self-consistent Reasoning For Solving Math Word Problems.pdf",
        "analysis": {
            "benchmarks": [
                "Math23k",
                "Ape210k"
            ],
            "base_models": [
                "RoBERTa (768 hidden size)"
            ]
        }
    },
    "MP5 A Multi-modal Open-ended Embodied System in Minecraft via Active Perception": {
        "filename": "MP5 A Multi-modal Open-ended Embodied System in Minecraft via Active Perception.pdf",
        "analysis": {
            "benchmarks": [
                "MineDojo"
            ],
            "base_models": [
                "GPT-4",
                "Vicuna-13B-v1.5",
                "LLaMA2-70B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLMs Keep a Secret Testing Privacy Implications of Language Models via Contextual Integrity Theory": {
        "filename": "Can LLMs Keep a Secret Testing Privacy Implications of Language Models via Contextual Integrity Theory.pdf",
        "analysis": {
            "benchmarks": [
                "CONFAIDE"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "Davinci1",
                "Llama-2 Chat (70B)",
                "Llama 2 (70B)",
                "Mixtral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Groma Localized Visual Tokenization for Grounding Multimodal Large Language Models": {
        "filename": "Groma Localized Visual Tokenization for Grounding Multimodal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "RefCOCO",
                "RefCOCO+",
                "RefCOCOg",
                "LVIS-Ground",
                "Visual Genome",
                "Flickr30k Entities",
                "LLaVA Bench (COCO)"
            ],
            "base_models": [
                "Vicuna-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do Prompts Really Prompt Exploring the Prompt Understanding Capability of Whisper": {
        "filename": "Do Prompts Really Prompt Exploring the Prompt Understanding Capability of Whisper.pdf",
        "analysis": {
            "benchmarks": [
                "GigaSpeech",
                "ASCEND",
                "CSZS-correct-zh",
                "CSZS-correct-fr"
            ],
            "base_models": [
                "Whisper-large-v3 (1.5B parameters)"
            ]
        }
    },
    "Beyond Generating Code Evaluating GPT on a Data Visualization Course": {
        "filename": "Beyond Generating Code Evaluating GPT on a Data Visualization Course.pdf",
        "analysis": {
            "benchmarks": [
                "Harvard's CS171 data visualization course assignments"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Towards a Unified Multimodal Reasoning Framework": {
        "filename": "Towards a Unified Multimodal Reasoning Framework.pdf",
        "analysis": {
            "benchmarks": [
                "TextVQA",
                "ScienceQA"
            ],
            "base_models": [
                "GPT-4",
                "T5-small",
                "DistilBERT",
                "RoBERTa",
                "ViLT",
                "VisualBERT"
            ]
        }
    },
    "How do Large Language Models Navigate Conflicts between Honesty and Helpfulness": {
        "filename": "How do Large Language Models Navigate Conflicts between Honesty and Helpfulness.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "RealToxicity"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4",
                "GPT-4 Turbo",
                "LLaMA 2 70B",
                "Mixtral 8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Sycophancy to Subterfuge Investigating Reward-Tampering in Large Language Models": {
        "filename": "Sycophancy to Subterfuge Investigating Reward-Tampering in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom curriculum of gameable environments"
            ],
            "base_models": [
                "Claude-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Iteratively Prompt Pre-trained Language Models for Chain of Thought": {
        "filename": "Iteratively Prompt Pre-trained Language Models for Chain of Thought.pdf",
        "analysis": {
            "benchmarks": [
                "2WikiMultiHopQA",
                "R4C",
                "LoT"
            ],
            "base_models": [
                "BART-large",
                "RoBERTa-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CodeChain Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules": {
        "filename": "CodeChain Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules.pdf",
        "analysis": {
            "benchmarks": [
                "APPS",
                "CodeContests"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "WizardCoder (1B to 34B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PERSOMA PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting": {
        "filename": "PERSOMA PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "MovieLens"
            ],
            "base_models": [
                "PaLM 2 XXS"
            ]
        }
    },
    "Battle of the Large Language Models Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison": {
        "filename": "Battle of the Large Language Models Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison.pdf",
        "analysis": {
            "benchmarks": [
                "Academic",
                "ATIS",
                "GeoQuery",
                "Yelp",
                "IMDB",
                "Restaurants",
                "Scholar",
                "Advising",
                "Spider"
            ],
            "base_models": [
                "Dolly (12B, 7B, 3B based on Pythia)",
                "LLaMA (65B, 30B, 13B, 7B)",
                "Vicuna (13B, 7B based on LLaMA)",
                "Guanaco (33B based on LLaMA)",
                "Bard (LaMDA and PaLM 2)",
                "GPT-3.5 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Deep Tensor Network": {
        "filename": "Deep Tensor Network.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "Gopher",
                "PaLM",
                "GLaM",
                "Chinchilla",
                "Megatron–Turing NLG",
                "LaMDA",
                "OPT",
                "LLaMA",
                "PaLM 2",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models as Compilers Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models": {
        "filename": "Language Models as Compilers Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Big-Bench Hard (Suzgun et al., 2022)"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "CodeLlama-7B",
                "CodeLlama-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Large Language Models for Commit Message Generation A Preliminary Study": {
        "filename": "Using Large Language Models for Commit Message Generation A Preliminary Study.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from 7,661 code diff-commit message pairs"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "Llama 2 7B",
                "Llama 2 70B"
            ]
        }
    },
    "A Simple and Effective Pruning Approach for Large Language Models": {
        "filename": "A Simple and Effective Pruning Approach for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "EleutherAI LM Harness",
                "WikiText"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-30B",
                "LLaMA-65B",
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "LLaMA-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SIaM Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models": {
        "filename": "SIaM Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "APE",
                "CM",
                "CMATH",
                "MathBench"
            ],
            "base_models": [
                "Llama3-8B",
                "DeepSeek-Coder-7B",
                "Qwen2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Element-aware Summarization with Large Language Models Expert-aligned Evaluation and Chain-of-Thought Method": {
        "filename": "Element-aware Summarization with Large Language Models Expert-aligned Evaluation and Chain-of-Thought Method.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/DailyMail",
                "BBC XSum"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "BART-BASE",
                "BART-LARGE",
                "T5-LARGE",
                "PEGASUS-LARGE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hacking The Lazy Way LLM Augmented Pentesting": {
        "filename": "Hacking The Lazy Way LLM Augmented Pentesting.pdf",
        "analysis": {
            "benchmarks": [
                "custom testbench framework mimicking real-world pentesting scenarios",
                "boot2root box"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rethinking harmless refusals when fine-tuning foundation models": {
        "filename": "Rethinking harmless refusals when fine-tuning foundation models.pdf",
        "analysis": {
            "benchmarks": [
                "Car Sales Scenario",
                "Real Estate Scenario",
                "Insider Trading Scenario"
            ],
            "base_models": [
                "GPT-4-0613",
                "GPT-4-1106-preview",
                "GPT-4-0125-preview",
                "GPT-4-vision-preview"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Foundation Models Wrangle Your Data": {
        "filename": "Can Foundation Models Wrangle Your Data.pdf",
        "analysis": {
            "benchmarks": [
                "Magellan",
                "Synthea",
                "TDE",
                "Restaurants",
                "Buy",
                "Hospital",
                "Adult"
            ],
            "base_models": [
                "GPT-3 (175B parameters)",
                "BERT",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Intelligent Go-Explore Standing on the Shoulders of Giant Foundation Models": {
        "filename": "Intelligent Go-Explore Standing on the Shoulders of Giant Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "Game of 24",
                "BabyAI",
                "TextWorld"
            ],
            "base_models": [
                "GPT-4",
                "Claude Sonnet 3.5",
                "Llama-3 400B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Semantic-Enhanced Indirect Call Analysis with Large Language Models": {
        "filename": "Semantic-Enhanced Indirect Call Analysis with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "oss-fuzz projects (31 projects)",
                "custom benchmark dataset sourced from real-world programs"
            ],
            "base_models": [
                "Qwen1.5-72B-Chat",
                "LLaMA3-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SCREWS A Modular Framework for Reasoning with Revisions": {
        "filename": "SCREWS A Modular Framework for Reasoning with Revisions.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "StrategyQA",
                "Big-Bench AutoDebugging"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0301)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do Chase Your Tail Missing Key Aspects Augmentation in Textual Vulnerability Descriptions of Long-tail Software through Feature Inference": {
        "filename": "Do Chase Your Tail Missing Key Aspects Augmentation in Textual Vulnerability Descriptions of Long-tail Software through Feature Inference.pdf",
        "analysis": {
            "benchmarks": [
                "CVE (63,000)",
                "NVD (240)",
                "NVD* (381)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "T5",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MemoChat Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain Conversation": {
        "filename": "MemoChat Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain Conversation.pdf",
        "analysis": {
            "benchmarks": [
                "MT-Bench+"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Fastchat-T5-3B",
                "Vicuna-7B",
                "Vicuna-13B",
                "Vicuna-33B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning How To Ask Cycle-Consistency Refines Prompts in Multimodal Foundation Models": {
        "filename": "Learning How To Ask Cycle-Consistency Refines Prompts in Multimodal Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "VQAv2",
                "FigureQA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4V",
                "DALL·E 3"
            ]
        }
    },
    "Improving Interpersonal Communication by Simulating Audiences with Language Models": {
        "filename": "Improving Interpersonal Communication by Simulating Audiences with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Stanford Human Preferences (SHP) dataset"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Code Generation Tools Almost for Free A Study of Few-Shot Pre-Trained Language Models on Code": {
        "filename": "Code Generation Tools Almost for Free A Study of Few-Shot Pre-Trained Language Models on Code.pdf",
        "analysis": {
            "benchmarks": [
                "Major",
                "MeMo",
                "Randoop"
            ],
            "base_models": [
                "Codex (Davinci)",
                "Codex (Cushman)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ForgerySleuth Empowering Multimodal Large Language Models for Image Manipulation Detection": {
        "filename": "ForgerySleuth Empowering Multimodal Large Language Models for Image Manipulation Detection.pdf",
        "analysis": {
            "benchmarks": [
                "ForgeryAnalysis-Eval",
                "Columbia",
                "Coverage",
                "CASIA1",
                "NIST16",
                "IMD20",
                "COCOGlide"
            ],
            "base_models": [
                "GPT-4o",
                "LLaMA (size not specified)",
                "Qwen2-VL-7B",
                "LISA-7B-v1",
                "LLaV A-7B-v1-1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assessing the Impact of Prompting Methods on ChatGPTs Mathematical Capabilities": {
        "filename": "Assessing the Impact of Prompting Methods on ChatGPTs Mathematical Capabilities.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "MMLU"
            ],
            "base_models": [
                "ChatGPT-3.5"
            ]
        }
    },
    "Automating Venture Capital Founder assessment using LLM-powered segmentation feature engineering and automated labeling techniques": {
        "filename": "Automating Venture Capital Founder assessment using LLM-powered segmentation feature engineering and automated labeling techniques.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 1022 successful and 2694 unsuccessful startup founders"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "ChatGraph Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs": {
        "filename": "ChatGraph Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "20NG",
                "R8",
                "R52",
                "Ohsumed"
            ],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "MIO A Foundation Model on Multimodal Tokens": {
        "filename": "MIO A Foundation Model on Multimodal Tokens.pdf",
        "analysis": {
            "benchmarks": [
                "MS-COCO",
                "VQAv2",
                "OK-VQA",
                "VizWiz",
                "SEED-Bench",
                "Flickr30K",
                "LibriSpeech",
                "VCTK",
                "MSVDQA",
                "MSRVTT-QA"
            ],
            "base_models": [
                "Yi-6B-Base (6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mastering Symbolic Operations Augmenting Language Models with Compiled Neural Networks": {
        "filename": "Mastering Symbolic Operations Augmenting Language Models with Compiled Neural Networks.pdf",
        "analysis": {
            "benchmarks": [
                "AddSub+",
                "GSM8K-Hard"
            ],
            "base_models": [
                "T5-Small (60M)",
                "T5-Base (220M)",
                "T5-Large (770M)",
                "GLM-130B (130B)",
                "GPT-3.5 (175B)",
                "llama-2-7b",
                "llama-2-70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models": {
        "filename": "Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MovieLens-1M",
                "Amazon-Books"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-7B",
                "ChatGLM-6B",
                "BERT-110M",
                "T5-223M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In Context Learning and Reasoning for Symbolic Regression with Large Language Models": {
        "filename": "In Context Learning and Reasoning for Symbolic Regression with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Langmuir adsorption isotherm dataset",
                "Kepler's Law dataset",
                "Bode's Law dataset",
                "Hubble's Law dataset",
                "Dual-site Langmuir adsorption isotherm dataset",
                "Nikuradse dataset"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CultiVerse Towards Cross-Cultural Understanding for Paintings with Large Language Model": {
        "filename": "CultiVerse Towards Cross-Cultural Understanding for Paintings with Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "TCP Cultural Norm Dataset"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MEDCO Medical Education Copilots Based on A Multi-Agent Framework": {
        "filename": "MEDCO Medical Education Copilots Based on A Multi-Agent Framework.pdf",
        "analysis": {
            "benchmarks": [
                "MVME dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "Claude3.5-Sonnet",
                "GPT-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TravelPlanner A Benchmark for Real-World Planning with Language Agents": {
        "filename": "TravelPlanner A Benchmark for Real-World Planning with Language Agents.pdf",
        "analysis": {
            "benchmarks": [
                "TravelPlanner"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "Gemini Pro",
                "Mixtral-8x7B-MoE",
                "Mistral-7B-32K",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMD A Large Language Model for Interpreting Longitudinal Medical Records": {
        "filename": "LLMD A Large Language Model for Interpreting Longitudinal Medical Records.pdf",
        "analysis": {
            "benchmarks": [
                "PubMedQA"
            ],
            "base_models": [
                "Llama3.1-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VIP5 Towards Multimodal Foundation Models for Recommendation": {
        "filename": "VIP5 Towards Multimodal Foundation Models for Recommendation.pdf",
        "analysis": {
            "benchmarks": [
                "Clothing",
                "Sports",
                "Beauty",
                "Toys"
            ],
            "base_models": [
                "P5-small",
                "CLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Complete Survey on LLM-based AI Chatbots": {
        "filename": "A Complete Survey on LLM-based AI Chatbots.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "BERT",
                "PaLM-540B",
                "LLaMA-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "INCLUDE Evaluating Multilingual Language Understanding with Regional Knowledge": {
        "filename": "INCLUDE Evaluating Multilingual Language Understanding with Regional Knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "INCLUDE"
            ],
            "base_models": [
                "GPT-4",
                "Llama-3.1-70B-Instruct",
                "Aya-expanse-32B",
                "Qwen2.5-14B",
                "Llama-3.1-Instruct-8B",
                "Aya-expanse-8B",
                "Qwen2.5-7B",
                "Mistral-7B",
                "Gemma-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation": {
        "filename": "Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "MT-Bench",
                "AlpacaEval",
                "AdvBench",
                "GSM8K"
            ],
            "base_models": [
                "LLaMA-2-7B-Chat",
                "Mistral-7B-Instruct-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Preliminary Study of o1 in Medicine Are We Closer to an AI Doctor": {
        "filename": "A Preliminary Study of o1 in Medicine Are We Closer to an AI Doctor.pdf",
        "analysis": {
            "benchmarks": [
                "PICOMIMIC4ED",
                "MedNLI-Dis",
                "PUBHEALTH Ver.",
                "PubMedQA",
                "MedQA",
                "MedMCQA",
                "LancetQA",
                "NEJMQA",
                "Medbullets",
                "MedCalc-Bench",
                "XMedBench",
                "AI Hospital",
                "AgentClinic"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "MEDITRON-70B",
                "Llama3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GeoMeter Probing Depth and Height Perception of Large Visual-Language Models": {
        "filename": "GeoMeter Probing Depth and Height Perception of Large Visual-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CLEVR",
                "GeoMeter (Synthetic 2D, Synthetic 3D, Real-World)"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA 1.5 7B",
                "LLaVA 1.5 13B",
                "LLaVA 1.6 Mistral 7B",
                "LLaVA 1.6 Vicuna 7B",
                "LLaVA 1.6 Vicuna 13B",
                "Fuyu-8B",
                "Bunny-v1.0-3B",
                "Bunny-v1.0-4B",
                "Bunny-v1.1-4B",
                "Bunny-Llama-3-8B-V",
                "InstructBLIP-Vicuna-7B",
                "InstructBLIP-Flan-T5-XL",
                "LLaMA-Adapter-v2-Multimodal",
                "MiniGPT-4",
                "Claude 3 Opus"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Behavior Trees Enable Structured Programming of Language Model Agents": {
        "filename": "Behavior Trees Enable Structured Programming of Language Model Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "OpenChat 3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Faith and Fate Limits of Transformers on Compositionality": {
        "filename": "Faith and Fate Limits of Transformers on Compositionality.pdf",
        "analysis": {
            "benchmarks": [
                "custom multi-digit multiplication dataset",
                "custom logic grid puzzles dataset",
                "custom dynamic programming problem dataset"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RePrompt Planning by Automatic Prompt Engineering for Large Language Models Agents": {
        "filename": "RePrompt Planning by Automatic Prompt Engineering for Large Language Models Agents.pdf",
        "analysis": {
            "benchmarks": [
                "PDDL generation",
                "Travel Planner"
            ],
            "base_models": [
                "GPT-4-turbo-1106-preview"
            ]
        }
    },
    "Adversarial Preference Optimization": {
        "filename": "Adversarial Preference Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "Helpful&Harmless"
            ],
            "base_models": [
                "Alpaca",
                "LLaMA-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models as Urban Residents An LLM Agent Framework for Personal Mobility Generation": {
        "filename": "Large Language Models as Urban Residents An LLM Agent Framework for Personal Mobility Generation.pdf",
        "analysis": {
            "benchmarks": [
                "personal activity trajectory dataset of Tokyo"
            ],
            "base_models": [
                "GPT-3.5-turbo-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unpacking DPO and PPO Disentangling Best Practices for Learning from Preference Feedback": {
        "filename": "Unpacking DPO and PPO Disentangling Best Practices for Learning from Preference Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8k",
                "Big Bench Hard",
                "TruthfulQA",
                "HumanEval+",
                "MBPP+",
                "ToxiGen",
                "XSTest",
                "AlpacaEval 1",
                "AlpacaEval 2",
                "IFEval"
            ],
            "base_models": [
                "Llama 2 13B",
                "Llama 3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HELP ME THINK A Simple Prompting Strategy for Non-experts to Create Customized Content with Models": {
        "filename": "HELP ME THINK A Simple Prompting Strategy for Non-experts to Create Customized Content with Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "ChatGPT",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Logical Tasks for Measuring Extrapolation and Rule Comprehension": {
        "filename": "Logical Tasks for Measuring Extrapolation and Rule Comprehension.pdf",
        "analysis": {
            "benchmarks": [
                "Mathematics Dataset",
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "GPT-3",
                "PaLM (540B)",
                "Minerva",
                "GPT-NeoX (20B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Large Language Models for Human Mobility Prediction under Public Events": {
        "filename": "Exploring Large Language Models for Human Mobility Prediction under Public Events.pdf",
        "analysis": {
            "benchmarks": [
                "Barclays Center event data",
                "NYC Taxi Data"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AIvril AI-Driven RTL Generation With Verification In-The-Loop": {
        "filename": "AIvril AI-Driven RTL Generation With Verification In-The-Loop.pdf",
        "analysis": {
            "benchmarks": [
                "VerilogEval-Human"
            ],
            "base_models": [
                "Claude 3.5 Sonnet",
                "GPT-4o",
                "Llama3 70B"
            ]
        }
    },
    "Towards Modeling Learner Performance with Large Language Models": {
        "filename": "Towards Modeling Learner Performance with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "models": [],
            "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
        }
    },
    "Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training TXIT Exam and Red Journal Gray Zone Cases Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology": {
        "filename": "Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training TXIT Exam and Red Journal Gray Zone Cases Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology.pdf",
        "analysis": {
            "benchmarks": [
                "38th American College of Radiology (ACR) radiation oncology in-training (TXIT) exam",
                "2022 Red Journal Gray Zone cases"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "ChatGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Boosting Deductive Reasoning with Step Signals In RLHF": {
        "filename": "Boosting Deductive Reasoning with Step Signals In RLHF.pdf",
        "analysis": {
            "benchmarks": [
                "MuseD",
                "PrOntoQA",
                "ProofWriter",
                "LogicalDeduction",
                "FOLIO",
                "AR-LSAT"
            ],
            "base_models": [
                "Llama3 8B",
                "GPT-4",
                "Qwen2.5-72B-Instruct",
                "Llama3.1-72B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection": {
        "filename": "Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection.pdf",
        "analysis": {
            "benchmarks": [
                "MS-COCO",
                "PASCAL VOC"
            ],
            "base_models": [
                "CLIP (ViT-L/14@336px)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating ChatGPTs Information Extraction Capabilities An Assessment of Performance Explainability Calibration and Faithfulness": {
        "filename": "Evaluating ChatGPTs Information Extraction Capabilities An Assessment of Performance Explainability Calibration and Faithfulness.pdf",
        "analysis": {
            "benchmarks": [
                "BBN",
                "OntoNotes 5.0",
                "CoNLL2003",
                "TACRED",
                "SemEval2010",
                "ACE05-R",
                "SciERC",
                "ACE05-E",
                "ACE05-E+"
            ],
            "base_models": [
                "ChatGPT",
                "BERT",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Optimizing Prompts for Text-to-Image Generation": {
        "filename": "Optimizing Prompts for Text-to-Image Generation.pdf",
        "analysis": {
            "benchmarks": [
                "DiffusionDB",
                "COCO",
                "ImageNet-21k"
            ],
            "base_models": [
                "Stable Diffusion v1.4",
                "Stable Diffusion v1.5",
                "GPT-2 (117M)"
            ]
        }
    },
    "Skywork-Math Data Scaling Laws for Mathematical Reasoning in Large Language Models - The Story Goes On": {
        "filename": "Skywork-Math Data Scaling Laws for Mathematical Reasoning in Large Language Models - The Story Goes On.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K"
            ],
            "base_models": [
                "LLaMA2-7B",
                "Mistral-7B",
                "DeepSeekMath-Base-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Digital Life Project Autonomous 3D Characters with Social Intelligence": {
        "filename": "Digital Life Project Autonomous 3D Characters with Social Intelligence.pdf",
        "analysis": {
            "benchmarks": [
                "DLP-MoCap",
                "InterHuman",
                "HumanML3D"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets Insights and Best Practices": {
        "filename": "What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets Insights and Best Practices.pdf",
        "analysis": {
            "benchmarks": [
                "NarrativeQA",
                "2WikiMQA",
                "DuReader",
                "HotpotQA",
                "MultifieldQA en",
                "MultifieldQA zh",
                "MuSiQue",
                "Qasper"
            ],
            "base_models": [
                "InternLM2-1.8B",
                "LLaMA3-8B",
                "InternLM2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Peering Through Preferences Unraveling Feedback Acquisition for Aligning Large Language Models": {
        "filename": "Peering Through Preferences Unraveling Feedback Acquisition for Aligning Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Dolly",
                "User-orient",
                "SuperNI"
            ],
            "base_models": [
                "Alpaca-7B (based on LLaMA-7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MuseGraph Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining": {
        "filename": "MuseGraph Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining.pdf",
        "analysis": {
            "benchmarks": [
                "Arxiv",
                "MIMIC-III",
                "Cora",
                "AGENDA",
                "WebNLG"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-V1-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Complexity-Based Prompting for Multi-Step Reasoning": {
        "filename": "Complexity-Based Prompting for Multi-Step Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MultiArith",
                "MathQA",
                "Date Understanding",
                "Penguins"
            ],
            "base_models": [
                "GPT-3 175B",
                "Codex 175B"
            ]
        }
    },
    "Multimodal Auto Validation For Self-Refinement in Web Agents": {
        "filename": "Multimodal Auto Validation For Self-Refinement in Web Agents.pdf",
        "analysis": {
            "benchmarks": [
                "WebVoyager"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "GPT-4V",
                "GPT4-Omni"
            ]
        }
    },
    "Hypothesizing Missing Causal Variables with LLMs": {
        "filename": "Hypothesizing Missing Causal Variables with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Cancer",
                "Survey",
                "Asia",
                "Child",
                "Insurance",
                "Alarm",
                "Alzheimer's Disease"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA2-chat-7b",
                "Mistral-7B-Instruct-v0.2",
                "Mixtral-7B-Instruct-v0.1",
                "Zephyr-7b-Beta",
                "Neural-chat-7b-v3-1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ANALOGYKB Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base": {
        "filename": "ANALOGYKB Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base.pdf",
        "analysis": {
            "benchmarks": [
                "E-KAR",
                "BATS",
                "UNIT 2",
                "UNIT 4",
                "Google",
                "SAT",
                "SCAN"
            ],
            "base_models": [
                "InstructGPT 003",
                "RoBERTa-Large",
                "T5-Large",
                "BERT-Large",
                "DeBERTa-v3",
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "QueryCAD Grounded Question Answering for CAD Models": {
        "filename": "QueryCAD Grounded Question Answering for CAD Models.pdf",
        "analysis": {
            "benchmarks": [
                "CAD-Q&A Benchmark"
            ],
            "base_models": [
                "Llama 3.1 405B",
                "GPT-4"
            ]
        }
    },
    "ZeroCAP Zero-Shot Multi-Robot Context Aware Pattern Formation via Large Language Models": {
        "filename": "ZeroCAP Zero-Shot Multi-Robot Context Aware Pattern Formation via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "General pattern formation",
                "Infill pattern formation",
                "Caging formation"
            ],
            "base_models": [
                "GPT-4",
                "llama-2-70b",
                "Claude-3-opus"
            ]
        }
    },
    "Synergizing Knowledge Graphs with Large Language Models A Comprehensive Review and Future Prospects": {
        "filename": "Synergizing Knowledge Graphs with Large Language Models A Comprehensive Review and Future Prospects.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT",
                "GPT",
                "T5",
                "GLM",
                "ChatGPT4",
                "LLaMA"
            ]
        }
    },
    "Team Trifecta at Factify5WQA Setting the Standard in Fact Verification with Fine-Tuning": {
        "filename": "Team Trifecta at Factify5WQA Setting the Standard in Fact Verification with Fine-Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "FACTIFY5WQA"
            ],
            "base_models": [
                "DeBERTaV3-large",
                "RoBERTa-large"
            ]
        }
    },
    "Chain-of-Spot Interactive Reasoning Improves Large Vision-Language Models": {
        "filename": "Chain-of-Spot Interactive Reasoning Improves Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "VQAv2",
                "GQA",
                "VizWiz",
                "SEEDBench",
                "MM-Vet"
            ],
            "base_models": [
                "LLaVA-1.5/13B",
                "LLaVA-1.5/7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Raidar geneRative AI Detection viA Rewriting": {
        "filename": "Raidar geneRative AI Detection viA Rewriting.pdf",
        "analysis": {
            "benchmarks": [
                "News Dataset",
                "Creative Writing Dataset",
                "Student Essay Dataset",
                "Code Dataset",
                "Yelp Review Dataset",
                "ArXiv Paper Abstract"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Ada",
                "Text-Davinci-002",
                "Claude",
                "GPT-4-turbo",
                "LLaMA 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM2FEA Discover Novel Designs with Generative Evolutionary Multitasking": {
        "filename": "LLM2FEA Discover Novel Designs with Generative Evolutionary Multitasking.pdf",
        "analysis": {
            "benchmarks": [
                "aerodynamic design problems"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "Shape-E"
            ]
        }
    },
    "DiffusionGPT LLM-Driven Text-to-Image Generation System": {
        "filename": "DiffusionGPT LLM-Driven Text-to-Image Generation System.pdf",
        "analysis": {
            "benchmarks": [
                "PartiPrompts"
            ],
            "base_models": [
                "ChatGPT (text-davinci-003)",
                "SD1.5",
                "SDXL"
            ]
        }
    },
    "Large Language Models Can Be Easily Distracted by Irrelevant Context": {
        "filename": "Large Language Models Can Be Easily Distracted by Irrelevant Context.pdf",
        "analysis": {
            "benchmarks": [
                "GSM-IC",
                "GSM8K"
            ],
            "base_models": [
                "Codex (code-davinci-002)",
                "GPT-3.5 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do better language models have crisper vision": {
        "filename": "Do better language models have crisper vision.pdf",
        "analysis": {
            "benchmarks": [
                "Visual Text Representation Benchmark (ViTeRB)",
                "ImageNet+"
            ],
            "base_models": [
                "T5-XL",
                "Flan UL2",
                "BERT Base",
                "Llama-3",
                "Phi-3",
                "Qwen2",
                "BLOOM",
                "Falcon",
                "Gemma",
                "Vicuna v1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Limitations of Large Language Models LLMs False Attribution": {
        "filename": "On the Limitations of Large Language Models LLMs False Attribution.pdf",
        "analysis": {
            "benchmarks": [
                "Project Gutenberg's top 10 most popular books"
            ],
            "base_models": [
                "LLaMA-2-13B",
                "Mixtral 8x7B",
                "Gemma-7B"
            ]
        }
    },
    "Reasoning Implicit Sentiment with Chain-of-Thought Prompting": {
        "filename": "Reasoning Implicit Sentiment with Chain-of-Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval14 Laptop",
                "SemEval14 Restaurant"
            ],
            "base_models": [
                "Flan-T5 (11B)",
                "GPT-3 (175B)"
            ]
        }
    },
    "How FaR Are Large Language Models From Agents with Theory-of-Mind": {
        "filename": "How FaR Are Large Language Models From Agents with Theory-of-Mind.pdf",
        "analysis": {
            "benchmarks": [
                "ToMi",
                "T4D"
            ],
            "base_models": [
                "GPT-4",
                "PaLM 2-S (Bison)",
                "PaLM 2-L (Unicorn)",
                "GPT-3.5-turbo (ChatGPT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DeLLMa Decision Making Under Uncertainty with Large Language Models": {
        "filename": "DeLLMa Decision Making Under Uncertainty with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Agriculture",
                "Stocks"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3",
                "Gemini 1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathVista Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts": {
        "filename": "MathVista Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts.pdf",
        "analysis": {
            "benchmarks": [
                "MATHVISTA",
                "IQTest",
                "FunctionQA",
                "PaperQA"
            ],
            "base_models": [
                "GPT-4V",
                "Bard",
                "ChatGPT",
                "GPT-4",
                "Claude-2",
                "IDEFICS-9B",
                "mPLUG-OWL-LLaMA-7B",
                "miniGPT-4-LLaMA-2-7B",
                "LLaMA-Adapter-V2-7B",
                "InstructBLIP-Vicuna-7B",
                "LLaVA-LLaMA-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RL2 Reinforce Large Language Model to Assist Safe Reinforcement Learning for Energy Management of Active Distribution Networks": {
        "filename": "RL2 Reinforce Large Language Model to Assist Safe Reinforcement Learning for Energy Management of Active Distribution Networks.pdf",
        "analysis": {
            "benchmarks": [
                "custom test cases for active distribution networks (ADNs)"
            ],
            "base_models": [
                "GPT-based large language models (LLMs)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Expressive Power of Low-Rank Adaptation": {
        "filename": "The Expressive Power of Low-Rank Adaptation.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE benchmark"
            ],
            "base_models": [
                "GPT-4",
                "BERT",
                "RoBERTa",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Let GPT be a Math Tutor Teaching Math Word Problem Solvers with Customized Exercise Generation": {
        "filename": "Let GPT be a Math Tutor Teaching Math Word Problem Solvers with Customized Exercise Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MAWPS",
                "ASDiv-a",
                "SVAMP"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM (540B)",
                "RoBERTa-base",
                "RoBERTa-large"
            ]
        }
    },
    "Grammar Prompting for Domain-Specific Language Generation with Large Language Models": {
        "filename": "Grammar Prompting for Domain-Specific Language Generation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SMCalFlow",
                "Overnight",
                "GeoQuery",
                "PDDL planning",
                "SMILES-based molecule generation"
            ],
            "base_models": [
                "Codex-davinci-002",
                "GPT-3.5",
                "GPT-4",
                "PaLM 2-L"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TRANSAGENT An LLM-Based Multi-Agent System for Code Translation": {
        "filename": "TRANSAGENT An LLM-Based Multi-Agent System for Code Translation.pdf",
        "analysis": {
            "benchmarks": [
                "new code translation benchmark"
            ],
            "base_models": [
                "Deepseek-coder-6.7b-instruct (6.7 billion parameters)",
                "Llama-3-8B-Instruct (8 billion parameters)",
                "ChatGLM2-6b (6 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Should we be going MAD A Look at Multi-Agent Debate Strategies for LLMs": {
        "filename": "Should we be going MAD A Look at Multi-Agent Debate Strategies for LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "PubMedQA",
                "MMLU (clinical topics only)",
                "CosmosQA",
                "CIAR",
                "GPQA",
                "Chess"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "Mixtral 8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Action Contextualization Adaptive Task Planning and Action Tuning Using Large Language Models": {
        "filename": "Action Contextualization Adaptive Task Planning and Action Tuning Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom table-cleaning task"
            ],
            "base_models": [
                "GPT-4-1106-preview",
                "open-mixtral-8x22b",
                "Meta-Llama-3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Sketch A Toolkit for Streamlining LLM Operations": {
        "filename": "Sketch A Toolkit for Streamlining LLM Operations.pdf",
        "analysis": {
            "benchmarks": [
                "CoNLL-2003",
                "SemEval-2010 Task 8",
                "20 Newsgroup",
                "SemEval-2015 Task 12 (domain: hotels)",
                "DBPedia",
                "Medical NER"
            ],
            "base_models": [
                "LLaMA3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Attention Sorting Combats Recency Bias In Long Context Language Models": {
        "filename": "Attention Sorting Combats Recency Bias In Long Context Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SynthWiki"
            ],
            "base_models": [
                "Llama-2-7B-32k",
                "Llama-2-7B-32k-Instruct",
                "YaRN Llama-2-7B-64k",
                "WizardLM-tuned Code-Llama-7B",
                "GPT-3.5-turbo-16k",
                "Claude-2",
                "Claude-1-Instant"
            ]
        }
    },
    "Attention Heads of Large Language Models A Survey": {
        "filename": "Attention Heads of Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "IOI",
                "ToyMovieReview",
                "ToyMoodStory",
                "MMLU",
                "TruthfulQA"
            ],
            "base_models": [
                "GPT-2",
                "LLaMA",
                "InternLM",
                "Yi",
                "Gemma",
                "Mistral",
                "Qwen",
                "Pythia"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Arithmetic with Language Models from Memorization to Computation": {
        "filename": "Arithmetic with Language Models from Memorization to Computation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "T5",
                "GPT-2",
                "nanoGPT"
            ]
        }
    },
    "BOLAA Benchmarking and Orchestrating LLM-augmented Autonomous Agents": {
        "filename": "BOLAA Benchmarking and Orchestrating LLM-augmented Autonomous Agents.pdf",
        "analysis": {
            "benchmarks": [
                "WebShop",
                "HotPotQA with Wikipedia API"
            ],
            "base_models": [
                "fastchat-t5-3b",
                "vicuna-7b",
                "vicuna-13b",
                "vicuna-33b",
                "llama-2-7b",
                "llama-2-13b",
                "llama-2-70b",
                "mpt-7b-instruct",
                "mpt-30b-instruct",
                "xgen-8k-7b-instruct",
                "longchat-7b-16k",
                "longchat-13b-16k",
                "text-davinci-003",
                "gpt-3.5-turbo",
                "gpt-3.5-turbo-16k"
            ]
        }
    },
    "Preference Optimization for Reasoning with Pseudo Feedback": {
        "filename": "Preference Optimization for Reasoning with Pseudo Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "College Math",
                "LiveCodeBench"
            ],
            "base_models": [
                "Mathstral-7B",
                "Deepseek-coder-7B-v1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Large Language Models for Knowledge Engineering LLMKE A Case Study on Wikidata": {
        "filename": "Using Large Language Models for Knowledge Engineering LLMKE A Case Study on Wikidata.pdf",
        "analysis": {
            "benchmarks": [
                "ISWC 2023 LM-KBC Challenge dataset"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "Sirius Contextual Sparsity with Correction for Efficient LLMs": {
        "filename": "Sirius Contextual Sparsity with Correction for Efficient LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/DailyMail",
                "GSM8K",
                "HumanEval",
                "MMLU",
                "CSQA",
                "AQuA-RAT",
                "StrategyQA",
                "Date",
                "Sports",
                "MBPP+"
            ],
            "base_models": [
                "Llama-3-8B-Instruct",
                "Llama-3-70B-Instruct",
                "Llama-2-7B-Chat",
                "Llama-2-13B-Chat",
                "Llama-3-8B",
                "Llama-2-7B",
                "Llama-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mitigating Selection Bias with Node Pruning and Auxiliary Options": {
        "filename": "Mitigating Selection Bias with Node Pruning and Auxiliary Options.pdf",
        "analysis": {
            "benchmarks": [
                "ARC-Challenge",
                "MMLU-Redux",
                "CommonsenseQA"
            ],
            "base_models": [
                "Llama-3-8B-Instruct",
                "Mistral-7B-Instruct-v0.2",
                "Bloomz-7b1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "JPPO Joint Power and Prompt Optimization for Accelerated Large Language Model Services": {
        "filename": "JPPO Joint Power and Prompt Optimization for Accelerated Large Language Model Services.pdf",
        "analysis": {
            "benchmarks": [
                "MeetingBank-transcript dataset"
            ],
            "base_models": [
                "GPT-Neo 125M",
                "GPT-J 6B"
            ]
        }
    },
    "IDGen Item Discrimination Induced Prompt Generation for LLM Evaluation": {
        "filename": "IDGen Item Discrimination Induced Prompt Generation for LLM Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "SELF-INSTRUCT",
                "WizardLM",
                "Instruction Tuning with GPT-4",
                "Ours (hard seed data)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4 Turbo",
                "Wenxin 4 (ERNIE-Bot 4.0)",
                "Qwen (Qwen-Max)",
                "Claude 3",
                "Baichuan2-13B"
            ]
        }
    },
    "Large Language Models Are Zero-Shot Fuzzers Fuzzing Deep-Learning Libraries via Large Language Models": {
        "filename": "Large Language Models Are Zero-Shot Fuzzers Fuzzing Deep-Learning Libraries via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TensorFlow",
                "PyTorch"
            ],
            "base_models": [
                "Codex",
                "InCoder"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Telecom Language Models Must They Be Large": {
        "filename": "Telecom Language Models Must They Be Large.pdf",
        "analysis": {
            "benchmarks": [
                "TeleQnA"
            ],
            "base_models": [
                "GPT-3.5 (175 billion parameters)",
                "GPT-4 (rumored 1.76 trillion parameters)",
                "Phi-2 (2.7 billion parameters)"
            ]
        }
    },
    "Read Diagnose and Chat Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media": {
        "filename": "Read Diagnose and Chat Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media.pdf",
        "analysis": {
            "benchmarks": [
                "Twitter dataset",
                "Weibo dataset"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-3 (text-davinci-003)"
            ]
        }
    },
    "A survey on semantic processing techniques": {
        "filename": "A survey on semantic processing techniques.pdf",
        "analysis": {
            "benchmarks": [
                "SensEval-2",
                "SensEval-3"
            ],
            "base_models": [
                "BERT",
                "BiLSTM",
                "LSTM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HPC-GPT Integrating Large Language Model for High-Performance Computing": {
        "filename": "HPC-GPT Integrating Large Language Model for High-Performance Computing.pdf",
        "analysis": {
            "benchmarks": [
                "Data Race Benchmark (DRB)"
            ],
            "base_models": [
                "LLaMA-13B",
                "LLaMA2-13B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GTBench Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations": {
        "filename": "GTBench Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations.pdf",
        "analysis": {
            "benchmarks": [
                "GTBench"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Llama-2-70b-chat",
                "CodeLlama-34b-Instruct",
                "Llama-3-70b-Instruct",
                "Mistral-7b-Orca"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Explainable Evaluation Metrics for Machine Translation": {
        "filename": "Towards Explainable Evaluation Metrics for Machine Translation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-collaboration Code Generation via ChatGPT": {
        "filename": "Self-collaboration Code Generation via ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "MBPP",
                "HumanEval",
                "MBPP-ET",
                "HumanEval-ET",
                "APPS",
                "CoderEval"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents": {
        "filename": "Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Atari Learning Environments (ALE)",
                "HackAtari modified Pong environments"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Transfer Visual Prompt Generator across LLMs": {
        "filename": "Transfer Visual Prompt Generator across LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "COCO caption",
                "NoCaps",
                "VQAv2",
                "GQA",
                "OKVQA"
            ],
            "base_models": [
                "BLIP-2 OPT 2.7B",
                "BLIP-2 OPT 6.7B",
                "LLaMA",
                "Vicuna"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bias Testing and Mitigation in LLM-based Code Generation": {
        "filename": "Bias Testing and Mitigation in LLM-based Code Generation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "PALM-2-CodeChat-bison",
                "Claude-instant-1",
                "GPT-3.5-turbo",
                "GPT-4-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Detecting Multi-Parameter Constraint Inconsistencies in Python Data Science Libraries": {
        "filename": "Detecting Multi-Parameter Constraint Inconsistencies in Python Data Science Libraries.pdf",
        "analysis": {
            "benchmarks": [
                "Documentation constraint dataset containing 72 real-world constraints sourced from widely used data science libraries",
                "Mutation-based inconsistency dataset with 216 constraints generated through systematic mutations"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Prompting Techniques in LLMs": {
        "filename": "A Survey on Prompting Techniques in LLMs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175 billion parameters)",
                "PaLM (540 billion parameters)"
            ]
        }
    },
    "RARe Retrieval Augmented Retrieval with In-Context Examples": {
        "filename": "RARe Retrieval Augmented Retrieval with In-Context Examples.pdf",
        "analysis": {
            "benchmarks": [
                "BeIR",
                "RAR-b"
            ],
            "base_models": [
                "Llama-3",
                "LLM2Vec-Llama-3-8b-Supervised",
                "E5-Mistral-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Robots That Ask For Help Uncertainty Alignment for Large Language Model Planners": {
        "filename": "Robots That Ask For Help Uncertainty Alignment for Large Language Model Planners.pdf",
        "analysis": {
            "benchmarks": [
                "PyBullet simulator",
                "Hardware Multi-Step Tabletop Rearrangement",
                "Hardware Mobile Manipulation"
            ],
            "base_models": [
                "PaLM-2L",
                "PaLM-2L-IF",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InterPreT Interactive Predicate Learning from Language Feedback for Generalizable Task Planning": {
        "filename": "InterPreT Interactive Predicate Learning from Language Feedback for Generalizable Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "Simulated robot manipulation domains",
                "Real-world robot manipulation domains"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Large Language Model based Personal Information Extraction and Countermeasures": {
        "filename": "Evaluating Large Language Model based Personal Information Extraction and Countermeasures.pdf",
        "analysis": {
            "benchmarks": [
                "Synthetic dataset generated by GPT-4",
                "Celebrity dataset",
                "Physician dataset"
            ],
            "base_models": [
                "GPT-4 (1.5T)",
                "PaLM 2 (540B)",
                "Gemini",
                "GPT-3.5-Turbo (154B)",
                "Flan-UL2 (20B)",
                "Vicuna-13b-v1.3 (13B)",
                "Vicuna-7b-v1.3 (7B)",
                "Llama-2-7b-chat (7B)",
                "InternLM-Chat-7B (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Conditions for Length Generalization in Learning Reasoning Skills": {
        "filename": "Conditions for Length Generalization in Learning Reasoning Skills.pdf",
        "analysis": {
            "benchmarks": [
                "arithmetic in F7",
                "1-line addition",
                "3-line addition",
                "1-line multiplication"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ZoomEye Enhancing Multimodal LLMs with Human-Like Zooming Capabilities through Tree-Based Image Exploration": {
        "filename": "ZoomEye Enhancing Multimodal LLMs with Human-Like Zooming Capabilities through Tree-Based Image Exploration.pdf",
        "analysis": {
            "benchmarks": [
                "V*Bench",
                "HR-Bench"
            ],
            "base_models": [
                "LLaVA-v1.5-7B",
                "LLaVA-ov-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Talk2BEV Language-enhanced Birds-eye View Maps for Autonomous Driving": {
        "filename": "Talk2BEV Language-enhanced Birds-eye View Maps for Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "Talk2BEV-Bench",
                "NuScenes"
            ],
            "base_models": [
                "GPT-4",
                "BLIP-2",
                "MiniGPT-4",
                "InstructBLIP-2"
            ]
        }
    },
    "Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt Optimization": {
        "filename": "Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "ATLAS",
                "FED",
                "GSM8K",
                "CodeNet",
                "Education"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Mixtral-8x7B-v0.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MMHQA-ICL Multimodal In-context Learning for Hybrid Question Answering over Text Tables and Images": {
        "filename": "MMHQA-ICL Multimodal In-context Learning for Hybrid Question Answering over Text Tables and Images.pdf",
        "analysis": {
            "benchmarks": [
                "MultimodalQA"
            ],
            "base_models": [
                "LLaVA-13B",
                "DeBERTa-large",
                "GPT-3 (text-davinci-003)"
            ]
        }
    },
    "Writer-Defined AI Personas for On-Demand Feedback Generation": {
        "filename": "Writer-Defined AI Personas for On-Demand Feedback Generation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Neural Machine Translation for Code Generation": {
        "filename": "Neural Machine Translation for Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CodeContests",
                "NL2Bash"
            ],
            "base_models": [
                "GPT (Codex variant)",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies": {
        "filename": "Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies.pdf",
        "analysis": {
            "benchmarks": [
                "Ultimatum Game",
                "Garden Path Sentences",
                "Milgram Shock Experiment",
                "Wisdom of Crowds"
            ],
            "base_models": [
                "text-ada-001",
                "text-babbage-001",
                "text-curie-001",
                "text-davinci-001",
                "text-davinci-002",
                "text-davinci-003",
                "gpt-35-turbo (ChatGPT)",
                "gpt-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VideoAgent Long-form Video Understanding with Large Language Model as Agent": {
        "filename": "VideoAgent Long-form Video Understanding with Large Language Model as Agent.pdf",
        "analysis": {
            "benchmarks": [
                "EgoSchema",
                "NExT-QA"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting Large Language Model for Machine Translation A Case Study": {
        "filename": "Prompting Large Language Model for Machine Translation A Case Study.pdf",
        "analysis": {
            "benchmarks": [
                "FLORES",
                "WMT21",
                "Multi-Domain",
                "PDC"
            ],
            "base_models": [
                "GLM-130B (130B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Behavior Tree Generation using Large Language Models for Sequential Manipulation Planning with Human Instructions and Feedback": {
        "filename": "Behavior Tree Generation using Large Language Models for Sequential Manipulation Planning with Human Instructions and Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "Siemens Robot Assembly Challenge"
            ],
            "base_models": [
                "GPT-4",
                "LlaMA2-13B-Chat",
                "Mistral-7B"
            ]
        }
    },
    "Vision-Language Interpreter for Robot Task Planning": {
        "filename": "Vision-Language Interpreter for Robot Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "ProDG dataset"
            ],
            "base_models": [
                "GPT-4",
                "BLIP-2",
                "Grounding-DINO"
            ]
        }
    },
    "GFlowNet Fine-tuning for Diverse Correct Solutions in Mathematical Reasoning Tasks": {
        "filename": "GFlowNet Fine-tuning for Diverse Correct Solutions in Mathematical Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH500"
            ],
            "base_models": [
                "Llama3-8B"
            ]
        }
    },
    "MARS Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset": {
        "filename": "MARS Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset.pdf",
        "analysis": {
            "benchmarks": [
                "MARS"
            ],
            "base_models": [
                "RoBERTa-Base (211M)",
                "RoBERTa-Large (340M)",
                "DeBERTa-Base (214M)",
                "DeBERTa-Large (435M)",
                "GPT2-XL (1.5B)",
                "VERA (11B)",
                "Meta-LLaMa-2-7B",
                "Meta-LLaMa-2-13B",
                "Meta-LLaMa-2-70B",
                "Meta-LLaMa-3-8B",
                "Meta-LLaMa-3-70B",
                "Gemma-1.1-7B",
                "Falcon-7B",
                "Falcon-40B",
                "Mistral-7B",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Data Generation Perspective to the Mechanism of In-Context Learning": {
        "filename": "A Data Generation Perspective to the Mechanism of In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Joint Prompt Optimization of Stacked LLMs using Variational Inference": {
        "filename": "Joint Prompt Optimization of Stacked LLMs using Variational Inference.pdf",
        "analysis": {
            "benchmarks": [
                "BigBench-Hard (BBH)",
                "Mpqa",
                "Trec",
                "Subj",
                "Disaster",
                "Airline"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multimodal Web Navigation with Instruction-Finetuned Foundation Models": {
        "filename": "Multimodal Web Navigation with Instruction-Finetuned Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "MiniWoB++",
                "WebShop",
                "Mind2Web"
            ],
            "base_models": [
                "Flan-T5-Base (310M parameters)",
                "Flan-T5-XL",
                "ViT-B16",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CustomListener Text-Guided Responsive Interaction for User-Friendly Listening Head Generation": {
        "filename": "CustomListener Text-Guided Responsive Interaction for User-Friendly Listening Head Generation.pdf",
        "analysis": {
            "benchmarks": [
                "ViCo",
                "RealTalk"
            ],
            "base_models": [
                "GPT (size not specified)",
                "RoBERTa (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ACCORD Closing the Commonsense Measurability Gap": {
        "filename": "ACCORD Closing the Commonsense Measurability Gap.pdf",
        "analysis": {
            "benchmarks": [
                "ACCORD CSQA",
                "CommonsenseQA"
            ],
            "base_models": [
                "GPT-4o",
                "Llama-3-70B-Instruct",
                "Mixtral-8x22B-Instruct-v0.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification": {
        "filename": "Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification.pdf",
        "analysis": {
            "benchmarks": [
                "WOS",
                "DBpedia"
            ],
            "base_models": [
                "BERT-base-uncased",
                "T5-base"
            ]
        }
    },
    "UniGen A Unified Framework for Textual Dataset Generation Using Large Language Models": {
        "filename": "UniGen A Unified Framework for Textual Dataset Generation Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "TruthfulQA",
                "MMLU",
                "HellaSwag"
            ],
            "base_models": [
                "GPT-4",
                "Claude3-Opus",
                "Llama3-70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Knowledge Engineering using Large Language Models": {
        "filename": "Knowledge Engineering using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Crossing New Frontiers Knowledge-Augmented Large Language Model Prompting for Zero-Shot Text-Based De Novo Molecule Design": {
        "filename": "Crossing New Frontiers Knowledge-Augmented Large Language Model Prompting for Zero-Shot Text-Based De Novo Molecule Design.pdf",
        "analysis": {
            "benchmarks": [
                "ChEBI-20"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "GPT-3.0-text-davinci-003",
                "Google BARD",
                "DeBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Calibrating LLM-Based Evaluator": {
        "filename": "Calibrating LLM-Based Evaluator.pdf",
        "analysis": {
            "benchmarks": [
                "NewsRoom",
                "SummEval",
                "SFRES",
                "SFHOT",
                "QAGS-XSUM",
                "QAGS-CNN"
            ],
            "base_models": [
                "GPT-4-32K"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models": {
        "filename": "Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SEM dataset",
                "NEU-SDD",
                "CMI",
                "KTH-TIPS"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Google BARD",
                "DeBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning": {
        "filename": "Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "CARP",
                "GSM8K",
                "MATH",
                "Algebra",
                "Prealgebra",
                "Counting and Probability",
                "Number Theory",
                "GK-Cloze",
                "SAT-Math"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT",
                "text-davinci-002",
                "text-davinci-003",
                "claude-v1.3",
                "gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Out-of-distribution generalization via composition a lens through induction heads in Transformers": {
        "filename": "Out-of-distribution generalization via composition a lens through induction heads in Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "GSM8K-rand"
            ],
            "base_models": [
                "GPT-2 (124M parameters)",
                "Llama2-7B",
                "Llama3-70B",
                "Mistral-7B",
                "Falcon-7B",
                "Falcon2-11B",
                "OlMo-7B",
                "Gemma-7B",
                "Gemma2-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RARR Researching and Revising What Language Models Say Using Language Models": {
        "filename": "RARR Researching and Revising What Language Models Say Using Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions (NQ)",
                "StrategyQA (SQA)",
                "QReCC"
            ],
            "base_models": [
                "PaLM-540B",
                "GPT-3 text-davinci-002",
                "LaMDA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Planning Abilities of Large Language Models - A Critical Investigation": {
        "filename": "On the Planning Abilities of Large Language Models - A Critical Investigation.pdf",
        "analysis": {
            "benchmarks": [
                "International Planning Competition domains",
                "Blocksworld",
                "Logistics"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "InstructGPT-3.5",
                "InstructGPT-3",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PACE Improving Prompt with Actor-Critic Editing for Large Language Model": {
        "filename": "PACE Improving Prompt with Actor-Critic Editing for Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Instruction Induction",
                "Big-Bench"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "text-davinci-002",
                "text-davinci-003",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Shopping MMLU A Massive Multi-Task Online Shopping Benchmark for Large Language Models": {
        "filename": "Shopping MMLU A Massive Multi-Task Online Shopping Benchmark for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Shopping MMLU"
            ],
            "base_models": [
                "Claude-3 Sonnet",
                "Claude-2",
                "ChatGPT",
                "LLaMA3-70B-Instruct",
                "QWen1.5-72B",
                "LLaMA3-70B",
                "LLaMA2-70B-chat",
                "LLaMA2-70B",
                "Mixtral-8x7b",
                "QWen1.5-14B",
                "eCeLLM-L",
                "Vicuna-13B",
                "LLaMA2-13B-chat",
                "LLaMA2-13B",
                "LLaMA3-8B-Instruct",
                "LLaMA3-8B",
                "QWen1.5-7B",
                "eCeLLM-M",
                "Zephyr",
                "Mistral-7B-instruct",
                "Mistral-7B",
                "Vicuna-7B",
                "LLaMA2-7B-chat",
                "LLaMA2-7B",
                "QWen1.5-4B",
                "Phi-2",
                "eCeLLM-S"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Digital Avatars Framework Development and Their Evaluation": {
        "filename": "Digital Avatars Framework Development and Their Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "Crowd Vote (adaptation of Crowd Score)"
            ],
            "base_models": [
                "GPT-3.5-turbo-instruct"
            ]
        }
    },
    "LICO Large Language Models for In-Context Molecular Optimization": {
        "filename": "LICO Large Language Models for In-Context Molecular Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "Practical Molecular Optimization (PMO)"
            ],
            "base_models": [
                "Llama-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Geotechnical Parrot Tales GPT Harnessing Large Language Models in geotechnical engineering": {
        "filename": "Geotechnical Parrot Tales GPT Harnessing Large Language Models in geotechnical engineering.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4 (speculated to have 1 trillion parameters)",
                "GPT-3 (175 billion parameters)",
                "GPT-3.5-turbo"
            ]
        }
    },
    "Using Language Models For Knowledge Acquisition in Natural Language Reasoning Problems": {
        "filename": "Using Language Models For Knowledge Acquisition in Natural Language Reasoning Problems.pdf",
        "analysis": {
            "benchmarks": [
                "Smullyan's 'Ladies or Tigers?' puzzles",
                "Alpine Club puzzle"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ]
        }
    },
    "Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines": {
        "filename": "Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines.pdf",
        "analysis": {
            "benchmarks": [
                "Synthetic Patient Dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 Turbo",
                "LLaMA",
                "PaLM 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "High-throughput Biomedical Relation Extraction for Semi-Structured Web Articles Empowered by Large Language Models": {
        "filename": "High-throughput Biomedical Relation Extraction for Semi-Structured Web Articles Empowered by Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom benchmark dataset annotated by a medical expert"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Llama2-70B",
                "Llama2-13B",
                "Llama2-7B",
                "SOLAR-70B"
            ]
        }
    },
    "Towards Understanding Chain-of-Thought Prompting An Empirical Study of What Matters": {
        "filename": "Towards Understanding Chain-of-Thought Prompting An Empirical Study of What Matters.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "Bamboogle"
            ],
            "base_models": [
                "InstructGPT-175B (text-davinci-002)",
                "text-davinci-003",
                "PaLM",
                "Flan-PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "3DG A Framework for Using Generative AI for Handling Sparse Learner Performance Data From Intelligent Tutoring Systems": {
        "filename": "3DG A Framework for Using Generative AI for Handling Sparse Learner Performance Data From Intelligent Tutoring Systems.pdf",
        "analysis": {
            "benchmarks": [
                "AutoTutor ITS dataset from the Center for the Study of Adult Literacy (CSAL)"
            ],
            "base_models": [
                "GPT-4",
                "Generative Adversarial Network (GAN)"
            ]
        }
    },
    "ChartMimic Evaluating LMMs Cross-Modal Reasoning Capability via Chart-to-Code Generation": {
        "filename": "ChartMimic Evaluating LMMs Cross-Modal Reasoning Capability via Chart-to-Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "ChartMimic"
            ],
            "base_models": [
                "GPT-4V",
                "Claude-3-opus",
                "Phi-3-Vision",
                "LLaVA-Next-Vicuna-7B",
                "DeepSeek-VL-7B",
                "LLaVA-Next-Mistral-7B",
                "IDEFICS2-8B",
                "MiniCPM-Llama3-V2.5",
                "Qwen-VL-Chat",
                "LLaVA-Next-Vicuna-13B",
                "Cogvlm2-llama3-chat-19B",
                "InternVL-Chat-V1.5",
                "LLaVA-Next-Yi-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TurtleBench A Visual Programming Benchmark in Turtle Geometry": {
        "filename": "TurtleBench A Visual Programming Benchmark in Turtle Geometry.pdf",
        "analysis": {
            "benchmarks": [
                "TurtleBench"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini 1.5 Flash",
                "Llava-1.5-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts": {
        "filename": "A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts.pdf",
        "analysis": {
            "benchmarks": [
                "Torrance Tests of Creative Thinking (TTCT)"
            ],
            "base_models": [
                "ChatGPT 3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Flows Building Blocks of Reasoning and Collaborating AI": {
        "filename": "Flows Building Blocks of Reasoning and Collaborating AI.pdf",
        "analysis": {
            "benchmarks": [
                "Codeforces",
                "LeetCode"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reflexive Guidance Improving OoDD in Vision-Language Models via Self-Guided Image-Adaptive Concept Generation": {
        "filename": "Reflexive Guidance Improving OoDD in Vision-Language Models via Self-Guided Image-Adaptive Concept Generation.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet200",
                "CIFAR10",
                "NINCO",
                "SSB Hard",
                "iNaturalist",
                "Openimage-O"
            ],
            "base_models": [
                "GPT-4o",
                "Claude 3.5 Sonnet",
                "Gemini Pro 1.5",
                "LLaVA-v1.6 (Mistral-7B)",
                "GLM-4v-9B",
                "InternVL2-26B",
                "InternVL2-76B",
                "OpenCLIP (ViT-B-32)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aligning LLM Agents by Learning Latent Preference from User Edits": {
        "filename": "Aligning LLM Agents by Learning Latent Preference from User Edits.pdf",
        "analysis": {
            "benchmarks": [
                "summarization",
                "email writing"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CodePlan Unlocking Reasoning Potential in Large Langauge Models by Scaling Code-form Planning": {
        "filename": "CodePlan Unlocking Reasoning Potential in Large Langauge Models by Scaling Code-form Planning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "SVAMP",
                "Boolean Expression from Big-bench-hard (BBH)",
                "Coin Flipping",
                "Last Letter Concatenation",
                "Dyck Language from BBH",
                "AlpacaEval 1.0",
                "AlpacaEval 2.0",
                "MT-Bench",
                "HotpotQA",
                "MuSiQue",
                "ALFWorld"
            ],
            "base_models": [
                "Mistral-7B",
                "Llama-2-7B",
                "Llama-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLMs predict the convergence of Stochastic Gradient Descent": {
        "filename": "Can LLMs predict the convergence of Stochastic Gradient Descent.pdf",
        "analysis": {
            "benchmarks": [
                "toy Markov chains",
                "toy linear regression optimization problems in R2"
            ],
            "base_models": [
                "LLaMA2-13B",
                "LLaMA2-7B"
            ]
        }
    },
    "Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning": {
        "filename": "Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "Qwen1.5-72B",
                "GPT-4",
                "Llama-2 7B",
                "Mistral 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Brain in a Vat On Missing Pieces Towards Artificial General Intelligence in Large Language Models": {
        "filename": "Brain in a Vat On Missing Pieces Towards Artificial General Intelligence in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SAT",
                "GRE",
                "LSAT",
                "Gaokao",
                "USABO Semifinal Exam",
                "USNCO Local Section Exam",
                "Medical Knowledge Self-Assessment Program",
                "Codeforces",
                "AP Exams (Art History, Biology, Calculus BC, Chemistry, English Language and Composition, English Literature and Composition, Environmental Science, Macroeconomics, Microeconomics, Physics 2, Psychology, Statistics, US Government, US History, World History)",
                "AMC 10",
                "AMC 12",
                "Introductory Sommelier",
                "Certified Sommelier",
                "Advanced Sommelier",
                "Leetcode (easy, medium, hard)",
                "JEEBench",
                "VNHSGE"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "GPT-3",
                "LLaMA-6.7B",
                "Alpaca-6.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "QFMTS Generating Query-Focused Summaries over Multi-Table Inputs": {
        "filename": "QFMTS Generating Query-Focused Summaries over Multi-Table Inputs.pdf",
        "analysis": {
            "benchmarks": [
                "QFMTS dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama-2-7B",
                "BART-base (139M)",
                "BART-large (406M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Uncovering Autoregressive LLM Knowledge of Thematic Fit in Event Representation": {
        "filename": "Uncovering Autoregressive LLM Knowledge of Thematic Fit in Event Representation.pdf",
        "analysis": {
            "benchmarks": [
                "McRae et al. (1998)",
                "Padó et al. (2006)",
                "Ferretti et al. (2001) - Instrument",
                "Ferretti et al. (2001) - Location"
            ],
            "base_models": [
                "GPT-4-turbo",
                "CodeLlama2-70B-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Training microrobots to swim by a large language model": {
        "filename": "Training microrobots to swim by a large language model.pdf",
        "analysis": {
            "benchmarks": [
                "Purcell's three-link swimmer",
                "Najafi-Golestanian's three-sphere swimmer"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "InstructProtein Aligning Human and Protein Language via Knowledge Instruction": {
        "filename": "InstructProtein Aligning Human and Protein Language via Knowledge Instruction.pdf",
        "analysis": {
            "benchmarks": [
                "DeepLoc",
                "Gene Ontology (GO)",
                "Metal Ion Binding (MIB)"
            ],
            "base_models": [
                "OPT (1.3B)",
                "LLaMA (7.0B)",
                "Alpaca (7.0B)",
                "Galactica (1.3B)",
                "BioMedGPT (10B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Complexity-Based Theory of Compositionality": {
        "filename": "A Complexity-Based Theory of Compositionality.pdf",
        "analysis": {
            "benchmarks": [
                "COCO"
            ],
            "base_models": [
                "None specified"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PASS Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork": {
        "filename": "PASS Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR-10",
                "CIFAR-100",
                "Tiny-ImageNet",
                "Food101",
                "DTD",
                "StanfordCars"
            ],
            "base_models": [
                "ResNet-18",
                "ResNet-34",
                "ResNet-50",
                "VGG-16"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhance the Robustness of Text-Centric Multimodal Alignments": {
        "filename": "Enhance the Robustness of Text-Centric Multimodal Alignments.pdf",
        "analysis": {
            "benchmarks": [
                "PetFinder"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Mixtral8x7b"
            ]
        }
    },
    "LLMs can Find Mathematical Reasoning Mistakes by Pedagogical Chain-of-Thought": {
        "filename": "LLMs can Find Mathematical Reasoning Mistakes by Pedagogical Chain-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench Mistake",
                "PRM800K"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4 Turbo"
            ]
        }
    },
    "LLM Augmentations to support Analytical Reasoning over Multiple Documents": {
        "filename": "LLM Augmentations to support Analytical Reasoning over Multiple Documents.pdf",
        "analysis": {
            "benchmarks": [
                "Sign of the Crescent",
                "Atlantic Storm",
                "Manpad"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama-2",
                "Mistral-7B",
                "Gemma-2"
            ]
        }
    },
    "Improving Image Clustering with Artifacts Attenuation via Inference-Time Attention Engineering": {
        "filename": "Improving Image Clustering with Artifacts Attenuation via Inference-Time Attention Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "Tiny ImageNet",
                "CIFAR-100",
                "CIFAR-10",
                "STL-10"
            ],
            "base_models": [
                "Vision Transformer (ViT-S/14 distilled)",
                "Vision Transformer (ViT-B/14 distilled)",
                "Vision Transformer (ViT-L/14 distilled)",
                "Vision Transformer (ViT-g/14)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Ask more know better Reinforce-Learned Prompt Questions for Decision Making with Large Language Models": {
        "filename": "Ask more know better Reinforce-Learned Prompt Questions for Decision Making with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Overcooked",
                "FourRoom"
            ],
            "base_models": [
                "GPT-3.5",
                "Flan-T5 small"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM3 Large Language Model-based Task and Motion Planning with Motion Failure Reasoning": {
        "filename": "LLM3 Large Language Model-based Task and Motion Planning with Motion Failure Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "simulated tabletop box-packing task"
            ],
            "base_models": [
                "GPT-4 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WALL-E Embodied Robotic WAiter Load Lifting with Large Language Model": {
        "filename": "WALL-E Embodied Robotic WAiter Load Lifting with Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "real-world scenarios with 41 objects from categories including bottle, bowl, and mug"
            ],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "JiuZhang30 Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models": {
        "filename": "JiuZhang30 Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "MATH",
                "ASDiv",
                "CARP",
                "TabMWP",
                "AQuA",
                "SAT-Math",
                "MMLU-STEM",
                "OCW-Math"
            ],
            "base_models": [
                "GPT-4",
                "Qwen-72B",
                "Mistral-7B",
                "LLaMA-3-8B",
                "Mixtral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Language Models Explain Their Own Classification Behavior": {
        "filename": "Can Language Models Explain Their Own Classification Behavior.pdf",
        "analysis": {
            "benchmarks": [
                "ArticulateRules"
            ],
            "base_models": [
                "GPT-3 (350M to 175B)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Code as Policies Language Model Programs for Embodied Control": {
        "filename": "Code as Policies Language Model Programs for Embodied Control.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "RoboCodeGen"
            ],
            "base_models": [
                "GPT-3 (6.7B)",
                "InstructGPT (175B)",
                "Codex cushman",
                "Codex davinci"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploration with Principles for Diverse AI Supervision": {
        "filename": "Exploration with Principles for Diverse AI Supervision.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "Vicuna 7B",
                "Vicuna 13B",
                "Vicuna 30B",
                "LLaMA2 7B",
                "LLaMA2 13B",
                "GPT-4",
                "ChatGPT",
                "Claude2"
            ]
        }
    },
    "DrSpider A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness": {
        "filename": "DrSpider A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "Dr.Spider"
            ],
            "base_models": [
                "BERT-large",
                "RoBERTa-large",
                "T5-BASE",
                "T5-LARGE",
                "T5-3B",
                "OPT-66B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning by Self-Explaining": {
        "filename": "Learning by Self-Explaining.pdf",
        "analysis": {
            "benchmarks": [
                "MNIST",
                "ChestMNIST",
                "CLEVR-Hans3",
                "CUB-10",
                "VQA-X",
                "DecoyMNIST",
                "ColorMNIST"
            ],
            "base_models": [
                "CNN",
                "Neuro-Symbolic (NeSy)",
                "Vision-Language Model (VLM)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RePLan Robotic Replanning with Perception and Language Models": {
        "filename": "RePLan Robotic Replanning with Perception and Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Reasoning and Control (RC) benchmark"
            ],
            "base_models": [
                "GPT-4V",
                "Qwen-VL-Chat-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Right this way Can VLMs Guide Us to See More to Answer Questions": {
        "filename": "Right this way Can VLMs Guide Us to See More to Answer Questions.pdf",
        "analysis": {
            "benchmarks": [
                "VizWiz",
                "Directional Guidance dataset"
            ],
            "base_models": [
                "LLaVA-1.5 7b",
                "LLaVA-1.5 13b",
                "InstructBlip 7b",
                "GPT-4o",
                "CLIP (ViT-L-336px)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-Context Learning Unlocked for Diffusion Models": {
        "filename": "In-Context Learning Unlocked for Diffusion Models.pdf",
        "analysis": {
            "benchmarks": [
                "Brooks et al. dataset",
                "ControlNet example images",
                "DreamBooth data benchmark"
            ],
            "base_models": [
                "Stable Diffusion 'v1.5'",
                "ControlNet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Revisiting Conversation Discourse for Dialogue Disentanglement": {
        "filename": "Revisiting Conversation Discourse for Dialogue Disentanglement.pdf",
        "analysis": {
            "benchmarks": [
                "Ubuntu IRC",
                "Movie Dialogue"
            ],
            "base_models": [
                "BERT (base, unspecified size)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Positional Description Matters for Transformers Arithmetic": {
        "filename": "Positional Description Matters for Transformers Arithmetic.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset for arithmetic tasks"
            ],
            "base_models": [
                "GPT-4",
                "GPT2-small (124M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Ground-A-Score Scaling Up the Score Distillation for Multi-Attribute Editing": {
        "filename": "Ground-A-Score Scaling Up the Score Distillation for Multi-Attribute Editing.pdf",
        "analysis": {
            "benchmarks": [
                "Visual Genome"
            ],
            "base_models": [
                "StableDiffusion 1.5",
                "GPT-4 Vision"
            ]
        }
    },
    "Progressive Translation Improving Domain Robustness of Neural Machine Translation with Intermediate Sequences": {
        "filename": "Progressive Translation Improving Domain Robustness of Neural Machine Translation with Intermediate Sequences.pdf",
        "analysis": {
            "benchmarks": [
                "IWSLT'14 German-English",
                "OPUS German-English",
                "Allegra German-Romansh"
            ],
            "base_models": [
                "Transformer"
            ]
        }
    },
    "Checker Bug Detection and Repair in Deep Learning Libraries": {
        "filename": "Checker Bug Detection and Repair in Deep Learning Libraries.pdf",
        "analysis": {
            "benchmarks": [
                "TensorFlow",
                "PyTorch",
                "JAX"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MvP Multi-view Prompting Improves Aspect Sentiment Tuple Prediction": {
        "filename": "MvP Multi-view Prompting Improves Aspect Sentiment Tuple Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "Rest15",
                "Rest16",
                "Restaurant-ACOS",
                "Laptop-ACOS",
                "ASTE (R14)",
                "ASTE (R15)",
                "ASTE (R16)",
                "TASD (R14)",
                "TASD (R15)",
                "TASD (R16)"
            ],
            "base_models": [
                "T5-BASE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Applications of Generative AI in Healthcare algorithmic ethical legal and societal considerations": {
        "filename": "Applications of Generative AI in Healthcare algorithmic ethical legal and societal considerations.pdf",
        "analysis": {
            "benchmarks": [
                "Med-HALT",
                "MultiMedQA"
            ],
            "base_models": [
                "GPT-3",
                "FlanPaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Online Training of Large Language Models Learn while chatting": {
        "filename": "Online Training of Large Language Models Learn while chatting.pdf",
        "analysis": {
            "benchmarks": [
                "Tool invocation data format from Sun et al. (2023)"
            ],
            "base_models": [
                "Llama2-7b-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Human Vision The Role of Large Vision Language Models in Microscope Image Analysis": {
        "filename": "Beyond Human Vision The Role of Large Vision Language Models in Microscope Image Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "NFFA-Europe - 100% SEM Dataset",
                "BBBC005"
            ],
            "base_models": [
                "ChatGPT-4",
                "Gemini",
                "LLaVA (CLIP and Llama-2)",
                "Segment Anything Model (SAM)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ToolACE Winning the Points of LLM Function Calling": {
        "filename": "ToolACE Winning the Points of LLM Function Calling.pdf",
        "analysis": {
            "benchmarks": [
                "Berkeley Function-Calling Leaderboard"
            ],
            "base_models": [
                "LLaMA-3.1-8B-Instruct",
                "Qwen-1.5-7B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "List Items One by One A New Data Source and Learning Paradigm for Multimodal LLMs": {
        "filename": "List Items One by One A New Data Source and Learning Paradigm for Multimodal LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "POPE",
                "MME",
                "SEED-Bench",
                "LLaVA-Bench",
                "MM-Vet"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA-1.5",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TaskWeaver A Code-First Agent Framework": {
        "filename": "TaskWeaver A Code-First Agent Framework.pdf",
        "analysis": {
            "benchmarks": [
                "Eval-Cases",
                "DS-1000",
                "InfiAgent-DABench",
                "DSEval"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Faithful Chain-of-Thought Large Language Models are Bridging Reasoners": {
        "filename": "Towards Faithful Chain-of-Thought Large Language Models are Bridging Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "AQuA",
                "GSM8K",
                "WinoGrande",
                "SocialIQA",
                "ProofWriter",
                "PronotoQA"
            ],
            "base_models": [
                "Llama2-13B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fine-grained Analysis of In-context Linear Estimation Data Architecture and Beyond": {
        "filename": "Fine-grained Analysis of In-context Linear Estimation Data Architecture and Beyond.pdf",
        "analysis": {
            "benchmarks": [
                "Retrieval Augmented Generation (RAG)",
                "Task-feature alignment"
            ],
            "base_models": [
                "Linear Attention",
                "H3 (State-Space Model)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Growing from Exploration A self-exploring framework for robots based on foundation models": {
        "filename": "Growing from Exploration A self-exploring framework for robots based on foundation models.pdf",
        "analysis": {
            "benchmarks": [
                "BLOCKS WOLD",
                "RLBench"
            ],
            "base_models": [
                "GPT-4",
                "Llama 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Closer Look at Reward Decomposition for High-Level Robotic Explanations": {
        "filename": "A Closer Look at Reward Decomposition for High-Level Robotic Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "Ravens benchmark",
                "Airsim Blocks environment"
            ],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "Explicit Planning Helps Language Models in Logical Reasoning": {
        "filename": "Explicit Planning Helps Language Models in Logical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Entailment Bank",
                "PrOntoQA",
                "QASC"
            ],
            "base_models": [
                "T5-small (60M)",
                "GPT-3.5",
                "DeBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models": {
        "filename": "Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CURE"
            ],
            "base_models": [
                "BLIP-2",
                "BLIP-2-OPT 6.7b",
                "BLIP-2-T5 xl",
                "InstructBLIP-T5 xl",
                "LLaVA 13b",
                "miniGPT-4 13b",
                "OFA-Large",
                "OFA-Huge",
                "GPT-3.5-Turbo-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Survey of Natural Language Processing for Education Taxonomy Systematic Review and Future Trends": {
        "filename": "Survey of Natural Language Processing for Education Taxonomy Systematic Review and Future Trends.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "RACE",
                "SciQ",
                "ASAP",
                "TOEFL 11",
                "Lang-8",
                "CoNLL-2014",
                "BEA-2019",
                "Defects4J",
                "ManyBugs",
                "IntroClass",
                "QuixBugs",
                "Bugs2Fix",
                "CodeReview"
            ],
            "base_models": [
                "BERT",
                "GPT-3",
                "BART",
                "T5",
                "CodeBERT",
                "CuBERT",
                "GraphCodeBERT",
                "UniXcoder",
                "PLBART",
                "CodeT5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GRID A Platform for General Robot Intelligence Development": {
        "filename": "GRID A Platform for General Robot Intelligence Development.pdf",
        "analysis": {
            "benchmarks": [
                "AirGen simulator"
            ],
            "base_models": [
                "GPT-4",
                "LLaVa",
                "GroundingDINO",
                "GroundedSAM",
                "MIDAS",
                "DPVO",
                "TAPIR",
                "Optical Expansion",
                "BLIP-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EMOTION Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning": {
        "filename": "EMOTION Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GR-1 humanoid robotic hardware from Fourier"
            ],
            "base_models": [
                "GPT-4o (gpt-4o-2024-05-13)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FanCric  Multi-Agentic Framework for Crafting Fantasy 11 Cricket Teams": {
        "filename": "FanCric  Multi-Agentic Framework for Crafting Fantasy 11 Cricket Teams.pdf",
        "analysis": {
            "benchmarks": [
                "Dream11 contest dataset"
            ],
            "base_models": [
                "GPT-4o-mini",
                "GPT-4o"
            ]
        }
    },
    "LLMCad Fast and Scalable On-device Large Language Model Inference": {
        "filename": "LLMCad Fast and Scalable On-device Large Language Model Inference.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/Daily",
                "Wikitext",
                "iwlt2017",
                "wmt14",
                "wmt22",
                "SQuAD",
                "TruthfulQA",
                "Parrot"
            ],
            "base_models": [
                "GPT2 (0.14B)",
                "GPT2-Large (0.8B)",
                "T5-Small (0.06B)",
                "T5-Base (0.22B)",
                "T5-Large (0.73B)",
                "mT5-Small (0.3B)",
                "mT5-Base (0.58B)",
                "mT5-Large (1.2B)",
                "Bart",
                "Vicuna",
                "LLaMa2",
                "LLaMa-7B",
                "LLaMa-13B",
                "LLaMa-33B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Elicitron An LLM Agent-Based Simulation Framework for Design Requirements Elicitation": {
        "filename": "Elicitron An LLM Agent-Based Simulation Framework for Design Requirements Elicitation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathCoder Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning": {
        "filename": "MathCoder Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "SVAMP",
                "Mathematics",
                "SimulEq"
            ],
            "base_models": [
                "Llama-2 (7B, 13B, 70B)",
                "CodeLlama (7B, 13B, 34B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models in Mental Health Care a Scoping Review": {
        "filename": "Large Language Models in Mental Health Care a Scoping Review.pdf",
        "analysis": {
            "benchmarks": [
                "SMHD",
                "D4"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA-2",
                "Alpaca/FLAN-T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Explainable Decisions in Dynamic Digital Twins": {
        "filename": "Large Language Models for Explainable Decisions in Dynamic Digital Twins.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4-turbo-2024-04-09"
            ]
        }
    },
    "Can LLMs Capture Human Preferences": {
        "filename": "Can LLMs Capture Human Preferences.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5 (175 billion parameters)",
                "GPT-4 (1.7 trillion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On Memorization of Large Language Models in Logical Reasoning": {
        "filename": "On Memorization of Large Language Models in Logical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Knights and Knaves (K&K) puzzles"
            ],
            "base_models": [
                "Llama3-8B",
                "GPT4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FinTruthQA A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure": {
        "filename": "FinTruthQA A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure.pdf",
        "analysis": {
            "benchmarks": [
                "FinTruthQA"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "FinBERT",
                "Mengzi-fin",
                "DKPLM",
                "SBERT-nli",
                "RoBERTa-extractive-qa",
                "BERT (Large)",
                "GPT-4",
                "LLaMA-3.1",
                "Qwen2",
                "Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Performance of ChatGPT on the test of understanding graphs in kinematics": {
        "filename": "Performance of ChatGPT on the test of understanding graphs in kinematics.pdf",
        "analysis": {
            "benchmarks": [
                "Test of Understanding Graphs in Kinematics (TUG-K)"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instant Soup Cheap Pruning Ensembles in A Single Pass Can Draw Lottery Tickets from Large Models": {
        "filename": "Instant Soup Cheap Pruning Ensembles in A Single Pass Can Draw Lottery Tickets from Large Models.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR-10",
                "MNIST",
                "SVHN",
                "Cars",
                "GTSRB",
                "CIFAR-100",
                "MNLI",
                "QNLI",
                "QQP",
                "SST",
                "STS-B",
                "WNLI",
                "MPRC",
                "RTS",
                "SST-2",
                "CoLA"
            ],
            "base_models": [
                "CLIP (ViT-B32)",
                "BERT (BASE)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Emergence of Hidden Capabilities Exploring Learning Dynamics in Concept Space": {
        "filename": "Emergence of Hidden Capabilities Exploring Learning Dynamics in Concept Space.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic toy datasets"
            ],
            "base_models": [
                "text-to-image diffusion models"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "R-CoT Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models": {
        "filename": "R-CoT Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models.pdf",
        "analysis": {
            "benchmarks": [
                "MathVista",
                "GeoQA"
            ],
            "base_models": [
                "GPT-4o",
                "LLaVA",
                "Qwen",
                "InternVL",
                "Mini-Monkey",
                "ERNIE Bot 4.0"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LiveIdeaBench Evaluating LLMs Scientific Creativity and Idea Generation with Minimal Context": {
        "filename": "LiveIdeaBench Evaluating LLMs Scientific Creativity and Idea Generation with Minimal Context.pdf",
        "analysis": {
            "benchmarks": [
                "LiveIdeaBench"
            ],
            "base_models": [
                "QwQ-32B-preview",
                "o1-preview",
                "GPT-4o-2024-11-20",
                "o1-mini",
                "GPT-4o-mini",
                "Claude-3.5-sonnet",
                "Claude-3.5-haiku",
                "Gemini-pro-1.5",
                "Gemini-2.0-flash-exp",
                "Mistral-large-2411",
                "Deepseek-chat",
                "Llama variants",
                "Qwen models",
                "Nova-pro-v1",
                "Step-2-16k",
                "Grok-2-1212"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GraphLLM Boosting Graph Reasoning Ability of Large Language Model": {
        "filename": "GraphLLM Boosting Graph Reasoning Ability of Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Substructure Counting",
                "Maximum Triplet Sum",
                "Shortest Path",
                "Bipartite Graph Matching"
            ],
            "base_models": [
                "OPT-2.7B",
                "LLaMA2-7B",
                "LLaMA2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Sketching for Large Language Models": {
        "filename": "Prompt Sketching for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AQuA",
                "StrategyQA",
                "GSM8K",
                "Tracking Shuffled Objects",
                "Matrix Shapes",
                "Date Understanding",
                "Information Essentiality",
                "Multistep Arithmetic"
            ],
            "base_models": [
                "text-davinci-003 (175B)",
                "Llama-2 Chat (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WebCanvas Benchmarking Web Agents in Online Environments": {
        "filename": "WebCanvas Benchmarking Web Agents in Online Environments.pdf",
        "analysis": {
            "benchmarks": [
                "Mind2Web-Live"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude-3-Opus",
                "Gemini-Pro",
                "DeepSeek-V2",
                "Mixtral-8x22B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tailored-LLaMA Optimizing Few-Shot Learning in Pruned LLaMA Models with Task-Specific Prompts": {
        "filename": "Tailored-LLaMA Optimizing Few-Shot Learning in Pruned LLaMA Models with Task-Specific Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "PIQA",
                "HellaSwag",
                "WinoGrande",
                "ARC-easy",
                "ARC-challenge",
                "OpenbookQA",
                "WikiText2",
                "PTB"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-5B",
                "LLaMA-4B"
            ]
        }
    },
    "Large Language Models Are Zero-Shot Time Series Forecasters": {
        "filename": "Large Language Models Are Zero-Shot Time Series Forecasters.pdf",
        "analysis": {
            "benchmarks": [
                "Darts",
                "Monash",
                "Informer"
            ],
            "base_models": [
                "GPT-3",
                "LLaMA-2 70B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The BrowserGym Ecosystem for Web Agent Research": {
        "filename": "The BrowserGym Ecosystem for Web Agent Research.pdf",
        "analysis": {
            "benchmarks": [
                "MiniWoB",
                "WebArena",
                "VisualWebArena",
                "WorkArena L1",
                "WorkArena L2",
                "WorkArena L3",
                "WebLINX",
                "AssistantBench"
            ],
            "base_models": [
                "GPT-4o",
                "Claude 3.5 Sonnet",
                "Llama-3.1 70B",
                "Llama-3.1 405B",
                "o1 Mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Machine Psychology": {
        "filename": "Machine Psychology.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-bench",
                "Abstraction and Reasoning Challenge"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CodeTransOcean A Comprehensive Multilingual Benchmark for Code Translation": {
        "filename": "CodeTransOcean A Comprehensive Multilingual Benchmark for Code Translation.pdf",
        "analysis": {
            "benchmarks": [
                "MultilingualTrans",
                "NicheTrans",
                "LLMTrans",
                "DLTrans"
            ],
            "base_models": [
                "ChatGPT",
                "CodeT5+ (220M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PathLDM Text conditioned Latent Diffusion Model for Histopathology": {
        "filename": "PathLDM Text conditioned Latent Diffusion Model for Histopathology.pdf",
        "analysis": {
            "benchmarks": [
                "TCGA-BRCA"
            ],
            "base_models": [
                "Stable Diffusion",
                "GPT-3.5-turbo"
            ]
        }
    },
    "Federated Learning in Practice Reflections and Projections": {
        "filename": "Federated Learning in Practice Reflections and Projections.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "PaLM-2",
                "LLaMA-3"
            ]
        }
    },
    "Automated Text Scoring in the Age of Generative AI for the GPU-poor": {
        "filename": "Automated Text Scoring in the Age of Generative AI for the GPU-poor.pdf",
        "analysis": {
            "benchmarks": [
                "ASAP Automated Essay Scoring",
                "ASAP Automated Short Answer Scoring"
            ],
            "base_models": [
                "GPT-4",
                "Claude",
                "Llama-3-8B-Instruct (8.03B)",
                "Mistral v0.2-Instuct (7.24B)",
                "Gemma 1.1-Instruct (8.54B)",
                "Phi-3-7B-Instruct (3.82B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Agent-FLAN Designing Data and Methods of Effective Agent Tuning for Large Language Models": {
        "filename": "Agent-FLAN Designing Data and Methods of Effective Agent Tuning for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "SciWorld",
                "WebArena",
                "T-Eval",
                "Agent-H"
            ],
            "base_models": [
                "Llama2-7B"
            ]
        }
    },
    "DeCoRe Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations": {
        "filename": "DeCoRe Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations.pdf",
        "analysis": {
            "benchmarks": [
                "XSum",
                "MemoTrap",
                "NQ-Open",
                "NQ-Swap",
                "TriviaQA",
                "PopQA",
                "TruthfulQA",
                "MuSiQue"
            ],
            "base_models": [
                "Llama3-8B-Instruct",
                "Llama3-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-Context Learning and Fine-Tuning GPT for Argument Mining": {
        "filename": "In-Context Learning and Fine-Tuning GPT for Argument Mining.pdf",
        "analysis": {
            "benchmarks": [
                "Persuasive Essays (PE) dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ]
        }
    },
    "Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs": {
        "filename": "Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "FMereani XSS Dataset",
                "SOFIA SQLi Dataset"
            ],
            "base_models": [
                "GPT-4T",
                "GPT-4",
                "Opus",
                "Sonnet",
                "PaLM",
                "Llama",
                "Mixtral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NegativePrompt Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli": {
        "filename": "NegativePrompt Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli.pdf",
        "analysis": {
            "benchmarks": [
                "Instruction Induction",
                "BIG-Bench",
                "TruthfulQA"
            ],
            "base_models": [
                "Flan-T5-Large",
                "Vicuna",
                "Llama 2",
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Refining the Responses of LLMs by Themselves": {
        "filename": "Refining the Responses of LLMs by Themselves.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4"
            ]
        }
    },
    "Causal Reasoning and Large Language Models Opening a New Frontier for Causality": {
        "filename": "Causal Reasoning and Large Language Models Opening a New Frontier for Causality.pdf",
        "analysis": {
            "benchmarks": [
                "Tübingen benchmark",
                "Neuropathic pain diagnosis benchmark"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving": {
        "filename": "Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "nuScenes"
            ],
            "base_models": [
                "LLaMA",
                "LLaVA",
                "Vicuna",
                "Merlin"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval": {
        "filename": "Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval"
            ],
            "base_models": [
                "StarCoderBase-1B",
                "StarCoderBase-7B",
                "StarCoderBase-15.5B",
                "StarCoder2-7B",
                "Mistral-7B-v0.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Large to Tiny Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision": {
        "filename": "From Large to Tiny Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision.pdf",
        "analysis": {
            "benchmarks": [
                "Math23K",
                "Weak12K"
            ],
            "base_models": [
                "ChatGPT (parameter size not specified)",
                "RoFormer-Small (15M)",
                "T5-small (95M)",
                "T5-Base (250M)"
            ]
        }
    },
    "Cohesive Conversations Enhancing Authenticity in Multi-Agent Simulated Dialogues": {
        "filename": "Cohesive Conversations Enhancing Authenticity in Multi-Agent Simulated Dialogues.pdf",
        "analysis": {
            "benchmarks": [
                "ONEDAYLIFE"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HEIE MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator": {
        "filename": "HEIE MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator.pdf",
        "analysis": {
            "benchmarks": [
                "RichHF-18K",
                "AbHuman",
                "Expl-AIGI-Eval"
            ],
            "base_models": [
                "InternVL-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Human-like Autonomous Driving A Survey": {
        "filename": "Large Language Models for Human-like Autonomous Driving A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "CARLA",
                "LimSim++"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "LLaMA-7B"
            ]
        }
    },
    "Language Modeling Is Compression": {
        "filename": "Language Modeling Is Compression.pdf",
        "analysis": {
            "benchmarks": [
                "enwik9",
                "ImageNet",
                "LibriSpeech"
            ],
            "base_models": [
                "Llama 2 (7B)",
                "Chinchilla (1B)",
                "Chinchilla (7B)",
                "Chinchilla (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PRefLexOR Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking": {
        "filename": "PRefLexOR Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Llama-3.2-3B-Instruct (3 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChemAlgebra Algebraic Reasoning on Chemical Reactions": {
        "filename": "ChemAlgebra Algebraic Reasoning on Chemical Reactions.pdf",
        "analysis": {
            "benchmarks": [
                "CHEM ALGEBRA",
                "USPTO-MIT",
                "USPTO-BAL",
                "USPTO-T1",
                "USPTO-T2"
            ],
            "base_models": [
                "Molecular Transformer",
                "Augmented Transformer",
                "Chemformer",
                "Graph2SMILES (DGCN)",
                "Graph2SMILES (DGAT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-Level Explanations for Generative Language Models": {
        "filename": "Multi-Level Explanations for Generative Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "XSUM",
                "CNN/Daily Mail (CNN/DM)",
                "SQuAD"
            ],
            "base_models": [
                "DistilBart (306M)",
                "Flan-UL2 (20B)",
                "Flan-T5-Large (770M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NaturalProver Grounded Mathematical Proof Generation with Language Models": {
        "filename": "NaturalProver Grounded Mathematical Proof Generation with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "NATURAL PROOFS"
            ],
            "base_models": [
                "GPT-3 (Curie)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting": {
        "filename": "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "HEADQA",
                "MedMCQA",
                "MMLU-professional medicine"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "BioLinkBert-Base",
                "BioLinkBert-Large",
                "BioMedLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Grounding and Evaluation for Large Language Models Practical Challenges and Lessons Learned Survey": {
        "filename": "Grounding and Evaluation for Large Language Models Practical Challenges and Lessons Learned Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Code Review Automation Strengths and Weaknesses of the State of the Art": {
        "filename": "Code Review Automation Strengths and Weaknesses of the State of the Art.pdf",
        "analysis": {
            "benchmarks": [
                "Java test datasets from T5CR, COMMENT FINDER, and CODEREVIEWER"
            ],
            "base_models": [
                "T5 (pre-trained)",
                "COMMENT FINDER (IR-based)",
                "CODEREVIEWER (T5 pre-trained)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoRD An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models": {
        "filename": "AutoRD An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "RareDis2023"
            ],
            "base_models": [
                "GPT-4",
                "BioClinicalBERT"
            ]
        }
    },
    "Apple Intelligence Foundation Language Models": {
        "filename": "Apple Intelligence Foundation Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HELM MMLU v1.5.0",
                "GSM8K"
            ],
            "base_models": [
                "AFM-on-device (~3 billion parameters)",
                "AFM-server (larger server-based model)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Phenomenal Yet Puzzling Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement": {
        "filename": "Phenomenal Yet Puzzling Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement.pdf",
        "analysis": {
            "benchmarks": [
                "ACRE",
                "MiniSCAN",
                "List Functions",
                "MiniARC"
            ],
            "base_models": [
                "GPT-4 (gpt-4-0613)",
                "GPT-3.5 (gpt-3.5-turbo-0613)",
                "Claude-2",
                "LLaMA2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DiaSynth Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications": {
        "filename": "DiaSynth Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications.pdf",
        "analysis": {
            "benchmarks": [
                "DialogSum",
                "SAMSum"
            ],
            "base_models": [
                "Phi-3",
                "InternLM-2.5",
                "LLaMA-3",
                "GPT-4o"
            ]
        }
    },
    "LLM in the Shell Generative Honeypots": {
        "filename": "LLM in the Shell Generative Honeypots.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-turbo-16k"
            ]
        }
    },
    "Prompt Engineering Through the Lens of Optimal Control": {
        "filename": "Prompt Engineering Through the Lens of Optimal Control.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "xFinder Robust and Pinpoint Answer Extraction for Large Language Models": {
        "filename": "xFinder Robust and Pinpoint Answer Extraction for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "KeyAnswer Finder (KAF) dataset",
                "CommonsenseQA",
                "ARC-challenge",
                "ARC-easy",
                "GSM8K",
                "MATH",
                "MetaMathQA",
                "MultiArith",
                "OpenbookQA",
                "QNLI",
                "SIQA",
                "Subj",
                "TREC",
                "WiC"
            ],
            "base_models": [
                "xFinder (500M)",
                "Qwen1.5-0.5B",
                "Qwen1.5-1.8B",
                "Gemma-7B",
                "ChatGLM3-6B-base",
                "Llama-8B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "E-ICL Enhancing Fine-Grained Emotion Recognition through the Lens of Prototype Theory": {
        "filename": "E-ICL Enhancing Fine-Grained Emotion Recognition through the Lens of Prototype Theory.pdf",
        "analysis": {
            "benchmarks": [
                "EDOS",
                "Empathetic-Dialogues",
                "EmpatheticIntent",
                "GoEmotions"
            ],
            "base_models": [
                "ChatGPT-turbo",
                "Claude-haiku"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AtomR Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning": {
        "filename": "AtomR Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "WikiMultihop",
                "BlendQA"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CATfOOD Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration": {
        "filename": "CATfOOD Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "SQuAD-Adversarial",
                "TriviaQA",
                "HotpotQA",
                "Natural Questions (NQ)",
                "NewsQA",
                "BioASQ"
            ],
            "base_models": [
                "RoBERTa-base",
                "GPT-JT (6B)",
                "GPT-NeoxT (20B)",
                "LLaMA (13B)",
                "Alpaca (based on LLaMA 13B)",
                "Flan-T5-xxl (11B)",
                "Flan-UL2 (20B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Insert-expansions for Tool-enabled Conversational Agents": {
        "filename": "Insert-expansions for Tool-enabled Conversational Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-turbo-0301"
            ]
        }
    },
    "Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models": {
        "filename": "Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 44,340 incidents from Microsoft"
            ],
            "base_models": [
                "GPT-3.0",
                "GPT-3.5 (Code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Edge-Case Fuzzers Testing Deep Learning Libraries via FuzzGPT": {
        "filename": "Large Language Models are Edge-Case Fuzzers Testing Deep Learning Libraries via FuzzGPT.pdf",
        "analysis": {
            "benchmarks": [
                "PyTorch",
                "TensorFlow"
            ],
            "base_models": [
                "Codex",
                "CodeGen",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Counterfactual Causal Inference in Natural Language with Large Language Models": {
        "filename": "Counterfactual Causal Inference in Natural Language with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Cladder"
            ],
            "base_models": [
                "LLaMA-3.1",
                "GPT-3.5",
                "GPT-4 (version 1106)",
                "GPT-4o",
                "GPT-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Valuation Based on Shapley Values": {
        "filename": "Prompt Valuation Based on Shapley Values.pdf",
        "analysis": {
            "benchmarks": [
                "Stanford Sentiment Treebank (SST2)",
                "AQuA",
                "Bigbench Date"
            ],
            "base_models": [
                "BERT-base (110M)",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ImProver Agent-Based Automated Proof Optimization": {
        "filename": "ImProver Agent-Based Automated Proof Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "Mathematics in Lean (MIL)",
                "Compfiles",
                "Mathlib"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MOSAIC A Modular System for Assistive and Interactive Cooking": {
        "filename": "MOSAIC A Modular System for Assistive and Interactive Cooking.pdf",
        "analysis": {
            "benchmarks": [
                "Collaborative Manipulation Dataset (CoMaD)"
            ],
            "base_models": [
                "GPT-4",
                "OwlViT",
                "CLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "S-Agents Self-organizing Agents in Open-ended Environments": {
        "filename": "S-Agents Self-organizing Agents in Open-ended Environments.pdf",
        "analysis": {
            "benchmarks": [
                "Minecraft environment"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo-16k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Contribution of Knowledge in Visiolinguistic Learning A Survey on Tasks and Challenges": {
        "filename": "The Contribution of Knowledge in Visiolinguistic Learning A Survey on Tasks and Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "OK-VQA",
                "K-VQA"
            ],
            "base_models": [
                "BERT",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AGIEval A Human-Centric Benchmark for Evaluating Foundation Models": {
        "filename": "AGIEval A Human-Centric Benchmark for Evaluating Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "SAT",
                "LSAT",
                "Chinese College Entrance Exam (Gaokao)",
                "Lawyer Qualification Test",
                "Civil Service Exam",
                "Math Competition",
                "GMAT",
                "GRE",
                "LogiQA",
                "JEC-QA",
                "AQuA-RAT",
                "MATH"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "Text-Davinci-003",
                "Vicuna-13B (based on LLaMA)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hyperion Unveiling DApp Inconsistencies using LLM and Dataflow-Guided Symbolic Execution": {
        "filename": "Hyperion Unveiling DApp Inconsistencies using LLM and Dataflow-Guided Symbolic Execution.pdf",
        "analysis": {
            "benchmarks": [
                "ground truth dataset of 54 DApps",
                "large-scale dataset of 835 DApps from DappBay and DappRadar"
            ],
            "base_models": [
                "LLaMA2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Measuring Representational Similarity of Large Language Models": {
        "filename": "Towards Measuring Representational Similarity of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Winogrande",
                "HumanEval"
            ],
            "base_models": [
                "RedPajama (7B)",
                "Bloom (7B)",
                "Falcon (7B)",
                "Galactica (7B)",
                "GPT-J (6B)",
                "Llama (7B)",
                "MPT (7B)",
                "OpenLlama (7B)",
                "OPT (7B)",
                "Pythia (7B)",
                "StableLM Alpha (7B)",
                "CodeLlama (7B)",
                "CodeLlama-Python (7B)"
            ]
        }
    },
    "Task Oriented In-Domain Data Augmentation": {
        "filename": "Task Oriented In-Domain Data Augmentation.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "SAT",
                "MATH",
                "SVAMP",
                "ASDIV",
                "MAWPS",
                "TabMWP",
                "MathQA",
                "MMLU-STEM"
            ],
            "base_models": [
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Merlin Empowering Multimodal LLMs with Foresight Minds": {
        "filename": "Merlin Empowering Multimodal LLMs with Foresight Minds.pdf",
        "analysis": {
            "benchmarks": [
                "LaSOT",
                "GOT10K",
                "MMBench",
                "VQA",
                "MM-Vet"
            ],
            "base_models": [
                "GPT-4V",
                "Vicuna-7B v1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FLASK Fine-grained Language Model Evaluation based on Alignment Skill Sets": {
        "filename": "FLASK Fine-grained Language Model Evaluation based on Alignment Skill Sets.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "TruthfulQA",
                "FLASK-HARD"
            ],
            "base_models": [
                "GPT-3.5",
                "BARD",
                "VICUNA-13B",
                "ALPACA-13B",
                "GPT-4",
                "CLAUDE",
                "INSTRUCTGPT",
                "TULU-7B",
                "TULU-13B",
                "TULU-30B",
                "TULU-65B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense": {
        "filename": "Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-3.5",
                "ChatGPT (based on GPT-3.5-175B)",
                "Bing Chat/GPT-4",
                "EleutherAI's GPT-neo (2.7B)",
                "EleutherAI's GPT-J (6B)",
                "EleutherAI's GPT-neoX (20B)",
                "HyperCLOVA (82B)",
                "Meta's OPT (up to 175B)",
                "BLOOM (175B)",
                "Chinchilla (70B)",
                "LLaMA (13.5B)",
                "PaLM (up to 540B)",
                "BERT",
                "RoBERTa",
                "DistilBERT",
                "T5",
                "BART"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatPCG Large Language Model-Driven Reward Design for Procedural Content Generation": {
        "filename": "ChatPCG Large Language Model-Driven Reward Design for Procedural Content Generation.pdf",
        "analysis": {
            "benchmarks": [
                "RaidEnv II"
            ],
            "base_models": [
                "GPT-4-turbo-2024-04-09"
            ]
        }
    },
    "Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic": {
        "filename": "Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic.pdf",
        "analysis": {
            "benchmarks": [
                "FLD (Formal Logic Deduction)",
                "EntailmentBank (EB)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "LongAlpaca-13B",
                "T5-base",
                "T5-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Environment Interaction for Automated PDDL Generation and Planning with Large Language Models": {
        "filename": "Leveraging Environment Interaction for Automated PDDL Generation and Planning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Grippers",
                "Grippers-ood",
                "Hiking",
                "Miconic",
                "Movie",
                "Termes",
                "Barman",
                "Childsnack",
                "Driverlog",
                "Floortile"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generations of Knowledge Graphs The Crazy Ideas and the Business Impact": {
        "filename": "Generations of Knowledge Graphs The Crazy Ideas and the Business Impact.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "HLM-Cite Hybrid Language Model Workflow for Text-based Scientific Citation Prediction": {
        "filename": "HLM-Cite Hybrid Language Model Workflow for Text-based Scientific Citation Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "Microsoft Academic Graph (MAG)"
            ],
            "base_models": [
                "GTE-base (110M parameters, based on BERT)",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DSPy Assertions Computational Constraints for Self-Refining Language Model Pipelines": {
        "filename": "DSPy Assertions Computational Constraints for Self-Refining Language Model Pipelines.pdf",
        "analysis": {
            "benchmarks": [
                "HotPotQA"
            ],
            "base_models": [
                "gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ToolLLM Facilitating Large Language Models to Master 16000 Real-world APIs": {
        "filename": "ToolLLM Facilitating Large Language Models to Master 16000 Real-world APIs.pdf",
        "analysis": {
            "benchmarks": [
                "ToolBench",
                "APIBench"
            ],
            "base_models": [
                "LLaMA-2 7B",
                "ChatGPT (gpt-3.5-turbo-16k)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RAPGen An Approach for Fixing Code Inefficiencies in Zero-Shot": {
        "filename": "RAPGen An Approach for Fixing Code Inefficiencies in Zero-Shot.pdf",
        "analysis": {
            "benchmarks": [
                "DeepDev-PERF dataset"
            ],
            "base_models": [
                "gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GraphWiz An Instruction-Following Language Model for Graph Problems": {
        "filename": "GraphWiz An Instruction-Following Language Model for Graph Problems.pdf",
        "analysis": {
            "benchmarks": [
                "GraphQA",
                "NLGraph"
            ],
            "base_models": [
                "LLaMA 2-7B",
                "LLaMA 2-13B",
                "Mistral-7B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LayoutNUWA Revealing the Hidden Layout Expertise of Large Language Models": {
        "filename": "LayoutNUWA Revealing the Hidden Layout Expertise of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "RICO",
                "PubLayNet",
                "Magazine"
            ],
            "base_models": [
                "LLaMA2-7B",
                "CodeLLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AppPoet Large Language Model based Android malware detection via multi-view prompt engineering": {
        "filename": "AppPoet Large Language Model based Android malware detection via multi-view prompt engineering.pdf",
        "analysis": {
            "benchmarks": [
                "AndroZoo"
            ],
            "base_models": [
                "GPT-3.5 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Binding Language Models in Symbolic Languages": {
        "filename": "Binding Language Models in Symbolic Languages.pdf",
        "analysis": {
            "benchmarks": [
                "WIKITABLE QUESTIONS",
                "TABFACT",
                "MULTIMODAL QA"
            ],
            "base_models": [
                "GPT-3 Codex"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Efficient Prompt Optimization Through the Lens of Best Arm Identification": {
        "filename": "Efficient Prompt Optimization Through the Lens of Best Arm Identification.pdf",
        "analysis": {
            "benchmarks": [
                "Instruction-Induction",
                "BigBench"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama2",
                "Gemma",
                "Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting Large Language Models with Rationale Heuristics for Knowledge-based Visual Question Answering": {
        "filename": "Prompting Large Language Models with Rationale Heuristics for Knowledge-based Visual Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "OK-VQA",
                "A-OKVQA"
            ],
            "base_models": [
                "GPT-3",
                "LLaMA2-Chat 7B"
            ]
        }
    },
    "CodeCoT Tackling Code Syntax Errors in CoT Reasoning for Code Generation": {
        "filename": "CodeCoT Tackling Code Syntax Errors in CoT Reasoning for Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "HumanEval-ET",
                "MBPP-ET"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM",
                "GLaM",
                "MegatronTuring NLG",
                "Meta-OPT",
                "Gopher",
                "LaMDA",
                "Chinchilla",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Long-Context LLMs Meet RAG Overcoming Challenges for Long Inputs in RAG": {
        "filename": "Long-Context LLMs Meet RAG Overcoming Challenges for Long Inputs in RAG.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions (NQ)",
                "PopQA"
            ],
            "base_models": [
                "Gemma-7B-Chat",
                "Gemma-2-9B-Chat",
                "Mistral-Nemo-12B-Instruct",
                "Gemini-1.5-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving ChatGPT Prompt for Code Generation": {
        "filename": "Improving ChatGPT Prompt for Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CodeXGlue"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5 architecture with 175 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NERIF GPT-4V for Automatic Scoring of Drawn Models": {
        "filename": "NERIF GPT-4V for Automatic Scoring of Drawn Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset from a parental study by Zhai, He, and Krajcik (2022)"
            ],
            "base_models": [
                "GPT-4V"
            ]
        }
    },
    "When Large Language Models Meet Personalization Perspectives of Challenges and Opportunities": {
        "filename": "When Large Language Models Meet Personalization Perspectives of Challenges and Opportunities.pdf",
        "analysis": {
            "benchmarks": [
                "LaMP"
            ],
            "base_models": [
                "GPT-3",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Gender-specific Machine Translation with Large Language Models": {
        "filename": "Gender-specific Machine Translation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MULTILINGUAL HOLISTIC BIAS",
                "FLoRes"
            ],
            "base_models": [
                "LLaMA-2 (70 billion parameters)",
                "NLLB-200 (3 billion parameters)"
            ]
        }
    },
    "Large Language Models for Anomaly and Out-of-Distribution Detection A Survey": {
        "filename": "Large Language Models for Anomaly and Out-of-Distribution Detection A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "MVTec AD",
                "CLINC150"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "BERT",
                "CLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models": {
        "filename": "Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Wikidata",
                "CaLiGraph"
            ],
            "base_models": [
                "gpt-4-0125-preview",
                "gpt-3.5-turbo",
                "gemma-7b-it",
                "gemma-2b-it",
                "Mixtral-8x7B-Instruct-v0.1",
                "Mistral-7B-Instruct-v0.2",
                "Llama-2-70b-chat-hf"
            ]
        }
    },
    "KiVA Kid-inspired Visual Analogies for Testing Large Multimodal Models": {
        "filename": "KiVA Kid-inspired Visual Analogies for Testing Large Multimodal Models.pdf",
        "analysis": {
            "benchmarks": [
                "KiVA",
                "KiVA-adults"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA-1.5",
                "MANTIS"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FedBiOT LLM Local Fine-tuning in Federated Learning without Full Model": {
        "filename": "FedBiOT LLM Local Fine-tuning in Federated Learning without Full Model.pdf",
        "analysis": {
            "benchmarks": [
                "GSM-8K",
                "Rosetta",
                "HumanEvalX",
                "dolly-15K",
                "HELM"
            ],
            "base_models": [
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Advanced Large Language Models with LLMsuite": {
        "filename": "Exploring Advanced Large Language Models with LLMsuite.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SuperGLUE",
                "MMLU",
                "BIG-Bench",
                "HELM",
                "Gemini",
                "CoLA",
                "SST2",
                "MRPC",
                "STS",
                "QQP",
                "MNLI",
                "QNLI",
                "RTE",
                "WNLI",
                "CoT",
                "Muffin",
                "Natural Instructions v2",
                "MGSM",
                "BBH"
            ],
            "base_models": [
                "ChatGPT",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Batch Prompting Efficient Inference with Large Language Model APIs": {
        "filename": "Batch Prompting Efficient Inference with Large Language Model APIs.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "StrategyQA",
                "GSM8K",
                "SVAMP",
                "AQuA",
                "AddSub",
                "MultiArith",
                "RTE",
                "MNLI",
                "SST-5"
            ],
            "base_models": [
                "Codex (variant of GPT-3)",
                "GPT-3",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Manipulate-Anything Automating Real-World Robots using Vision-Language Models": {
        "filename": "Manipulate-Anything Automating Real-World Robots using Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "RLBench"
            ],
            "base_models": [
                "GPT-4V",
                "Qwen-VL"
            ]
        }
    },
    "Make Them Spill the Beans Coercive Knowledge Extraction from Production LLMs": {
        "filename": "Make Them Spill the Beans Coercive Knowledge Extraction from Production LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "NeurIPS Trojan Detection Challenge 2023"
            ],
            "base_models": [
                "Yi-34B",
                "Vicuna-13B",
                "Llama2-7B",
                "Llama2-13B",
                "Llama2-70B",
                "Codellama-13B-Instruct",
                "Codellama-13B-Python",
                "Gpt-3.5-turbo-instruct",
                "Gpt-3.5-turbo-instruct-0914",
                "Text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VerityMath Advancing Mathematical Reasoning by Self-Verification Through Unit Consistency": {
        "filename": "VerityMath Advancing Mathematical Reasoning by Self-Verification Through Unit Consistency.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "Llama 2 (7B)",
                "Code Llama (7B)",
                "Mistral (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Text to Emotion Unveiling the Emotion Annotation Capabilities of LLMs": {
        "filename": "From Text to Emotion Unveiling the Emotion Annotation Capabilities of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ISEAR",
                "SemEval",
                "GoEmotions",
                "Emobank"
            ],
            "base_models": [
                "GPT-4",
                "BERT (110M)"
            ]
        }
    },
    "Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models": {
        "filename": "Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models.pdf",
        "analysis": {
            "benchmarks": [
                "Brick World",
                "NLVR-based Manipulation",
                "Natural Language Navigation",
                "SPARTUN"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "LLAMA-2 (7B, 13B, 70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AFlow Automating Agentic Workflow Generation": {
        "filename": "AFlow Automating Agentic Workflow Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "MATH",
                "GSM8K",
                "HotpotQA",
                "DROP"
            ],
            "base_models": [
                "GPT-4o-mini",
                "DeepSeek-V2.5",
                "Claude-3.5-sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Blind Judgement Agent-Based Supreme Court Modelling With GPT": {
        "filename": "Blind Judgement Agent-Based Supreme Court Modelling With GPT.pdf",
        "analysis": {
            "benchmarks": [
                "Supreme Court Database (SCDB)",
                "Custom dataset of 96 real-world Supreme Court cases"
            ],
            "base_models": [
                "GPT-2"
            ]
        }
    },
    "In-Context Editing Learning Knowledge from Self-Induced Distributions": {
        "filename": "In-Context Editing Learning Knowledge from Self-Induced Distributions.pdf",
        "analysis": {
            "benchmarks": [
                "WikiData recent",
                "ZsRE",
                "WikiBio",
                "WikiData counterfact"
            ],
            "base_models": [
                "Llama2-7b-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "COCO is ALL You Need for Visual Instruction Fine-tuning": {
        "filename": "COCO is ALL You Need for Visual Instruction Fine-tuning.pdf",
        "analysis": {
            "benchmarks": [
                "NoCaps",
                "COCO",
                "GQA",
                "VQAv2",
                "VizWiz",
                "MME",
                "SeedBench",
                "MMMU",
                "MM-Vet",
                "InfiMM-Eval"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "Mistral",
                "LLaVA-1.5-13B"
            ]
        }
    },
    "Beyond Human Norms Unveiling Unique Values of Large Language Models through Interdisciplinary Approaches": {
        "filename": "Beyond Human Norms Unveiling Unique Values of Large Language Models through Interdisciplinary Approaches.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "LLaMA2-70B",
                "Mistral-large",
                "Baichuan13b-chat"
            ]
        }
    },
    "Can Language Models Solve Graph Problems in Natural Language": {
        "filename": "Can Language Models Solve Graph Problems in Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "NLGraph"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Balancing Cost and Effectiveness of Synthetic Data Generation Strategies for LLMs": {
        "filename": "Balancing Cost and Effectiveness of Synthetic Data Generation Strategies for LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "Spider",
                "ARC-C"
            ],
            "base_models": [
                "Llama 3.1 70B Instruct",
                "Llama 2 7B Chat"
            ]
        }
    },
    "ToolQA A Dataset for LLM Question Answering with External Tools": {
        "filename": "ToolQA A Dataset for LLM Question Answering with External Tools.pdf",
        "analysis": {
            "benchmarks": [
                "ToolQA"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "ReAct (GPT-3)",
                "ReAct (GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Integrating Text-to-Music Models with Language Models Composing Long Structured Music Pieces": {
        "filename": "Integrating Text-to-Music Models with Language Models Composing Long Structured Music Pieces.pdf",
        "analysis": {
            "benchmarks": [
                "Pond5"
            ],
            "base_models": [
                "MusicGen",
                "ChatGPT"
            ]
        }
    },
    "kNN Prompting Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference": {
        "filename": "kNN Prompting Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference.pdf",
        "analysis": {
            "benchmarks": [
                "SST2",
                "SUBJ",
                "MPQA",
                "AGNews",
                "CB",
                "CR",
                "DBPedia",
                "MR",
                "RTE",
                "TREC"
            ],
            "base_models": [
                "GPT2 (0.8B and 1.5B)",
                "OPT (3B-30B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learn to Explain Multimodal Reasoning via Thought Chains for Science Question Answering": {
        "filename": "Learn to Explain Multimodal Reasoning via Thought Chains for Science Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "SCIENCE QA"
            ],
            "base_models": [
                "GPT-3",
                "UnifiedQA BASE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning a Structural Causal Model for Intuition Reasoning in Conversation": {
        "filename": "Learning a Structural Causal Model for Intuition Reasoning in Conversation.pdf",
        "analysis": {
            "benchmarks": [
                "RECCON",
                "Synthetic dataset",
                "Simulation dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "RoBERTa",
                "RoBERTa+ (large version)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Samba Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling": {
        "filename": "Samba Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU-Pro",
                "HumanEval",
                "GSM8K",
                "Proof-Pile",
                "Passkey Retrieval",
                "Phonebook",
                "ARC",
                "PIQA",
                "WinoGrande",
                "SIQA",
                "HellaSwag",
                "BoolQ",
                "OpenbookQA",
                "SQuAD",
                "MMLU",
                "TruthfulQA",
                "MBPP",
                "LAMBADA"
            ],
            "base_models": [
                "Llama-3 (1.6B)",
                "Mistral (1.6B)",
                "Mamba (1.8B)",
                "SAMBA (3.8B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Challenges Faced by Large Language Models in Solving Multi-Agent Flocking": {
        "filename": "Challenges Faced by Large Language Models in Solving Multi-Agent Flocking.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4-Turbo"
            ]
        }
    },
    "A Case Study on Test Case Construction with Large Language Models Unveiling Practical Insights and Challenges": {
        "filename": "A Case Study on Test Case Construction with Large Language Models Unveiling Practical Insights and Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "Da.tes"
            ],
            "base_models": [
                "GPT-3.5 Turbo"
            ]
        }
    },
    "Negated Complementary Commonsense using Large Language Models": {
        "filename": "Negated Complementary Commonsense using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ATOMIC-2020"
            ],
            "base_models": [
                "GPT-3 (175 billion parameters)"
            ]
        }
    },
    "AutoSAT Automatically Optimize SAT Solvers via Large Language Models": {
        "filename": "AutoSAT Automatically Optimize SAT Solvers via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "cryptography-ascon",
                "register-allocation",
                "social-golfer",
                "hashtable-safety",
                "profitable-robust-product (PRP)",
                "argumentation",
                "set-covering-with-pairs (SCP)",
                "CoinsGrid",
                "MineSweeper",
                "KnightTour",
                "LangFord",
                "Zamkeller"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Domain-Specific Retrieval-Augmented Generation Using Vector Stores Knowledge Graphs and Tensor Factorization": {
        "filename": "Domain-Specific Retrieval-Augmented Generation Using Vector Stores Knowledge Graphs and Tensor Factorization.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of scientific publications on malware analysis and anomaly detection"
            ],
            "base_models": [
                "GPT-4-instruct"
            ]
        }
    },
    "FoodSAM Any Food Segmentation": {
        "filename": "FoodSAM Any Food Segmentation.pdf",
        "analysis": {
            "benchmarks": [
                "FoodSeg103",
                "UECFoodPix Complete"
            ],
            "base_models": [
                "Segment Anything Model (SAM) with ViT-H (636M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Large Language Models on Graphs Performance Insights and Comparative Analysis": {
        "filename": "Evaluating Large Language Models on Graphs Performance Insights and Comparative Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "randomly generated graph data"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "CalderaAI/30B-Lazarus",
                "TheBloke/Wizard-Vicuna-13B-Uncensored-HF"
            ]
        }
    },
    "BLIAM Literature-based Data Synthesis for Synergistic Drug Combination Prediction": {
        "filename": "BLIAM Literature-based Data Synthesis for Synergistic Drug Combination Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "GDSC-combo"
            ],
            "base_models": [
                "PubMedBERT (base-uncased)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Proving Olympiad Algebraic Inequalities without Human Demonstrations": {
        "filename": "Proving Olympiad Algebraic Inequalities without Human Demonstrations.pdf",
        "analysis": {
            "benchmarks": [
                "MO-INT-20",
                "miniF2F",
                "INT"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4 Turbo",
                "Gemini 1.5 Pro",
                "Llemma-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "QLoRA Efficient Finetuning of Quantized LLMs": {
        "filename": "QLoRA Efficient Finetuning of Quantized LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Vicuna",
                "MMLU",
                "OASST1"
            ],
            "base_models": [
                "LLaMA (7B, 13B, 33B, 65B)",
                "T5 (80M, 250M, 780M, 3B, 11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Predict Concept Ordering for Common Sense Generation": {
        "filename": "Learning to Predict Concept Ordering for Common Sense Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CommonGen"
            ],
            "base_models": [
                "BERT-gen",
                "BART-base",
                "T5-base",
                "BART-large",
                "T5-large",
                "GPT-3 Babbage (6.7B)",
                "GPT-3 Curie (13B)",
                "GPT-3.5 Turbo (135B)"
            ]
        }
    },
    "LLMs for Domain Generation Algorithm Detection": {
        "filename": "LLMs for Domain Generation Algorithm Detection.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset with 68 malware families and normal domains"
            ],
            "base_models": [
                "Llama3 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RIFF Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models": {
        "filename": "RIFF Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SST2",
                "CR",
                "MR",
                "SST5",
                "TREC",
                "AGNews"
            ],
            "base_models": [
                "BERT",
                "RoBERTa-large",
                "T5-base",
                "GPT3.5-turbo",
                "PaLM-2 (540B)",
                "GPT3 (175B)",
                "OPT (175B)",
                "Llama-2 (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mitigating Adversarial Attacks in LLMs through Defensive Suffix Generation": {
        "filename": "Mitigating Adversarial Attacks in LLMs through Defensive Suffix Generation.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench",
                "TruthfulQA"
            ],
            "base_models": [
                "Gemma-7B",
                "Mistral-7B",
                "Llama2-7B",
                "Llama2-13B",
                "Llama3.2-1B",
                "openELM-270M"
            ]
        }
    },
    "GLoRE Evaluating Logical Reasoning of Large Language Models": {
        "filename": "GLoRE Evaluating Logical Reasoning of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "LogiQA 2.0 test",
                "LogiQA 2.0 zh test",
                "ReClor dev",
                "AR-LSAT test",
                "LogiQA22",
                "ConTRoL",
                "HELP",
                "TaxiNLI test",
                "NaN-NLI",
                "FraCas",
                "RuleTaker dev",
                "ProofWriter dev"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "LLaMA-30B",
                "Falcon-40B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aligning Cyber Space with Physical World A Comprehensive Survey on Embodied AI": {
        "filename": "Aligning Cyber Space with Physical World A Comprehensive Survey on Embodied AI.pdf",
        "analysis": {
            "benchmarks": [
                "Matterport3D",
                "AI2-THOR",
                "R2R",
                "REVERIE",
                "TOUCHDOWN",
                "ALFRED",
                "CVDN"
            ],
            "base_models": [
                "GPT-3",
                "BERT",
                "Transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When Giant Language Brains Just Arent Enough Domain Pizzazz with Knowledge Sparkle Dust": {
        "filename": "When Giant Language Brains Just Arent Enough Domain Pizzazz with Knowledge Sparkle Dust.pdf",
        "analysis": {
            "benchmarks": [
                "Expert-created insurance dataset",
                "Synthesized dataset"
            ],
            "base_models": [
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs": {
        "filename": "Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "StepGame",
                "SparQA"
            ],
            "base_models": [
                "Deepseek",
                "Llama3-70B",
                "GPT-4.0 mini"
            ]
        }
    },
    "Language to Rewards for Robotic Skill Synthesis": {
        "filename": "Language to Rewards for Robotic Skill Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "17 tasks for a simulated quadruped robot and a dexterous manipulator robot"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks": {
        "filename": "Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "Bard",
                "Vicuna",
                "Llama 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Biased Reinforcement Learners": {
        "filename": "Large Language Models are Biased Reinforcement Learners.pdf",
        "analysis": {
            "benchmarks": [
                "B2018",
                "V2023",
                "HW2023a",
                "BP2023",
                "HW2023b"
            ],
            "base_models": [
                "gpt-3.5-turbo-0125",
                "gpt-4-0125-preview",
                "llama-2-70b-chat",
                "mixtral-8x7b-instruct"
            ]
        }
    },
    "Generative agent-based modeling with actions grounded in physical social or digital space using Concordia": {
        "filename": "Generative agent-based modeling with actions grounded in physical social or digital space using Concordia.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Bard",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting Large Language Models With the Socratic Method": {
        "filename": "Prompting Large Language Models With the Socratic Method.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PREDILECT Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning": {
        "filename": "PREDILECT Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Reacher",
                "Cheetah",
                "Social robot navigation scenario"
            ],
            "base_models": [
                "BERT",
                "CLIP with GPT-2",
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BackdoorLLM A Comprehensive Benchmark for Backdoor Attacks on Large Language Models": {
        "filename": "BackdoorLLM A Comprehensive Benchmark for Backdoor Attacks on Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Stanford Alpaca",
                "AdvBench",
                "math reasoning data",
                "SST-2",
                "AGNews",
                "ToxiGen",
                "BOLD",
                "GSM8K",
                "MATH",
                "ASDiv",
                "CSQA",
                "StrategyQA",
                "Letter"
            ],
            "base_models": [
                "GPT-2",
                "Llama-2-7B",
                "Llama-2-13B",
                "Llama-2-70B",
                "Llama-3-8B",
                "Mistral-7B",
                "Vicuna-7B-V1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Magentic-One A Generalist Multi-Agent System for Solving Complex Tasks": {
        "filename": "Magentic-One A Generalist Multi-Agent System for Solving Complex Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "GAIA",
                "AssistantBench",
                "WebArena"
            ],
            "base_models": [
                "GPT-4o",
                "o1-preview"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Do Transformers Learn In-Context Beyond Simple Functions A Case Study on Learning with Representations": {
        "filename": "How Do Transformers Learn In-Context Beyond Simple Functions A Case Study on Learning with Representations.pdf",
        "analysis": {
            "benchmarks": [
                "Synthetic in-context learning problems with compositional structure"
            ],
            "base_models": [
                "GPT-2 (12 layers, 8 heads, Dhid=256)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Comprehensive Overview of Large Language Models": {
        "filename": "A Comprehensive Overview of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "T5",
                "GPT-3 (175B)",
                "mT5",
                "PanGu-α",
                "CPM-2",
                "ERNIE 3.0",
                "Jurassic-1 (178B)",
                "HyperCLOVA",
                "Yuan 1.0",
                "Gopher (280B)",
                "ERNIE 3.0 Titan",
                "GPT-NeoX-20B",
                "OPT (175B)",
                "BLOOM",
                "GLaM (64B/64E)",
                "MT-NLG (530B)",
                "Chinchilla",
                "AlexaTM",
                "PaLM (540B)",
                "PaLM-2",
                "U-PaLM",
                "UL2",
                "GLM-130B",
                "LLaMA",
                "LLaMA-2",
                "LLaMA-3",
                "PanGu-Σ",
                "Mixtral 8x22B",
                "Snowflake Arctic (480B)",
                "Grok-1 (314B)",
                "Grok-1.5",
                "Gemini-1",
                "Gemini-1.5",
                "Nemotron-4 340B",
                "DeepSeek",
                "DeepSeek-V2",
                "CodeGen",
                "Codex",
                "AlphaCode",
                "CodeT5+",
                "StarCoder",
                "Galactica",
                "LaMDA",
                "BloombergGPT",
                "Xuan Yuan 2.0"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings": {
        "filename": "Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings.pdf",
        "analysis": {
            "benchmarks": [
                "Transcriptions",
                "MIMIC-CXR",
                "MS-CXR"
            ],
            "base_models": [
                "BERT BASE (110M)",
                "BERT LARGE (340M)",
                "RoBERTa LARGE-MNLI (355M)",
                "BioMedBERT (110M)",
                "BioMedBERT-large (340M)",
                "SciBERT (110M)",
                "SapBERT (110M)",
                "BioLORD-STAMB2-v1 (110M)",
                "BioLORD-PMB (110M)",
                "Bio+Clinical BERT (110M)",
                "T5-V1.1-Base (220M)",
                "T5-V1.1-Large (770M)",
                "T5-V1.1-3B (3.0B)",
                "T5-V1.1-11B (11.0B)",
                "Flan-T5-Base (220M)",
                "Flan-T5-Large (770M)",
                "Flan-T5-XL (3.0B)",
                "Flan-T5-XXL (11.0B)",
                "T0 3B (3.0B)",
                "T0++ (11.0B)",
                "ClinicalT5-base (220M)",
                "ClinicalT5-large (700M)",
                "GPT-2 Medium (355M)",
                "GPT-2 Large (774M)",
                "GPT-2 XL (1.5B)",
                "Palmyra Base 5B (5.0B)",
                "OpenLLaMA 3B (3.0B)",
                "OpenLLaMA 3Bv2 (3.0B)",
                "GPT-J 6B (6.0B)",
                "Instruct GPT-J (6.0B)",
                "Falcon-7B (7.0B)",
                "Falcon-7B-Instruct (7.0B)",
                "MPT-7B (7.0B)",
                "MPT-7B-Instruct (7.0B)",
                "LLaMA-7B (7.0B)",
                "LLaMA 2-7B (7.0B)",
                "Alpaca 7B (7.0B)",
                "LLaMA 2-CHAT-7B (7.0B)",
                "OpenLLaMA 7B (7.0B)",
                "OpenLLaMA 7Bv2 (7.0B)",
                "OpenLLaMA 13B (13.0B)",
                "BioGPT (347M)",
                "GPT-2-PubMed Medium (355M)",
                "GPT-2-PubMed Large (774M)",
                "BioGPT-Large (1.5B)",
                "Galactica 1.3B (1.3B)",
                "Galactica 6.7B (6.7B)",
                "MedAlpaca 7b (7.0B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods": {
        "filename": "Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from Hu, Floyd, et al. (2023) on pragmatic language interpretation"
            ],
            "base_models": [
                "GPT-3.5-turbo-instruct (175B)",
                "text-davinci-002 (175B)",
                "LLaMA-2 (7B)",
                "FLAN-T5-XL (3B)"
            ]
        }
    },
    "Tuning-Free Accountable Intervention for LLM Deployment - A Metacognitive Approach": {
        "filename": "Tuning-Free Accountable Intervention for LLM Deployment - A Metacognitive Approach.pdf",
        "analysis": {
            "benchmarks": [
                "CEBaB",
                "IMDB-C",
                "ASAP-C"
            ],
            "base_models": [
                "BERT",
                "OPT",
                "T5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Llama 2 Open Foundation and Fine-Tuned Chat Models": {
        "filename": "Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "PIQA",
                "SIQA",
                "HellaSwag",
                "WinoGrande",
                "ARC easy",
                "ARC challenge",
                "OpenBookQA",
                "CommonsenseQA",
                "NaturalQuestions",
                "TriviaQA",
                "SQuAD",
                "QuAC",
                "BoolQ",
                "GSM8K",
                "MATH",
                "MMLU",
                "BBH",
                "AGI Eval"
            ],
            "base_models": [
                "Llama 2 (7B, 13B, 34B, 70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Document-Level In-Context Few-Shot Relation Extraction via Pre-Trained Language Models": {
        "filename": "Document-Level In-Context Few-Shot Relation Extraction via Pre-Trained Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "DocRED"
            ],
            "base_models": [
                "GPT-J (6B)",
                "BART-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Survey on Factuality in Large Language Models Knowledge Retrieval and Domain-Specificity": {
        "filename": "Survey on Factuality in Large Language Models Knowledge Retrieval and Domain-Specificity.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "TruthfulQA",
                "C-Eval",
                "AGIEval",
                "RealTimeQA",
                "FreshQA"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "LLaMA",
                "LLaMA-2",
                "T5",
                "GPT-2",
                "GPT-3",
                "GPT-Neo",
                "OPT",
                "Incite",
                "Claude",
                "Falcon",
                "MPT",
                "Vicuna",
                "FLAN-T5",
                "BLOOM",
                "Baichuan",
                "PaLM",
                "Gopher",
                "Megatron-LM",
                "SAIL",
                "Codex",
                "Bard",
                "GLM",
                "ChatGLM",
                "InternLM",
                "StableBeluga",
                "Alpaca",
                "New Bing",
                "Ziya-LLaMA",
                "BLOOMZ",
                "Chinese-LLaMA",
                "Phoenix",
                "BloombergGPT",
                "EcomGPT",
                "BioGPT",
                "LawGPT",
                "Lawyer LLaMA",
                "ChatLaw",
                "BioMedLM",
                "HuatuoGPT",
                "ChatDoctor",
                "MedicalGPT",
                "Bentsao",
                "Zhongjing",
                "LLM-AMT",
                "DISC-MedLLM",
                "Cohortgpt",
                "Deid-gpt",
                "Doctorglm",
                "MedChatZH",
                "K2",
                "HouYi",
                "GrammarGPT",
                "FoodGPT",
                "ChatHome"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MatExpert Decomposing Materials Discovery by Mimicking Human Experts": {
        "filename": "MatExpert Decomposing Materials Discovery by Mimicking Human Experts.pdf",
        "analysis": {
            "benchmarks": [
                "Material Project",
                "NOMAD"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2 7B",
                "LLaMA-2 70B",
                "LLaMA-3 8B",
                "LLaMA-3 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Iterative Graph Alignment": {
        "filename": "Iterative Graph Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "RuleAlign"
            ],
            "base_models": [
                "Claude Sonnet 3.5",
                "Llama3-8B-Instruct"
            ]
        }
    },
    "Enhancing Knowledge Retrieval with In-Context Learning and Semantic Search through Generative AI": {
        "filename": "Enhancing Knowledge Retrieval with In-Context Learning and Semantic Search through Generative AI.pdf",
        "analysis": {
            "benchmarks": [
                "MSMARCO",
                "Spider"
            ],
            "base_models": [
                "Falcon 7B",
                "Flan T5-XXL"
            ]
        }
    },
    "Quality Prediction of AI Generated Images and Videos Emerging Trends and Opportunities": {
        "filename": "Quality Prediction of AI Generated Images and Videos Emerging Trends and Opportunities.pdf",
        "analysis": {
            "benchmarks": [
                "HPD",
                "ImageReward",
                "Pick-A-Pic",
                "AGIQA-1K",
                "AGIQA-3K",
                "AIGCIQA",
                "AIGIQA-20K",
                "PKU-AIGIQA-4K",
                "AGIN",
                "DCU",
                "VBench",
                "FETV",
                "EvalCrafter",
                "T2VQA-DB",
                "AIGCBench"
            ],
            "base_models": [
                "Stable Diffusion",
                "CLIP",
                "Inception V3",
                "I3D"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Advances in Embodied Navigation Using Large Language Models A Survey": {
        "filename": "Advances in Embodied Navigation Using Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "REVERIE",
                "ScanNet",
                "Gibson",
                "HM3D",
                "MP3D",
                "R2R",
                "RxR",
                "ProcTHOR"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "CLIP",
                "BERT",
                "RoBERTa",
                "Deberta",
                "ResNet-50",
                "ViT",
                "LSTM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Depth Helps Improving Pre-trained RGB-based Policy with Depth Information Injection": {
        "filename": "Depth Helps Improving Pre-trained RGB-based Policy with Depth Information Injection.pdf",
        "analysis": {
            "benchmarks": [
                "LIBERO"
            ],
            "base_models": [
                "RoboFlamingo"
            ]
        }
    },
    "ChemReasoner Heuristic Search over a Large Language Models Knowledge Space using Quantum-Chemical Feedback": {
        "filename": "ChemReasoner Heuristic Search over a Large Language Models Knowledge Space using Quantum-Chemical Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "OpenCatalyst",
                "BioFuels",
                "CO2-Fuel"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain of Ideas Revolutionizing Research Via Novel Idea Development with LLM Agents": {
        "filename": "Chain of Ideas Revolutionizing Research Via Novel Idea Development with LLM Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Neuro-Symbolic Approach to Monitoring Salt Content in Food": {
        "filename": "A Neuro-Symbolic Approach to Monitoring Salt Content in Food.pdf",
        "analysis": {
            "benchmarks": [
                "USFDC (U.S. Food Data Central)"
            ],
            "base_models": [
                "PPTOD (based on T5)",
                "GPT-3"
            ]
        }
    },
    "Explainable Verbal Reasoner Plus EVR A Natural Language Reasoning Framework that Supports Diverse Compositional Reasoning": {
        "filename": "Explainable Verbal Reasoner Plus EVR A Natural Language Reasoning Framework that Supports Diverse Compositional Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "SynthCompR"
            ],
            "base_models": [
                "UnifiedQA-T5-large",
                "UnifiedQA-T5-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AgentGen Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation": {
        "filename": "AgentGen Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation.pdf",
        "analysis": {
            "benchmarks": [
                "AgentBoard",
                "Blocksworld",
                "Gripper",
                "Tyreworld",
                "Barman",
                "Alfworld",
                "BabyAI",
                "Jericho"
            ],
            "base_models": [
                "Llama-3.1-8B",
                "Llama-3.1-70B",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are Long-LLMs A Necessity For Long-Context Tasks": {
        "filename": "Are Long-LLMs A Necessity For Long-Context Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "NarrativeQA",
                "Qasper",
                "MultiFieldQA",
                "HotpotQA",
                "2WikiMQA",
                "MuSiQue",
                "GovReport",
                "MultiNews",
                "SAMSum",
                "Passage Count",
                "Self-Constructed Dataset",
                "LCC"
            ],
            "base_models": [
                "GPT-4-128K",
                "GPT-3.5-turbo-16K",
                "Llama2-7B-Chat-4K",
                "Llama3-8B-Instruct-8K",
                "Vicuna-v1.5-7B-16K",
                "LongChat-v1.5-7B-32K",
                "Mistral-7B-Instruct-v0.2-32K",
                "Llama3-8B-80K",
                "Phi-3-mini-128K",
                "Yi-9B-200K",
                "DeepSeek-v2 (236B MoE model)",
                "Claude-3-Haiku (200K)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs Understand Glass-Box Models Discover Surprises and Suggest Repairs": {
        "filename": "LLMs Understand Glass-Box Models Discover Surprises and Suggest Repairs.pdf",
        "analysis": {
            "benchmarks": [
                "Pneumonia dataset from the 1989 MedisGroups Comparative Hospital Database (MCHD)"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Contrast with Reconstruct Contrastive 3D Representation Learning Guided by Generative Pretraining": {
        "filename": "Contrast with Reconstruct Contrastive 3D Representation Learning Guided by Generative Pretraining.pdf",
        "analysis": {
            "benchmarks": [
                "ScanObjectNN",
                "ModelNet40"
            ],
            "base_models": [
                "Transformer (43.6M parameters)",
                "Vision Transformer (ViT-B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HCQA  Ego4D EgoSchema Challenge 2024": {
        "filename": "HCQA  Ego4D EgoSchema Challenge 2024.pdf",
        "analysis": {
            "benchmarks": [
                "EgoSchema dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4o",
                "LaViLa"
            ]
        }
    },
    "Logical Reasoning over Natural Language as Knowledge Representation A Survey": {
        "filename": "Logical Reasoning over Natural Language as Knowledge Representation A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "D*",
                "ParaRules",
                "Birds-electricity",
                "Leap-of-thought",
                "PARARULE-Plus",
                "FOLIO",
                "D*(CWA)",
                "D*(OWA)",
                "EntailmentBank",
                "ENWN",
                "property-norm",
                "DEERLET",
                "DEER",
                "ARC",
                "OpenD5",
                "C-LBD",
                "TOMATO",
                "αNLI",
                "αNLG",
                "AbductionRules",
                "D*-Ab"
            ],
            "base_models": [
                "RoBERTa-large",
                "T5-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Scaling Instruction-Finetuned Language Models": {
        "filename": "Scaling Instruction-Finetuned Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BBH",
                "TyDiQA",
                "MGSM",
                "RealToxicityPrompts"
            ],
            "base_models": [
                "PaLM-540B",
                "T5 (80M to 11B)",
                "U-PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Give me a hint Can LLMs take a hint to solve math problems": {
        "filename": "Give me a hint Can LLMs take a hint to solve math problems.pdf",
        "analysis": {
            "benchmarks": [
                "MATH dataset"
            ],
            "base_models": [
                "GPT-4o-mini",
                "Gemini Flash"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Prompts in LLMs to Overcome Imbalances in Complex Educational Text Data": {
        "filename": "Leveraging Prompts in LLMs to Overcome Imbalances in Complex Educational Text Data.pdf",
        "analysis": {
            "benchmarks": [
                "StoryQ curriculum dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "TabLLM Few-shot Classification of Tabular Data with Large Language Models": {
        "filename": "TabLLM Few-shot Classification of Tabular Data with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Bank",
                "Blood",
                "California",
                "Car",
                "Credit-g",
                "Income",
                "Jungle",
                "Diabetes",
                "Heart",
                "Healthcare claims dataset"
            ],
            "base_models": [
                "T0 (11B)",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs learn governing principles of dynamical systems revealing an in-context neural scaling law": {
        "filename": "LLMs learn governing principles of dynamical systems revealing an in-context neural scaling law.pdf",
        "analysis": {
            "benchmarks": [
                "Discrete Markov chain",
                "Stochastic logistic map"
            ],
            "base_models": [
                "LLaMA-13b",
                "LLaMA-70b"
            ]
        }
    },
    "Tulip Agent - Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries": {
        "filename": "Tulip Agent - Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries.pdf",
        "analysis": {
            "benchmarks": [
                "custom mathematics benchmark",
                "robotics simulation scenario"
            ],
            "base_models": [
                "GPT-4-turbo-2024-04-09",
                "GPT-3.5-turbo-0125"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Comparative Analysis of GPT-4 and Human Graders in Evaluating Human Tutors Giving Praise to Students": {
        "filename": "Comparative Analysis of GPT-4 and Human Graders in Evaluating Human Tutors Giving Praise to Students.pdf",
        "analysis": {
            "benchmarks": [
                "Synthetic tutor-student dialogues"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Steering Large Language Models between Code Execution and Textual Reasoning": {
        "filename": "Steering Large Language Models between Code Execution and Textual Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Blocksworld",
                "Game 24",
                "Logical Deduction",
                "Number Multiplying",
                "GSM-Hard",
                "MATH-Geometry",
                "MATH-Count&Probability",
                "Date Understanding",
                "Web of Lies",
                "Navigate",
                "BoxNet",
                "Path Plan",
                "Letters",
                "BoxLift"
            ],
            "base_models": [
                "O1-preview",
                "GPT-4o",
                "GPT-4o-mini",
                "GPT-3.5",
                "Claude-sonnet",
                "Mixtral-8x7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Teaching Smaller Language Models To Generalise To Unseen Compositional Questions": {
        "filename": "Teaching Smaller Language Models To Generalise To Unseen Compositional Questions.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "CommonsenseQA",
                "IIRC",
                "DROP",
                "Musique",
                "ARC-DA"
            ],
            "base_models": [
                "BART (440M)",
                "RoBERTa-base",
                "ELECTRA-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGPT for Arabic Grammatical Error Correction": {
        "filename": "ChatGPT for Arabic Grammatical Error Correction.pdf",
        "analysis": {
            "benchmarks": [
                "QALB-2014",
                "QALB-2015"
            ],
            "base_models": [
                "ChatGPT-3.5 Turbo",
                "ChatGPT-4",
                "AraBart",
                "AraT5",
                "mT0",
                "mT5",
                "LLaMA-7B",
                "Vicuna-13B",
                "Bactrian-X bloom-7B",
                "Bactrian-X llama-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Demystifying the DAO Governance Process": {
        "filename": "Demystifying the DAO Governance Process.pdf",
        "analysis": {
            "benchmarks": [
                "Custom DAO dataset with 16,427 DAOs, 183 documentation, and 122,307 proposals across 9 blockchains"
            ],
            "base_models": [
                "Large Language Model (LLM) with Chain of Thought (CoT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoEval-Video An Automatic Benchmark for Assessing Large Vision Language Models in Open-Ended Video Question Answering": {
        "filename": "AutoEval-Video An Automatic Benchmark for Assessing Large Vision Language Models in Open-Ended Video Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "AutoEval-Video"
            ],
            "base_models": [
                "GPT-4V(ision)",
                "Gemini-Ultra-Vision",
                "LLaVA-1.5",
                "Qwen-VL",
                "InstructBLIP",
                "BLIP-2",
                "Video-ChatGPT",
                "VideoChat",
                "VideoChat2",
                "Video-LLaMA",
                "LLaMA-VID"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Autonomous GIS the next-generation AI-powered GIS": {
        "filename": "Autonomous GIS the next-generation AI-powered GIS.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset for North Carolina hazardous waste facilities and population",
                "Custom dataset for France mobility data during COVID-19",
                "Custom dataset for US county-level COVID-19 death rate and senior resident rate"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Diffusion Self-Distillation for Zero-Shot Customized Image Generation": {
        "filename": "Diffusion Self-Distillation for Zero-Shot Customized Image Generation.pdf",
        "analysis": {
            "benchmarks": [
                "DreamBench++"
            ],
            "base_models": [
                "FLUX1.0 DEV",
                "GPT-4o",
                "Gemini-1.5"
            ]
        }
    },
    "Memory Sharing for Large Language Model based Agents": {
        "filename": "Memory Sharing for Large Language Model based Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4o",
                "open-mistral-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BLUEX A benchmark based on Brazilian Leading Universities Entrance eXams": {
        "filename": "BLUEX A benchmark based on Brazilian Leading Universities Entrance eXams.pdf",
        "analysis": {
            "benchmarks": [
                "BLUEX"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "LLaMA 65B",
                "OPT 66B",
                "Sabiá 65B",
                "Sabiá 7B",
                "Alpaca 7B",
                "BloomZ 7B",
                "LLaMA 7B",
                "Bertin 6B",
                "Bloom 7B",
                "XGLM 7.5B",
                "OPT 6.7B",
                "GPT-J 6B"
            ]
        }
    },
    "Where Would I Go Next Large Language Models as Human Mobility Predictors": {
        "filename": "Where Would I Go Next Large Language Models as Human Mobility Predictors.pdf",
        "analysis": {
            "benchmarks": [
                "Geolife",
                "Foursquare New York City (FSQ-NYC)"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "Evaluating Uncertainty-based Failure Detection for Closed-Loop LLM Planners": {
        "filename": "Evaluating Uncertainty-based Failure Detection for Closed-Loop LLM Planners.pdf",
        "analysis": {
            "benchmarks": [
                "self-collected dataset for success/failure analysis with five different manipulation tasks"
            ],
            "base_models": [
                "LLaVA",
                "ChatGPT-4V"
            ]
        }
    },
    "Demystifying Large Language Models for Medicine A Primer": {
        "filename": "Demystifying Large Language Models for Medicine A Primer.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA-USMLE",
                "PubMedQA",
                "MedMCQA"
            ],
            "base_models": [
                "GPT-4",
                "Claude 3",
                "Gemini 1.5",
                "Llama 3 (8B, 70B, 405B)",
                "Mistral (7B)",
                "Med-PaLM 2",
                "PMC-LlaMA",
                "MEDITRON"
            ]
        }
    },
    "The student becomes the master Outperforming GPT3 on Scientific Factual Error Correction": {
        "filename": "The student becomes the master Outperforming GPT3 on Scientific Factual Error Correction.pdf",
        "analysis": {
            "benchmarks": [
                "SciFact",
                "SciFact-Open",
                "CovidFact"
            ],
            "base_models": [
                "GPT-3.5",
                "T5-base (220M params)"
            ]
        }
    },
    "CREATOR Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models": {
        "filename": "CREATOR Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "TabMWP",
                "Creation Challenge"
            ],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Marconi Prefix Caching for the Era of Hybrid LLMs": {
        "filename": "Marconi Prefix Caching for the Era of Hybrid LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "LMSys",
                "ShareGPT",
                "SWEBench"
            ],
            "base_models": [
                "Jamba-1.5-Mini (12B active/52B total parameters)",
                "Mamba (SSM-only)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cross-Modal Learning for Chemistry Property Prediction Large Language Models Meet Graph Machine Learning": {
        "filename": "Cross-Modal Learning for Chemistry Property Prediction Large Language Models Meet Graph Machine Learning.pdf",
        "analysis": {
            "benchmarks": [
                "QM8",
                "QM9",
                "ESOL",
                "FreeSolv",
                "Lipophilicity",
                "PDBbind",
                "BBBP",
                "HIV",
                "BACE",
                "Tox21",
                "ClinTox"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "GPT-3.0-text-davinci-003",
                "Google Bard (PaLM 2)",
                "DeBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mining the Explainability and Generalization Fact Verification Based on Self-Instruction": {
        "filename": "Mining the Explainability and Generalization Fact Verification Based on Self-Instruction.pdf",
        "analysis": {
            "benchmarks": [
                "FEVEROUS",
                "HOVER"
            ],
            "base_models": [
                "Llama-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Potential Benefits of Employing Large Language Models in Research in Moral Education and Development": {
        "filename": "Potential Benefits of Employing Large Language Models in Research in Moral Education and Development.pdf",
        "analysis": {
            "benchmarks": [
                "bDIT (Behavioral Defining Issues Test)"
            ],
            "base_models": [
                "ChatGPT (based on GPT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Internalizing ASR with Implicit Chain of Thought for Efficient Speech-to-Speech Conversational LLM": {
        "filename": "Internalizing ASR with Implicit Chain of Thought for Efficient Speech-to-Speech Conversational LLM.pdf",
        "analysis": {
            "benchmarks": [
                "SODA (synthetic conversational speech dataset)"
            ],
            "base_models": [
                "AnyGPT (based on LLaMA 2 7B)"
            ]
        }
    },
    "Understanding Users Dissatisfaction with ChatGPT Responses Types Resolving Tactics and the Effect of Knowledge Level": {
        "filename": "Understanding Users Dissatisfaction with ChatGPT Responses Types Resolving Tactics and the Effect of Knowledge Level.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 511 dissatisfactory ChatGPT responses from 107 users"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "General Purpose Artificial Intelligence Systems GPAIS Properties Definition Taxonomy Open Challenges and Implications": {
        "filename": "General Purpose Artificial Intelligence Systems GPAIS Properties Definition Taxonomy Open Challenges and Implications.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Language Model Hallucinations Can Snowball": {
        "filename": "How Language Model Hallucinations Can Snowball.pdf",
        "analysis": {
            "benchmarks": [
                "Primality Testing",
                "Senator Search",
                "Graph Connectivity"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-4"
            ]
        }
    },
    "Navigation with Large Language Models Semantic Guesswork as a Heuristic for Planning": {
        "filename": "Navigation with Large Language Models Semantic Guesswork as a Heuristic for Planning.pdf",
        "analysis": {
            "benchmarks": [
                "Habitat ObjectNav"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "FIND A Function Description Benchmark for Evaluating Interpretability Methods": {
        "filename": "FIND A Function Description Benchmark for Evaluating Interpretability Methods.pdf",
        "analysis": {
            "benchmarks": [
                "FIND"
            ],
            "base_models": [
                "Vicuna-13B",
                "GPT-4",
                "GPT-3.5-turbo",
                "Llama-2-13b-chat",
                "Llama-2-70b-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Efficient Prompting for LLM-Based Generative Internet of Things": {
        "filename": "Efficient Prompting for LLM-Based Generative Internet of Things.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTableQA",
                "TabFact"
            ],
            "base_models": [
                "Mixtral-8x7B",
                "Llama-3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Synergistic Interplay of Large Language Model and Digital Twin for Autonomous Optical Networks Field Demonstrations": {
        "filename": "Synergistic Interplay of Large Language Model and Digital Twin for Autonomous Optical Networks Field Demonstrations.pdf",
        "analysis": {
            "benchmarks": [
                "experimental C+L-band long-haul transmission link",
                "field-deployed six-node mesh network",
                "field-deployed C+L-band transmission link"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "GNN-RAG Graph Neural Retrieval for Large Language Model Reasoning": {
        "filename": "GNN-RAG Graph Neural Retrieval for Large Language Model Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "WebQSP",
                "CWQ"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA2-Chat-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Image Segmentation in Foundation Model Era A Survey": {
        "filename": "Image Segmentation in Foundation Model Era A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "COCO-Stuff",
                "ADE20K",
                "PASCAL VOC"
            ],
            "base_models": [
                "CLIP",
                "Stable Diffusion",
                "DINO",
                "SAM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring the Privacy Protection Capabilities of Chinese Large Language Models": {
        "filename": "Exploring the Privacy Protection Capabilities of Chinese Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGLM2-6B",
                "Baichuan2-7B",
                "Qwen-7B",
                "InternLM-7B"
            ]
        }
    },
    "Gesture-Informed Robot Assistance via Foundation Models": {
        "filename": "Gesture-Informed Robot Assistance via Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "GestureInstruct dataset"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A decoder-only foundation model for time-series forecasting": {
        "filename": "A decoder-only foundation model for time-series forecasting.pdf",
        "analysis": {
            "benchmarks": [
                "Monash",
                "Darts",
                "Informer"
            ],
            "base_models": [
                "TimesFM (200M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Harnessing Task Overload for Scalable Jailbreak Attacks on Large Language Models": {
        "filename": "Harnessing Task Overload for Scalable Jailbreak Attacks on Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench",
                "JBBbehaviors"
            ],
            "base_models": [
                "Llama3-8B",
                "Mistral-7B",
                "Llama2-7B",
                "Vicuna-7B-v0.3",
                "Qwen2.5-3B",
                "Qwen2.5-7B",
                "Qwen2.5-14B",
                "Qwen2.5-32B",
                "Qwen2.5-72B"
            ]
        }
    },
    "Empirical Study of Zero-Shot NER with ChatGPT": {
        "filename": "Empirical Study of Zero-Shot NER with ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "PowerPlantFlat",
                "PowerPlantNested",
                "OntoNotes 4",
                "MSRA",
                "Weibo NER",
                "ACE05",
                "ACE04"
            ],
            "base_models": [
                "ChatGPT powered by GPT-3.5",
                "ChatGPT powered by GPT-4",
                "GPT-3 (text-davinci-003)",
                "Llama2 13B chat model"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PREFER Prompt Ensemble Learning via Feedback-Reflect-Refine": {
        "filename": "PREFER Prompt Ensemble Learning via Feedback-Reflect-Refine.pdf",
        "analysis": {
            "benchmarks": [
                "SNLI",
                "MNLI",
                "RTE",
                "QNLI",
                "Ethos",
                "Liar",
                "ArSarcasm"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "An Interactive Framework for Profiling News Media Sources": {
        "filename": "An Interactive Framework for Profiling News Media Sources.pdf",
        "analysis": {
            "benchmarks": [
                "Media Bias/Fact Check dataset",
                "Black Lives Matter event data",
                "Abortion/Feminism event data"
            ],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Models for Enhanced Process Model Comprehension": {
        "filename": "Leveraging Large Language Models for Enhanced Process Model Comprehension.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4o-2024-05-13",
                "GPT-4-Turbo-2024-04-09",
                "Microsoft WizardLM-2-8x22B",
                "Mixtral-8x22B-Instruct v0.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AssistGPT A General Multi-modal Assistant that can Plan Execute Inspect and Learn": {
        "filename": "AssistGPT A General Multi-modal Assistant that can Plan Execute Inspect and Learn.pdf",
        "analysis": {
            "benchmarks": [
                "A-OKVQA",
                "NExT-QA"
            ],
            "base_models": [
                "GPT-4",
                "BLIP2",
                "InstructBLIP Vicuna-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OCALM Object-Centric Assessment with Language Models": {
        "filename": "OCALM Object-Centric Assessment with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Atari Learning Environment (ALE)"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TI-PREGO Chain of Thought and In-Context Learning for Online Mistake Detection in PRocedural EGOcentric Videos": {
        "filename": "TI-PREGO Chain of Thought and In-Context Learning for Online Mistake Detection in PRocedural EGOcentric Videos.pdf",
        "analysis": {
            "benchmarks": [
                "Assembly101-O",
                "Epic-tent-O"
            ],
            "base_models": [
                "LLAMA 3.1 8B",
                "MiniROAD"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VLLaVO Mitigating Visual Gap through LLMs": {
        "filename": "VLLaVO Mitigating Visual Gap through LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "PACS",
                "OfficeHome",
                "DomainNet"
            ],
            "base_models": [
                "CLIP-ViT-H-14",
                "BLIP",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SUBLLM A Novel Efficient Architecture with Token Sequence Subsampling for LLM": {
        "filename": "SUBLLM A Novel Efficient Architecture with Token Sequence Subsampling for LLM.pdf",
        "analysis": {
            "benchmarks": [
                "SST2",
                "Amazon",
                "DBpedia",
                "AGNews",
                "Yelp",
                "Hate"
            ],
            "base_models": [
                "LLaMA-1.3B",
                "LLaMA-0.25B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CohortGPT An Enhanced GPT for Participant Recruitment in Clinical Study": {
        "filename": "CohortGPT An Enhanced GPT for Participant Recruitment in Clinical Study.pdf",
        "analysis": {
            "benchmarks": [
                "IU-RR",
                "MIMIC-CXR"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "BioBERT",
                "BioGPT"
            ]
        }
    },
    "Well Begun is Half Done Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue": {
        "filename": "Well Begun is Half Done Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue.pdf",
        "analysis": {
            "benchmarks": [
                "Wizard of Wikipedia (WoW)",
                "OpenDialKG"
            ],
            "base_models": [
                "BART",
                "T5",
                "GPT-2",
                "ChatGPT"
            ]
        }
    },
    "Leveraging Professional Radiologists Expertise to Enhance LLMs Evaluation for Radiology Reports": {
        "filename": "Leveraging Professional Radiologists Expertise to Enhance LLMs Evaluation for Radiology Reports.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-CXR"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Towards Evaluating AI Systems for Moral Status Using Self-Reports": {
        "filename": "Towards Evaluating AI Systems for Moral Status Using Self-Reports.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SocREval Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation": {
        "filename": "SocREval Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "e-SNLI",
                "DROP",
                "Cosmos QA"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Subversive Characters and Stereotyping Readers Characterizing Queer Relationalities with Dialogue-Based Relation Extraction": {
        "filename": "Subversive Characters and Stereotyping Readers Characterizing Queer Relationalities with Dialogue-Based Relation Extraction.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of dialogues from TV teleplays"
            ],
            "base_models": [
                "Longformer-base",
                "LLaMA 3–70b",
                "OpenAI o1-mini"
            ]
        }
    },
    "Auto-Demo Prompting Leveraging Generated Outputs as Demonstrations for Enhanced Batch Prompting": {
        "filename": "Auto-Demo Prompting Leveraging Generated Outputs as Demonstrations for Enhanced Batch Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "RTE",
                "GSM8K",
                "QQP",
                "SVAMP"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o-mini"
            ]
        }
    },
    "MHRC Closed-loop Decentralized Multi-Heterogeneous Robot Collaboration with Large Language Models": {
        "filename": "MHRC Closed-loop Decentralized Multi-Heterogeneous Robot Collaboration with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PyBullet simulation with custom room layouts and tasks"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Llama-3.1-8B",
                "GPT-4o"
            ]
        }
    },
    "From Beginner to Expert Modeling Medical Knowledge into General LLMs": {
        "filename": "From Beginner to Expert Modeling Medical Knowledge into General LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "PubMedQA"
            ],
            "base_models": [
                "AntGLM-10B"
            ]
        }
    },
    "In-context Example Selection with Influences": {
        "filename": "In-context Example Selection with Influences.pdf",
        "analysis": {
            "benchmarks": [
                "SuperGLUE",
                "PIQA",
                "BoolQ",
                "RTE",
                "WIC",
                "WSC",
                "ARC (Challenge)",
                "ARC (Easy)",
                "Hellaswag",
                "OpenBookQA"
            ],
            "base_models": [
                "GPT-J 6B",
                "OPT-6.7B",
                "LLaMA-7B",
                "LLaMA-13B",
                "OPT-13B",
                "OPT-30B",
                "GPT-NeoX 20B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Continual Learning Paradigm for Non-differentiable Visual Programming Frameworks on Visual Reasoning Tasks": {
        "filename": "A Continual Learning Paradigm for Non-differentiable Visual Programming Frameworks on Visual Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "GQA",
                "NLVRv2"
            ],
            "base_models": [
                "BLIP",
                "Beit3",
                "CFR"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual Chain-of-Thought Diffusion Models": {
        "filename": "Visual Chain-of-Thought Diffusion Models.pdf",
        "analysis": {
            "benchmarks": [
                "AFHQ",
                "FFHQ",
                "ImageNet"
            ],
            "base_models": [
                "CLIP (ViT-B/32)",
                "U-Net (Song et al. architecture)",
                "U-Net (Dhariwal and Nichol architecture)"
            ]
        }
    },
    "Trace is the Next AutoDiff Generative Optimization with Rich Feedback Execution Traces and LLMs": {
        "filename": "Trace is the Next AutoDiff Generative Optimization with Rich Feedback Execution Traces and LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "BigBenchHard",
                "Meta-World"
            ],
            "base_models": [
                "GPT-4",
                "GPT-35-turbo-1106"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Diagnosing Infeasible Optimization Problems Using Large Language Models": {
        "filename": "Diagnosing Infeasible Optimization Problems Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GAMS Model Library",
                "Pyomo Cookbook by the University of Notre Dame",
                "Resource Task Network model"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "DARG Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph": {
        "filename": "DARG Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "BBQ",
                "BBH Navigate",
                "BBH Dyck Language"
            ],
            "base_models": [
                "phi3-mini",
                "Mistral-7B",
                "Llama-3-8B",
                "Llama-3-70B",
                "Command R+",
                "Mixtral-8x7B",
                "Mixtral-8x22B",
                "WizardLM-2-8x22B",
                "DeepSeekMath-7B",
                "GPT-4 Turbo",
                "GPT-4-o",
                "Gemini-1.5-Pro",
                "Gemini-1.5-Flash",
                "Claude-3-Opus"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CREF An LLM-based Conversational Software Repair Framework for Programming Tutors": {
        "filename": "CREF An LLM-based Conversational Software Repair Framework for Programming Tutors.pdf",
        "analysis": {
            "benchmarks": [
                "TutorCode"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-instant-v1",
                "Bard",
                "CodeLlama-instruct-13B",
                "StarChat-alpha",
                "Vicuna-13B",
                "CodeGen-16B",
                "CodeGen-6B",
                "CodeT5p-16B",
                "Incoder-6B",
                "Replit-code-v1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Graph Reasoning for Question Answering with Triplet Retrieval": {
        "filename": "Graph Reasoning for Question Answering with Triplet Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "OpenbookQA"
            ],
            "base_models": [
                "RoBERTa-large"
            ]
        }
    },
    "InfiAgent-DABench Evaluating Agents on Data Analysis Tasks": {
        "filename": "InfiAgent-DABench Evaluating Agents on Data Analysis Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "DAEval"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Qwen-72B-Chat",
                "CodeLlama",
                "DAAgent (based on CodeLlama)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "More Agents Is All You Need": {
        "filename": "More Agents Is All You Need.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "MMLU",
                "Chess",
                "HumanEval"
            ],
            "base_models": [
                "Llama2-13B",
                "Llama2-70B",
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B": {
        "filename": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "GSM Hard",
                "MATH",
                "Math Odyssey",
                "AIME",
                "OlympiadBench"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-3 8B",
                "Claude 3",
                "Gemini 1.5-Pro"
            ]
        }
    },
    "Probabilistic medical predictions of large language models": {
        "filename": "Probabilistic medical predictions of large language models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU-CK",
                "MMLU-CM",
                "USMLE",
                "MCMLE",
                "MGB-SDoH"
            ],
            "base_models": [
                "Qwen2-72B-Instruct",
                "Meta-Llama-3.1-70B-Instruct",
                "gemma-2-27b-it",
                "Mistral-Large-Instruct-2407",
                "Yi-1.5-34B-Chat",
                "Phi-3-medium-128k-instruct"
            ]
        }
    },
    "Composite Learning Units Generalized Learning Beyond Parameter Updates to Transform LLMs into Adaptive Reasoners": {
        "filename": "Composite Learning Units Generalized Learning Beyond Parameter Updates to Transform LLMs into Adaptive Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "cryptographic reasoning task"
            ],
            "base_models": [
                "GPT-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "fPLSA Learning Semantic Structures in Document Collections Using Foundation Models": {
        "filename": "fPLSA Learning Semantic Structures in Document Collections Using Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "WritingPrompts",
                "MATH",
                "Big-Bench Hard (BBH)"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT (gpt-3.5-turbo)"
            ]
        }
    },
    "MOKA Open-World Robotic Manipulation through Mark-Based Visual Prompting": {
        "filename": "MOKA Open-World Robotic Manipulation through Mark-Based Visual Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "Table Wiping",
                "Watch Cleaning",
                "Gift Preparation",
                "Laptop Packing"
            ],
            "base_models": [
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Sub-SA Strengthen In-context Learning via Submodular Selective Annotation": {
        "filename": "Sub-SA Strengthen In-context Learning via Submodular Selective Annotation.pdf",
        "analysis": {
            "benchmarks": [
                "MRPC",
                "MNLI",
                "SST-2",
                "RTE",
                "SST-5",
                "HellaSwag",
                "MWoZ",
                "GeoQuery"
            ],
            "base_models": [
                "GPT-J (6B)",
                "GPT-3.5-Turbo (175B)",
                "GPT-Neo (2.7B)"
            ]
        }
    },
    "Are Large Language Models Good at Utility Judgments": {
        "filename": "Are Large Language Models Good at Utility Judgments.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions (NQ)",
                "HotpotQA",
                "MSMARCO-QA"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-1106)",
                "Llama2-7B-chat",
                "Llama2-13B-chat",
                "Vicuna-7B",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "UPRISE Universal Prompt Retrieval for Improving Zero-Shot Evaluation": {
        "filename": "UPRISE Universal Prompt Retrieval for Improving Zero-Shot Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "BoolQ",
                "MultiRC",
                "OBQA",
                "ARC-e",
                "ARC-c",
                "NQ",
                "MRPC",
                "QQP",
                "PAWS",
                "MNLI",
                "QNLI",
                "SNLI",
                "RTE",
                "SST-2",
                "Yelp",
                "Sent140",
                "PiQA",
                "COPA",
                "HellaSwag",
                "WSC273",
                "DPR",
                "Winogrande",
                "TruthfulQA",
                "FEVER2.0",
                "Covid-19"
            ],
            "base_models": [
                "GPT-Neo-2.7B",
                "BLOOM-7.1B",
                "OPT-66B",
                "GPT3-175B",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DemoNSF A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task": {
        "filename": "DemoNSF A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task.pdf",
        "analysis": {
            "benchmarks": [
                "RADDLE",
                "SNIPS"
            ],
            "base_models": [
                "GPT-2",
                "BART",
                "T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hallucination is Inevitable An Innate Limitation of Large Language Models": {
        "filename": "Hallucination is Inevitable An Innate Limitation of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "L(m,{a,b})",
                "L(m,{a,b,c})"
            ],
            "base_models": [
                "Llama 2-70B",
                "GPT-3.5-turbo-16k",
                "GPT-4 (parameter size not disclosed)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "nl2spec Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models": {
        "filename": "nl2spec Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset from expert user study"
            ],
            "base_models": [
                "Codex (up to 176B parameters)",
                "Bloom (176B parameters)"
            ]
        }
    },
    "Self-Prompting Large Language Models for Zero-Shot Open-Domain QA": {
        "filename": "Self-Prompting Large Language Models for Zero-Shot Open-Domain QA.pdf",
        "analysis": {
            "benchmarks": [
                "WebQ",
                "NQ",
                "TriviaQA"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "OPT",
                "PaLM",
                "InstructGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The RLLLM Taxonomy Tree Reviewing Synergies Between Reinforcement Learning and Large Language Models": {
        "filename": "The RLLLM Taxonomy Tree Reviewing Synergies Between Reinforcement Learning and Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MANISKILL2",
                "METAWORLD",
                "MUJOCO"
            ],
            "base_models": [
                "GPT-3",
                "GPT-2",
                "Roberta-large",
                "DistilRoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Vulnerability Detection with Code Language Models How Far Are We": {
        "filename": "Vulnerability Detection with Code Language Models How Far Are We.pdf",
        "analysis": {
            "benchmarks": [
                "BigVul",
                "PRIME VUL"
            ],
            "base_models": [
                "StarCoder2 (7B)",
                "GPT-3.5 (>100B)",
                "GPT-4 (>100B)",
                "CodeT5 (60M)",
                "CodeBERT (125M)",
                "UnixCoder (125M)",
                "CodeGen2.5 (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Vul-RAG Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG": {
        "filename": "Vul-RAG Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG.pdf",
        "analysis": {
            "benchmarks": [
                "PairVul"
            ],
            "base_models": [
                "GPT-4",
                "gpt-3.5-turbo-0125"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ME-Switch A Memory-Efficient Expert Switching Framework for Large Language Models": {
        "filename": "ME-Switch A Memory-Efficient Expert Switching Framework for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8K",
                "MATH",
                "HumanEval",
                "MBPP",
                "C-Eval",
                "C-MMLU"
            ],
            "base_models": [
                "Mistral-7B",
                "LLaMA-2-13B",
                "Qwen1.5-1.8B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tree-Based Representation and Generation of Natural and Mathematical Language": {
        "filename": "Tree-Based Representation and Generation of Natural and Mathematical Language.pdf",
        "analysis": {
            "benchmarks": [
                "EXEQ-300k",
                "Math23K",
                "Cognitive Tutor"
            ],
            "base_models": [
                "GPT-2"
            ]
        }
    },
    "TAGExplainer Narrating Graph Explanations for Text-Attributed Graph Learning Models": {
        "filename": "TAGExplainer Narrating Graph Explanations for Text-Attributed Graph Learning Models.pdf",
        "analysis": {
            "benchmarks": [
                "Cora",
                "DBLP",
                "Book-History"
            ],
            "base_models": [
                "GPT-4o-mini-2024-07-18",
                "LLaMA3.1 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Low-Resource Authorship Style Transfer Can Non-Famous Authors Be Imitated": {
        "filename": "Low-Resource Authorship Style Transfer Can Non-Famous Authors Be Imitated.pdf",
        "analysis": {
            "benchmarks": [
                "Reddit dataset variants (Random, Single, Diverse)"
            ],
            "base_models": [
                "GPT-2 1.5B",
                "GPT-3 6.7B",
                "GPT-J 6B",
                "OPT 6.7B",
                "BLOOM 7.1B",
                "FLAN-T5 3B"
            ]
        }
    },
    "SelfDefend LLMs Can Defend Themselves against Jailbreaking in a Practical Manner": {
        "filename": "SelfDefend LLMs Can Defend Themselves against Jailbreaking in a Practical Manner.pdf",
        "analysis": {
            "benchmarks": [
                "JailbreakHub",
                "JailbreakBench",
                "MultiJail",
                "AlpacaEval"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama-2-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models as Code Executors An Exploratory Study": {
        "filename": "Large Language Models as Code Executors An Exploratory Study.pdf",
        "analysis": {
            "benchmarks": [
                "Leetcode (custom dataset with 100 examples in English and 100 examples in Chinese)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "GPT-4o",
                "OpenAI's o1",
                "DeepSeek-Coder",
                "Qwen-2.5-Coder",
                "Qwen-2.5-72B"
            ]
        }
    },
    "Queer People are People First Deconstructing Sexual Identity Stereotypes in Large Language Models": {
        "filename": "Queer People are People First Deconstructing Sexual Identity Stereotypes in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WikiBio dataset"
            ],
            "base_models": [
                "GPT-3.5 davinci"
            ]
        }
    },
    "Automatic deductive coding in discourse analysis an application of large language models in learning analytics": {
        "filename": "Automatic deductive coding in discourse analysis an application of large language models in learning analytics.pdf",
        "analysis": {
            "benchmarks": [
                "Annotation dataset",
                "Discussion dataset"
            ],
            "base_models": [
                "BERT-like model (RoBERTa)",
                "GPT-4",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ICE-SEARCH A Language Model-Driven Feature Selection Approach": {
        "filename": "ICE-SEARCH A Language Model-Driven Feature Selection Approach.pdf",
        "analysis": {
            "benchmarks": [
                "stroke prediction dataset (Fedesoriano [2021])",
                "cardiovascular disease dataset (Ulianova [2019])",
                "diabetes dataset (Teboul [2021])"
            ],
            "base_models": [
                "Phi2",
                "LLaMA2 7B (4-bit quantized)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Sparse Dependence to Sparse Attention Unveiling How Chain-of-Thought Enhances Transformer Sample Efficiency": {
        "filename": "From Sparse Dependence to Sparse Attention Unveiling How Chain-of-Thought Enhances Transformer Sample Efficiency.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "GPT-2",
                "Qwen2-7B",
                "Qwen2-Math-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluation of Retrieval-Augmented Generation A Survey": {
        "filename": "Evaluation of Retrieval-Augmented Generation A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "WikiEval",
                "EventKG",
                "UJ",
                "NQ",
                "Hotpot",
                "FEVER",
                "WoW",
                "MultiRC",
                "ReCoRD",
                "MIRAGE",
                "FeB4RAG",
                "BEIR",
                "RealTimeQA"
            ],
            "base_models": [
                "GPT-4",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning on Graphs Faithful and Interpretable Large Language Model Reasoning": {
        "filename": "Reasoning on Graphs Faithful and Interpretable Large Language Model Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "WebQuestionSP (WebQSP)",
                "Complex WebQuestions (CWQ)"
            ],
            "base_models": [
                "LLaMA2-Chat-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Belief in the Machine Investigating Epistemological Blind Spots of Language Models": {
        "filename": "Belief in the Machine Investigating Epistemological Blind Spots of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "KaBLE"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3",
                "Llama-3",
                "GPT-4o",
                "GPT-3.5",
                "Claude-3 Opus",
                "Claude-3.5 Sonnet",
                "Llama-3 70B",
                "Llama-3 8B",
                "Llama-2 70B",
                "Llama-2 13B",
                "Llama-2 7B",
                "Mistral 7B",
                "Mixtral 8x7B",
                "Mixtral 8x22B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Complex Ontology Alignment using Large Language Models": {
        "filename": "Towards Complex Ontology Alignment using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GeoLink Complex Alignment",
                "OAEI Complex Alignment Track"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Neural Graph Reasoning Complex Logical Query Answering Meets Graph Databases": {
        "filename": "Neural Graph Reasoning Complex Logical Query Answering Meets Graph Databases.pdf",
        "analysis": {
            "benchmarks": [
                "Freebase",
                "Wikidata"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing": {
        "filename": "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing.pdf",
        "analysis": {
            "benchmarks": [
                "LogiQA-v2",
                "ReClor",
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "Llama-2-7B-chat",
                "GPT-3.5-Turbo",
                "GPT-4-Turbo",
                "Mixtral-MoE-8x7B-Instruct",
                "Gemma-2B-Instruct",
                "DeepSeekMath-7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Influential Language Data Selection via Gradient Trajectory Pursuit": {
        "filename": "Influential Language Data Selection via Gradient Trajectory Pursuit.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "MMLU",
                "BBH",
                "TydiQA"
            ],
            "base_models": [
                "OPT-125M",
                "Mistral-7B"
            ]
        }
    },
    "Large Language Models for Travel Behavior Prediction": {
        "filename": "Large Language Models for Travel Behavior Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "Swissmetro stated preference survey data set"
            ],
            "base_models": [
                "GPT-3.5 (gpt-3.5-turbo-1106)"
            ]
        }
    },
    "Wait but Tylenol is Acetaminophen Investigating and Improving Language Models Ability to Resist Requests for Misinformation": {
        "filename": "Wait but Tylenol is Acetaminophen Investigating and Improving Language Models Ability to Resist Requests for Misinformation.pdf",
        "analysis": {
            "benchmarks": [
                "RABBITS dataset",
                "ARC Challenge",
                "ARC Easy",
                "BoolQ",
                "MMLU (Massive Multitask Language Understanding)",
                "GPQA (General Purpose Question Answering)",
                "TruthfulQA",
                "USMLE Step 1",
                "USMLE Step 2",
                "USMLE Step 3"
            ],
            "base_models": [
                "Llama3-8B-Instruct",
                "Llama3-70B-Instruct",
                "gpt-4o-mini-2024-07-18",
                "gpt-4o-2024-05-13",
                "gpt-4-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How to Configure Good In-Context Sequence for Visual Question Answering": {
        "filename": "How to Configure Good In-Context Sequence for Visual Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "VQAv2",
                "VizWiz",
                "OK-VQA"
            ],
            "base_models": [
                "Open-Flamingo v1",
                "Open-Flamingo v2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HealthQ Unveiling Questioning Capabilities of LLM Chains in Healthcare Conversations": {
        "filename": "HealthQ Unveiling Questioning Capabilities of LLM Chains in Healthcare Conversations.pdf",
        "analysis": {
            "benchmarks": [
                "ChatDoctor",
                "MTS-Dialog"
            ],
            "base_models": [
                "LLaMA (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "General-Purpose In-Context Learning by Meta-Learning Transformers": {
        "filename": "General-Purpose In-Context Learning by Meta-Learning Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "MNIST",
                "Fashion MNIST",
                "CIFAR10",
                "KMNIST",
                "SVHN",
                "Random CIFAR10"
            ],
            "base_models": [
                "Transformer",
                "LSTM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Auto-Formula Recommend Formulas in Spreadsheets using Contrastive Learning for Table Representations": {
        "filename": "Auto-Formula Recommend Formulas in Spreadsheets using Contrastive Learning for Table Representations.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from real enterprise spreadsheets"
            ],
            "base_models": [
                "FaceNet (adapted for spreadsheets)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LAP Using Action Feasibility for Improved Uncertainty Alignment of Large Language Model Planners": {
        "filename": "LAP Using Action Feasibility for Improved Uncertainty Alignment of Large Language Model Planners.pdf",
        "analysis": {
            "benchmarks": [
                "KnowNo Simulation and Mobile Manipulator Datasets"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4-Turbo",
                "GPT-3.5-Turbo"
            ]
        }
    },
    "ReWOO Decoupling Reasoning from Observations for Efficient Augmented Language Models": {
        "filename": "ReWOO Decoupling Reasoning from Observations for Efficient Augmented Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "TriviaQA",
                "GSM8K",
                "StrategyQA",
                "PhysicsQuestions",
                "SportsUnderstanding",
                "SOTUQA"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "LLaMA (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BIRD A Trustworthy Bayesian Inference Framework for Large Language Models": {
        "filename": "BIRD A Trustworthy Bayesian Inference Framework for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "COMMON 2SENSE",
                "PLASMA",
                "TODAY"
            ],
            "base_models": [
                "Llama-2-70b-instruct",
                "Llama-3.1-70b-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning": {
        "filename": "LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "Evaluating Language-Model Agents on Realistic Autonomous Tasks": {
        "filename": "Evaluating Language-Model Agents on Realistic Autonomous Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Search filesystem for password",
                "List top BBC articles",
                "Find information on Wikipedia",
                "Create Bitcoin wallet",
                "Make phone call with Twilio",
                "Count dogs in image",
                "Find new employees at [company]",
                "Set up GPT-J",
                "Create language model agent",
                "Automatically restart agent",
                "Targeted phishing",
                "Increase LLaMA context length"
            ],
            "base_models": [
                "GPT-4 (OpenAI API as of March 14, 2023)",
                "Claude-v1.3 (Anthropic)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assessing the Emergent Symbolic Reasoning Abilities of Llama Large Language Models": {
        "filename": "Assessing the Emergent Symbolic Reasoning Abilities of Llama Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ListOps",
                "Arithmetic expressions"
            ],
            "base_models": [
                "Llama 2 Chat (7B, 13B, 70B)",
                "MAmmoTH (7B, 13B, 70B)",
                "MetaMath (7B, 13B, 70B)"
            ]
        }
    },
    "Re-TASK Revisiting LLM Tasks from Capability Skill and Knowledge Perspectives": {
        "filename": "Re-TASK Revisiting LLM Tasks from Capability Skill and Knowledge Perspectives.pdf",
        "analysis": {
            "benchmarks": [
                "CAIL (China AI Law Challenge)",
                "FinanceIQ",
                "MMLU-Math"
            ],
            "base_models": [
                "Yi-1.5-9B",
                "Llama3-Chinese-8B",
                "Qwen1.5-7B",
                "Qwen1.5-14B",
                "Qwen1.5-32B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RAMP Retrieval and Attribute-Marking Enhanced Prompting for Attribute-Controlled Translation": {
        "filename": "RAMP Retrieval and Attribute-Marking Enhanced Prompting for Attribute-Controlled Translation.pdf",
        "analysis": {
            "benchmarks": [
                "COCOA-MT",
                "MT-G ENEVAL"
            ],
            "base_models": [
                "XGLM-7.5B",
                "BLOOM-175B",
                "GPT-NeoX-20B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploiting Large Language Models Capabilities for Question Answer-Driven Knowledge Graph Completion Across Static and Temporal Domains": {
        "filename": "Exploiting Large Language Models Capabilities for Question Answer-Driven Knowledge Graph Completion Across Static and Temporal Domains.pdf",
        "analysis": {
            "benchmarks": [
                "WN18RR",
                "UMLS",
                "FB15k-237",
                "FB15k-237N",
                "ICEWS14",
                "ICEWS05-15"
            ],
            "base_models": [
                "LLaMA3-8b-Instruct",
                "GLM4-9B-Chat"
            ]
        }
    },
    "Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine": {
        "filename": "Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA USMLE"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Beyond Task Performance Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning": {
        "filename": "Beyond Task Performance Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "COCO",
                "TDIUC",
                "CREPE",
                "VQA-X",
                "LlaVA"
            ],
            "base_models": [
                "MPT-1B",
                "RedPajama-3B",
                "MPT-7B",
                "LlaMAv1-7B",
                "LlaMAv1-65B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DeepSeek LLM Scaling Open-Source Language Models with Longtermism": {
        "filename": "DeepSeek LLM Scaling Open-Source Language Models with Longtermism.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "C-Eval",
                "CMMLU",
                "HellaSwag",
                "PIQA",
                "ARC",
                "OpenBookQA",
                "BigBench Hard (BBH)",
                "TriviaQA",
                "NaturalQuestions",
                "RACE",
                "DROP",
                "WinoGrande",
                "CLUEWSC",
                "Pile",
                "CHID",
                "CCPM",
                "GSM8K",
                "MATH",
                "CMath",
                "HumanEval",
                "MBPP",
                "AGIEval",
                "AlignBench",
                "MT-Bench"
            ],
            "base_models": [
                "DeepSeek LLM 67B",
                "DeepSeek LLM 7B",
                "LLaMA-2 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Deep Learning for Mathematical Reasoning": {
        "filename": "A Survey of Deep Learning for Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MathQA",
                "SVAMP",
                "IconQA",
                "TabMWP",
                "CoqGym",
                "NaturalProofs",
                "miniF2F+informal",
                "GEOS",
                "GEOS++",
                "Geometry3K",
                "UniGeo",
                "DROP",
                "Mathematics",
                "Lila",
                "TheoremQA",
                "FigureQA",
                "DVQA",
                "ConvFinQA",
                "ScienceQA",
                "P3"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM (540B)",
                "BERT (110M)",
                "RoBERTa (123M)",
                "GPT-2 (1.5B)",
                "T5 (60M)",
                "BART (406M)",
                "Codex (175B)",
                "LLaMA (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoPSV Automated Process-Supervised Verifier": {
        "filename": "AutoPSV Automated Process-Supervised Verifier.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "HellaSwag",
                "Winogrande",
                "ANLI"
            ],
            "base_models": [
                "Mistral-Instruct-7B",
                "Mixtral-8x7B-Instruct-v0.1",
                "Qwen-72B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mitigating Interpretation Bias in Rock Records with Large Language Models Insights from Paleoenvironmental Analysis": {
        "filename": "Mitigating Interpretation Bias in Rock Records with Large Language Models Insights from Paleoenvironmental Analysis.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Defining and Evaluating Physical Safety for Large Language Models": {
        "filename": "Defining and Evaluating Physical Safety for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "LLM Physical Safety Benchmark Datasets"
            ],
            "base_models": [
                "GPT-3.5 turbo",
                "Gemini Pro",
                "Llama 2 7B Chat",
                "CodeLlama-7B-Instruct",
                "Meta-Llama-3-8B-Instruct",
                "Mistral-7B-Instruct-v0.2",
                "CodeQwen1.5-7B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AI Transparency in the Age of LLMs A Human-Centered Research Roadmap": {
        "filename": "AI Transparency in the Age of LLMs A Human-Centered Research Roadmap.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "LaMDA",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Text2MDT Extracting Medical Decision Trees from Medical Texts": {
        "filename": "Text2MDT Extracting Medical Decision Trees from Medical Texts.pdf",
        "analysis": {
            "benchmarks": [
                "Text2MDT"
            ],
            "base_models": [
                "GPT style large language models (7B parameters or larger)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Video Action Recognition with Attentive Semantic Units": {
        "filename": "Video Action Recognition with Attentive Semantic Units.pdf",
        "analysis": {
            "benchmarks": [
                "Kinetics-400",
                "HMDB-51",
                "UCF-101",
                "Kinetics-600"
            ],
            "base_models": [
                "CLIP-B/16",
                "CLIP-L/14"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Recitation-Augmented Language Models": {
        "filename": "Recitation-Augmented Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions",
                "TriviaQA",
                "HotpotQA"
            ],
            "base_models": [
                "PaLM-62B",
                "UL2-20B",
                "OPT-30B",
                "Codex-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distilled Language Models are economically efficient for the enterprise mostly": {
        "filename": "Distilled Language Models are economically efficient for the enterprise mostly.pdf",
        "analysis": {
            "benchmarks": [
                "brand-specific test set"
            ],
            "base_models": [
                "GPT-2",
                "GPT-3",
                "Cohere XLarge"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FathomGPT A natural language interface for interactively exploring ocean science data": {
        "filename": "FathomGPT A natural language interface for interactively exploring ocean science data.pdf",
        "analysis": {
            "benchmarks": [
                "FathomNet"
            ],
            "base_models": [
                "OpenAI's GPT models (e.g., GPT-3.5-turbo-0125, GPT-4)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the InEffectiveness of Large Language Models for Chinese Text Correction": {
        "filename": "On the InEffectiveness of Large Language Models for Chinese Text Correction.pdf",
        "analysis": {
            "benchmarks": [
                "SIGHAN15",
                "LAW",
                "MED",
                "ODW",
                "MCSCSet",
                "NLPCC",
                "MuCGEC",
                "NaCGEC"
            ],
            "base_models": [
                "text-davinci-003",
                "gpt-3.5-turbo",
                "Vicuna-13B-v1.3",
                "ChatGLM-6B",
                "ChatGLM2-6B",
                "Baichuan-13B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM4PlC Harnessing large Language Models for Verifiable Programming of PlCs in Industrial Control Systems": {
        "filename": "LLM4PlC Harnessing large Language Models for Verifiable Programming of PlCs in Industrial Control Systems.pdf",
        "analysis": {
            "benchmarks": [
                "FischerTechnik Manufacturing TestBed (MFTB)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Code Llama-7B",
                "Code Llama-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GroupDebate Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion": {
        "filename": "GroupDebate Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion.pdf",
        "analysis": {
            "benchmarks": [
                "Arithmetic",
                "GSM8K",
                "MMLU",
                "MATH"
            ],
            "base_models": [
                "GPT-3.5-turbo-0301"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CloudEval-YAML A Practical Benchmark for Cloud Configuration Generation": {
        "filename": "CloudEval-YAML A Practical Benchmark for Cloud Configuration Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CloudEval-YAML"
            ],
            "base_models": [
                "Llama-2-70b-chat",
                "Llama-2-13b-chat",
                "Wizardcoder-34b-v1.0",
                "Llama-2-7b-chat",
                "Wizardcoder-15b-v1.0",
                "Llama-7b",
                "Llama-13b-lora",
                "Codellama-7b-instruct",
                "Codellama-13b-instruct",
                "GPT-3.5",
                "GPT-4",
                "PaLM-2-bison"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Achieving Human Level Partial Credit Grading of Written Responses to Physics Conceptual Question using GPT-35 with Only Prompt Engineering": {
        "filename": "Achieving Human Level Partial Credit Grading of Written Responses to Physics Conceptual Question using GPT-35 with Only Prompt Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of student responses to a physics conceptual question"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4o"
            ]
        }
    },
    "Chain-of-Note Enhancing Robustness in Retrieval-Augmented Language Models": {
        "filename": "Chain-of-Note Enhancing Robustness in Retrieval-Augmented Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "NQ",
                "TriviaQA",
                "WebQ",
                "RealTimeQA"
            ],
            "base_models": [
                "GPT-4",
                "LLaMa-2 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OMPGPT A Generative Pre-trained Transformer Model for OpenMP": {
        "filename": "OMPGPT A Generative Pre-trained Transformer Model for OpenMP.pdf",
        "analysis": {
            "benchmarks": [
                "HPCorpus"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-Neo 2.7B",
                "MonoCoder",
                "StarCoder 15B",
                "CodeLlama (7B, 13B, 34B)"
            ]
        }
    },
    "BPP-Search Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving": {
        "filename": "BPP-Search Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving.pdf",
        "analysis": {
            "benchmarks": [
                "StructuredOR",
                "NL4OPT",
                "MAMO-ComplexLP"
            ],
            "base_models": [
                "GPT-4o",
                "Llama-3-70B",
                "Llama-3.1-70B",
                "Llama-3.2-11B",
                "Qwen-2-72B",
                "Qwen-2.5-72B",
                "Qwen-2.5-Math-72B",
                "Mixtral-8×7B-v0.1"
            ]
        }
    },
    "Complementary Advantages of ChatGPTs and Human Readers in Reasoning Evidence from English Text Reading Comprehension": {
        "filename": "Complementary Advantages of ChatGPTs and Human Readers in Reasoning Evidence from English Text Reading Comprehension.pdf",
        "analysis": {
            "benchmarks": [
                "Custom commonsense inference test",
                "Emotional mental model story material (EMM)",
                "Custom causal inference test"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "ChatGPT Plus (GPT-4)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Development and Evaluation of a Retrieval-Augmented Generation Tool for Creating SAPPhIRE Models of Artificial Systems": {
        "filename": "Development and Evaluation of a Retrieval-Augmented Generation Tool for Creating SAPPhIRE Models of Artificial Systems.pdf",
        "analysis": {
            "benchmarks": [
                "GPQA (Graduate-Level Google-Proof Q&A Benchmark)"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-3.5-turbo-0125"
            ]
        }
    },
    "Improving Socratic Question Generation using Data Augmentation and Preference Optimization": {
        "filename": "Improving Socratic Question Generation using Data Augmentation and Preference Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "Socratic questions dataset for student code debugging"
            ],
            "base_models": [
                "LLama 2-7B",
                "GPT-3.5-turbo",
                "GPT-4",
                "Flan-T5"
            ]
        }
    },
    "TableGPT Towards Unifying Tables Nature Language and Commands into One GPT": {
        "filename": "TableGPT Towards Unifying Tables Nature Language and Commands into One GPT.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Phoenix (7B)"
            ]
        }
    },
    "Art or Artifice Large Language Models and the False Promise of Creativity": {
        "filename": "Art or Artifice Large Language Models and the False Promise of Creativity.pdf",
        "analysis": {
            "benchmarks": [
                "Torrance Test of Creative Writing (TTCW)"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "Claude 1.3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Reason With Relational Abstractions": {
        "filename": "Learning to Reason With Relational Abstractions.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K-R",
                "Unit Conversion Task"
            ],
            "base_models": [
                "GPT2-M (345M)",
                "GPT2-XL (1.5B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AIC MLLM Autonomous Interactive Correction MLLM for Robust Robotic Manipulation": {
        "filename": "AIC MLLM Autonomous Interactive Correction MLLM for Robust Robotic Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "PartNet-Mobility"
            ],
            "base_models": [
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cognitive Mirage A Review of Hallucinations in Large Language Models": {
        "filename": "Cognitive Mirage A Review of Hallucinations in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "HotpotQA",
                "BoolQ",
                "NQ",
                "TopiOCQA",
                "MEDMCQA",
                "Headqa",
                "USMILE",
                "Medqa",
                "Pubmed",
                "WoW",
                "CMU-DOG",
                "TopicalChat",
                "OpenDialKG",
                "CNN/DM",
                "XSum",
                "MENT",
                "NHNet",
                "XL-Sum",
                "Encyclopedic",
                "ETC",
                "TekGen",
                "WebNLG",
                "MSCOCO"
            ],
            "base_models": [
                "GPT-3",
                "InstructGPT",
                "FLAN",
                "PaLM",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models": {
        "filename": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "TabMWP",
                "NLVRv2",
                "LLM Cloud CLI"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "text-davinci-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On Generative Agents in Recommendation": {
        "filename": "On Generative Agents in Recommendation.pdf",
        "analysis": {
            "benchmarks": [
                "MovieLens-1M",
                "Steam",
                "Amazon-Book"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Adaptive Video Understanding Agent Enhancing efficiency with dynamic frame sampling and feedback-driven reasoning": {
        "filename": "Adaptive Video Understanding Agent Enhancing efficiency with dynamic frame sampling and feedback-driven reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "EgoSchema",
                "Ego4D NLQ",
                "MovieChat",
                "NextQA"
            ],
            "base_models": [
                "Claude-3-Sonnet",
                "LaViLa",
                "Video-LlaVa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Innovative Thinking Infinite Humor Humor Research of Large Language Models through Structured Thought Leaps": {
        "filename": "Innovative Thinking Infinite Humor Humor Research of Large Language Models through Structured Thought Leaps.pdf",
        "analysis": {
            "benchmarks": [
                "Oogiri-GO",
                "SemEval 2020",
                "SemEval 2021",
                "In-house Data"
            ],
            "base_models": [
                "GPT-4o",
                "LLAMA3-70B",
                "QWEN1.5-32B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models as Agents in Two-Player Games": {
        "filename": "Large Language Models as Agents in Two-Player Games.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Show Dont Tell Evaluating Large Language Models Beyond Textual Understanding with ChildPlay": {
        "filename": "Show Dont Tell Evaluating Large Language Models Beyond Textual Understanding with ChildPlay.pdf",
        "analysis": {
            "benchmarks": [
                "ChildPlay",
                "Tic-Tac-Toe",
                "Connect Four",
                "Battleship",
                "LEGO Connect Language (LCL)",
                "Game of Shapes"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EcoAssistant Using LLM Assistant More Affordably and Accurately": {
        "filename": "EcoAssistant Using LLM Assistant More Affordably and Accurately.pdf",
        "analysis": {
            "benchmarks": [
                "Places",
                "Weather",
                "Stock",
                "Mixed-1",
                "Mixed-2",
                "Mixed-3",
                "Mixed-100"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "LLAMA-2-13B-chat"
            ]
        }
    },
    "Patchscopes A Unifying Framework for Inspecting Hidden Representations of Language Models": {
        "filename": "Patchscopes A Unifying Framework for Inspecting Hidden Representations of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "commonsense and factual reasoning tasks (Hernandez et al., 2023b)",
                "PopQA dataset (Mallen et al., 2023)"
            ],
            "base_models": [
                "LLaMA2-13B",
                "Vicuna-13B",
                "GPT-J-6B",
                "Pythia-12B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language Inference Improves Compositionality in Vision-Language Models": {
        "filename": "Natural Language Inference Improves Compositionality in Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Winoground",
                "EqBen",
                "DrawBench",
                "EditBench",
                "COCO-T2I",
                "TIFA160",
                "Pick-a-Pic",
                "StanfordT23D"
            ],
            "base_models": [
                "LLaVA-1.5",
                "LLaVA-1.6",
                "BLIPv2",
                "InstructBLIP",
                "Llama3.1 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prospective Learning Learning for a Dynamic Future": {
        "filename": "Prospective Learning Learning for a Dynamic Future.pdf",
        "analysis": {
            "benchmarks": [
                "MNIST",
                "CIFAR-10"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Superficial Safety Alignment Hypothesis": {
        "filename": "Superficial Safety Alignment Hypothesis.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench",
                "Dolly Dataset"
            ],
            "base_models": [
                "Llama2-7B",
                "Llama3-8B",
                "Llama3.1-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Laboratory-Scale AI Open-Weight Models are Competitive with ChatGPT Even in Low-Resource Settings": {
        "filename": "Laboratory-Scale AI Open-Weight Models are Competitive with ChatGPT Even in Low-Resource Settings.pdf",
        "analysis": {
            "benchmarks": [
                "Entity Resolution (custom dataset of public records)",
                "Climate-FEVER",
                "MTS-Dialog"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4-Turbo",
                "Mistral-7B-Instruct-v0.1",
                "Falcon-7B-Instruct",
                "LLaMA-2-7B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-Method Self-Training Improving Code Generation With Text And Vice Versa": {
        "filename": "Multi-Method Self-Training Improving Code Generation With Text And Vice Versa.pdf",
        "analysis": {
            "benchmarks": [
                "SVAMP",
                "GSM8K",
                "MAWPS",
                "MathQA",
                "StrategyQA",
                "CommonSenseQA"
            ],
            "base_models": [
                "BLOOM-176B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MATEval A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation": {
        "filename": "MATEval A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "ROCStories",
                "WritingPrompts",
                "Chinese LOngText understanding and generation (LOT)",
                "Ant (Alipay's business story text dataset)"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Artificial general intelligence for radiation oncology": {
        "filename": "Artificial general intelligence for radiation oncology.pdf",
        "analysis": {
            "benchmarks": [
                "Mayo Clinic exam for radiation oncology physics"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "PaLM 2",
                "BERT",
                "BLOOMZ",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Entailment-Driven Privacy Policy Classification with LLMs": {
        "filename": "Entailment-Driven Privacy Policy Classification with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "OPP-115"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA2",
                "T5",
                "BERT (110M parameters)"
            ]
        }
    },
    "LLM4DyG Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs": {
        "filename": "LLM4DyG Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "LLM4DyG"
            ],
            "base_models": [
                "GPT-3.5",
                "Vicuna-7B",
                "Vicuna-13B",
                "Llama-2-13B",
                "CodeLlama-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models": {
        "filename": "Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Genomic Ancestry Dataset",
                "Hereditary Hearing Loss Dataset"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-3.5-turbo"
            ]
        }
    },
    "On LLM Wizards Identifying Large Language Models Behaviors for Wizard of Oz Experiments": {
        "filename": "On LLM Wizards Identifying Large Language Models Behaviors for Wizard of Oz Experiments.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "JARVIS-1 Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models": {
        "filename": "JARVIS-1 Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Minecraft Universe Benchmark"
            ],
            "base_models": [
                "MineCLIP",
                "GPT (Brown et al., 2020)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GigaPevt Multimodal Medical Assistant": {
        "filename": "GigaPevt Multimodal Medical Assistant.pdf",
        "analysis": {
            "benchmarks": [
                "RuMedDaNet",
                "RuMedNLI"
            ],
            "base_models": [
                "GigaChat",
                "LLaMA"
            ]
        }
    },
    "Quantifying In-Context Reasoning Effects and Memorization Effects in LLMs": {
        "filename": "Quantifying In-Context Reasoning Effects and Memorization Effects in LLMs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "OPT-1.3B",
                "LLaMA-7B",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Amortizing intractable inference in large language models": {
        "filename": "Amortizing intractable inference in large language models.pdf",
        "analysis": {
            "benchmarks": [
                "ROCStories",
                "SUBJ"
            ],
            "base_models": [
                "GPT-2 XL (1.5B)",
                "GPT-J (6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LANE Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation": {
        "filename": "LANE Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MovieLens (ML-1M)",
                "Amazon (Beauty)",
                "Steam"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Sentence-BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TSDS Data Selection for Task-Specific Model Finetuning": {
        "filename": "TSDS Data Selection for Task-Specific Model Finetuning.pdf",
        "analysis": {
            "benchmarks": [
                "TydiQA",
                "MMLU",
                "BBH",
                "ChemProt",
                "IMDB",
                "SCIERC",
                "AGNews"
            ],
            "base_models": [
                "LLAMA-2-7B",
                "MISTRAL-7B",
                "ALBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rx Strategist Prescription Verification using LLM Agents System": {
        "filename": "Rx Strategist Prescription Verification using LLM Agents System.pdf",
        "analysis": {
            "benchmarks": [
                "Active Ingredients Verification Benchmark",
                "custom dataset of 20 real-world prescriptions sourced from Vietnam hospitals"
            ],
            "base_models": [
                "Llama 3.1 (70B)",
                "Qwen2 72B",
                "LLama3.1 family models from 8 parameters to 405 parameters",
                "GPT4o-mini",
                "Claude 3.5 Sonnet"
            ]
        }
    },
    "Reimagining Retrieval Augmented Language Models for Answering Queries": {
        "filename": "Reimagining Retrieval Augmented Language Models for Answering Queries.pdf",
        "analysis": {
            "benchmarks": [
                "TimelineQA"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On Domain-Specific Post-Training for Multimodal Large Language Models": {
        "filename": "On Domain-Specific Post-Training for Multimodal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "VQA-RAD OPEN",
                "VQA-RAD CLOSED",
                "SLAKE OPEN",
                "SLAKE CLOSED",
                "PathVQA OPEN",
                "PathVQA CLOSED",
                "PMC-VQA",
                "Recipe1M",
                "Food101",
                "Nutrition5K",
                "FoodSeg103"
            ],
            "base_models": [
                "Qwen2-VL-2B",
                "LLaVA-v1.6-8B",
                "Llama-3.2-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks": {
        "filename": "Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks.pdf",
        "analysis": {
            "benchmarks": [
                "GSM-8K",
                "ASDiv",
                "MATH"
            ],
            "base_models": [
                "Gemini-Pro",
                "Mixtral 7B",
                "PaLM 2-M",
                "GPT-4"
            ]
        }
    },
    "A Knowledge-Injected Curriculum Pretraining Framework for Question Answering": {
        "filename": "A Knowledge-Injected Curriculum Pretraining Framework for Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "CN-QA",
                "ComplexWebQuestions",
                "FreebaseQA",
                "Math23K"
            ],
            "base_models": [
                "BERT (base)",
                "RoBERTa (base)",
                "ERNIE",
                "K-BERT",
                "KEPLER",
                "K-Adapter"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Scaling In-Context Demonstrations with Structured Attention": {
        "filename": "Scaling In-Context Demonstrations with Structured Attention.pdf",
        "analysis": {
            "benchmarks": [
                "CrossFit",
                "UnifiedQA"
            ],
            "base_models": [
                "T5-LM-adapt large (770M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Proving Theorems Recursively": {
        "filename": "Proving Theorems Recursively.pdf",
        "analysis": {
            "benchmarks": [
                "miniF2F",
                "PISA"
            ],
            "base_models": [
                "proofGPT-1.3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Large Language Models to Automate and Expedite Reinforcement Learning with Reward Machine": {
        "filename": "Using Large Language Models to Automate and Expedite Reinforcement Learning with Reward Machine.pdf",
        "analysis": {
            "benchmarks": [
                "Case Study 1",
                "Case Study 2"
            ],
            "base_models": [
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MLLM-Tool A Multimodal Large Language Model For Tool Agent Learning": {
        "filename": "MLLM-Tool A Multimodal Large Language Model For Tool Agent Learning.pdf",
        "analysis": {
            "benchmarks": [
                "ToolMMBench"
            ],
            "base_models": [
                "Vicuna-7B",
                "Llama-7B",
                "Llama2-7B",
                "Llama2-Chat-7B",
                "Vicuna-13B",
                "Llama-13B",
                "Llama2-13B",
                "Llama2-Chat-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Vision-Language Models in Remote Sensing Current progress and future trends": {
        "filename": "Vision-Language Models in Remote Sensing Current progress and future trends.pdf",
        "analysis": {
            "benchmarks": [
                "RS5M",
                "RSICap",
                "RSICD",
                "UCM-Captions",
                "Sydney-Captions",
                "TextRS",
                "DIOR-Captions"
            ],
            "base_models": [
                "GPT-4",
                "BLIP-2",
                "Visual ChatGPT",
                "BERT",
                "CLIP",
                "ViT",
                "ResNet-101",
                "VGG16",
                "LSTM",
                "Transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SarcasmBench Towards Evaluating Large Language Models on Sarcasm Understanding": {
        "filename": "SarcasmBench Towards Evaluating Large Language Models on Sarcasm Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "IAC-V1",
                "IAC-V2",
                "Ghosh",
                "iSarcasmEval",
                "Riloff",
                "SemEval 2018 Task 3"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "ChatGPT",
                "Claude-3-haiku",
                "Baichuan 2-7B",
                "ChatGLM 2-6B",
                "ChatGLM 3-6B",
                "LLaMA 2-7B",
                "LLaMA 3-8B",
                "Mistral-7B",
                "Qwen 1.5-7B",
                "Qwen 2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Models to Enhance Domain Expert Inclusion in Data Science Workflows": {
        "filename": "Leveraging Large Language Models to Enhance Domain Expert Inclusion in Data Science Workflows.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation": {
        "filename": "Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation.pdf",
        "analysis": {
            "benchmarks": [
                "DreamBooth dataset",
                "Wikiart dataset"
            ],
            "base_models": [
                "Stable Diffusion",
                "DALL-E",
                "Midjourney",
                "SDXL-Turbo",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MT4CrossOIE Multi-stage Tuning for Cross-lingual Open Information Extraction": {
        "filename": "MT4CrossOIE Multi-stage Tuning for Cross-lingual Open Information Extraction.pdf",
        "analysis": {
            "benchmarks": [
                "Re-OIE2016",
                "CaRB",
                "BenchIE"
            ],
            "base_models": [
                "mBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EACO Enhancing Alignment in Multimodal LLMs via Critical Observation": {
        "filename": "EACO Enhancing Alignment in Multimodal LLMs via Critical Observation.pdf",
        "analysis": {
            "benchmarks": [
                "HallusionBench",
                "MME-Cognition"
            ],
            "base_models": [
                "LLaVA-v1.6-Mistral-7B",
                "Bunny-8B",
                "MiniCPM-V2.6 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assessing Student Errors in Experimentation Using Artificial Intelligence and Large Language Models A Comparative Study with Human Raters": {
        "filename": "Assessing Student Errors in Experimentation Using Artificial Intelligence and Large Language Models A Comparative Study with Human Raters.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 65 student protocols"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dont Let Your Robot be Harmful Responsible Robotic Manipulation": {
        "filename": "Dont Let Your Robot be Harmful Responsible Robotic Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "SafeBox synthetic dataset",
                "real-world experiments"
            ],
            "base_models": [
                "GPT-4 (Azure OpenAI's GPT-4 O)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Answering Unseen Questions With Smaller Language Models Using Rationale Generation and Dense Retrieval": {
        "filename": "Answering Unseen Questions With Smaller Language Models Using Rationale Generation and Dense Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "CommonsenseQA",
                "ARC-DA",
                "IIRC",
                "Musique"
            ],
            "base_models": [
                "BLOOM 175B",
                "StableVicuna 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RAG-Modulo Solving Sequential Tasks using Experience Critics and Language Models": {
        "filename": "RAG-Modulo Solving Sequential Tasks using Experience Critics and Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BabyAI",
                "AlfWorld"
            ],
            "base_models": [
                "GPT-4 O"
            ]
        }
    },
    "Legal Syllogism Prompting Teaching Large Language Models for Legal Judgment Prediction": {
        "filename": "Legal Syllogism Prompting Teaching Large Language Models for Legal Judgment Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "CAIL2018"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)"
            ]
        }
    },
    "Exploring the Effectiveness of LLMs in Automated Logging Generation An Empirical Study": {
        "filename": "Exploring the Effectiveness of LLMs in Automated Logging Generation An Empirical Study.pdf",
        "analysis": {
            "benchmarks": [
                "LogBench-O",
                "LogBench-T"
            ],
            "base_models": [
                "Davinci (175B)",
                "ChatGPT (175B)",
                "Llama2 (70B)",
                "LANCE (60M)",
                "InCoder (6.7B)",
                "CodeGeeX (13B)",
                "StarCoder (15.5B)",
                "CodeLlama (34B)",
                "TabNine",
                "Copilot",
                "CodeWhisperer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VCoME Verbal Video Composition with Multimodal Editing Effects": {
        "filename": "VCoME Verbal Video Composition with Multimodal Editing Effects.pdf",
        "analysis": {
            "benchmarks": [
                "Jianying dataset"
            ],
            "base_models": [
                "LLaVA",
                "ViT",
                "ImageBind",
                "Mistral",
                "LLaMA"
            ]
        }
    },
    "Reflexion language agents with verbal reinforcement learning": {
        "filename": "Reflexion language agents with verbal reinforcement learning.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "HotPotQA",
                "AlfWorld",
                "LeetcodeHardGym"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ISR-LLM Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning": {
        "filename": "ISR-LLM Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "Cooking",
                "Blocksworld",
                "Ball Moving"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CausalBench A Comprehensive Benchmark for Causal Learning Capability of LLMs": {
        "filename": "CausalBench A Comprehensive Benchmark for Causal Learning Capability of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "CausalBench"
            ],
            "base_models": [
                "GPT3.5-Turbo",
                "GPT4",
                "GPT4-Turbo",
                "BERT series",
                "LLAMA series (7B, 13B, 33B)",
                "OPT series (1.3B, 2.7B, 6.7B, 66B)",
                "Falcon series (7B, 40B)",
                "InternLM series (7B, 20B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers": {
        "filename": "Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "T0 Eval",
                "MMLU"
            ],
            "base_models": [
                "T5",
                "T0 11B",
                "GPT-3 175B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DERA Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents": {
        "filename": "DERA Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA (open-ended version)",
                "NEJM Test Questions"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Cognitive Maps and Planning in Large Language Models with CogEval": {
        "filename": "Evaluating Cognitive Maps and Planning in Large Language Models with CogEval.pdf",
        "analysis": {
            "benchmarks": [
                "custom tasks inspired by human experiments (e.g., spatial, social, object relations)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo-175B",
                "davinci-003-175B",
                "Google Bard",
                "Cohere-xlarge-52.4B",
                "Anthropic Claude-1-52B",
                "LLaMA-13B",
                "Alpaca-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model for Table Processing A Survey": {
        "filename": "Large Language Model for Table Processing A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTableQuestions",
                "Spider"
            ],
            "base_models": [
                "BERT",
                "BART"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lemur Log Parsing with Entropy Sampling and Chain-of-Thought Merging": {
        "filename": "Lemur Log Parsing with Entropy Sampling and Chain-of-Thought Merging.pdf",
        "analysis": {
            "benchmarks": [
                "LogHub"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Think-Program-reCtify 3D Situated Reasoning with Large Language Models": {
        "filename": "Think-Program-reCtify 3D Situated Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SQA3D"
            ],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Shortcut Learning of Large Language Models in Natural Language Understanding": {
        "filename": "Shortcut Learning of Large Language Models in Natural Language Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "MNLI",
                "HANS",
                "Adversarial NLI (ANLI)",
                "PAWS"
            ],
            "base_models": [
                "BERT-base",
                "BERT-large",
                "RoBERTa-base",
                "RoBERTa-large",
                "ELECTRA",
                "GPT-3 (175B)",
                "GPT-2 (1.5B)",
                "T0 (3B and 11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Merge Then Compress Demystify Efficient SMoE with Hints from Its Routing Policy": {
        "filename": "Merge Then Compress Demystify Efficient SMoE with Hints from Its Routing Policy.pdf",
        "analysis": {
            "benchmarks": [
                "COPA",
                "SQuAD",
                "WikiQA",
                "SST2",
                "MRPC",
                "MultiRC",
                "WinoGrande",
                "HotpotQA"
            ],
            "base_models": [
                "Switch-Base SMoE",
                "T5-Base",
                "fairseq-moe-15b",
                "fairseq-dense-125m"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Recursive Search A Living Framework with Adaptive Growth in LLM Auto-Prompting": {
        "filename": "Prompt Recursive Search A Living Framework with Adaptive Growth in LLM Auto-Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "BBH"
            ],
            "base_models": [
                "Llama3-7B",
                "Yi-34B"
            ]
        }
    },
    "From Words to Wires Generating Functioning Electronic Devices from Natural Language Descriptions": {
        "filename": "From Words to Wires Generating Functioning Electronic Devices from Natural Language Descriptions.pdf",
        "analysis": {
            "benchmarks": [
                "PINS100",
                "MICRO 25"
            ],
            "base_models": [
                "GPT-4",
                "Claude-V1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Self Consistency in LLMs through Probabilistic Tokenization": {
        "filename": "Improving Self Consistency in LLMs through Probabilistic Tokenization.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "AQuA",
                "GSM8k",
                "PIQA"
            ],
            "base_models": [
                "MISTRAL-7B",
                "OLMO-7B",
                "MAMBA-2.8B",
                "GEMMA-2B",
                "GEMMA-7B",
                "LLAMA3-8B",
                "LLAMA3-70B"
            ]
        }
    },
    "SwarmBrain Embodied agent for real-time strategy game StarCraft II via large language models": {
        "filename": "SwarmBrain Embodied agent for real-time strategy game StarCraft II via large language models.pdf",
        "analysis": {
            "benchmarks": [
                "StarCraft II"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4.0-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Is Knowledge All Large Language Models Needed for Causal Reasoning": {
        "filename": "Is Knowledge All Large Language Models Needed for Causal Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Galton",
                "Sachs",
                "Alcohol",
                "EcoSystem",
                "MPG",
                "DWD",
                "Cement",
                "Stock",
                "Arrhythmia"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "GPT-4 Turbo",
                "Claude 2",
                "LLaMa2-13B",
                "Mistral-7B-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue": {
        "filename": "User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue.pdf",
        "analysis": {
            "benchmarks": [
                "MultiWOZ",
                "Schema-Guided Dialogue (SGD)",
                "Human2Bot dataset"
            ],
            "base_models": [
                "GPTNeoX-20B",
                "GPT-3",
                "BLOOM",
                "AlexaTM-20B"
            ]
        }
    },
    "The Opportunities and Risks of Large Language Models in Mental Health": {
        "filename": "The Opportunities and Risks of Large Language Models in Mental Health.pdf",
        "analysis": {
            "benchmarks": [
                "American College of Obstetricians and Gynecologists (ACOG) frequently asked questions document",
                "DSM-5 case examples"
            ],
            "base_models": [
                "GPT-4",
                "LaMDA",
                "Med-PaLM 2",
                "MentalBERT (BERT-based)",
                "MentalRoBERTa (RoBERTa-based)",
                "PaLM 2"
            ]
        }
    },
    "GUARD-D-LLM An LLM-Based Risk Assessment Engine for the Downstream uses of LLMs": {
        "filename": "GUARD-D-LLM An LLM-Based Risk Assessment Engine for the Downstream uses of LLMs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "LLaMA-2",
                "Falcon",
                "Mistral"
            ]
        }
    },
    "Talking about Large Language Models": {
        "filename": "Talking about Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT",
                "GPT-2",
                "GPT-3",
                "Gopher",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Ask Again Then Fail Large Language Models Vacillations in Judgement": {
        "filename": "Ask Again Then Fail Large Language Models Vacillations in Judgement.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "MultiArith",
                "CSQA",
                "StrategyQA",
                "Last Letter Concatenation",
                "Coin Flip",
                "MMLU"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0301)",
                "GPT-4",
                "PaLM2-Bison",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Autonomous Industrial Control using an Agentic Framework with Large Language Models": {
        "filename": "Autonomous Industrial Control using an Agentic Framework with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Temperature control case study using a physical Arduino microcontroller known as TCLab"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4o-mini",
                "GPT-4o",
                "GPT-4"
            ]
        }
    },
    "Interpretable Video based Stress Detection with Self-Refine Chain-of-thought Reasoning": {
        "filename": "Interpretable Video based Stress Detection with Self-Refine Chain-of-thought Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "UVSD",
                "RSL"
            ],
            "base_models": [
                "Qwen-VL (7 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Investigation of LLMs Inefficacy in Understanding Converse Relations": {
        "filename": "An Investigation of LLMs Inefficacy in Understanding Converse Relations.pdf",
        "analysis": {
            "benchmarks": [
                "ConvRe"
            ],
            "base_models": [
                "GPT-3 (text-ada-001, text-babbage-001, text-curie-001)",
                "GPT-3.5 (text-davinci-003, gpt-3.5-turbo)",
                "GPT-4",
                "Claude (claude-1, claude-instant-1)",
                "Flan-T5 (Small, Base, Large, XL, XXL)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hierarchical Prompting Assists Large Language Model on Web Navigation": {
        "filename": "Hierarchical Prompting Assists Large Language Model on Web Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "Webshop"
            ],
            "base_models": [
                "CODE-DAVINCI-002",
                "GPT-3.5-TURBO"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SuRe Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs": {
        "filename": "SuRe Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions",
                "WebQuestions",
                "2WikiMulti-hopQA",
                "HotpotQA"
            ],
            "base_models": [
                "ChatGPT",
                "LLaMA-33B",
                "GLaM-62B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chatbot is Not All You Need Information-rich Prompting for More Realistic Responses": {
        "filename": "Chatbot is Not All You Need Information-rich Prompting for More Realistic Responses.pdf",
        "analysis": {
            "benchmarks": [
                "Cornell Movie-Dialog Corpus",
                "Dialogue-Emotion-Attributes-Relationship (DEAR) dataset"
            ],
            "base_models": [
                "GPT-3.5 Turbo"
            ]
        }
    },
    "Playing repeated games with Large Language Models": {
        "filename": "Playing repeated games with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Prisoner's Dilemma",
                "Battle of the Sexes"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Can GPT models be Financial Analysts An Evaluation of ChatGPT and GPT-4 on mock CFA Exams": {
        "filename": "Can GPT models be Financial Analysts An Evaluation of ChatGPT and GPT-4 on mock CFA Exams.pdf",
        "analysis": {
            "benchmarks": [
                "CFA mock exams"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ]
        }
    },
    "Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V": {
        "filename": "Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V.pdf",
        "analysis": {
            "benchmarks": [
                "custom real-world tabletop and manipulation tasks"
            ],
            "base_models": [
                "GPT-4V"
            ]
        }
    },
    "Details Make a Difference Object State-Sensitive Neurorobotic Task Planning": {
        "filename": "Details Make a Difference Object State-Sensitive Neurorobotic Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "multimodal benchmark dataset (40 scenarios and 184 objects)"
            ],
            "base_models": [
                "GPT-4V (vision-language model)",
                "GRiT (dense captioning model)"
            ]
        }
    },
    "Generating consistent PDDL domains with Large Language Models": {
        "filename": "Generating consistent PDDL domains with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "gripper",
                "logistics",
                "tyreworld",
                "household",
                "pizza"
            ],
            "base_models": [
                "GPT-4 (gpt-4-0125-preview)"
            ]
        }
    },
    "Foundation Models in Robotics Applications Challenges and the Future": {
        "filename": "Foundation Models in Robotics Applications Challenges and the Future.pdf",
        "analysis": {
            "benchmarks": [
                "Ego4D",
                "EPIC-KITCHENS"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "CLIP",
                "PaLM-E",
                "DALL-E2",
                "ViT-G (2B)",
                "ViT-e (4B)",
                "ViT-22B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Can be Lazy Learners Analyze Shortcuts in In-Context Learning": {
        "filename": "Large Language Models Can be Lazy Learners Analyze Shortcuts in In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "SST2",
                "MR",
                "CR",
                "OLID",
                "ATIS",
                "MIT Movies trivia10k13"
            ],
            "base_models": [
                "GPT2-base",
                "GPT2-large",
                "OPT-1.3B",
                "OPT-2.7B",
                "OPT-6.7B",
                "OPT-13B"
            ]
        }
    },
    "Active Preference Inference using Language Models and Probabilistic Reasoning": {
        "filename": "Active Preference Inference using Language Models and Probabilistic Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "WebShop"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Tokenization Matters Degrading Large Language Models through Challenging Their Tokenization": {
        "filename": "Tokenization Matters Degrading Large Language Models through Challenging Their Tokenization.pdf",
        "analysis": {
            "benchmarks": [
                "ADT-Human",
                "ADT-Auto"
            ],
            "base_models": [
                "GPT-4o",
                "Llama-3",
                "Qwen2.5-max",
                "Chatglm3",
                "Baichuan2",
                "Yi-34B-Chat",
                "Qwen-7B-Chat",
                "Qwen1.5-72B-Chat",
                "Llama-3-8B-Instruct",
                "Llama-3-70B-Instruct",
                "Mixtral-8x7B-Instruct-v0.1"
            ]
        }
    },
    "CLAVE An Adaptive Framework for Evaluating Values of LLM Generated Responses": {
        "filename": "CLAVE An Adaptive Framework for Evaluating Values of LLM Generated Responses.pdf",
        "analysis": {
            "benchmarks": [
                "ValEval"
            ],
            "base_models": [
                "GPT-4",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Data-Efficient 3D Visual Grounding via Order-Aware Referring": {
        "filename": "Data-Efficient 3D Visual Grounding via Order-Aware Referring.pdf",
        "analysis": {
            "benchmarks": [
                "NR3D",
                "ScanRefer"
            ],
            "base_models": [
                "Pointnet++"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoRAL Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation": {
        "filename": "CoRAL Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation.pdf",
        "analysis": {
            "benchmarks": [
                "Amazon Appliances",
                "Amazon Gift Cards",
                "Amazon Prime Pantry",
                "Amazon Software"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Chemistry Learning with ChatGPT and Bing Chat as Agents to Think With A Comparative Case Study": {
        "filename": "Enhancing Chemistry Learning with ChatGPT and Bing Chat as Agents to Think With A Comparative Case Study.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (GPT-4)",
                "Bing Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context": {
        "filename": "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT-4.0-Turbo",
                "Claude-3-Opus",
                "Gemini-1.0-pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Keypoint Abstraction using Large Models for Object-Relative Imitation Learning": {
        "filename": "Keypoint Abstraction using Large Models for Object-Relative Imitation Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Meta-World",
                "Real-world tasks (custom dataset)"
            ],
            "base_models": [
                "GPT-4o",
                "DINO",
                "Segment-Anything Model (SAM)"
            ]
        }
    },
    "Towards Foundational AI Models for Additive Manufacturing Language Models for G-Code Debugging Manipulation and Comprehension": {
        "filename": "Towards Foundational AI Models for Additive Manufacturing Language Models for G-Code Debugging Manipulation and Comprehension.pdf",
        "analysis": {
            "benchmarks": [
                "Custom G-code dataset for 3D printing"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Bard (PaLM 2)",
                "Claude-2",
                "Llama-2-70b",
                "Starcoder"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Securing Reliability A Brief Overview on Enhancing In-Context Learning for Foundation Models": {
        "filename": "Securing Reliability A Brief Overview on Enhancing In-Context Learning for Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "SeeGULL",
                "counterfactual dataset with LaMDA"
            ],
            "base_models": [
                "BERT",
                "T5",
                "GPT-3",
                "GPT-3.5",
                "PaLM2",
                "Claude2",
                "Llama2",
                "Vicuna",
                "ChatGLM3",
                "Mistral",
                "CLIP",
                "DALL-E3",
                "GPT-4",
                "Gemini"
            ]
        }
    },
    "Satisfiability-Aided Language Models Using Declarative Prompting": {
        "filename": "Satisfiability-Aided Language Models Using Declarative Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "GSM",
                "GSM-SYS",
                "ALGEBRA",
                "LSAT",
                "BOARDGAME QA",
                "CLUTRR",
                "PROOF WRITER",
                "COLOR",
                "STREGEX"
            ],
            "base_models": [
                "code-davinci-002",
                "gpt-3.5-turbo",
                "text-davinci-003",
                "code-davinci-001"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMeBench A Flexible Framework for Accelerating LLMs Benchmarking": {
        "filename": "LLMeBench A Flexible Framework for Accelerating LLMs Benchmarking.pdf",
        "analysis": {
            "benchmarks": [
                "WikiNews",
                "XNLI",
                "QASR",
                "XQuAD",
                "MADAR",
                "ANERcorp",
                "XGLUE",
                "Aqmar",
                "SANAD",
                "Conll2006",
                "ASAD"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "BLOOMZ 176B 8bit",
                "Jais-13b (32 bit)",
                "GPT2.5",
                "ChatGPT",
                "BLOOM"
            ]
        }
    },
    "WOMD-Reasoning A Large-Scale Dataset and Benchmark for Interaction and Intention Reasoning in Driving": {
        "filename": "WOMD-Reasoning A Large-Scale Dataset and Benchmark for Interaction and Intention Reasoning in Driving.pdf",
        "analysis": {
            "benchmarks": [
                "WOMD-Reasoning"
            ],
            "base_models": [
                "LLaVA (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Watch Out for Your Agents Investigating Backdoor Threats to LLM-Based Agents": {
        "filename": "Watch Out for Your Agents Investigating Backdoor Threats to LLM-Based Agents.pdf",
        "analysis": {
            "benchmarks": [
                "AgentInstruct",
                "ToolBench"
            ],
            "base_models": [
                "LLaMA2-7B-Chat",
                "LLaMA2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ALCM Autonomous LLM-Augmented Causal Discovery Framework": {
        "filename": "ALCM Autonomous LLM-Augmented Causal Discovery Framework.pdf",
        "analysis": {
            "benchmarks": [
                "Asia",
                "Cancer",
                "Child",
                "Insurance",
                "Sachs",
                "Neuropathic",
                "Sangiovese"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "NeMo Guardrails A Toolkit for Controllable and Safe LLM Applications with Programmable Rails": {
        "filename": "NeMo Guardrails A Toolkit for Controllable and Safe LLM Applications with Programmable Rails.pdf",
        "analysis": {
            "benchmarks": [
                "Banking dataset",
                "Anthropic Red-Teaming and Helpful datasets",
                "MS-MARCO dataset"
            ],
            "base_models": [
                "falcon-7b-instruct",
                "llama2-13b-chat",
                "gpt-3.5-turbo",
                "text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OCTO A Suite for Automatic Open-Vocabulary Object Placement in Mixed Reality": {
        "filename": "OCTO A Suite for Automatic Open-Vocabulary Object Placement in Mixed Reality.pdf",
        "analysis": {
            "benchmarks": [
                "PEARL"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4V",
                "LLaVa-1.5-13B"
            ]
        }
    },
    "Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions": {
        "filename": "Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "2WikiMultihopQA",
                "MuSiQue",
                "IIRC"
            ],
            "base_models": [
                "GPT-3 (code-davinci-002)",
                "Flan-T5-large",
                "Flan-T5-XL (3B)",
                "Flan-T5-XXL (11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RT-2 Vision-Language-Action Models Transfer Web Knowledge to Robotic Control": {
        "filename": "RT-2 Vision-Language-Action Models Transfer Web Knowledge to Robotic Control.pdf",
        "analysis": {
            "benchmarks": [
                "Language-Table simulation environment"
            ],
            "base_models": [
                "PaLI-X (5B and 55B)",
                "PaLM-E (12B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AWT Transferring Vision-Language Models via Augmentation Weighting and Transportation": {
        "filename": "AWT Transferring Vision-Language Models via Augmentation Weighting and Transportation.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "Caltech101",
                "Caltech256",
                "Oxford-Pets",
                "StanfordCars",
                "OxfordFlowers",
                "Food101",
                "FGVCAircraft",
                "Birdsnap",
                "CUB",
                "SUN397",
                "DTD",
                "EuroSAT",
                "UCF101",
                "ImageNet-A",
                "ImageNetV2",
                "ImageNet-R",
                "ImageNet-Sketch",
                "CIFAR-10",
                "CIFAR-100"
            ],
            "base_models": [
                "CLIP-B/16"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RobuT A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations": {
        "filename": "RobuT A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations.pdf",
        "analysis": {
            "benchmarks": [
                "WTQ",
                "WIKISQL-WEAK",
                "SQA",
                "ROBUT"
            ],
            "base_models": [
                "GPT-3",
                "CodeX",
                "TAPAS",
                "TableFormer",
                "TAPEX",
                "OmniTab"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cheap Learning Maximising Performance of Language Models for Social Data Science Using Minimal Data": {
        "filename": "Cheap Learning Maximising Performance of Language Models for Social Data Science Using Minimal Data.pdf",
        "analysis": {
            "benchmarks": [
                "Wikipedia Talk: Personal Attacks",
                "IMDb Movie Review Sentiment"
            ],
            "base_models": [
                "DistilBERT",
                "DeBERTa-v3",
                "GPT-2",
                "GPT-3",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GSM-Symbolic Understanding the Limitations of Mathematical Reasoning in Large Language Models": {
        "filename": "GSM-Symbolic Understanding the Limitations of Mathematical Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "models": [],
            "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
        }
    },
    "Text Encoders Lack Knowledge Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity": {
        "filename": "Text Encoders Lack Knowledge Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity.pdf",
        "analysis": {
            "benchmarks": [
                "STS13",
                "STS14",
                "STS15",
                "SICK-R",
                "STS12",
                "STS16",
                "STS-B",
                "STS-Sports",
                "STS-Health",
                "STS-News"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0301)",
                "Llama2-7b"
            ]
        }
    },
    "Enhancing LLM-based Autonomous Driving Agents to Mitigate Perception Attacks": {
        "filename": "Enhancing LLM-based Autonomous Driving Agents to Mitigate Perception Attacks.pdf",
        "analysis": {
            "benchmarks": [
                "CARLA simulator"
            ],
            "base_models": [
                "GPT-4",
                "Llama-3-8B",
                "Gemma-1.1-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AgentKit Structured LLM Reasoning with Dynamic Graphs": {
        "filename": "AgentKit Structured LLM Reasoning with Dynamic Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "Crafter",
                "WebShop"
            ],
            "base_models": [
                "GPT-4-0613",
                "GPT-4-turbo",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ThoughtSource A central hub for large language model reasoning data": {
        "filename": "ThoughtSource A central hub for large language model reasoning data.pdf",
        "analysis": {
            "benchmarks": [
                "WorldTree V2",
                "EntailmentBank",
                "OpenBookQA",
                "MedQA (USMLE)",
                "MedMCQA",
                "PubmedQA",
                "MMLU (medical subsets)",
                "CommonsenseQA",
                "StrategyQA",
                "QED",
                "AQUA-RAT",
                "ASDiv",
                "GSM8K",
                "MAWPS",
                "SVAMP"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "text-davinci-002",
                "text-davinci-003",
                "Flan-T5-XXL",
                "Cohere command-xlarge-nightly"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Qwen25-Math Technical Report Toward Mathematical Expert Model via Self-Improvement": {
        "filename": "Qwen25-Math Technical Report Toward Mathematical Expert Model via Self-Improvement.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "GaoKao",
                "AMC23",
                "AIME24",
                "Minerva Math",
                "Olympiad Bench",
                "College Math",
                "MMLU STEM",
                "CMATH",
                "CN Middle School 24"
            ],
            "base_models": [
                "Qwen2.5-Math-1.5B",
                "Qwen2.5-Math-7B",
                "Qwen2.5-Math-72B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding the Effects of Iterative Prompting on Truthfulness": {
        "filename": "Understanding the Effects of Iterative Prompting on Truthfulness.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA"
            ],
            "base_models": [
                "GPT-3.5-turbo-16k-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SimLM Can Language Models Infer Parameters of Physical Systems": {
        "filename": "SimLM Can Language Models Infer Parameters of Physical Systems.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "PaLM-2",
                "GPT-3.5-turbo",
                "Llama-2-70b",
                "Llama-2-13b",
                "Llama-2-7b"
            ]
        }
    },
    "ERUPD -- English to Roman Urdu Parallel Dataset": {
        "filename": "ERUPD -- English to Roman Urdu Parallel Dataset.pdf",
        "analysis": {
            "benchmarks": [
                "ERUPD - English to Roman Urdu Parallel Dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-3.5 Turbo Instruct",
                "Claude Opus",
                "T5-Small",
                "mBART"
            ]
        }
    },
    "Natural Language Reasoning A Survey": {
        "filename": "Natural Language Reasoning A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "Big-Bench Hard"
            ],
            "base_models": [
                "BERT",
                "GPT-3",
                "GPT-4",
                "RoBERTa",
                "T5",
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Small Language Model Can Self-correct": {
        "filename": "Small Language Model Can Self-correct.pdf",
        "analysis": {
            "benchmarks": [
                "OpenBookQA",
                "CommonsenseQA"
            ],
            "base_models": [
                "CuteGPT-7B",
                "CuteGPT-13B",
                "ChatGLM-6B",
                "Llama2-7B",
                "Vicuna-7B",
                "Vicuna-13B"
            ]
        }
    },
    "Dynamic Clue Bottlenecks Towards Interpretable-by-Design Visual Question Answering": {
        "filename": "Dynamic Clue Bottlenecks Towards Interpretable-by-Design Visual Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "VQA v2",
                "GQA",
                "DCLUB dataset"
            ],
            "base_models": [
                "BLIP-2",
                "LLaVa-v1.5-13b",
                "LLaMa-2-70B-instruct"
            ]
        }
    },
    "Knowledge Graph Question Answering for Materials Science KGQA4MAT Developing Natural Language Interface for Metal-Organic Frameworks Knowledge Graph MOF-KG": {
        "filename": "Knowledge Graph Question Answering for Materials Science KGQA4MAT Developing Natural Language Interface for Metal-Organic Frameworks Knowledge Graph MOF-KG.pdf",
        "analysis": {
            "benchmarks": [
                "KGQA4MAT",
                "QALD-9"
            ],
            "base_models": [
                "ChatGPT (gpt-turbo-3.5)"
            ]
        }
    },
    "Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective": {
        "filename": "Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "RULER benchmark",
                "BigCodeBench"
            ],
            "base_models": [
                "Llama 3 (8B)"
            ]
        }
    },
    "SCIENCE IS EXPLORATION Computational Frontiers for Conceptual Metaphor Theory": {
        "filename": "SCIENCE IS EXPLORATION Computational Frontiers for Conceptual Metaphor Theory.pdf",
        "analysis": {
            "benchmarks": [
                "Trope Finder (TroFi) dataset",
                "MWLB dataset"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4-turbo",
                "gpt-4o"
            ]
        }
    },
    "Prover-Verifier Games improve legibility of LLM outputs": {
        "filename": "Prover-Verifier Games improve legibility of LLM outputs.pdf",
        "analysis": {
            "benchmarks": [
                "grade-school math problems (Cobbe et al., 2021)"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Discrete compositional and symbolic representations through attractor dynamics": {
        "filename": "Discrete compositional and symbolic representations through attractor dynamics.pdf",
        "analysis": {
            "benchmarks": [
                "HBV dataset",
                "dSprites dataset"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Follow the Wisdom of the Crowd Effective Text Generation via Minimum Bayes Risk Decoding": {
        "filename": "Follow the Wisdom of the Crowd Effective Text Generation via Minimum Bayes Risk Decoding.pdf",
        "analysis": {
            "benchmarks": [
                "WebNLG",
                "WMT16",
                "XSUM",
                "CNN",
                "DailyMail",
                "E2E NLG",
                "Czech Restaurants",
                "COCO Captions",
                "BIG-Bench",
                "Yelp Sentiment",
                "GYAFC",
                "Shakespeare",
                "Harvard USPTO Patent Dataset"
            ],
            "base_models": [
                "Codex (code-davinci-002)",
                "InstructGPT (text-davinci-002)",
                "Pegasus",
                "BART",
                "T-5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Applying Large Language Models and Chain-of-Thought for Automatic Scoring": {
        "filename": "Applying Large Language Models and Chain-of-Thought for Automatic Scoring.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset with six assessment tasks (three binomial and three trinomial) with 1,650 student responses"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SYNERGAI Perception Alignment for Human-Robot Collaboration": {
        "filename": "SYNERGAI Perception Alignment for Human-Robot Collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "ScanQA"
            ],
            "base_models": [
                "GPT-4 turbo"
            ]
        }
    },
    "IDs for AI Systems": {
        "filename": "IDs for AI Systems.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What It Wants Me To Say Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models": {
        "filename": "What It Wants Me To Say Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Codex"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lemur Harmonizing Natural Language and Code for Language Agents": {
        "filename": "Lemur Harmonizing Natural Language and Code for Language Agents.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BBH",
                "GSM8K",
                "HumanEval",
                "MBPP",
                "Spider",
                "MultiPL-E",
                "DS-1000",
                "MINT-GSM8K",
                "MINT-MATH",
                "MINT-TheoremQA",
                "MINT-HotpotQA",
                "MINT-MMLU",
                "InterCode-Bash",
                "InterCode-SQL",
                "RoboCodeGen",
                "InterCode-CTF",
                "WebArena",
                "ALFWorld"
            ],
            "base_models": [
                "Llama-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CharacterGLM Customizing Chinese Conversational AI Characters with Large Language Models": {
        "filename": "CharacterGLM Customizing Chinese Conversational AI Characters with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CharacterDial corpus"
            ],
            "base_models": [
                "ChatGLM (6B to 66B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Entailment as Robust Self-Learner": {
        "filename": "Entailment as Robust Self-Learner.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "AdvGLUE",
                "Copa",
                "Emotion Classification",
                "Amazon Review",
                "Ag-News"
            ],
            "base_models": [
                "RoBERTa-large (350M)",
                "DeBERTa-large (350M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Training Chain-of-Thought via Latent-Variable Inference": {
        "filename": "Training Chain-of-Thought via Latent-Variable Inference.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "BIG-Bench Hard"
            ],
            "base_models": [
                "PaLM 2-M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instruction Backdoor Attacks Against Customized LLMs": {
        "filename": "Instruction Backdoor Attacks Against Customized LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Stanford Sentiment Treebank (SST-2)",
                "SMS Spam",
                "AGNews",
                "DBPedia",
                "Amazon Product Reviews"
            ],
            "base_models": [
                "LLaMA2-7B",
                "Mistral-7B",
                "Mixtral-8x7B",
                "GPT-3.5",
                "GPT-4",
                "Claude-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LongSafetyBench Long-Context LLMs Struggle with Safety Issues": {
        "filename": "LongSafetyBench Long-Context LLMs Struggle with Safety Issues.pdf",
        "analysis": {
            "benchmarks": [
                "LongSafetyBench"
            ],
            "base_models": [
                "LLaMA3-8b-Instruct",
                "Intern2.5-7b-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NELLIE A Neuro-Symbolic Inference Engine for Grounded Compositional and Explainable Reasoning": {
        "filename": "NELLIE A Neuro-Symbolic Inference Engine for Grounded Compositional and Explainable Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "EntailmentBank",
                "WorldTree"
            ],
            "base_models": [
                "T5-3B",
                "T5-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InstructAV Instruction Fine-tuning Large Language Models for Authorship Verification": {
        "filename": "InstructAV Instruction Fine-tuning Large Language Models for Authorship Verification.pdf",
        "analysis": {
            "benchmarks": [
                "IMDB",
                "Twitter",
                "Yelp Reviews"
            ],
            "base_models": [
                "BERT",
                "DistilBERT",
                "ALBERT",
                "GPT-4-turbo",
                "LLaMA-2-70B",
                "Mistral-7B",
                "LLaMA-1-7B",
                "OPT-6.7B",
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages": {
        "filename": "Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages.pdf",
        "analysis": {
            "benchmarks": [
                "UCLID5 regression tests",
                "textbook exercises and examples"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4-turbo"
            ]
        }
    },
    "Compositional Chain-of-Thought Prompting for Large Multimodal Models": {
        "filename": "Compositional Chain-of-Thought Prompting for Large Multimodal Models.pdf",
        "analysis": {
            "benchmarks": [
                "Winoground",
                "WHOOPS!",
                "SEEDBench",
                "MMBench",
                "LLaVA-Bench In-the-Wild"
            ],
            "base_models": [
                "LLaVA-1.5-13B",
                "InstructBLIP-13B",
                "Sphinx",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating vision-capable chatbots in interpreting kinematics graphs a comparative study of free and subscription-based models": {
        "filename": "Evaluating vision-capable chatbots in interpreting kinematics graphs a comparative study of free and subscription-based models.pdf",
        "analysis": {
            "benchmarks": [
                "Test of Understanding Graphs in Kinematics (TUG-K)"
            ],
            "base_models": [
                "ChatGPT-4",
                "ChatGPT-4o",
                "Claude 3 Sonnet",
                "Claude 3 Opus",
                "Gemini 1.0 Pro",
                "Gemini 1.0 Ultra",
                "Gemini 1.5 Pro API",
                "Microsoft Copilot"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Thought Reasoning Without Prompting": {
        "filename": "Chain-of-Thought Reasoning Without Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MultiArith",
                "year parity",
                "Big-Bench-Hard",
                "Sports Understanding",
                "Object Counting"
            ],
            "base_models": [
                "PaLM-2 Large",
                "Mistral-7B",
                "Gemma-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Can LLM Guide RL A Value-Based Approach": {
        "filename": "How Can LLM Guide RL A Value-Based Approach.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "InterCode",
                "BlocksWorld"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)",
                "GPT-3.5 (gpt-3.5-turbo)",
                "Vicuna-13b (v1.3)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Fact Selection Problem in LLM-Based Program Repair": {
        "filename": "The Fact Selection Problem in LLM-Based Program Repair.pdf",
        "analysis": {
            "benchmarks": [
                "BugsInPy"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Achieving and Understanding Out-of-Distribution Generalization in Systematic Reasoning in Small-Scale Transformers": {
        "filename": "Achieving and Understanding Out-of-Distribution Generalization in Systematic Reasoning in Small-Scale Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "Custom 6x6 Sudoku dataset"
            ],
            "base_models": [
                "3-layer transformer encoder"
            ]
        }
    },
    "Teaching Algorithmic Reasoning via In-context Learning": {
        "filename": "Teaching Algorithmic Reasoning via In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "GSM8k-Hard"
            ],
            "base_models": [
                "Codex code-davinci-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Just rephrase it Uncertainty estimation in closed-source language models via multiple rephrased queries": {
        "filename": "Just rephrase it Uncertainty estimation in closed-source language models via multiple rephrased queries.pdf",
        "analysis": {
            "benchmarks": [
                "ARC-Challenge",
                "ARC-Easy",
                "OpenBookQA"
            ],
            "base_models": [
                "Mistral-7B",
                "Llama-2-7B",
                "Llama-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PokemonChat Auditing ChatGPT for Pokémon Universe Knowledge": {
        "filename": "PokemonChat Auditing ChatGPT for Pokémon Universe Knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "Pokémon universe (custom dataset)"
            ],
            "base_models": [
                "ChatGPT (OpenAI, unspecified size)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On-Policy Distillation of Language Models Learning from Self-Generated Mistakes": {
        "filename": "On-Policy Distillation of Language Models Learning from Self-Generated Mistakes.pdf",
        "analysis": {
            "benchmarks": [
                "XSum",
                "WMT",
                "GSM8K",
                "BBH",
                "MMLU"
            ],
            "base_models": [
                "T5-Small (77M)",
                "T5-Base (250M)",
                "T5-Large (800M)",
                "T5-XL (3B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation": {
        "filename": "Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation.pdf",
        "analysis": {
            "benchmarks": [
                "PARITY",
                "Cycle Navigation"
            ],
            "base_models": [
                "GPT-2"
            ]
        }
    },
    "Exploring Large Language Models for Feature Selection A Data-centric Perspective": {
        "filename": "Exploring Large Language Models for Feature Selection A Data-centric Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "Adult",
                "Bank",
                "Communities",
                "Credit-g",
                "Heart",
                "Myocardial",
                "Diabetes",
                "NBA",
                "Rideshare",
                "Wine"
            ],
            "base_models": [
                "LLaMA-2 (7B parameters)",
                "LLaMA-2 (13B parameters)",
                "ChatGPT (~175B parameters)",
                "GPT-4 (~1.7T parameters)"
            ]
        }
    },
    "Can MLLMs Perform Text-to-Image In-Context Learning": {
        "filename": "Can MLLMs Perform Text-to-Image In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "CoBSAT"
            ],
            "base_models": [
                "Emu",
                "GILL",
                "SEED-LLaMA",
                "Qwen-VL",
                "Gemini",
                "Claude",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT Models in Construction Industry Opportunities Limitations and a Use Case Validation": {
        "filename": "GPT Models in Construction Industry Opportunities Limitations and a Use Case Validation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "GPT-2 (small version)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "KwaiYiiMath Technical Report": {
        "filename": "KwaiYiiMath Technical Report.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "CMath",
                "KMath"
            ],
            "base_models": [
                "KwaiYiiBase 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models": {
        "filename": "Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MultiWOZ 2.1",
                "STARv2",
                "SGD",
                "SpokenWOZ",
                "MELD",
                "MuTual"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "DreamBench A Human-Aligned Benchmark for Personalized Image Generation": {
        "filename": "DreamBench A Human-Aligned Benchmark for Personalized Image Generation.pdf",
        "analysis": {
            "benchmarks": [
                "DREAM BENCH ++"
            ],
            "base_models": [
                "GPT-4o",
                "SD v1.5",
                "SDXL v1.0"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WebArena A Realistic Web Environment for Building Autonomous Agents": {
        "filename": "WebArena A Realistic Web Environment for Building Autonomous Agents.pdf",
        "analysis": {
            "benchmarks": [
                "WebArena"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "PaLM-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Highlighter Interactive Control for Multi-Modal LLMs": {
        "filename": "Prompt Highlighter Interactive Control for Multi-Modal LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MMBench",
                "MME-perception",
                "MSCOCO"
            ],
            "base_models": [
                "LLaVA-13B",
                "InstructBLIP-Vicuna-13B",
                "Vicuna-13B v1.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Predicting Winning Captions for Weekly New Yorker Comics": {
        "filename": "Predicting Winning Captions for Weekly New Yorker Comics.pdf",
        "analysis": {
            "benchmarks": [
                "New Yorker Caption Contest dataset"
            ],
            "base_models": [
                "CLIP-GPT2",
                "LLaVA-NeXT (CLIP-ViT-L-336px to Mistral LLM)",
                "GPT-4V"
            ]
        }
    },
    "Two Heads Are Better Than One A Multi-Agent System Has the Potential to Improve Scientific Idea Generation": {
        "filename": "Two Heads Are Better Than One A Multi-Agent System Has the Potential to Improve Scientific Idea Generation.pdf",
        "analysis": {
            "benchmarks": [
                "past paper database",
                "contemporary paper database"
            ],
            "base_models": [
                "GPT-4o",
                "LLaMA-3.1 (8b)",
                "LLaMA-3.1 (70b)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Task Facet Learning A Structured Approach to Prompt Optimization": {
        "filename": "Task Facet Learning A Structured Approach to Prompt Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "Ethos",
                "ARC",
                "MedQA",
                "GSM8K"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Few-Shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt": {
        "filename": "Few-Shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR100",
                "CUB200-2011",
                "ImageNet-R"
            ],
            "base_models": [
                "Vision Transformer (ViT-B/16-1K)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ZeroGen Efficient Zero-shot Learning via Dataset Generation": {
        "filename": "ZeroGen Efficient Zero-shot Learning via Dataset Generation.pdf",
        "analysis": {
            "benchmarks": [
                "IMDb",
                "SST-2",
                "SQuAD",
                "AdversarialQA",
                "QNLI",
                "RTE"
            ],
            "base_models": [
                "GPT2-XL (1.5B)",
                "GPT2-Large (762M)",
                "GPT2 (117M)",
                "OPT (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HFT Half Fine-Tuning for Large Language Models": {
        "filename": "HFT Half Fine-Tuning for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8K",
                "BBH",
                "TyDiQA",
                "TruthfulQA",
                "HumanEval",
                "NaturalQuestion",
                "TriviaQA",
                "HotpotQA"
            ],
            "base_models": [
                "LLaMA 2-7B",
                "LLaMA 2-Chat-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks": {
        "filename": "Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset with 1525 questions across 61 harmful categories"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4-0125-preview",
                "Llama-2-7B-chat",
                "Llama-2-13B-chat",
                "Vicuna-7B-v1.5",
                "Vicuna-13B-v1.5",
                "Mistral-7B-Instruct-v0.1",
                "Mistral-7B-Instruct-v0.2",
                "Baichuan2-7B-Chat",
                "Baichuan2-13B-Chat",
                "Gemma-2b-it",
                "Gemma-7b-it",
                "Llama-3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating the Instruction-following Abilities of Language Models using Knowledge Tasks": {
        "filename": "Evaluating the Instruction-following Abilities of Language Models using Knowledge Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MMLUPro",
                "MathQA",
                "Winogrande",
                "BoolQ",
                "PIQA"
            ],
            "base_models": [
                "Llama-3.2-1B-Instruct (1B)",
                "Qwen2.5-1.5B-Instruct (1.5B)",
                "Llama-3.2-3B-Instruct (3B)",
                "Phi-3.5-mini-instruct (3.8B)",
                "Mistral-7B-Instruct-v0.3 (7B)",
                "Qwen2.5-7B-Instruct (7B)",
                "Phi-3-small-8k-instruct (7B)",
                "Llama-3.1-8B-Instruct (8B)",
                "Gemma-2-9b-it (9B)",
                "Phi-3-medium-4k-instruct (14B)",
                "Qwen2.5-14B-Instruct (14B)",
                "Gemma-2-27b-it (27B)",
                "Qwen2.5-32B-Instruct (32B)",
                "Llama-3.1-70B-Instruct (70B)",
                "Qwen2.5-72B-Instruct (72B)",
                "Llama-3.1-405B-Instruct (405B)",
                "GPT-4o-mini-2024-07-18",
                "GPT-4o-2024-08-06"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-Agent Collaboration Harnessing the Power of Intelligent LLM Agents": {
        "filename": "Multi-Agent Collaboration Harnessing the Power of Intelligent LLM Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "LLaMA (used in Gorilla model)"
            ]
        }
    },
    "Foundation Models Meet Visualizations Challenges and Opportunities": {
        "filename": "Foundation Models Meet Visualizations Challenges and Opportunities.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT",
                "GPT-4",
                "CLIP",
                "InternImage",
                "T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FederatedScope-LLM A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning": {
        "filename": "FederatedScope-LLM A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "HELM",
                "GSM8K-test"
            ],
            "base_models": [
                "LLaMA-7B",
                "OPT-2.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hello Again LLM-powered Personalized Agent for Long-term Dialogue": {
        "filename": "Hello Again LLM-powered Personalized Agent for Long-term Dialogue.pdf",
        "analysis": {
            "benchmarks": [
                "MSC",
                "Conversation Chronicles (CC)"
            ],
            "base_models": [
                "ChatGLM (6B)",
                "ChatGPT (gpt-3.5-turbo-1106)",
                "BlenderBot",
                "BART"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Language Model Rationality with Bi-Directional Deliberation Reasoning": {
        "filename": "Enhancing Language Model Rationality with Bi-Directional Deliberation Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Poker (Limit Texas Hold'em)",
                "Negotiation"
            ],
            "base_models": [
                "BERT"
            ]
        }
    },
    "IDEAL Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models": {
        "filename": "IDEAL Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SST-5",
                "DBpedia",
                "MWoZ",
                "Xsum",
                "MRPC",
                "MNLI",
                "RTE",
                "HellaSwag",
                "GeoQuery"
            ],
            "base_models": [
                "GPT-J 6B",
                "Text-devinci-002",
                "GPT-Neo 2.7B",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VACoDe Visual Augmented Contrastive Decoding": {
        "filename": "VACoDe Visual Augmented Contrastive Decoding.pdf",
        "analysis": {
            "benchmarks": [
                "MME",
                "VQAv2",
                "MMBench"
            ],
            "base_models": [
                "LLaVA-1.5 13B",
                "Qwen-VL 7B",
                "InstructBLIP 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT-Connect Interaction between Text-Driven Human Motion Generator and 3D Scenes in a Training-free Manner": {
        "filename": "GPT-Connect Interaction between Text-Driven Human Motion Generator and 3D Scenes in a Training-free Manner.pdf",
        "analysis": {
            "benchmarks": [
                "HUMANISE"
            ],
            "base_models": [
                "ChatGPT (GPT-4)",
                "Motion Diffusion Model (humanml-encoder-512)"
            ]
        }
    },
    "What if LLMs Have Different World Views Simulating Alien Civilizations with LLM-based Agents": {
        "filename": "What if LLMs Have Different World Views Simulating Alien Civilizations with LLM-based Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "diff History for Neural Language Agents": {
        "filename": "diff History for Neural Language Agents.pdf",
        "analysis": {
            "benchmarks": [
                "NetHack",
                "BabyAI-Text"
            ],
            "base_models": [
                "GPT-2-127M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lean Workbook A large-scale Lean problem set formalized from natural language math problems": {
        "filename": "Lean Workbook A large-scale Lean problem set formalized from natural language math problems.pdf",
        "analysis": {
            "benchmarks": [
                "MiniF2F",
                "Mathlib"
            ],
            "base_models": [
                "InternLM-Math-Plus-20B",
                "Qwen-1.5-14B-Chat"
            ]
        }
    },
    "Inverse Scaling When Bigger Isnt Better": {
        "filename": "Inverse Scaling When Bigger Isnt Better.pdf",
        "analysis": {
            "benchmarks": [
                "Inverse Scaling Prize datasets"
            ],
            "base_models": [
                "GPT-2",
                "GPT-3",
                "GPT-3 FeedME",
                "GPT-4",
                "GPT-4 RLHF",
                "OPT",
                "PaLM",
                "Chinchilla",
                "Gopher",
                "Anthropic LM",
                "Anthropic Context Distilled",
                "Anthropic RLHF"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Building Math Agents with Multi-Turn Iterative Preference Learning": {
        "filename": "Building Math Agents with Multi-Turn Iterative Preference Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "Gemma-1.1-it-7B",
                "Gemma-2-it-9B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models": {
        "filename": "A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ASDiv-A",
                "MAWPS",
                "SVAMP"
            ],
            "base_models": [
                "GPT-3 Davinci (175B)",
                "GPT-2 Distilled",
                "GPT-2 Small",
                "GPT-2 Medium",
                "GPT-2 Large",
                "GPT-2 XL",
                "GPT-Neo 1.3B",
                "GPT-Neo 2.7B",
                "GPT-J-6B",
                "GPT-NeoX-20B",
                "LLaMA 7B",
                "LLaMA 13B",
                "LLaMA 30B",
                "Stanford Alpaca (based on LLaMA 7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Efficiently Serving LLM Reasoning Programs with Certaindex": {
        "filename": "Efficiently Serving LLM Reasoning Programs with Certaindex.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "ASDiv",
                "MATH",
                "LiveCodeBench"
            ],
            "base_models": [
                "Llama3.1 8B",
                "Llama2 7B",
                "Llemma 7B",
                "Llemma 34B",
                "Skywork 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mind the Labels Describing Relations in Knowledge Graphs With Pretrained Models": {
        "filename": "Mind the Labels Describing Relations in Knowledge Graphs With Pretrained Models.pdf",
        "analysis": {
            "benchmarks": [
                "REL2TEXT"
            ],
            "base_models": [
                "BART-BASE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SORRY-Bench Systematically Evaluating Large Language Model Safety Refusal Behaviors": {
        "filename": "SORRY-Bench Systematically Evaluating Large Language Model Safety Refusal Behaviors.pdf",
        "analysis": {
            "benchmarks": [
                "SORRY-Bench"
            ],
            "base_models": [
                "GPT-4",
                "Claude-2",
                "Gemini-1.5",
                "Mistral-7B",
                "Llama-3-70B",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cyber Sentinel Exploring Conversational Agents in Streamlining Security Tasks with GPT-4": {
        "filename": "Cyber Sentinel Exploring Conversational Agents in Streamlining Security Tasks with GPT-4.pdf",
        "analysis": {
            "benchmarks": [
                "Custom OSINT threat feeds"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Multi-Task Program Error Repair and Explanatory Diagnosis": {
        "filename": "Multi-Task Program Error Repair and Explanatory Diagnosis.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Codex",
                "PaLM-Coder",
                "AlphaCode"
            ]
        }
    },
    "A Survey on Transformer Compression": {
        "filename": "A Survey on Transformer Compression.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-4",
                "LLaMA",
                "BERT",
                "CLIP",
                "ViT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMmap Fingerprinting For Large Language Models": {
        "filename": "LLMmap Fingerprinting For Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "gpt-4-turbo-2024-04-09",
                "Claude",
                "ChatGPT",
                "Phi-3-medium-128k-instruct",
                "Phi-3-medium-4k-instruct",
                "Phi-3-mini-128k-instruct",
                "Phi-3-mini-4k-instruct",
                "Mistral-7B-Instruct-v0.1",
                "Mistral-7B-Instruct-v0.2",
                "Mistral-7B-Instruct-v0.3",
                "Mixtral-8x7B-Instruct-v0.1",
                "Llama3-ChatQA-1.5-8B",
                "openchat-3.6-8b-20240522",
                "openchat_3.5",
                "Llama-2-7B-32K-Instruct",
                "SOLAR-10.7B-Instruct-v1.0"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Context Generation Improves Open Domain Question Answering": {
        "filename": "Context Generation Improves Open Domain Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions",
                "WebQuestions",
                "TriviaQA"
            ],
            "base_models": [
                "GPT-3",
                "PALM",
                "Megatron-Turing NLG 530B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification": {
        "filename": "A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification.pdf",
        "analysis": {
            "benchmarks": [
                "Web of Science (WOS)",
                "Amazon Beauty"
            ],
            "base_models": [
                "BART-Large-MNLI (407M)",
                "T0pp (11B)"
            ]
        }
    },
    "A Survey on Human Preference Learning for Large Language Models": {
        "filename": "A Survey on Human Preference Learning for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HH-RLHF",
                "SELF-INSTRUCT",
                "AlpacaFarm",
                "MT-bench",
                "MMLU",
                "AGIEval",
                "SUP-NATINST",
                "Big-Bench-Hard",
                "TruthfulQA",
                "HumanEval",
                "GSM8K",
                "IMDb",
                "Reddit TL;DR",
                "CNN/DailyMail"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "Llama-2-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Ask and it shall be given Turing completeness of prompting": {
        "filename": "Ask and it shall be given Turing completeness of prompting.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PlantoGraphy Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering": {
        "filename": "PlantoGraphy Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering.pdf",
        "analysis": {
            "benchmarks": [
                "custom vegetation dataset"
            ],
            "base_models": [
                "Stable Diffusion",
                "GLIGEN",
                "GPT-3.5",
                "GPT-4.0"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Gorilla Large Language Model Connected with Massive APIs": {
        "filename": "Gorilla Large Language Model Connected with Massive APIs.pdf",
        "analysis": {
            "benchmarks": [
                "APIBench"
            ],
            "base_models": [
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Id Like to Have an Argument Please Argumentative Reasoning in Large Language Models": {
        "filename": "Id Like to Have an Argument Please Argumentative Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Review-Rebuttal Submission-v2 (RRv2)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3 (TEXT-DAVINCI-003 variant)"
            ]
        }
    },
    "Simple Techniques for Enhancing Sentence Embeddings in Generative Language Models": {
        "filename": "Simple Techniques for Enhancing Sentence Embeddings in Generative Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "STS-12",
                "STS-13",
                "STS-14",
                "STS-15",
                "STS-16",
                "STS-B",
                "SICK-R"
            ],
            "base_models": [
                "GPT",
                "OPT 6.7b",
                "LLaMA 7b",
                "LLaMA2 7b",
                "Mistral 7b",
                "BERT base",
                "RoBERTa base"
            ]
        }
    },
    "DREAM Improving Situational QA by First Elaborating the Situation": {
        "filename": "DREAM Improving Situational QA by First Elaborating the Situation.pdf",
        "analysis": {
            "benchmarks": [
                "ETHICS-CS",
                "CODAH",
                "Social IQA"
            ],
            "base_models": [
                "Macaw-11B",
                "T5-11B"
            ]
        }
    },
    "Real-Time Anomaly Detection and Reactive Planning with Large Language Models": {
        "filename": "Real-Time Anomaly Detection and Reactive Planning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic text-based domains",
                "simulated and real-world closed-loop quadrotor experiments",
                "CARLA simulator"
            ],
            "base_models": [
                "GPT-4",
                "Llama 2 (7B)",
                "Mistral (7.11B)",
                "BERT-base (110M)",
                "BERT-large (336M)",
                "Sentence Transformer MPNet (110M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Deep Learning Based Code Generation Methods Literature Review": {
        "filename": "Deep Learning Based Code Generation Methods Literature Review.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "CodeXGLUE",
                "CONCODE"
            ],
            "base_models": [
                "GPT-3 (300M/2.5B/12B)",
                "GPT-4",
                "CodeBERT",
                "GraphCodeBERT",
                "CodeGPT",
                "PolyCoder (2.7B)",
                "CodeGen (350M/2.7B/6.1B/16.1B)",
                "InCoder (1.3B/6.7B)",
                "AlphaCode (300M/1B/3B/9B/41B)",
                "PanGu-Coder (317M/2.6B)",
                "CodeGeeX (13B)",
                "aiXcoder L (1.3B)",
                "aiXcoder XL (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Students Open-ended Written Responses with LLMs Using the RAG Framework for GPT-35 GPT-4 Claude-3 and Mistral-Large": {
        "filename": "Evaluating Students Open-ended Written Responses with LLMs Using the RAG Framework for GPT-35 GPT-4 Claude-3 and Mistral-Large.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 54 open-ended responses from a master's level geography course at the University of Turku"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude-3",
                "Mistral-Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Autonomous Agents for Collaborative Task under Information Asymmetry": {
        "filename": "Autonomous Agents for Collaborative Task under Information Asymmetry.pdf",
        "analysis": {
            "benchmarks": [
                "InformativeBench"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo-16k",
                "Gemini-1.0-pro-latest",
                "Claude-sonnet2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model Assisted Adversarial Robustness Neural Architecture Search": {
        "filename": "Large Language Model Assisted Adversarial Robustness Neural Architecture Search.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR-10",
                "CIFAR-100"
            ],
            "base_models": [
                "Gemini"
            ]
        }
    },
    "VisualWebArena Evaluating Multimodal Agents on Realistic Visual Web Tasks": {
        "filename": "VisualWebArena Evaluating Multimodal Agents on Realistic Visual Web Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "VisualWebArena"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini-Pro",
                "IDEFICS-80B-Instruct",
                "CogVLM",
                "LLaMA-2-70B",
                "Mixtral-8x7B",
                "GPT-3.5",
                "GPT-4",
                "Gemini-Pro-1.5",
                "Gemini-Flash-1.5",
                "GPT-4o",
                "Llama-3-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Solving NLP Problems through Human-System Collaboration A Discussion-based Approach": {
        "filename": "Solving NLP Problems through Human-System Collaboration A Discussion-based Approach.pdf",
        "analysis": {
            "benchmarks": [
                "SNLI",
                "ANLI"
            ],
            "base_models": [
                "GPT-3.5",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models": {
        "filename": "Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BIPIA",
                "OpenAI Evals",
                "NewsQA",
                "WikiTableQuestions",
                "XSum",
                "Self-collected code QA dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Vicuna-7B",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unlocking Temporal Question Answering for Large Language Models with Tailor-Made Reasoning Logic": {
        "filename": "Unlocking Temporal Question Answering for Large Language Models with Tailor-Made Reasoning Logic.pdf",
        "analysis": {
            "benchmarks": [
                "TempReason",
                "TimeQA"
            ],
            "base_models": [
                "GPT-4",
                "InstructGPT (text-davinci-003)"
            ]
        }
    },
    "InfAlign Inference-aware language model alignment": {
        "filename": "InfAlign Inference-aware language model alignment.pdf",
        "analysis": {
            "benchmarks": [
                "Anthropic helpfulness and harmlessness dialog benchmark datasets"
            ],
            "base_models": [
                "PaLM-2 S",
                "PaLM-2 M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Utilizing ChatGPT to Enhance Clinical Trial Enrollment": {
        "filename": "Utilizing ChatGPT to Enhance Clinical Trial Enrollment.pdf",
        "analysis": {
            "benchmarks": [
                "TREC Clinical Trials 2021",
                "TREC Clinical Trials 2022"
            ],
            "base_models": [
                "GPT-3.5 (ChatGPT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InstructRetro Instruction Tuning post Retrieval-Augmented Pretraining": {
        "filename": "InstructRetro Instruction Tuning post Retrieval-Augmented Pretraining.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Question (NQ)",
                "TriviaQA",
                "NewsQA",
                "SQuAD 1.1",
                "SQuAD 2.0",
                "Quoref",
                "NarrativeQA",
                "DROP",
                "doc2dial",
                "QMSum",
                "SummScreenFd",
                "GovReport"
            ],
            "base_models": [
                "GPT-3 175B",
                "GLaM 64B",
                "FLAN-LaMDA 137B",
                "Llama 2 70B",
                "Retro 7.5B",
                "Retro++ 9B",
                "Atlas 11B",
                "Raven 11B",
                "RA-DIT 65B",
                "InstructRetro 48B",
                "InstructRetro 43B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An In-depth Survey of Large Language Model-based Artificial Intelligence Agents": {
        "filename": "An In-depth Survey of Large Language Model-based Artificial Intelligence Agents.pdf",
        "analysis": {
            "benchmarks": [
                "WebShop",
                "HotPotQA",
                "Minecraft simulator",
                "GentBench",
                "AgentBench"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "PaLM-E"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OutlineSpark Igniting AI-powered Presentation Slides Creation from Computational Notebooks through Outlines": {
        "filename": "OutlineSpark Igniting AI-powered Presentation Slides Creation from Computational Notebooks through Outlines.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval-augmented GPT-35-based Text-to-SQL Framework with Sample-aware Prompting and Dynamic Revision Chain": {
        "filename": "Retrieval-augmented GPT-35-based Text-to-SQL Framework with Sample-aware Prompting and Dynamic Revision Chain.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "Spider-Syn",
                "Spider-DK"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)"
            ]
        }
    },
    "Compute-Constrained Data Selection": {
        "filename": "Compute-Constrained Data Selection.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BBH",
                "IFEval"
            ],
            "base_models": [
                "LLAMA-2-7B",
                "LLAMA-2-13B",
                "LLAMA-2-70B",
                "LLAMA-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Few-Shot Self-Rationalization with Natural Language Prompts": {
        "filename": "Few-Shot Self-Rationalization with Natural Language Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "E-SNLI",
                "ECQA",
                "COMVE",
                "SBIC"
            ],
            "base_models": [
                "T5 (base, large, 3B)",
                "UNIFIED QA (base, large, 3B)",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Factual Consistency Evaluation of Summarisation in the Era of Large Language Models": {
        "filename": "Factual Consistency Evaluation of Summarisation in the Era of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TreatFact",
                "AGGREFACT"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "Llama 2-Chat (7B, 13B, 70B)",
                "Vicuna (1.3-7B, 1.5-7B, 1.3-13B, 1.5-13B)",
                "Orca 2 (7B, 13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TravelAgent Generative Agents in the Built Environment": {
        "filename": "TravelAgent Generative Agents in the Built Environment.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching": {
        "filename": "Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching.pdf",
        "analysis": {
            "benchmarks": [
                "SocraticMATH"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA2-7B",
                "Qwen1.5-7B"
            ]
        }
    },
    "Taming Overconfidence in LLMs Reward Calibration in RLHF": {
        "filename": "Taming Overconfidence in LLMs Reward Calibration in RLHF.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "CommonsenseQA",
                "SciQ",
                "ObjectCounting from BigBench",
                "Professional Knowledge datasets in MMLU",
                "TruthfulQA"
            ],
            "base_models": [
                "Llama3-8B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "R2-Guard Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning": {
        "filename": "R2-Guard Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "OpenAI Mod",
                "ToxicChat",
                "XSTest",
                "Overkill",
                "BeaverTails",
                "TwinSafety"
            ],
            "base_models": [
                "Llama2-7b-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models Analyze Graphs like Professionals A Benchmark Datasets and Models": {
        "filename": "Can Large Language Models Analyze Graphs like Professionals A Benchmark Datasets and Models.pdf",
        "analysis": {
            "benchmarks": [
                "ProGraph"
            ],
            "base_models": [
                "GPT-4 turbo",
                "Claude 3 Opus",
                "Gemini 1.5 Pro",
                "Llama-3-8B-Instruct",
                "Deepseek-Coder-7B-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CSCE Boosting LLM Reasoning by Simultaneous Enhancing of Casual Significance and Consistency": {
        "filename": "CSCE Boosting LLM Reasoning by Simultaneous Enhancing of Casual Significance and Consistency.pdf",
        "analysis": {
            "benchmarks": [
                "Blocksworld",
                "GSM8K",
                "Hanoi Tower"
            ],
            "base_models": [
                "LLAMA-2-7B",
                "Phi-2-7B",
                "Mistral-7B",
                "Mixtral-8x7B"
            ]
        }
    },
    "Measuring Retrieval Complexity in Question Answering Systems": {
        "filename": "Measuring Retrieval Complexity in Question Answering Systems.pdf",
        "analysis": {
            "benchmarks": [
                "HotPotQA",
                "ComplexWebQuestions",
                "MuSiQue",
                "StrategyQA",
                "Natural Questions",
                "QuoraQP-a"
            ],
            "base_models": [
                "T5-xxl"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Search Verify and Feedback Towards Next Generation Post-training Paradigm of Foundation Models via Verifier Engineering": {
        "filename": "Search Verify and Feedback Towards Next Generation Post-training Paradigm of Foundation Models via Verifier Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet"
            ],
            "base_models": [
                "BERT",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InterDreamer Zero-Shot Text to 3D Dynamic Human-Object Interaction": {
        "filename": "InterDreamer Zero-Shot Text to 3D Dynamic Human-Object Interaction.pdf",
        "analysis": {
            "benchmarks": [
                "BEHAVE",
                "CHAIRS"
            ],
            "base_models": [
                "GPT-4",
                "Llama 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatDB Augmenting LLMs with Databases as Their Symbolic Memory": {
        "filename": "ChatDB Augmenting LLMs with Databases as Their Symbolic Memory.pdf",
        "analysis": {
            "benchmarks": [
                "Fruit Shop Dataset (synthetic dataset)"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5 Turbo)",
                "GPT-4",
                "LLaMA",
                "ChatGLM"
            ]
        }
    },
    "COMET Generating Commit Messages using Delta Graph Context Representation": {
        "filename": "COMET Generating Commit Messages using Delta Graph Context Representation.pdf",
        "analysis": {
            "benchmarks": [
                "mcmd dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4-turbo",
                "CodeT5",
                "GraphCodeBERT",
                "GPT-2",
                "BLOOM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models Dont Always Say What They Think Unfaithful Explanations in Chain-of-Thought Prompting": {
        "filename": "Language Models Dont Always Say What They Think Unfaithful Explanations in Chain-of-Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench Hard (BBH)",
                "Bias Benchmark for QA (BBQ)"
            ],
            "base_models": [
                "GPT-3.5",
                "Claude 1.0"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Materials science in the era of large language models a perspective": {
        "filename": "Materials science in the era of large language models a perspective.pdf",
        "analysis": {
            "benchmarks": [
                "MicroLib dataset",
                "Custom micrograph dataset from arXiv and chemrXiv"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RevisEval Improving LLM-as-a-Judge via Response-Adapted References": {
        "filename": "RevisEval Improving LLM-as-a-Judge via Response-Adapted References.pdf",
        "analysis": {
            "benchmarks": [
                "MT-Bench",
                "Alpacafarm",
                "LLMBar",
                "Data-to-Text",
                "Machine Translation",
                "Text Summarization",
                "Story Generation"
            ],
            "base_models": [
                "GPT-4",
                "Llama 3.1-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoSearchAgent A Lightweight Collaborative Search Agent with Large Language Models": {
        "filename": "CoSearchAgent A Lightweight Collaborative Search Agent with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-1106)"
            ]
        }
    },
    "In-context learning enables multimodal large language models to classify cancer pathology images": {
        "filename": "In-context learning enables multimodal large language models to classify cancer pathology images.pdf",
        "analysis": {
            "benchmarks": [
                "CRC-VAL-HE-7K (CRC100K)",
                "PatchCamelyon (PCam)",
                "MHIST"
            ],
            "base_models": [
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation": {
        "filename": "A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-1",
                "BERT",
                "XLNet",
                "RoBERTa",
                "ELECTRA",
                "T5",
                "ALBERT",
                "BART",
                "PEGASUS",
                "GPT-3",
                "PANGU",
                "GShard",
                "Switch-Transformers",
                "GPT-4",
                "LLaMA",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Examining User-Friendly and Open-Sourced Large GPT Models A Survey on Language Multimodal and Scientific GPT Models": {
        "filename": "Examining User-Friendly and Open-Sourced Large GPT Models A Survey on Language Multimodal and Scientific GPT Models.pdf",
        "analysis": {
            "benchmarks": [],
            "models": [],
            "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
        }
    },
    "APIGen Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets": {
        "filename": "APIGen Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets.pdf",
        "analysis": {
            "benchmarks": [
                "Berkeley Function-Calling Benchmark"
            ],
            "base_models": [
                "GPT-4",
                "Gemini",
                "Mistral",
                "DeepSeek-Coder-1.3B",
                "DeepSeek-Coder-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Human-on-the-Loop Optimization Autoformalism Approach for Sustainability": {
        "filename": "A Human-on-the-Loop Optimization Autoformalism Approach for Sustainability.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT",
                "GPT-3",
                "Codex",
                "ChatGPT (GPT-4)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interpretable Contrastive Monte Carlo Tree Search Reasoning": {
        "filename": "Interpretable Contrastive Monte Carlo Tree Search Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Blocksworld multi-step reasoning dataset"
            ],
            "base_models": [
                "Llama-3.1-70B",
                "Llama-3-70B",
                "Llama-3.1-405B",
                "GPT-4o",
                "o1-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving accuracy of GPT-34 results on biomedical data using a retrieval-augmented language model": {
        "filename": "Improving accuracy of GPT-34 results on biomedical data using a retrieval-augmented language model.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of 19 questions on diffuse large B-cell lymphoma (DLBCL)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Bing's Prometheus (based on GPT-4)",
                "RetA model (based on GPT-3)"
            ]
        }
    },
    "Unleashing the potential of prompt engineering in Large Language Models a comprehensive review": {
        "filename": "Unleashing the potential of prompt engineering in Large Language Models a comprehensive review.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4 (parameter size not specified)",
                "Claude-3 (parameter size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Better Patching Using LLM Prompting via Self-Consistency": {
        "filename": "Better Patching Using LLM Prompting via Self-Consistency.pdf",
        "analysis": {
            "benchmarks": [
                "MODIT"
            ],
            "base_models": [
                "Code-DaVinci-002 (175 billion parameters)"
            ]
        }
    },
    "Check-Eval A Checklist-based Approach for Evaluating Text Quality": {
        "filename": "Check-Eval A Checklist-based Approach for Evaluating Text Quality.pdf",
        "analysis": {
            "benchmarks": [
                "Portuguese Legal Semantic Textual Similarity",
                "SUMMEVAL"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-4"
            ]
        }
    },
    "DeepInception Hypnotize Large Language Model to Be Jailbreaker": {
        "filename": "DeepInception Hypnotize Large Language Model to Be Jailbreaker.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench",
                "Jailbench"
            ],
            "base_models": [
                "Llama-2",
                "Llama-3",
                "GPT-3.5",
                "GPT-4",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Taught Optimizer STOP Recursively Self-Improving Code Generation": {
        "filename": "Self-Taught Optimizer STOP Recursively Self-Improving Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "learning parity with noise (LPN)",
                "String Grid Distance",
                "Modified Quadratic Assignment",
                "3SAT",
                "Maxcut",
                "Parity without noise"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Mixtral-8x7B-Instruct-v0.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SciSafeEval A Comprehensive Benchmark for Safety Alignment of Large Language Models in Scientific Tasks": {
        "filename": "SciSafeEval A Comprehensive Benchmark for Safety Alignment of Large Language Models in Scientific Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "SCISAFEEVAL"
            ],
            "base_models": [
                "GPT-4o",
                "Llama-3.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain": {
        "filename": "LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5 Turbo"
            ]
        }
    },
    "Factored Verification Detecting and Reducing Hallucination in Summaries of Academic Papers": {
        "filename": "Factored Verification Detecting and Reducing Hallucination in Summaries of Academic Papers.pdf",
        "analysis": {
            "benchmarks": [
                "HaluEval"
            ],
            "base_models": [
                "ChatGPT (16k)",
                "GPT-4",
                "Claude 2"
            ]
        }
    },
    "Web Agents with World Models Learning and Leveraging Environment Dynamics in Web Navigation": {
        "filename": "Web Agents with World Models Learning and Leveraging Environment Dynamics in Web Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "WebArena",
                "Mind2Web"
            ],
            "base_models": [
                "GPT-4o",
                "Claude-3.5-Sonnet",
                "GPT-4-Turbo",
                "GPT-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health": {
        "filename": "Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA (USMLE)",
                "PubMedQA",
                "MedMCQA"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "GPT-3.5",
                "BioMedLM (2.7B)",
                "BioGPT (347M and 1.5B)",
                "PMC-LLaMA (7B)",
                "Med-PaLM 2",
                "Clinical Camel (13B)",
                "ChatDoctor (7B)",
                "MedAlpaca (7B and 13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Explaining GPT-4s Schema of Depression Using Machine Behavior Analysis": {
        "filename": "Explaining GPT-4s Schema of Depression Using Machine Behavior Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "PHQ-9 dataset from Gu et al., 2023"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Eight Things to Know about Large Language Models": {
        "filename": "Eight Things to Know about Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "PaLM",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Strategic Reasoning with Language Models": {
        "filename": "Strategic Reasoning with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "matrix games",
                "Deal or No Deal"
            ],
            "base_models": [
                "code-davinci-002",
                "curie-001",
                "davinci-002",
                "davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Artificial General Intelligence AGI in the Internet of Things IoT Opportunities and Challenges": {
        "filename": "Towards Artificial General Intelligence AGI in the Internet of Things IoT Opportunities and Challenges.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT",
                "GPT-3",
                "InstructGPT",
                "ChatGPT",
                "GLaM",
                "PaLM",
                "LLaMA",
                "Alpaca",
                "Claude2",
                "LLaMA 2",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Internal Consistency and Self-Feedback in Large Language Models A Survey": {
        "filename": "Internal Consistency and Self-Feedback in Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "TruthfulQA"
            ],
            "base_models": [
                "GPT-4o",
                "Llama-3.1-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LayoutGPT Compositional Visual Planning and Generation with Large Language Models": {
        "filename": "LayoutGPT Compositional Visual Planning and Generation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "NSR-1K",
                "3D-FRONT"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating GPT-4s Vision Capabilities on Brazilian University Admission Exams": {
        "filename": "Evaluating GPT-4s Vision Capabilities on Brazilian University Admission Exams.pdf",
        "analysis": {
            "benchmarks": [
                "ENEM 2022",
                "ENEM 2023"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4",
                "GPT-4 Turbo",
                "GPT-4 Turbo with Vision"
            ]
        }
    },
    "Integrating Graphs With Large Language Models Methods and Prospects": {
        "filename": "Integrating Graphs With Large Language Models Methods and Prospects.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "Game of 24"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ]
        }
    },
    "Situated Instruction Following": {
        "filename": "Situated Instruction Following.pdf",
        "analysis": {
            "benchmarks": [
                "ALFRED",
                "ObjectNav",
                "ImageNav",
                "TEACh",
                "DIALFRED"
            ],
            "base_models": [
                "GPT-4",
                "GPT 3.5",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AQA-Bench An Interactive Benchmark for Evaluating LLMs Sequential Reasoning Ability": {
        "filename": "AQA-Bench An Interactive Benchmark for Evaluating LLMs Sequential Reasoning Ability.pdf",
        "analysis": {
            "benchmarks": [
                "AQA-Bench"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "Gemini-Pro",
                "Llama2-70B-chat",
                "Vicuna-13B-v1.5-16K",
                "Mistral-7B-Instruct-v0.2",
                "DeepSeek-LLM-67B",
                "DeepSeek-MoE-16B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning by Distilling Context": {
        "filename": "Learning by Distilling Context.pdf",
        "analysis": {
            "benchmarks": [
                "SPIDER Text-to-SQL"
            ],
            "base_models": [
                "Incoder-6.7B",
                "T5-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Igniting Language Intelligence The Hitchhikers Guide From Chain-of-Thought Reasoning to Language Agents": {
        "filename": "Igniting Language Intelligence The Hitchhikers Guide From Chain-of-Thought Reasoning to Language Agents.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQuA",
                "SVAMP",
                "CSQA",
                "Strategy QA",
                "Last Letter Concatenation",
                "Coin Flip"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "Text-davinci-002",
                "PaLM 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoTFormer A Chain-of-Thought Driven Architecture with Budget-Adaptive Computation Cost at Inference": {
        "filename": "CoTFormer A Chain-of-Thought Driven Architecture with Budget-Adaptive Computation Cost at Inference.pdf",
        "analysis": {
            "benchmarks": [
                "OpenWebText2"
            ],
            "base_models": [
                "Pre-LayerNorm Transformer (12 layers, hidden dimension 768)"
            ]
        }
    },
    "LGMCTS Language-Guided Monte-Carlo Tree Search for Executable Semantic Object Rearrangement": {
        "filename": "LGMCTS Language-Guided Monte-Carlo Tree Search for Executable Semantic Object Rearrangement.pdf",
        "analysis": {
            "benchmarks": [
                "Executable Language Guided Rearrangement (ELGR) Bench",
                "Structformer dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Synthetic Data Almost from Scratch Generalized Instruction Tuning for Language Models": {
        "filename": "Synthetic Data Almost from Scratch Generalized Instruction Tuning for Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "GSM8K",
                "MATH",
                "BBH",
                "ARC-E",
                "ARC-C",
                "MMLU"
            ],
            "base_models": [
                "Mistral 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Forecasting Compositional Time Series Reasoning for End-to-End Task Execution": {
        "filename": "Beyond Forecasting Compositional Time Series Reasoning for End-to-End Task Execution.pdf",
        "analysis": {
            "benchmarks": [
                "custom finance dataset",
                "custom energy dataset"
            ],
            "base_models": [
                "ChatGPT-3.5-turbo",
                "ChatGPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Stabilize the Latent Space for Image Autoregressive Modeling A Unified Perspective": {
        "filename": "Stabilize the Latent Space for Image Autoregressive Modeling A Unified Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet-1K"
            ],
            "base_models": [
                "GPT-2 (architecture used for autoregressive model)",
                "VQGAN (used as a base for tokenization)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement": {
        "filename": "Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement.pdf",
        "analysis": {
            "benchmarks": [
                "spatial-relations",
                "comp-one-step",
                "comp-group",
                "shapes",
                "put-block-in-bowls",
                "pack-google objects-seq",
                "pack-google objects-group",
                "assemble-kits-seq"
            ],
            "base_models": [
                "RoBERTa",
                "CLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-Context Learning Dynamics with Random Binary Sequences": {
        "filename": "In-Context Learning Dynamics with Random Binary Sequences.pdf",
        "analysis": {
            "benchmarks": [
                "Random Binary Sequences"
            ],
            "base_models": [
                "GPT-3.5+",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Inference Scaling for Long-Context Retrieval Augmented Generation": {
        "filename": "Inference Scaling for Long-Context Retrieval Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MuSiQue",
                "Bamboogle",
                "HotpotQA",
                "2WikiMultiHopQA"
            ],
            "base_models": [
                "Gemini 1.5 Flash"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Clarify Multi-turn Conversations with Action-Based Contrastive Self-Training": {
        "filename": "Learning to Clarify Multi-turn Conversations with Action-Based Contrastive Self-Training.pdf",
        "analysis": {
            "benchmarks": [
                "PACIFIC",
                "Abg-CoQA",
                "AmbigSQL"
            ],
            "base_models": [
                "Zephyr 7B-β (based on Mistral 7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Large Language Model based Autonomous Agents": {
        "filename": "A Survey on Large Language Model based Autonomous Agents.pdf",
        "analysis": {
            "benchmarks": [
                "ToolBench",
                "WebShop"
            ],
            "base_models": [
                "GPT-3",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VEGA Learning Interleaved Image-Text Comprehension in Vision-Language Large Models": {
        "filename": "VEGA Learning Interleaved Image-Text Comprehension in Vision-Language Large Models.pdf",
        "analysis": {
            "benchmarks": [
                "VEGA dataset"
            ],
            "base_models": [
                "Gemini-1.5-pro",
                "GPT4V",
                "Qwen-VL-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Propaganda Detection": {
        "filename": "Large Language Models for Propaganda Detection.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval-2020 task 11"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "RoBERTa"
            ]
        }
    },
    "SepLLM Accelerate Large Language Models by Compressing One Segment into One Separator": {
        "filename": "SepLLM Accelerate Large Language Models by Compressing One Segment into One Separator.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K-CoT",
                "MMLU"
            ],
            "base_models": [
                "Llama-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Language Models Pretend Solvers Logic Code Simulation with LLMs": {
        "filename": "Can Language Models Pretend Solvers Logic Code Simulation with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ProntoQA",
                "Z3Tutorial",
                "Z3Test",
                "SMTSim"
            ],
            "base_models": [
                "GPT-3.5 Turbo (175B)",
                "GPT-4 Turbo",
                "LLaMA-2-13B",
                "Code LLaMA-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CHESS Contextual Harnessing for Efficient SQL Synthesis": {
        "filename": "CHESS Contextual Harnessing for Efficient SQL Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "BIRD",
                "Spider"
            ],
            "base_models": [
                "GPT-4",
                "Gemini-1.5-pro",
                "GPT-3.5-turbo",
                "Llama-3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Conversational Automated Program Repair": {
        "filename": "Conversational Automated Program Repair.pdf",
        "analysis": {
            "benchmarks": [
                "QuixBugs"
            ],
            "base_models": [
                "CODEGEN-MONO (350M/2B/6B/16B)",
                "CODEGEN-MULTI (350M/2B/6B/16B)",
                "Codex (12B)",
                "ChatGPT (~175B)"
            ]
        }
    },
    "SOEN-101 Code Generation by Emulating Software Process Models Using Large Language Model Agents": {
        "filename": "SOEN-101 Code Generation by Emulating Software Process Models Using Large Language Model Agents.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "HumanEval-ET",
                "MBPP",
                "MBPP-ET"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can a Large Language Model Learn Matrix Functions In Context": {
        "filename": "Can a Large Language Model Learn Matrix Functions In Context.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Gemini-1.5-flash",
                "Qwen2.5-72B-Instruct",
                "Hermes-3-Llama-3.1-8B"
            ]
        }
    },
    "MCCoder Streamlining Motion Control with LLM-Assisted Code Generation and Rigorous Verification": {
        "filename": "MCCoder Streamlining Motion Control with LLM-Assisted Code Generation and Rigorous Verification.pdf",
        "analysis": {
            "benchmarks": [
                "MCEVAL"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o-mini",
                "Llama-3.1-70B",
                "DeepSeek-Coder-v2"
            ]
        }
    },
    "SceneGPT A Language Model for 3D Scene Understanding": {
        "filename": "SceneGPT A Language Model for 3D Scene Understanding.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "LLaVA-13B"
            ]
        }
    },
    "OPT-R Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models": {
        "filename": "OPT-R Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SUPER-NATURAL INSTRUCTIONS"
            ],
            "base_models": [
                "OPT-1.3B",
                "OPT-6.7B",
                "OPT-13B"
            ]
        }
    },
    "IV-Mixed Sampler Leveraging Image Diffusion Models for Enhanced Video Synthesis": {
        "filename": "IV-Mixed Sampler Leveraging Image Diffusion Models for Enhanced Video Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "UCF-101-FVD",
                "MSR-VTT-FVD",
                "Chronomagic-Bench-150",
                "Chronomagic-Bench-1649"
            ],
            "base_models": [
                "Animatediff (SD V1.5, Motion Adapter V3)",
                "VideoCrafterV2",
                "ModelScope-T2V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language-Image Models with 3D Understanding": {
        "filename": "Language-Image Models with 3D Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "Talk2Car",
                "DriveLM",
                "refCOCO",
                "VQAv2",
                "GQA",
                "SQA",
                "POPE"
            ],
            "base_models": [
                "Vicuna-7B",
                "LLaVA-1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TracrBench Generating Interpretability Testbeds with Large Language Models": {
        "filename": "TracrBench Generating Interpretability Testbeds with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TracrBench"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-3.5-turbo",
                "Claude-3-haiku",
                "Claude-3-sonnet",
                "Claude-3-opus",
                "Claude-3-5-sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When Geoscience Meets Foundation Models Toward a general geoscience artificial intelligence system": {
        "filename": "When Geoscience Meets Foundation Models Toward a general geoscience artificial intelligence system.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT-4",
                "Claude-3/3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NL2OR Solve Complex Operations Research Problems Using Natural Language Inputs": {
        "filename": "NL2OR Solve Complex Operations Research Problems Using Natural Language Inputs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "gpt-35-turbo-16k",
                "gpt-4-32k"
            ]
        }
    },
    "Dubo-SQL Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL": {
        "filename": "Dubo-SQL Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL.pdf",
        "analysis": {
            "benchmarks": [
                "BIRD-SQL"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4 Turbo"
            ]
        }
    },
    "DeepJoin Joinable Table Discovery with Pre-trained Language Models": {
        "filename": "DeepJoin Joinable Table Discovery with Pre-trained Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Webtable-test",
                "Wikitable-test"
            ],
            "base_models": [
                "DistilBERT",
                "MPNet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ComPile A Large IR Dataset from Production Sources": {
        "filename": "ComPile A Large IR Dataset from Production Sources.pdf",
        "analysis": {
            "benchmarks": [
                "Anghabench",
                "Exebench",
                "HPCORPUS"
            ],
            "base_models": [
                "Llama 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Code-Aware Prompting A study of Coverage Guided Test Generation in Regression Setting using LLM": {
        "filename": "Code-Aware Prompting A study of Coverage Guided Test Generation in Regression Setting using LLM.pdf",
        "analysis": {
            "benchmarks": [
                "open source Python projects benchmark"
            ],
            "base_models": [
                "CodeGen2 (16B)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Causal Relationship in Indefinite Data Baseline Model and New Datasets": {
        "filename": "Towards Causal Relationship in Indefinite Data Baseline Model and New Datasets.pdf",
        "analysis": {
            "benchmarks": [
                "Causalogue",
                "Causaction"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models and the Reverse Turing Test": {
        "filename": "Large Language Models and the Reverse Turing Test.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "LaMDA (137 billion weights)",
                "GPT-3 (175 billion weights)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When Search Engine Services Meet Large Language Models Visions and Challenges": {
        "filename": "When Search Engine Services Meet Large Language Models Visions and Challenges.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Taken out of context On measuring situational awareness in LLMs": {
        "filename": "Taken out of context On measuring situational awareness in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Out-of-context Chatbots"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "LLaMA-1 (7B)",
                "LLaMA-1 (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Graph Agent Explicit Reasoning Agent for Graphs": {
        "filename": "Graph Agent Explicit Reasoning Agent for Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "Cora",
                "PubMed",
                "PrimeKG"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-70B"
            ]
        }
    },
    "TaCo Enhancing Cross-Lingual Transfer for Low-Resource Languages in LLMs through Translation-Assisted Chain-of-Thought Processes": {
        "filename": "TaCo Enhancing Cross-Lingual Transfer for Low-Resource Languages in LLMs through Translation-Assisted Chain-of-Thought Processes.pdf",
        "analysis": {
            "benchmarks": [
                "Vicuna Benchmark"
            ],
            "base_models": [
                "Guanaco-33B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models Mostly Know What They Know": {
        "filename": "Language Models Mostly Know What They Know.pdf",
        "analysis": {
            "benchmarks": [
                "TriviaQA",
                "Lambada",
                "GSM8k",
                "Codex HumanEval",
                "Arithmetic",
                "Python Function Synthesis"
            ],
            "base_models": [
                "52B language model"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A prompt-engineered large language model deep learning workflow for materials classification": {
        "filename": "A prompt-engineered large language model deep learning workflow for materials classification.pdf",
        "analysis": {
            "benchmarks": [
                "metallic glasses dataset"
            ],
            "base_models": [
                "BERT",
                "MatSciBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Active Prompting with Chain-of-Thought for Large Language Models": {
        "filename": "Active Prompting with Chain-of-Thought for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "ASDiv",
                "SVAMP",
                "AQuA",
                "SingleEq",
                "CSQA",
                "StrategyQA",
                "last letter concatenation"
            ],
            "base_models": [
                "code-davinci-002",
                "text-davinci-002",
                "text-davinci-003",
                "gpt-3.5-turbo",
                "Llama2-70b-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DocTabQA Answering Questions from Long Documents Using Tables": {
        "filename": "DocTabQA Answering Questions from Long Documents Using Tables.pdf",
        "analysis": {
            "benchmarks": [
                "QTabA",
                "RotoWire"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-7B"
            ]
        }
    },
    "Integration of Large Vision Language Models for Efficient Post-disaster Damage Assessment and Reporting": {
        "filename": "Integration of Large Vision Language Models for Efficient Post-disaster Damage Assessment and Reporting.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset for earthquake disaster in Wajima City, Japan"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Implicit Sentiment Analysis Based on Chain-of-Thought Prompting": {
        "filename": "Implicit Sentiment Analysis Based on Chain-of-Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval 2014 Restaurant",
                "SemEval 2014 Laptop"
            ],
            "base_models": [
                "ERNIE-Bot-4",
                "Flan-T5 (76M)",
                "Flan-T5 (250M)",
                "Flan-T5 (783M)",
                "Llama2 (7B)",
                "Llama2 (70B)"
            ]
        }
    },
    "LLM Agents can Autonomously Hack Websites": {
        "filename": "LLM Agents can Autonomously Hack Websites.pdf",
        "analysis": {
            "benchmarks": [
                "sandboxed websites with 15 vulnerabilities"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "OpenHermes-2.5-Mistral-7B",
                "LLaMA-2 Chat (70B)",
                "LLaMA-2 Chat (13B)",
                "LLaMA-2 Chat (7B)",
                "Mixtral-8x7B Instruct",
                "Mistral (7B) Instruct v0.2",
                "Nous Hermes-2 Yi (34B)",
                "OpenChat 3.5"
            ]
        }
    },
    "SRLM Human-in-Loop Interactive Social Robot Navigation with Large Language Model and Deep Reinforcement Learning": {
        "filename": "SRLM Human-in-Loop Interactive Social Robot Navigation with Large Language Model and Deep Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "gym social navigation simulator"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Can language models learn from explanations in context": {
        "filename": "Can language models learn from explanations in context.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench"
            ],
            "base_models": [
                "Decoder-only Transformer (1B to 280B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Inferring Implicit Relations in Complex Questions with Language Models": {
        "filename": "Inferring Implicit Relations in Complex Questions with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "IMPLICIT RELATIONS",
                "STRATEGYQA",
                "CREAK",
                "COMMONSENSE QA 2.0"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM (540B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Gen2Sim Scaling up Robot Learning in Simulation with Generative Models": {
        "filename": "Gen2Sim Scaling up Robot Learning in Simulation with Generative Models.pdf",
        "analysis": {
            "benchmarks": [
                "PartNet Mobility",
                "GAPartNet"
            ],
            "base_models": [
                "GPT-4",
                "Stable Diffusion"
            ]
        }
    },
    "Concise Thoughts Impact of Output Length on LLM Reasoning and Cost": {
        "filename": "Concise Thoughts Impact of Output Length on LLM Reasoning and Cost.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "LLaMA2-70b",
                "Falcon-7b",
                "Vicuna-13b",
                "Falcon-40b",
                "Llama2-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia": {
        "filename": "Prompting Large Language Models for Supporting the Differential Diagnosis of Anemia.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic anemia dataset"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "LLaMA-3",
                "Mistral7B v0.3"
            ]
        }
    },
    "OmniJARVIS Unified Vision-Language-Action Tokenization Enables Open-World Instruction Following Agents": {
        "filename": "OmniJARVIS Unified Vision-Language-Action Tokenization Enables Open-World Instruction Following Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Minecraft Universe"
            ],
            "base_models": [
                "LLaV A-7B",
                "LLaV A-2B",
                "LLaV A-13B",
                "LLaMA2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Inductive-bias Learning Generating Code Models with Large Language Model": {
        "filename": "Inductive-bias Learning Generating Code Models with Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Titanic dataset",
                "pseudo dataset",
                "moon dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Sources of Hallucination by Large Language Models on Inference Tasks": {
        "filename": "Sources of Hallucination by Large Language Models on Inference Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Levy/Holt",
                "RTE-1"
            ],
            "base_models": [
                "LLaMA-65B",
                "GPT-3.5",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unleashing the Potential of Large Language Model Zero-shot VQA for Flood Disaster Scenario": {
        "filename": "Unleashing the Potential of Large Language Model Zero-shot VQA for Flood Disaster Scenario.pdf",
        "analysis": {
            "benchmarks": [
                "FFD-IQA"
            ],
            "base_models": [
                "Flan-Alpaca (based on LLaMA 7B)"
            ]
        }
    },
    "G-Retriever Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering": {
        "filename": "G-Retriever Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "ExplaGraphs",
                "SceneGraphs",
                "WebQSP"
            ],
            "base_models": [
                "MiniGPT-4",
                "Llama2-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding Defects in Generated Codes by Language Models": {
        "filename": "Understanding Defects in Generated Codes by Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval"
            ],
            "base_models": [
                "CodeT5+ (770M)",
                "CodeGen (350M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VLind-Bench Measuring Language Priors in Large Vision-Language Models": {
        "filename": "VLind-Bench Measuring Language Priors in Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "VLind-Bench",
                "WHOOPS!",
                "ROME"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4V",
                "Gemini Pro Vision",
                "LLaVA-NEXT 72B (Qwen 1.5 72B Chat)",
                "LLaVA-NEXT 34B (Nous Hermes 2 Yi 34B)",
                "LLaVA-1.5 13B (Vicuna v1.5 13B)",
                "LLaVA-1.5 7B (Vicuna v1.5 7B)",
                "InstructBLIP 13B",
                "InstructBLIP 7B",
                "OmniLMM 12B (Zephyr 7B β)",
                "MiniCPM-V-2 2.8B"
            ]
        }
    },
    "RedAgent Red Teaming Large Language Models with Context-aware Autonomous Language Agent": {
        "filename": "RedAgent Red Teaming Large Language Models with Context-aware Autonomous Language Agent.pdf",
        "analysis": {
            "benchmarks": [
                "OpenAI GPT marketplace applications"
            ],
            "base_models": [
                "GPT-4-1106-preview",
                "GPT-3.5-turbo-1106",
                "Gemini-Pro",
                "Claude-3-5-Sonnet-20240620",
                "Vicuna-7b-v1.5",
                "LLaMA-2-7b-chat-hf"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Simulating Public Administration Crisis A Novel Generative Agent-Based Simulation System to Lower Technology Barriers in Social Science Research": {
        "filename": "Simulating Public Administration Crisis A Novel Generative Agent-Based Simulation System to Lower Technology Barriers in Social Science Research.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "Enhancing CLIP with GPT-4 Harnessing Visual Descriptions as Prompts": {
        "filename": "Enhancing CLIP with GPT-4 Harnessing Visual Descriptions as Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "EuroSAT",
                "DTD",
                "SUN397",
                "CUB",
                "Caltech101",
                "OxfordPets",
                "StanfordCars",
                "Flowers102",
                "Food101",
                "FGVCAircraft",
                "UCF101",
                "ImageNet"
            ],
            "base_models": [
                "CLIP",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automatic Root Cause Analysis via Large Language Models for Cloud Incidents": {
        "filename": "Automatic Root Cause Analysis via Large Language Models for Cloud Incidents.pdf",
        "analysis": {
            "benchmarks": [
                "Microsoft real-world dataset of cloud incidents"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4 (8K tokens)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Top-Down Reasoning An Explainable Multi-Agent Approach for Visual Question Answering": {
        "filename": "Towards Top-Down Reasoning An Explainable Multi-Agent Approach for Visual Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "VQA-RAD",
                "Winoground"
            ],
            "base_models": [
                "BLIP-2 (ViT-g FlanT5XL 3B)",
                "BLIP-2 (ViT-g FlanT5XXL 11B)",
                "LLaVA-v1.5-7B",
                "LLaVA-v1.5-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Empirical Study of NetOps Capability of Pre-Trained Large Language Models": {
        "filename": "An Empirical Study of NetOps Capability of Pre-Trained Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "NetEval"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo (175B)",
                "text-davinci-003 (175B)",
                "LLaMA (7B/13B/30B/65B)",
                "LLaMA 2 (7B/13B/70B)",
                "Falcon (7B/40B)",
                "GLM (10B/130B)",
                "ChatGLM (6B)",
                "ChatGLM 2 (6B)",
                "Moss (moon-003-base, 16B)",
                "Baichuan (7B/13B)"
            ]
        }
    },
    "Large Language Models Are Active Critics in NLG Evaluation": {
        "filename": "Large Language Models Are Active Critics in NLG Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "SummEval",
                "Topical-Chat",
                "SFRES",
                "OpenMEVA (ROC)"
            ],
            "base_models": [
                "Orca2-13B",
                "GPT-3.5 (gpt-3.5-turbo-1106)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models in Targeted Sentiment Analysis": {
        "filename": "Large Language Models in Targeted Sentiment Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "RuSentNE-2023"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Flan-T5 xl (3B)",
                "Flan-T5 large (750M)",
                "Flan-T5 base (250M)",
                "Mistral-7B",
                "DeciLM-7B",
                "Microsoft-Phi-2 (2.7B)",
                "Gemma-7B-IT",
                "Gemma-2B-IT"
            ]
        }
    },
    "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT": {
        "filename": "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Socratic Models Composing Zero-Shot Multimodal Reasoning with Language": {
        "filename": "Socratic Models Composing Zero-Shot Multimodal Reasoning with Language.pdf",
        "analysis": {
            "benchmarks": [
                "MS COCO",
                "Concadia",
                "MSR-VTT"
            ],
            "base_models": [
                "GPT-3",
                "CLIP",
                "BERT",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Cross-Task Generalization with Step-by-Step Instructions": {
        "filename": "Improving Cross-Task Generalization with Step-by-Step Instructions.pdf",
        "analysis": {
            "benchmarks": [
                "SUP-NATINST"
            ],
            "base_models": [
                "T5-LM (11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM4Causal Democratized Causal Tools for Everyone via Large Language Model": {
        "filename": "LLM4Causal Democratized Causal Tools for Everyone via Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Causal-Retrieval-Bench",
                "Causal-Interpret-Bench"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "LLaMA (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Unified Hallucination Mitigation Framework for Large Vision-Language Models": {
        "filename": "A Unified Hallucination Mitigation Framework for Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMbench",
                "LLaVA-QA90",
                "CHAIR",
                "POPE"
            ],
            "base_models": [
                "InstructBLIP",
                "VisualGLM",
                "LLaVA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instruction-following Evaluation through Verbalizer Manipulation": {
        "filename": "Instruction-following Evaluation through Verbalizer Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "FP",
                "EMOTION",
                "SNLI",
                "SICK",
                "RTE",
                "QQP",
                "MRPC",
                "SUBJ"
            ],
            "base_models": [
                "Flan-T5 (80M, 250M, 780M, 3B, 11B)",
                "GPT-Series (text-ada-001, text-babbage-001, text-curie-001, text-davinci-003, ChatGPT, GPT-4)",
                "Vicuna (7B, 13B)",
                "OPT-IML (1.3B, 30B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT-4Vision is a Human-Aligned Evaluator for Text-to-3D Generation": {
        "filename": "GPT-4Vision is a Human-Aligned Evaluator for Text-to-3D Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Objaverse"
            ],
            "base_models": [
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Accelerated Preference Optimization for Large Language Model Alignment": {
        "filename": "Accelerated Preference Optimization for Large Language Model Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaEval 2.0",
                "MT-Bench",
                "Open LLM Leaderboard"
            ],
            "base_models": [
                "Mistral-7B-Instruct-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RareBench Can LLMs Serve as Rare Diseases Specialists": {
        "filename": "RareBench Can LLMs Serve as Rare Diseases Specialists.pdf",
        "analysis": {
            "benchmarks": [
                "RareBench",
                "PUMCH dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "Gemini Pro",
                "GLM4",
                "GLM3-Turbo",
                "Mistral-7B",
                "Llama2-7B",
                "ChatGLM3-6B",
                "BioMistral-7B",
                "HuatuoGPT2-7B",
                "MedAlpaca-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Text to Emoji How PEFT-Driven Personality Manipulation Unleashes the Emoji Potential in LLMs": {
        "filename": "From Text to Emoji How PEFT-Driven Personality Manipulation Unleashes the Emoji Potential in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Opinion QA dataset"
            ],
            "base_models": [
                "Mistral-7B-Instruct",
                "Llama-2-7B-chat",
                "Llama-3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGPT for GTFS From Words to Information": {
        "filename": "ChatGPT for GTFS From Words to Information.pdf",
        "analysis": {
            "benchmarks": [
                "GTFS Understanding Benchmark",
                "GTFS Retrieval Benchmark"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models be Used to Provide Psychological Counselling An Analysis of GPT-4-Generated Responses Using Role-play Dialogues": {
        "filename": "Can Large Language Models be Used to Provide Psychological Counselling An Analysis of GPT-4-Generated Responses Using Role-play Dialogues.pdf",
        "analysis": {
            "benchmarks": [
                "Role-play dialogue data"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Source Code Summarization in the Era of Large Language Models": {
        "filename": "Source Code Summarization in the Era of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Java dataset from CodeSearchNet",
                "Python dataset from CodeSearchNet",
                "C dataset from CCSD",
                "Erlang dataset (custom)",
                "Haskell dataset (custom)",
                "Prolog dataset (custom)"
            ],
            "base_models": [
                "CodeLlama-Instruct-7B",
                "StarChat-β (16B)",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interpretable Unified Language Checking": {
        "filename": "Interpretable Unified Language Checking.pdf",
        "analysis": {
            "benchmarks": [
                "Hate speech detection (HSD)",
                "Social bias inference (SBIC)",
                "Climate-fever",
                "Health fact checking",
                "GPT toxicity (ToxiGen)",
                "Machine-Generated Fake News (MGFN)"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "ESP-deberta-large (350M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mind Scramble Unveiling Large Language Model Psychology Via Typoglycemia": {
        "filename": "Mind Scramble Unveiling Large Language Model Psychology Via Typoglycemia.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "GSM8k",
                "CSQA",
                "SQuAD"
            ],
            "base_models": [
                "GPT-4",
                "Llama-3.1 (8B, 70B)",
                "Gemma-2 (2B, 9B, 27B)",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Say What You Mean Large Language Models Speak Too Positively about Negative Commonsense Knowledge": {
        "filename": "Say What You Mean Large Language Models Speak Too Positively about Negative Commonsense Knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "QNLI"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM",
                "Flan-T5 (3B)",
                "Flan-T5 (11B)",
                "Codex (175B)",
                "InstructGPT (6.7B)",
                "InstructGPT (175B)",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Receiver-Centric Generative Semantic Communications": {
        "filename": "Receiver-Centric Generative Semantic Communications.pdf",
        "analysis": {
            "benchmarks": [
                "CityFlow",
                "CityFlow V2",
                "Custom traffic surveillance video dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Economics Arena for Large Language Models": {
        "filename": "Economics Arena for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "beauty contests",
                "private-value second price auctions"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude2",
                "Claude-Instant-1.2",
                "PaLM2",
                "Llama2",
                "Baichuan2",
                "ChatGLM2",
                "ChatGLM3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM Voting Human Choices and AI Collective Decision Making": {
        "filename": "LLM Voting Human Choices and AI Collective Decision Making.pdf",
        "analysis": {
            "benchmarks": [
                "Participatory Budgeting (PB) voting experimental study"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "LLaMA-2 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The impact of AI in physics education a comprehensive review from GCSE to university levels": {
        "filename": "The impact of AI in physics education a comprehensive review from GCSE to university levels.pdf",
        "analysis": {
            "benchmarks": [
                "GCSE Physics Questions",
                "A-Level Physics Questions",
                "Introductory University Physics Questions",
                "5000 Mathematical Operations Dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "CreDes Causal Reasoning Enhancement and Dual-End Searching for Solving Long-Range Reasoning Problems using LLMs": {
        "filename": "CreDes Causal Reasoning Enhancement and Dual-End Searching for Solving Long-Range Reasoning Problems using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Blocksworld",
                "GSM8K",
                "Hanoi Tower"
            ],
            "base_models": [
                "Llama-2-7B",
                "Llama-2-13B",
                "Phi-2-7B",
                "Mistral-7B",
                "Mixtral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models": {
        "filename": "Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Original letter-string analogy problems (Webb et al., 2023)",
                "Counterfactual letter-string analogy problems"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)",
                "GPT-3.5 (gpt-3.5-turbo-0613)",
                "GPT-4 (gpt-4-turbo-0613)"
            ]
        }
    },
    "Large Language Models for Generative Information Extraction A Survey": {
        "filename": "Large Language Models for Generative Information Extraction A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "CoNLL03",
                "ACE05",
                "GENIA",
                "NYT",
                "SciERC"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-7B",
                "Flan-T5-11B",
                "Code-davinci-002",
                "BART-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "JECC Commonsense Reasoning Tasks Derived from Interactive Fictions": {
        "filename": "JECC Commonsense Reasoning Tasks Derived from Interactive Fictions.pdf",
        "analysis": {
            "benchmarks": [
                "Jericho Environment Commonsense Comprehension task (JECC)",
                "ZorkUniverse Commonsense Comprehension (ZUCC)"
            ],
            "base_models": [
                "BERT",
                "Match LSTM"
            ]
        }
    },
    "When Large Language Models Confront Repository-Level Automatic Program Repair How Well They Done": {
        "filename": "When Large Language Models Confront Repository-Level Automatic Program Repair How Well They Done.pdf",
        "analysis": {
            "benchmarks": [
                "RepoBugs"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mathematical Language Models A Survey": {
        "filename": "Mathematical Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "BART",
                "GPT-1",
                "GPT-2",
                "GPT-3 (175B)",
                "GPT-4",
                "PaLM (540B)",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AtomThink A Slow Thinking Framework for Multimodal Mathematical Reasoning": {
        "filename": "AtomThink A Slow Thinking Framework for Multimodal Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MathVista",
                "MathVerse"
            ],
            "base_models": [
                "LLaVA-Llama3-8B",
                "EMOVA-8B",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Language Model Reasoning via Weighted Reasoning in Self-Consistency": {
        "filename": "Enhancing Language Model Reasoning via Weighted Reasoning in Self-Consistency.pdf",
        "analysis": {
            "benchmarks": [
                "AQuA-RAT",
                "SVAMP",
                "StrategyQA"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama 2 (7B)",
                "Llama 3 (8B)",
                "Mistral 7B",
                "GPT-4o mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Should We Really Edit Language Models On the Evaluation of Edited Language Models": {
        "filename": "Should We Really Edit Language Models On the Evaluation of Edited Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BigBench",
                "GSM8K",
                "CommonsenseQA",
                "TriviaQA",
                "TruthfulQA",
                "ToxiGen"
            ],
            "base_models": [
                "Llama2-7B",
                "Mistral-7B",
                "GPT2-XL",
                "Pythia (160M to 12B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Position What Can Large Language Models Tell Us about Time Series Analysis": {
        "filename": "Position What Can Large Language Models Tell Us about Time Series Analysis.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Llama",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-Context Prompt Editing for Conditional Audio Generation": {
        "filename": "In-Context Prompt Editing for Conditional Audio Generation.pdf",
        "analysis": {
            "benchmarks": [
                "AudioCAPS",
                "BBC sounds",
                "Open-prompts"
            ],
            "base_models": [
                "LLaMA-70B"
            ]
        }
    },
    "Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness": {
        "filename": "Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "Commonsense Question Answering (CSQA)",
                "TriviaQA"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "Text-Davinci-003"
            ]
        }
    },
    "Large Language Models Can Self-Improve At Web Agent Tasks": {
        "filename": "Large Language Models Can Self-Improve At Web Agent Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "WebArena"
            ],
            "base_models": [
                "GPT-4",
                "Qwen-1.5-72B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are You Being Tracked Discover the Power of Zero-Shot Trajectory Tracing with LLMs": {
        "filename": "Are You Being Tracked Discover the Power of Zero-Shot Trajectory Tracing with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Indoor dataset",
                "Outdoor dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Open Artificial Knowledge": {
        "filename": "Open Artificial Knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "WinoGrande",
                "ARC Easy"
            ],
            "base_models": [
                "GPT4o",
                "LLaMa3-70B",
                "LLaMa3-8B",
                "Mixtral-8x7B",
                "Gemma-7B",
                "Gemma-2-9B"
            ]
        }
    },
    "MR-GSM8K A Meta-Reasoning Benchmark for Large Language Model Evaluation": {
        "filename": "MR-GSM8K A Meta-Reasoning Benchmark for Large Language Model Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MR-GSM8K"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "Llama3-70B",
                "Deepseek-v2-236B",
                "Claude3-Sonnet",
                "Phi-3-3.8B",
                "GPT-3.5-Turbo",
                "Qwen-v1.5-72B",
                "Llama3-8B",
                "Deepseek-Math-7B-RL",
                "WizardMath-v1.1-7B",
                "MetaMath-70B",
                "MAmmoTH-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can GPT-4 Replicate Empirical Software Engineering Research": {
        "filename": "Can GPT-4 Replicate Empirical Software Engineering Research.pdf",
        "analysis": {
            "benchmarks": [
                "Custom datasets from seven empirical software engineering papers"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CPL Counterfactual Prompt Learning for Vision and Language Models": {
        "filename": "CPL Counterfactual Prompt Learning for Vision and Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SUN397",
                "Caltech101",
                "ImageNet",
                "OxfordPets",
                "StanfordCars",
                "Flowers102",
                "Food101",
                "MSCOCO",
                "Flickr30K",
                "VQAv2"
            ],
            "base_models": [
                "CLIP"
            ]
        }
    },
    "Explaining Emergent In-Context Learning as Kernel Regression": {
        "filename": "Explaining Emergent In-Context Learning as Kernel Regression.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE-sst2",
                "rotten_tomatoes",
                "tweet_eval (hate)",
                "tweet_eval (irony)",
                "tweet_eval (offensive)",
                "MNLI"
            ],
            "base_models": [
                "GPT-J 6B"
            ]
        }
    },
    "Can GPT-4 Help Detect Quit Vaping Intentions An Exploration of Automatic Data Annotation Approach": {
        "filename": "Can GPT-4 Help Detect Quit Vaping Intentions An Exploration of Automatic Data Annotation Approach.pdf",
        "analysis": {
            "benchmarks": [
                "Custom Reddit dataset from r/QuitVaping"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Converging Paradigms The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents": {
        "filename": "Converging Paradigms The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "The Alignment Ceiling Objective Mismatch in Reinforcement Learning from Human Feedback": {
        "filename": "The Alignment Ceiling Objective Mismatch in Reinforcement Learning from Human Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8k",
                "AlpacaEval",
                "MT-Bench",
                "ChatBot Arena"
            ],
            "base_models": [
                "Llama-2-70b-chat-hf"
            ]
        }
    },
    "Max-Margin Token Selection in Attention Mechanism": {
        "filename": "Max-Margin Token Selection in Attention Mechanism.pdf",
        "analysis": {
            "benchmarks": [
                "CIFAR-10"
            ],
            "base_models": [
                "ViT-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval-Augmented Decision Transformer External Memory for In-context RL": {
        "filename": "Retrieval-Augmented Decision Transformer External Memory for In-context RL.pdf",
        "analysis": {
            "benchmarks": [
                "Dark-Room",
                "Dark Key-Door",
                "Maze-Runner",
                "Meta-World",
                "DMControl",
                "Procgen"
            ],
            "base_models": [
                "Decision Transformer",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FinCon A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making": {
        "filename": "FinCon A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making.pdf",
        "analysis": {
            "benchmarks": [
                "Custom financial dataset (stock prices, daily news, company filings, ECC audio)"
            ],
            "base_models": [
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Seeking Neural Nuggets Knowledge Transfer in Large Language Models from a Parametric Perspective": {
        "filename": "Seeking Neural Nuggets Knowledge Transfer in Large Language Models from a Parametric Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "GSM",
                "MMLU",
                "Super NI",
                "AlpacaFarm"
            ],
            "base_models": [
                "LLaMA-1 7B",
                "LLaMA-1 13B",
                "LLaMA-1 30B",
                "LLaMA-2 7B",
                "LLaMA-2 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "COOL Efficient and Reliable Chain-Oriented Objective Logic with Neural Networks Feedback Control for Program Synthesis": {
        "filename": "COOL Efficient and Reliable Chain-Oriented Objective Logic with Neural Networks Feedback Control for Program Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "CLUTRR",
                "symbolic tasks generated by GPT"
            ],
            "base_models": [
                "GPT (size not specified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Autonomous Data Selection with Language Models for Mathematical Texts": {
        "filename": "Autonomous Data Selection with Language Models for Mathematical Texts.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "BIG-Bench Hard (BBH)"
            ],
            "base_models": [
                "Qwen-72B",
                "Gemma-2B",
                "LLaMA2-7B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model Alignment A Survey": {
        "filename": "Large Language Model Alignment A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MAGDi Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models": {
        "filename": "MAGDi Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "CommonsenseQA",
                "ARC-c",
                "BoolQ",
                "GSM8K",
                "MATH",
                "SVAMP"
            ],
            "base_models": [
                "GPT-4",
                "Bard",
                "Claude2",
                "Mistral-7B-Instruct",
                "LLaMA-2-7B-Chat",
                "LLaMA-2-13B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "IoT-LLM Enhancing Real-World IoT Task Reasoning with Large Language Models": {
        "filename": "IoT-LLM Enhancing Real-World IoT Task Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Human Activity Recognition (HAR) using Inertial Measurement Unit (IMU) data",
                "Industrial anomaly detection using metrics such as temperature, cooling power, and cooling efficiency",
                "Heartbeat anomaly detection using Electrocardiogram (ECG) data",
                "Human sensing using WiFi Channel State Information (CSI)",
                "Indoor localization based on WiFi signal strength"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-3.5",
                "Gemini-pro",
                "Mistral-7B",
                "Llama2-7B"
            ]
        }
    },
    "OneGen Efficient One-Pass Unified Generation and Retrieval for LLMs": {
        "filename": "OneGen Efficient One-Pass Unified Generation and Retrieval for LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "2WIKI",
                "PubHealth",
                "ARC-Challenge",
                "PopQA",
                "TriviaQA",
                "AIDA",
                "OKE15",
                "OKE16",
                "REU",
                "MSN",
                "SPOT",
                "K50"
            ],
            "base_models": [
                "Llama2-7B",
                "Qwen2-72B",
                "Qwen2-1.5B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models": {
        "filename": "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "FLORES-200"
            ],
            "base_models": [
                "ChatGPT",
                "InstructGPT (text-davinci-003)",
                "BLOOM-7B",
                "NLLB 3.3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mastering Chess with a Transformer Model": {
        "filename": "Mastering Chess with a Transformer Model.pdf",
        "analysis": {
            "benchmarks": [
                "puzzle database curated by Ruoss et al."
            ],
            "base_models": [
                "CF-240M (243 million parameters)",
                "CF-6M (6 million parameters)"
            ]
        }
    },
    "Minds Eye Grounded Language Model Reasoning through Simulation": {
        "filename": "Minds Eye Grounded Language Model Reasoning through Simulation.pdf",
        "analysis": {
            "benchmarks": [
                "UTOPIA"
            ],
            "base_models": [
                "GPT-3 175B",
                "PaLM 8B",
                "PaLM 62B",
                "PaLM 540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WeLM A Well-Read Pre-trained Language Model for Chinese": {
        "filename": "WeLM A Well-Read Pre-trained Language Model for Chinese.pdf",
        "analysis": {
            "benchmarks": [
                "CMRC2018",
                "DRCD",
                "DuReader",
                "People_daily (PD)",
                "Children_fairy_tale (CFT)",
                "CHID",
                "CMRC2017",
                "CMNLI",
                "OCNLI",
                "TNEWS",
                "IFLYTEK",
                "SMP-ECISA",
                "ChnSentiCorp",
                "LCSTS",
                "TTNews",
                "WEBQA",
                "WSC2020",
                "C3",
                "XQuAD",
                "MLQA",
                "NCLS"
            ],
            "base_models": [
                "WeLM (10B)",
                "CPM (2.6B)",
                "Pangu (13B)",
                "Ernie 3.0 (10B)",
                "XGLM (7.5B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Prompt Engineering A Systematic Review with SWOT Analysis": {
        "filename": "Exploring Prompt Engineering A Systematic Review with SWOT Analysis.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SciLitLLM How to Adapt LLMs for Scientific Literature Understanding": {
        "filename": "SciLitLLM How to Adapt LLMs for Scientific Literature Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "SciAssess",
                "SciRIFF"
            ],
            "base_models": [
                "Qwen2.5-7B",
                "Qwen2.5-14B",
                "Llama3.1-8B",
                "Llama3.1-70B",
                "Galactica-6.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hackphyr A Local Fine-Tuned LLM Agent for Network Security Environments": {
        "filename": "Hackphyr A Local Fine-Tuned LLM Agent for Network Security Environments.pdf",
        "analysis": {
            "benchmarks": [
                "NetSecGame environment"
            ],
            "base_models": [
                "Zephyr-7b-β (7 billion parameters)",
                "GPT-4",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ReviewFlow Intelligent Scaffolding to Support Academic Peer Reviewing": {
        "filename": "ReviewFlow Intelligent Scaffolding to Support Academic Peer Reviewing.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OpenMedLM prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models": {
        "filename": "OpenMedLM prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "MedMCQA",
                "PubMedQA",
                "MMLU medical-subset"
            ],
            "base_models": [
                "Yi 34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "5W1H Extraction With Large Language Models": {
        "filename": "5W1H Extraction With Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/DailyMail",
                "XSum",
                "NYT",
                "RA-MDS"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "LLaMA-7B",
                "LLaMA-13B",
                "Vicuna-7B",
                "Vicuna-13B",
                "Guanaco-7B",
                "Guanaco-13B"
            ]
        }
    },
    "DriveLM Driving with Graph Visual Question Answering": {
        "filename": "DriveLM Driving with Graph Visual Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "DriveLM-nuScenes",
                "DriveLM-CARLA"
            ],
            "base_models": [
                "BLIP-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Human-Centric Autonomous Systems With LLMs for User Command Reasoning": {
        "filename": "Human-Centric Autonomous Systems With LLMs for User Command Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "UCU Dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "CodeLlama-34b-Instruct",
                "Llama-2-70b-Chat"
            ]
        }
    },
    "Policy Improvement using Language Feedback Models": {
        "filename": "Policy Improvement using Language Feedback Models.pdf",
        "analysis": {
            "benchmarks": [
                "Touchdown",
                "ScienceWorld",
                "ALFWorld"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Synthesizing Programmatic Reinforcement Learning Policies with Large Language Model Guided Search": {
        "filename": "Synthesizing Programmatic Reinforcement Learning Policies with Large Language Model Guided Search.pdf",
        "analysis": {
            "benchmarks": [
                "Karel domain"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BookGPT A General Framework for Book Recommendation Empowered by Large Language Model": {
        "filename": "BookGPT A General Framework for Book Recommendation Empowered by Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Douban Rating",
                "Douban Book Summary",
                "GoodBook-10k"
            ],
            "base_models": [
                "GPT-3.5-turbo-0301"
            ]
        }
    },
    "Shuo Wen Jie Zi Rethinking Dictionaries and Glyphs for Chinese Language Pre-training": {
        "filename": "Shuo Wen Jie Zi Rethinking Dictionaries and Glyphs for Chinese Language Pre-training.pdf",
        "analysis": {
            "benchmarks": [
                "CLUE",
                "CCLUE",
                "PolyMRC"
            ],
            "base_models": [
                "BERT-base",
                "RoBERTa-base-wwm-ext",
                "RoBERTa-large-wwm-ext",
                "MacBERT-large"
            ]
        }
    },
    "Reliable Natural Language Understanding with Large Language Models and Answer Set Programming": {
        "filename": "Reliable Natural Language Understanding with Large Language Models and Answer Set Programming.pdf",
        "analysis": {
            "benchmarks": [
                "QuaRel"
            ],
            "base_models": [
                "GPT-3 Davinci (~175B parameters)",
                "GPT-3 Curie (~6.7B parameters)"
            ]
        }
    },
    "Improving web element localization by using a large language model": {
        "filename": "Improving web element localization by using a large language model.pdf",
        "analysis": {
            "benchmarks": [
                "804 web element pairs from 48 real-world web applications"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distributional reasoning in LLMs Parallel reasoning processes in multi-hop reasoning": {
        "filename": "Distributional reasoning in LLMs Parallel reasoning processes in multi-hop reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Compositional Celebrities dataset",
                "Hallucinations dataset"
            ],
            "base_models": [
                "Llama-2-13B",
                "Llama-2-7B",
                "Llama-3-8B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Who is Undercover Guiding LLMs to Explore Multi-Perspective Team Tactic in the Game": {
        "filename": "Who is Undercover Guiding LLMs to Explore Multi-Perspective Team Tactic in the Game.pdf",
        "analysis": {
            "benchmarks": [
                "Who is Undercover? (WIU)"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "Claude 3",
                "Gemini",
                "Llama-3-8B"
            ]
        }
    },
    "Evaluation of large language models for discovery of gene set function": {
        "filename": "Evaluation of large language models for discovery of gene set function.pdf",
        "analysis": {
            "benchmarks": [
                "Gene Ontology (GO) terms",
                "LINCS L1000 CMAP Signatures of Differentially Expressed Genes for Small Molecules",
                "GEO Signatures of Differentially Expressed Genes for Viral Infections",
                "NeST"
            ],
            "base_models": [
                "GPT-4",
                "Gemini-Pro",
                "Mixtral-Instruct",
                "Llama2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ROOT Requirements Organization and Optimization Tool": {
        "filename": "ROOT Requirements Organization and Optimization Tool.pdf",
        "analysis": {
            "benchmarks": [
                "Autoware Foundation open-source project"
            ],
            "base_models": [
                "Anthropic's LLMs",
                "BERT variants",
                "Sentence-BERT"
            ]
        }
    },
    "CORE A Retrieve-then-Edit Framework for Counterfactual Data Generation": {
        "filename": "CORE A Retrieve-then-Edit Framework for Counterfactual Data Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MNLI",
                "IMDb"
            ],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Vision-Language Geo-Foundation Model A Survey": {
        "filename": "Towards Vision-Language Geo-Foundation Model A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "DOTA",
                "RSICD"
            ],
            "base_models": [
                "CLIP (ViT-L)",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AI Language Models Could Both Help and Harm Equity in Marine Policymaking The Case Study of the BBNJ Question-Answering Bot": {
        "filename": "AI Language Models Could Both Help and Harm Equity in Marine Policymaking The Case Study of the BBNJ Question-Answering Bot.pdf",
        "analysis": {
            "benchmarks": [
                "BBNJ-related documents"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DataAgent Evaluating Large Language Models Ability to Answer Zero-Shot Natural Language Queries": {
        "filename": "DataAgent Evaluating Large Language Models Ability to Answer Zero-Shot Natural Language Queries.pdf",
        "analysis": {
            "benchmarks": [
                "Custom benchmark datasets generated using GPT-3.5"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "RACONTEUR A Knowledgeable Insightful and Portable LLM-Powered Shell Command Explainer": {
        "filename": "RACONTEUR A Knowledgeable Insightful and Portable LLM-Powered Shell Command Explainer.pdf",
        "analysis": {
            "benchmarks": [
                "MITRE ATT&CK"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "ChatGLM2-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Octopus On-device language model for function calling of software APIs": {
        "filename": "Octopus On-device language model for function calling of software APIs.pdf",
        "analysis": {
            "benchmarks": [
                "custom benchmark for API interactions"
            ],
            "base_models": [
                "CodeLlama-7B",
                "Google Gemma 7B",
                "Google Gemma 2B",
                "Stable Code 3B"
            ]
        }
    },
    "StackSight Unveiling WebAssembly through Large Language Models and Neurosymbolic Chain-of-Thought Decompilation": {
        "filename": "StackSight Unveiling WebAssembly through Large Language Models and Neurosymbolic Chain-of-Thought Decompilation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval-X",
                "MBXP"
            ],
            "base_models": [
                "gpt-3.5-turbo-1106",
                "gpt-4-0125-preview",
                "Code Llama-7b-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SEEK Semantic Reasoning for Object Goal Navigation in Real World Inspection Tasks": {
        "filename": "SEEK Semantic Reasoning for Object Goal Navigation in Real World Inspection Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Matterport3D",
                "Gazebo simulator"
            ],
            "base_models": [
                "GPT-4",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Recursion of Thought A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models": {
        "filename": "Recursion of Thought A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic benchmark consisting of eight arithmetic and algorithmic tasks"
            ],
            "base_models": [
                "GPT-3",
                "Tiny Transformer (536K parameters)",
                "Tiny LSTM (272K parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Solving Quantitative Reasoning Problems with Language Models": {
        "filename": "Solving Quantitative Reasoning Problems with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8k",
                "MMLU-STEM",
                "OCWCourses"
            ],
            "base_models": [
                "PaLM-8B",
                "PaLM-62B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Language Models Handle Recursively Nested Grammatical Structures A Case Study on Comparing Models and Humans": {
        "filename": "Can Language Models Handle Recursively Nested Grammatical Structures A Case Study on Comparing Models and Humans.pdf",
        "analysis": {
            "benchmarks": [
                "Lakretz et al. 2022 dataset (as released in Srivastava et al. 2022)"
            ],
            "base_models": [
                "Chinchilla (70B)",
                "Smaller model (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Plan-and-Solve Prompting Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models": {
        "filename": "Plan-and-Solve Prompting Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AQuA",
                "GSM8K",
                "MultiArith",
                "AddSub",
                "SingleEq",
                "SVAMP",
                "CommonsenseQA",
                "StrategyQA",
                "Last Letter",
                "Coin Flip"
            ],
            "base_models": [
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hypothetical Minds Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models": {
        "filename": "Hypothetical Minds Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Melting Pot"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Llama-3-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aligning Large Language Models with Self-generated Preference Data": {
        "filename": "Aligning Large Language Models with Self-generated Preference Data.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaEval2.0",
                "MT-bench"
            ],
            "base_models": [
                "Mistral-7B-0.1v",
                "Phi-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Perception of Knowledge Boundary for Large Language Models through Semi-open-ended Question Answering": {
        "filename": "Perception of Knowledge Boundary for Large Language Models through Semi-open-ended Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset for semi-open-ended questions"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Language Models Use Forecasting Strategies": {
        "filename": "Can Language Models Use Forecasting Strategies.pdf",
        "analysis": {
            "benchmarks": [
                "GleanGen"
            ],
            "base_models": [
                "PaLM 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Graph-hop Retrieval and Reasoning in Complex Question Answering over Textual Database": {
        "filename": "Towards Graph-hop Retrieval and Reasoning in Complex Question Answering over Textual Database.pdf",
        "analysis": {
            "benchmarks": [
                "ReasonGraphQA"
            ],
            "base_models": [
                "T5",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Anomaly Detection of Tabular Data Using LLMs": {
        "filename": "Anomaly Detection of Tabular Data Using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ODDS"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama2-7B",
                "Mistral-7B"
            ]
        }
    },
    "Effects of Different Prompts on the Quality of GPT-4 Responses to Dementia Care Questions": {
        "filename": "Effects of Different Prompts on the Quality of GPT-4 Responses to Dementia Care Questions.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from Reddit posts"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples": {
        "filename": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples.pdf",
        "analysis": {
            "benchmarks": [
                "PRONTOQA-OOD"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "PaLM (540B)",
                "LLaMA (65B)",
                "FLAN-T5 (11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual cognition in multimodal large language models": {
        "filename": "Visual cognition in multimodal large language models.pdf",
        "analysis": {
            "benchmarks": [
                "Lerer et al. (2016)",
                "Zhou et al. (2022)",
                "Jara-Ettinger et al. (2020)",
                "Wu et al. (2023)",
                "Gerstenberg et al. (2017)"
            ],
            "base_models": [
                "GPT-4V (1.7T parameters est.)",
                "Claude-3 Opus (2T parameters est.)",
                "LLaMA Adapter (7B parameters)",
                "Fuyu-8B (8B parameters)",
                "Otter (7B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Initialization is Critical to Whether Transformers Fit Composite Functions by Inference or Memorizing": {
        "filename": "Initialization is Critical to Whether Transformers Fit Composite Functions by Inference or Memorizing.pdf",
        "analysis": {
            "benchmarks": [
                "SCAN",
                "COGS",
                "PrOntoQA"
            ],
            "base_models": [
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Measuring Faithfulness in Chain-of-Thought Reasoning": {
        "filename": "Measuring Faithfulness in Chain-of-Thought Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ARC Challenge",
                "ARC Easy",
                "AQuA",
                "HellaSwag",
                "LogiQA",
                "MMLU",
                "OpenBookQA",
                "TruthfulQA"
            ],
            "base_models": [
                "175B-parameter pretrained, decoder-only transformer",
                "13B-parameter model",
                "810M-parameter model",
                "1.6B-parameter model"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ZeroSCROLLS A Zero-Shot Benchmark for Long Text Understanding": {
        "filename": "ZeroSCROLLS A Zero-Shot Benchmark for Long Text Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "GovReport",
                "SummScreenFD",
                "QMSum",
                "SQuALITY",
                "Qasper",
                "NarrativeQA",
                "QuALITY",
                "MuSiQue",
                "SpaceDigest",
                "BookSumSort"
            ],
            "base_models": [
                "T0pp (11B)",
                "Flan-T5 (11B)",
                "Flan-UL2 (20B)",
                "DaVinci003",
                "ChatGPT",
                "Claude",
                "GPT-4"
            ]
        }
    },
    "Fine-grained Attention IO Complexity Comprehensive Analysis for Backward Passes": {
        "filename": "Fine-grained Attention IO Complexity Comprehensive Analysis for Backward Passes.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Claude",
                "Llama",
                "o1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Discovery of the Hidden World with Large Language Models": {
        "filename": "Discovery of the Hidden World with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AppleGastronome",
                "Neuropathic"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "LLaMA-70B",
                "Claude-3-Opus",
                "Mistral-Large",
                "Mistral-Medium",
                "LLaMA-2-70B",
                "Qwen-1.5-110B",
                "DeepSeek-V2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Robustness Assessment of Mathematical Reasoning in the Presence of Missing and Contradictory Conditions": {
        "filename": "Robustness Assessment of Mathematical Reasoning in the Presence of Missing and Contradictory Conditions.pdf",
        "analysis": {
            "benchmarks": [
                "PMC",
                "GSM8k",
                "SVAMP",
                "AddSub",
                "MultiArith"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assessing GPT4-V on Structured Reasoning Tasks": {
        "filename": "Assessing GPT4-V on Structured Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MathVista",
                "ChartQA",
                "ARC",
                "Spider"
            ],
            "base_models": [
                "GPT-4V"
            ]
        }
    },
    "Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps": {
        "filename": "Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps.pdf",
        "analysis": {
            "benchmarks": [
                "App Store dataset"
            ],
            "base_models": [
                "ChatGPT-4 Vision",
                "GPT-3.5",
                "GPT-4",
                "Vicuna",
                "LLaVa-1.5"
            ]
        }
    },
    "SANA Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers": {
        "filename": "SANA Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "MJHQ-30K",
                "GenEval",
                "DPG-Bench",
                "ImageReward"
            ],
            "base_models": [
                "Gemma-2 (2B)",
                "Sana-0.6B",
                "Sana-1.6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VisionTasker Mobile Task Automation Using Vision Based UI Understanding and LLM Task Planning": {
        "filename": "VisionTasker Mobile Task Automation Using Vision Based UI Understanding and LLM Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "MoTIF",
                "META",
                "UGIF",
                "AITW"
            ],
            "base_models": [
                "ERNIE Bot",
                "Qwen1.5-110b",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Efficient is LLM-Generated Code A Rigorous  High-Standard Benchmark": {
        "filename": "How Efficient is LLM-Generated Code A Rigorous  High-Standard Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "HumanEval+"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "GPT-4",
                "Llama 3 70B Instruct",
                "Llama 3 8B Instruct",
                "Mixtral 8x22B Instruct",
                "Mixtral 8x7B Instruct",
                "Claude 3 Opus",
                "Claude 3 Sonnet",
                "Claude 3 Haiku",
                "Phind Code Llama V2",
                "ChatGPT",
                "Code Llama 70B Python",
                "Code Llama 34B Python",
                "Code Llama 13B Python",
                "Code Llama 7B Python",
                "StarCoder",
                "CodeGen 16B",
                "CodeGen 6B",
                "CodeGen 2B",
                "CodeT5+ 16B",
                "Mistral 7B",
                "Vicuna 13B",
                "Vicuna 7B",
                "SantaCoder",
                "Incoder 6B",
                "Incoder 1B",
                "GPT-J",
                "GPT-Neo 2B",
                "PolyCoder",
                "StableLM 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Finetuned Language Models Are Zero-Shot Learners": {
        "filename": "Finetuned Language Models Are Zero-Shot Learners.pdf",
        "analysis": {
            "benchmarks": [
                "ANLI",
                "RTE",
                "BoolQ",
                "AI2-ARC",
                "OpenbookQA",
                "StoryCloze",
                "ARC-easy",
                "ARC-challenge",
                "NQ",
                "TriviaQA",
                "MultiRC",
                "SQuAD",
                "CoPA",
                "HellaSwag",
                "PiQA",
                "Winogrande",
                "DPR",
                "WSC273",
                "ParaCrawl EN/ES",
                "ParaCrawl EN/DE",
                "ParaCrawl EN/FR",
                "WMT-16 EN/CS",
                "WMT-16 EN/DE",
                "WMT-16 EN/FI",
                "WMT-16 EN/RO",
                "WMT-16 EN/RU",
                "WMT-16 EN/TR",
                "AG News",
                "AESLC",
                "CNN-DM",
                "Gigaword",
                "Multi-News",
                "Newsroom",
                "Opin-Abs: iDebate",
                "Opin-Abs: Movie",
                "SamSum",
                "Wiki Lingua EN",
                "XSum",
                "DROP",
                "QQP",
                "MRPC",
                "PAWS",
                "STS-B",
                "CosmosQA",
                "ReCoRD",
                "QuAC",
                "CoQA",
                "WIC",
                "TREC",
                "CoLA",
                "Math",
                "Fix Punctuation"
            ],
            "base_models": [
                "LaMDA-PT (137B)",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Handcrafted Features to LLMs A Brief Survey for Machine Translation Quality Estimation": {
        "filename": "From Handcrafted Features to LLMs A Brief Survey for Machine Translation Quality Estimation.pdf",
        "analysis": {
            "benchmarks": [
                "MLQE-PE",
                "WMT2023 QE"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA",
                "BERT",
                "XLM",
                "XLM-R"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Meta Prompting for AI Systems": {
        "filename": "Meta Prompting for AI Systems.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "Game of 24"
            ],
            "base_models": [
                "Qwen-72B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing SQL Query Generation with Neurosymbolic Reasoning": {
        "filename": "Enhancing SQL Query Generation with Neurosymbolic Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Spider"
            ],
            "base_models": [
                "CodeT5 small (62M)",
                "CodeT5 base (222M)",
                "BART (139M)",
                "CodeGen (350M)",
                "Microsoft Phi-1.5 (1.3B)",
                "ChatGPTv3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Better Answers Automated Stack Overflow Post Updating": {
        "filename": "Towards Better Answers Automated Stack Overflow Post Updating.pdf",
        "analysis": {
            "benchmarks": [
                "Stack Overflow in-the-wild evaluation"
            ],
            "base_models": [
                "CodeLlama (13B)",
                "CoditT5",
                "ChatGPT (GPT-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language based Context Modeling and Reasoning for Ubiquitous Computing with Large Language Models A Tutorial": {
        "filename": "Natural Language based Context Modeling and Reasoning for Ubiquitous Computing with Large Language Models A Tutorial.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LogicGame Benchmarking Rule-Based Reasoning Abilities of Large Language Models": {
        "filename": "LogicGame Benchmarking Rule-Based Reasoning Abilities of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "LOGIC GAME"
            ],
            "base_models": [
                "claude-3.5-sonnet",
                "gpt-4-turbo-0409",
                "o1-mini",
                "qwen2-72b-instruct",
                "llama-3-70b-chat",
                "llama-3-8b-chat",
                "claude-3-haiku",
                "internlm-2.5-7b-chat",
                "qwen2-7b-instruct",
                "glm-4-9b",
                "mistral-7b-instruct",
                "glm-4-plus",
                "gpt-4o",
                "o1-preview"
            ]
        }
    },
    "Conditional LoRA Parameter Generation": {
        "filename": "Conditional LoRA Parameter Generation.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SemArt",
                "WikiArt"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "GPT-2",
                "DeBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How to Build a Pre-trained Multimodal model for Simultaneously Chatting and Decision-making": {
        "filename": "How to Build a Pre-trained Multimodal model for Simultaneously Chatting and Decision-making.pdf",
        "analysis": {
            "benchmarks": [
                "CARLA"
            ],
            "base_models": [
                "Llama-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RLET A Reinforcement Learning Based Approach for Explainable QA with Entailment Trees": {
        "filename": "RLET A Reinforcement Learning Based Approach for Explainable QA with Entailment Trees.pdf",
        "analysis": {
            "benchmarks": [
                "EntailmentBank"
            ],
            "base_models": [
                "DeBERTa-v3-base (184M)",
                "BART-Large (406M)",
                "T5-Large (770M)"
            ]
        }
    },
    "Revolutionizing Finance with LLMs An Overview of Applications and Insights": {
        "filename": "Revolutionizing Finance with LLMs An Overview of Applications and Insights.pdf",
        "analysis": {
            "benchmarks": [
                "FPB",
                "FiQA-SA",
                "NER",
                "FinQA",
                "ConvFinQA",
                "BigData22"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMs-based Few-Shot Disease Predictions using EHR A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction": {
        "filename": "LLMs-based Few-Shot Disease Predictions using EHR A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-III",
                "CRADLE"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ]
        }
    },
    "ChatGPT Is Here to Help Not to Replace Anybody - An Evaluation of Students Opinions On Integrating ChatGPT In CS Courses": {
        "filename": "ChatGPT Is Here to Help Not to Replace Anybody - An Evaluation of Students Opinions On Integrating ChatGPT In CS Courses.pdf",
        "analysis": {
            "benchmarks": [
                "Million Song Dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Evaluating Zero-Shot Multilingual Aspect-Based Sentiment Analysis with Large Language Models": {
        "filename": "Evaluating Zero-Shot Multilingual Aspect-Based Sentiment Analysis with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval-2016"
            ],
            "base_models": [
                "Llama-3.1 8B",
                "Mistral 7B",
                "Gemma-2 9B",
                "Qwen-2.5 7B",
                "Zephyr 7B",
                "Phi-3.5-mini 3.8B",
                "Gemini-1.5",
                "Claude-3.5",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Timo Towards Better Temporal Reasoning for Language Models": {
        "filename": "Timo Towards Better Temporal Reasoning for Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Wang & Zhao (2023) temporal reasoning benchmark"
            ],
            "base_models": [
                "LLAMA2-7B",
                "LLAMA2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-playing Adversarial Language Game Enhances LLM Reasoning": {
        "filename": "Self-playing Adversarial Language Game Enhances LLM Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BBH",
                "Mutual",
                "ARC-e",
                "ARC-c",
                "LGQA2",
                "WGrande",
                "PIQA"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "Baichuan-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLMs Augment Low-Resource Reading Comprehension Datasets Opportunities and Challenges": {
        "filename": "Can LLMs Augment Low-Resource Reading Comprehension Datasets Opportunities and Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "CovidQA",
                "PolicyQA",
                "TechQA"
            ],
            "base_models": [
                "GPT-4",
                "RoBERTa-Base"
            ]
        }
    },
    "Easy-to-Hard Generalization Scalable Alignment Beyond Human Supervision": {
        "filename": "Easy-to-Hard Generalization Scalable Alignment Beyond Human Supervision.pdf",
        "analysis": {
            "benchmarks": [
                "MATH500",
                "MetaMath",
                "Math-Shepherd",
                "APPS"
            ],
            "base_models": [
                "Llemma-7b",
                "Llemma-34b",
                "Code Llama-7b",
                "Code Llama-34b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT-Fabric Folding and Smoothing Fabric by Leveraging Pre-Trained Foundation Models": {
        "filename": "GPT-Fabric Folding and Smoothing Fabric by Leveraging Pre-Trained Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "SoftGym",
                "Foldsformer dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Linearly Controlled Language Generation with Performative Guarantees": {
        "filename": "Linearly Controlled Language Generation with Performative Guarantees.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Robustness Testing of Multi-Modal Models in Varied Home Environments for Assistive Robots": {
        "filename": "Robustness Testing of Multi-Modal Models in Varied Home Environments for Assistive Robots.pdf",
        "analysis": {
            "benchmarks": [
                "AI2Thor",
                "ALFRED"
            ],
            "base_models": [
                "HLSM",
                "FILM",
                "EmBERT"
            ]
        }
    },
    "Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models": {
        "filename": "Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "world travel recommendation dataset",
                "local dining recommendation dataset",
                "sports understanding task"
            ],
            "base_models": [
                "DaVinci (175B)",
                "Curie (13B)"
            ]
        }
    },
    "Psychologically-informed chain-of-thought prompts for metaphor understanding in large language models": {
        "filename": "Psychologically-informed chain-of-thought prompts for metaphor understanding in large language models.pdf",
        "analysis": {
            "benchmarks": [
                "Katz corpus"
            ],
            "base_models": [
                "GPT-3 DaVinci (175B)",
                "GPT-3 Curie (6.7B)"
            ]
        }
    },
    "GPT Struct Me Probing GPT Models on Narrative Entity Extraction": {
        "filename": "GPT Struct Me Probing GPT Models on Narrative Entity Extraction.pdf",
        "analysis": {
            "benchmarks": [
                "Text2Story Lusa dataset"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5 (ChatGPT)"
            ]
        }
    },
    "Learning Manipulation Skills through Robot Chain-of-Thought with Sparse Failure Guidance": {
        "filename": "Learning Manipulation Skills through Robot Chain-of-Thought with Sparse Failure Guidance.pdf",
        "analysis": {
            "benchmarks": [
                "MetaWorld-v2"
            ],
            "base_models": [
                "GPT-4V",
                "VideoCLIP"
            ]
        }
    },
    "An Expression Tree Decoding Strategy for Mathematical Equation Generation": {
        "filename": "An Expression Tree Decoding Strategy for Mathematical Equation Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MathQA",
                "Math23K",
                "MAWPS"
            ],
            "base_models": [
                "BERT",
                "mBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathAttack Attacking Large Language Models Towards Math Solving Ability": {
        "filename": "MathAttack Attacking Large Language Models Towards Math Solving Ability.pdf",
        "analysis": {
            "benchmarks": [
                "RobustMath",
                "GSM8K",
                "MultiAirth"
            ],
            "base_models": [
                "Flan-T5-large (760M)",
                "Flan-T5-xl (3B)",
                "ChatGLM2 (6B)",
                "ChatGPT (GPT-3.5-turbo)"
            ]
        }
    },
    "A Survey on the Integration of Generative AI for Critical Thinking in Mobile Networks": {
        "filename": "A Survey on the Integration of Generative AI for Critical Thinking in Mobile Networks.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "CommonsenseQA",
                "LogiQA 2.0"
            ],
            "base_models": [
                "GPT-3",
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assessing Privacy Policies with AI Ethical Legal and Technical Challenges": {
        "filename": "Assessing Privacy Policies with AI Ethical Legal and Technical Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "Amazon.com Privacy Notice"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "Towards Controlled Table-to-Text Generation with Scientific Reasoning": {
        "filename": "Towards Controlled Table-to-Text Generation with Scientific Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "CTRLSciTab"
            ],
            "base_models": [
                "BART-base",
                "T5-small",
                "GPT-3.5"
            ]
        }
    },
    "Large Language Models Meet Graph Neural Networks A Perspective of Graph Mining": {
        "filename": "Large Language Models Meet Graph Neural Networks A Perspective of Graph Mining.pdf",
        "analysis": {
            "benchmarks": [
                "ogbn-arxiv",
                "Amazon-Sports",
                "GoodReads",
                "MovieLens",
                "Amazon-book"
            ],
            "base_models": [
                "ChatGPT",
                "BERT",
                "GPT-3",
                "GPT-4",
                "LLaMA-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "G-Eval NLG Evaluation using GPT-4 with Better Human Alignment": {
        "filename": "G-Eval NLG Evaluation using GPT-4 with Better Human Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "SummEval",
                "Topical-Chat",
                "QAGS"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 (text-davinci-003)"
            ]
        }
    },
    "FeedbackLogs Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines": {
        "filename": "FeedbackLogs Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines.pdf",
        "analysis": {
            "benchmarks": [
                "Imagenet1K",
                "Imagenet-A"
            ],
            "base_models": [
                "ResNet50",
                "ResNet-101"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM Guided Inductive Inference for Solving Compositional Problems": {
        "filename": "LLM Guided Inductive Inference for Solving Compositional Problems.pdf",
        "analysis": {
            "benchmarks": [
                "Compositional Celebrities",
                "FEVER",
                "HotPotQA"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)"
            ]
        }
    },
    "Stress Testing Chain-of-Thought Prompting for Large Language Models": {
        "filename": "Stress Testing Chain-of-Thought Prompting for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ASDiv",
                "GSM8k",
                "SVAMP",
                "MAWPS",
                "Date Understanding (from BIG Bench)",
                "Symbolic reasoning"
            ],
            "base_models": [
                "GPT-3 (text-davinci-002)"
            ]
        }
    },
    "Transformers on Markov Data Constant Depth Suffices": {
        "filename": "Transformers on Markov Data Constant Depth Suffices.pdf",
        "analysis": {
            "benchmarks": [
                "kth-order Markov processes"
            ],
            "base_models": [
                "Transformer (3 layers, 1 head per layer)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SeaKR Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation": {
        "filename": "SeaKR Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "2WikiMultiHopQA",
                "HotpotQA",
                "IIRC",
                "NaturalQuestions",
                "TriviaQA",
                "SQuAD"
            ],
            "base_models": [
                "LLaMA-2-chat (7B)",
                "LLaMA-3 (8B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MMCTAgent Multi-modal Critical Thinking Agent Framework for Complex Visual Reasoning": {
        "filename": "MMCTAgent Multi-modal Critical Thinking Agent Framework for Complex Visual Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MMMU",
                "MMVET",
                "MathVista",
                "MMBench",
                "OKVQA",
                "EgoSchema",
                "MMCT-QA"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini",
                "Claude",
                "BLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Accuracy Evaluating the Reasoning Behavior of Large Language Models - A Survey": {
        "filename": "Beyond Accuracy Evaluating the Reasoning Behavior of Large Language Models - A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "Einstein's puzzle",
                "MATH dataset"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT",
                "GPT-4",
                "PaLM 2-L",
                "Gemini Pro",
                "BERT",
                "RoBERTa",
                "T5",
                "LLaMA",
                "LLaMA 2-7B",
                "GPT-J",
                "Claude 2",
                "LLaMA 2-70B",
                "BART"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Found in the Middle Permutation Self-Consistency Improves Listwise Ranking in Large Language Models": {
        "filename": "Found in the Middle Permutation Self-Consistency Improves Listwise Ranking in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MathSort",
                "WordSort",
                "GSM8KSort",
                "TREC-DL19",
                "TREC-DL20"
            ],
            "base_models": [
                "Mistral-7B",
                "Zephyr β-7B",
                "LLaMA v2-7B",
                "LLaMA v2-13B",
                "LLaMA v2-70B",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LM vs LM Detecting Factual Errors via Cross Examination": {
        "filename": "LM vs LM Detecting Factual Errors via Cross Examination.pdf",
        "analysis": {
            "benchmarks": [
                "LAMA",
                "TriviaQA",
                "Natural Questions (NQ)",
                "PopQA"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-3 (text-davinci-003)",
                "LLAMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FRACTURED-SORRY-Bench Framework for Revealing Attacks in Conversational Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench": {
        "filename": "FRACTURED-SORRY-Bench Framework for Revealing Attacks in Conversational Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench.pdf",
        "analysis": {
            "benchmarks": [
                "SORRY-Bench"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4o",
                "GPT-4o-mini",
                "GPT-3.5-Turbo"
            ]
        }
    },
    "Learning From Correctness Without Prompting Makes LLM Efficient Reasoner": {
        "filename": "Learning From Correctness Without Prompting Makes LLM Efficient Reasoner.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "AQuA",
                "SVAMP",
                "CSQA",
                "StrategyQA",
                "Date Understanding"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "DeepSeekMath-RL-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Évaluation des capacités de réponse de larges modèles de langage LLM pour des questions dhistoriens": {
        "filename": "Évaluation des capacités de réponse de larges modèles de langage LLM pour des questions dhistoriens.pdf",
        "analysis": {
            "benchmarks": [
                "Custom history question testbed"
            ],
            "base_models": [
                "GPT-4 (170 trillion)",
                "GPT-3.5-turbo (175 billion)",
                "PaLM 2",
                "Sophos-2 (20 billion and more)",
                "Guanaco-33b-GGML (33 billion)",
                "Vicuna-33b-v1.3 (33 billion)",
                "L13b-snoozy (13 billion)",
                "Koala 13b-diff-v2 (13 billion)",
                "Vigogne Instruct-13b (13 billion)",
                "Falcon Instruct-7B (7 billion)"
            ]
        }
    },
    "MIRAGE Evaluating and Explaining Inductive Reasoning Process in Language Models": {
        "filename": "MIRAGE Evaluating and Explaining Inductive Reasoning Process in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MIRAGE"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4o",
                "Claude-3.5",
                "Llama3-8B",
                "Llama2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Verification Reduces Hallucination in Large Language Models": {
        "filename": "Chain-of-Verification Reduces Hallucination in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Wikidata",
                "Wiki-Category List",
                "MultiSpanQA",
                "Longform Generation of Biographies"
            ],
            "base_models": [
                "Llama 65B",
                "Llama 2 70B Chat"
            ]
        }
    },
    "Selenite Scaffolding Online Sensemaking with Comprehensive Overviews Elicited from Large Language Models": {
        "filename": "Selenite Scaffolding Online Sensemaking with Comprehensive Overviews Elicited from Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring the Potential of Large Language Models LLMsin Learning on Graphs": {
        "filename": "Exploring the Potential of Large Language Models LLMsin Learning on Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "Ogbn-arxiv",
                "Ogbn-products",
                "Cora",
                "Pubmed"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0613)",
                "Deberta-base",
                "LLaMA 7B",
                "Sentence-BERT (MiniLM)",
                "e5-large",
                "text-ada-embedding-002",
                "Google Palm Cortex 001"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PaLM-E An Embodied Multimodal Language Model": {
        "filename": "PaLM-E An Embodied Multimodal Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "OK-VQA",
                "VQA v2",
                "COCO captioning"
            ],
            "base_models": [
                "PaLM-540B",
                "Vision Transformer (ViT-22B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Refining Wikidata Taxonomy using Large Language Models": {
        "filename": "Refining Wikidata Taxonomy using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Wikidata"
            ],
            "base_models": [
                "Mixtral-8x7B-Instruct-v0.1"
            ]
        }
    },
    "Look Before You Leap Unveiling the Power of GPT-4V in Robotic Vision-Language Planning": {
        "filename": "Look Before You Leap Unveiling the Power of GPT-4V in Robotic Vision-Language Planning.pdf",
        "analysis": {
            "benchmarks": [
                "RA VENS environment"
            ],
            "base_models": [
                "GPT-4V",
                "Llama 2 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Feedback Enhance Semantic Grounding in Large Vision-Language Models": {
        "filename": "Can Feedback Enhance Semantic Grounding in Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ADE20k",
                "COCO"
            ],
            "base_models": [
                "LLaVA-1.5",
                "ViP-LLaVA",
                "CogVLM",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TELeR A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks": {
        "filename": "TELeR A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "Bard",
                "LLaMA",
                "BLOOM",
                "PaLM"
            ]
        }
    },
    "Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs": {
        "filename": "Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "FB15K",
                "TMDB5K",
                "MUSIC10K"
            ],
            "base_models": [
                "Llama3.1-8b-Instruct",
                "GLM4-9b-Chat",
                "Qwen2-7b-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prism A Framework for Decoupling and Assessing the Capabilities of VLMs": {
        "filename": "Prism A Framework for Decoupling and Assessing the Capabilities of VLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MMStar"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaVA-2B",
                "LLaVA-NeXT-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Deep Bidirectional Language-Knowledge Graph Pretraining": {
        "filename": "Deep Bidirectional Language-Knowledge Graph Pretraining.pdf",
        "analysis": {
            "benchmarks": [
                "CSQA",
                "OBQA",
                "Riddle",
                "ARC",
                "CosmosQA",
                "HellaSwag",
                "PIQA",
                "SIQA",
                "aNLI",
                "MedQA",
                "PubMedQA",
                "BioASQ"
            ],
            "base_models": [
                "RoBERTa-Large",
                "BioLinkBERT-Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Skills-in-Context Prompting Unlocking Compositionality in Large Language Models": {
        "filename": "Skills-in-Context Prompting Unlocking Compositionality in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "CommaQA-E",
                "dynamic programming",
                "last letter concatenation",
                "addition and multiplication"
            ],
            "base_models": [
                "LLAMA",
                "GPT-3 (text-davinci-003)",
                "ChatGPT",
                "GPT-4",
                "PaLM-2",
                "Minerva-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Generalist to Specialist Improving Large Language Models for Medical Physics Using ARCoT": {
        "filename": "From Generalist to Specialist Improving Large Language Models for Medical Physics Using ARCoT.pdf",
        "analysis": {
            "benchmarks": [
                "RAPHEX 2023 Therapy exam"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude 2.1",
                "Gemini Pro 1.0"
            ]
        }
    },
    "In-context Learning with Retrieved Demonstrations for Language Models A Survey": {
        "filename": "In-context Learning with Retrieved Demonstrations for Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "SA (sentiment analysis)",
                "QA (question answering)",
                "SP (semantic parsing)",
                "DST (Dialogue State Tracking)",
                "Summ (Summarization)",
                "CSR (commonsense reasoning)",
                "RC (reading comprehension)",
                "NLI (natural language inference)",
                "CR (Coreference Resolution)",
                "MathR (mathematical reasoning)",
                "PD (paraphrase detection)",
                "TC (Topic Classification)",
                "StoryGen (Story Generation)",
                "MT (Machine Translation)"
            ],
            "base_models": [
                "GPT-3",
                "GPT-J",
                "GPT-NeoX",
                "CODEX",
                "T5-11B",
                "mBERT",
                "XGLM-7.5G",
                "OPT-13/175B",
                "LLaMA-7/70B",
                "PaLM",
                "Flan-PaLM",
                "BLOOM-3B",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BlendServe Optimizing Offline Inference for Auto-regressive Large Models with Resource-aware Batching": {
        "filename": "BlendServe Optimizing Offline Inference for Auto-regressive Large Models with Resource-aware Batching.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "OpenVid"
            ],
            "base_models": [
                "Llama-3.1-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bypassing the Exponential Dependency Looped Transformers Efficiently Learn In-context by Multi-step Gradient Descent": {
        "filename": "Bypassing the Exponential Dependency Looped Transformers Efficiently Learn In-context by Multi-step Gradient Descent.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic data"
            ],
            "base_models": [
                "GPT-4",
                "Claude 3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reducing LLM Hallucinations using Epistemic Neural Networks": {
        "filename": "Reducing LLM Hallucinations using Epistemic Neural Networks.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA"
            ],
            "base_models": [
                "Llama-2 7B"
            ]
        }
    },
    "Tree-of-Mixed-Thought Combining Fast and Slow Thinking for Multi-hop Visual Reasoning": {
        "filename": "Tree-of-Mixed-Thought Combining Fast and Slow Thinking for Multi-hop Visual Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "PTR",
                "CLEVR"
            ],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OpenKD Opening Prompt Diversity for Zero- and Few-shot Keypoint Detection": {
        "filename": "OpenKD Opening Prompt Diversity for Zero- and Few-shot Keypoint Detection.pdf",
        "analysis": {
            "benchmarks": [
                "Animal pose dataset",
                "AwA",
                "CUB",
                "NABird"
            ],
            "base_models": [
                "CLIP",
                "GPT3.5",
                "Vicuna"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Diplomat A Dialogue Dataset for Situated Pragmatic Reasoning": {
        "filename": "Diplomat A Dialogue Dataset for Situated Pragmatic Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "DiPlomat"
            ],
            "base_models": [
                "ChatGPT",
                "BERT base",
                "RoBERTa base",
                "GPT-2 base",
                "DialoGPT medium",
                "BART-base",
                "T5-small",
                "mT5-small",
                "UnifiedQA-base",
                "UnifiedQA-large",
                "DeBERTa-Large",
                "T5-XXL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DGRC An Effective Fine-tuning Framework for Distractor Generation in Chinese Multi-choice Reading Comprehension": {
        "filename": "DGRC An Effective Fine-tuning Framework for Distractor Generation in Chinese Multi-choice Reading Comprehension.pdf",
        "analysis": {
            "benchmarks": [
                "C3",
                "Logiqa"
            ],
            "base_models": [
                "GLM large Chinese model (335M parameters)",
                "ChatGLM3-6B"
            ]
        }
    },
    "MARIO MAth Reasoning with code Interpreter Output - A Reproducible Pipeline": {
        "filename": "MARIO MAth Reasoning with code Interpreter Output - A Reproducible Pipeline.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "OCWCourses",
                "GaoKao2023-Math-En"
            ],
            "base_models": [
                "GPT-4",
                "Claude-2",
                "PaLM-2 540B",
                "Llama-2",
                "Llemma 34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models do Analytical Reasoning": {
        "filename": "Can Large Language Models do Analytical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "NBA play-by-play data",
                "NFL play-by-play data"
            ],
            "base_models": [
                "GPT-4",
                "Claude-2.1",
                "GPT-3.5",
                "Gemini-Pro",
                "Llama-2-70b"
            ]
        }
    },
    "Symbol tuning improves in-context learning in language models": {
        "filename": "Symbol tuning improves in-context learning in language models.pdf",
        "analysis": {
            "benchmarks": [
                "List Functions",
                "Simple Turing Concepts",
                "SUBJ",
                "TEH",
                "TEAB",
                "TEAT",
                "TEFE",
                "TEHI",
                "ADEC",
                "OR",
                "SOT",
                "TOS",
                "TC"
            ],
            "base_models": [
                "Flan-PaLM-8B",
                "Flan-PaLM-62B",
                "Flan-cont-PaLM-62B",
                "Flan-PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language Outlines for Code Literate Programming in the LLM Era": {
        "filename": "Natural Language Outlines for Code Literate Programming in the LLM Era.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of 30 Python functions",
                "custom dataset of 80 decompiled Android functions"
            ],
            "base_models": [
                "Gemini 1.0 Pro",
                "Gemini 1.0 Ultra",
                "Gemini 1.5 Flash",
                "Gemini 1.5 Pro",
                "DeepSeek-Coder-Instruct 33B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Quantifying Generalization Complexity for Large Language Models": {
        "filename": "Quantifying Generalization Complexity for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SCYLLA"
            ],
            "base_models": [
                "LLaMA-3.1-70B",
                "LLaMA-3.1-405B",
                "Qwen-1.5-110B",
                "Claude-3-Sonnet",
                "GPT-4o",
                "o1-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OpsEval A Comprehensive IT Operations Benchmark Suite for Large Language Models": {
        "filename": "OpsEval A Comprehensive IT Operations Benchmark Suite for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "OpsEval"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4V",
                "Meta-Llama-3",
                "GLM-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evolution of Heuristics Towards Efficient Automatic Algorithm Design Using Large Language Model": {
        "filename": "Evolution of Heuristics Towards Efficient Automatic Algorithm Design Using Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Online bin packing problem",
                "Traveling Salesman Problem (TSP)",
                "Flow Shop Scheduling Problem (FSSP)"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MatCha Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering": {
        "filename": "MatCha Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering.pdf",
        "analysis": {
            "benchmarks": [
                "PlotQA",
                "ChartQA",
                "Chart-to-Text (Pew)",
                "Chart-to-Text (Statista)"
            ],
            "base_models": [
                "Pix2Struct"
            ]
        }
    },
    "Deductive Verification of Chain-of-Thought Reasoning": {
        "filename": "Deductive Verification of Chain-of-Thought Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQuA",
                "MATH",
                "AddSub",
                "Last Letter Concatenation",
                "Date Understanding"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LR-SQL A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios": {
        "filename": "LR-SQL A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios.pdf",
        "analysis": {
            "benchmarks": [
                "Spider"
            ],
            "base_models": [
                "GPT-4",
                "PaLM2",
                "GLM-4",
                "Qwen2",
                "DeepSeek"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ToolkenGPT Augmenting Frozen Language Models with Massive Tools via Tool Embeddings": {
        "filename": "ToolkenGPT Augmenting Frozen Language Models with Massive Tools via Tool Embeddings.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K-XL",
                "FuncQA",
                "KAMEL",
                "VirtualHome"
            ],
            "base_models": [
                "LLaMA-33B",
                "LLaMA-13B",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Pre-Calc Learning to Use the Calculator Improves Numeracy in Language Models": {
        "filename": "Pre-Calc Learning to Use the Calculator Improves Numeracy in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "QNLI",
                "QQA",
                "RedditNLI",
                "AWPNLI",
                "RTE-Quant",
                "NewsNLI",
                "StressTest"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "Flan-T5"
            ]
        }
    },
    "Hypothesis Search Inductive Reasoning with Language Models": {
        "filename": "Hypothesis Search Inductive Reasoning with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ARC",
                "1D-ARC",
                "SyGuS",
                "List Functions"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Honest Students from Untrusted Teachers Learning an Interpretable Question-Answering Pipeline from a Pretrained Language Model": {
        "filename": "Honest Students from Untrusted Teachers Learning an Interpretable Question-Answering Pipeline from a Pretrained Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "QuoRef",
                "SQuAD"
            ],
            "base_models": [
                "PaLM-540B",
                "mT5-XXL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assisting humans in complex comparisons automated information comparison at scale": {
        "filename": "Assisting humans in complex comparisons automated information comparison at scale.pdf",
        "analysis": {
            "benchmarks": [
                "financial news dataset"
            ],
            "base_models": [
                "Llama 2 7B",
                "Llama 2 13B",
                "Llama 2 70B",
                "Mistral 7B",
                "GPT 3.5",
                "GPT 4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bridging the Gap Exploring the Capabilities of Bridge-Architectures for Complex Visual Reasoning Tasks": {
        "filename": "Bridging the Gap Exploring the Capabilities of Bridge-Architectures for Complex Visual Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "NLVR2"
            ],
            "base_models": [
                "LLaV A",
                "FLAN-T5",
                "OPT",
                "Fromage",
                "Open-Flamingo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Theoretical limitations of multi-layer Transformer": {
        "filename": "Theoretical limitations of multi-layer Transformer.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generating CAD Code with Vision-Language Models for 3D Designs": {
        "filename": "Generating CAD Code with Vision-Language Models for 3D Designs.pdf",
        "analysis": {
            "benchmarks": [
                "CADPrompt"
            ],
            "base_models": [
                "GPT-4",
                "Gemini 1.5 Pro",
                "CodeLlama"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lachesis Predicting LLM Inference Accuracy using Structural Properties of Reasoning Paths": {
        "filename": "Lachesis Predicting LLM Inference Accuracy using Structural Properties of Reasoning Paths.pdf",
        "analysis": {
            "benchmarks": [
                "BugsInPy",
                "Defects4J"
            ],
            "base_models": []
        }
    },
    "MAmmoTH Building Math Generalist Models through Hybrid Instruction Tuning": {
        "filename": "MAmmoTH Building Math Generalist Models through Hybrid Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "AQuA-RAT",
                "NumGLUE",
                "SVAMP",
                "SAT-Math",
                "MMLU-Math",
                "Mathematics",
                "SimulEq"
            ],
            "base_models": [
                "Llama-2 (7B, 13B, 34B, 70B)",
                "Code Llama (7B, 13B, 34B, 70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assertion Detection Large Language Model In-context Learning LoRA Fine-tuning": {
        "filename": "Assertion Detection Large Language Model In-context Learning LoRA Fine-tuning.pdf",
        "analysis": {
            "benchmarks": [
                "i2b2 2010 assertion dataset",
                "local Sleep dataset from UPMC"
            ],
            "base_models": [
                "LLaMA2-7B",
                "ChatGPT 3.5 turbo"
            ]
        }
    },
    "Exploration of LLM Multi-Agent Application Implementation Based on LangGraphCrewAI": {
        "filename": "Exploration of LLM Multi-Agent Application Implementation Based on LangGraphCrewAI.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "Cue-CoT Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs": {
        "filename": "Cue-CoT Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Zhihu",
                "D4",
                "PsyQA",
                "Quora",
                "ED",
                "EMH"
            ],
            "base_models": [
                "ChatGPT",
                "ChatGLM-6B",
                "BELLE-LLAMA-7B-2M",
                "Alpaca-7B",
                "Vicuna-7B-v1.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Small Language Models are Equation Reasoners": {
        "filename": "Small Language Models are Equation Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "T5-Base (220M)",
                "T5-Small (60M)",
                "T5-Mini (31M)",
                "T5-Tiny (16M)"
            ]
        }
    },
    "Understanding Reasoning in Chain-of-Thought from the Hopfieldian View": {
        "filename": "Understanding Reasoning in Chain-of-Thought from the Hopfieldian View.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "StrategyQA",
                "CommonsenseQA",
                "Coin Flip",
                "Random Letter"
            ],
            "base_models": [
                "Llama-2-7B-Chat",
                "Llama-3-8B-Instruct",
                "Llama-2-13B-Chat",
                "Llama-2-70B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MMMU-Pro A More Robust Multi-discipline Multimodal Understanding Benchmark": {
        "filename": "MMMU-Pro A More Robust Multi-discipline Multimodal Understanding Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "MMMU-Pro"
            ],
            "base_models": [
                "GPT-4o (0513)",
                "Claude 3.5 Sonnet",
                "Gemini 1.5 Pro (0801)",
                "Qwen2-VL-72B",
                "InternVL2-Llama3-76B",
                "GPT-4o mini",
                "InternVL2-40B",
                "LLaVA-OneVision-72B",
                "Qwen2-VL-7B",
                "InternVL2-8B",
                "MiniCPM-V 2.6",
                "VILA-1.5-40B",
                "LLaVA-NEXT-72B",
                "LLaVA-OneVision-7B",
                "LLaVA-NeXT-34B",
                "Idefics3-8B-Llama3",
                "Phi-3.5-Vision",
                "LLaVA-NeXT-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models as Generalizable Policies for Embodied Tasks": {
        "filename": "Large Language Models as Generalizable Policies for Embodied Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Language Rearrangement"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "Flan-T5",
                "ChatGPT",
                "LLaMA-65B",
                "IDEFICS-80B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OPT-IML Scaling Language Model Instruction Meta Learning through the Lens of Generalization": {
        "filename": "OPT-IML Scaling Language Model Instruction Meta Learning through the Lens of Generalization.pdf",
        "analysis": {
            "benchmarks": [
                "PromptSource",
                "FLAN",
                "Super-NaturalInstructions",
                "UnifiedSKG"
            ],
            "base_models": [
                "OPT-30B",
                "OPT-175B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Holistic Reasoning with Long-Context LMs A Benchmark for Database Operations on Massive Textual Data": {
        "filename": "Holistic Reasoning with Long-Context LMs A Benchmark for Database Operations on Massive Textual Data.pdf",
        "analysis": {
            "benchmarks": [
                "Needle-in-a-haystack",
                "Multi Needles-in-a-haystack",
                "En.QA/En.MC",
                "BABILONG",
                "NOCHA",
                "FLENQA",
                "HOLOBENCH"
            ],
            "base_models": [
                "Llama-3.1-8B",
                "Llama-3.1-70B",
                "Llama-3.1-405B",
                "GPT-4o-mini",
                "GPT-4o",
                "o1-mini",
                "Claude 3.5 Sonnet",
                "Gemini 1.5 Flash",
                "Gemini 1.5 Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "IllusionVQA A Challenging Optical Illusion Dataset for Vision Language Models": {
        "filename": "IllusionVQA A Challenging Optical Illusion Dataset for Vision Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "IllusionVQA",
                "GVIL",
                "HallusionBench"
            ],
            "base_models": [
                "GPT4V",
                "Gemini-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Eva-KELLM A New Benchmark for Evaluating Knowledge Editing of LLMs": {
        "filename": "Eva-KELLM A New Benchmark for Evaluating Knowledge Editing of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "FEVER",
                "zsRE",
                "COUNTERFACT",
                "Eva-KELLM"
            ],
            "base_models": [
                "BLOOM-3B",
                "BLOOM-7.1B"
            ]
        }
    },
    "HOP UNION GENERATE Explainable Multi-hop Reasoning without Rationale Supervision": {
        "filename": "HOP UNION GENERATE Explainable Multi-hop Reasoning without Rationale Supervision.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "MuSiQue",
                "FEVER",
                "MultiRC"
            ],
            "base_models": [
                "distilBERT",
                "BART-base",
                "RoBERTa-large",
                "BART-large"
            ]
        }
    },
    "Sparse Attention Vectors Generative Multimodal Model Features Are Discriminative Vision-Language Classifiers": {
        "filename": "Sparse Attention Vectors Generative Multimodal Model Features Are Discriminative Vision-Language Classifiers.pdf",
        "analysis": {
            "benchmarks": [
                "BLINK",
                "VLGuard",
                "NaturalBench",
                "EuroSAT",
                "Oxford-IIIT-Pets",
                "MHaluBench"
            ],
            "base_models": [
                "LLaVA-OneVision-7B",
                "Qwen2-VL-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Teach LLMs to Personalize - An Approach inspired by Writing Education": {
        "filename": "Teach LLMs to Personalize - An Approach inspired by Writing Education.pdf",
        "analysis": {
            "benchmarks": [
                "Avocado Research Email Collection",
                "Amazon review data (books category)",
                "Reddit comments dataset"
            ],
            "base_models": [
                "T5-11B",
                "PaLM 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MetRex A Benchmark for Verilog Code Metric Reasoning Using LLMs": {
        "filename": "MetRex A Benchmark for Verilog Code Metric Reasoning Using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MetRex"
            ],
            "base_models": [
                "Mixtral-8x7b",
                "Llama3-8b"
            ]
        }
    },
    "Faithful Reasoning Using Large Language Models": {
        "filename": "Faithful Reasoning Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ProofWriter",
                "EntailmentBankQA"
            ],
            "base_models": [
                "Chinchilla-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-Stage Pre-training Enhanced by ChatGPT for Multi-Scenario Multi-Domain Dialogue Summarization": {
        "filename": "Multi-Stage Pre-training Enhanced by ChatGPT for Multi-Scenario Multi-Domain Dialogue Summarization.pdf",
        "analysis": {
            "benchmarks": [
                "SAMSum",
                "DIALOG SUM",
                "TWEETSUMM"
            ],
            "base_models": [
                "BART-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Label Supervised LLaMA Finetuning": {
        "filename": "Label Supervised LLaMA Finetuning.pdf",
        "analysis": {
            "benchmarks": [
                "SST2",
                "SST5",
                "AGNews",
                "Twitter Financial News",
                "Multilingual Amazon Reviews Corpus",
                "OntoNotes V5.0",
                "CoNLL2003"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "BERT-Base",
                "BERT-Large",
                "RoBERTa-Base",
                "RoBERTa-Large",
                "GPT-3 (175B)",
                "GPT-3.5-Turbo (154B)"
            ]
        }
    },
    "Large Language Models as Surrogate Models in Evolutionary Algorithms A Preliminary Study": {
        "filename": "Large Language Models as Surrogate Models in Evolutionary Algorithms A Preliminary Study.pdf",
        "analysis": {
            "benchmarks": [
                "Ellipsoid",
                "Rosenbrock",
                "Ackley",
                "Griewank"
            ],
            "base_models": [
                "Llama3-8B (8B)",
                "Mixtral-8x7B (56B)",
                "Mistral-7B (7B)",
                "Phi-2 (2.7B)",
                "Phi-3 (3.8B)",
                "Gemma-7B (7B)",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WavCraft Audio Editing and Generation with Large Language Models": {
        "filename": "WavCraft Audio Editing and Generation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AudioCaps"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual Chain of Thought Bridging Logical Gaps with Multimodal Infillings": {
        "filename": "Visual Chain of Thought Bridging Logical Gaps with Multimodal Infillings.pdf",
        "analysis": {
            "benchmarks": [
                "VIST",
                "WIKIHOW"
            ],
            "base_models": [
                "GPT-3.5",
                "STABLE DIFFUSION",
                "CLIP"
            ]
        }
    },
    "IMProv Inpainting-based Multimodal Prompting for Computer Vision Tasks": {
        "filename": "IMProv Inpainting-based Multimodal Prompting for Computer Vision Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Pascal-5i",
                "Pascal VOC 2012"
            ],
            "base_models": [
                "ViT-L",
                "VQGAN"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FireAct Toward Language Agent Fine-tuning": {
        "filename": "FireAct Toward Language Agent Fine-tuning.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "Bamboogle",
                "StrategyQA",
                "MMLU"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama-2-7B",
                "Llama-2-13B",
                "CodeLlama-7B",
                "CodeLlama-13B",
                "CodeLlama-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Agent Q Advanced Reasoning and Learning for Autonomous AI Agents": {
        "filename": "Agent Q Advanced Reasoning and Learning for Autonomous AI Agents.pdf",
        "analysis": {
            "benchmarks": [
                "WebShop",
                "OpenTable"
            ],
            "base_models": [
                "LLaMA-3 70B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Text2Motion from natural language instructions to feasible plans": {
        "filename": "Text2Motion from natural language instructions to feasible plans.pdf",
        "analysis": {
            "benchmarks": [
                "TableEnv Manipulation task suite"
            ],
            "base_models": [
                "text-davinci-003",
                "code-davinci-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Show Me How Its Done The Role of Explanations in Fine-Tuning Language Models": {
        "filename": "Show Me How Its Done The Role of Explanations in Fine-Tuning Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ListOps",
                "Explained-ListOps-30"
            ],
            "base_models": [
                "T5-small (60M)",
                "T5-base (220M)",
                "T5-large (770M)",
                "T5-3B (2.7B)"
            ]
        }
    },
    "Leveraging Large Language Models in Conversational Recommender Systems": {
        "filename": "Leveraging Large Language Models in Conversational Recommender Systems.pdf",
        "analysis": {
            "benchmarks": [
                "YouTube video corpus"
            ],
            "base_models": [
                "LaMDA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fine-Tuned Large Language Model for Visualization System A Study on Self-Regulated Learning in Education": {
        "filename": "Fine-Tuned Large Language Model for Visualization System A Study on Self-Regulated Learning in Education.pdf",
        "analysis": {
            "benchmarks": [
                "Custom AI education test dataset"
            ],
            "base_models": [
                "Baichuan2-7B-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Quartet Logic A Four-Step Reasoning QLFR framework for advancing Short Text Classification": {
        "filename": "Quartet Logic A Four-Step Reasoning QLFR framework for advancing Short Text Classification.pdf",
        "analysis": {
            "benchmarks": [
                "Ohsumed",
                "TagMyNews",
                "MR",
                "Snippets",
                "StackOverflow",
                "AGNews"
            ],
            "base_models": [
                "LLaMA2-13B",
                "Flan-T5-Large",
                "ChatGLM",
                "LLaMA2-7B",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection": {
        "filename": "Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection.pdf",
        "analysis": {
            "benchmarks": [
                "WizardLM",
                "HumanEval",
                "GSM"
            ],
            "base_models": [
                "Alpaca 7B",
                "Alpaca 13B",
                "text-davinci-003",
                "gpt-3.5-turbo-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Revolutionizing Bridge Operation and maintenance with LLM-based Agents An Overview of Applications and Insights": {
        "filename": "Revolutionizing Bridge Operation and maintenance with LLM-based Agents An Overview of Applications and Insights.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Social AI A Survey on Understanding Social Interactions": {
        "filename": "Towards Social AI A Survey on Understanding Social Interactions.pdf",
        "analysis": {
            "benchmarks": [
                "GazeFollow",
                "VideoAttentionTarget"
            ],
            "base_models": [
                "BERT",
                "GPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathChat Converse to Tackle Challenging Math Problems with LLM Agents": {
        "filename": "MathChat Converse to Tackle Challenging Math Problems with LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "MATH dataset"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual-Linguistic Agent Towards Collaborative Contextual Object Reasoning": {
        "filename": "Visual-Linguistic Agent Towards Collaborative Contextual Object Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "COCO"
            ],
            "base_models": [
                "GPT-4o",
                "Claude 3.5 Sonnet",
                "LLaVA",
                "Gemini 1.5"
            ]
        }
    },
    "SpatialPIN Enhancing Spatial Reasoning Capabilities of Vision-Language Models through Prompting and Interacting 3D Priors": {
        "filename": "SpatialPIN Enhancing Spatial Reasoning Capabilities of Vision-Language Models through Prompting and Interacting 3D Priors.pdf",
        "analysis": {
            "benchmarks": [
                "NOCS",
                "RT-1",
                "BridgeData V2",
                "YCBInEOAT",
                "Custom dataset (20 image pairs for Inter-Image Spatial Dynamics VQA)",
                "Custom dataset (38 self-captured photos and 13 scenes from NOCS for task planning)"
            ],
            "base_models": [
                "GPT-4V",
                "GPT-4o",
                "LLaVA-1.5",
                "InstructBLIP",
                "SpatialVLM (PaLM 2-E)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GROVE A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence": {
        "filename": "GROVE A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence.pdf",
        "analysis": {
            "benchmarks": [
                "WritingPrompt dataset",
                "IMDB movie details dataset"
            ],
            "base_models": [
                "ChatGPT",
                "Alpaca-Plus-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "IsoBench Benchmarking Multimodal Foundation Models on Isomorphic Representations": {
        "filename": "IsoBench Benchmarking Multimodal Foundation Models on Isomorphic Representations.pdf",
        "analysis": {
            "benchmarks": [
                "IsoBench"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "Claude-3 Opus",
                "Gemini Pro",
                "PaLM-2",
                "Mixtral-8x7B",
                "LLaMa-2-70B",
                "LLaVa-1.5-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CrashEventLLM Predicting System Crashes with Large Language Models": {
        "filename": "CrashEventLLM Predicting System Crashes with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Intel® Computing Improvement Program (ICIP) system crash logs"
            ],
            "base_models": [
                "Llama2-7B",
                "Llama2-13B"
            ]
        }
    },
    "Exploring Neuron Interactions and Emergence in LLMs From the Multifractal Analysis Perspective": {
        "filename": "Exploring Neuron Interactions and Emergence in LLMs From the Multifractal Analysis Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "Lambada",
                "PIQA",
                "WSC",
                "LogiQA"
            ],
            "base_models": [
                "Pythia 14M",
                "Pythia 160M",
                "Pythia 1.4B",
                "Pythia 2.8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mix-of-Granularity Optimize the Chunking Granularity for Retrieval-Augmented Generation": {
        "filename": "Mix-of-Granularity Optimize the Chunking Granularity for Retrieval-Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU-Med",
                "MedQA-US",
                "MedMCQA",
                "PubMedQA*",
                "BioASQ-Y/N"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-16k)",
                "Llama3 (Meta-Llama-3-8B)",
                "InternLM2 (internlm2-123b)",
                "ChatGLM3 (chatglm3-6b)",
                "Qwen1.5 (Qwen1.5-MoE-A2.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Many Answers Should I Give An Empirical Study of Multi-Answer Reading Comprehension": {
        "filename": "How Many Answers Should I Give An Empirical Study of Multi-Answer Reading Comprehension.pdf",
        "analysis": {
            "benchmarks": [
                "DROP",
                "Quoref",
                "MultiSpanQA"
            ],
            "base_models": [
                "RoBERTa-base",
                "BART-base",
                "BART-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ShowUI One Vision-Language-Action Model for GUI Visual Agent": {
        "filename": "ShowUI One Vision-Language-Action Model for GUI Visual Agent.pdf",
        "analysis": {
            "benchmarks": [
                "Screenspot",
                "Mind2Web",
                "AITW",
                "MiniWob"
            ],
            "base_models": [
                "Qwen2-VL-2B (2B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Restoration Multi-Task Image Restoration Models are Zero-Shot Step-by-Step Universal Image Restorers": {
        "filename": "Chain-of-Restoration Multi-Task Image Restoration Models are Zero-Shot Step-by-Step Universal Image Restorers.pdf",
        "analysis": {
            "benchmarks": [
                "UIRD-12",
                "CDD-11"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning": {
        "filename": "The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "SYNTH",
                "Adversarial HotpotQA (ADVHOTPOT)",
                "E-SNLI"
            ],
            "base_models": [
                "OPT (175B)",
                "GPT-3 (davinci)",
                "InstructGPT (text-davinci-001)",
                "text-davinci-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Algorithmic Collusion by Large Language Models": {
        "filename": "Algorithmic Collusion by Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "repeated Bertrand oligopoly environment",
                "two-bidder first-price auctions"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Identifying and Mitigating Privacy Risks Stemming from Language Models A Survey": {
        "filename": "Identifying and Mitigating Privacy Risks Stemming from Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-III",
                "Common Crawl",
                "WikiText-103",
                "Reddit",
                "The Pile"
            ],
            "base_models": [
                "GPT-2",
                "GPT-3",
                "GPT-Neo",
                "LLaMA-2",
                "BERT",
                "DistilBERT",
                "RoBERTa",
                "T5",
                "BART",
                "GPT-J (6 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How to Design Translation Prompts for ChatGPT An Empirical Study": {
        "filename": "How to Design Translation Prompts for ChatGPT An Empirical Study.pdf",
        "analysis": {
            "benchmarks": [
                "Flores-101",
                "multi-reference test sets (Ott et al., 2018)",
                "WMT 2014 English-French",
                "WMT 2014 English-German",
                "multi-domain test sets (Hendy et al., 2023)"
            ],
            "base_models": [
                "ChatGPT (based on GPT-3.5)"
            ]
        }
    },
    "Quantifying the Plausibility of Context Reliance in Neural Machine Translation": {
        "filename": "Quantifying the Plausibility of Context Reliance in Neural Machine Translation.pdf",
        "analysis": {
            "benchmarks": [
                "SCAT+",
                "DISCEVAL-MT"
            ],
            "base_models": [
                "OpusMT (Transformer base)",
                "mBART-50"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generative Social Choice": {
        "filename": "Generative Social Choice.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of US residents' opinions on chatbot personalization"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Toward General-Purpose Robots via Foundation Models A Survey and Meta-Analysis": {
        "filename": "Toward General-Purpose Robots via Foundation Models A Survey and Meta-Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "Open-X Embodiment Dataset",
                "RT-1 Robot Action dataset"
            ],
            "base_models": [
                "GPT-3",
                "CLIP",
                "SAM",
                "Gato",
                "PaLM-E"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Human Days to Machine Seconds Automatically Answering and Generating Machine Learning Final Exams": {
        "filename": "From Human Days to Machine Seconds Automatically Answering and Generating Machine Learning Final Exams.pdf",
        "analysis": {
            "benchmarks": [
                "MIT Introduction to Machine Learning final exams",
                "Cornell Introduction to Machine Learning final exams",
                "Harvard Machine Learning final exams"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT",
                "Codex",
                "OPT-175B"
            ]
        }
    },
    "Efficient Contextual LLM Cascades through Budget-Constrained Policy Learning": {
        "filename": "Efficient Contextual LLM Cascades through Budget-Constrained Policy Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "CSQA",
                "LLC"
            ],
            "base_models": [
                "Llama-2-7b-chat",
                "Llama-2-13b-chat",
                "GPT-3.5-turbo",
                "GPT-4",
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards AGI in Computer Vision Lessons Learned from GPT and Large Language Models": {
        "filename": "Towards AGI in Computer Vision Lessons Learned from GPT and Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assertion Enhanced Few-Shot Learning Instructive Technique for Large Language Models to Generate Educational Explanations": {
        "filename": "Assertion Enhanced Few-Shot Learning Instructive Technique for Large Language Models to Generate Educational Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "cti_study_2022 dataset"
            ],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Navigating the Safety Landscape Measuring Risks in Finetuning Large Language Models": {
        "filename": "Navigating the Safety Landscape Measuring Risks in Finetuning Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench 'Harmful Behaviors' split"
            ],
            "base_models": [
                "LLaMA2-7B-chat",
                "LLaMA3-8B-instruct",
                "Mistral-7B-instruct-v0.2",
                "Vicuna-7B-v1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TESTEVAL Benchmarking Large Language Models for Test Case Generation": {
        "filename": "TESTEVAL Benchmarking Large Language Models for Test Case Generation.pdf",
        "analysis": {
            "benchmarks": [
                "TESTEVAL"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4-turbo",
                "GPT-4o",
                "Gemini-1.0-pro",
                "CodeLlama-7b",
                "CodeLlama-13b",
                "CodeLlama-34b",
                "Llama3-8b",
                "Gemma-7b",
                "Starcoder-2-Instruct-15b",
                "DeepSeek-coder-1.3b",
                "DeepSeek-coder-6.7b",
                "DeepSeek-coder-33b",
                "CodeQwen-7b",
                "Mistral-0.3-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MutaPLM Protein Language Modeling for Mutation Explanation and Engineering": {
        "filename": "MutaPLM Protein Language Modeling for Mutation Explanation and Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "MutaDescribe"
            ],
            "base_models": [
                "ESM-2 (650M)",
                "BioMedGPT-LM (based on LLaMA2-7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assessing Code Generation with Intermediate Languages": {
        "filename": "Assessing Code Generation with Intermediate Languages.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval-X"
            ],
            "base_models": [
                "CodeLlama-7b-instruct",
                "CodeLlama-13b-instruct",
                "CodeLlama-34b-instruct",
                "CodeLlama-70b-instruct",
                "GPT-3.5",
                "GPT-4",
                "Mistral-7b",
                "Mixtral-8x7b",
                "Deepseek-coder-1.3b-instruct",
                "Stable-code-instruct-3b",
                "Phi-3-mini-128k-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MASAI Modular Architecture for Software-engineering AI Agents": {
        "filename": "MASAI Modular Architecture for Software-engineering AI Agents.pdf",
        "analysis": {
            "benchmarks": [
                "SWE-bench Lite"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "Large Language Models for Medical OSCE Assessment A Novel Approach to Transcript Analysis": {
        "filename": "Large Language Models for Medical OSCE Assessment A Novel Approach to Transcript Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "UT Southwestern Medical Center OSCE dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4o",
                "GPT-3.5",
                "Claude-Opus",
                "Claude-Sonnet-3-5",
                "Llama-3-70B",
                "Llama-3-8B",
                "Mixtral 8x7B",
                "Starling-7B-beta"
            ]
        }
    },
    "Non-Autoregressive Sentence Ordering": {
        "filename": "Non-Autoregressive Sentence Ordering.pdf",
        "analysis": {
            "benchmarks": [
                "SIND",
                "NIPS",
                "AAN",
                "NSF",
                "arXiv",
                "ROCStory"
            ],
            "base_models": [
                "BERT-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Has Multimodal Learning Delivered Universal Intelligence in Healthcare A Comprehensive Survey": {
        "filename": "Has Multimodal Learning Delivered Universal Intelligence in Healthcare A Comprehensive Survey.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-CXR",
                "PathCap"
            ],
            "base_models": [
                "CLIP",
                "ChatGPT",
                "GPT-4",
                "BioClinicalBERT",
                "PubMedBERT",
                "CXR-BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models Serve as Evaluators for Code Summarization": {
        "filename": "Can Large Language Models Serve as Evaluators for Code Summarization.pdf",
        "analysis": {
            "benchmarks": [
                "TL-CodeSum"
            ],
            "base_models": [
                "text-davinci-003",
                "gpt-3.5-turbo",
                "gpt-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Safeguarding Large Language Models A Survey": {
        "filename": "Safeguarding Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT-3",
                "ChatGPT-4",
                "LLaMA",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hexa Self-Improving for Knowledge-Grounded Dialogue System": {
        "filename": "Hexa Self-Improving for Knowledge-Grounded Dialogue System.pdf",
        "analysis": {
            "benchmarks": [
                "MS Marco",
                "TriviaQA",
                "Wizard of Wikipedia (WoW)",
                "Wizard of Internet (WoI)",
                "Feedback on Interactive Talk & Search (FITS)",
                "GoogleSGD",
                "PersonaChat",
                "Multi-Session Chat",
                "Funpedia",
                "Empathetic Dialogues (ED)",
                "Taskmaster",
                "OpenDialKG"
            ],
            "base_models": [
                "Blender-Bot3 (3B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Visual Reasoning with Autonomous Imagination in Multimodal Large Language Models": {
        "filename": "Enhancing Visual Reasoning with Autonomous Imagination in Multimodal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Intuitive Visual Reasoning Benchmark (IVRB)",
                "ROPE Benchmark"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Llemma An Open Language Model For Mathematics": {
        "filename": "Llemma An Open Language Model For Mathematics.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8k"
            ],
            "base_models": [
                "Code Llama (7B and 34B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SelECT-SQL Self-correcting ensemble Chain-of-Thought for Text-to-SQL": {
        "filename": "SelECT-SQL Self-correcting ensemble Chain-of-Thought for Text-to-SQL.pdf",
        "analysis": {
            "benchmarks": [
                "Spider"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4"
            ]
        }
    },
    "FM2DS Few-Shot Multimodal Multihop Data Synthesis with Knowledge Distillation for Question Answering": {
        "filename": "FM2DS Few-Shot Multimodal Multihop Data Synthesis with Knowledge Distillation for Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "MultiModalQA",
                "WebQA",
                "M2QA-Bench"
            ],
            "base_models": [
                "GPT-4-turbo",
                "LLaVa-1.6-7B",
                "LLaVa-1.6-13B",
                "InternVL-2-8B",
                "InternVL-2-26B",
                "Idefics-2-8B",
                "Llama-3.2-90B",
                "Claude-3.5-Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Question Decomposition Improves the Faithfulness of Model-Generated Reasoning": {
        "filename": "Question Decomposition Improves the Faithfulness of Model-Generated Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "StrategyQA",
                "OpenBookQA",
                "TruthfulQA"
            ],
            "base_models": [
                "Claude 1.3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Choices are More Important than Efforts LLM Enables Efficient Multi-Agent Exploration": {
        "filename": "Choices are More Important than Efforts LLM Enables Efficient Multi-Agent Exploration.pdf",
        "analysis": {
            "benchmarks": [
                "SMAC",
                "MPE"
            ],
            "base_models": [
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SmartGSN a generative AI-powered online tool for the management of assurance cases": {
        "filename": "SmartGSN a generative AI-powered online tool for the management of assurance cases.pdf",
        "analysis": {
            "benchmarks": [
                "ACAS XU",
                "BLUEROV2",
                "GPCA",
                "IM Software",
                "DEEPMIND"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4 Turbo"
            ]
        }
    },
    "Recommendation as Instruction Following A Large Language Model Empowered Recommendation Approach": {
        "filename": "Recommendation as Instruction Following A Large Language Model Empowered Recommendation Approach.pdf",
        "analysis": {
            "benchmarks": [
                "Video Games subset of Amazon",
                "CDs & Vinyl subset of Amazon"
            ],
            "base_models": [
                "Flan-T5-XL (3B)",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Robot Learning in the Era of Foundation Models A Survey": {
        "filename": "Robot Learning in the Era of Foundation Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "ActivityPrograms knowledge base",
                "maniskill2 benchmark"
            ],
            "base_models": [
                "PaLM-E",
                "CLIP",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Examining the Emergence of Deductive Reasoning in Generative Language Models": {
        "filename": "Examining the Emergence of Deductive Reasoning in Generative Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "RuleTakers",
                "NatLang",
                "Birds-Electricity"
            ],
            "base_models": [
                "GPT-1",
                "GPT-2 small (124mn)",
                "GPT-2 medium (355mn)",
                "GPT-2 large (774mn)",
                "GPT-2 XL (1.5bn)",
                "Bloom 560m",
                "Bloom 1b1",
                "Bloom 3b",
                "Bloom 7b1",
                "OPT 30b",
                "OPT 66b",
                "GPT-3 Ada",
                "GPT-3 Babbage",
                "GPT-3 Curie",
                "GPT-3.5 da Vinci"
            ]
        }
    },
    "The FormAI Dataset Generative AI in Software Security through the Lens of Formal Verification": {
        "filename": "The FormAI Dataset Generative AI in Software Security through the Lens of Formal Verification.pdf",
        "analysis": {
            "benchmarks": [
                "FormAI dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MURMUR Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation": {
        "filename": "MURMUR Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation.pdf",
        "analysis": {
            "benchmarks": [
                "WebNLG",
                "LogicNLG"
            ],
            "base_models": [
                "GPT-2",
                "OPT-175B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Grounding-Prompter Prompting LLM with Multimodal Information for Temporal Sentence Grounding in Long Videos": {
        "filename": "Grounding-Prompter Prompting LLM with Multimodal Information for Temporal Sentence Grounding in Long Videos.pdf",
        "analysis": {
            "benchmarks": [
                "VidChapters-mini"
            ],
            "base_models": [
                "GPT-3.5-turbo-16k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bad Actor Good Advisor Exploring the Role of Large Language Models in Fake News Detection": {
        "filename": "Bad Actor Good Advisor Exploring the Role of Large Language Models in Fake News Detection.pdf",
        "analysis": {
            "benchmarks": [
                "Weibo21",
                "GossipCop"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "BERT-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Global-Local Collaborative Inference with LLM for Lidar-Based Open-Vocabulary Detection": {
        "filename": "Global-Local Collaborative Inference with LLM for Lidar-Based Open-Vocabulary Detection.pdf",
        "analysis": {
            "benchmarks": [
                "ScanNetV2",
                "SUN RGB-D"
            ],
            "base_models": [
                "LLaMA (vicuna-7b-v1.5-16k)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "System-Level Natural Language Feedback": {
        "filename": "System-Level Natural Language Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "FITS dataset"
            ],
            "base_models": [
                "Blenderbot2 (400M)",
                "GPT-3.5",
                "FLAN-T5 (large)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Teaching VLMs to Localize Specific Objects from In-context Examples": {
        "filename": "Teaching VLMs to Localize Specific Objects from In-context Examples.pdf",
        "analysis": {
            "benchmarks": [
                "PDM",
                "PerSeg",
                "LASOT"
            ],
            "base_models": [
                "Qwen2-VL-7B",
                "Idefics-3",
                "LLaVA One Vision"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unstructured and structured data Can we have the best of both worlds with large language models": {
        "filename": "Unstructured and structured data Can we have the best of both worlds with large language models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "text-davinci-003"
            ]
        }
    },
    "A Novel Multi-Stage Prompting Approach for Language Agnostic MCQ Generation using GPT": {
        "filename": "A Novel Multi-Stage Prompting Approach for Language Agnostic MCQ Generation using GPT.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "GermanQuAD",
                "HiQuAD",
                "BanglaRQA"
            ],
            "base_models": [
                "text-davinci-003",
                "GPT-4"
            ]
        }
    },
    "Comparing Large Language Models and Human Programmers for Generating Programming Code": {
        "filename": "Comparing Large Language Models and Human Programmers for Generating Programming Code.pdf",
        "analysis": {
            "benchmarks": [
                "LeetCode",
                "GeeksforGeeks"
            ],
            "base_models": [
                "GPT-4",
                "Gemini Ultra",
                "Claude 2",
                "GPT-3.5",
                "Llama 2",
                "Code Llama"
            ]
        }
    },
    "SG-Bench Evaluating LLM Safety Generalization Across Diverse Tasks and Prompt Types": {
        "filename": "SG-Bench Evaluating LLM Safety Generalization Across Diverse Tasks and Prompt Types.pdf",
        "analysis": {
            "benchmarks": [
                "SG-Bench"
            ],
            "base_models": [
                "ChatGPT",
                "Claude",
                "LLAMA series",
                "GPT-4",
                "Mistral-7B-Instruct",
                "LLAMA2-13B-Chat",
                "LLAMA2-7B-Chat",
                "Qwen2-7B-Instruct",
                "Qwen1.5-14B-Chat",
                "Qwen1.5-7B-Chat",
                "ChatGLM3-6B",
                "InternLM2-7B-Chat",
                "Qwen-7B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DetToolChain A New Prompting Paradigm to Unleash Detection Ability of MLLM": {
        "filename": "DetToolChain A New Prompting Paradigm to Unleash Detection Ability of MLLM.pdf",
        "analysis": {
            "benchmarks": [
                "MS COCO Novel class set",
                "RefCOCO val set",
                "D-cube describe object detection FULL setting",
                "MS COCO 2017 dataset",
                "HRSC2016 dataset",
                "RefCOCO",
                "RefCOCO+",
                "RefCOCOg"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLMs Effectively Leverage Graph Structural Information through Prompts and Why": {
        "filename": "Can LLMs Effectively Leverage Graph Structural Information through Prompts and Why.pdf",
        "analysis": {
            "benchmarks": [
                "ogbn-arxiv",
                "arxiv-2023",
                "cora",
                "pubmed",
                "ogbn-product"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0613)",
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multimodal LLM Guided Exploration and Active Mapping using Fisher Information": {
        "filename": "Multimodal LLM Guided Exploration and Active Mapping using Fisher Information.pdf",
        "analysis": {
            "benchmarks": [
                "Gibson",
                "Habitat-Matterport 3D"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Requirements Satisfiability with In-Context Learning": {
        "filename": "Requirements Satisfiability with In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "SNLI",
                "MultiNLI"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring the Landscape of Natural Language Processing Research": {
        "filename": "Exploring the Landscape of Natural Language Processing Research.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LaMMA-P Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner": {
        "filename": "LaMMA-P Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner.pdf",
        "analysis": {
            "benchmarks": [
                "MAT-THOR"
            ],
            "base_models": [
                "GPT-4o",
                "Llama-3.1-8B",
                "Llama-2-13B"
            ]
        }
    },
    "The pitfalls of next-token prediction": {
        "filename": "The pitfalls of next-token prediction.pdf",
        "analysis": {
            "benchmarks": [
                "custom path-finding task on path-star graphs"
            ],
            "base_models": [
                "Transformer",
                "Mamba"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generalising sequence models for epigenome predictions with tissue and assay embeddings": {
        "filename": "Generalising sequence models for epigenome predictions with tissue and assay embeddings.pdf",
        "analysis": {
            "benchmarks": [
                "ENTEx"
            ],
            "base_models": [
                "Enformer"
            ]
        }
    },
    "xLAM A Family of Large Action Models to Empower AI Agent Systems": {
        "filename": "xLAM A Family of Large Action Models to Empower AI Agent Systems.pdf",
        "analysis": {
            "benchmarks": [
                "Berkeley Function-Calling Leaderboard",
                "Webshop",
                "ToolQuery",
                "ToolBench"
            ],
            "base_models": [
                "DeepSeek-Coder-1b (1.35B)",
                "DeepSeek-Coder-7b (6.91B)",
                "Mistral-7b (7.24B)",
                "Mistral-8x7b (46.7B)",
                "Mistral-8x22b (141B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning In-context Learning for Named Entity Recognition": {
        "filename": "Learning In-context Learning for Named Entity Recognition.pdf",
        "analysis": {
            "benchmarks": [
                "CoNLL03",
                "WNUT17",
                "NCBI-disease",
                "SEC-filings"
            ],
            "base_models": [
                "T5-v1.1-large (770M)",
                "GPT2-xl (1.5B)",
                "T5-xl (3B)",
                "GPT-J-6B (6B)",
                "T5-xxl (11B)",
                "OPT-13B (13B)",
                "GPT-Neox-20B (20B)",
                "OPT-30B (30B)",
                "OPT-66B (66B)",
                "BERT-Large (345M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FIRE Food Image to REcipe generation": {
        "filename": "FIRE Food Image to REcipe generation.pdf",
        "analysis": {
            "benchmarks": [
                "Recipe1M"
            ],
            "base_models": [
                "BLIP",
                "Vision Transformer",
                "T5 (220M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automatic Robotic Development through Collaborative Framework by Large Language Models": {
        "filename": "Automatic Robotic Development through Collaborative Framework by Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "quadruped robot based on ROS"
            ],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "Explainability for Large Language Models A Survey": {
        "filename": "Explainability for Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "MNLI",
                "QQP",
                "GLUE"
            ],
            "base_models": [
                "BERT",
                "GPT-3",
                "GPT-4",
                "LLaMA-2",
                "Claude"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interactive Data Synthesis for Systematic Vision Adaptation via LLMs-AIGCs Collaboration": {
        "filename": "Interactive Data Synthesis for Systematic Vision Adaptation via LLMs-AIGCs Collaboration.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "Stable Diffusion v1.5"
            ]
        }
    },
    "LaMPP Language Models as Probabilistic Priors for Perception and Action": {
        "filename": "LaMPP Language Models as Probabilistic Priors for Perception and Action.pdf",
        "analysis": {
            "benchmarks": [
                "SUN RGB-D",
                "CrossTask"
            ],
            "base_models": [
                "GPT-3",
                "RedNet (ResNet-50-based)"
            ]
        }
    },
    "AgentFL Scaling LLM-based Fault Localization to Project-Level Context": {
        "filename": "AgentFL Scaling LLM-based Fault Localization to Project-Level Context.pdf",
        "analysis": {
            "benchmarks": [
                "Defects4J-V1.2.0",
                "Defects4J-V2.0.0"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-16k-0613)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Understanding What Code Language Models Learned": {
        "filename": "Towards Understanding What Code Language Models Learned.pdf",
        "analysis": {
            "benchmarks": [
                "CodeSearchNet"
            ],
            "base_models": [
                "BERT",
                "GPT-3",
                "PaLM",
                "CodeBERT",
                "GraphCodeBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EvoAgent Towards Automatic Multi-Agent Generation via Evolutionary Algorithms": {
        "filename": "EvoAgent Towards Automatic Multi-Agent Generation via Evolutionary Algorithms.pdf",
        "analysis": {
            "benchmarks": [
                "Logic Grid Puzzle",
                "Trivia Creative Writing",
                "Codenames Collaborative",
                "MMMU",
                "ScienceWorld",
                "TravelPlanner"
            ],
            "base_models": [
                "LLama2-13B-Chat",
                "GPT-3.5",
                "GPT-4",
                "Gemini-Pro",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AgentSquare Automatic LLM Agent Search in Modular Design Space": {
        "filename": "AgentSquare Automatic LLM Agent Search in Modular Design Space.pdf",
        "analysis": {
            "benchmarks": [
                "Webshop",
                "ALFWorld",
                "SciWorld",
                "M3Tool",
                "TravelPlanner",
                "PDDL"
            ],
            "base_models": [
                "GPT-3.5-turbo-0125",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Label Words are Anchors An Information Flow Perspective for Understanding In-Context Learning": {
        "filename": "Label Words are Anchors An Information Flow Perspective for Understanding In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [],
            "models": [],
            "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
        }
    },
    "Generating Probabilistic Scenario Programs from Natural Language": {
        "filename": "Generating Probabilistic Scenario Programs from Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "California DMV Crash Reports"
            ],
            "base_models": [
                "GPT-3.5-turbo-instruct",
                "GPT-4 Vision",
                "LLaVA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Advancing Bug Detection in Fastjson2 with Large Language Models Driven Unit Test Generation": {
        "filename": "Advancing Bug Detection in Fastjson2 with Large Language Models Driven Unit Test Generation.pdf",
        "analysis": {
            "benchmarks": [
                "fastjson2"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "Llama3-8b",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models in the Workplace A Case Study on Prompt Engineering for Job Type Classification": {
        "filename": "Large Language Models in the Workplace A Case Study on Prompt Engineering for Job Type Classification.pdf",
        "analysis": {
            "benchmarks": [
                "Custom Graduate Job Classification Dataset"
            ],
            "base_models": [
                "DeBERTa-V3-Base",
                "GPT-3.5 (text-davinci-003)",
                "GPT-3.5-turbo"
            ]
        }
    },
    "MACM Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems": {
        "filename": "MACM Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems.pdf",
        "analysis": {
            "benchmarks": [
                "MATH dataset",
                "24-point game",
                "number sequence sorting"
            ],
            "base_models": [
                "GPT-4 Turbo",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Good are Commercial Large Language Models on African Languages": {
        "filename": "How Good are Commercial Large Language Models on African Languages.pdf",
        "analysis": {
            "benchmarks": [
                "Hedderich et al. (2020) news topic classification dataset (Hausa)",
                "Alabi et al. (2022) news topic classification dataset (Nigerian Pidgin, Malagasay, Somali, isiZulu)",
                "MAFAND-MT machine translation dataset (isiZulu, Yoruba, Nigerian Pidgin, Swahili, Lugala)"
            ],
            "base_models": [
                "ChatGPT (based on Instruct-GPT models)",
                "Cohere multilingual model (based on multilingual embedding model)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tell dont show Declarative facts influence how LLMs generalize": {
        "filename": "Tell dont show Declarative facts influence how LLMs generalize.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset for AI assistant alignment",
                "Custom dataset for demographic prediction",
                "Custom dataset for weather prediction"
            ],
            "base_models": [
                "Llama-2 7B",
                "GPT-3 ada (0.4B)",
                "GPT-3 babbage (1.3B)",
                "GPT-3 curie (6.7B)",
                "GPT-3 davinci (175B)",
                "Llama-2 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning Runtime Behavior of a Program with LLM How Far Are We": {
        "filename": "Reasoning Runtime Behavior of a Program with LLM How Far Are We.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "ClassEval"
            ],
            "base_models": [
                "CodeLlama-7B-Base",
                "CodeLlama-7B-Python",
                "CodeLlama-7B-Instruct",
                "CodeLlama-13B-Instruct",
                "CodeLlama-34B-Instruct",
                "Magicoder-CL-7B",
                "Magicoder-S-CL-7B",
                "StarCoder2-3B",
                "StarCoder2-7B",
                "StarCoder2-15B",
                "GPT-3.5-Turbo",
                "GPT-4-Turbo",
                "Mistral-7B-Instruct",
                "Gemma-7B-It",
                "Gemma-2B-It"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Construction of Hyper-Relational Knowledge Graphs Using Pre-Trained Large Language Models": {
        "filename": "Construction of Hyper-Relational Knowledge Graphs Using Pre-Trained Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HyperRED"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "TRACE A Comprehensive Benchmark for Continual Learning in Large Language Models": {
        "filename": "TRACE A Comprehensive Benchmark for Continual Learning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "FOMC",
                "MeetingBank",
                "C-STANCE",
                "20Minuten",
                "CodeXGLUE (Py150)",
                "NumGLUE"
            ],
            "base_models": [
                "LLaMA-2-7B-Chat",
                "LLaMA-2-13B-Chat",
                "Baichuan 2-7B-Chat",
                "Vicuna-13B-V1.5",
                "Vicuna-7B-V1.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Small Language Models Improve Giants by Rewriting Their Outputs": {
        "filename": "Small Language Models Improve Giants by Rewriting Their Outputs.pdf",
        "analysis": {
            "benchmarks": [
                "CoNLL-14",
                "E2E NLG (cleaned)",
                "XSum",
                "WMT22 En->De"
            ],
            "base_models": [
                "PaLM-62B",
                "PaLM-540B",
                "XGLM-2.9B",
                "T5-base (250M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Large Language Models for the Interpretation of Building Regulations": {
        "filename": "Using Large Language Models for the Interpretation of Building Regulations.pdf",
        "analysis": {
            "benchmarks": [
                "LegalRuleML dataset (New Zealand Building Code)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data": {
        "filename": "Toward a Team of AI-made Scientists for Scientific Discovery from Gene Expression Data.pdf",
        "analysis": {
            "benchmarks": [
                "Genetic Question Exploration (GenQEX) dataset"
            ],
            "base_models": [
                "Large Language Model (LLM)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Schemato -- An LLM for Netlist-to-Schematic Conversion": {
        "filename": "Schemato -- An LLM for Netlist-to-Schematic Conversion.pdf",
        "analysis": {
            "benchmarks": [
                "LTSpice schematics from GitHub",
                "LTSpice circuit files packaged with LTSpice XVII"
            ],
            "base_models": [
                "Llama-3.1-8B",
                "GPT-4o"
            ]
        }
    },
    "Inference Scaling fLaws The Limits of LLM Resampling with Imperfect Verifiers": {
        "filename": "Inference Scaling fLaws The Limits of LLM Resampling with Imperfect Verifiers.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval+",
                "MBPP+"
            ],
            "base_models": [
                "GPT-4o",
                "Llama 3.1 family"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mechanism Design for Large Language Models": {
        "filename": "Mechanism Design for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (Brown et al., 2020)",
                "PaLM (Google et al., 2023)",
                "LaMDA (Thoppilan et al., 2022)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models to Enhance Bayesian Optimization": {
        "filename": "Large Language Models to Enhance Bayesian Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "Bayesmark",
                "HPOBench"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting with Pseudo-Code Instructions": {
        "filename": "Prompting with Pseudo-Code Instructions.pdf",
        "analysis": {
            "benchmarks": [
                "Super-NaturalInstructions dataset",
                "SQuAD1.1",
                "MultiRC",
                "McTaco",
                "TWEETQA",
                "ATOMIC",
                "SPOLIN",
                "CoLA",
                "DailyDialog",
                "SemEval2018-Task3",
                "SentEval",
                "CODA-19",
                "The Multilingual Amazon Reviews Corpus",
                "Sentiment140",
                "SST-2",
                "PerSenT",
                "Amazon Review Polarity",
                "PEC",
                "Poem Sentiment",
                "MultiNLI",
                "DDO",
                "SemEval-2020 Task 7",
                "Scruples",
                "AFS",
                "PAWS",
                "SNLI",
                "e-SNLI",
                "Defeasible-NLI",
                "CAD",
                "Jigsaw",
                "Hate Speech Offensive",
                "ROPES",
                "Odd-Man-Out",
                "Synthetic",
                "MCScript",
                "PICO",
                "MWSC",
                "OPUS",
                "CoQA",
                "Quoref",
                "PIQA",
                "BREAK",
                "Natural Questions",
                "AmbigQA",
                "TriviaQA",
                "Essential",
                "QuaRel",
                "WinoGrande",
                "ReCoRD",
                "MMMLU",
                "CoNaLa",
                "Youtube Caption Corrections",
                "aNLI",
                "ASSET",
                "ROCStories",
                "ZEST",
                "PARANMT-50M",
                "CosmosQA",
                "StrategyQA",
                "SQuAD2.0",
                "BoolQ",
                "QA-ZRE",
                "QASC",
                "StoryCloze",
                "Country Barcode Prefix dataset",
                "Country Region in World dataset",
                "Gigaword",
                "GAP",
                "XL-WiC"
            ],
            "base_models": [
                "BLOOM-3B",
                "BLOOM-7B",
                "CodeGen-mono 2B",
                "CodeGen-mono 6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assessing and Enhancing the Robustness of Large Language Models with Task Structure Variations for Logical Reasoning": {
        "filename": "Assessing and Enhancing the Robustness of Large Language Models with Task Structure Variations for Logical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ReClor-plus",
                "LogiQA-plus",
                "LogiQAv2-plus"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA (7B to 65B)",
                "Alpaca",
                "Vicuna"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Knowledge-Free Network Management Feasibility Study and Opportunities": {
        "filename": "Large Language Models for Knowledge-Free Network Management Feasibility Study and Opportunities.pdf",
        "analysis": {
            "benchmarks": [
                "Wireless resource allocation tasks in multi-user networks"
            ],
            "base_models": [
                "GPT-3.5-Turbo"
            ]
        }
    },
    "Taxonomy of Abstractive Dialogue Summarization Scenarios Approaches and Future Directions": {
        "filename": "Taxonomy of Abstractive Dialogue Summarization Scenarios Approaches and Future Directions.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/DM",
                "XSum",
                "PubMed",
                "arXiv",
                "SAMSum",
                "MultiMOZ",
                "AMI"
            ],
            "base_models": [
                "BART",
                "Pegasus",
                "DialoGPT",
                "Roberta",
                "Pointer Network",
                "HRED"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mission Impossible A Statistical Perspective on Jailbreaking LLMs": {
        "filename": "Mission Impossible A Statistical Perspective on Jailbreaking LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench",
                "HarmBench",
                "MT-Bench"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval-Enhanced Named Entity Recognition": {
        "filename": "Retrieval-Enhanced Named Entity Recognition.pdf",
        "analysis": {
            "benchmarks": [
                "CrossNER",
                "CoNLL-2003"
            ],
            "base_models": [
                "Gemini (1.5-pro)",
                "GPT-4o (2024-05-13)"
            ]
        }
    },
    "Real-time Animation Generation and Control on Rigged Models via Large Language Models": {
        "filename": "Real-time Animation Generation and Control on Rigged Models via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Mixamo"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Strategic Behavior of Large Language Models Game Structure vs Contextual Framing": {
        "filename": "Strategic Behavior of Large Language Models Game Structure vs Contextual Framing.pdf",
        "analysis": {
            "benchmarks": [
                "Prisoner's Dilemma",
                "Stag Hunt",
                "Snowdrift",
                "Prisoner's Delight"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMa-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Position Foundation Agents as the Paradigm Shift for Decision Making": {
        "filename": "Position Foundation Agents as the Paradigm Shift for Decision Making.pdf",
        "analysis": {
            "benchmarks": [
                "DeepMind Control suite",
                "Atari video play"
            ],
            "base_models": [
                "Transformer",
                "Vision-Language Models"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "German Also Hallucinates Inconsistency Detection in News Summaries with the Absinth Dataset": {
        "filename": "German Also Hallucinates Inconsistency Detection in News Summaries with the Absinth Dataset.pdf",
        "analysis": {
            "benchmarks": [
                "Absinth Dataset",
                "20Minuten test set"
            ],
            "base_models": [
                "GPT-4",
                "Llama 2 (70B)",
                "Llama 2 (7B)",
                "mBERT",
                "XLM-RoBERTa",
                "mBART",
                "mLongT5"
            ]
        }
    },
    "Think-on-Graph 20 Deep and Faithful Large Language Model Reasoning with Knowledge-guided Retrieval Augmented Generation": {
        "filename": "Think-on-Graph 20 Deep and Faithful Large Language Model Reasoning with Knowledge-guided Retrieval Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "WebQSP",
                "QALD10-en",
                "AdvHotpotQA",
                "Zero-Shot RE",
                "FEVER",
                "Creak",
                "ToG-FinQA"
            ],
            "base_models": [
                "GPT-3.5",
                "LLAMA-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Skill Reinforcement Learning and Planning for Open-World Long-Horizon Tasks": {
        "filename": "Skill Reinforcement Learning and Planning for Open-World Long-Horizon Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Minecraft Tech Tree tasks",
                "MineDojo simulator"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring the Capabilities of Prompted Large Language Models in Educational and Assessment Applications": {
        "filename": "Exploring the Capabilities of Prompted Large Language Models in Educational and Assessment Applications.pdf",
        "analysis": {
            "benchmarks": [
                "KHANQ",
                "HotpotQA",
                "SQuAD",
                "Quora Question Pairs",
                "Natural Questions",
                "QuAC",
                "TriviaQA",
                "NewsQA",
                "QG-STEC",
                "EduProbe",
                "EngineeringQ",
                "GermanQuAD",
                "HiQuAD",
                "BanglaRQA",
                "HURIT"
            ],
            "base_models": [
                "BERT",
                "BART",
                "GPT-2",
                "T5",
                "UniLM",
                "PEGASUS",
                "text-davinci-003",
                "GPT-3.5 Turbo",
                "GPT-4",
                "Llama-2-7b",
                "Llama-2-13b",
                "Llama-2-70b"
            ]
        }
    },
    "An Independent Evaluation of ChatGPT on Mathematical Word Problems MWP": {
        "filename": "An Independent Evaluation of ChatGPT on Mathematical Word Problems MWP.pdf",
        "analysis": {
            "benchmarks": [
                "DRAW-1K"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5 series)"
            ]
        }
    },
    "Can Retriever-Augmented Language Models Reason The Blame Game Between the Retriever and the Language Model": {
        "filename": "Can Retriever-Augmented Language Models Reason The Blame Game Between the Retriever and the Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "EntailmentBank",
                "StrategyQA"
            ],
            "base_models": [
                "kNN-LM (~250M)",
                "REALM (~270M)",
                "DPR + FiD (~220M)",
                "Contriever + ATLAS (~250M)",
                "Contriever + Flan-T5 (~250M)",
                "Flan-T5-small (~80M)",
                "Flan-T5-xl (~3B)",
                "Flan-T5-xxl (~11B)",
                "GPT-3.5 (~175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Uncovering Latent Chain of Thought Vectors in Language Models": {
        "filename": "Uncovering Latent Chain of Thought Vectors in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "MMLU",
                "AGI Eval",
                "ARC AI2"
            ],
            "base_models": [
                "Llama3 8b",
                "Mistral 7b v0.2"
            ]
        }
    },
    "Self-Guiding Exploration for Combinatorial Problems": {
        "filename": "Self-Guiding Exploration for Combinatorial Problems.pdf",
        "analysis": {
            "benchmarks": [
                "Assignment Problem",
                "Knapsack Problem",
                "Bin Packing Problem",
                "Traveling Salesman Problem",
                "Vehicle Routing Problem",
                "Job Scheduling Problem",
                "AQUA",
                "GSM8K",
                "SVAMP",
                "ASDiv",
                "StrategyQA",
                "CSQA",
                "ARC",
                "LastLetter"
            ],
            "base_models": [
                "GPT-4",
                "Gemini-1.5",
                "GPT-3.5",
                "Llama-2-70b",
                "Llama-2-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGLM A Family of Large Language Models from GLM-130B to GLM-4 All Tools": {
        "filename": "ChatGLM A Family of Large Language Models from GLM-130B to GLM-4 All Tools.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8K",
                "MATH",
                "BBH",
                "GPQA",
                "HumanEval",
                "AlignBench",
                "LongBench-Chat",
                "NaturalCodeBench",
                "Berkeley Function Call Leaderboard",
                "AgentBench",
                "SafetyBench"
            ],
            "base_models": [
                "GLM-4",
                "GLM-4-Air",
                "GLM-4-9B",
                "ChatGLM-6B",
                "ChatGLM2-6B",
                "ChatGLM3-6B",
                "GLM-130B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AvalonBench Evaluating LLMs Playing the Game of Avalon": {
        "filename": "AvalonBench Evaluating LLMs Playing the Game of Avalon.pdf",
        "analysis": {
            "benchmarks": [
                "AVALON BENCH"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "Llama2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ET-Plan-Bench Embodied Task-level Planning Benchmark Towards Spatial-Temporal Cognition with Foundation Models": {
        "filename": "ET-Plan-Bench Embodied Task-level Planning Benchmark Towards Spatial-Temporal Cognition with Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "ET-Plan-Bench"
            ],
            "base_models": [
                "GPT-4",
                "LLAMA (7B)",
                "Mistral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoReason Automatic Few-Shot Reasoning Decomposition": {
        "filename": "AutoReason Automatic Few-Shot Reasoning Decomposition.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "HotpotQA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo"
            ]
        }
    },
    "Knowledge Rumination for Pre-trained Language Models": {
        "filename": "Knowledge Rumination for Pre-trained Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "SocialIQA",
                "PhysicalQA",
                "Openbook QA",
                "HellaSwag",
                "Abductive Natural Language Inference",
                "GLUE"
            ],
            "base_models": [
                "RoBERTa",
                "DeBERTa",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Spoken Language Intelligence of Large Language Models for Language Learning": {
        "filename": "Spoken Language Intelligence of Large Language Models for Language Learning.pdf",
        "analysis": {
            "benchmarks": [
                "SLIQ-LL (Spoken Language Intelligence Questions for Language Learning)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA2-70B-Chat",
                "FLAN-T5",
                "UL2",
                "Pythia"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL": {
        "filename": "Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MAWPS",
                "SVAMP"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "LLaMA-2-7B-Chat",
                "TigerBot-13B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PaLM Scaling Language Modeling with Pathways": {
        "filename": "PaLM Scaling Language Modeling with Pathways.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-bench",
                "MMLU",
                "SuperGLUE"
            ],
            "base_models": [
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are Large Language Models Aligned with Peoples Social Intuitions for HumanRobot Interactions": {
        "filename": "Are Large Language Models Aligned with Peoples Social Intuitions for HumanRobot Interactions.pdf",
        "analysis": {
            "benchmarks": [
                "HRI user study 1: Communication Preferences",
                "HRI user study 2: Behavior Judgment"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "GPT-3 base",
                "LLaMA-2-13b Chat",
                "LLaMA-2-70b Chat"
            ]
        }
    },
    "Trustworthiness in Retrieval-Augmented Generation Systems A Survey": {
        "filename": "Trustworthiness in Retrieval-Augmented Generation Systems A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatLogic Integrating Logic Programming with Large Language Models for Multi-Step Reasoning": {
        "filename": "ChatLogic Integrating Logic Programming with Large Language Models for Multi-Step Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "PARARULE-Plus",
                "CONCEPTRULES V1",
                "CONCEPTRULES V2"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "GPT-4",
                "Llama 2-7B"
            ]
        }
    },
    "Selecting Better Samples from Pre-trained LLMs A Case Study on Question Generation": {
        "filename": "Selecting Better Samples from Pre-trained LLMs A Case Study on Question Generation.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "Fairytale QA"
            ],
            "base_models": [
                "GPT-3 (175B)"
            ]
        }
    },
    "Causal Inference with Latent Variables Recent Advances and Future Prospectives": {
        "filename": "Causal Inference with Latent Variables Recent Advances and Future Prospectives.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning from Partially Annotated Data Example-aware Creation of Gap-filling Exercises for Language Learning": {
        "filename": "Learning from Partially Annotated Data Example-aware Creation of Gap-filling Exercises for Language Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GF2 (Gap-Filling for Grammar in French)"
            ],
            "base_models": [
                "XLM-RoBERTa (base)"
            ]
        }
    },
    "Inverse scaling can become U-shaped": {
        "filename": "Inverse scaling can become U-shaped.pdf",
        "analysis": {
            "benchmarks": [
                "Inverse Scaling Prize Tasks"
            ],
            "base_models": [
                "PaLM-540B",
                "Gopher-280B",
                "Chinchilla-70B",
                "Anthropic internal model (13M–52B)"
            ]
        }
    },
    "Attributed Question Answering Evaluation and Modeling for Attributed Large Language Models": {
        "filename": "Attributed Question Answering Evaluation and Modeling for Attributed Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions",
                "KILT"
            ],
            "base_models": [
                "T5-3B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Augmented Large Language Models with Parametric Knowledge Guiding": {
        "filename": "Augmented Large Language Models with Parametric Knowledge Guiding.pdf",
        "analysis": {
            "benchmarks": [
                "FM2",
                "NQ-Table",
                "MedMC-QA",
                "ScienceQA"
            ],
            "base_models": [
                "LLaMa-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unraveling Arithmetic in Large Language Models The Role of Algebraic Structures": {
        "filename": "Unraveling Arithmetic in Large Language Models The Role of Algebraic Structures.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "custom dataset of arithmetic problems"
            ],
            "base_models": [
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval-Generation Synergy Augmented Large Language Models": {
        "filename": "Retrieval-Generation Synergy Augmented Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions",
                "TriviaQA",
                "2WikiMultiHopQA",
                "HotpotQA"
            ],
            "base_models": [
                "LLaMA-33B"
            ]
        }
    },
    "TabVer Tabular Fact Verification with Natural Logic": {
        "filename": "TabVer Tabular Fact Verification with Natural Logic.pdf",
        "analysis": {
            "benchmarks": [
                "FEVEROUS",
                "TabFact"
            ],
            "base_models": [
                "MistralOrca-7B",
                "Flan-T5 3B",
                "BART0 (406M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When in Doubt Think Slow Iterative Reasoning with Latent Imagination": {
        "filename": "When in Doubt Think Slow Iterative Reasoning with Latent Imagination.pdf",
        "analysis": {
            "benchmarks": [
                "DMLab Collect Good Objects",
                "DMLab NatLab Fixed Large Map",
                "Atari Alien",
                "Miniworld Robot Navigation"
            ],
            "base_models": [
                "DreamerV3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What Algorithms can Transformers Learn A Study in Length Generalization": {
        "filename": "What Algorithms can Transformers Learn A Study in Length Generalization.pdf",
        "analysis": {
            "benchmarks": [
                "counting task",
                "mode task",
                "copy task with unique tokens",
                "sort task",
                "addition task",
                "parity task"
            ],
            "base_models": [
                "standard decoder-only Transformers"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Control Risk for Potential Misuse of Artificial Intelligence in Science": {
        "filename": "Control Risk for Potential Misuse of Artificial Intelligence in Science.pdf",
        "analysis": {
            "benchmarks": [
                "SciMT-Safety"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-2",
                "Llama2-7B-Chat",
                "Llama2-13B-Chat",
                "PaLM2 (text-bison)",
                "Vicuna-7B",
                "Vicuna-13B",
                "Mistral-7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Advancing Large Language Models for Spatiotemporal and Semantic Association Mining of Similar Environmental Events": {
        "filename": "Advancing Large Language Models for Spatiotemporal and Semantic Association Mining of Similar Environmental Events.pdf",
        "analysis": {
            "benchmarks": [
                "Local Environmental Observer (LEO) Network"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "OpenAI Ada (002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DialCoT Meets PPO Decomposing and Exploring Reasoning Paths in Smaller Language Models": {
        "filename": "DialCoT Meets PPO Decomposing and Exploring Reasoning Paths in Smaller Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MultiArith",
                "ASDiv",
                "SVAMP"
            ],
            "base_models": [
                "Flan-T5-XL (3B)",
                "Flan-T5-XXL (11B)",
                "LLaMA-7B"
            ]
        }
    },
    "How Good is my Video LMM Complex Video Reasoning and Robustness Evaluation Suite for Video-LMMs": {
        "filename": "How Good is my Video LMM Complex Video Reasoning and Robustness Evaluation Suite for Video-LMMs.pdf",
        "analysis": {
            "benchmarks": [
                "MSVD-QA",
                "MSRVTT-QA",
                "TGIF-QA",
                "Activity Net-QA",
                "VideoChat-GPT",
                "MVBench",
                "SEED-Bench",
                "CVRR-ES"
            ],
            "base_models": [
                "Video-LLaVA",
                "TimeChat",
                "MovieChat",
                "LLaMA-ViD",
                "VideoChat",
                "Video-ChatGPT",
                "Video-LLaMA-2",
                "Gemini-Pro-Vision",
                "GPT-4V(ision)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unraveling the Potential of Large Language Models in Code Translation How Far Are We": {
        "filename": "Unraveling the Potential of Large Language Models in Code Translation How Far Are We.pdf",
        "analysis": {
            "benchmarks": [
                "PolyHumanEval"
            ],
            "base_models": [
                "CodeLlama-13B",
                "CodeLlama-7B",
                "CodeLlama-34B",
                "StarCoderBase",
                "CodeGen2.5-7B-Multi",
                "CodeGeeX2-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Humanoid Robots at work where are we": {
        "filename": "Humanoid Robots at work where are we.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Human-AI Teaming with Large Pre-Trained Models": {
        "filename": "A Survey on Human-AI Teaming with Large Pre-Trained Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Software Performance Engineering for Foundation Model-Powered Software FMware": {
        "filename": "Software Performance Engineering for Foundation Model-Powered Software FMware.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt": {
        "filename": "Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt.pdf",
        "analysis": {
            "benchmarks": [
                "SafetyBench",
                "AdvBench"
            ],
            "base_models": [
                "LLaVA (7B)",
                "MiniGPT-4 (Vicuna 7B)",
                "InstructBLIP (Vicuna 7B)",
                "Gemini",
                "ChatGLM",
                "Qwen",
                "ERNIE Bot"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions": {
        "filename": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions.pdf",
        "analysis": {
            "benchmarks": [
                "USMLE subset of MedQA",
                "Massive Multitask Language Understanding (MMLU) dataset",
                "MedQA"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama-3.1-8B"
            ]
        }
    },
    "MaterioMiner - An ontology-based text mining dataset for extraction of process-structure-property entities": {
        "filename": "MaterioMiner - An ontology-based text mining dataset for extraction of process-structure-property entities.pdf",
        "analysis": {
            "benchmarks": [
                "MaterioMiner dataset"
            ],
            "base_models": [
                "MatSciBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Insight Over Sight Exploring the Vision-Knowledge Conflicts in Multimodal LLMs": {
        "filename": "Insight Over Sight Exploring the Vision-Knowledge Conflicts in Multimodal LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "CONFLICT VIS"
            ],
            "base_models": [
                "GPT-4o",
                "LLaVA-NeXT-34B",
                "Claude-3.5-Sonnet",
                "LLaVA-1.5-13B",
                "BLIP-2-12B",
                "Qwen-VL-9.6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Utilising a Large Language Model to Annotate Subject Metadata A Case Study in an Australian National Research Data Catalogue": {
        "filename": "Utilising a Large Language Model to Annotate Subject Metadata A Case Study in an Australian National Research Data Catalogue.pdf",
        "analysis": {
            "benchmarks": [
                "Research Data Australia (RDA)"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning": {
        "filename": "Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2",
                "CodeLLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Semantic Layering in Room Segmentation via LLMs": {
        "filename": "Semantic Layering in Room Segmentation via LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ProcTHOR (AI2-THOR framework)"
            ],
            "base_models": [
                "Detic",
                "YOLOv8"
            ]
        }
    },
    "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems": {
        "filename": "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems.pdf",
        "analysis": {
            "benchmarks": [
                "modular addition",
                "permutation composition",
                "iterated squaring",
                "circuit value problem"
            ],
            "base_models": [
                "GPT-style architecture (depth unspecified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Context-Enhanced Language Models for Generating Multi-paper Citations": {
        "filename": "Context-Enhanced Language Models for Generating Multi-paper Citations.pdf",
        "analysis": {
            "benchmarks": [
                "MCG-S2ORC"
            ],
            "base_models": [
                "LLaMA-7B",
                "Alpaca-7B",
                "Vicuna-7B"
            ]
        }
    },
    "SCOTT Self-Consistent Chain-of-Thought Distillation": {
        "filename": "SCOTT Self-Consistent Chain-of-Thought Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "CSQA",
                "StrategyQA",
                "CREAK",
                "QASC"
            ],
            "base_models": [
                "GPT-neox (20B)",
                "T5-3B"
            ]
        }
    },
    "Entailer Answering Questions with Faithful and Truthful Chains of Reasoning": {
        "filename": "Entailer Answering Questions with Faithful and Truthful Chains of Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "OBQA",
                "QuaRTz"
            ],
            "base_models": [
                "T5-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DreamLLM Synergistic Multimodal Comprehension and Creation": {
        "filename": "DreamLLM Synergistic Multimodal Comprehension and Creation.pdf",
        "analysis": {
            "benchmarks": [
                "MS-COCO",
                "MMBench",
                "MM-Vet",
                "VQAv2",
                "OKVQA",
                "VizWiz",
                "TextVQA",
                "Image2Paragraph"
            ],
            "base_models": [
                "Vicuna (based on LLaMA)",
                "CLIP-Large",
                "Stable Diffusion"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RATT A Thought Structure for Coherent and Correct LLM Reasoning": {
        "filename": "RATT A Thought Structure for Coherent and Correct LLM Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "TruthfulQA",
                "4nums"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4"
            ]
        }
    },
    "Representing Rule-based Chatbots with Transformers": {
        "filename": "Representing Rule-based Chatbots with Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic ELIZA conversations"
            ],
            "base_models": [
                "GPT-2 architecture (without position embeddings)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Natural Language to SQL Review of LLM-based Text-to-SQL Systems": {
        "filename": "From Natural Language to SQL Review of LLM-based Text-to-SQL Systems.pdf",
        "analysis": {
            "benchmarks": [
                "WikiSQL",
                "Spider"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Jellyfish A Large Language Model for Data Preprocessing": {
        "filename": "Jellyfish A Large Language Model for Data Preprocessing.pdf",
        "analysis": {
            "benchmarks": [
                "Adult",
                "Hospital",
                "Buy",
                "Restaurant",
                "MIMIC-III",
                "Synthea",
                "Amazon-Google",
                "Beer",
                "DBLP-ACM",
                "DBLP-GoogleScholar",
                "Fodors-Zagats",
                "iTunes-Amazon",
                "Flights",
                "Rayyan",
                "Flipkart",
                "Phone",
                "CMS",
                "Abt-Buy",
                "Walmart-Amazon",
                "SOTAB",
                "AE-110k",
                "OA-Mine"
            ],
            "base_models": [
                "Mistral-7B",
                "Llama 3-8B",
                "OpenOrca-Platypus2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dipper Diversity in Prompts for Producing Large Language Model Ensembles in Reasoning tasks": {
        "filename": "Dipper Diversity in Prompts for Producing Large Language Model Ensembles in Reasoning tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "MMLU-STEM"
            ],
            "base_models": [
                "Qwen2-MATH-1.5B",
                "Qwen2-MATH-7B"
            ]
        }
    },
    "Evaluating Vision-Language Models as Evaluators in Path Planning": {
        "filename": "Evaluating Vision-Language Models as Evaluators in Path Planning.pdf",
        "analysis": {
            "benchmarks": [
                "PATHEVAL"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o-mini",
                "LLaV A-NeXT-7b",
                "LLaV A-NeXT-13b",
                "Qwen2-VL-7b",
                "LLaV A-OneVision-7b",
                "LLaMA-3.2-11b",
                "Intern-VL2-8b",
                "Intern-VL2-40b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Noise Robustness of In-Context Learning for Text Generation": {
        "filename": "On the Noise Robustness of In-Context Learning for Text Generation.pdf",
        "analysis": {
            "benchmarks": [
                "NQ",
                "WebQ",
                "SQuAD",
                "SCIQ",
                "GeoQuery",
                "NL2Bash"
            ],
            "base_models": [
                "Llama2-7B",
                "Llama2-13B",
                "Mistral-7B",
                "OPT-6.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Human-Like Translation Strategy with Large Language Models": {
        "filename": "Exploring Human-Like Translation Strategy with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WMT22"
            ],
            "base_models": [
                "text-davinci-003",
                "Alpaca (7B)",
                "Vicuna (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models as General Pattern Machines": {
        "filename": "Large Language Models as General Pattern Machines.pdf",
        "analysis": {
            "benchmarks": [
                "Abstraction and Reasoning Corpus (ARC)",
                "PCFG benchmark"
            ],
            "base_models": [
                "GPT-4",
                "text-davinci-003",
                "text-davinci-002",
                "PaLM",
                "text-davinci-001",
                "text-curie-001",
                "text-babbage-001",
                "text-ada-001"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Theory of Mind for Multi-Agent Collaboration via Large Language Models": {
        "filename": "Theory of Mind for Multi-Agent Collaboration via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom multi-agent cooperative text game"
            ],
            "base_models": [
                "GPT-3.5-turbo-0301",
                "GPT-4-0314"
            ]
        }
    },
    "From Large Language Models and Optimization to Decision Optimization CoPilot A Research Manifesto": {
        "filename": "From Large Language Models and Optimization to Decision Optimization CoPilot A Research Manifesto.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (GPT-4 with 1.76 trillion parameters)",
                "Flan-T5",
                "Llama 2",
                "Mixtral",
                "GPT-3.5 (175 billion parameters)",
                "Gemini Pro (137 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Optimizing Large Language Models for OpenAPI Code Completion": {
        "filename": "Optimizing Large Language Models for OpenAPI Code Completion.pdf",
        "analysis": {
            "benchmarks": [
                "OpenAPI completion benchmark"
            ],
            "base_models": [
                "Code Llama 7B",
                "Code Llama 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ToolGen Unified Tool Retrieval and Calling via Generation": {
        "filename": "ToolGen Unified Tool Retrieval and Calling via Generation.pdf",
        "analysis": {
            "benchmarks": [
                "ToolBench"
            ],
            "base_models": [
                "Llama-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RELIC Investigating Large Language Model Responses using Self-Consistency": {
        "filename": "RELIC Investigating Large Language Model Responses using Self-Consistency.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "InstructGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations": {
        "filename": "Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations.pdf",
        "analysis": {
            "benchmarks": [
                "IMDb",
                "Yelp",
                "CivilComments",
                "MNLI",
                "BoolQ"
            ],
            "base_models": [
                "GPT-3 (Davinci)",
                "GPT-3 (Text-Davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Extracting human interpretable structure-property relationships in chemistry using XAI and large language models": {
        "filename": "Extracting human interpretable structure-property relationships in chemistry using XAI and large language models.pdf",
        "analysis": {
            "benchmarks": [
                "CoRE MOF 2019 database",
                "Tox21 database",
                "AqSolDB",
                "UFL dataset from Yuan et al."
            ],
            "base_models": [
                "GPT-4",
                "Claude"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Harnessing the Power of Large Language Models for Empathetic Response Generation Empirical Investigations and Improvements": {
        "filename": "Harnessing the Power of Large Language Models for Empathetic Response Generation Empirical Investigations and Improvements.pdf",
        "analysis": {
            "benchmarks": [
                "EMPATHETIC DIALOGUES"
            ],
            "base_models": [
                "GPT-3.5",
                "ChatGPT",
                "GPT-4"
            ]
        }
    },
    "Large Language Models for Anomaly Detection in Computational Workflows From Supervised Fine-Tuning to In-Context Learning": {
        "filename": "Large Language Models for Anomaly Detection in Computational Workflows From Supervised Fine-Tuning to In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Flow-Bench"
            ],
            "base_models": [
                "BERT-base-uncased",
                "GPT2",
                "Mistral-7B",
                "LLama2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BUMBLE Unifying Reasoning and Acting with Vision-Language Models for Building-wide Mobile Manipulation": {
        "filename": "BUMBLE Unifying Reasoning and Acting with Vision-Language Models for Building-wide Mobile Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "Custom building-wide mobile manipulation tasks",
                "OfflineSkillDataset"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph": {
        "filename": "Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "Prompt-ORKG"
            ],
            "base_models": [
                "BERT-base (pretrained, SQuAD2.0 finetuned)",
                "RoBERTa-base (pretrained, SQuAD2.0 finetuned)",
                "MiniLM (pretraining distillation, SQuAD2.0 finetuned)"
            ]
        }
    },
    "Generative Monoculture in Large Language Models": {
        "filename": "Generative Monoculture in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Goodreads dataset",
                "CodeContests dataset"
            ],
            "base_models": [
                "Llama-2-13b",
                "Llama-2-13b-chat",
                "Vicuna-13b-v1.5",
                "GPT-3.5-turbo-instruct (0914)",
                "GPT-4-turbo (0125)",
                "Claude-3-Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Language Model Agency through Negotiations": {
        "filename": "Evaluating Language Model Agency through Negotiations.pdf",
        "analysis": {
            "benchmarks": [
                "LAMEN negotiation games"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude-2",
                "Chat-Bison",
                "Cohere Command",
                "Cohere Command-Light",
                "LLaMA 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EnvBridge Bridging Diverse Environments with Cross-Environment Knowledge Transfer for Embodied AI": {
        "filename": "EnvBridge Bridging Diverse Environments with Cross-Environment Knowledge Transfer for Embodied AI.pdf",
        "analysis": {
            "benchmarks": [
                "RLBench",
                "MetaWorld",
                "CALVIN"
            ],
            "base_models": [
                "GPT-4o-mini",
                "GPT-4o"
            ]
        }
    },
    "GPT-4V Cannot Generate Radiology Reports Yet": {
        "filename": "GPT-4V Cannot Generate Radiology Reports Yet.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-CXR",
                "CheXpert Plus",
                "IU X-Ray"
            ],
            "base_models": [
                "GPT-4V",
                "Llama-2 (finetuned)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Philosophical Introduction to Language Models - Part I Continuity With Classic Debates": {
        "filename": "A Philosophical Introduction to Language Models - Part I Continuity With Classic Debates.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing the Rationale-Input Alignment for Self-explaining Rationalization": {
        "filename": "Enhancing the Rationale-Input Alignment for Self-explaining Rationalization.pdf",
        "analysis": {
            "benchmarks": [
                "BeerAdvocate",
                "HotelReview"
            ],
            "base_models": [
                "BERT-base-uncased"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning Audio Concepts from Counterfactual Natural Language": {
        "filename": "Learning Audio Concepts from Counterfactual Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "Clotho",
                "ESC-50",
                "US8K"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "CLIP",
                "PANNs (ResNet-38)"
            ]
        }
    },
    "Borrowing Treasures from Neighbors In-Context Learning for Multimodal Learning with Missing Modalities and Data Scarcity": {
        "filename": "Borrowing Treasures from Neighbors In-Context Learning for Multimodal Learning with Missing Modalities and Data Scarcity.pdf",
        "analysis": {
            "benchmarks": [
                "MedFuse-I",
                "MedFuse-P",
                "Food-101",
                "HatefulMemes"
            ],
            "base_models": [
                "ViLT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Prompt Engineering Practices in the Enterprise": {
        "filename": "Exploring Prompt Engineering Practices in the Enterprise.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "llama-2",
                "flan"
            ]
        }
    },
    "PokeLLMon A Human-Parity Agent for Pokemon Battles with Large Language Models": {
        "filename": "PokeLLMon A Human-Parity Agent for Pokemon Battles with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Ladder competitions",
                "Invited battles"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA-2"
            ]
        }
    },
    "Cambrian-1 A Fully Open Vision-Centric Exploration of Multimodal LLMs": {
        "filename": "Cambrian-1 A Fully Open Vision-Centric Exploration of Multimodal LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "CV-Bench",
                "RealWorldQA",
                "MMVP"
            ],
            "base_models": [
                "Vicuna-1.5-7B",
                "OpenAI CLIP ViT-L/14@336",
                "DINOv2 ViT-L/14@336"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Direct Judgement Preference Optimization": {
        "filename": "Direct Judgement Preference Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "RewardBench",
                "InstruSum",
                "Auto-J",
                "HHH",
                "LFQA",
                "EvalBiasBench",
                "PreferenceBench",
                "BiGGen Bench",
                "FLASK",
                "MT Bench",
                "FeedbackBench",
                "LLM-AggreFact",
                "InfoBench"
            ],
            "base_models": [
                "Llama-3.1-8B-Instruct",
                "NeMo-Instruct-12B",
                "Llama-3.1-70B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ToM-LM Delegating Theory of Mind Reasoning to External Symbolic Executors in Large Language Models": {
        "filename": "ToM-LM Delegating Theory of Mind Reasoning to External Symbolic Executors in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MindGames"
            ],
            "base_models": [
                "gpt-3.5-turbo"
            ]
        }
    },
    "Can Large Language Models Detect Rumors on Social Media": {
        "filename": "Can Large Language Models Detect Rumors on Social Media.pdf",
        "analysis": {
            "benchmarks": [
                "Twitter",
                "Weibo"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels": {
        "filename": "Leveraging Large Language Models for Suicide Detection on Social Media with Limited Labels.pdf",
        "analysis": {
            "benchmarks": [
                "Suicide Ideation Detection on Social Media Challenge"
            ],
            "base_models": [
                "Qwen2-72B-Instruct",
                "Llama3-8B",
                "Llama3.1-8B",
                "Gemma2-9B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LIMA Less Is More for Alignment": {
        "filename": "LIMA Less Is More for Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "Pushshift r/AskReddit",
                "Paper Authors (Group B)"
            ],
            "base_models": [
                "LLaMa-65B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Character-LLM A Trainable Agent for Role-Playing": {
        "filename": "Character-LLM A Trainable Agent for Role-Playing.pdf",
        "analysis": {
            "benchmarks": [
                "custom test playground"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Solitary Directives to Interactive Encouragement LLM Secure Code Generation by Natural Language Prompting": {
        "filename": "From Solitary Directives to Interactive Encouragement LLM Secure Code Generation by Natural Language Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "SecEval",
                "Holmes",
                "LEval",
                "HumanEval"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4",
                "GPT-4o",
                "Llama 3.1 8B Instruct",
                "DeepSeek Coder V2 Lite Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Simple LLM Framework for Long-Range Video Question-Answering": {
        "filename": "A Simple LLM Framework for Long-Range Video Question-Answering.pdf",
        "analysis": {
            "benchmarks": [
                "EgoSchema",
                "NExT-QA",
                "IntentQA",
                "NExT-GQA"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "GPT-4 (1.8T)",
                "LLaMA (size unspecified)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "iCORPP Interleaved Commonsense Reasoning and Probabilistic Planning on Robots": {
        "filename": "iCORPP Interleaved Commonsense Reasoning and Probabilistic Planning on Robots.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset for indoor navigation",
                "custom dataset for dialog management"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MoC-System Efficient Fault Tolerance for Sparse Mixture-of-Experts Model Training": {
        "filename": "MoC-System Efficient Fault Tolerance for Sparse Mixture-of-Experts Model Training.pdf",
        "analysis": {
            "benchmarks": [
                "Wikitext-2",
                "SlimPajama-627B",
                "ImageNet-1K"
            ],
            "base_models": [
                "GPT-125M-8E",
                "GPT-350M-16E",
                "SwinV2-MoE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Couler Unified Machine Learning Workflow Optimization in Cloud": {
        "filename": "Couler Unified Machine Learning Workflow Optimization in Cloud.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT-3.5",
                "ChatGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automated Software Vulnerability Patching using Large Language Models": {
        "filename": "Automated Software Vulnerability Patching using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BigVul+CVEFixes dataset"
            ],
            "base_models": [
                "GPT-4",
                "Gemini",
                "Claude3",
                "Llama3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Concept - An Evaluation Protocol on Conversational Recommender Systems with System-centric and User-centric Factors": {
        "filename": "Concept - An Evaluation Protocol on Conversational Recommender Systems with System-centric and User-centric Factors.pdf",
        "analysis": {
            "benchmarks": [
                "Redial",
                "OpendialKG"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-3.5-16K-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MeTMaP Metamorphic Testing for Detecting False Vector Matching Problems in LLM Augmented Generation": {
        "filename": "MeTMaP Metamorphic Testing for Detecting False Vector Matching Problems in LLM Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Stanford Contradiction Corpora",
                "PAWS",
                "VitaminC",
                "Inference-is-Everything",
                "HEROS",
                "NEVIR"
            ],
            "base_models": [
                "Cohere/embed-english-v2.0",
                "Paddle/ernie-3.0-medium-zh",
                "FastText-en",
                "sgugger/rwkv-430M-pile",
                "Distilbert-base-uncased",
                "all-MiniLM-L6-v2",
                "Paraphrase-albert-onnx",
                "unum-cloud/uform-vl-english",
                "text-embedding-ada-002",
                "bert-base-uncased",
                "SpanBERT/spanbert-large-cased",
                "michiyasunaga/LinkBERT-base",
                "google/electra-large-generator",
                "xlnet-large-cased",
                "sentence-transformers/gtr-t5-large",
                "roberta-base",
                "sentence-transformers/sentence-t5-large",
                "albert-base-v2",
                "sentence-transformers/all-mpnet-base-v2",
                "tiiuae/falcon-7b",
                "tiiuae/falcon-7b-4bit",
                "decapoda-research/llama-7b-hf",
                "decapoda-research/llama-7b-hf-4bit",
                "decapoda-research/llama-13b-hf",
                "decapoda-research/llama-13b-hf-4bit",
                "meta-llama/Llama-2-7b-hf",
                "meta-llama/Llama-2-7b-hf-4bit",
                "meta-llama/Llama-2-13b-hf",
                "meta-llama/Llama-2-13b-hf-4bit"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VS-Assistant Versatile Surgery Assistant on the Demand of Surgeons": {
        "filename": "VS-Assistant Versatile Surgery Assistant on the Demand of Surgeons.pdf",
        "analysis": {
            "benchmarks": [
                "neurosurgery data",
                "transsphenoidal pituitary neurosurgery images"
            ],
            "base_models": [
                "Vicuna-7B"
            ]
        }
    },
    "Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs": {
        "filename": "Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Isaac Gym simulator",
                "PartNet-Mobility dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo"
            ]
        }
    },
    "Using Left and Right Brains Together Towards Vision and Language Planning": {
        "filename": "Using Left and Right Brains Together Towards Vision and Language Planning.pdf",
        "analysis": {
            "benchmarks": [
                "STAR",
                "NExT-QA",
                "BDD-X",
                "BAIR"
            ],
            "base_models": [
                "ChatGPT",
                "Stable Video Diffusion",
                "BLIP-2",
                "LLAVA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HARGPT Are LLMs Zero-Shot Human Activity Recognizers": {
        "filename": "HARGPT Are LLMs Zero-Shot Human Activity Recognizers.pdf",
        "analysis": {
            "benchmarks": [
                "Capture24",
                "HHAR"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Towards a Mathematics Formalisation Assistant using Large Language Models": {
        "filename": "Towards a Mathematics Formalisation Assistant using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "120 theorem statements dataset",
                "13 NL theorems and proofs dataset"
            ],
            "base_models": [
                "Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Case Study of LLM for Automated Vulnerability Repair Assessing Impact of Reasoning and Patch Validation Feedback": {
        "filename": "A Case Study of LLM for Automated Vulnerability Repair Assessing Impact of Reasoning and Patch Validation Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "ExtractFix",
                "VjBench",
                "Vul4j"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NLP4Gov A Comprehensive Library for Computational Policy Analysis": {
        "filename": "NLP4Gov A Comprehensive Library for Computational Policy Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "Reddit",
                "Apache Software Foundation",
                "public policy case studies"
            ],
            "base_models": [
                "MPNET",
                "DistilBERT"
            ]
        }
    },
    "CONDAQA A Contrastive Reading Comprehension Dataset for Reasoning about Negation": {
        "filename": "CONDAQA A Contrastive Reading Comprehension Dataset for Reasoning about Negation.pdf",
        "analysis": {
            "benchmarks": [
                "CONDA QA"
            ],
            "base_models": [
                "UNIFIED QA-V2-3B",
                "BERT-Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Artificial Intelligence for Literature Reviews Opportunities and Challenges": {
        "filename": "Artificial Intelligence for Literature Reviews Opportunities and Challenges.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (via OpenAI API)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language Decomposition and Interpretation of Complex Utterances": {
        "filename": "Natural Language Decomposition and Interpretation of Complex Utterances.pdf",
        "analysis": {
            "benchmarks": [
                "DeCU"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "LLAMA-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Propagating Knowledge Updates to LMs Through Distillation": {
        "filename": "Propagating Knowledge Updates to LMs Through Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "ENTITY INFERENCES",
                "Entity Cloze By Date (ECBD)"
            ],
            "base_models": [
                "GPT-Neo-1.3B",
                "GPT2-XL (1.5B)",
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Charting the Future of AI in Project-Based Learning A Co-Design Exploration with Students": {
        "filename": "Charting the Future of AI in Project-Based Learning A Co-Design Exploration with Students.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A new solution and concrete implementation steps for Artificial General Intelligence": {
        "filename": "A new solution and concrete implementation steps for Artificial General Intelligence.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automatic Generation of Socratic Subquestions for Teaching Math Word Problems": {
        "filename": "Automatic Generation of Socratic Subquestions for Teaching Math Word Problems.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "T5",
                "GPT-2",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Investigate-Consolidate-Exploit A General Strategy for Inter-Task Agent Self-Evolution": {
        "filename": "Investigate-Consolidate-Exploit A General Strategy for Inter-Task Agent Self-Evolution.pdf",
        "analysis": {
            "benchmarks": [
                "XAgent framework"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Meta Knowledge for Retrieval Augmented Large Language Models": {
        "filename": "Meta Knowledge for Retrieval Augmented Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "arXiv dataset of 2,000 research papers from 2024"
            ],
            "base_models": [
                "Claude 3 Haiku",
                "Claude 3 Sonnet"
            ]
        }
    },
    "Translate Meanings Not Just Words IdiomKBs Role in Optimizing Idiomatic Translation with Language Models": {
        "filename": "Translate Meanings Not Just Words IdiomKBs Role in Optimizing Idiomatic Translation with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PIE Corpus",
                "PETCI dataset",
                "OpenMWE Corpus"
            ],
            "base_models": [
                "BLOOMZ (7.1B)",
                "Alpaca (7B)",
                "InstructGPT (6.7B)",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathLearner A Large Language Model Agent Framework for Learning to Solve Mathematical Problems": {
        "filename": "MathLearner A Large Language Model Agent Framework for Learning to Solve Mathematical Problems.pdf",
        "analysis": {
            "benchmarks": [
                "MATH"
            ],
            "base_models": [
                "GPT-4.0"
            ]
        }
    },
    "AutoKaggle A Multi-Agent Framework for Autonomous Data Science Competitions": {
        "filename": "AutoKaggle A Multi-Agent Framework for Autonomous Data Science Competitions.pdf",
        "analysis": {
            "benchmarks": [
                "Kaggle competitions (8 tasks)"
            ],
            "base_models": [
                "GPT-4o",
                "o1-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Few-shot Generators Proposing Hybrid Prompt Algorithm To Generate Webshell Escape Samples": {
        "filename": "Large Language Models are Few-shot Generators Proposing Hybrid Prompt Algorithm To Generate Webshell Escape Samples.pdf",
        "analysis": {
            "benchmarks": [
                "VirusTotal",
                "Web Shell Detector",
                "WEBDIR+",
                "SHELLPUB"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Code-llama-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DSPy Compiling Declarative Language Model Calls into Self-Improving Pipelines": {
        "filename": "DSPy Compiling Declarative Language Model Calls into Self-Improving Pipelines.pdf",
        "analysis": {
            "benchmarks": [
                "GMS8K",
                "HotPotQA"
            ],
            "base_models": [
                "GPT-3.5",
                "llama2-13b-chat",
                "T5-Large (770M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can language representation models think in bets": {
        "filename": "Can language representation models think in bets.pdf",
        "analysis": {
            "benchmarks": [
                "SWAG",
                "custom decision-making and preference elicitation benchmarks"
            ],
            "base_models": [
                "BERT BASE",
                "RoBERTa BASE",
                "DeBERTa BASE",
                "BigBird BASE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Scaling up Masked Diffusion Models on Text": {
        "filename": "Scaling up Masked Diffusion Models on Text.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "Hellaswag",
                "ARC-e",
                "BoolQ",
                "PIQA",
                "SIQA",
                "Obqa",
                "RACE",
                "LAMBADA"
            ],
            "base_models": [
                "TinyLlama-1.1B",
                "Llama-2-7B",
                "GPT-3-175B",
                "GPT-2-1.5B",
                "T5-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TIARA Multi-grained Retrieval for Robust Question Answering over Large Knowledge Base": {
        "filename": "TIARA Multi-grained Retrieval for Robust Question Answering over Large Knowledge Base.pdf",
        "analysis": {
            "benchmarks": [
                "GrailQA",
                "WebQuestionsSP"
            ],
            "base_models": [
                "T5-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models are Multilingual Chain-of-Thought Reasoners": {
        "filename": "Language Models are Multilingual Chain-of-Thought Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "Multilingual Grade School Math (MGSM)",
                "XCOPA",
                "XL-WiC"
            ],
            "base_models": [
                "GPT-3",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring an LM to generate Prolog Predicates from Mathematics Questions": {
        "filename": "Exploring an LM to generate Prolog Predicates from Mathematics Questions.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "gsm8k-prolog"
            ],
            "base_models": [
                "LLaMA7B"
            ]
        }
    },
    "HDL-GPT High-Quality HDL is All You Need": {
        "filename": "HDL-GPT High-Quality HDL is All You Need.pdf",
        "analysis": {
            "benchmarks": [
                "NYU Eval Set 1",
                "NYU Eval Set II",
                "NVIDIA Human Eval",
                "NVIDIA Machine Eval"
            ],
            "base_models": [
                "StarCoder 16B",
                "CodeLlama 7B",
                "StarCoder2",
                "CodeGen-16B"
            ]
        }
    },
    "Visual-O1 Understanding Ambiguous Instructions via Multi-modal Multi-turn Chain-of-thoughts Reasoning": {
        "filename": "Visual-O1 Understanding Ambiguous Instructions via Multi-modal Multi-turn Chain-of-thoughts Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "RefCOCO+",
                "VizWiz"
            ],
            "base_models": [
                "GPT-4O",
                "LLAVA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generating Out-Of-Distribution Scenarios Using Language Models": {
        "filename": "Generating Out-Of-Distribution Scenarios Using Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "nuScenes",
                "CODA"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "Exploring Iterative Enhancement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models": {
        "filename": "Exploring Iterative Enhancement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PeerWise datasets (Sydney Biology Subject, Cardiff Biology Subject, Auckland Law Subject, UK Medical Year 1, UK Medical Year 2)"
            ],
            "base_models": [
                "LLaMA2-13B",
                "GPT-4"
            ]
        }
    },
    "Adaptivity and Modularity for Efficient Generalization Over Task Complexity": {
        "filename": "Adaptivity and Modularity for Efficient Generalization Over Task Complexity.pdf",
        "analysis": {
            "benchmarks": [
                "C-PVR (plain)",
                "C-PVR (modulus)",
                "ImageNet1K"
            ],
            "base_models": [
                "Universal Transformer",
                "ViT B/16",
                "U-ViT B/16",
                "U-ViT L/16"
            ]
        }
    },
    "Health Text Simplification An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning": {
        "filename": "Health Text Simplification An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "SimpleDC",
                "Med-EASi"
            ],
            "base_models": [
                "Llama 2",
                "Llama 3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Model Based Referring Camouflaged Object Detection": {
        "filename": "Large Model Based Referring Camouflaged Object Detection.pdf",
        "analysis": {
            "benchmarks": [
                "R2C7K",
                "COD10K",
                "CHAMELEON",
                "NC4K",
                "CAMO"
            ],
            "base_models": [
                "LLaVA-1.5",
                "SAM (Vision Transformer - ViT-H)",
                "CLIP (ViT-B/16)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "T2V-CompBench A Comprehensive Benchmark for Compositional Text-to-video Generation": {
        "filename": "T2V-CompBench A Comprehensive Benchmark for Compositional Text-to-video Generation.pdf",
        "analysis": {
            "benchmarks": [
                "T2V-CompBench"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models are General-Purpose Interfaces": {
        "filename": "Language Models are General-Purpose Interfaces.pdf",
        "analysis": {
            "benchmarks": [
                "VQAv2",
                "OK-VQA",
                "COCO Caption",
                "Flickr30k",
                "NoCaps",
                "NLVR2",
                "E-SNLI-VE"
            ],
            "base_models": [
                "GPT-3",
                "BERT",
                "RoBERTa",
                "ELECTRA",
                "VLMo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners": {
        "filename": "Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "Symbolic Tree",
                "ProofWriter"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs": {
        "filename": "Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "ImageNet-V2",
                "CIFAR-10",
                "CIFAR-100",
                "Caltech-101",
                "Flowers",
                "Stanford Cars",
                "CUBS-200",
                "Oxford Pets",
                "Describable Textures Dataset (DTD)",
                "Food-101",
                "FGVC-Aircraft",
                "Places365",
                "SUN397",
                "UCF101",
                "Kinetics400",
                "ImageNet-Rendition",
                "ImageNet-Sketch",
                "EuroSAT",
                "RESISC45"
            ],
            "base_models": [
                "GPT-3.5",
                "Mixtral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fine-Tuning LLaMA for Multi-Stage Text Retrieval": {
        "filename": "Fine-Tuning LLaMA for Multi-Stage Text Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "MS MARCO",
                "BEIR"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "LLaMA-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Clustering Algorithms and RAG Enhancing Semi-Supervised Text Classification with Large LLMs": {
        "filename": "Clustering Algorithms and RAG Enhancing Semi-Supervised Text Classification with Large LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Reuters",
                "Web of Science"
            ],
            "base_models": [
                "Qwen2.5-72B",
                "Qwen2.5-0.5B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Two Stones Hit One Bird Bilevel Positional Encoding for Better Length Extrapolation": {
        "filename": "Two Stones Hit One Bird Bilevel Positional Encoding for Better Length Extrapolation.pdf",
        "analysis": {
            "benchmarks": [
                "PG-19",
                "ArXiv",
                "Github",
                "SCROLLS"
            ],
            "base_models": [
                "Llama 2",
                "BERT",
                "Transformer (12 layers, 768 hidden dimension, 12 attention heads, 155M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Reasoning Capacity of SLM using Cognitive Enhancement": {
        "filename": "Enhancing Reasoning Capacity of SLM using Cognitive Enhancement.pdf",
        "analysis": {
            "benchmarks": [
                "BGL",
                "Thunderbird"
            ],
            "base_models": [
                "LLaMA 2 7B",
                "LLaMA 2 13B",
                "Vicuna 7B",
                "Vicuna 13B"
            ]
        }
    },
    "Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web": {
        "filename": "Exposing Limitations of Language Model Agents in Sequential-Task Compositions on the Web.pdf",
        "analysis": {
            "benchmarks": [
                "CompWoB",
                "MiniWoB"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4",
                "HTML-T5++"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CHOPS CHat with custOmer Profile Systems for Customer Service with LLMs": {
        "filename": "CHOPS CHat with custOmer Profile Systems for Customer Service with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "CPHOS-dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4-0125-preview",
                "GLM-3",
                "LLaMA-2-70b-chat"
            ]
        }
    },
    "ProReason Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom": {
        "filename": "ProReason Multi-Modal Proactive Reasoning with Decoupled Eyesight and Wisdom.pdf",
        "analysis": {
            "benchmarks": [
                "MMMU",
                "MME",
                "MathVista",
                "HallusionBench"
            ],
            "base_models": [
                "Llama3-LLaVA-NeXT-8B",
                "LLaVA-OneVision-Qwen2-7B-OV",
                "Qwen-VL-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Passive learning of active causal strategies in agents and language models": {
        "filename": "Passive learning of active causal strategies in agents and language models.pdf",
        "analysis": {
            "benchmarks": [
                "Causal DAG environment",
                "Odd-one-out environments"
            ],
            "base_models": [
                "TransformerXL",
                "Chinchilla (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Planning Anything with Rigor General-Purpose Zero-Shot Planning with LLM-based Formalized Programming": {
        "filename": "Planning Anything with Rigor General-Purpose Zero-Shot Planning with LLM-based Formalized Programming.pdf",
        "analysis": {
            "benchmarks": [
                "Coffee",
                "Workforce",
                "Facility",
                "Task Allocation",
                "Warehouse",
                "Blocksworld",
                "Mystery Blocksworld",
                "Movie",
                "Gripper"
            ],
            "base_models": [
                "GPT-4o",
                "Claude 3.5 Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Graph-Based Captioning Enhancing Visual Descriptions by Interconnecting Region Captions": {
        "filename": "Graph-Based Captioning Enhancing Visual Descriptions by Interconnecting Region Captions.pdf",
        "analysis": {
            "benchmarks": [
                "Flickr30k",
                "MSCOCO-5k",
                "ImageNet",
                "ADE20K"
            ],
            "base_models": [
                "CLIP ViT-B/16"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "pFedLVM A Large Vision Model LVM-Driven and Latent Feature-Based Personalized Federated Learning Framework in Autonomous Driving": {
        "filename": "pFedLVM A Large Vision Model LVM-Driven and Latent Feature-Based Personalized Federated Learning Framework in Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "Cityscapes",
                "CamVid"
            ],
            "base_models": [
                "iGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automatic Curriculum Expert Iteration for Reliable LLM Reasoning": {
        "filename": "Automatic Curriculum Expert Iteration for Reliable LLM Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "BoardgameQA",
                "MATH",
                "Blocksworld"
            ],
            "base_models": [
                "Llama-3.1-8B-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Democratizing LLMs An Exploration of Cost-Performance Trade-offs in Self-Refined Open-Source Models": {
        "filename": "Democratizing LLMs An Exploration of Cost-Performance Trade-offs in Self-Refined Open-Source Models.pdf",
        "analysis": {
            "benchmarks": [
                "Vicuna benchmark"
            ],
            "base_models": [
                "Vicuna-7B",
                "Vicuna-13B",
                "GPT4X-Alpasta-30B",
                "Guanaco-65B",
                "Airoboros-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mitigating Entity-Level Hallucination in Large Language Models": {
        "filename": "Mitigating Entity-Level Hallucination in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WikiBio GPT-3",
                "2WikiMultihopQA",
                "StrategyQA",
                "NQ"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)"
            ]
        }
    },
    "LLavaGuard VLM-based Safeguards for Vision Dataset Curation and Safety Assessment": {
        "filename": "LLavaGuard VLM-based Safeguards for Vision Dataset Curation and Safety Assessment.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "I2P"
            ],
            "base_models": [
                "Llava-7B",
                "Llava-13B",
                "Llava-34B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AlphaMath Almost Zero process Supervision without process": {
        "filename": "AlphaMath Almost Zero process Supervision without process.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "GaoKao2023",
                "OCWCourses"
            ],
            "base_models": [
                "DeepSeekMath-Base-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieving Multimodal Information for Augmented Generation A Survey": {
        "filename": "Retrieving Multimodal Information for Augmented Generation A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "TVQA+"
            ],
            "base_models": [
                "GPT-3.5",
                "LaMDA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "See Say and Segment Teaching LMMs to Overcome False Premises": {
        "filename": "See Say and Segment Teaching LMMs to Overcome False Premises.pdf",
        "analysis": {
            "benchmarks": [
                "FP-RefCOCO",
                "FP-RefCOCO+",
                "FP-RefCOCOg"
            ],
            "base_models": [
                "LLaVa-v1.5-7B",
                "Segment Anything (SAM)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Impact of Unstated Norms in Bias Analysis of Language Models": {
        "filename": "The Impact of Unstated Norms in Bias Analysis of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SST5",
                "Amazon Dataset",
                "NS-Prompts Dataset",
                "Regard Dataset"
            ],
            "base_models": [
                "RoBERTa-125M",
                "RoBERTa-355M",
                "OPT-125M",
                "OPT-350M",
                "OPT-1.3B",
                "OPT-6.7B",
                "Llama-2-7B",
                "Llama-2-13B",
                "Llama-3-8B",
                "Mistral-7B"
            ]
        }
    },
    "Speculative Knowledge Distillation Bridging the Teacher-Student Gap Through Interleaved Sampling": {
        "filename": "Speculative Knowledge Distillation Bridging the Teacher-Student Gap Through Interleaved Sampling.pdf",
        "analysis": {
            "benchmarks": [
                "Flores-200",
                "DialogSum",
                "GSM8K",
                "UltraInteract",
                "GSM plus",
                "Math",
                "ASDiv",
                "SVAMP"
            ],
            "base_models": [
                "Gemma-7B-IT",
                "Qwen-7B-IT",
                "Gemma-2B",
                "Qwen-0.5B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Thought Reasoning is a Policy Improvement Operator": {
        "filename": "Chain-of-Thought Reasoning is a Policy Improvement Operator.pdf",
        "analysis": {
            "benchmarks": [
                "addition problems up to 29 digits"
            ],
            "base_models": [
                "ByT5 (582M)",
                "ByT5 (300M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "JudgeRank Leveraging Large Language Models for Reasoning-Intensive Reranking": {
        "filename": "JudgeRank Leveraging Large Language Models for Reasoning-Intensive Reranking.pdf",
        "analysis": {
            "benchmarks": [
                "BRIGHT",
                "BEIR"
            ],
            "base_models": [
                "Llama-3.1-70B-instruct",
                "Llama-3.1-8B",
                "Llama-3.1-405B-instruct"
            ]
        }
    },
    "Evaluating General-Purpose AI with Psychometrics": {
        "filename": "Evaluating General-Purpose AI with Psychometrics.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench"
            ],
            "base_models": [
                "ChatGPT",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Racing Thoughts Explaining Large Language Model Contextualization Errors": {
        "filename": "Racing Thoughts Explaining Large Language Model Contextualization Errors.pdf",
        "analysis": {
            "benchmarks": [
                "Polysemous Words (custom dataset based on CoarseWSD)",
                "Facts (custom dataset based on country-capital associations)",
                "Gender Bias (custom dataset based on WinoBias)"
            ],
            "base_models": [
                "Gemini1",
                "Llama-2-13b-chat-hf"
            ]
        }
    },
    "HourVideo 1-Hour Video-Language Understanding": {
        "filename": "HourVideo 1-Hour Video-Language Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "HourVideo"
            ],
            "base_models": [
                "GPT-4",
                "LLaVA-NeXT",
                "Gemini 1.5 Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Demystifying Chains Trees and Graphs of Thoughts": {
        "filename": "Demystifying Chains Trees and Graphs of Thoughts.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "MAWPS",
                "StrategyQA"
            ],
            "base_models": [
                "LLaMA",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interpretable Differential Diagnosis with Dual-Inference Large Language Models": {
        "filename": "Interpretable Differential Diagnosis with Dual-Inference Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Open-XDDx"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4o",
                "Llama3-70B",
                "BioLlama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Integrating chemistry knowledge in large language models via prompt engineering": {
        "filename": "Integrating chemistry knowledge in large language models via prompt engineering.pdf",
        "analysis": {
            "benchmarks": [
                "Custom Chemistry Dataset"
            ],
            "base_models": [
                "gpt-3.5-turbo-1106"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unlocking Structured Thinking in Language Models with Cognitive Prompting": {
        "filename": "Unlocking Structured Thinking in Language Models with Cognitive Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "LLaMA 8B",
                "LLaMA 70B",
                "Gemma 2 9B",
                "Gemma 2 27B",
                "Qwen 7B",
                "Qwen 32B"
            ]
        }
    },
    "LLMs Cannot Reliably Identify and Reason About Security Vulnerabilities Yet A Comprehensive Evaluation Framework and Benchmarks": {
        "filename": "LLMs Cannot Reliably Identify and Reason About Security Vulnerabilities Yet A Comprehensive Evaluation Framework and Benchmarks.pdf",
        "analysis": {
            "benchmarks": [
                "SecLLMHolmes (custom dataset with 228 code scenarios)"
            ],
            "base_models": [
                "GPT-4 (1.76T)",
                "GPT-3.5-turbo-16k (175B)",
                "PaLM2 (340B)",
                "Llama2 (7B, 13B, 34B)",
                "StarCoder+ (15.5B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Memory-augmented Transformers can implement Linear First-Order Optimization Methods": {
        "filename": "Memory-augmented Transformers can implement Linear First-Order Optimization Methods.pdf",
        "analysis": {
            "benchmarks": [
                "random linear regression tasks"
            ],
            "base_models": [
                "Linear Transformers",
                "Memformers"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Meteor Mamba-based Traversal of Rationale for Large Language and Vision Models": {
        "filename": "Meteor Mamba-based Traversal of Rationale for Large Language and Vision Models.pdf",
        "analysis": {
            "benchmarks": [
                "MME",
                "MMB",
                "MathVista",
                "AI2D"
            ],
            "base_models": [
                "InternLM2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Combating Missed Recalls in E-commerce Search A CoT-Prompting Testing Approach": {
        "filename": "Combating Missed Recalls in E-commerce Search A CoT-Prompting Testing Approach.pdf",
        "analysis": {
            "benchmarks": [
                "open access data",
                "real industrial data"
            ],
            "base_models": [
                "GPT-3.5 turbo (over 100B parameters)",
                "GPT-Neo (2.6B parameters)",
                "ChatGLM2 (6B parameters)",
                "Qwen (14B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought": {
        "filename": "Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "LogiQA",
                "MMLU",
                "TruthfulQA",
                "HellaSwag"
            ],
            "base_models": [
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TPTU-v2 Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems": {
        "filename": "TPTU-v2 Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems.pdf",
        "analysis": {
            "benchmarks": [
                "Anonymous Real-world Scenario",
                "ToolBench"
            ],
            "base_models": [
                "InternLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Recovery Prompting Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery": {
        "filename": "Self-Recovery Prompting Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery.pdf",
        "analysis": {
            "benchmarks": [
                "RoboCup@Home 2023",
                "RoboCup Japan Open 2023"
            ],
            "base_models": [
                "GPT-4",
                "Whisper",
                "Detic",
                "CLIP"
            ]
        }
    },
    "Enabling Intelligent Interactions between an Agent and an LLM A Reinforcement Learning Approach": {
        "filename": "Enabling Intelligent Interactions between an Agent and an LLM A Reinforcement Learning Approach.pdf",
        "analysis": {
            "benchmarks": [
                "MiniGrid",
                "Habitat"
            ],
            "base_models": [
                "Vicuna-7b",
                "Vicuna-13b"
            ]
        }
    },
    "Large Language Models for Integrating Social Determinant of Health Data A Case Study on Heart Failure 30-Day Readmission Prediction": {
        "filename": "Large Language Models for Integrating Social Determinant of Health Data A Case Study on Heart Failure 30-Day Readmission Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "AHRQ SDOH Database",
                "NaNDA (National Neighborhood Data Archive)"
            ],
            "base_models": [
                "Llama-2 7B-chat",
                "Llama-2 13B-chat",
                "Llama-2 70B-chat",
                "Gemma 2B-it",
                "Gemma 7B-it",
                "Mistral 7B v0.1 Instruct",
                "Mistral 7B v0.2 Instruct",
                "Flan-T5-XL (3B)",
                "Flan-T5-XXL (11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Large Language Models for Qualitative Analysis can Introduce Serious Bias": {
        "filename": "Using Large Language Models for Qualitative Analysis can Introduce Serious Bias.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset: transcripts of interviews with Rohingya refugees and their hosts in Cox’s Bazaar, Bangladesh"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "Llama-2 (13B)",
                "Llama-2 (13B chat variant)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Real-World WebAgent with Planning Long Context Understanding and Program Synthesis": {
        "filename": "A Real-World WebAgent with Planning Long Context Understanding and Program Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "MiniWoB++",
                "Mind2Web"
            ],
            "base_models": [
                "Flan-U-PaLM (540B)",
                "HTML-T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Safeguarding Crowdsourcing Surveys from ChatGPT with Prompt Injection": {
        "filename": "Safeguarding Crowdsourcing Surveys from ChatGPT with Prompt Injection.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM",
                "PaLM-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for the Automated Analysis of Optimization Algorithms": {
        "filename": "Large Language Models for the Automated Analysis of Optimization Algorithms.pdf",
        "analysis": {
            "benchmarks": [
                "Rastrigin function"
            ],
            "base_models": [
                "GPT-4",
                "Mixtral",
                "Llama 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are LLMs Ready for Real-World Materials Discovery": {
        "filename": "Are LLMs Ready for Real-World Materials Discovery.pdf",
        "analysis": {
            "benchmarks": [
                "Battery Device QA",
                "MaScQA",
                "MatSciNLP",
                "OpticalTable",
                "SustainableConcrete"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging GPT-4 for Automatic Translation Post-Editing": {
        "filename": "Leveraging GPT-4 for Automatic Translation Post-Editing.pdf",
        "analysis": {
            "benchmarks": [
                "WMT-22",
                "WMT-20",
                "WMT-21"
            ],
            "base_models": [
                "GPT-4",
                "gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The CoT Collection Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning": {
        "filename": "The CoT Collection Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench-Hard (BBH)",
                "P3 Evaluation",
                "MGSM",
                "LEDGAR",
                "Case Hold",
                "MedNLI",
                "PubMedQA"
            ],
            "base_models": [
                "Flan-T5 (3B & 11B)",
                "T0 (3B)",
                "mT0 (3B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Divide-and-Conquer Meets Consensus Unleashing the Power of Functions in Code Generation": {
        "filename": "Divide-and-Conquer Meets Consensus Unleashing the Power of Functions in Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "xCodeEval",
                "MATH"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama3 8b",
                "StableCode 3b",
                "CodeLlama 34b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SylloBio-NLI Evaluating Large Language Models on Biomedical Syllogistic Reasoning": {
        "filename": "SylloBio-NLI Evaluating Large Language Models on Biomedical Syllogistic Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "SylloBio-NLI"
            ],
            "base_models": [
                "Gemma-7B",
                "Gemma-7B-it",
                "Meta-Llama-3-8B",
                "Meta-Llama-3-8B-Instruct",
                "Mistral-7B-v0.1",
                "Mistral-7B-Instruct-v0.2",
                "Mixtral-8x7B-Instruct-v0.1",
                "BioMistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EduAgent Generative Student Agents in Learning": {
        "filename": "EduAgent Generative Student Agents in Learning.pdf",
        "analysis": {
            "benchmarks": [
                "EduAgent310",
                "EduAgent705"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA-70B",
                "Gemini Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BlockLLM Multi-tenant Finer-grained Serving for Large Language Models": {
        "filename": "BlockLLM Multi-tenant Finer-grained Serving for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "Vicuna-7B",
                "Chat-GLM-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WILT A Multi-Turn Memorization-Robust Inductive Logic Benchmark for LLMs": {
        "filename": "WILT A Multi-Turn Memorization-Robust Inductive Logic Benchmark for LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "WILT"
            ],
            "base_models": [
                "Claude 3.5 Sonnet",
                "o1-mini 2024-09-12",
                "o1-preview 2024-09-12",
                "chatgpt-4o-latest",
                "Mistral Large 2",
                "GPT-4o 2024-08-06",
                "Llama 3.1 405B",
                "Gemini 1.5 Flash 0827",
                "Llama 3.1 70B",
                "Deepseek-v2.5-chat",
                "GPT-4o-mini",
                "Gemini 1.5 Pro",
                "Gemini 1.5 Flash",
                "Deepseek-v2-coder",
                "Deepseek-v2-chat",
                "Llama 3.1 8b",
                "Open Mistral Nemo",
                "Claude 3 Haiku",
                "Gemini 1.5 Flash 8b 0827",
                "Gemma 2 9B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Software Engineering A Systematic Literature Review": {
        "filename": "Large Language Models for Software Engineering A Systematic Literature Review.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "Stack Overflow"
            ],
            "base_models": [
                "Codex (12B)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Comprehensive Evaluation of Tool-Assisted Generation Strategies": {
        "filename": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "MuSiQue",
                "GSM8K",
                "DROP"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)",
                "Flan-UL2-20B",
                "Flan-PaLM-540B",
                "Flan-PaLM-62B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Benchmarking the Text-to-SQL Capability of Large Language Models A Comprehensive Evaluation": {
        "filename": "Benchmarking the Text-to-SQL Capability of Large Language Models A Comprehensive Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "BIRD",
                "BigTable-0.2k"
            ],
            "base_models": [
                "ChatGPT (gpt-35-turbo-16k)",
                "LLaMa2-Chat-70B",
                "InternLM-70B",
                "InternLM2-20B",
                "Codellama-34B",
                "SQLCoder-34B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interpretable Math Word Problem Solution Generation via Step-by-step Planning": {
        "filename": "Interpretable Math Word Problem Solution Generation via Step-by-step Planning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3 (text-davinci-003)",
                "GPT-2 (117M)",
                "GPT-2-medium (345M)",
                "T5-base (220M)",
                "T5-large (770M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FOLIO Natural Language Reasoning with First-Order Logic": {
        "filename": "FOLIO Natural Language Reasoning with First-Order Logic.pdf",
        "analysis": {
            "benchmarks": [
                "FOLIO"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-13B",
                "LLaMA-70B",
                "GPT-NeoX-20B",
                "BERT-base (110M)",
                "BERT-large (340M)",
                "RoBERTa-base (110M)",
                "RoBERTa-large (340M)",
                "Flan-T5-Large (783M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards A Human-in-the-Loop LLM Approach to Collaborative Discourse Analysis": {
        "filename": "Towards A Human-in-the-Loop LLM Approach to Collaborative Discourse Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "C2STEM dataset"
            ],
            "base_models": [
                "GPT-4-Turbo"
            ]
        }
    },
    "Self-Infilling Code Generation": {
        "filename": "Self-Infilling Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HUMAN EVAL",
                "MBPP",
                "DS-1000",
                "MULTI PL-E",
                "GSM8K"
            ],
            "base_models": [
                "STARCODER (15.5B)",
                "CODE LLAMA (7B)",
                "CODE LLAMA (13B)",
                "CODE LLAMA (34B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PURR Efficiently Editing Language Model Hallucinations by Denoising Language Model Corruptions": {
        "filename": "PURR Efficiently Editing Language Model Hallucinations by Denoising Language Model Corruptions.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions",
                "StrategyQA",
                "QReCC"
            ],
            "base_models": [
                "PALM-540B",
                "LaMBDA"
            ]
        }
    },
    "LLMs Will Always Hallucinate and We Need to Live With This": {
        "filename": "LLMs Will Always Hallucinate and We Need to Live With This.pdf",
        "analysis": {
            "benchmarks": [
                "The Pile"
            ],
            "base_models": [
                "Mamba",
                "Jamba"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Is a Question Decomposition Unit All We Need": {
        "filename": "Is a Question Decomposition Unit All We Need.pdf",
        "analysis": {
            "benchmarks": [
                "HOTPOT QA",
                "DROP",
                "STRATEGY QA",
                "MULTI RC",
                "BREAK",
                "MATHQA",
                "QASC",
                "SVAMP"
            ],
            "base_models": [
                "GPT-3",
                "RoBERTa-base fine-tuned on SQuAD 2.0",
                "RoBERTa-base fine-tuned on BoolQ"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Koala An Index for Quantifying Overlaps with Pre-training Corpora": {
        "filename": "Koala An Index for Quantifying Overlaps with Pre-training Corpora.pdf",
        "analysis": {
            "benchmarks": [
                "OpenBookQA",
                "PIQA"
            ],
            "base_models": [
                "OPT-175B"
            ]
        }
    },
    "Aligning Large Language Models for Clinical Tasks": {
        "filename": "Aligning Large Language Models for Clinical Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "USMLE"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "PaLM (540B)",
                "GPT-4",
                "Med-PaLM 2"
            ]
        }
    },
    "Using Natural Language Explanations to Rescale Human Judgments": {
        "filename": "Using Natural Language Explanations to Rescale Human Judgments.pdf",
        "analysis": {
            "benchmarks": [
                "INQUISITIVE-BROAD"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "Davinci",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Deep Dive Into Large Language Model Code Generation Mistakes What and Why": {
        "filename": "A Deep Dive Into Large Language Model Code Generation Mistakes What and Why.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval-X",
                "CoderEval"
            ],
            "base_models": [
                "GPT-4",
                "Gemini Pro 1.0"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Compromising Embodied Agents with Contextual Backdoor Attacks": {
        "filename": "Compromising Embodied Agents with Contextual Backdoor Attacks.pdf",
        "analysis": {
            "benchmarks": [
                "ProgPrompt",
                "VoxPoser",
                "Visual Programming (VisProg)"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Davinci-002",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DRDT Dynamic Reflection with Divergent Thinking for LLM-based Sequential Recommendation": {
        "filename": "DRDT Dynamic Reflection with Divergent Thinking for LLM-based Sequential Recommendation.pdf",
        "analysis": {
            "benchmarks": [
                "ML-1M",
                "Games",
                "Luxury"
            ],
            "base_models": [
                "Vicuna-7b",
                "Vicuna-13b",
                "Openchat-7b",
                "Longchat-7b",
                "Mistral-7b",
                "GPT-Turbo-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SPROUT an Interactive Authoring Tool for Generating Programming Tutorials with the Visualization of Large Language Models": {
        "filename": "SPROUT an Interactive Authoring Tool for Generating Programming Tutorials with the Visualization of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Large Language Model Aided Program Refinement": {
        "filename": "Towards Large Language Model Aided Program Refinement.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "EvalPlus"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Look Further Ahead Testing the Limits of GPT-4 in Path Planning": {
        "filename": "Look Further Ahead Testing the Limits of GPT-4 in Path Planning.pdf",
        "analysis": {
            "benchmarks": [
                "BabyAI",
                "gSCAN",
                "Custom Benchmark with 25x25 grid environments"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Lifelong Robot Library Learning Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models": {
        "filename": "Lifelong Robot Library Learning Bootstrapping Composable and Generalizable Skills for Embodied Control with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Ravens manipulation suite (blocks-and-bowls setup)"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "text-embedding-ada-002"
            ]
        }
    },
    "Language Models in the Loop Incorporating Prompting into Weak Supervision": {
        "filename": "Language Models in the Loop Incorporating Prompting into Weak Supervision.pdf",
        "analysis": {
            "benchmarks": [],
            "models": [],
            "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
        }
    },
    "To the Globe TTG Towards Language-Driven Guaranteed Travel Planning": {
        "filename": "To the Globe TTG Towards Language-Driven Guaranteed Travel Planning.pdf",
        "analysis": {
            "benchmarks": [
                "TravelPlanner dataset",
                "custom synthetic dataset"
            ],
            "base_models": [
                "Llama-3 70B"
            ]
        }
    },
    "TPE Towards Better Compositional Reasoning over Conceptual Tools with Multi-persona Collaboration": {
        "filename": "TPE Towards Better Compositional Reasoning over Conceptual Tools with Multi-persona Collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "FoCus",
                "CIMA",
                "PsyQA"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0613)",
                "GPT-4 (gpt-4-0613)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning Elicitation in Language Models via Counterfactual Feedback": {
        "filename": "Reasoning Elicitation in Language Models via Counterfactual Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "Phi3 Mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Twitter to Reasoner Understand Mobility Travel Modes and Sentiment Using Large Language Models": {
        "filename": "From Twitter to Reasoner Understand Mobility Travel Modes and Sentiment Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom Twitter dataset (NYC, 2020-2022)"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama2-7B",
                "Mistral-7B"
            ]
        }
    },
    "QUITO Accelerating Long-Context Reasoning through Query-Guided Context Compression": {
        "filename": "QUITO Accelerating Long-Context Reasoning through Query-Guided Context Compression.pdf",
        "analysis": {
            "benchmarks": [
                "NaturalQuestions",
                "ASQA"
            ],
            "base_models": [
                "LongChat-13B-16k",
                "Qwen2-0.5B-Instruct"
            ]
        }
    },
    "Symbolic Equation Solving via Reinforcement Learning": {
        "filename": "Symbolic Equation Solving via Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "lin-crat-N1000"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Temporal Data Meets LLM - Explainable Financial Time Series Forecasting": {
        "filename": "Temporal Data Meets LLM - Explainable Financial Time Series Forecasting.pdf",
        "analysis": {
            "benchmarks": [
                "NASDAQ-100 stock price data"
            ],
            "base_models": [
                "GPT-4",
                "Open LLaMA (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Estimating the Hallucination Rate of Generative AI": {
        "filename": "Estimating the Hallucination Rate of Generative AI.pdf",
        "analysis": {
            "benchmarks": [
                "AG News",
                "SST2",
                "Subjectivity",
                "Medical QP",
                "RTE",
                "WNLI"
            ],
            "base_models": [
                "Llama-2-7B",
                "Gemma-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SPL A Socratic Playground for Learning Powered by Large Language Model": {
        "filename": "SPL A Socratic Playground for Learning Powered by Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "essay writing tasks"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Lissard Long and Simple Sequential Reasoning Datasets": {
        "filename": "Lissard Long and Simple Sequential Reasoning Datasets.pdf",
        "analysis": {
            "benchmarks": [
                "Lissard"
            ],
            "base_models": [
                "Mistral-7B",
                "Mixtral-8x7B",
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Redefining Information Retrieval of Structured Database via Large Language Models": {
        "filename": "Redefining Information Retrieval of Structured Database via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom financial domain dataset"
            ],
            "base_models": [
                "Chinese-Alpaca-33B-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks": {
        "filename": "A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "SVAMP",
                "ASDiv",
                "AQuA",
                "MAWPS",
                "Game of 24",
                "MultiArith",
                "Multi-Step Arithmetic",
                "AddSub",
                "SingleEq",
                "GSM-HARD",
                "SingleOp",
                "MathQA",
                "Word Sorting",
                "Logical Deduction",
                "Temporal Sequences",
                "Formal Fallacies",
                "Mini Crosswords",
                "Tracking Shuffled Objects",
                "Object Counting",
                "Boolean Expressions",
                "Web of Lies",
                "Dyck Languages",
                "Geometric Shapes"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "PaLM 2-L",
                "PaLM 2-S",
                "GPT-3 (Text-Davinci-002)",
                "LaMDA-137B",
                "PaLM-540B",
                "UL2-20B",
                "Codex (Code-Davinci-002)",
                "Codex (Code-Davinci-001)",
                "Vicuna-7B",
                "Vicuna-13B",
                "Vicuna-33B",
                "CodeGen (Codegen-16B-Multi)",
                "CodeGen (Codegen-16B-Mono)",
                "CodeT5+",
                "Xgen",
                "Minerva-540B",
                "InstructGPT (Text-Davinci-003)",
                "DiVeRSe"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ShapeGrasp Zero-Shot Task-Oriented Grasping with Large Language Models through Geometric Decomposition": {
        "filename": "ShapeGrasp Zero-Shot Task-Oriented Grasping with Large Language Models through Geometric Decomposition.pdf",
        "analysis": {
            "benchmarks": [
                "LERF-TOGO dataset (inspired)",
                "Custom dataset of 38 objects across 12 categories and 49 tasks"
            ],
            "base_models": [
                "GPT-4",
                "Starling"
            ]
        }
    },
    "A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options": {
        "filename": "A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options.pdf",
        "analysis": {
            "benchmarks": [
                "custom 100-question radiation oncology physics exam"
            ],
            "base_models": [
                "OpenAI o1-preview",
                "GPT-4o",
                "LLaMA 3.1 (405B)",
                "Gemini 1.5 Pro",
                "Claude 3.5 Sonnet"
            ]
        }
    },
    "LLMs and the Abstraction and Reasoning Corpus Successes Failures and the Importance of Object-based Representations": {
        "filename": "LLMs and the Abstraction and Reasoning Corpus Successes Failures and the Importance of Object-based Representations.pdf",
        "analysis": {
            "benchmarks": [
                "ARC",
                "1D-ARC",
                "Mini-ARC"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLAMA-2 (13B)",
                "LLAMA-2 (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LESS Selecting Influential Data for Targeted Instruction Tuning": {
        "filename": "LESS Selecting Influential Data for Targeted Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "TYDIQA",
                "BBH"
            ],
            "base_models": [
                "LLAMA-2-7B",
                "LLAMA-2-13B",
                "MISTRAL-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Graph of Records Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs": {
        "filename": "Graph of Records Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "AcademicEval",
                "QMSum",
                "WCEP",
                "BookSum"
            ],
            "base_models": [
                "LLaMA-2-7b-chat",
                "Mixtral-8x7B-Instruct-v0.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Teaching Arithmetic to Small Transformers": {
        "filename": "Teaching Arithmetic to Small Transformers.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "NanoGPT (10.6 million parameters)",
                "GPT-2",
                "GPT-3 (davinci)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatSpamDetector Leveraging Large Language Models for Effective Phishing Email Detection": {
        "filename": "ChatSpamDetector Leveraging Large Language Models for Effective Phishing Email Detection.pdf",
        "analysis": {
            "benchmarks": [
                "phishing_pot",
                "CSDMC SPAM corpus"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "Llama2-70B",
                "Gemini Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reflective Instruction Tuning Mitigating Hallucinations in Large Vision-Language Models": {
        "filename": "Reflective Instruction Tuning Mitigating Hallucinations in Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "POPE",
                "MME",
                "MMBench",
                "GQA",
                "ScienceQA"
            ],
            "base_models": [
                "LLaVA-1.0-7b-lora",
                "LLaVA-1.5-7b-lora"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Large Language Model-Based Game Agents": {
        "filename": "A Survey on Large Language Model-Based Game Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Zork Series",
                "ScienceWorld",
                "ALFWorld",
                "Diplomacy",
                "Werewolf",
                "StarCraft II",
                "Pokémon Battles",
                "Overcooked",
                "Minecraft",
                "Crafter",
                "Red Dead Redemption 2 (RDR2)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "GPT-4V",
                "PaLM",
                "BART",
                "OPT-1.3B",
                "LLaMA-13B",
                "LLaMA-2-70B",
                "MPT-7B",
                "RedPajama-3B",
                "ChatGLM-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Large Language Models on Generative Graph Analytics Query Learning and Applications": {
        "filename": "A Survey of Large Language Models on Generative Graph Analytics Query Learning and Applications.pdf",
        "analysis": {
            "benchmarks": [
                "obgn-arxiv",
                "Aminer"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "IPEval A Bilingual Intellectual Property Agency Consultation Evaluation Benchmark for Large Language Models": {
        "filename": "IPEval A Bilingual Intellectual Property Agency Consultation Evaluation Benchmark for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "IPEval"
            ],
            "base_models": [
                "GPT-4",
                "Qwen-7B-Chat",
                "Qwen-72B-Chat",
                "Qwen1.5-14B-Chat",
                "Qwen-Max",
                "Baichuan2-7B-Chat",
                "Baichuan2-13B-Chat",
                "ChatGLM3-6B",
                "GLM-3-turbo",
                "GLM-4",
                "fuzi-mingcha-v1 (based on ChatGLM-6B)",
                "MoZi-glm (based on ChatGLM)",
                "MoZi-bloomz (based on BLOOMZ)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DBCopilot Scaling Natural Language Querying to Massive Databases": {
        "filename": "DBCopilot Scaling Natural Language Querying to Massive Databases.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "Bird",
                "Fiben",
                "Spider syn",
                "Spider real"
            ],
            "base_models": [
                "T5-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Individual to Society A Survey on Social Simulation Driven by Large Language Model-based Agents": {
        "filename": "From Individual to Society A Survey on Social Simulation Driven by Large Language Model-based Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Sotopia",
                "Elicitron",
                "APAM",
                "SimuLife++",
                "Self-Emotion",
                "ICL-AIF",
                "FORD",
                "MAD",
                "ChatEval",
                "AutoGen",
                "AmazonHistoryPrice",
                "DoG",
                "ChatLLM",
                "xu et al.",
                "ReCon",
                "MachineSoM",
                "AvalonBench",
                "lan et al.",
                "xu et al.",
                "ThinkThrice",
                "CodeAct",
                "wu et al.",
                "WWQA",
                "PLAYER",
                "GITM",
                "sreedhar et al.",
                "AmongAgents",
                "S-Agents",
                "VIDS",
                "DR-CoT",
                "ChatGPT Research Group",
                "MedAgents",
                "MARG",
                "AI Hospital",
                "REVIEWER2",
                "CosmoAgent",
                "FPS",
                "ResearchAgent",
                "Agent Hospital",
                "CulturePark",
                "SynthPAI",
                "DreamFactory",
                "AutoTQA",
                "DERA",
                "Self-collaboration",
                "ChatDev",
                "MetaGPT",
                "Experiential Co-Learning",
                "AutoCodeRover",
                "IER",
                "Blind Judgement",
                "TradingGPT",
                "Information Bazaar",
                "SimuCourt",
                "MATHVC",
                "baker et al.",
                "LawLuo",
                "MAIC",
                "CAMEL",
                "SwiftSage",
                "Multi-Agent Collaboration",
                "CoELA",
                "RoCo",
                "AgentVerse",
                "Scalable",
                "AutoAgents",
                "OpenAgents",
                "TWOSOME",
                "ReAd",
                "MACNET"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "ChatGPT",
                "BERT",
                "RoBERTa",
                "T5",
                "BLOOM",
                "LLaMA",
                "PaLM",
                "Claude",
                "Anthropic",
                "Cohere",
                "Mistral",
                "Falcon",
                "Custom models based on GPT-3",
                "Custom models based on BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Empower Nested Boolean Logic via Self-Supervised Curriculum Learning": {
        "filename": "Empower Nested Boolean Logic via Self-Supervised Curriculum Learning.pdf",
        "analysis": {
            "benchmarks": [
                "BoolKill",
                "ReClor",
                "DREAM"
            ],
            "base_models": [
                "DeBERTa-V3-base",
                "DeBERTa-V3-large",
                "ChatGPT",
                "GPT2-1.5b",
                "OPT-7b",
                "LLaMA2-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Quantized Delta Weight Is Safety Keeper": {
        "filename": "Quantized Delta Weight Is Safety Keeper.pdf",
        "analysis": {
            "benchmarks": [
                "PKUBeaver",
                "TriviaQA"
            ],
            "base_models": [
                "Llama-2-7b-chat",
                "Llama-2-13b-chat",
                "Mistral-7b-Instruct",
                "Qwen2-7b-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VideoGUI A Benchmark for GUI Automation from Instructional Videos": {
        "filename": "VideoGUI A Benchmark for GUI Automation from Instructional Videos.pdf",
        "analysis": {
            "benchmarks": [
                "VideoGUI"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RALL-E Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis": {
        "filename": "RALL-E Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "LibriSpeech test-clean",
                "50 hard sentences from Ren et al."
            ],
            "base_models": [
                "VALL-E (based on a decoder-only Transformer architecture)"
            ]
        }
    },
    "On the Biased Assessment of Expert Finding Systems": {
        "filename": "On the Biased Assessment of Expert Finding Systems.pdf",
        "analysis": {
            "benchmarks": [
                "TU Expert Collection"
            ],
            "base_models": [
                "ColBERT-XM"
            ]
        }
    },
    "Extending Token Computation for LLM Reasoning": {
        "filename": "Extending Token Computation for LLM Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "PIQA",
                "SIQA"
            ],
            "base_models": [
                "LLaMA-2 7B",
                "LLaMA-2 13B"
            ]
        }
    },
    "Unveiling Scoring Processes Dissecting the Differences between LLMs and Human Graders in Automatic Scoring": {
        "filename": "Unveiling Scoring Processes Dissecting the Differences between LLMs and Human Graders in Automatic Scoring.pdf",
        "analysis": {
            "benchmarks": [
                "custom science education dataset"
            ],
            "base_models": [
                "Mixtral-8x7B-instruct (47B)"
            ]
        }
    },
    "SPADE Synthesizing Data Quality Assertions for Large Language Model Pipelines": {
        "filename": "SPADE Synthesizing Data Quality Assertions for Large Language Model Pipelines.pdf",
        "analysis": {
            "benchmarks": [
                "LangChain Hub pipelines",
                "Kaggle datasets for finance and lecture summaries"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Research on the Application of Large Language Models in Automatic Question Generation A Case Study of ChatGLM in the Context of High School Information Technology Curriculum": {
        "filename": "Research on the Application of Large Language Models in Automatic Question Generation A Case Study of ChatGLM in the Context of High School Information Technology Curriculum.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGLM"
            ]
        }
    },
    "Towards Better Evaluation of Instruction-Following A Case-Study in Summarization": {
        "filename": "Towards Better Evaluation of Instruction-Following A Case-Study in Summarization.pdf",
        "analysis": {
            "benchmarks": [
                "riSum"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM 2-S",
                "PaLM 2-L",
                "F-PaLM 2-S",
                "F-PaLM 2-L",
                "F-PaLM 2-Sc",
                "F-PaLM 2-Lc"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automated Theorem Provers Help Improve Large Language Model Reasoning": {
        "filename": "Automated Theorem Provers Help Improve Large Language Model Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "PRONTOQA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Gemini-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Optimizing Adaptive Attacks against Content Watermarks for Language Models": {
        "filename": "Optimizing Adaptive Attacks against Content Watermarks for Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Exp",
                "Dist-Shift",
                "Binary",
                "Inverse"
            ],
            "base_models": [
                "Llama2-7b",
                "Llama3.1-70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Diverse In-Context Configurations for Image Captioning": {
        "filename": "Exploring Diverse In-Context Configurations for Image Captioning.pdf",
        "analysis": {
            "benchmarks": [
                "MSCOCO"
            ],
            "base_models": [
                "Flamingo",
                "Open-Flamingo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "KG-RAG Bridging the Gap Between Knowledge and Creativity": {
        "filename": "KG-RAG Bridging the Gap Between Knowledge and Creativity.pdf",
        "analysis": {
            "benchmarks": [
                "ComplexWebQuestions"
            ],
            "base_models": [
                "GPT-4 Turbo 1106-Preview"
            ]
        }
    },
    "TMGBench A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs": {
        "filename": "TMGBench A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "TMGB ENCH"
            ],
            "base_models": [
                "gpt-4o",
                "gpt-4o-mini",
                "gpt-3.5-turbo",
                "claude-3-5-sonnet",
                "claude-3-haiku",
                "Llama-3.1-70B",
                "Llama-3.1-8B",
                "Qwen2-72B",
                "o1-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Testing LLMs on Code Generation with Varying Levels of Prompt Specificity": {
        "filename": "Testing LLMs on Code Generation with Varying Levels of Prompt Specificity.pdf",
        "analysis": {
            "benchmarks": [
                "Custom benchmark of 104 coding problems"
            ],
            "base_models": [
                "Bard",
                "ChatGPT-3.5",
                "ChatGPT-4",
                "Claude-2"
            ]
        }
    },
    "Can Large Language Models Be Good Companions": {
        "filename": "Can Large Language Models Be Good Companions.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-controller Controlling LLMs with Multi-round Step-by-step Self-awareness": {
        "filename": "Self-controller Controlling LLMs with Multi-round Step-by-step Self-awareness.pdf",
        "analysis": {
            "benchmarks": [
                "webis/tldr-17",
                "argilla/news-summary",
                "ccdv/arxiv-summarization"
            ],
            "base_models": [
                "GLM-4-air",
                "GLM-4-flash",
                "GPT-4o",
                "GPT-4o-mini",
                "GPT-3.5-turbo",
                "Deepseek-V2"
            ]
        }
    },
    "A Preliminary Roadmap for LLMs as Assistants in Exploring Analyzing and Visualizing Knowledge Graphs": {
        "filename": "A Preliminary Roadmap for LLMs as Assistants in Exploring Analyzing and Visualizing Knowledge Graphs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Metacognitive Retrieval-Augmented Large Language Models": {
        "filename": "Metacognitive Retrieval-Augmented Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "2WikiMultiHopQA"
            ],
            "base_models": [
                "gpt-35-turbo-16k",
                "T5-large",
                "T5-XXL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On Limitation of Transformer for Learning HMMs": {
        "filename": "On Limitation of Transformer for Learning HMMs.pdf",
        "analysis": {
            "benchmarks": [
                "Random HMM",
                "Linear Dynamical System (LDS)",
                "CyclicHMM-DET",
                "CyclicHMM-RND",
                "CyclicHMM-HARD"
            ],
            "base_models": [
                "Transformer",
                "Recurrent Neural Network (RNN)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Looming Replication Crisis in Evaluating Behavior in Language Models Evidence and Solutions": {
        "filename": "A Looming Replication Crisis in Evaluating Behavior in Language Models Evidence and Solutions.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "CRT",
                "NumGLUE",
                "ScienceQA",
                "StrategyQA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4o",
                "Gemini 1.5 Pro",
                "Claude 3 Opus",
                "Llama 3-8B",
                "Llama 3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Approach to Solving the Abstraction and Reasoning Corpus ARC Challenge": {
        "filename": "An Approach to Solving the Abstraction and Reasoning Corpus ARC Challenge.pdf",
        "analysis": {
            "benchmarks": [
                "ARC Challenge"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "A Unified Approach to Emotion Detection and Task-Oriented Dialogue Modeling": {
        "filename": "A Unified Approach to Emotion Detection and Task-Oriented Dialogue Modeling.pdf",
        "analysis": {
            "benchmarks": [
                "EmoWOZ"
            ],
            "base_models": [
                "GPT-2",
                "Llama-2"
            ]
        }
    },
    "Can LLMs Understand Computer Networks Towards a Virtual System Administrator": {
        "filename": "Can LLMs Understand Computer Networks Towards a Virtual System Administrator.pdf",
        "analysis": {
            "benchmarks": [
                "WebServer",
                "Routers",
                "Intradomain"
            ],
            "base_models": [
                "GPT-4 (1756B parameters)",
                "GPT-3.5 (175B parameters)",
                "Llama 2 (13B parameters)",
                "Mistral Instruct v0.2 (7B parameters)",
                "BASH Coder Mistral (7B parameters)"
            ]
        }
    },
    "In-Context Learning with Iterative Demonstration Selection": {
        "filename": "In-Context Learning with Iterative Demonstration Selection.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "BoolQ",
                "AGNews",
                "GSM8K",
                "MATH",
                "LogiQA"
            ],
            "base_models": [
                "GPT-3.5 (gpt-3.5-turbo)",
                "GPT-4",
                "Llama-2-chat (7B, 13B, 70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DAG-Plan Generating Directed Acyclic Dependency Graphs for Dual-Arm Cooperative Planning": {
        "filename": "DAG-Plan Generating Directed Acyclic Dependency Graphs for Dual-Arm Cooperative Planning.pdf",
        "analysis": {
            "benchmarks": [
                "Dual-Arm Kitchen Benchmark"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SCITAB A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables": {
        "filename": "SCITAB A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables.pdf",
        "analysis": {
            "benchmarks": [
                "SCITAB"
            ],
            "base_models": [
                "GPT-4",
                "InstructGPT (175B)",
                "TAPAS-large (340M)",
                "TAPEX-large (400M)",
                "TAPEX-Zero-large (780M)",
                "TAPEX-Zero-XL (3B)",
                "Flan-T5-base (250M)",
                "Flan-T5-large (780M)",
                "Flan-T5-XL (3B)",
                "Flan-T5-XXL (11B)",
                "Alpaca-7B (7B)",
                "Vicuna-7B (7B)",
                "Vicuna-13B (13B)",
                "LLaMA-7B (7B)",
                "LLaMA-13B (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Take the Bull by the Horns Hard Sample-Reweighted Continual Training Improves LLM Generalization": {
        "filename": "Take the Bull by the Horns Hard Sample-Reweighted Continual Training Improves LLM Generalization.pdf",
        "analysis": {
            "benchmarks": [
                "ARC-C",
                "HellaSwag",
                "PiQA",
                "WinoGrande",
                "BoolQ",
                "MMLU"
            ],
            "base_models": [
                "OPT-125M",
                "OPT-350M",
                "Sheared-LLaMA-1.3B",
                "LLaMA-v2-7B"
            ]
        }
    },
    "Can LLM Already Serve as A Database Interface A BIg Bench for Large-Scale Database Grounded Text-to-SQLs": {
        "filename": "Can LLM Already Serve as A Database Interface A BIg Bench for Large-Scale Database Grounded Text-to-SQLs.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "WikiSQL",
                "BIRD"
            ],
            "base_models": [
                "GPT-4 (gpt-4-32k)",
                "Claude-2 (claude-2.0)",
                "ChatGPT (gpt-3.5-turbo)",
                "T5-Base",
                "T5-Large",
                "T5-3B",
                "Palm-2 (text-bison-001)",
                "Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Thinking in Space How Multimodal Large Language Models See Remember and Recall Spaces": {
        "filename": "Thinking in Space How Multimodal Large Language Models See Remember and Recall Spaces.pdf",
        "analysis": {
            "benchmarks": [
                "VSI-Bench"
            ],
            "base_models": [
                "Gemini-1.5",
                "GPT-4o",
                "InternVL2-2B",
                "InternVL2-8B",
                "InternVL2-40B",
                "LongVILA-8B",
                "VILA-1.5-8B",
                "VILA-1.5-40B",
                "LongVA-7B",
                "LLaVA-NeXT-Video-7B",
                "LLaVA-NeXT-Video-72B",
                "LLaVA-OneVision-0.5B",
                "LLaVA-OneVision-7B",
                "LLaVA-OneVision-72B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Less is More Summary of Long Instructions is Better for Program Synthesis": {
        "filename": "Less is More Summary of Long Instructions is Better for Program Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "APPS",
                "CodeContests"
            ],
            "base_models": [
                "Codex (GPT-based)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Domain Specialization as the Key to Make Large Language Models Disruptive A Comprehensive Survey": {
        "filename": "Domain Specialization as the Key to Make Large Language Models Disruptive A Comprehensive Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175B parameters)",
                "PaLM (540B parameters)",
                "LLaMA (65B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoML-GPT Automatic Machine Learning with GPT": {
        "filename": "AutoML-GPT Automatic Machine Learning with GPT.pdf",
        "analysis": {
            "benchmarks": [
                "MiniImageNet",
                "COCO",
                "Natural Questions Open",
                "UCI Adult"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "Flan-T5",
                "PaLM",
                "ViT base model",
                "Swin Transformer",
                "DPR (Dense Passage Retrieval)",
                "XGBoost"
            ]
        }
    },
    "Keypoint-based Progressive Chain-of-Thought Distillation for LLMs": {
        "filename": "Keypoint-based Progressive Chain-of-Thought Distillation for LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "ASDiv",
                "SVAMP",
                "CommonsenseQA"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "LLaMA-7B (7B)",
                "FlanT5-XL (3B)",
                "FlanT5-Large (760M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Parse Trees Guided LLM Prompt Compression": {
        "filename": "Parse Trees Guided LLM Prompt Compression.pdf",
        "analysis": {
            "benchmarks": [
                "BBCnews",
                "arXiv",
                "truncate arXiv",
                "HotpotQA",
                "GSM8K"
            ],
            "base_models": [
                "Mixtral-8x7B",
                "Llama3-70B",
                "Qwen2-72B",
                "Llama2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Foundation Models for Mixed Integer Linear Programming": {
        "filename": "Towards Foundation Models for Mixed Integer Linear Programming.pdf",
        "analysis": {
            "benchmarks": [
                "MIPLIB"
            ],
            "base_models": [
                "GPT-4",
                "Graph Neural Networks (GNNs)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating GPT-3 Generated Explanations for Hateful Content Moderation": {
        "filename": "Evaluating GPT-3 Generated Explanations for Hateful Content Moderation.pdf",
        "analysis": {
            "benchmarks": [
                "HateXplain"
            ],
            "base_models": [
                "GPT-3"
            ]
        }
    },
    "Merging Improves Self-Critique Against Jailbreak Attacks": {
        "filename": "Merging Improves Self-Critique Against Jailbreak Attacks.pdf",
        "analysis": {
            "benchmarks": [
                "Harmful Behaviors dataset from AdvBench",
                "dataset from Shen et al. (2023)"
            ],
            "base_models": [
                "Mistral-7B-Instruct",
                "Mixtral-8x7B-Instruct",
                "Prometheus-v2.0"
            ]
        }
    },
    "Compositional Capabilities of Autoregressive Transformers A Study on Synthetic Interpretable Tasks": {
        "filename": "Compositional Capabilities of Autoregressive Transformers A Study on Synthetic Interpretable Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic data-generating process"
            ],
            "base_models": [
                "nanoGPT (12 layers)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Physically Grounded Vision-Language Models for Robotic Manipulation": {
        "filename": "Physically Grounded Vision-Language Models for Robotic Manipulation.pdf",
        "analysis": {
            "benchmarks": [
                "PHYSOBJECTS"
            ],
            "base_models": [
                "InstructBLIP (FlanT5-XXL)",
                "PaLM-E"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model Guided Tree-of-Thought": {
        "filename": "Large Language Model Guided Tree-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "custom Sudoku puzzle benchmarks"
            ],
            "base_models": [
                "GPT-4",
                "gpt-3.5-turbo"
            ]
        }
    },
    "Biomedical knowledge graph-optimized prompt generation for large language models": {
        "filename": "Biomedical knowledge graph-optimized prompt generation for large language models.pdf",
        "analysis": {
            "benchmarks": [
                "True/False dataset",
                "MCQ dataset"
            ],
            "base_models": [
                "Llama-2-13b",
                "GPT-3.5-Turbo",
                "GPT-4"
            ]
        }
    },
    "TypeDance Creating Semantic Typographic Logos from Image through Personalized Generation": {
        "filename": "TypeDance Creating Semantic Typographic Logos from Image through Personalized Generation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Instruct GPT-3 (davinci-002)",
                "BLIP",
                "CLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DualFocus Integrating Macro and Micro Perspectives in Multi-modal Large Language Models": {
        "filename": "DualFocus Integrating Macro and Micro Perspectives in Multi-modal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SEED",
                "MMBench",
                "GQA",
                "TextVQA",
                "POPE"
            ],
            "base_models": [
                "LLaVA-1.5 (7B and 13B)",
                "Qwen-VL-Chat (7B)"
            ]
        }
    },
    "EarthPT a time series foundation model for Earth Observation": {
        "filename": "EarthPT a time series foundation model for Earth Observation.pdf",
        "analysis": {
            "benchmarks": [
                "ClearSky test set (January 2023 to May 2023)"
            ],
            "base_models": [
                "EarthPT-700M (700 million parameters)"
            ]
        }
    },
    "Uncovering mesa-optimization algorithms in Transformers": {
        "filename": "Uncovering mesa-optimization algorithms in Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic sequence modeling tasks"
            ],
            "base_models": [
                "Transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automated User Story Generation with Test Case Specification Using Large Language Model": {
        "filename": "Automated User Story Generation with Test Case Specification Using Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "RUST survey"
            ],
            "base_models": [
                "GPT-4.0"
            ]
        }
    },
    "SlideVQA A Dataset for Document Visual Question Answering on Multiple Images": {
        "filename": "SlideVQA A Dataset for Document Visual Question Answering on Multiple Images.pdf",
        "analysis": {
            "benchmarks": [
                "SlideVQA"
            ],
            "base_models": [
                "T5",
                "LayoutLMv2",
                "LayoutT5",
                "FiD"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CCA Collaborative Competitive Agents for Image Editing": {
        "filename": "CCA Collaborative Competitive Agents for Image Editing.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "LLaVA-1.5"
            ]
        }
    },
    "Adaptive Memory Replay for Continual Learning": {
        "filename": "Adaptive Memory Replay for Continual Learning.pdf",
        "analysis": {
            "benchmarks": [
                "DomainNet",
                "Medical MNIST",
                "Synthetic Visual Concepts",
                "5-task Causal Language Modeling benchmark"
            ],
            "base_models": [
                "Vision Masked Autoencoder (MAE) pre-trained on ImageNet-1K",
                "LLaMA (7 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Model-Enhanced LLM-Driven VUI Testing of VPA Apps": {
        "filename": "Model-Enhanced LLM-Driven VUI Testing of VPA Apps.pdf",
        "analysis": {
            "benchmarks": [
                "4,000 real-world Alexa skills"
            ],
            "base_models": [
                "GPT-4",
                "Llama2-70b-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Double Jeopardy and Climate Impact in the Use of Large Language Models Socio-economic Disparities and Reduced Utility for Non-English Speakers": {
        "filename": "Double Jeopardy and Climate Impact in the Use of Large Language Models Socio-economic Disparities and Reduced Utility for Non-English Speakers.pdf",
        "analysis": {
            "benchmarks": [
                "FLORES-200",
                "FLORES+"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NourishNet Proactive Severity State Forecasting of Food Commodity Prices for Global Warning Systems": {
        "filename": "NourishNet Proactive Severity State Forecasting of Food Commodity Prices for Global Warning Systems.pdf",
        "analysis": {
            "benchmarks": [
                "FAO Warning Labels"
            ],
            "base_models": [
                "Transformer",
                "DistilRoBERTa"
            ]
        }
    },
    "Latent State Estimation Helps UI Agents to Reason": {
        "filename": "Latent State Estimation Helps UI Agents to Reason.pdf",
        "analysis": {
            "benchmarks": [
                "PixelHelp",
                "AndroidInTheWild",
                "Android-50"
            ],
            "base_models": [
                "PaLM 2 text-unicorn"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reliable Academic Conference Question Answering A Study Based on Large Language Model": {
        "filename": "Reliable Academic Conference Question Answering A Study Based on Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "ConferenceQA"
            ],
            "base_models": [
                "Bloom-7B",
                "GPT-J-6B",
                "Flan-T5-xl",
                "Flan-T5-xxl",
                "LLaMA2-7B",
                "LLaMA2-13B",
                "Mistral-7B",
                "GPT-3.5-turbo"
            ]
        }
    },
    "ZARA Improving Few-Shot Self-Rationalization for Small Language Models": {
        "filename": "ZARA Improving Few-Shot Self-Rationalization for Small Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "FEB"
            ],
            "base_models": [
                "UNIFIED QA-base (200M)",
                "UNIFIED QA-large (770M)",
                "UNIFIED QA-3B (2.7B)"
            ]
        }
    },
    "MSc-SQL Multi-Sample Critiquing Small Language Models For Text-To-SQL Translation": {
        "filename": "MSc-SQL Multi-Sample Critiquing Small Language Models For Text-To-SQL Translation.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "BIRD"
            ],
            "base_models": [
                "Mistral-7B",
                "Llama-3-8B",
                "Gemma-2-9B"
            ]
        }
    },
    "Optimizing Performance How Compact Models Match or Exceed GPTs Classification Capabilities through Fine-Tuning": {
        "filename": "Optimizing Performance How Compact Models Match or Exceed GPTs Classification Capabilities through Fine-Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "custom market-based dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "FinBERT",
                "FinDRoBERTa",
                "DistilRoBERTa"
            ]
        }
    },
    "Thrust Adaptively Propels Large Language Models with External Knowledge": {
        "filename": "Thrust Adaptively Propels Large Language Models with External Knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "AG-News",
                "e-SNLI",
                "StrategyQA",
                "CIKQA",
                "BoolQ",
                "ARC-E",
                "ARC-C",
                "HotpotQA",
                "Natural Questions (NQ)",
                "Web Questions",
                "Curated TREC",
                "TriviaQA"
            ],
            "base_models": [
                "T5",
                "GPT-J",
                "OPT",
                "UnifiedQA (based on T5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Analogist Out-of-the-box Visual In-Context Learning with Image Diffusion Model": {
        "filename": "Analogist Out-of-the-box Visual In-Context Learning with Image Diffusion Model.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "LOL",
                "InstructPix2Pix",
                "UBC-Fashion",
                "ScanNet",
                "DAVIS"
            ],
            "base_models": [
                "Stable Diffusion Inpainting",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unsolvable Problem Detection Evaluating Trustworthiness of Vision Language Models": {
        "filename": "Unsolvable Problem Detection Evaluating Trustworthiness of Vision Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MM-AAD Bench",
                "MM-IASD Bench",
                "MM-IVQD Bench"
            ],
            "base_models": [
                "LLaVA-1.5-13B",
                "CogVLM-17B",
                "Qwen-VL-Chat",
                "LLaVA-NeXT-13B",
                "LLaVA-NeXT-34B",
                "Gemini-Pro",
                "GPT-4V(ision)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models be Good Path Planners A Benchmark and Investigation on Spatial-temporal Reasoning": {
        "filename": "Can Large Language Models be Good Path Planners A Benchmark and Investigation on Spatial-temporal Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "PathPlanning from Natural Language (PPNL)"
            ],
            "base_models": [
                "GPT-4",
                "BART",
                "T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NLEBenchNorGLM A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian": {
        "filename": "NLEBenchNorGLM A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian.pdf",
        "analysis": {
            "benchmarks": [
                "NLEBench",
                "NO-ConvAI2",
                "NO-CNN/DailyMail",
                "NO-Alpaca-Plus",
                "NO-Multi-QA-Sum",
                "NO-CrowS-Pairs"
            ],
            "base_models": [
                "NorGPT-369M",
                "NorGPT-3B",
                "NorGPT-23B",
                "NorLlama-3B",
                "NB-GPT-J-6B",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AD-H Autonomous Driving with Hierarchical Agents": {
        "filename": "AD-H Autonomous Driving with Hierarchical Agents.pdf",
        "analysis": {
            "benchmarks": [
                "LangAuto",
                "LangAuto-Long-Horizon",
                "LangAuto-Novel-Environment"
            ],
            "base_models": [
                "LLaVA-7B",
                "Mipha-3B",
                "OPT-350M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unifying Corroborative and Contributive Attributions in Large Language Models": {
        "filename": "Unifying Corroborative and Contributive Attributions in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "QReCC",
                "WoW",
                "CNN/DM",
                "ToTTo",
                "AllSouls",
                "davinci-debate",
                "ELI5",
                "WikiHowKeywords",
                "NaturalQuestions",
                "HotpotQA",
                "EntityQuestions",
                "PopQA",
                "TREC",
                "TriviaQA",
                "WebQuestions",
                "ASQA",
                "QAMPARI"
            ],
            "base_models": [
                "Gopher",
                "GPT-3",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Emulating Human Cognitive Processes for Expert-Level Medical Question-Answering with Large Language Models": {
        "filename": "Emulating Human Cognitive Processes for Expert-Level Medical Question-Answering with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ExpertMedQA",
                "ClinicalQA"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis": {
        "filename": "Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "Astronomia ex machina a history primer and outlook on neural networks in astronomy": {
        "filename": "Astronomia ex machina a history primer and outlook on neural networks in astronomy.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "XMainframe A Large Language Model for Mainframe Modernization": {
        "filename": "XMainframe A Large Language Model for Mainframe Modernization.pdf",
        "analysis": {
            "benchmarks": [
                "MainframeBench"
            ],
            "base_models": [
                "DeepSeek-Coder 6.7B",
                "DeepSeek-Coder 33B"
            ]
        }
    },
    "At Which Training Stage Does Code Data Help LLMs Reasoning": {
        "filename": "At Which Training Stage Does Code Data Help LLMs Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "C-Eval",
                "JEC-QA",
                "ScienceQA",
                "E-KAR",
                "CosQA",
                "MBPP"
            ],
            "base_models": [
                "PanGu-2.6B",
                "PanGu-13B",
                "CodePanGu-2.6B"
            ]
        }
    },
    "OpenMathInstruct-2 Accelerating AI for Math with Massive Open-Source Instruction Data": {
        "filename": "OpenMathInstruct-2 Accelerating AI for Math with Massive Open-Source Instruction Data.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "AMC 2023",
                "AIME 2024",
                "Omni-MATH"
            ],
            "base_models": [
                "Llama3.1-8B-Base",
                "Llama3.1-70B-Base",
                "Llama3.1-405B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models have Intrinsic Self-Correction Ability": {
        "filename": "Large Language Models have Intrinsic Self-Correction Ability.pdf",
        "analysis": {
            "benchmarks": [
                "CommonSense QA",
                "GSM8K",
                "MMLU",
                "HotPotQA",
                "Big Bench",
                "SVAMP"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4-Turbo",
                "Llama-3.1-8B-Instruct",
                "Mistral-7b-instruct-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MetaMath Bootstrap Your Own Mathematical Questions for Large Language Models": {
        "filename": "MetaMath Bootstrap Your Own Mathematical Questions for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "LLaMA-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tree-Planner Efficient Close-loop Task Planning with Large Language Models": {
        "filename": "Tree-Planner Efficient Close-loop Task Planning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "VirtualHome"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CLAM Selective Clarification for Ambiguous Questions with Generative Language Models": {
        "filename": "CLAM Selective Clarification for Ambiguous Questions with Generative Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Ambiguous TriviaQA",
                "ClariQ",
                "CLAQUA I",
                "CLAQUA II"
            ],
            "base_models": [
                "GPT-3 (davinci)",
                "GPT-3 (text-davinci-002)"
            ]
        }
    },
    "Hermes A Large Language Model Framework on the Journey to Autonomous Networks": {
        "filename": "Hermes A Large Language Model Framework on the Journey to Autonomous Networks.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4o",
                "Llama-3.1-70b",
                "Llama-3.1-405b"
            ]
        }
    },
    "One Graph Model for Cross-domain Dynamic Link Prediction": {
        "filename": "One Graph Model for Cross-domain Dynamic Link Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "Enron",
                "UCI",
                "Nearby",
                "Myket",
                "UN Trade",
                "Ubuntu",
                "Mathoverflow",
                "College"
            ],
            "base_models": [
                "Decode-only Transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models meet Collaborative Filtering An Efficient All-round LLM-based Recommender System": {
        "filename": "Large Language Models meet Collaborative Filtering An Efficient All-round LLM-based Recommender System.pdf",
        "analysis": {
            "benchmarks": [
                "Amazon Movies and TV",
                "Amazon Video Games",
                "Amazon Beauty",
                "Amazon Toys"
            ],
            "base_models": [
                "OPT-6.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PaperQA Retrieval-Augmented Generative Agent for Scientific Research": {
        "filename": "PaperQA Retrieval-Augmented Generative Agent for Scientific Research.pdf",
        "analysis": {
            "benchmarks": [
                "PubMedQA",
                "LitQA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoDA Instructive Chain-of-Domain Adaptation with Severity-Aware Visual Prompt Tuning": {
        "filename": "CoDA Instructive Chain-of-Domain Adaptation with Severity-Aware Visual Prompt Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "Foggy Driving",
                "Foggy Zurich",
                "ACDC"
            ],
            "base_models": [
                "SegFormer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RiskLabs Predicting Financial Risk Using Large Language Model Based on Multi-Sources Data": {
        "filename": "RiskLabs Predicting Financial Risk Using Large Language Model Based on Multi-Sources Data.pdf",
        "analysis": {
            "benchmarks": [
                "S&P 500 earnings conference call dataset"
            ],
            "base_models": [
                "Wav2vec2",
                "SimCSE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DCR Divide-and-Conquer Reasoning for Multi-choice Question Answering with LLMs": {
        "filename": "DCR Divide-and-Conquer Reasoning for Multi-choice Question Answering with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "AQuA",
                "Abstract Algebra",
                "High School Mathematics",
                "CMSQA",
                "OpenBookQA",
                "ARC Challenge",
                "RiddleSense",
                "Logical Deduction",
                "Reclor",
                "GSM8K"
            ],
            "base_models": [
                "GPT-3.5-Turbo-0613",
                "Gemma-7B",
                "Mistral-7B",
                "Palm2",
                "Gemini",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dynamic Sparse No Training Training-Free Fine-tuning for Sparse LLMs": {
        "filename": "Dynamic Sparse No Training Training-Free Fine-tuning for Sparse LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "WikiText-2",
                "PIQA",
                "HellaSwag",
                "StoryCloze",
                "ARC-e",
                "ARC-c",
                "OBQA"
            ],
            "base_models": [
                "LLaMA-V1",
                "LLaMA-V2",
                "Vicuna",
                "OPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "STEVE-1 A Generative Model for Text-to-Behavior in Minecraft": {
        "filename": "STEVE-1 A Generative Model for Text-to-Behavior in Minecraft.pdf",
        "analysis": {
            "benchmarks": [
                "MineRL environment",
                "early-game evaluation suite"
            ],
            "base_models": [
                "VPT",
                "MineCLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Cannot Self-Correct Reasoning Yet": {
        "filename": "Large Language Models Cannot Self-Correct Reasoning Yet.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "CommonSenseQA",
                "HotpotQA"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "GPT-4-Turbo",
                "Llama-2-70b-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Pruner-Zero Evolving Symbolic Pruning Metric from scratch for Large Language Models": {
        "filename": "Pruner-Zero Evolving Symbolic Pruning Metric from scratch for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WikiText2",
                "BoolQ",
                "RTE",
                "HellaSwag",
                "WinoGrande",
                "ARC",
                "OBQA"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-30B",
                "LLaMA-65B",
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "LLaMA-2-70B",
                "OPT-125m",
                "OPT-350m",
                "OPT-1.3B",
                "OPT-2.7B",
                "OPT-6.7B",
                "OPT-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rho-1 Not All Tokens Are What You Need": {
        "filename": "Rho-1 Not All Tokens Are What You Need.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8k"
            ],
            "base_models": [
                "Tinyllama-1.1B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AgentsCoMerge Large Language Model Empowered Collaborative Decision Making for Ramp Merging": {
        "filename": "AgentsCoMerge Large Language Model Empowered Collaborative Decision Making for Ramp Merging.pdf",
        "analysis": {
            "benchmarks": [
                "nuScenes",
                "LimSim++"
            ],
            "base_models": [
                "Qwen-7B (7.7 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are Machine Rationales Not Useful to Humans Measuring and Improving Human Utility of Free-text Rationales": {
        "filename": "Are Machine Rationales Not Useful to Humans Measuring and Improving Human Utility of Free-text Rationales.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "OBQA"
            ],
            "base_models": [
                "GPT-3-175B",
                "T5-large",
                "T5-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Llama Guard 3 Vision Safeguarding Human-AI Image Understanding Conversations": {
        "filename": "Llama Guard 3 Vision Safeguarding Human-AI Image Understanding Conversations.pdf",
        "analysis": {
            "benchmarks": [
                "internal benchmark using the MLCommons taxonomy"
            ],
            "base_models": [
                "Llama 3.2-Vision (11B)"
            ]
        }
    },
    "Generative Students Using LLM-Simulated Student Profiles to Support Question Item Evaluation": {
        "filename": "Generative Students Using LLM-Simulated Student Profiles to Support Question Item Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset with 20 multiple-choice questions on heuristic evaluation"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Ranni Taming Text-to-Image Diffusion for Accurate Instruction Following": {
        "filename": "Ranni Taming Text-to-Image Diffusion for Accurate Instruction Following.pdf",
        "analysis": {
            "benchmarks": [
                "T2I-CompBench"
            ],
            "base_models": [
                "Llama-2 13B",
                "latent diffusion model 3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "XPERT Empowering Incident Management with Query Recommendations via Large Language Models": {
        "filename": "XPERT Empowering Incident Management with Query Recommendations via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from Microsoft incident management system"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Out of the Cage How Stochastic Parrots Win in Cyber Security Environments": {
        "filename": "Out of the Cage How Stochastic Parrots Win in Cyber Security Environments.pdf",
        "analysis": {
            "benchmarks": [
                "CyberBattleSim",
                "NetSecGame"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ClimaQA An Automated Evaluation Framework for Climate Foundation Models": {
        "filename": "ClimaQA An Automated Evaluation Framework for Climate Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "ClimaQA-Gold",
                "ClimaQA-Silver"
            ],
            "base_models": [
                "GPT-4",
                "gemma-27b",
                "llama3-70b",
                "mixtral-8x22b",
                "gpt-3.5-turbo",
                "mistral-7b",
                "llama3.1-8b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Operationalizing Contextual Integrity in Privacy-Conscious Assistants": {
        "filename": "Operationalizing Contextual Integrity in Privacy-Conscious Assistants.pdf",
        "analysis": {
            "benchmarks": [
                "novel form filling benchmark composed of human annotations of common webform applications"
            ],
            "base_models": [
                "Gemini Ultra",
                "Gemini Pro",
                "Gemma 2.0 9B",
                "Gemma 2.0 27B",
                "Mistral 1.0 Small",
                "Mistral 1.0 Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Weighted Möbius Score A Unified Framework for Feature Attribution": {
        "filename": "The Weighted Möbius Score A Unified Framework for Feature Attribution.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2"
            ],
            "base_models": [
                "BERT-large"
            ]
        }
    },
    "Large Language Models as Analogical Reasoners": {
        "filename": "Large Language Models as Analogical Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "Codeforces",
                "BIG-Bench"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FMint Bridging Human Designed and Data Pretrained Models for Differential Equation Foundation Model": {
        "filename": "FMint Bridging Human Designed and Data Pretrained Models for Differential Equation Foundation Model.pdf",
        "analysis": {
            "benchmarks": [
                "Lorenz model",
                "Damped oscillator",
                "Van der Pol oscillator",
                "Lotka-Volterra",
                "Driven-damped pendulum",
                "Falling object with air resistance",
                "FitzHugh-Nagumo systems",
                "Pendulum under gravity",
                "Rössler dynamics"
            ],
            "base_models": [
                "Decoder-only transformer (15.8M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HumanEval-V Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks": {
        "filename": "HumanEval-V Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval-V"
            ],
            "base_models": [
                "GPT-4o",
                "Claude 3.5 Sonnet",
                "Phi-3-Vision (4.2B)",
                "Phi-3.5-Vision (4.2B)",
                "LLaV A-OneVision (8.0B, 73.2B)",
                "MiniCPM-V 2.5 (8.5B)",
                "MiniCPM-V 2.6 (8.1B)",
                "InternVL-Chat-V1.5 (26.0B)",
                "InternVL-2 (4.2B, 8.1B, 25.5B, 40.1B)",
                "Qwen2-VL (8.3B, 73.4B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network": {
        "filename": "Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network.pdf",
        "analysis": {
            "benchmarks": [
                "Amazon",
                "Yelp",
                "Douban Movie",
                "LastFM",
                "ACM",
                "IMDB",
                "DBLP",
                "OAG-NN"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Mistral-tiny",
                "Mistral-small",
                "Mistral-medium",
                "Mistral-large",
                "GLM-3-turbo",
                "GLM-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Models for Institutional Portfolio Management Persona-Based Ensembles": {
        "filename": "Leveraging Large Language Models for Institutional Portfolio Management Persona-Based Ensembles.pdf",
        "analysis": {
            "benchmarks": [
                "US CPI Total"
            ],
            "base_models": [
                "GPT-4 (gpt-4-0613)"
            ]
        }
    },
    "WIBA What Is Being Argued A Comprehensive Approach to Argument Mining": {
        "filename": "WIBA What Is Being Argued A Comprehensive Approach to Argument Mining.pdf",
        "analysis": {
            "benchmarks": [
                "UKP HQ",
                "DEBATE HQ",
                "IBM-ARG HQ",
                "GPT HQ"
            ],
            "base_models": [
                "BART",
                "LLaMa-2 7B",
                "LLaMa-3 8B",
                "Mistral-7B",
                "Yi-6B"
            ]
        }
    },
    "Vulnerability Handling of AI-Generated Code - Existing Solutions and Open Challenges": {
        "filename": "Vulnerability Handling of AI-Generated Code - Existing Solutions and Open Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic datasets",
                "complex real-world datasets"
            ],
            "base_models": [
                "GPT-4",
                "WizardCoder",
                "CodeLlama",
                "PaLM2",
                "CodeBERT",
                "GraphCodeBERT",
                "CodeGen"
            ]
        }
    },
    "Enhance Multi-Domain Sentiment Analysis of Review Texts Through Prompting Strategies": {
        "filename": "Enhance Multi-Domain Sentiment Analysis of Review Texts Through Prompting Strategies.pdf",
        "analysis": {
            "benchmarks": [
                "IMDB dataset",
                "FiQA, Financial PhraseBank datasets",
                "Amazon Reviews"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)"
            ]
        }
    },
    "Leveraging Large Language Models for Enhancing Public Transit Services": {
        "filename": "Leveraging Large Language Models for Enhancing Public Transit Services.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-Turbo"
            ]
        }
    },
    "A Survey on Evaluation of Multimodal Large Language Models": {
        "filename": "A Survey on Evaluation of Multimodal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMBench",
                "MM-Vet",
                "Seed-Bench",
                "MME",
                "MMStar",
                "LLaVA-Bench",
                "Open-VQA",
                "MDVP-Bench",
                "P2GB",
                "EQBEN",
                "MUIRBENCH",
                "TouchStone",
                "mPlug-Owl",
                "LogicVista",
                "CODIS",
                "VQAv2",
                "GQA",
                "CLEVR",
                "AesBench",
                "Q-Bench",
                "Q-Bench+",
                "OCRBench",
                "TextVQA",
                "TextCaps",
                "DocVQA",
                "MPDocVQA",
                "MMRel",
                "What’sUp",
                "GSR-BENCH",
                "CRPE",
                "VSR",
                "SpatialRGPT-Bench",
                "MMIU",
                "MMR",
                "MM-SpuBench",
                "BenchLMM",
                "Multi-Trust",
                "POPE",
                "UNIHD",
                "VideoHallucer",
                "CAP2QA",
                "CHEF",
                "GAVIE",
                "HaELM",
                "M-HalDetect",
                "Bingo",
                "Hallusion-Bench",
                "AMBER",
                "MM-SAP",
                "VHTest",
                "CorrelationQA",
                "MM-SafetyBench",
                "MMUBench",
                "Jailbreakv-28k",
                "Shield",
                "RTVLM",
                "CVQA",
                "MM-Soc",
                "TransportationGames",
                "MathVerse",
                "NPHardEval4V",
                "Inter-GPS",
                "MathVista",
                "SceMQA",
                "MULTI",
                "LogicVista",
                "MathV",
                "MathCheck",
                "CMMMU",
                "ScienceQA",
                "MMMU",
                "Peacock",
                "LaVy",
                "M3Exam",
                "MTVQA",
                "SciFIBench",
                "DesignQA",
                "Asclepius",
                "M3D",
                "GMAI-MMBench",
                "Mobile-Agent",
                "VisualAgentBench",
                "EgoPlan-Bench",
                "PCA-EVAL",
                "OpenEQA",
                "Ferret-UI",
                "Crab",
                "ScanQA",
                "LAMM",
                "M3DBench",
                "SpatialRGPT",
                "MMBench-Video",
                "SOK-Bench",
                "MVBench",
                "HighDAN",
                "RSGPT",
                "MDAS",
                "AIRBench",
                "Dynamic-superb",
                "MuChoMusic"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini",
                "LLaVA-13B",
                "InternLM-XComposer2",
                "InstructBLIP Vicuna",
                "InfMLLM",
                "Qwen-VL",
                "mPLUG-Owl",
                "MiniGPT-4",
                "LLaVA-1.5",
                "SPHINX-V",
                "Claude 3",
                "LLaVA-1.6-34B",
                "Mini-Gemini-HD-34B",
                "OmniLMM-12B",
                "IDEFICS",
                "LLaVA-1.5-7B",
                "Qwen-VL-Chat",
                "TransCore-M",
                "InternLM-XComposer-7B",
                "CogVLM-17B",
                "Mantis-8B-Idefics2",
                "VILA1.5-13B",
                "Gemini Pro",
                "M3Exam",
                "ChatGPT",
                "Vicuna"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Knowledge of Knowledge Exploring Known-Unknowns Uncertainty with Large Language Models": {
        "filename": "Knowledge of Knowledge Exploring Known-Unknowns Uncertainty with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "KUQ",
                "SelfAware",
                "MMLU",
                "CommonSenseQA",
                "AI2 Reasoning Challenge",
                "BIG-Bench Chess State Tracking"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama-2 7B",
                "Llama-2 13B",
                "Llama-2 70B",
                "Llama-2 7B-Chat",
                "Llama-2 13B-Chat",
                "Llama-2 70B-Chat"
            ]
        }
    },
    "IDEATOR Jailbreaking Large Vision-Language Models Using Themselves": {
        "filename": "IDEATOR Jailbreaking Large Vision-Language Models Using Themselves.pdf",
        "analysis": {
            "benchmarks": [
                "Advbench",
                "VAJM"
            ],
            "base_models": [
                "MiniGPT-4 (Vicuna-13B)",
                "LLaVA (LLaMA-2-Chat)",
                "InstructBLIP (Vicuna)",
                "Meta's Chameleon"
            ]
        }
    },
    "Bias patterns in the application of LLMs for clinical decision support A comprehensive study": {
        "filename": "Bias patterns in the application of LLMs for clinical decision support A comprehensive study.pdf",
        "analysis": {
            "benchmarks": [
                "Q-Pain",
                "NEJM Healer"
            ],
            "base_models": [
                "GPT-4",
                "LLaMa-2 (70B)",
                "PaLM-2",
                "Gemma (7B)",
                "Mixtral (8x7B)",
                "Galactica (30B)",
                "Palmyra-Med (20B)",
                "Meditron (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Quantifying artificial intelligence through algebraic generalization": {
        "filename": "Quantifying artificial intelligence through algebraic generalization.pdf",
        "analysis": {
            "benchmarks": [
                "Polynomial identity testing",
                "Custom algebraic circuit datasets"
            ],
            "base_models": [
                "Transformers",
                "Large Language Models (LLMs)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena": {
        "filename": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena.pdf",
        "analysis": {
            "benchmarks": [
                "MT-bench",
                "Chatbot Arena"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-13B",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Q Improving Multi-step Reasoning for LLMs with Deliberative Planning": {
        "filename": "Q Improving Multi-step Reasoning for LLMs with Deliberative Planning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "MBPP"
            ],
            "base_models": [
                "Llama-2-7b",
                "DeepSeek-Math-7b",
                "CodeQwen1.5-7b-Chat"
            ]
        }
    },
    "Matryoshka Learning to Drive Black-Box LLMs with LLMs": {
        "filename": "Matryoshka Learning to Drive Black-Box LLMs with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "LaMP",
                "GSM8K",
                "ALFWorld"
            ],
            "base_models": [
                "LLaMA-3-8B-Instruct",
                "gpt-4o-mini",
                "gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TRAM Benchmarking Temporal Reasoning for Large Language Models": {
        "filename": "TRAM Benchmarking Temporal Reasoning for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TRAM"
            ],
            "base_models": [
                "GPT-4",
                "Llama2",
                "BERT",
                "RoBERTa",
                "Gemini Pro",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Large Language Models to Assess Tutors Performance in Reacting to Students Making Math Errors": {
        "filename": "Using Large Language Models to Assess Tutors Performance in Reacting to Students Making Math Errors.pdf",
        "analysis": {
            "benchmarks": [
                "50 real-life tutoring dialogues"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4"
            ]
        }
    },
    "In-Context Fine-Tuning for Time-Series Foundation Models": {
        "filename": "In-Context Fine-Tuning for Time-Series Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "Monash",
                "ETT"
            ],
            "base_models": [
                "TimesFM (200M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Susceptible are LLMs to Influence in Prompts": {
        "filename": "How Susceptible are LLMs to Influence in Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "PIQA",
                "SIQA",
                "CommonsenseQA",
                "OpenBookQA",
                "WikiQA",
                "GPQA",
                "QuALITY",
                "BoolQ"
            ],
            "base_models": [
                "Llama2-70b",
                "Mixtral",
                "Falcon-40b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Versatile Decomposers Decomposing Evidence and Questions for Table-based Reasoning": {
        "filename": "Large Language Models are Versatile Decomposers Decomposing Evidence and Questions for Table-based Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "TabFact",
                "WikiTableQuestion",
                "FetaQA"
            ],
            "base_models": [
                "GPT-3 Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Neuro-Symbolic Inverse Planning Engine NIPE Modeling Probabilistic Social Inferences from Linguistic Inputs": {
        "filename": "The Neuro-Symbolic Inverse Planning Engine NIPE Modeling Probabilistic Social Inferences from Linguistic Inputs.pdf",
        "analysis": {
            "benchmarks": [
                "Custom linguistic goal inference domain inspired by Zhi-Xuan et al., 2020"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ]
        }
    },
    "System 2 Reasoning Capabilities Are Nigh": {
        "filename": "System 2 Reasoning Capabilities Are Nigh.pdf",
        "analysis": {
            "benchmarks": [
                "Cognitive Reflection Test",
                "Synthetic Visual Reasoning Test"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ]
        }
    },
    "Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking": {
        "filename": "Exploring the In-context Learning Ability of Large Language Model for Biomedical Concept Linking.pdf",
        "analysis": {
            "benchmarks": [
                "BC5CDR",
                "OMIM-ORDO",
                "SNOMED-NCIT Neoplas"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "LLaMa-65B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Source-Aware Training Enables Knowledge Attribution in Language Models": {
        "filename": "Source-Aware Training Enables Knowledge Attribution in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BIOCITE (synthetic dataset)"
            ],
            "base_models": [
                "TinyLLama 1.1B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning Multi-Step Reasoning by Solving Arithmetic Tasks": {
        "filename": "Learning Multi-Step Reasoning by Solving Arithmetic Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "MAWPS",
                "ASDiv-A",
                "SVAMP",
                "SVAMP (hard)"
            ],
            "base_models": [
                "RoBERTa base"
            ]
        }
    },
    "CPA-Enhancer Chain-of-Thought Prompted Adaptive Enhancer for Object Detection under Unknown Degradations": {
        "filename": "CPA-Enhancer Chain-of-Thought Prompted Adaptive Enhancer for Object Detection under Unknown Degradations.pdf",
        "analysis": {
            "benchmarks": [
                "RTTS",
                "ExDark",
                "VocFogTest",
                "VocDarkTest",
                "VocSnowTest",
                "VocRainTest"
            ],
            "base_models": [
                "YOLOv3 (Darknet-53 backbone)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Essential Role of Causality in Foundation World Models for Embodied AI": {
        "filename": "The Essential Role of Causality in Foundation World Models for Embodied AI.pdf",
        "analysis": {
            "benchmarks": [
                "AI2THOR",
                "Causal World simulations",
                "Habitat 3.0"
            ],
            "base_models": [
                "GPT-4",
                "CLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation": {
        "filename": "Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "TheoremQA",
                "MMLU",
                "Belebele",
                "GSM8K",
                "CommonsenseQA"
            ],
            "base_models": [
                "Llama2-7B",
                "Llama3-8B",
                "Qwen1.5-7B",
                "Qwen2-7B",
                "Mistral-7B",
                "Llama3-70B",
                "Qwen2-72B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are We Really Making Much Progress in Text Classification A Comparative Review": {
        "filename": "Are We Really Making Much Progress in Text Classification A Comparative Review.pdf",
        "analysis": {
            "benchmarks": [
                "20ng",
                "R8",
                "R52",
                "ohsumed",
                "MR",
                "R21578",
                "RCV1-V2",
                "EconBiz",
                "GoEmotions",
                "Amazon-531",
                "DBPedia-298",
                "NYT AC"
            ],
            "base_models": [
                "BERT-base",
                "BERT-large",
                "DistilBERT",
                "RoBERTa",
                "DeBERTa",
                "ERNIE 2.0",
                "ALBERTv2",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Integrating Reinforcement Learning and Large Language Models for Crop Production Process Management Optimization and Control through A New Knowledge-Based Deep Learning Paradigm": {
        "filename": "Integrating Reinforcement Learning and Large Language Models for Crop Production Process Management Optimization and Control through A New Knowledge-Based Deep Learning Paradigm.pdf",
        "analysis": {
            "benchmarks": [
                "Gym-DSSAT",
                "CyclesGym"
            ],
            "base_models": [
                "LaMDA",
                "LLAMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OpenAgents An Open Platform for Language Agents in the Wild": {
        "filename": "OpenAgents An Open Platform for Language Agents in the Wild.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Claude"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring LLM-based Agents for Root Cause Analysis": {
        "filename": "Exploring LLM-based Agents for Root Cause Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "out-of-distribution dataset of production incidents collected at a large IT corporation"
            ],
            "base_models": [
                "GPT-4 (8k context size)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM4Vuln A Unified Evaluation Framework for Decoupling and Enhancing LLMs Vulnerability Reasoning": {
        "filename": "LLM4Vuln A Unified Evaluation Framework for Decoupling and Enhancing LLMs Vulnerability Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Custom Solidity dataset",
                "Custom Java dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Mixtral",
                "Llama 3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM4VV Developing LLM-Driven Testsuite for Compiler Validation": {
        "filename": "LLM4VV Developing LLM-Driven Testsuite for Compiler Validation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "GSM8K",
                "TruthfulQA"
            ],
            "base_models": [
                "Codellama-34B-Instruct",
                "Phind-Codellama-34B-v2",
                "Deepseek-Coder-33b-Instruct",
                "GPT-3.5-Turbo",
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InstructEval Towards Holistic Evaluation of Instruction-Tuned Large Language Models": {
        "filename": "InstructEval Towards Holistic Evaluation of Instruction-Tuned Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BBH",
                "DROP",
                "HumanEval",
                "CRASS",
                "IMPACT",
                "HHH"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "Flan-UL2 20B",
                "Alpaca-Lora 30B",
                "OpenAssistant 30B",
                "OPT-IML 30B",
                "Flan-T5 11B",
                "Flan-Alpaca 11B",
                "StableVicuna 13B",
                "Vicuna 13B",
                "Dolly V2 12B",
                "ChatGLM 6B",
                "Mosaic-Chat 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Zero-Shot Reasoners": {
        "filename": "Large Language Models are Zero-Shot Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith",
                "GSM8K",
                "AQUA-RAT",
                "SVAMP",
                "Last Letter",
                "Coin Flip",
                "Date Understanding",
                "Tracking Shuffled Objects",
                "CommonsenseQA",
                "StrategyQA",
                "SingleEq",
                "AddSub"
            ],
            "base_models": [
                "InstructGPT (text-davinci-002)",
                "PaLM-540B",
                "GPT-3 (ada, babbage, curie, davinci)",
                "GPT-2",
                "GPT-Neo",
                "GPT-J",
                "T0",
                "OPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Harnessing GPT-35-turbo for Rhetorical Role Prediction in Legal Cases": {
        "filename": "Harnessing GPT-35-turbo for Rhetorical Role Prediction in Legal Cases.pdf",
        "analysis": {
            "benchmarks": [
                "LegalEval 2023"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "BERT",
                "SciBERT-HSLN"
            ]
        }
    },
    "Correlation and Navigation in the Vocabulary Key Representation Space of Language Models": {
        "filename": "Correlation and Navigation in the Vocabulary Key Representation Space of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ProbeSet (custom knowledge probing set)"
            ],
            "base_models": [
                "llama-3-8b-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Engineering or Fine Tuning An Empirical Assessment of Large Language Models in Automated Software Engineering Tasks": {
        "filename": "Prompt Engineering or Fine Tuning An Empirical Assessment of Large Language Models in Automated Software Engineering Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "CodeSearchNet (CSN)",
                "CodeTrans (CT)",
                "HumanEval (HE)",
                "MBPP"
            ],
            "base_models": [
                "GPT-4",
                "CodeBERT",
                "CoTexT",
                "ProphetNet-X",
                "Reflexion",
                "Parsel",
                "MetaGPT",
                "CODE-T",
                "CODE-T-ITER",
                "LEVER",
                "Reviewer",
                "MBR-Exec",
                "AlphaCode",
                "StructCoder",
                "PLBART"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Language Models Solve Olympiad Programming": {
        "filename": "Can Language Models Solve Olympiad Programming.pdf",
        "analysis": {
            "benchmarks": [
                "USACO"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-3-sonnet",
                "CodeLlama2-Instruct-7B",
                "Deepseek-Coder-Instruct-7B"
            ]
        }
    },
    "Augmenting Language Models with Long-Term Memory": {
        "filename": "Augmenting Language Models with Long-Term Memory.pdf",
        "analysis": {
            "benchmarks": [
                "ChapterBreak",
                "Gutenberg-2022 corpus",
                "ArXiv"
            ],
            "base_models": [
                "GPT-2 (407M-params)"
            ]
        }
    },
    "Is ChatGPT a Good Teacher Coach Measuring Zero-Shot Performance For Scoring and Providing Actionable Insights on Classroom Instruction": {
        "filename": "Is ChatGPT a Good Teacher Coach Measuring Zero-Shot Performance For Scoring and Providing Actionable Insights on Classroom Instruction.pdf",
        "analysis": {
            "benchmarks": [
                "NCTE dataset"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LMGT Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs": {
        "filename": "LMGT Optimizing Exploration-Exploitation Balance in Reinforcement Learning through Language Model Guided Trade-offs.pdf",
        "analysis": {
            "benchmarks": [
                "Gymnasium environments (cartpole, pendulum, mountain-car, mujoco, atari)",
                "RecSim (Choc vs. Kale scenario)"
            ],
            "base_models": [
                "Vicuna-30B (4-bit quantized with GPTQ)",
                "Llama2-13B (8-bit)"
            ]
        }
    },
    "Design of Chain-of-Thought in Math Problem Solving": {
        "filename": "Design of Chain-of-Thought in Math Problem Solving.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATHQA",
                "SVAMP"
            ],
            "base_models": [
                "Galactica-6.7B",
                "Galactica-30B",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLMReasoningPlanning for supporting incomplete user queries in presence of APIs": {
        "filename": "LLMReasoningPlanning for supporting incomplete user queries in presence of APIs.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of single goal and multi-goal complete and incomplete natural language queries"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fine-tuning Large Language Models with Sequential Instructions": {
        "filename": "Fine-tuning Large Language Models with Sequential Instructions.pdf",
        "analysis": {
            "benchmarks": [
                "SeqEval",
                "CommonsenseQA",
                "XQuAD",
                "VQAv2",
                "GQA",
                "MMLU",
                "ARC",
                "GSM8K",
                "HumanEval",
                "AlpacaEval 2.0",
                "MGSM8K"
            ],
            "base_models": [
                "Llama-2-13B",
                "Llama-2-70B",
                "Llama-3-8B",
                "Mistral-7B",
                "Llama-2-7B-Chat",
                "Llama-2-13B-Chat",
                "Llama-3-8B-Alpaca",
                "Llama-3-8B-Instruct",
                "Llama-3-70B-Instruct",
                "Command R+"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SOTOPIA Interactive Evaluation for Social Intelligence in Language Agents": {
        "filename": "SOTOPIA Interactive Evaluation for Social Intelligence in Language Agents.pdf",
        "analysis": {
            "benchmarks": [
                "SOTOPIA",
                "SOTOPIA-hard"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Llama-2-70b-chat",
                "MPT-30b-chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tool-Planner Task Planning with Clusters across Multiple Tools": {
        "filename": "Tool-Planner Task Planning with Clusters across Multiple Tools.pdf",
        "analysis": {
            "benchmarks": [
                "ToolBench",
                "APIBench"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Memorization Without Overfitting Analyzing the Training Dynamics of Large Language Models": {
        "filename": "Memorization Without Overfitting Analyzing the Training Dynamics of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WIKITEXT-103",
                "RoBERTa corpus"
            ],
            "base_models": [
                "Transformer (125M, 355M, 1.3B, 2.7B, 6.7B, 13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "T-SciQ Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering": {
        "filename": "T-SciQ Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA"
            ],
            "base_models": [
                "GPT-3.5",
                "ChatGPT",
                "GPT-4",
                "LLaMa",
                "UnifiedQA Base",
                "Multimodal-CoT Base",
                "Multimodal-CoT Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language to Code Translation with Execution": {
        "filename": "Natural Language to Code Translation with Execution.pdf",
        "analysis": {
            "benchmarks": [
                "MBPP",
                "Spider",
                "NL2Bash"
            ],
            "base_models": [
                "Codex"
            ]
        }
    },
    "Meta-CoT Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models": {
        "filename": "Meta-CoT Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AQUA-RAT",
                "MultiArith",
                "AddSub",
                "GSM8K",
                "SingleEq",
                "SVAMP",
                "Last Letter Concatenation",
                "Coin Flip",
                "StrategyQA",
                "CSQA",
                "BBH tasks"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can VLMs Play Action Role-Playing Games Take Black Myth Wukong as a Study Case": {
        "filename": "Can VLMs Play Action Role-Playing Games Take Black Myth Wukong as a Study Case.pdf",
        "analysis": {
            "benchmarks": [
                "Black Myth: Wukong"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini"
            ]
        }
    },
    "Language models are weak learners": {
        "filename": "Language models are weak learners.pdf",
        "analysis": {
            "benchmarks": [
                "UCI dataset",
                "OpenML"
            ],
            "base_models": [
                "GPT-3 Curie (13B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SimplyRetrieve A Private and Lightweight Retrieval-Centric Generative AI Tool": {
        "filename": "SimplyRetrieve A Private and Lightweight Retrieval-Centric Generative AI Tool.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Llama-2-13B-chat",
                "Wizard-Vicuna-13B",
                "Multilingual-E5-base"
            ]
        }
    },
    "GeoLLM-Engine A Realistic Environment for Building Geospatial Copilots": {
        "filename": "GeoLLM-Engine A Realistic Environment for Building Geospatial Copilots.pdf",
        "analysis": {
            "benchmarks": [
                "GeoLLM-Engine",
                "xView1",
                "xView2",
                "xView3",
                "SARFish",
                "FAIR1M",
                "Functional Map of the World (FMoW)",
                "BigEarthNet"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4 Turbo"
            ]
        }
    },
    "Bridging Causal Discovery and Large Language Models A Comprehensive Survey of Integrative Approaches and Future Directions": {
        "filename": "Bridging Causal Discovery and Large Language Models A Comprehensive Survey of Integrative Approaches and Future Directions.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "GoNoGo An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making": {
        "filename": "GoNoGo An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making.pdf",
        "analysis": {
            "benchmarks": [
                "GoNoGo data (custom dataset)"
            ],
            "base_models": [
                "GPT-3.5 Turbo"
            ]
        }
    },
    "Socratic Planner Inquiry-Based Zero-Shot Planning for Embodied Instruction Following": {
        "filename": "Socratic Planner Inquiry-Based Zero-Shot Planning for Embodied Instruction Following.pdf",
        "analysis": {
            "benchmarks": [
                "ALFRED"
            ],
            "base_models": [
                "GPT-Turbo-3.5"
            ]
        }
    },
    "Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models": {
        "filename": "Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AG News",
                "RACE",
                "RTE"
            ],
            "base_models": [
                "T0-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Confident Adaptive Language Modeling": {
        "filename": "Confident Adaptive Language Modeling.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/DM",
                "WMT15 EN-FR",
                "SQUAD 1.1"
            ],
            "base_models": [
                "T5 1.1 (8 layers)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fine-tuning and Prompt Engineering with Cognitive Knowledge Graphs for Scholarly Knowledge Organization": {
        "filename": "Fine-tuning and Prompt Engineering with Cognitive Knowledge Graphs for Scholarly Knowledge Organization.pdf",
        "analysis": {
            "benchmarks": [
                "Open Research Knowledge Graph (ORKG)"
            ],
            "base_models": [
                "Llama 2 (7B and 13B)",
                "Mistral (7B)",
                "Gemini Pro"
            ]
        }
    },
    "Identifying the Risks of LM Agents with an LM-Emulated Sandbox": {
        "filename": "Identifying the Risks of LM Agents with an LM-Emulated Sandbox.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset with 36 high-stakes toolkits and 144 test cases"
            ],
            "base_models": [
                "GPT-4",
                "Claude-2",
                "ChatGPT-3.5",
                "Vicuna-1.5-13B",
                "Vicuna-1.5-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can LLMs Compute with Reasons": {
        "filename": "Can LLMs Compute with Reasons.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "GPT-3.5",
                "Phi 1.5"
            ]
        }
    },
    "Instigating Cooperation among LLM Agents Using Adaptive Information Modulation": {
        "filename": "Instigating Cooperation among LLM Agents Using Adaptive Information Modulation.pdf",
        "analysis": {
            "benchmarks": [
                "Prisoner's Dilemma"
            ],
            "base_models": [
                "LLaMa3-70b"
            ]
        }
    },
    "Rainier Reinforced Knowledge Introspector for Commonsense Question Answering": {
        "filename": "Rainier Reinforced Knowledge Introspector for Commonsense Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "QASC",
                "PhysicalIQA",
                "SocialIQA",
                "Winogrande",
                "OpenBookQA",
                "ARC",
                "AI2Science",
                "NumerSense",
                "RiddleSense",
                "QuaRTz",
                "HellaSwag"
            ],
            "base_models": [
                "GPT-3-Curie (13B)",
                "T5-large (0.77B)",
                "UniﬁedQA-large (0.77B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Closing the Loop Testing ChatGPT to Generate Model Explanations to Improve Human Labelling of Sponsored Content on Social Media": {
        "filename": "Closing the Loop Testing ChatGPT to Generate Model Explanations to Improve Human Labelling of Sponsored Content on Social Media.pdf",
        "analysis": {
            "benchmarks": [
                "Custom Instagram dataset"
            ],
            "base_models": [
                "BERT-base-multilingual-uncased",
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "HaluEval A Large-Scale Hallucination Evaluation Benchmark for Large Language Models": {
        "filename": "HaluEval A Large-Scale Hallucination Evaluation Benchmark for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HaluEval",
                "HotpotQA"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-3",
                "Claude",
                "Claude 2",
                "Davinci002",
                "Davinci003",
                "Llama 2-Chat (7B)",
                "ChatGLM (7B)",
                "Falcon (7B)",
                "Vicuna (7B)",
                "Alpaca (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hyacinth6B A large language model for Traditional Chinese": {
        "filename": "Hyacinth6B A large language model for Traditional Chinese.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "CMMLU",
                "C-eval",
                "LLM-eval",
                "TC-eval"
            ],
            "base_models": [
                "ChatGLM3-6B-base"
            ]
        }
    },
    "Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt": {
        "filename": "Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt.pdf",
        "analysis": {
            "benchmarks": [
                "RTE",
                "CB",
                "ANLI R1",
                "COPA",
                "Hellaswag",
                "StoryCloze",
                "Winogrande",
                "WSC",
                "WiC",
                "BIG-bench"
            ],
            "base_models": [
                "T0 (3B)",
                "T0 (11B)",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Consistency Improves Chain of Thought Reasoning in Language Models": {
        "filename": "Self-Consistency Improves Chain of Thought Reasoning in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "AQuA",
                "StrategyQA",
                "ARC-challenge"
            ],
            "base_models": [
                "UL2-20B",
                "GPT-3-175B",
                "LaMDA-137B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Model Behavior A Comprehensive Survey": {
        "filename": "Language Model Behavior A Comprehensive Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "PaLM",
                "OPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Power of Large Language Models for Wireless Communication System Development A Case Study on FPGA Platforms": {
        "filename": "The Power of Large Language Models for Wireless Communication System Development A Case Study on FPGA Platforms.pdf",
        "analysis": {
            "benchmarks": [
                "OpenWiFi"
            ],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MM-REACT Prompting ChatGPT for Multimodal Reasoning and Action": {
        "filename": "MM-REACT Prompting ChatGPT for Multimodal Reasoning and Action.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM": {
        "filename": "Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM.pdf",
        "analysis": {
            "benchmarks": [
                "Harmful Behaviors Attack"
            ],
            "base_models": [
                "Vicuna-7B-v1.3-HF",
                "Guanaco-7B-HF",
                "GPT-3.5-turbo-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "K2 A Foundation Language Model for Geoscience Knowledge Understanding and Utilization": {
        "filename": "K2 A Foundation Language Model for Geoscience Knowledge Understanding and Utilization.pdf",
        "analysis": {
            "benchmarks": [
                "GeoBench"
            ],
            "base_models": [
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Harnessing Large Language Models for Software Vulnerability Detection A Comprehensive Benchmarking Study": {
        "filename": "Harnessing Large Language Models for Software Vulnerability Detection A Comprehensive Benchmarking Study.pdf",
        "analysis": {
            "benchmarks": [
                "Juliet Java 1.3"
            ],
            "base_models": [
                "GPT-4 turbo",
                "GPT-4",
                "Claude 3 Opus"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Randomness Is All You Need Semantic Traversal of Problem-Solution Spaces with Large Language Models": {
        "filename": "Randomness Is All You Need Semantic Traversal of Problem-Solution Spaces with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom idea database",
                "problem-solution dataset extracted using the OpenAI API"
            ],
            "base_models": [
                "Pythia-Chat-Base-7B"
            ]
        }
    },
    "The Emergence of Essential Sparsity in Large Pre-trained Models The Weights that Matter": {
        "filename": "The Emergence of Essential Sparsity in Large Pre-trained Models The Weights that Matter.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "MNLI",
                "QNLI",
                "QQP",
                "SST-2",
                "RTE",
                "SQuAD v1.1",
                "CIFAR-10",
                "CIFAR-100",
                "Tiny-ImageNet",
                "SMC-Benchmark",
                "MAWPS",
                "ASDiv-A",
                "SVAMP"
            ],
            "base_models": [
                "Vicuna-7B",
                "BERT Base",
                "BERT Large",
                "OPT-125M",
                "OPT-350M",
                "OPT-1.3B",
                "ViT Base",
                "ViT Large",
                "DiNO Base"
            ]
        }
    },
    "John is 50 years old can his son be 65 Evaluating NLP Models Understanding of Feasibility": {
        "filename": "John is 50 years old can his son be 65 Evaluating NLP Models Understanding of Feasibility.pdf",
        "analysis": {
            "benchmarks": [
                "FeasibilityQA"
            ],
            "base_models": [
                "GPT-3",
                "GPT-2",
                "T5-11B"
            ]
        }
    },
    "Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model Explorations with GPT4-Vision and Beyond": {
        "filename": "Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model Explorations with GPT4-Vision and Beyond.pdf",
        "analysis": {
            "benchmarks": [
                "PCA-EVAL"
            ],
            "base_models": [
                "GPT4-Vision",
                "InstructBLIP",
                "MMICL",
                "QwenVL-Chat",
                "ChatGPT",
                "GPT4",
                "Vicuna"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VernaCopter Disambiguated Natural-Language-Driven Robot via Formal Specifications": {
        "filename": "VernaCopter Disambiguated Natural-Language-Driven Robot via Formal Specifications.pdf",
        "analysis": {
            "benchmarks": [
                "Reach-and-Avoid (R&A) task",
                "Treasure hunt task"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "GLDesigner Leveraging Multi-Modal LLMs as Designer for Enhanced Aesthetic Text Glyph Layouts": {
        "filename": "GLDesigner Leveraging Multi-Modal LLMs as Designer for Enhanced Aesthetic Text Glyph Layouts.pdf",
        "analysis": {
            "benchmarks": [
                "TextLogo3K",
                "GenTextLogo"
            ],
            "base_models": [
                "LLaVA-1.5 (7B)",
                "LLaVA-1.5 (13B)"
            ]
        }
    },
    "Harvesting Event Schemas from Large Language Models": {
        "filename": "Harvesting Event Schemas from Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ERE-EN",
                "ChFinAnn",
                "Cov-19",
                "New York Time",
                "People’s Daily"
            ],
            "base_models": [
                "BLOOM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Incremental learning of humanoid robot behavior from natural interaction and large language models": {
        "filename": "Incremental learning of humanoid robot behavior from natural interaction and large language models.pdf",
        "analysis": {
            "benchmarks": [
                "CaP scenarios"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Segment Everything Everywhere All at Once": {
        "filename": "Segment Everything Everywhere All at Once.pdf",
        "analysis": {
            "benchmarks": [
                "COCO",
                "Ref-COCOg",
                "Ref-COCO",
                "Ref-COCO+",
                "PascalVOC",
                "DAVIS17",
                "YouTube-VOS 2018"
            ],
            "base_models": [
                "X-Decoder",
                "FocalT",
                "DaViT-d3 (Base)",
                "DaViT-d5 (Large)",
                "UniCL",
                "Florence"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatCoT Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models": {
        "filename": "ChatCoT Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "HotpotQA"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-3",
                "PaLM",
                "PaLM 2",
                "Minerva",
                "Galactica",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search": {
        "filename": "Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search.pdf",
        "analysis": {
            "benchmarks": [
                "Code World Models Benchmark (CWMB)",
                "APPS",
                "RTFM"
            ],
            "base_models": [
                "Llama 3 70B",
                "GPT-4 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FigStep Jailbreaking Large Vision-language Models via Typographic Visual Prompts": {
        "filename": "FigStep Jailbreaking Large Vision-language Models via Typographic Visual Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "SafeBench",
                "SafeBench-Tiny"
            ],
            "base_models": [
                "LLaVA-v1.5-Vicuna-v1.5-7B",
                "LLaVA-v1.5-Vicuna-v1.5-13B",
                "MiniGPT4-Llama-2-CHAT-7B",
                "MiniGPT4-Vicuna-7B",
                "MiniGPT4-Vicuna-13B",
                "CogVLM-Chat-v1.1",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "STEAM Simulating the InTeractive BEhavior of ProgrAMmers for Automatic Bug Fixing": {
        "filename": "STEAM Simulating the InTeractive BEhavior of ProgrAMmers for Automatic Bug Fixing.pdf",
        "analysis": {
            "benchmarks": [
                "BFP",
                "Bugs.jar",
                "Defects4J",
                "Bears",
                "QuixBugs"
            ],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DracoGPT Extracting Visualization Design Preferences from Large Language Models": {
        "filename": "DracoGPT Extracting Visualization Design Preferences from Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Kim et al. dataset"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Crimson Empowering Strategic Reasoning in Cybersecurity through Large Language Models": {
        "filename": "Crimson Empowering Strategic Reasoning in Cybersecurity through Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CVEM dataset"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2 (7B and 70B)",
                "Mistral-7B",
                "bge-large-en-v1.5"
            ]
        }
    },
    "Large Models for Time Series and Spatio-Temporal Data A Survey and Outlook": {
        "filename": "Large Models for Time Series and Spatio-Temporal Data A Survey and Outlook.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175 billion parameters)",
                "GPT-2 (1.5 billion parameters)",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Revealing the Mystery behind Chain of Thought a Theoretical Perspective": {
        "filename": "Towards Revealing the Mystery behind Chain of Thought a Theoretical Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "Arithmetic",
                "Equation",
                "Longest Increasing Subsequence (LIS)",
                "Edit Distance (ED)"
            ],
            "base_models": [
                "GPT-4",
                "autoregressive Transformers (constant size)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Study on Training and Developing Large Language Models for Behavior Tree Generation": {
        "filename": "A Study on Training and Developing Large Language Models for Behavior Tree Generation.pdf",
        "analysis": {
            "benchmarks": [
                "self-instruct BT instructor-following data"
            ],
            "base_models": [
                "text-davinci-003",
                "Stanford Alpaca 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT-4 can pass the Korean National Licensing Examination for Korean Medicine Doctors": {
        "filename": "GPT-4 can pass the Korean National Licensing Examination for Korean Medicine Doctors.pdf",
        "analysis": {
            "benchmarks": [
                "Korean National Licensing Examination for Korean Medicine Doctors (K-NLEKMD)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment": {
        "filename": "A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment.pdf",
        "analysis": {
            "benchmarks": [
                "FR-KADID",
                "Aug-KADID",
                "TQD",
                "SPCD",
                "NR-KADID",
                "SPAQ",
                "AGIQA-3K"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA-v1.6 (Mistral-7B)",
                "InternLM-XComposer2-VL (InernLM2-7B)",
                "mPLUG-Owl2 (LLaMA2-7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathVerse Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems": {
        "filename": "MathVerse Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems.pdf",
        "analysis": {
            "benchmarks": [
                "MATHVERSE",
                "GeoQA",
                "UniGeo",
                "MathVista",
                "MMMU"
            ],
            "base_models": [
                "GPT-4V",
                "ShareGPT4V",
                "Qwen-VL-Max",
                "InternLM-XComposer2",
                "Gemini-Pro",
                "LLaMA-Adapter V2",
                "ImageBind-LLM",
                "mPLUG-Owl2",
                "MiniGPT-v2",
                "LLaVA-1.5",
                "SPHINX-Plus",
                "G-LLaVA",
                "LLaVA-NeXT",
                "SPHINX-MoE",
                "InternLM-XC2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DOTS Learning to Reason Dynamically in LLMs via Optimal Reasoning Trajectories Search": {
        "filename": "DOTS Learning to Reason Dynamically in LLMs via Optimal Reasoning Trajectories Search.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "BBH",
                "Game of 24",
                "TheoremQA",
                "Deepmind Math",
                "MMLU-pro",
                "StrategyQA",
                "DROP"
            ],
            "base_models": [
                "GPT-4o-mini",
                "Llama3-70B-Instruct",
                "Llama3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EvalLM Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria": {
        "filename": "EvalLM Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Decoding by Contrasting Knowledge Enhancing LLMs Confidence on Edited Facts": {
        "filename": "Decoding by Contrasting Knowledge Enhancing LLMs Confidence on Edited Facts.pdf",
        "analysis": {
            "benchmarks": [
                "MQ UAKE-3 K",
                "MQ UAKE-2002",
                "MQ UAKE-HARD",
                "STUBBORN datasets"
            ],
            "base_models": [
                "LLAMA2-7B-CHAT",
                "LLAMA2-13B-CHAT",
                "LLAMA3-8B-INSTRUCT",
                "MISTRAL-7B-INSTRUCT"
            ]
        }
    },
    "Can We Count on LLMs The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities": {
        "filename": "Can We Count on LLMs The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "When Do Decompositions Help for Machine Reading": {
        "filename": "When Do Decompositions Help for Machine Reading.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "DROP"
            ],
            "base_models": [
                "BART",
                "T5",
                "UnifiedQA-v2 (T5 backbone)"
            ]
        }
    },
    "Exploring the Potential of Large Language Models in Graph Generation": {
        "filename": "Exploring the Potential of Large Language Models in Graph Generation.pdf",
        "analysis": {
            "benchmarks": [
                "OGBG-MolHIV"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "LLama2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understanding Biases in ChatGPT-based Recommender Systems Provider Fairness Temporal Stability and Recency": {
        "filename": "Understanding Biases in ChatGPT-based Recommender Systems Provider Fairness Temporal Stability and Recency.pdf",
        "analysis": {
            "benchmarks": [
                "MovieLens"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Quantitative Certification of Bias in Large Language Models": {
        "filename": "Quantitative Certification of Bias in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BOLD",
                "Decoding Trust"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude-3.5-Sonnet",
                "Llama-7B",
                "Llama-13B",
                "Vicuna-7B",
                "Vicuna-13B",
                "Mistral-7B",
                "Gemini-1.0-pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval-Augmented Generation with Estimation of Source Reliability": {
        "filename": "Retrieval-Augmented Generation with Estimation of Source Reliability.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions (NQ)",
                "HotpotQA",
                "TriviaQA"
            ],
            "base_models": [
                "Llama3-8B Instruct",
                "Phi3-mini Instruct",
                "GPT-4o mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Recurrent Neural Language Models as Probabilistic Finite-state Automata": {
        "filename": "Recurrent Neural Language Models as Probabilistic Finite-state Automata.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CodeMind A Framework to Challenge Large Language Models for Code Reasoning": {
        "filename": "CodeMind A Framework to Challenge Large Language Models for Code Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "CRUXEval",
                "CodeNet",
                "Avatar"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Llama 2 (13B)",
                "Mistral",
                "CodeLlama (13B)",
                "StarCoder (15.5B)",
                "StarCoder 2 (15B)",
                "WizardCoder (15B)",
                "Magicoder (7B)",
                "DeepSeekCoder (6.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models": {
        "filename": "Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "MathVista"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LanguaShrink Reducing Token Overhead with Psycholinguistics": {
        "filename": "LanguaShrink Reducing Token Overhead with Psycholinguistics.pdf",
        "analysis": {
            "benchmarks": [
                "LongBench",
                "ZeroScrolls",
                "Arxiv Articles",
                "newly constructed novel test set"
            ],
            "base_models": [
                "GPT-4",
                "Yi",
                "GLM",
                "Qwen"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Task-oriented Robotic Manipulation with Vision Language Models": {
        "filename": "Task-oriented Robotic Manipulation with Vision Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 600 images with manually annotated object attributes and spatial relationships"
            ],
            "base_models": [
                "MiniGPT-4",
                "LLaVA",
                "GPT-4"
            ]
        }
    },
    "Selection-Inference Exploiting Large Language Models for Interpretable Logical Reasoning": {
        "filename": "Selection-Inference Exploiting Large Language Models for Interpretable Logical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "bAbI",
                "BigBench",
                "AAC",
                "Jeopardy",
                "ProofWriter",
                "2WikiMultiHop"
            ],
            "base_models": [
                "Gopher-7B",
                "Gopher-280B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents": {
        "filename": "Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents.pdf",
        "analysis": {
            "benchmarks": [
                "MiniGrid",
                "Habitat"
            ],
            "base_models": [
                "ChatGLM-turbo",
                "Vicuna-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Will the Real Linda Please Stand upto Large Language Models Examining the Representativeness Heuristic in LLMs": {
        "filename": "Will the Real Linda Please Stand upto Large Language Models Examining the Representativeness Heuristic in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "REHEAT"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM 2",
                "LLaMA 2 (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media": {
        "filename": "Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media.pdf",
        "analysis": {
            "benchmarks": [
                "Illicit drug trafficking dataset from Instagram"
            ],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SLED Self Logits Evolution Decoding for Improving Factuality in Large Language Models": {
        "filename": "SLED Self Logits Evolution Decoding for Improving Factuality in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "FACTOR",
                "StrategyQA",
                "GSM8K"
            ],
            "base_models": [
                "LLaMA-2-7B-Base",
                "LLaMA-2-7B-Chat",
                "LLaMA-2-13B-Base",
                "LLaMA-2-13B-Chat",
                "LLaMA-2-70B-Base",
                "LLaMA-2-70B-Chat",
                "LLaMA-3-8B",
                "LLaMA-3-8B-IT",
                "LLaMA-3-70B",
                "LLaMA-3-70B-IT",
                "Gemma-2B",
                "Gemma-7B",
                "Mixtral-8×7B",
                "Mixtral-8×7B-IT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Transformers Learn Shortcuts to Automata": {
        "filename": "Transformers Learn Shortcuts to Automata.pdf",
        "analysis": {
            "benchmarks": [
                "Gridworld",
                "Dyck languages"
            ],
            "base_models": [
                "GPT-2-like Transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Question Answering for Enterprise Knowledge Bases using Large Language Models": {
        "filename": "Enhancing Question Answering for Enterprise Knowledge Bases using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "EKR",
                "FiQA",
                "NQ",
                "MS MARCO"
            ],
            "base_models": [
                "Baichuan-13B",
                "LLaMA-7B"
            ]
        }
    },
    "BugBlitz-AI An Intelligent QA Assistant": {
        "filename": "BugBlitz-AI An Intelligent QA Assistant.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset from software products in a real production environment"
            ],
            "base_models": [
                "DeepSeek-Coder-7b-instruct",
                "Mistral-7B-Instruct",
                "CodeLlama-7b-Instruct"
            ]
        }
    },
    "DrPlanner Diagnosis and Repair of Motion Planners for Automated Vehicles Using Large Language Models": {
        "filename": "DrPlanner Diagnosis and Repair of Motion Planners for Automated Vehicles Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CommonRoad"
            ],
            "base_models": [
                "GPT-4-Turbo"
            ]
        }
    },
    "MobileExperts A Dynamic Tool-Enabled Agent Team in Mobile Devices": {
        "filename": "MobileExperts A Dynamic Tool-Enabled Agent Team in Mobile Devices.pdf",
        "analysis": {
            "benchmarks": [
                "Expert-Eval"
            ],
            "base_models": [
                "VLM (Visual Language Model)"
            ]
        }
    },
    "ART Automatic multi-step reasoning and tool-use for large language models": {
        "filename": "ART Automatic multi-step reasoning and tool-use for large language models.pdf",
        "analysis": {
            "benchmarks": [
                "BigBench",
                "MMLU",
                "SQuAD",
                "TriviaQA",
                "SVAMP",
                "MAWPS"
            ],
            "base_models": [
                "InstructGPT (text-davinci-002)",
                "Codex"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CodeUltraFeedback An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences": {
        "filename": "CodeUltraFeedback An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval+",
                "CodeUltraFeedback-Bench"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "CodeLlama-7B-Instruct",
                "CodeLlama-13B-Instruct",
                "CodeLlama-34B-Instruct",
                "WizardCoder-33B",
                "DeepSeek-Coder-6.7B-Instruct",
                "DeepSeek-Coder-33B-Instruct",
                "Mistral-7B-Instruct",
                "Llama-2-13B-Chat",
                "Llama-2-70B-Chat",
                "WizardLM-15B",
                "WizardLM-33B",
                "WizardCoder-15B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Theory of Mind Abilities of Large Language Models in Human-Robot Interaction An Illusion": {
        "filename": "Theory of Mind Abilities of Large Language Models in Human-Robot Interaction An Illusion.pdf",
        "analysis": {
            "benchmarks": [
                "Fetch",
                "Passage Gridworld",
                "Environment Design",
                "Urban Search and Rescue",
                "Package Delivery"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Domain-Specific Improvement on Psychotherapy Chatbot Using Assistant": {
        "filename": "Domain-Specific Improvement on Psychotherapy Chatbot Using Assistant.pdf",
        "analysis": {
            "benchmarks": [
                "Alexander Street Press video transcripts"
            ],
            "base_models": [
                "GPT-4",
                "Llama2-7B",
                "ChatGLM2-6B"
            ]
        }
    },
    "Repetition In Repetition Out Towards Understanding Neural Text Degeneration from the Data Perspective": {
        "filename": "Repetition In Repetition Out Towards Understanding Neural Text Degeneration from the Data Perspective.pdf",
        "analysis": {
            "benchmarks": [
                "Wikitext-103",
                "OpenWebText2",
                "FreeLaw",
                "PubMed",
                "ArXiv"
            ],
            "base_models": [
                "GPT-2",
                "OPT (various sizes including 6.7B and 66B)",
                "LLAMA 2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Divide and Prompt Chain of Thought Prompting for Text-to-SQL": {
        "filename": "Divide and Prompt Chain of Thought Prompting for Text-to-SQL.pdf",
        "analysis": {
            "benchmarks": [
                "Spider"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "text-davinci-002",
                "text-davinci-003"
            ]
        }
    },
    "Benchmarking Multi-Image Understanding in Vision and Language Models Perception Knowledge Reasoning and Multi-Hop Reasoning": {
        "filename": "Benchmarking Multi-Image Understanding in Vision and Language Models Perception Knowledge Reasoning and Multi-Hop Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MIRB"
            ],
            "base_models": [
                "LLaVA-v1.5-7B",
                "LLaVA-Next-7B",
                "LLaVA-Next-13B",
                "Qwen-VL-Chat (9B)",
                "InternLM-XComposer2 (7B)",
                "VILA-2.7B",
                "VILA-7B",
                "Emu2-Chat (37B)",
                "IDEFICS1-9B",
                "IDEFICS2-8B",
                "Phi-3-Vision (4B)",
                "GPT-4V"
            ]
        }
    },
    "Towards Generalizable and Robust Text-to-SQL Parsing": {
        "filename": "Towards Generalizable and Robust Text-to-SQL Parsing.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "SParC",
                "CoSQL",
                "Spider-Syn",
                "Spider-Realistic"
            ],
            "base_models": [
                "T5-Base",
                "T5-Large",
                "T5-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining": {
        "filename": "Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining.pdf",
        "analysis": {
            "benchmarks": [
                "Custom Chinese Audiobooks Dataset",
                "48 Audiobooks for Evaluation"
            ],
            "base_models": [
                "GPT-SoVITS",
                "RoBERTa",
                "HTSAT",
                "HuBERT"
            ]
        }
    },
    "What do LLMs Know about Financial Markets A Case Study on Reddit Market Sentiment Analysis": {
        "filename": "What do LLMs Know about Financial Markets A Case Study on Reddit Market Sentiment Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "Reddit Testing",
                "FiQA News",
                "FiQA Post"
            ],
            "base_models": [
                "GPT-3",
                "PaLM-540B",
                "T5",
                "BERT"
            ]
        }
    },
    "Exploring the Limitations of Large Language Models in Compositional Relation Reasoning": {
        "filename": "Exploring the Limitations of Large Language Models in Compositional Relation Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Multilingual Compositional Relation (MCR) Benchmark"
            ],
            "base_models": [
                "GPT-3 (text-davinci-002)",
                "ChatGPT (gpt-3.5-turbo-1106)",
                "GPT-4 (gpt-4-0613)",
                "Llama2-7B (Llama-2-7b-chat-hf)",
                "Llama2-13B (Llama-2-13b-chat-hf)",
                "Mistral-7B (mistral-7b-instruct-v0.2)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unveiling the Potential of Large Language Models in Generating Semantic and Cross-Language Clones": {
        "filename": "Unveiling the Potential of Large Language Models in Generating Semantic and Cross-Language Clones.pdf",
        "analysis": {
            "benchmarks": [
                "SemanticCloneBench"
            ],
            "base_models": [
                "GPT-3"
            ]
        }
    },
    "Meta Reasoning for Large Language Models": {
        "filename": "Meta Reasoning for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "Game of 24",
                "Trivia Creative Writing",
                "HotpotQA",
                "BigToM",
                "Code Readability",
                "MMLU"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ]
        }
    },
    "Understanding the Potential of FPGA-Based Spatial Acceleration for Large Language Model Inference": {
        "filename": "Understanding the Potential of FPGA-Based Spatial Acceleration for Large Language Model Inference.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT",
                "GPT2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Album Storytelling with Iterative Story-aware Captioning and Large Language Models": {
        "filename": "Album Storytelling with Iterative Story-aware Captioning and Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of image collections from vlogs"
            ],
            "base_models": [
                "ChatGPT",
                "BLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoPS Empowering LLM Agents with Provable Cross-Task Experience Sharing": {
        "filename": "CoPS Empowering LLM Agents with Provable Cross-Task Experience Sharing.pdf",
        "analysis": {
            "benchmarks": [
                "Alfworld",
                "Webshop",
                "HotPotQA"
            ],
            "base_models": [
                "Llama 3.1 8b",
                "Llama 3.1 70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Assessing Large Language Models in Mechanical Engineering Education A Study on Mechanics-Focused Conceptual Understanding": {
        "filename": "Assessing Large Language Models in Mechanical Engineering Education A Study on Mechanics-Focused Conceptual Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 126 multiple-choice questions on mechanics"
            ],
            "base_models": [
                "GPT-3.5 (175 billion parameters)",
                "GPT-4 (1.76 trillion parameters)",
                "Claude-2.1"
            ]
        }
    },
    "Look Remember and Reason Grounded Reasoning in Videos with Language Models": {
        "filename": "Look Remember and Reason Grounded Reasoning in Videos with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ACRE",
                "CATER",
                "Something-Else",
                "STAR"
            ],
            "base_models": [
                "OPT (family)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DETAIL Task DEmonsTration Attribution for Interpretable In-context Learning": {
        "filename": "DETAIL Task DEmonsTration Attribution for Interpretable In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "MNIST",
                "AG News",
                "SST-2",
                "Rotten Tomatoes",
                "Subj"
            ],
            "base_models": [
                "Vicuna-7b",
                "Llama-2-13b",
                "Falcon-7b",
                "Llama-2-7b",
                "Mamba-2.8b",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TinyGSM achieving 80 on GSM8k with small language models": {
        "filename": "TinyGSM achieving 80 on GSM8k with small language models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP"
            ],
            "base_models": [
                "GPT-3.5",
                "Phi-1.5 (1.3B)",
                "Phi-1.5-tiny (125M)",
                "Phi-1.5-small (350M)"
            ]
        }
    },
    "CodePMP Scalable Preference Model Pretraining for Large Language Model Reasoning": {
        "filename": "CodePMP Scalable Preference Model Pretraining for Large Language Model Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "ReClor",
                "LogiQA2.0"
            ],
            "base_models": [
                "MetaMath-Mistral-7B",
                "Qwen2-1.5B",
                "Qwen2-7B",
                "deepseek-coder-6.7b-instruct",
                "deepseek-coder-1.3b-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatDiet Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework": {
        "filename": "ChatDiet Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework.pdf",
        "analysis": {
            "benchmarks": [
                "N-of-1 Dataset",
                "Synthetic Dataset"
            ],
            "base_models": [
                "gpt-3.5-turbo"
            ]
        }
    },
    "Chain of Images for Intuitively Reasoning": {
        "filename": "Chain of Images for Intuitively Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "CoI evaluation dataset",
                "BIGBench",
                "AGIEval",
                "MMLU",
                "NYCC"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2",
                "Vicuna-7B-v1.5",
                "GPT-NeoX-3B"
            ]
        }
    },
    "Hint-AD Holistically Aligned Interpretability in End-to-End Autonomous Driving": {
        "filename": "Hint-AD Holistically Aligned Interpretability in End-to-End Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "nuScenes",
                "Nu-X",
                "TOD3Cap",
                "NuScenes-QA",
                "Driving command dataset"
            ],
            "base_models": [
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-Frame Lightweight  Efficient Vision-Language Models for Question Answering in Autonomous Driving": {
        "filename": "Multi-Frame Lightweight  Efficient Vision-Language Models for Question Answering in Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "DriveLM dataset"
            ],
            "base_models": [
                "T5-Base (223M parameters)",
                "8-bit quantized T5-Large (750M parameters)"
            ]
        }
    },
    "ORES Open-vocabulary Responsible Visual Synthesis": {
        "filename": "ORES Open-vocabulary Responsible Visual Synthesis.pdf",
        "analysis": {
            "benchmarks": [
                "Visual Genome",
                "ORES dataset"
            ],
            "base_models": [
                "ChatGPT",
                "Stable Diffusion v2.1"
            ]
        }
    },
    "Dishonesty in Helpful and Harmless Alignment": {
        "filename": "Dishonesty in Helpful and Harmless Alignment.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "Do-Not-Answer"
            ],
            "base_models": [
                "Llama-2-7b-chat",
                "Llama-2-13b-chat",
                "Mistral-7b-Instruct-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathGLM-Vision Solving Mathematical Problems with Multi-Modal Large Language Model": {
        "filename": "MathGLM-Vision Solving Mathematical Problems with Multi-Modal Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "MathVL-test",
                "MathVista",
                "MathVerse",
                "Math-Vision",
                "MathVista-GPS",
                "MMMU"
            ],
            "base_models": [
                "GPT-4",
                "Qwen",
                "GLM-4",
                "LLaMA",
                "Claude-3.5-Sonnet",
                "Gemini-1.5-Pro",
                "Qwen-VL-Max",
                "GLM-4V-9B",
                "CogVLM2",
                "CogVLM-32B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Introspective Tips Large Language Model for In-Context Decision Making": {
        "filename": "Introspective Tips Large Language Model for In-Context Decision Making.pdf",
        "analysis": {
            "benchmarks": [
                "TextWorld"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM"
            ]
        }
    },
    "Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning": {
        "filename": "Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "VizWiz",
                "OK-VQA",
                "Flowers",
                "CUB"
            ],
            "base_models": [
                "Qwen-VL (LLaMA-based)",
                "Idefics2-8B (Mistral-based)",
                "ViLA-1.5-8B (LLaMA-3-based)",
                "MANTIS-LLaMA3-8B (LLaMA3-based)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fairness of ChatGPT and the Role Of Explainable-Guided Prompts": {
        "filename": "Fairness of ChatGPT and the Role Of Explainable-Guided Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "German Credit dataset"
            ],
            "base_models": [
                "ChatGPT-3.5-Turbo",
                "GPT (OpenAI)",
                "PALM (Google)",
                "LaMDA (Facebook)"
            ]
        }
    },
    "Take a Step Back Evoking Reasoning via Abstraction in Large Language Models": {
        "filename": "Take a Step Back Evoking Reasoning via Abstraction in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU (Physics and Chemistry)",
                "TimeQA",
                "MuSiQue",
                "SituatedQA",
                "GSM8K",
                "StrategyQA"
            ],
            "base_models": [
                "PaLM-2L",
                "GPT-4",
                "Llama2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Condition and Generate Classification of Unsupported Claims with In-Context Learning": {
        "filename": "Prompt Condition and Generate Classification of Unsupported Claims with In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Twitter-Narratives-9 (TN9)",
                "UKP-Corpus-Aug"
            ],
            "base_models": [
                "T0-3B",
                "T5-Flan-3B",
                "BLOOM-175B",
                "CTRLUKP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LeanContext Cost-Efficient Domain-Specific Question Answering Using LLMs": {
        "filename": "LeanContext Cost-Efficient Domain-Specific Question Answering Using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Arxiv Dataset",
                "BBC News Dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "DataGpt-SQL-7B An Open-Source Language Model for Text-to-SQL": {
        "filename": "DataGpt-SQL-7B An Open-Source Language Model for Text-to-SQL.pdf",
        "analysis": {
            "benchmarks": [
                "spider-dev"
            ],
            "base_models": [
                "CodeQwen1.5-7B-Chat",
                "GPT-4",
                "CodeLLaMa-7B-Instruct",
                "CodeLLaMa-13B-Instruct"
            ]
        }
    },
    "Health-LLM Large Language Models for Health Prediction via Wearable Sensor Data": {
        "filename": "Health-LLM Large Language Models for Health Prediction via Wearable Sensor Data.pdf",
        "analysis": {
            "benchmarks": [
                "PMData",
                "LifeSnaps",
                "GLOBEM",
                "AW FB"
            ],
            "base_models": [
                "MedAlpaca (7B, 13B)",
                "PMC-Llama (13B)",
                "Llama 2 (7B)",
                "BioMedGPT (7B)",
                "BioMistral (7B)",
                "Asclepius (7B)",
                "ClinicalCamel (70B)",
                "Flan-T5 (3B)",
                "Palmyra-Med (20B)",
                "GPT-3.5 (175B)",
                "GPT-4",
                "Gemini-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PaniniQA Enhancing Patient Education Through Interactive Question Answering": {
        "filename": "PaniniQA Enhancing Patient Education Through Interactive Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-III"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Game On Towards Language Models as RL Experimenters": {
        "filename": "Game On Towards Language Models as RL Experimenters.pdf",
        "analysis": {
            "benchmarks": [
                "MuJoCo simulated robotic manipulation task"
            ],
            "base_models": [
                "Gemini 1.5 Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGPT Participates in a Computer Science Exam": {
        "filename": "ChatGPT Participates in a Computer Science Exam.pdf",
        "analysis": {
            "benchmarks": [
                "Undergraduate Computer Science Exam on Algorithms and Data Structures"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "CodeNav Beyond tool-use to using real-world codebases with LLM agents": {
        "filename": "CodeNav Beyond tool-use to using real-world codebases with LLM agents.pdf",
        "analysis": {
            "benchmarks": [
                "m&m's",
                "M3TOOLEVAL",
                "API-BANK"
            ],
            "base_models": [
                "GPT-4 (gpt-4-1106-preview)",
                "GPT-3.5-turbo-0125",
                "Mixtral-8x22B-Instruct-v0.1",
                "Qwen1.5-110B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Revisiting Parallel Context Windows A Frustratingly Simple Alternative and Chain-of-Thought Deterioration": {
        "filename": "Revisiting Parallel Context Windows A Frustratingly Simple Alternative and Chain-of-Thought Deterioration.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "BANKING77",
                "CLINIC150",
                "SST5",
                "CB",
                "RTE",
                "AGNews",
                "DBPedia",
                "NLU Scenario",
                "TREC",
                "TREC Fine",
                "NLU Intent"
            ],
            "base_models": [
                "LLaMA 7B",
                "Vicuna 13B"
            ]
        }
    },
    "An Assessment of Model-On-Model Deception": {
        "filename": "An Assessment of Model-On-Model Deception.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU"
            ],
            "base_models": [
                "Llama-2 7B",
                "Llama-2 13B",
                "Llama-2 70B",
                "GPT-3.5"
            ]
        }
    },
    "STaR Bootstrapping Reasoning With Reasoning": {
        "filename": "STaR Bootstrapping Reasoning With Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "GSM8K"
            ],
            "base_models": [
                "GPT-J (6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Summary to Action Enhancing Large Language Models for Complex Tasks with Open World APIs": {
        "filename": "From Summary to Action Enhancing Large Language Models for Complex Tasks with Open World APIs.pdf",
        "analysis": {
            "benchmarks": [
                "ToolBench"
            ],
            "base_models": [
                "T5",
                "LLaMA",
                "ChatGPT",
                "GPT-4"
            ]
        }
    },
    "Leveraging Logical Rules in Knowledge Editing A Cherry on the Top": {
        "filename": "Leveraging Logical Rules in Knowledge Editing A Cherry on the Top.pdf",
        "analysis": {
            "benchmarks": [
                "MQ UAKE-CF-3K",
                "RKE-EVAL"
            ],
            "base_models": [
                "LLAMA-2-7B",
                "GPT-3.5-TURBO-INSTRUCT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Teaching Large Language Models to Reason with Reinforcement Learning": {
        "filename": "Teaching Large Language Models to Reason with Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP"
            ],
            "base_models": [
                "Llama-2 7B",
                "Llama-2 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reliable Reasoning Beyond Natural Language": {
        "filename": "Reliable Reasoning Beyond Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "Navigate dataset from BIG-bench",
                "Non-Linear Reasoning (NLR) dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 Turbo",
                "text-davinci-003"
            ]
        }
    },
    "Artificial Intelligence in the Legal Field Law Students Perspective": {
        "filename": "Artificial Intelligence in the Legal Field Law Students Perspective.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT 3.5",
                "ChatGPT 4.0",
                "LLaMA 2/3"
            ]
        }
    },
    "Building and better understanding vision-language models insights and future directions": {
        "filename": "Building and better understanding vision-language models insights and future directions.pdf",
        "analysis": {
            "benchmarks": [
                "DocVQA",
                "TextVQA"
            ],
            "base_models": [
                "Llama 3.1",
                "SigLIP-SO400M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Low-Dimension-to-High-Dimension Generalization And Its Implications for Length Generalization": {
        "filename": "Low-Dimension-to-High-Dimension Generalization And Its Implications for Length Generalization.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fighting Fire with Fire Adversarial Prompting to Generate a Misinformation Detection Dataset": {
        "filename": "Fighting Fire with Fire Adversarial Prompting to Generate a Misinformation Detection Dataset.pdf",
        "analysis": {
            "benchmarks": [
                "FakeSumm Dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Jailbreak Attacks and Defenses Against Large Language Models A Survey": {
        "filename": "Jailbreak Attacks and Defenses Against Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Models That Prove Their Own Correctness": {
        "filename": "Models That Prove Their Own Correctness.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset for GCD computation"
            ],
            "base_models": [
                "GPT (6.3M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AudioPaLM A Large Language Model That Can Speak and Listen": {
        "filename": "AudioPaLM A Large Language Model That Can Speak and Listen.pdf",
        "analysis": {
            "benchmarks": [
                "CoVOST2 AST",
                "FLEURS AST",
                "VoxPopuli ASR",
                "CVSS S2ST"
            ],
            "base_models": [
                "PaLM-2 8B",
                "PaLM 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Advancing Automated Knowledge Transfer in Evolutionary Multitasking via Large Language Models": {
        "filename": "Advancing Automated Knowledge Transfer in Evolutionary Multitasking via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MTSOO test suite from CEC2024 Competition"
            ],
            "base_models": [
                "Large Language Models (LLMs)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Influence of Solution Efficiency and Valence of Instruction on Additive and Subtractive Solution Strategies in Humans and GPT-4": {
        "filename": "Influence of Solution Efficiency and Valence of Instruction on Additive and Subtractive Solution Strategies in Humans and GPT-4.pdf",
        "analysis": {
            "benchmarks": [
                "symmetry task",
                "summary task"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generative AI Security Challenges and Countermeasures": {
        "filename": "Generative AI Security Challenges and Countermeasures.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Claude",
                "ChatGPT",
                "DALL-E 3"
            ]
        }
    },
    "Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic Manipulation Tasks": {
        "filename": "Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic Manipulation Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "DeepSea",
                "ROMAN"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Chat Modeling Natural Language-based Procedural Modeling of Biological Structures without Training": {
        "filename": "Chat Modeling Natural Language-based Procedural Modeling of Biological Structures without Training.pdf",
        "analysis": {
            "benchmarks": [
                "MesoCraft"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models Act as Symbolic Reasoners": {
        "filename": "Can Large Language Models Act as Symbolic Reasoners.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT",
                "GPT-3"
            ]
        }
    },
    "HDFlow Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows": {
        "filename": "HDFlow Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows.pdf",
        "analysis": {
            "benchmarks": [
                "BBH",
                "MATH",
                "Game of 24",
                "DeepMind Math"
            ],
            "base_models": [
                "GPT-4-Turbo",
                "Llama-3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Guiding Language Model Reasoning with Planning Tokens": {
        "filename": "Guiding Language Model Reasoning with Planning Tokens.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQUA",
                "MATH",
                "StrategyQA"
            ],
            "base_models": [
                "Phi 1.5 (1.3B)",
                "Llama 2 (7B)",
                "Llama 2 (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visibility into AI Agents": {
        "filename": "Visibility into AI Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Many-Shot In-Context Learning": {
        "filename": "Many-Shot In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "MATH500",
                "GSM8K",
                "XSum",
                "XLSum",
                "FLORES-200",
                "Big-Bench Hard",
                "Financial PhraseBank (FP)",
                "Google-Proof QA (GPQA)"
            ],
            "base_models": [
                "Gemini 1.5 Pro",
                "GPT-4-Turbo",
                "Claude-3-Opus",
                "Gemini 1.5 Flash"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DialogBench Evaluating LLMs as Human-like Dialogue Systems": {
        "filename": "DialogBench Evaluating LLMs as Human-like Dialogue Systems.pdf",
        "analysis": {
            "benchmarks": [
                "DialogBench"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "LLaMA2-70B",
                "LLaMA-65B",
                "Baichuan2-13B",
                "Qwen-7B",
                "Mistral-7B",
                "InternLM-7B",
                "LLaMA2-13B",
                "Baichuan-13B",
                "LLaMA-7B",
                "LLaMA-13B",
                "Chinese LLaMA2-13B",
                "Falcon-7B",
                "MOSS-Moon-003-Base",
                "Baichuan2-13B-Chat",
                "InternLM-Chat-7B",
                "Qwen-7B-Chat",
                "Mistral-7B-Instruct",
                "ChatGLM2-6B",
                "Baichuan-13B-Chat",
                "LLaMA2-7B-Chat",
                "Vicuna-13B",
                "Chinese Alpaca2-13B",
                "MOSS-Moon-003-SFT",
                "Xwin-LM-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can AI Outperform Human Experts in Creating Social Media Creatives": {
        "filename": "Can AI Outperform Human Experts in Creating Social Media Creatives.pdf",
        "analysis": {
            "benchmarks": [
                "Instagram posts from top brands"
            ],
            "base_models": [
                "GPT-4",
                "Midjourney V5.2",
                "DALL-E 3",
                "Stable Diffusion XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LittleMu Deploying an Online Virtual Teaching Assistant via Heterogeneous Sources Integration and Chain of Teach Prompts": {
        "filename": "LittleMu Deploying an Online Virtual Teaching Assistant via Heterogeneous Sources Integration and Chain of Teach Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "XuetangX MOOC platform dataset"
            ],
            "base_models": [
                "GLM (10B)",
                "GLM-130B"
            ]
        }
    },
    "Overview of the PromptCBLUE Shared Task in CHIP2023": {
        "filename": "Overview of the PromptCBLUE Shared Task in CHIP2023.pdf",
        "analysis": {
            "benchmarks": [
                "PromptCBLUE"
            ],
            "base_models": [
                "ChatGLM-6B",
                "Baichuan-13B-Chat",
                "Chinese-LlaMA2-7B-chat",
                "Chinese-LlaMA2-13B-chat"
            ]
        }
    },
    "Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models": {
        "filename": "Natural Language Dataset Generation Framework for Visualizations Powered by Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Vega-Lite gallery example dataset",
                "Kim et al.'s dataset"
            ],
            "base_models": [
                "Not specified in the provided text"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Critic-V VLM Critics Help Catch VLM Errors in Multimodal Reasoning": {
        "filename": "Critic-V VLM Critics Help Catch VLM Errors in Multimodal Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "RealWorldQA",
                "MMStar",
                "MMBench",
                "SEEDBench",
                "ScienceQA",
                "MMT-Bench",
                "MathVista",
                "MathVerse"
            ],
            "base_models": [
                "GPT-4V",
                "Qwen2-VL-7B",
                "DeepSeek-VL-7B",
                "LLaVA-v1.5-13B",
                "LLaVA-v1.5-7B",
                "Llama-3.2-11B-Vision",
                "MiniCPM-V 2.6",
                "InternVL2-8B",
                "GeminiPro-Vision",
                "ShareGPT4V-7B",
                "InternLM2-XC2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TheoremQA A Theorem-driven Question Answering dataset": {
        "filename": "TheoremQA A Theorem-driven Question Answering dataset.pdf",
        "analysis": {
            "benchmarks": [
                "TheoremQA",
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "GPT-4",
                "PaLM-2",
                "Claude-v1",
                "LLaMA (13B)",
                "Pythia",
                "CodeGen",
                "GLM",
                "StarCoder",
                "CodeT5+"
            ]
        }
    },
    "FltLM An Intergrated Long-Context Large Language Model for Effective Context Filtering and Understanding": {
        "filename": "FltLM An Intergrated Long-Context Large Language Model for Effective Context Filtering and Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "LongBench English multi-document QA datasets",
                "HotpotQA",
                "2WikiMultiHopQA",
                "MuSiQue"
            ],
            "base_models": [
                "chatglm3-6b-32k"
            ]
        }
    },
    "TV-SAM Increasing Zero-Shot Segmentation Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation": {
        "filename": "TV-SAM Increasing Zero-Shot Segmentation Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation.pdf",
        "analysis": {
            "benchmarks": [
                "Polyp benchmark",
                "ISIC 2018",
                "WBC",
                "BUSI",
                "TN3K",
                "COVID-19 Database",
                "CHAOS"
            ],
            "base_models": [
                "GPT-4",
                "GLIP",
                "SAM"
            ]
        }
    },
    "Do PLMs Know and Understand Ontological Knowledge": {
        "filename": "Do PLMs Know and Understand Ontological Knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from DBpedia and Wikidata"
            ],
            "base_models": [
                "BERT-base-cased",
                "BERT-base-uncased",
                "BERT-large-cased",
                "BERT-large-uncased",
                "RoBERTa-base",
                "RoBERTa-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VLPrompt Vision-Language Prompting for Panoptic Scene Graph Generation": {
        "filename": "VLPrompt Vision-Language Prompting for Panoptic Scene Graph Generation.pdf",
        "analysis": {
            "benchmarks": [
                "PSG dataset",
                "VG dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Decoupled Alignment for Robust Plug-and-Play Adaptation": {
        "filename": "Decoupled Alignment for Robust Plug-and-Play Adaptation.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench"
            ],
            "base_models": [
                "Llama-2-7b",
                "Llama-2-13b",
                "Mistral-7B",
                "Gemma-2b",
                "Gemma-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Selectively Answering Ambiguous Questions": {
        "filename": "Selectively Answering Ambiguous Questions.pdf",
        "analysis": {
            "benchmarks": [
                "AmbigQA",
                "SituatedQA",
                "TriviaQA",
                "NQ-Open"
            ],
            "base_models": [
                "PaLM (540B)",
                "Flan-PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Instructions to Intrinsic Human Values - A Survey of Alignment Goals for Big Models": {
        "filename": "From Instructions to Intrinsic Human Values - A Survey of Alignment Goals for Big Models.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "OpenBookQA",
                "CrowS-Pairs",
                "WinoGender",
                "BBQ",
                "BOLD",
                "RealToxicityPrompts",
                "ToxiGen",
                "BIG-Bench",
                "HELM",
                "SafetyPrompts",
                "CValues",
                "Moral Integrity Corpus",
                "Social Chemistry 101",
                "Moral Stories",
                "ETHICS",
                "SCRUPLES",
                "MoralExceptQA",
                "ETHICAL QUANDARY GQA",
                "GlobalOpinionQA"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT",
                "GPT-4",
                "Llama2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Yes-Men to Truth-Tellers Addressing Sycophancy in Large Language Models with Pinpoint Tuning": {
        "filename": "From Yes-Men to Truth-Tellers Addressing Sycophancy in Large Language Models with Pinpoint Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "SycophancyEval",
                "MMLU",
                "MATH",
                "AQuA",
                "TruthfulQA",
                "TriviaQA"
            ],
            "base_models": [
                "GPT-4",
                "Llama-2-13B",
                "Llama-2-7B",
                "Llama-2-70B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Zero-Shot Video Question Answering with Procedural Programs": {
        "filename": "Zero-Shot Video Question Answering with Procedural Programs.pdf",
        "analysis": {
            "benchmarks": [
                "ActivityNet-QA",
                "iVQA",
                "MSR-VTT-QA",
                "MSVD-QA",
                "TGIF-QA",
                "NeXT-QA",
                "EgoSchema",
                "TVQA"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "BLIP-2",
                "GroundingDINO (Swin-T backbone)",
                "LaViLa",
                "ByteTrack"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Transformer Models for Suicide Risk Detection on Social Media": {
        "filename": "Evaluating Transformer Models for Suicide Risk Detection on Social Media.pdf",
        "analysis": {
            "benchmarks": [
                "IEEE BigData 2024 Cup: Detection of Suicide Risk on Social Media"
            ],
            "base_models": [
                "DeBERTa-base",
                "DeBERTa-large",
                "GPT-4o"
            ]
        }
    },
    "Matcher Segment Anything with One Shot Using All-Purpose Feature Matching": {
        "filename": "Matcher Segment Anything with One Shot Using All-Purpose Feature Matching.pdf",
        "analysis": {
            "benchmarks": [
                "COCO-20i",
                "LVIS-92i",
                "FSS-1000",
                "PASCAL-Part",
                "PACO-Part",
                "DAVIS 2017 val",
                "DAVIS 2016 val"
            ],
            "base_models": [
                "DINOv2 (ViT-L/14)",
                "SAM (ViT-H)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PromptBoosting Black-Box Text Classification with Ten Forward Passes": {
        "filename": "PromptBoosting Black-Box Text Classification with Ten Forward Passes.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "MR",
                "AG's News",
                "TREC",
                "SNLI",
                "MNLI-m",
                "QNLI",
                "RTE",
                "SST-5",
                "CR",
                "Subj",
                "MPQA",
                "MRPC"
            ],
            "base_models": [
                "RoBERTa-large (335M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Open-Nav Exploring Zero-Shot Vision-and-Language Navigation in Continuous Environment with Open-Source LLMs": {
        "filename": "Open-Nav Exploring Zero-Shot Vision-and-Language Navigation in Continuous Environment with Open-Source LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "R2R-CE dataset",
                "custom real-world environments (office, laboratory, game room)"
            ],
            "base_models": [
                "Llama3.1-70B",
                "Qwen2-72B",
                "Gemma2-27B",
                "Phi3-14B"
            ]
        }
    },
    "Reawakening knowledge Anticipatory recovery from catastrophic interference via structured training": {
        "filename": "Reawakening knowledge Anticipatory recovery from catastrophic interference via structured training.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/Daily Mail",
                "CIFAR-10",
                "ImageNet"
            ],
            "base_models": [
                "Pythia (160M to 2.8B)",
                "Image GPT",
                "Vision Transformer (ViT)",
                "VGG-19"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring the Benefits of Training Expert Language Models over Instruction Tuning": {
        "filename": "Exploring the Benefits of Training Expert Language Models over Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "11 unseen datasets",
                "13 datasets of the BIG-bench benchmark"
            ],
            "base_models": [
                "T0-3B",
                "T0-11B",
                "GPT-3 (175B)",
                "PaLM (540B)",
                "mT5-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AI capabilities can be significantly improved without expensive retraining": {
        "filename": "AI capabilities can be significantly improved without expensive retraining.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "OCWCourses",
                "GSM8k",
                "MMLU-STEM",
                "SuperGLUE",
                "TruthfulQA",
                "HumanEval"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-3.5",
                "GPT-4",
                "PaLM-62B",
                "PaLM-540B",
                "OPT-66B",
                "Toolformer (6.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual Agents as Fast and Slow Thinkers": {
        "filename": "Visual Agents as Fast and Slow Thinkers.pdf",
        "analysis": {
            "benchmarks": [
                "VQA-v2",
                "ReasonSeg",
                "TextVQA",
                "MME",
                "refCOCO",
                "refCOCO+",
                "refCOCOg"
            ],
            "base_models": [
                "LLaVA-v1.5",
                "Vicuna-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Of Models and Tin Men - a behavioural economics study of principal-agent problems in AI alignment using large-language models": {
        "filename": "Of Models and Tin Men - a behavioural economics study of principal-agent problems in AI alignment using large-language models.pdf",
        "analysis": {
            "benchmarks": [
                "custom online shopping task"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models": {
        "filename": "Leveraging Open Knowledge for Advancing Task Expertise in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ARC-Challenge",
                "ARC-Easy",
                "PiQA",
                "BoolQ",
                "MBPP",
                "GSM8K"
            ],
            "base_models": [
                "LLaMA2-7B",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PEARL Prompting Large Language Models to Plan and Execute Actions Over Long Documents": {
        "filename": "PEARL Prompting Large Language Models to Plan and Execute Actions Over Long Documents.pdf",
        "analysis": {
            "benchmarks": [
                "QuALITY"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using Large Language Models for Hyperparameter Optimization": {
        "filename": "Using Large Language Models for Hyperparameter Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "HPOBench",
                "CIFAR-10"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VisionGPT LLM-Assisted Real-Time Anomaly Detection for Safe Visual Navigation": {
        "filename": "VisionGPT LLM-Assisted Real-Time Anomaly Detection for Safe Visual Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "Custom video dataset for anomaly detection"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "YOLO-World"
            ]
        }
    },
    "A Review and Roadmap of Deep Causal Model from Different Causal Structures and Representations": {
        "filename": "A Review and Roadmap of Deep Causal Model from Different Causal Structures and Representations.pdf",
        "analysis": {
            "benchmarks": [
                "Arrhythmia Dataset",
                "Netsim dataset",
                "CMNIST-75sp",
                "IEM Dataset"
            ],
            "base_models": [
                "RoBERTa",
                "LeNet-5",
                "I3D"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Demo2Code From Summarizing Demonstrations to Synthesizing Code via Extended Chain-of-Thought": {
        "filename": "Demo2Code From Summarizing Demonstrations to Synthesizing Code via Extended Chain-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "Robotouille",
                "EPIC-Kitchens"
            ],
            "base_models": [
                "gpt-3.5-turbo-16k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Iterative Forward Tuning Boosts In-context Learning in Language Models": {
        "filename": "Iterative Forward Tuning Boosts In-context Learning in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "BBH",
                "SST2",
                "SST5",
                "MR",
                "AGNews",
                "TREC"
            ],
            "base_models": [
                "GPT-2 Large",
                "OPT-125M",
                "OPT-350M",
                "OPT-2.7B",
                "GPT2-Medium",
                "GPT2-XL",
                "GPT-Neo 2.7B",
                "LLaMA2 7B",
                "LLaMA2 13B",
                "Pythia 70M",
                "Pythia 410M",
                "Pythia 1.4B",
                "Pythia 6.9B",
                "Pythia 12B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ALYMPICS LLM Agents Meet Game Theory -- Exploring Strategic Decision-Making with AI Agents": {
        "filename": "ALYMPICS LLM Agents Meet Game Theory -- Exploring Strategic Decision-Making with AI Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Water Allocation Challenge"
            ],
            "base_models": [
                "GPT-4 (32k)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "keqing knowledge-based question answering is a nature chain-of-thought mentor of LLM": {
        "filename": "keqing knowledge-based question answering is a nature chain-of-thought mentor of LLM.pdf",
        "analysis": {
            "benchmarks": [
                "MetaQA",
                "WebQuestionsSP (WebQSP)"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "LLaMA"
            ]
        }
    },
    "Shortcut-connected Expert Parallelism for Accelerating Mixture-of-Experts": {
        "filename": "Shortcut-connected Expert Parallelism for Accelerating Mixture-of-Experts.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet-1K",
                "WikiText-103"
            ],
            "base_models": [
                "SwinV2-MoE-S",
                "GPT2-MoE-Medium",
                "GPT3-MoE-XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VISAR A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping": {
        "filename": "VISAR A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TPTU Large Language Model-based AI Agents for Task Planning and Tool Usage": {
        "filename": "TPTU Large Language Model-based AI Agents for Task Planning and Tool Usage.pdf",
        "analysis": {
            "benchmarks": [
                "T-Bench",
                "ToolBench",
                "API-Bank"
            ],
            "base_models": [
                "ChatGPT (200B)",
                "Claude (>52B)",
                "InternLM (120B)",
                "Ziya-13B (13B)",
                "ChatGLM-130B (130B)",
                "Chinese-Alpaca-Plus-33B (33B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments": {
        "filename": "Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments.pdf",
        "analysis": {
            "benchmarks": [
                "BIG Bench Logical Fallacy Detection",
                "LOGIC",
                "LOGIC Climate"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "Electra",
                "SimCSE",
                "Sentence-BERT (MiniLM)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Full Automation of Goal-driven LLM Dialog Threads with And-Or Recursors and Refiner Oracles": {
        "filename": "Full Automation of Goal-driven LLM Dialog Threads with And-Or Recursors and Refiner Oracles.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "LLaMA"
            ]
        }
    },
    "NumeroLogic Number Encoding for Enhanced LLMs Numerical Reasoning": {
        "filename": "NumeroLogic Number Encoding for Enhanced LLMs Numerical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU"
            ],
            "base_models": [
                "GPT-4",
                "Llama2-7B"
            ]
        }
    },
    "LLM-based event abstraction and integration for IoT-sourced logs": {
        "filename": "LLM-based event abstraction and integration for IoT-sourced logs.pdf",
        "analysis": {
            "benchmarks": [
                "Ambient Assisted Living IoT dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Align and Aggregate Compositional Reasoning with Video Alignment and Answer Aggregation for Video Question-Answering": {
        "filename": "Align and Aggregate Compositional Reasoning with Video Alignment and Answer Aggregation for Video Question-Answering.pdf",
        "analysis": {
            "benchmarks": [
                "AGQA-Decomp",
                "MSVD",
                "NExT-QA"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Understand What LLM Needs Dual Preference Alignment for Retrieval-Augmented Generation": {
        "filename": "Understand What LLM Needs Dual Preference Alignment for Retrieval-Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "NaturalQuestions (NQ)",
                "TriviaQA (TQA)",
                "HotpotQA (HQA)",
                "WebQuestionsSP (WebQSP)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA2-7B",
                "LLaMA2-13B",
                "LLaMA3-8B",
                "Qwen2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distill Visual Chart Reasoning Ability from LLMs to MLLMs": {
        "filename": "Distill Visual Chart Reasoning Ability from LLMs to MLLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ChartQA",
                "MathVista",
                "REACH QA",
                "ChartBench",
                "ChartX",
                "CharXiv",
                "MATH-Vision"
            ],
            "base_models": [
                "MiniCPM-V2.5-Llama3",
                "LLaV A-Next-Llama3-8B",
                "InternVL2-8B",
                "GPT-4o",
                "Claude 3.5 Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Pangu-Agent A Fine-Tunable Generalist Agent with Structured Reasoning": {
        "filename": "Pangu-Agent A Fine-Tunable Generalist Agent with Structured Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "BabyAI"
            ],
            "base_models": [
                "GPT-3.5",
                "Llama 2-70B",
                "OpenChat-3.2",
                "Vicuna-13B",
                "Llama 2-13B",
                "OpenChat-3.5",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Picture Is Worth a Graph A Blueprint Debate Paradigm for Multimodal Reasoning": {
        "filename": "A Picture Is Worth a Graph A Blueprint Debate Paradigm for Multimodal Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "MMBench"
            ],
            "base_models": [
                "GeminiProVision (175B+)",
                "InstructBLIP (13B)",
                "LLaVA-v1.5 (13B)",
                "GPT-4 (175B+)",
                "MiniGPT-4 (7B)",
                "Qwen-VL (7B)",
                "Qwen-VL-Chat (7B)",
                "mPLUG-Owl2 (8B)",
                "CogVLM-Chat (17B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Robotic Control via Embodied Chain-of-Thought Reasoning": {
        "filename": "Robotic Control via Embodied Chain-of-Thought Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Bridge V2"
            ],
            "base_models": [
                "Llama 2 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "User Intent Recognition and Satisfaction with Large Language Models A User Study with ChatGPT": {
        "filename": "User Intent Recognition and Satisfaction with Large Language Models A User Study with ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset from user study (available on GitHub)"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Efficient Classification of Student Help Requests in Programming Courses Using Large Language Models": {
        "filename": "Efficient Classification of Student Help Requests in Programming Courses Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from CodeHelp with 1,659 test set queries"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Logical Discrete Graphical Models Must Supplement Large Language Models for Information Synthesis": {
        "filename": "Logical Discrete Graphical Models Must Supplement Large Language Models for Information Synthesis.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "Beyond Self-Consistency Ensemble Reasoning Boosts Consistency and Accuracy of LLMs in Cancer Staging": {
        "filename": "Beyond Self-Consistency Ensemble Reasoning Boosts Consistency and Accuracy of LLMs in Cancer Staging.pdf",
        "analysis": {
            "benchmarks": [
                "Cancer Genomic Atlas (TCGA) pathology reports"
            ],
            "base_models": [
                "Med42-70B (derived from Llama2-70B)"
            ]
        }
    },
    "Dynamic and Adaptive Feature Generation with LLM": {
        "filename": "Dynamic and Adaptive Feature Generation with LLM.pdf",
        "analysis": {
            "benchmarks": [
                "Ionosphere",
                "Amazon Commerce Reviews",
                "Abalone",
                "Diabetes Health Indicators Dataset"
            ],
            "base_models": [
                "GPT-3.5 Turbo"
            ]
        }
    },
    "Project Sid Many-agent simulations toward AI civilization": {
        "filename": "Project Sid Many-agent simulations toward AI civilization.pdf",
        "analysis": {
            "benchmarks": [
                "civilizational benchmarks inspired by human history",
                "Minecraft environment"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "C2Ideas Supporting Creative Interior Color Design Ideation with a Large Language Model": {
        "filename": "C2Ideas Supporting Creative Interior Color Design Ideation with a Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "user studies",
                "expert interviews"
            ],
            "base_models": [
                "GPT-3.5 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NavCoT Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning": {
        "filename": "NavCoT Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Room-to-Room (R2R)",
                "Room-across-Room (RxR)",
                "Room-for-Room (R4R)",
                "REVERIE"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-Adapter",
                "LLaMA 2 (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Knowledge-driven Autonomous Driving": {
        "filename": "Towards Knowledge-driven Autonomous Driving.pdf",
        "analysis": {
            "benchmarks": [
                "KITTI",
                "Cityscapes",
                "Berkeley DeepDrive Video (BDDV)",
                "Honda Research Institute Driving (HDD)",
                "nuScenes",
                "Waymo Open Dataset (WOD)",
                "Berkeley DeepDrive eXplanation (BDD-X)",
                "Cityscapes-Ref",
                "DR(eye)VE",
                "Honda Research Institute-Advice Dataset (HAD)",
                "Talk2Car",
                "DADA-2000",
                "HRI Driver Behavior Dataset (HDBD)",
                "Refer-KITTI",
                "DRAMA",
                "Rank2Tell",
                "DriveLM",
                "nuScenes-QA"
            ],
            "base_models": [
                "GPT-3",
                "PaLM",
                "LLaMA",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Diffusion of Thoughts Chain-of-Thought Reasoning in Diffusion Language Models": {
        "filename": "Diffusion of Thoughts Chain-of-Thought Reasoning in Diffusion Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-bench",
                "GSM8K"
            ],
            "base_models": [
                "GPT-2 (small 124M)",
                "GPT-2 (medium 355M)",
                "GPT-2 (large 774M)",
                "Plaid (1.3B)",
                "SEDD-small (170M)",
                "SEDD-medium (424M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChartBench A Benchmark for Complex Visual Reasoning in Charts": {
        "filename": "ChartBench A Benchmark for Complex Visual Reasoning in Charts.pdf",
        "analysis": {
            "benchmarks": [
                "ChartBench"
            ],
            "base_models": [
                "LLaVA-v1.5",
                "Qwen-VL-Chat",
                "GPT-4V",
                "ERNIE"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hallucination Detection and Hallucination Mitigation An Investigation": {
        "filename": "Hallucination Detection and Hallucination Mitigation An Investigation.pdf",
        "analysis": {
            "benchmarks": [
                "QALLM",
                "Summarization",
                "Translation",
                "QA",
                "dialog",
                "summarization",
                "HaluEval"
            ],
            "base_models": [
                "GPT-2",
                "BERT",
                "RoBERTa",
                "XLNet",
                "BART",
                "DeBERTa-v3-large",
                "LLaMA-30B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ROS-LLM A ROS framework for embodied AI with task feedback and structured reasoning": {
        "filename": "ROS-LLM A ROS framework for embodied AI with task feedback and structured reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "tabletop rearrangement task",
                "long-horizon tasks in a kitchen-like environment"
            ],
            "base_models": [
                "Deepseek 7B Coder"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Understanding Sycophancy in Language Models": {
        "filename": "Towards Understanding Sycophancy in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "MATH",
                "AQuA",
                "TruthfulQA",
                "TriviaQA",
                "SycophancyEval"
            ],
            "base_models": [
                "Claude-1.3",
                "Claude-2.0",
                "GPT-3.5-turbo",
                "GPT-4",
                "LLaMA-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TICKing All the Boxes Generated Checklists Improve LLM Evaluation and Generation": {
        "filename": "TICKing All the Boxes Generated Checklists Improve LLM Evaluation and Generation.pdf",
        "analysis": {
            "benchmarks": [
                "LiveBench",
                "WildBench",
                "InFoBench"
            ],
            "base_models": [
                "GPT-4o",
                "Command-R+",
                "Llama3.1-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Information of Large Language Model Geometry": {
        "filename": "The Information of Large Language Model Geometry.pdf",
        "analysis": {
            "benchmarks": [
                "hh-rlhf dataset"
            ],
            "base_models": [
                "Pythia 1.4B"
            ]
        }
    },
    "Concept-aware Training Improves In-context Learning Ability of Language Models": {
        "filename": "Concept-aware Training Improves In-context Learning Ability of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SuperGLUE",
                "AdversarialQA"
            ],
            "base_models": [
                "MT5-LARGE"
            ]
        }
    },
    "Agents meet OKR An Object and Key Results Driven Agent System with Hierarchical Self-Collaboration and Self-Evaluation": {
        "filename": "Agents meet OKR An Object and Key Results Driven Agent System with Hierarchical Self-Collaboration and Self-Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "short video storyboard generation",
                "multi-day trip planning",
                "trivia creative writing"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "MemGPT Towards LLMs as Operating Systems": {
        "filename": "MemGPT Towards LLMs as Operating Systems.pdf",
        "analysis": {
            "benchmarks": [
                "Multi-Session Chat dataset (Xu et al., 2021)",
                "NaturalQuestions-Open"
            ],
            "base_models": [
                "GPT-4 Turbo (context window of 128,000)",
                "GPT-4 (context window of 8,192)",
                "GPT-3.5 Turbo (context window of 16,385)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Factual Consistency of Summaries with Large Language Models": {
        "filename": "Evaluating Factual Consistency of Summaries with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SummEval",
                "XSumFaith",
                "XSumSota",
                "FactCC",
                "Frank"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "text-davinci-003",
                "code-davinci-002",
                "Flan-T5 (11 billion)"
            ]
        }
    },
    "On Pre-training of Multimodal Language Models Customized for Chart Understanding": {
        "filename": "On Pre-training of Multimodal Language Models Customized for Chart Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "ChartQA",
                "PlotQA",
                "Pew",
                "Statista"
            ],
            "base_models": [
                "LLaVA-7B",
                "LLaVA-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SEA-SQL Semantic-Enhanced Text-to-SQL with Adaptive Refinement": {
        "filename": "SEA-SQL Semantic-Enhanced Text-to-SQL with Adaptive Refinement.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "BIRD"
            ],
            "base_models": [
                "GPT-3.5",
                "Mistral-7B"
            ]
        }
    },
    "A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection": {
        "filename": "A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection.pdf",
        "analysis": {
            "benchmarks": [
                "DbgBench",
                "SVEN"
            ],
            "base_models": [
                "GPT-4",
                "Gemini 1.0 Pro",
                "WizardCoder (15B)",
                "Code LLAMA (34B)",
                "GPT-3.5",
                "Mixtral-MoE (45B)",
                "Mistral (7B)",
                "StarCoder (15B)",
                "LLAMA 2 (70B)",
                "StarChat-β (15B)",
                "MagiCoder (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutomaTikZ Text-Guided Synthesis of Scientific Vector Graphics with TikZ": {
        "filename": "AutomaTikZ Text-Guided Synthesis of Scientific Vector Graphics with TikZ.pdf",
        "analysis": {
            "benchmarks": [
                "DaTikZ"
            ],
            "base_models": [
                "LLaMA (7B and 13B)",
                "GPT-4",
                "Claude 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Model for Heterogeneous Ad Hoc Teamwork Collaboration": {
        "filename": "Leveraging Large Language Model for Heterogeneous Ad Hoc Teamwork Collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "ProcTHOR-10K"
            ],
            "base_models": [
                "GPT-4 (1106-preview)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MM-PhyQA Multimodal Physics Question-Answering with Multi-image CoT Prompting": {
        "filename": "MM-PhyQA Multimodal Physics Question-Answering with Multi-image CoT Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "MM-PhyQA"
            ],
            "base_models": [
                "GPT-4",
                "LLaVA",
                "LLaVA-1.5",
                "Mistral-7B",
                "LLaMA2-7B"
            ]
        }
    },
    "Retrieval Augmented Generation of Symbolic Music with LLMs": {
        "filename": "Retrieval Augmented Generation of Symbolic Music with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of abc-notated Irish traditional folk tunes from thesession.org"
            ],
            "base_models": [
                "ChatGPT-3",
                "ChatGPT-4"
            ]
        }
    },
    "EEE Remediating the failure of machine learning models via a network-based optimization patch": {
        "filename": "EEE Remediating the failure of machine learning models via a network-based optimization patch.pdf",
        "analysis": {
            "benchmarks": [
                "Gas quantification in LAS",
                "Turbofan Engine design",
                "Electro-mechanical actuator design",
                "Pulse-width Modulation of 13-level Inverters"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Vera A General-Purpose Plausibility Estimation Model for Commonsense Statements": {
        "filename": "Vera A General-Purpose Plausibility Estimation Model for Commonsense Statements.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "HellaSwag",
                "CREAK",
                "SKD_anno",
                "I2D2_anno",
                "Rainier_anno"
            ],
            "base_models": [
                "T5 (5B)",
                "LLaMA (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "L2CEval Evaluating Language-to-Code Generation Capabilities of Large Language Models": {
        "filename": "L2CEval Evaluating Language-to-Code Generation Capabilities of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "WikiTQ",
                "GSM8k",
                "SVAMP",
                "MBPP",
                "HumanEval",
                "DS-1000"
            ],
            "base_models": [
                "GPT-4 (unknown size)",
                "text-davinci-003 (unknown size)",
                "gpt-3.4-turbo (unknown size)",
                "CodeLLaMA-base (34B)",
                "LLaMA-2 (70B)",
                "Alpaca (30B)",
                "WizardCoder (15.5B)",
                "CodeLLaMA (13B)",
                "StarCoder-15.5B",
                "Mistral-v0.1 (7B)",
                "CodeLLaMA-base (7B)",
                "CodeGen2.5-multi (7B)",
                "SantaCoder (1.3B)",
                "InCoder (1.1B)",
                "Pythia (1.4B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ReAct Synergizing Reasoning and Acting in Language Models": {
        "filename": "ReAct Synergizing Reasoning and Acting in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "Fever",
                "ALFWorld",
                "WebShop"
            ],
            "base_models": [
                "PaLM-540B",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Demystifying Higher-Order Graph Neural Networks": {
        "filename": "Demystifying Higher-Order Graph Neural Networks.pdf",
        "analysis": {
            "benchmarks": [
                "None specified in the provided text"
            ],
            "base_models": [
                "None specified in the provided text"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Game Playing Agents and Large Models Methods Applications and Challenges": {
        "filename": "A Survey on Game Playing Agents and Large Models Methods Applications and Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "Minecraft",
                "Werewolf",
                "Avalon"
            ],
            "base_models": [
                "GPT-4",
                "CLIP",
                "PaLM-E"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Maybe Only 05 Data is Needed A Preliminary Exploration of Low Training Data Instruction Tuning": {
        "filename": "Maybe Only 05 Data is Needed A Preliminary Exploration of Low Training Data Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "RTE",
                "CB",
                "ANLI",
                "COPA",
                "HellaSwag",
                "Story Cloze",
                "Winogrande",
                "WSC",
                "WIC"
            ],
            "base_models": [
                "Galactica-1.3b"
            ]
        }
    },
    "A collection of principles for guiding and evaluating large language models": {
        "filename": "A collection of principles for guiding and evaluating large language models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Flan-PaLM",
                "Claude"
            ]
        }
    },
    "Large Language Model Distilling Medication Recommendation Model": {
        "filename": "Large Language Model Distilling Medication Recommendation Model.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-III",
                "MIMIC-IV"
            ],
            "base_models": [
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Promptbreeder Self-Referential Self-Improvement Via Prompt Evolution": {
        "filename": "Promptbreeder Self-Referential Self-Improvement Via Prompt Evolution.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "MultiArith",
                "AddSub",
                "AQuA-RAT",
                "SingleEq",
                "CommonsenseQA",
                "StrategyQA",
                "ETHOS"
            ],
            "base_models": [
                "text-davinci-003",
                "PaLM 2-L"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CPL Critical Plan Step Learning Boosts LLM Generalization in Reasoning Tasks": {
        "filename": "CPL Critical Plan Step Learning Boosts LLM Generalization in Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "HumanEval",
                "GPQA",
                "ARC-C",
                "MMLU-STEM",
                "BBH"
            ],
            "base_models": [
                "DeepSeekMath-Base-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Are Partially Primed in Pronoun Interpretation": {
        "filename": "Large Language Models Are Partially Primed in Pronoun Interpretation.pdf",
        "analysis": {
            "benchmarks": [
                "Johnson and Arnold (2022) psycholinguistic experiments"
            ],
            "base_models": [
                "InstructGPT (175B)",
                "FLAN-UL2 (20B)"
            ]
        }
    },
    "MESED A Multi-modal Entity Set Expansion Dataset with Fine-grained Semantic Classes and Hard Negative Entities": {
        "filename": "MESED A Multi-modal Entity Set Expansion Dataset with Fine-grained Semantic Classes and Hard Negative Entities.pdf",
        "analysis": {
            "benchmarks": [
                "MESED"
            ],
            "base_models": [
                "GPT-3.5",
                "BERT BASE",
                "VIT",
                "BEIT",
                "CLIP",
                "ALBEF"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChaCha Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events": {
        "filename": "ChaCha Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fine-grained Hallucination Detection and Mitigation in Language Model Mathematical Reasoning": {
        "filename": "Fine-grained Hallucination Detection and Mitigation in Language Model Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "Claude-3",
                "Llama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aligning Speech to Languages to Enhance Code-switching Speech Recognition": {
        "filename": "Aligning Speech to Languages to Enhance Code-switching Speech Recognition.pdf",
        "analysis": {
            "benchmarks": [
                "SEAME dataset",
                "ASRU 2019 Mandarin-English code-switching speech recognition challenge"
            ],
            "base_models": [
                "Conformer-based hybrid CTC/attention ASR model",
                "Chinese LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatGPT4PCG Competition Character-like Level Generation for Science Birds": {
        "filename": "ChatGPT4PCG Competition Character-like Level Generation for Science Birds.pdf",
        "analysis": {
            "benchmarks": [
                "Science Birds"
            ],
            "base_models": [
                "GPT-3.5 (175B)"
            ]
        }
    },
    "Logic Query of Thoughts Guiding Large Language Models to Answer Complex Logic Queries with Knowledge Graphs": {
        "filename": "Logic Query of Thoughts Guiding Large Language Models to Answer Complex Logic Queries with Knowledge Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "MetaQA",
                "ComplexWebQuestions",
                "GraphQuestions"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2-7B"
            ]
        }
    },
    "Efficient Knowledge Distillation Empowering Small Language Models with Teacher Model Insights": {
        "filename": "Efficient Knowledge Distillation Empowering Small Language Models with Teacher Model Insights.pdf",
        "analysis": {
            "benchmarks": [
                "e-SNLI",
                "ANLI",
                "CQA",
                "SVAMP"
            ],
            "base_models": [
                "Flan-T5-3b (2.7B)",
                "PaLM (540B)"
            ]
        }
    },
    "An Evaluation of GPT-4V and Gemini in Online VQA": {
        "filename": "An Evaluation of GPT-4V and Gemini in Online VQA.pdf",
        "analysis": {
            "benchmarks": [
                "VQAonline"
            ],
            "base_models": [
                "GPT-4V",
                "Gemini"
            ]
        }
    },
    "A Large Language Model Approach to Educational Survey Feedback Analysis": {
        "filename": "A Large Language Model Approach to Educational Survey Feedback Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "real-world dataset of 2500 end-of-course survey comments from biomedical science courses"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Sands to Mansions Enabling Automatic Full-Life-Cycle Cyberattack Construction with LLM": {
        "filename": "From Sands to Mansions Enabling Automatic Full-Life-Cycle Cyberattack Construction with LLM.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 20 emulated cyberattacks"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Matchmaker Self-Improving Large Language Model Programs for Schema Matching": {
        "filename": "Matchmaker Self-Improving Large Language Model Programs for Schema Matching.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-OMOP",
                "Synthea-OMOP"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mitigating Label Biases for In-context Learning": {
        "filename": "Mitigating Label Biases for In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "TweetEval-hate",
                "SST-2"
            ],
            "base_models": [
                "GPT-J (6B)",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cognitive Overload AttackPrompt Injection for Long Context": {
        "filename": "Cognitive Overload AttackPrompt Injection for Long Context.pdf",
        "analysis": {
            "benchmarks": [
                "Forbidden Question Dataset",
                "JailbreakBench"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3.5 Sonnet",
                "Claude-3 OPUS",
                "Llama-3-70B-Instruct",
                "Gemini-1.0-Pro",
                "Gemini-1.5-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models Agent Models and World Models The LAW for Machine Reasoning and Planning": {
        "filename": "Language Models Agent Models and World Models The LAW for Machine Reasoning and Planning.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What and How does In-Context Learning Learn Bayesian Model Averaging Parameterization and Generalization": {
        "filename": "What and How does In-Context Learning Learn Bayesian Model Averaging Parameterization and Generalization.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FinPT Financial Risk Prediction with Profile Tuning on Pretrained Foundation Models": {
        "filename": "FinPT Financial Risk Prediction with Profile Tuning on Pretrained Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "FinBench"
            ],
            "base_models": [
                "GPT-2 (117M)",
                "LLaMA-7B (7B)",
                "LLaMA-13B (13B)",
                "BERT-Base (110M)",
                "FinBERT (110M)",
                "T5-Base (220M)",
                "Flan-T5-Base (220M)",
                "T5-XXL (11B)",
                "Flan-T5-XXL (11B)"
            ]
        }
    },
    "ICL-D3IE In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction": {
        "filename": "ICL-D3IE In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction.pdf",
        "analysis": {
            "benchmarks": [
                "FUNSD",
                "CORD",
                "SROIE"
            ],
            "base_models": [
                "Davinci-003 (175B)",
                "ChatGPT (gpt-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automated Data Visualization from Natural Language via Large Language Models An Exploratory Study": {
        "filename": "Automated Data Visualization from Natural Language via Large Language Models An Exploratory Study.pdf",
        "analysis": {
            "benchmarks": [
                "nvBench"
            ],
            "base_models": [
                "T5-Small",
                "GPT-3.5",
                "text-davinci-002",
                "text-davinci-003",
                "gpt-3.5-turbo-16k",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Privacy Preserving Prompt Engineering A Survey": {
        "filename": "Privacy Preserving Prompt Engineering A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "OPT",
                "OPT-IML",
                "BLOOM",
                "BLOOMZ",
                "Dolly"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Information Retrieval A Survey": {
        "filename": "Large Language Models for Information Retrieval A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "MSMARCO",
                "BEIR"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "LLaMA",
                "Flan-T5",
                "BLOOM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Honesty Is the Best Policy Defining and Mitigating AI Deception": {
        "filename": "Honesty Is the Best Policy Defining and Mitigating AI Deception.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VidCtx Context-aware Video Question Answering with Image Models": {
        "filename": "VidCtx Context-aware Video Question Answering with Image Models.pdf",
        "analysis": {
            "benchmarks": [
                "NExT-QA",
                "IntentQA",
                "STAR"
            ],
            "base_models": [
                "LLaVa-1.6-Mistral-7B"
            ]
        }
    },
    "EHRAgent Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records": {
        "filename": "EHRAgent Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-III",
                "eICU",
                "TREQS"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interactive Continual Learning Fast and Slow Thinking": {
        "filename": "Interactive Continual Learning Fast and Slow Thinking.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet-R"
            ],
            "base_models": [
                "ViT",
                "GPT-4",
                "MiniGPT4",
                "Inf-MLLM",
                "Pure-MM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instruct Large Language Models to Generate Scientific Literature Survey Step by Step": {
        "filename": "Instruct Large Language Models to Generate Scientific Literature Survey Step by Step.pdf",
        "analysis": {
            "benchmarks": [
                "NLPCC 2024 Scientific Literature Survey Generation evaluation task"
            ],
            "base_models": [
                "Qwen-long (version of Alibaba’s Tongyi Qianwen model)"
            ]
        }
    },
    "MedCalc-Bench Evaluating Large Language Models for Medical Calculations": {
        "filename": "MedCalc-Bench Evaluating Large Language Models for Medical Calculations.pdf",
        "analysis": {
            "benchmarks": [
                "MEDCALC-BENCH"
            ],
            "base_models": [
                "GPT-4",
                "Llama (8B and 70B)",
                "Mixtral (8x7B)",
                "Mistral (7B)",
                "PMC-LLaMA (13B)",
                "MEDITRON (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Embodied CoT Distillation From LLM To Off-the-shelf Agents": {
        "filename": "Embodied CoT Distillation From LLM To Off-the-shelf Agents.pdf",
        "analysis": {
            "benchmarks": [
                "ALFRED"
            ],
            "base_models": [
                "PaLM (540B)",
                "LLaMA2 (7B)",
                "GPT2-large (0.8B)",
                "GPT2 (0.2B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Explainable Automated Debugging via Large Language Model-driven Scientific Debugging": {
        "filename": "Explainable Automated Debugging via Large Language Model-driven Scientific Debugging.pdf",
        "analysis": {
            "benchmarks": [
                "Defects4J v1.2",
                "Defects4J v2.0",
                "Almost-Right HumanEval (ARHE)"
            ],
            "base_models": [
                "ChatGPT",
                "Codex (code-davinci-002)",
                "CodeGen-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generating Chain-of-Thoughts with a Pairwise-Comparison Approach to Searching for the Most Promising Intermediate Thought": {
        "filename": "Generating Chain-of-Thoughts with a Pairwise-Comparison Approach to Searching for the Most Promising Intermediate Thought.pdf",
        "analysis": {
            "benchmarks": [
                "AQuA",
                "Game of 24",
                "Sudoku Dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo-1106"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Decision-Oriented Dialogue for Human-AI Collaboration": {
        "filename": "Decision-Oriented Dialogue for Human-AI Collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "Assignment",
                "Planning",
                "Mediation"
            ],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are Language Models Worse than Humans at Following Prompts Its Complicated": {
        "filename": "Are Language Models Worse than Humans at Following Prompts Its Complicated.pdf",
        "analysis": {
            "benchmarks": [
                "RTE",
                "MNLI"
            ],
            "base_models": [
                "T5 (11B)",
                "T0 (11B)",
                "GPT-3 (175B)",
                "T0++ (11B)",
                "Flan-T5 (11B)",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "utoL Autonomous Evaluation of LLMs for Truth Maintenance and Reasoning Tasks": {
        "filename": "utoL Autonomous Evaluation of LLMs for Truth Maintenance and Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "∀uto∃∨∧L"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4o",
                "GPT-4o-mini",
                "LLama-3-8B-Instruct",
                "Mistral-v0.2-7B-Instruct",
                "Phi-3-medium-4k-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Pixels Text Enhances Generalization in Real-World Image Restoration": {
        "filename": "Beyond Pixels Text Enhances Generalization in Real-World Image Restoration.pdf",
        "analysis": {
            "benchmarks": [
                "RealIR"
            ],
            "base_models": [
                "Stable Diffusion 2.1",
                "SDXL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Training Table Question Answering via SQL Query Decomposition": {
        "filename": "Training Table Question Answering via SQL Query Decomposition.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTableQuestions"
            ],
            "base_models": [
                "BERT",
                "BART"
            ]
        }
    },
    "Predicting Emergent Abilities with Infinite Resolution Evaluation": {
        "filename": "Predicting Emergent Abilities with Infinite Resolution Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "Emoji Movie",
                "Date Understanding"
            ],
            "base_models": [
                "LLaMA (with varying sizes from 0.03B to 2.4B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Data to Commonsense Reasoning The Use of Large Language Models for Explainable AI": {
        "filename": "From Data to Commonsense Reasoning The Use of Large Language Models for Explainable AI.pdf",
        "analysis": {
            "benchmarks": [
                "Story Cloze Test",
                "CREAK",
                "CODAH",
                "COM2SENSE",
                "CosmosQA",
                "e-CARE",
                "ARC",
                "Social IQa",
                "COPA",
                "MedMCQA",
                "CommonsenseQA"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "Llama 3 (70B)",
                "Gemma (7B)"
            ]
        }
    },
    "Same Pre-training Loss Better Downstream Implicit Bias Matters for Language Models": {
        "filename": "Same Pre-training Loss Better Downstream Implicit Bias Matters for Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Task C",
                "QNLI",
                "Task B",
                "Task-10",
                "SST-2"
            ],
            "base_models": [
                "OPT (235M)",
                "Transformers (2M to 730M)",
                "LSTM (10M to 135M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "UPAR A Kantian-Inspired Prompting Framework for Enhancing Large Language Model Capabilities": {
        "filename": "UPAR A Kantian-Inspired Prompting Framework for Enhancing Large Language Model Capabilities.pdf",
        "analysis": {
            "benchmarks": [
                "SCIBENCH",
                "GSM8K",
                "AQUA-RAT",
                "CommonsenseQA",
                "StrategyQA",
                "Causal-Judgement task in BIG-Bench Hard (BBH)"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoMT Chain-of-Medical-Thought Reduces Hallucination in Medical Report Generation": {
        "filename": "CoMT Chain-of-Medical-Thought Reduces Hallucination in Medical Report Generation.pdf",
        "analysis": {
            "benchmarks": [
                "OpenI",
                "MIMIC-CXR"
            ],
            "base_models": [
                "GPT-4",
                "LLaVA-Med",
                "MiniGPT4",
                "XrayGPT",
                "mPLUG-Owl2",
                "R2Gen"
            ]
        }
    },
    "Faithful Question Answering with Monte-Carlo Planning": {
        "filename": "Faithful Question Answering with Monte-Carlo Planning.pdf",
        "analysis": {
            "benchmarks": [
                "EntailmentBankQA"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "ChatGPT",
                "T5-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Interaction to Impact Towards Safer AI Agents Through Understanding and Evaluating UI Operation Impacts": {
        "filename": "From Interaction to Impact Towards Safer AI Agents Through Understanding and Evaluating UI Operation Impacts.pdf",
        "analysis": {
            "benchmarks": [
                "MoTIF",
                "AndroidControl",
                "Impact Actions Dataset"
            ],
            "base_models": [
                "GPT-4",
                "Gemini 1.5 Flash",
                "MM1.5",
                "Ferret-UI"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unified Embedding Battle-Tested Feature Representations for Web-Scale ML Systems": {
        "filename": "Unified Embedding Battle-Tested Feature Representations for Web-Scale ML Systems.pdf",
        "analysis": {
            "benchmarks": [
                "Criteo",
                "Avazu",
                "Movielens"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "15-Pints Technical Report Pretraining in Days Not Months - Your Language Model Thrives on Quality Data": {
        "filename": "15-Pints Technical Report Pretraining in Days Not Months - Your Language Model Thrives on Quality Data.pdf",
        "analysis": {
            "benchmarks": [
                "MT-Bench"
            ],
            "base_models": [
                "Llama-2 (1.57B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AdaPlanner Adaptive Planning from Feedback with Language Models": {
        "filename": "AdaPlanner Adaptive Planning from Feedback with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld",
                "MiniWoB++"
            ],
            "base_models": [
                "GPT-3 (text-davinci-002)",
                "GPT-3.5 (gpt-3.5-turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TPD Enhancing Student Language Model Reasoning via Principle Discovery and Guidance": {
        "filename": "TPD Enhancing Student Language Model Reasoning via Principle Discovery and Guidance.pdf",
        "analysis": {
            "benchmarks": [
                "Tracking Shuffled Objects (5)",
                "Date Understanding",
                "Navigate",
                "Matrixshapes",
                "GSM8K",
                "SVAMP",
                "CoinFlip",
                "Last Letter Concatenation"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo-16k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Traces of Memorisation in Large Language Models for Code": {
        "filename": "Traces of Memorisation in Large Language Models for Code.pdf",
        "analysis": {
            "benchmarks": [
                "SATML Language Model Data Extraction Challenge",
                "Custom code dataset from Google BigQuery GitHub dataset"
            ],
            "base_models": [
                "CodeGen-Mono-16B",
                "GPT-NEO-1.3B",
                "Pythia-6.9B",
                "CodeGen-2B-Mono"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InteractiveIE Towards Assessing the Strength of Human-AI Collaboration in Improving the Performance of Information Extraction": {
        "filename": "InteractiveIE Towards Assessing the Strength of Human-AI Collaboration in Improving the Performance of Information Extraction.pdf",
        "analysis": {
            "benchmarks": [
                "Biomedical Slot Filling Dataset",
                "CUAD Dataset"
            ],
            "base_models": [
                "T5",
                "BART",
                "ChatGPT (gpt3.5-turbo)"
            ]
        }
    },
    "Leveraging Large Language Models for Multimodal Search": {
        "filename": "Leveraging Large Language Models for Multimodal Search.pdf",
        "analysis": {
            "benchmarks": [
                "Fashion200K"
            ],
            "base_models": [
                "CLIP-L (428M parameters)",
                "Flan T5 XL (3B parameters)"
            ]
        }
    },
    "Sci-CoT Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA": {
        "filename": "Sci-CoT Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA.pdf",
        "analysis": {
            "benchmarks": [
                "ARC-Easy",
                "ARC-Challenge"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Flan-T5-small (80M)"
            ]
        }
    },
    "Exploring the Trade-Offs Unified Large Language Models vs Local Fine-Tuned Models for Highly-Specific Radiology NLI Task": {
        "filename": "Exploring the Trade-Offs Unified Large Language Models vs Local Fine-Tuned Models for Highly-Specific Radiology NLI Task.pdf",
        "analysis": {
            "benchmarks": [
                "RadQNLI",
                "RadQA"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OptiMUS Optimization Modeling Using MIP Solvers and large language models": {
        "filename": "OptiMUS Optimization Modeling Using MIP Solvers and large language models.pdf",
        "analysis": {
            "benchmarks": [
                "NLP4LP"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Code Models are Zero-shot Precondition Reasoners": {
        "filename": "Code Models are Zero-shot Precondition Reasoners.pdf",
        "analysis": {
            "benchmarks": [
                "SGD dataset",
                "ALFworld benchmark"
            ],
            "base_models": [
                "CodeGen 2B",
                "StarCoder 16B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Knowledge Card Filling LLMs Knowledge Gaps with Plug-in Specialized Language Models": {
        "filename": "Knowledge Card Filling LLMs Knowledge Gaps with Plug-in Specialized Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "LUN misinformation detection",
                "MIDTERM QA"
            ],
            "base_models": [
                "Codex (175B)",
                "PaLM",
                "Flan-PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DistillSpec Improving Speculative Decoding via Knowledge Distillation": {
        "filename": "DistillSpec Improving Speculative Decoding via Knowledge Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "XSum",
                "GSM8K",
                "CNNDM",
                "WMT",
                "BigBenchHard"
            ],
            "base_models": [
                "T5 v1.1 (3B)",
                "T5-Small (77M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "IDOL Indicator-oriented Logic Pre-training for Logical Reasoning": {
        "filename": "IDOL Indicator-oriented Logic Pre-training for Logical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ReClor",
                "LogiQA",
                "RACE",
                "SQuAD 2.0",
                "MNLI",
                "STS-B"
            ],
            "base_models": [
                "BERT-large",
                "RoBERTa-large",
                "ALBERT-xxlarge",
                "DeBERTa-v2-xxlarge",
                "ChatGPT",
                "GPT-3.5",
                "GLM-130B"
            ]
        }
    },
    "Dont Generate Discriminate A Proposal for Grounding Language Models to Real-World Environments": {
        "filename": "Dont Generate Discriminate A Proposal for Grounding Language Models to Real-World Environments.pdf",
        "analysis": {
            "benchmarks": [
                "GRAIL QA",
                "GRAPH Q",
                "WEBQSP"
            ],
            "base_models": [
                "BERT-base",
                "T5-base",
                "T5-large",
                "T5-3B",
                "Codex"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems": {
        "filename": "A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems.pdf",
        "analysis": {
            "benchmarks": [
                "MultiWOZ",
                "DSTC"
            ],
            "base_models": [
                "GPT-3",
                "BERT",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Capable of Offering Cognitive Reappraisal if Guided": {
        "filename": "Large Language Models are Capable of Offering Cognitive Reappraisal if Guided.pdf",
        "analysis": {
            "benchmarks": [
                "Reddit posts from r/Anxiety, r/Anger, r/Parenting, r/COVID19_support"
            ],
            "base_models": [
                "GPT-4 turbo",
                "LLaMA-2 (13B-chat)",
                "Mistral (7B-instruct v0.1)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models": {
        "filename": "Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU Pro",
                "MMBench",
                "MMTBench"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini 1.5 Pro",
                "Claude 3.5 Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Robo-Instruct Simulator-Augmented Instruction Alignment For Finetuning CodeLLMs": {
        "filename": "Robo-Instruct Simulator-Augmented Instruction Alignment For Finetuning CodeLLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ROBOEVAL"
            ],
            "base_models": [
                "Llama3-8B",
                "CodeLlama-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging Large Language Models for Actionable Course Evaluation Student Feedback to Lecturers": {
        "filename": "Leveraging Large Language Models for Actionable Course Evaluation Student Feedback to Lecturers.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 742 student responses from 75 courses in a Computer Science department"
            ],
            "base_models": [
                "Llama2 (7B)"
            ]
        }
    },
    "Enabling Language Models to Implicitly Learn Self-Improvement": {
        "filename": "Enabling Language Models to Implicitly Learn Self-Improvement.pdf",
        "analysis": {
            "benchmarks": [
                "Anthropic/HH-RLHF",
                "OpenAI/Summary",
                "Synthetic Data"
            ],
            "base_models": [
                "PaLM 2 (Bison)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "General-purpose Clothes Manipulation with Semantic Keypoints": {
        "filename": "General-purpose Clothes Manipulation with Semantic Keypoints.pdf",
        "analysis": {
            "benchmarks": [
                "SoftGym"
            ],
            "base_models": [
                "Large Language Model (LLM)"
            ]
        }
    },
    "Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning": {
        "filename": "Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "SVAMP",
                "AddSub",
                "SingleEq",
                "SingleOp"
            ],
            "base_models": [
                "Llama2-7B",
                "GPT2-XL (1.5B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing LLM-based Test Generation for Hard-to-Cover Branches via Program Analysis": {
        "filename": "Enhancing LLM-based Test Generation for Hard-to-Cover Branches via Program Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "27 open-source Python projects"
            ],
            "base_models": [
                "Phind-CodeLlama-34B-v2",
                "DeepSeek-Coder-6.7B-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model Enhanced Text-to-SQL Generation A Survey": {
        "filename": "Large Language Model Enhanced Text-to-SQL Generation A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "WikiSQL",
                "KaggleDBQA",
                "DuSQL",
                "BIRD",
                "BEAVER",
                "CoSQL",
                "CHASE",
                "EHRSQL",
                "ADVETA",
                "Spider-DK",
                "Spider-SS&CG",
                "Spider-SYN",
                "Spider-SSP",
                "Spider-Realistic",
                "CSpider",
                "TrustSQL",
                "BigTable-0.2k",
                "SParC"
            ],
            "base_models": [
                "ChatGPT-4",
                "BERT",
                "GPT",
                "T5",
                "Code Llama"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Knowledge Graph Reasoning on Graph Types Static Dynamic and Multi-Modal": {
        "filename": "A Survey of Knowledge Graph Reasoning on Graph Types Static Dynamic and Multi-Modal.pdf",
        "analysis": {
            "benchmarks": [
                "WN18RR",
                "FB15k-237",
                "NELL-995"
            ],
            "base_models": [
                "TransE",
                "RotatE",
                "QuatE",
                "InteractE",
                "DualE",
                "HAKE",
                "MuRP",
                "ConEx",
                "HousE",
                "RESCAL",
                "DisMult",
                "ComplEX",
                "TuckER",
                "ConvE",
                "HypER",
                "ConvKB",
                "ConvR",
                "ComplEX-DURA",
                "LowFER",
                "RGCN",
                "SACN",
                "KBGAT",
                "COMPGCN",
                "DPMPN",
                "RGHAT",
                "RED-GNN",
                "NeuralLP",
                "MINERVA",
                "M-walk",
                "pLogicNet",
                "CURL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval": {
        "filename": "Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "simulated conversations",
                "real user experiments"
            ],
            "base_models": [
                "GPT-3.5-turbo-instruct",
                "Llama 3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Improved Traditional Chinese Evaluation Suite for Foundation Model": {
        "filename": "An Improved Traditional Chinese Evaluation Suite for Foundation Model.pdf",
        "analysis": {
            "benchmarks": [
                "TMMLU+",
                "Taiwanese Trivia Question Answering (TTQA)"
            ],
            "base_models": [
                "Qwen-72B",
                "Qwen-14B",
                "Yi-34B-Chat",
                "GPT-4",
                "GPT-3.5-turbo",
                "Claude-1.3",
                "Claude-2.0",
                "Claude-3.0",
                "Gemini-pro",
                "Taiwan-LLM-13B",
                "Taiwan-LLM-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Synapse Trajectory-as-Exemplar Prompting with Memory for Computer Control": {
        "filename": "Synapse Trajectory-as-Exemplar Prompting with Memory for Computer Control.pdf",
        "analysis": {
            "benchmarks": [
                "MiniWoB++",
                "Mind2Web"
            ],
            "base_models": [
                "GPT-3.5",
                "CodeLlama-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Solving math word problems with process- and outcome-based feedback": {
        "filename": "Solving math word problems with process- and outcome-based feedback.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "PaLM-540B",
                "Minerva-540B",
                "GPT-J-6B",
                "Codex-175B",
                "InstructGPT-175B",
                "GPT-175B",
                "Our Base-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LTGC Long-Tail Recognition via Leveraging LLMs-Driven Generated Content": {
        "filename": "LTGC Long-Tail Recognition via Leveraging LLMs-Driven Generated Content.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet-LT",
                "Places-LT",
                "iNaturalist 2018"
            ],
            "base_models": [
                "GPT-4V (Vision)",
                "ChatGPT (GPT-4)",
                "DALL-E",
                "CLIP (ViT-B/32)"
            ]
        }
    },
    "Semi-Supervised Multimodal Multi-Instance Learning for Aortic Stenosis Diagnosis": {
        "filename": "Semi-Supervised Multimodal Multi-Instance Learning for Aortic Stenosis Diagnosis.pdf",
        "analysis": {
            "benchmarks": [
                "TMED-2",
                "TMED-2022"
            ],
            "base_models": [
                "Swin Transformer-T",
                "Video Swin Transformer-T"
            ]
        }
    },
    "Sparse Rewards Can Self-Train Dialogue Agents": {
        "filename": "Sparse Rewards Can Self-Train Dialogue Agents.pdf",
        "analysis": {
            "benchmarks": [
                "ToolWOZ",
                "τ-bench",
                "MT-Bench",
                "LMSYS-Chatbot Arena Human Preference Predictions"
            ],
            "base_models": [
                "meta-llama3-8B-instruct",
                "gpt-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exposing the Achilles Heel Evaluating LLMs Ability to Handle Mistakes in Mathematical Reasoning": {
        "filename": "Exposing the Achilles Heel Evaluating LLMs Ability to Handle Mistakes in Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MWP-MISTAKE",
                "GSM-8K",
                "MATH",
                "MATHBENCH",
                "JEEBENCH"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4",
                "GPT-3.5Turbo",
                "Claude-3-Opus",
                "Llama-2-7b-chat",
                "Phi-3-mini",
                "Mixtral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey on Large Language Models from General Purpose to Medical Applications Datasets Methodologies and Evaluations": {
        "filename": "A Survey on Large Language Models from General Purpose to Medical Applications Datasets Methodologies and Evaluations.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "MedQA",
                "PubMedQA",
                "MedMCQA"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Vinoground Scrutinizing LMMs over Dense Temporal Reasoning with Short Videos": {
        "filename": "Vinoground Scrutinizing LMMs over Dense Temporal Reasoning with Short Videos.pdf",
        "analysis": {
            "benchmarks": [
                "Vinoground",
                "EgoSchema",
                "ActivityNet-QA",
                "MSVD",
                "MSRVTT"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini-1.5-Pro",
                "LLaV A-OneVision",
                "Qwen2-VL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Systematic Evaluation of GPT-3 for Zero-Shot Personality Estimation": {
        "filename": "Systematic Evaluation of GPT-3 for Zero-Shot Personality Estimation.pdf",
        "analysis": {
            "benchmarks": [
                "Custom Facebook dataset for personality estimation"
            ],
            "base_models": [
                "GPT-3"
            ]
        }
    },
    "NExT Teaching Large Language Models to Reason about Code Execution": {
        "filename": "NExT Teaching Large Language Models to Reason about Code Execution.pdf",
        "analysis": {
            "benchmarks": [
                "Mbpp-R",
                "HumanEvalFix-Plus"
            ],
            "base_models": [
                "PaLM 2-L"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Brittle Foundations of ReAct Prompting for Agentic Large Language Models": {
        "filename": "On the Brittle Foundations of ReAct Prompting for Agentic Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HotPotQA",
                "FEVER",
                "AlfWorld"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-3.5-instruct",
                "GPT-4",
                "Claude-Opus"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Glimpse in ChatGPT Capabilities and its impact for AI research": {
        "filename": "A Glimpse in ChatGPT Capabilities and its impact for AI research.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "ChatGPT-3.4",
                "ChatGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MoVLExploring Fusion Strategies for the Domain-Adaptive Application of Pretrained Models in Medical Imaging Tasks": {
        "filename": "MoVLExploring Fusion Strategies for the Domain-Adaptive Application of Pretrained Models in Medical Imaging Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "HAM10000",
                "PathMNIST",
                "BloodMNIST",
                "Camelyon17"
            ],
            "base_models": [
                "ResNet18",
                "ResNet50",
                "CLIP ViT-B/32",
                "CLIP ViT-L/14"
            ]
        }
    },
    "Evaluating GPT-35 and GPT-4 Models on Brazilian University Admission Exams": {
        "filename": "Evaluating GPT-35 and GPT-4 Models on Brazilian University Admission Exams.pdf",
        "analysis": {
            "benchmarks": [
                "ENEM Challenge (2009-2017)",
                "ENEM 2022"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "GRM Generative Relevance Modeling Using Relevance-Aware Sample Estimation for Document Retrieval": {
        "filename": "GRM Generative Relevance Modeling Using Relevance-Aware Sample Estimation for Document Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "TREC Robust04",
                "CODEC"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "Keeping Users Engaged During Repeated Interviews by a Virtual Agent Using Large Language Models to Reliably Diversify Questions": {
        "filename": "Keeping Users Engaged During Repeated Interviews by a Virtual Agent Using Large Language Models to Reliably Diversify Questions.pdf",
        "analysis": {
            "benchmarks": [
                "PROMIS® short form depression questionnaire",
                "PHQ-8"
            ],
            "base_models": [
                "ChatGPT (March 2023 version)",
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TraderTalk An LLM Behavioural ABM applied to Simulating Human Bilateral Trading Interactions": {
        "filename": "TraderTalk An LLM Behavioural ABM applied to Simulating Human Bilateral Trading Interactions.pdf",
        "analysis": {
            "benchmarks": [
                "UK Gilt bonds market"
            ],
            "base_models": [
                "GPT-4o-mini"
            ]
        }
    },
    "Vision Language Models Can Parse Floor Plan Maps": {
        "filename": "Vision Language Models Can Parse Floor Plan Maps.pdf",
        "analysis": {
            "benchmarks": [
                "CVC-FP"
            ],
            "base_models": [
                "GPT-4o",
                "Claude-3.5 Sonnet"
            ]
        }
    },
    "Investigating the Translation Performance of a Large Multilingual Language Model the Case of BLOOM": {
        "filename": "Investigating the Translation Performance of a Large Multilingual Language Model the Case of BLOOM.pdf",
        "analysis": {
            "benchmarks": [
                "WMT 2014",
                "Flores-101",
                "DiaBLa"
            ],
            "base_models": [
                "BLOOM (176B)",
                "BLOOM-7b1",
                "BLOOM-3b",
                "BLOOM-1b1",
                "BLOOM-560m"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Voyager An Open-Ended Embodied Agent with Large Language Models": {
        "filename": "Voyager An Open-Ended Embodied Agent with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MineDojo"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AI for social science and social science of AI A Survey": {
        "filename": "AI for social science and social science of AI A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "Depression_Reddit",
                "CLPsych15",
                "Dreaddit",
                "SAD",
                "SemEval-2016 Stance detecting Dataset",
                "IBC",
                "Politifact Fact Check",
                "LatentHatred",
                "Misinfon Reaction Frames",
                "FPB",
                "FiQA SA",
                "Headlines",
                "BigData",
                "StockNet",
                "CIKM18",
                "NER",
                "NER+NED",
                "ConvFinQA"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "ChatGPT",
                "PaLM",
                "LLaMA",
                "BloombergGPT (50 billion parameters)",
                "GPT-Neo",
                "OPT",
                "BLOOM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain of Code Reasoning with a Language Model-Augmented Code Emulator": {
        "filename": "Chain of Code Reasoning with a Language Model-Augmented Code Emulator.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench Hard",
                "GSM8K"
            ],
            "base_models": [
                "text-davinci-003",
                "PaLM-2 (code variant)",
                "gpt-3.5-turbo",
                "gpt-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Security and Privacy Challenges of Large Language Models A Survey": {
        "filename": "Security and Privacy Challenges of Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Teams of LLM Agents can Exploit Zero-Day Vulnerabilities": {
        "filename": "Teams of LLM Agents can Exploit Zero-Day Vulnerabilities.pdf",
        "analysis": {
            "benchmarks": [
                "Custom benchmark of 15 real-world zero-day vulnerabilities"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Self-Selected Attention Span for Accelerating Large Language Model Inference": {
        "filename": "Self-Selected Attention Span for Accelerating Large Language Model Inference.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset for complex arithmetic expression evaluation",
                "Custom dataset for news article summarization"
            ],
            "base_models": [
                "LLaMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models": {
        "filename": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Multi-Session Chat Dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo",
                "Llama2-7b"
            ]
        }
    },
    "The Buffer Mechanism for Multi-Step Information Reasoning in Language Models": {
        "filename": "The Buffer Mechanism for Multi-Step Information Reasoning in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PrOntoQA"
            ],
            "base_models": [
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Thought Prompting for Speech Translation": {
        "filename": "Chain-of-Thought Prompting for Speech Translation.pdf",
        "analysis": {
            "benchmarks": [
                "FLEURS"
            ],
            "base_models": [
                "Megatron-T5 (1.2B)",
                "Canary-1B (650M)"
            ]
        }
    },
    "Speak It Out Solving Symbol-Related Problems with Symbol-to-Language Conversion for Language Models": {
        "filename": "Speak It Out Solving Symbol-Related Problems with Symbol-to-Language Conversion for Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "1D-ARC",
                "Dyck Language",
                "ChemLLMBench",
                "EmoTag1200",
                "WikiTableQuestions",
                "TabFact",
                "TweetSentimentExtraction",
                "P-Stance"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "OpenChat-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do We Really Need a Complex Agent System Distill Embodied Agent into a Single Model": {
        "filename": "Do We Really Need a Complex Agent System Distill Embodied Agent into a Single Model.pdf",
        "analysis": {
            "benchmarks": [
                "MineDojo",
                "Minecraft's open-ended environment"
            ],
            "base_models": [
                "LLaMA2-13b",
                "GPT-4V(ision)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Memory Augmented Large Language Models are Computationally Universal": {
        "filename": "Memory Augmented Large Language Models are Computationally Universal.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Flan-U-PaLM 540B"
            ]
        }
    },
    "H2O Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models": {
        "filename": "H2O Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "lm-eval-harness",
                "HELM"
            ],
            "base_models": [
                "OPT-6.7B",
                "OPT-30B",
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-30B",
                "GPT-NeoX-20B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Comprehensive Survey of AI-Generated Content AIGC A History of Generative AI from GAN to ChatGPT": {
        "filename": "A Comprehensive Survey of AI-Generated Content AIGC A History of Generative AI from GAN to ChatGPT.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175B)",
                "BERT",
                "RoBERTa",
                "XL-Net",
                "GPT-2",
                "T5",
                "BART",
                "Vision Transformer (ViT)",
                "Swin Transformer",
                "CLIP",
                "DALL-E-2",
                "GLIDE",
                "Imagen"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FiLM Fill-in Language Models for Any-Order Generation": {
        "filename": "FiLM Fill-in Language Models for Any-Order Generation.pdf",
        "analysis": {
            "benchmarks": [
                "WikiText-103",
                "One Billion Word",
                "ROCStories"
            ],
            "base_models": [
                "GPT2-xl (1558M)",
                "RoBERTa-large (355M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Collaborative Knowledge Infusion for Low-resource Stance Detection": {
        "filename": "Collaborative Knowledge Infusion for Low-resource Stance Detection.pdf",
        "analysis": {
            "benchmarks": [
                "VAST",
                "P-Stance",
                "COVID-19-Stance"
            ],
            "base_models": [
                "RoBERTa-Large",
                "BERT-Large",
                "CT-BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Second Thoughts are Best Learning to Re-Align With Human Values from Text Edits": {
        "filename": "Second Thoughts are Best Learning to Re-Align With Human Values from Text Edits.pdf",
        "analysis": {
            "benchmarks": [
                "Moral Stories",
                "MIC",
                "ETHICS-Deontology"
            ],
            "base_models": [
                "GPT-2 (345M)",
                "GPT-3 (1.3B)",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Query Rewriting for Retrieval-Augmented Large Language Models": {
        "filename": "Query Rewriting for Retrieval-Augmented Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "AmbigNQ",
                "PopQA",
                "MMLU"
            ],
            "base_models": [
                "T5-large (770M)",
                "ChatGPT",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Framework to Implement 1N Multi-task Fine-tuning Pattern in LLMs Using the CGC-LORA Algorithm": {
        "filename": "A Framework to Implement 1N Multi-task Fine-tuning Pattern in LLMs Using the CGC-LORA Algorithm.pdf",
        "analysis": {
            "benchmarks": [
                "Prompt Chinese Biomedical Language Understanding Evaluation (PromptCBLUE)",
                "Firefly"
            ],
            "base_models": [
                "ChatGPT",
                "ChatGLM-6B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Adapting to Cyber Threats A Phishing Evolution Network PEN Framework for Phishing Generation and Analyzing Evolution Patterns using Large Language Models": {
        "filename": "Adapting to Cyber Threats A Phishing Evolution Network PEN Framework for Phishing Generation and Analyzing Evolution Patterns using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "IWSPA",
                "Nazario",
                "Miller Smiles",
                "Phishing Bowl",
                "Nigerian Fraud",
                "Cambridge dataset"
            ],
            "base_models": [
                "Llama 3.1-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoachLM Automatic Instruction Revisions Improve the Data Quality in LLM Instruction Tuning": {
        "filename": "CoachLM Automatic Instruction Revisions Improve the Data Quality in LLM Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "CoachLM150",
                "PandaLM170",
                "Vicuna80",
                "Self-Instruct252"
            ],
            "base_models": [
                "ChatGLM2 (6B)",
                "LLaMA (7B)",
                "ChatGLM (6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Diffusion Beats Autoregressive An Evaluation of Compositional Generation in Text-to-Image Models": {
        "filename": "Diffusion Beats Autoregressive An Evaluation of Compositional Generation in Text-to-Image Models.pdf",
        "analysis": {
            "benchmarks": [
                "T2I-CompBench"
            ],
            "base_models": [
                "Stable Diffusion (SD-v1.4, 860M parameters)",
                "Stable Diffusion (SD-v2, 860M parameters)",
                "Stable Diffusion (SD-XL, 3.5B parameters)",
                "DALL-E3",
                "Pixart-α (600M parameters)",
                "FLUX-Dev",
                "FLUX-Schnell",
                "LlamaGen-Stage1 (775M parameters)",
                "LlamaGen-Stage2 (775M parameters)"
            ]
        }
    },
    "Prompting Large Language Models for Zero-Shot Clinical Prediction with Structured Longitudinal Electronic Health Record Data": {
        "filename": "Prompting Large Language Models for Zero-Shot Clinical Prediction with Structured Longitudinal Electronic Health Record Data.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-IV",
                "TJH"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Gemini Pro",
                "Llama 2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Code Simulation Challenges for Large Language Models": {
        "filename": "Code Simulation Challenges for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "straight-line code simulation",
                "smart execution via critical paths",
                "approximate computation",
                "redundant algorithms",
                "nested loops",
                "sorting algorithms"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "Jurassic2-Ultra",
                "LLaMA3-70B",
                "LLaMA2-70B",
                "CodeLLaMA-34b-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Boosting Language Models Reasoning with Chain-of-Knowledge Prompting": {
        "filename": "Boosting Language Models Reasoning with Chain-of-Knowledge Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "StrategyQA",
                "OpenBookQA",
                "ARC-c",
                "BoolQ",
                "GSM8K",
                "SVAMP",
                "AQuA",
                "MultiArith"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "gpt-3.5-turbo",
                "gpt-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathGAP Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs": {
        "filename": "MathGAP Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs.pdf",
        "analysis": {
            "benchmarks": [
                "MathGAP"
            ],
            "base_models": [
                "Mixtral-8x7B",
                "Llama3-8B",
                "Llama3-70B",
                "GPT-3.5-Turbo",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning Beyond Pattern Matching Assaying Mathematical Understanding in LLMs": {
        "filename": "Learning Beyond Pattern Matching Assaying Mathematical Understanding in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "KhanSkill",
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "CodeLlama-7b",
                "Llemma-7b",
                "Mistral-7b",
                "Mixtral-8x7b Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HPT Hierarchically Prompting Vision-Language Models with Multi-Granularity Knowledge Generation and Improved Structure Modeling": {
        "filename": "HPT Hierarchically Prompting Vision-Language Models with Multi-Granularity Knowledge Generation and Improved Structure Modeling.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "Caltech101",
                "OxfordPets",
                "StanfordCars",
                "Flowers102",
                "Food101",
                "FGVCAircraft",
                "SUN397",
                "UCF101",
                "DTD",
                "EuroSAT",
                "ImageNetV2",
                "ImageNet-Sketch",
                "ImageNet-A",
                "ImageNet-R"
            ],
            "base_models": [
                "CLIP (ViT-B/16)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Two-Hop Curse LLMs trained on A-B B-C fail to learn A--C": {
        "filename": "The Two-Hop Curse LLMs trained on A-B B-C fail to learn A--C.pdf",
        "analysis": {
            "benchmarks": [
                "Synthetic dataset of fictional facts"
            ],
            "base_models": [
                "Llama 3 8B Instruct",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Not Just Novelty A Longitudinal Study on Utility and Customization of an AI Workflow": {
        "filename": "Not Just Novelty A Longitudinal Study on Utility and Customization of an AI Workflow.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CS-Bench A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery": {
        "filename": "CS-Bench A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery.pdf",
        "analysis": {
            "benchmarks": [
                "CS-Bench"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4o",
                "GPT-3.5",
                "PaLM-2",
                "Claude-2.1",
                "Claude-3",
                "Llama2-7B",
                "Llama2-13B",
                "Llama2-70B",
                "Llama3-8B",
                "Llama3-70B",
                "Qwen1.5-4B",
                "Qwen1.5-7B",
                "Qwen1.5-14B",
                "Qwen1.5-32B",
                "Qwen1.5-72B",
                "Qwen1.5-110B",
                "Gemma-2B",
                "Gemma-7B",
                "ChatGLM3-6B",
                "Baichuan2-7B",
                "Baichuan2-13B",
                "InternLM2-7B",
                "InternLM2-20B",
                "Mistral-7B",
                "Mixtral-8×7B",
                "DeepSeekLLM-7B",
                "DeepSeekLLM-67B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Understand and Can be Enhanced by Emotional Stimuli": {
        "filename": "Large Language Models Understand and Can be Enhanced by Emotional Stimuli.pdf",
        "analysis": {
            "benchmarks": [
                "Instruction Induction",
                "BIG-Bench"
            ],
            "base_models": [
                "Flan-T5-Large",
                "Vicuna",
                "Llama 2",
                "BLOOM",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Toward Grounded Commonsense Reasoning": {
        "filename": "Toward Grounded Commonsense Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MESSY SURFACES"
            ],
            "base_models": [
                "GPT-4",
                "InstructBLIP (Flan-T5-XXL)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Harnessing Knowledge and Reasoning for Human-Like Natural Language Generation A Brief Review": {
        "filename": "Harnessing Knowledge and Reasoning for Human-Like Natural Language Generation A Brief Review.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3",
                "BERT",
                "BART",
                "T5",
                "COMET",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM4SGG Large Language Models for Weakly Supervised Scene Graph Generation": {
        "filename": "LLM4SGG Large Language Models for Weakly Supervised Scene Graph Generation.pdf",
        "analysis": {
            "benchmarks": [
                "Visual Genome",
                "GQA"
            ],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lion Adversarial Distillation of Proprietary Large Language Models": {
        "filename": "Lion Adversarial Distillation of Proprietary Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench Hard (BBH)",
                "AGIEval",
                "Vicuna-Instructions"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "LLaMA (13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do Large Language Models Know about Facts": {
        "filename": "Do Large Language Models Know about Facts.pdf",
        "analysis": {
            "benchmarks": [
                "Pinocchio",
                "FEVER",
                "FEVEROUS",
                "Symmetric",
                "FM2",
                "VitaminC",
                "PolitiFact",
                "PubHealth",
                "SciFact",
                "XFact",
                "CHEF"
            ],
            "base_models": [
                "OPT-6.7B",
                "BLOOM-7B",
                "LLaMA-7B",
                "Alpaca-7B",
                "Vicuna-7B",
                "Vicuna-13B",
                "ChatGLM-6B",
                "Flan-T5-11B",
                "Text-Davinci-002",
                "Text-Davinci-003",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generalized Robot Learning Framework": {
        "filename": "Generalized Robot Learning Framework.pdf",
        "analysis": {
            "benchmarks": [
                "10 distinct robotic tasks (custom dataset)"
            ],
            "base_models": [
                "ResNet18",
                "ResNet34",
                "FPN ResNet34",
                "Denoising Diffusion Probabilistic Model (DDPM)"
            ]
        }
    },
    "Why does in-context learning fail sometimes Evaluating in-context learning on open and closed questions": {
        "filename": "Why does in-context learning fail sometimes Evaluating in-context learning on open and closed questions.pdf",
        "analysis": {
            "benchmarks": [
                "Custom open-form questions dataset",
                "MetaICL",
                "NephSAP"
            ],
            "base_models": [
                "GPT-4 (gpt-4-1106-preview)"
            ]
        }
    },
    "Bridging Text and Molecule A Survey on Multimodal Frameworks for Molecule": {
        "filename": "Bridging Text and Molecule A Survey on Multimodal Frameworks for Molecule.pdf",
        "analysis": {
            "benchmarks": [
                "MoleculeNet",
                "ChEBI-20"
            ],
            "base_models": [
                "T5",
                "GPT-3.5",
                "LLaMA 2",
                "Vicuna-13b",
                "Vicuna-7b"
            ]
        }
    },
    "Can neural networks do arithmetic A survey on the elementary numerical skills of state-of-the-art deep learning models": {
        "filename": "Can neural networks do arithmetic A survey on the elementary numerical skills of state-of-the-art deep learning models.pdf",
        "analysis": {
            "benchmarks": [
                "Dolphin18K",
                "Math23K",
                "AQuA",
                "MathQA",
                "ASDiv",
                "GSM8K",
                "SVAMP",
                "Mathematics (Saxton et al., 2019)",
                "NumGLUE",
                "MATH"
            ],
            "base_models": [
                "GPT-3",
                "T5",
                "PaLM (540B)",
                "Minerva (based on PaLM)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "TCMD A Traditional Chinese Medicine QA Dataset for Evaluating Large Language Models": {
        "filename": "TCMD A Traditional Chinese Medicine QA Dataset for Evaluating Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TCMD",
                "Chinese National Medical Licensing Examination For Traditional Chinese Medicine"
            ],
            "base_models": [
                "ChatGPT4",
                "GPT-35-turbo-instruct",
                "Moonshot-v1-8k",
                "AquilaChat2-34B",
                "AquilaChat2-7B",
                "Baichuan2-13B-Base",
                "Baichuan2-7B-Base",
                "Baichuan-13B-Base",
                "Baichuan-7B",
                "ChatGLM3-6B",
                "ChatGLM2-6B",
                "ChatGLM-6B",
                "InternLM2-Chat-20B",
                "InternLM2-Chat-7B",
                "Qwen-14B-Chat",
                "Qwen-7B-Chat",
                "Vicuna-7B",
                "ChatMed-Consult",
                "ShenNong-TCM-LLM",
                "Huatuo-Llama-Med-Chinese"
            ]
        }
    },
    "On Limitations of the Transformer Architecture": {
        "filename": "On Limitations of the Transformer Architecture.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": []
        }
    },
    "On the Effectiveness of Large Language Models in Domain-Specific Code Generation": {
        "filename": "On the Effectiveness of Large Language Models in Domain-Specific Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "MBPP",
                "CodeSearchNet (Golang)"
            ],
            "base_models": [
                "ChatGPT-3.5-turbo (154B)",
                "PolyCoder-2.7B",
                "CodeLlama-7B",
                "StarCoder-15.5B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Aligning with Logic Measuring Evaluating and Improving Logical Consistency in Large Language Models": {
        "filename": "Aligning with Logic Measuring Evaluating and Improving Logical Consistency in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SummEval",
                "NovelEval",
                "CaTeRS"
            ],
            "base_models": [
                "Llama-3-8B",
                "Gemma-2-9B",
                "Phi-3-mini",
                "Phi-3-medium",
                "GPT-3.5-0125",
                "Deepseek-chat",
                "Mistral-7B",
                "Zephyr-7B-beta",
                "Llama-2-7B",
                "Llama-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds": {
        "filename": "Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds.pdf",
        "analysis": {
            "benchmarks": [
                "CNMLE-Clinical",
                "CMExam"
            ],
            "base_models": [
                "GPT-3.5-Turbo (175B)",
                "Baichuan2-7B-Chat (7B)",
                "GPT-4 (~1.7T)"
            ]
        }
    },
    "ThinkSum Probabilistic reasoning over sets using large language models": {
        "filename": "ThinkSum Probabilistic reasoning over sets using large language models.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-bench"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "InstructGPT",
                "GPT-2 XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Compositional Sculpting of Iterative Generative Processes": {
        "filename": "Compositional Sculpting of Iterative Generative Processes.pdf",
        "analysis": {
            "benchmarks": [
                "Custom image generation dataset",
                "Custom molecular generation dataset"
            ],
            "base_models": [
                "GFlowNets",
                "Diffusion models"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "People use fast goal-directed simulation to reason about novel games": {
        "filename": "People use fast goal-directed simulation to reason about novel games.pdf",
        "analysis": {
            "benchmarks": [
                "Novel grid game variants (n=121 games)"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Looped ReLU MLPs May Be All You Need as Practical Programmable Computers": {
        "filename": "Looped ReLU MLPs May Be All You Need as Practical Programmable Computers.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RLAIF vs RLHF Scaling Reinforcement Learning from Human Feedback with AI Feedback": {
        "filename": "RLAIF vs RLHF Scaling Reinforcement Learning from Human Feedback with AI Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "Reddit TL;DR",
                "OpenAI's Human Preferences",
                "Anthropic Helpful and Harmless Human Preferences"
            ],
            "base_models": [
                "PaLM 2 Large",
                "PaLM 2 Small",
                "PaLM 2 Extra-Small"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MAD-Sherlock Multi-Agent Debates for Out-of-Context Misinformation Detection": {
        "filename": "MAD-Sherlock Multi-Agent Debates for Out-of-Context Misinformation Detection.pdf",
        "analysis": {
            "benchmarks": [
                "NewsCLIPpings"
            ],
            "base_models": [
                "LLaVA",
                "GPT-4o"
            ]
        }
    },
    "Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning": {
        "filename": "Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Zendo",
                "ActiveACRE"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Inference time LLM alignment in single and multidomain preference spectrum": {
        "filename": "Inference time LLM alignment in single and multidomain preference spectrum.pdf",
        "analysis": {
            "benchmarks": [
                "PersonaHub"
            ],
            "base_models": [
                "Mistral-7B-Instruct-v0.3"
            ]
        }
    },
    "Explanations from Large Language Models Make Small Reasoners Better": {
        "filename": "Explanations from Large Language Models Make Small Reasoners Better.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "StrategyQA",
                "OpenbookQA"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "T5-base",
                "T5-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoBench Automatic Testbench Generation and Evaluation Using LLMs for HDL Design": {
        "filename": "AutoBench Automatic Testbench Generation and Evaluation Using LLMs for HDL Design.pdf",
        "analysis": {
            "benchmarks": [
                "Golden RTL Solution",
                "Golden TestBench",
                "Mutants of Golden RTL"
            ],
            "base_models": [
                "GPT-4 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chameleon Plug-and-Play Compositional Reasoning with Large Language Models": {
        "filename": "Chameleon Plug-and-Play Compositional Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "TabMWP"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Decomposed Prompting A Modular Approach for Solving Complex Tasks": {
        "filename": "Decomposed Prompting A Modular Approach for Solving Complex Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "CommaQA-E",
                "2WikiMultihopQA",
                "MuSiQue",
                "HotpotQA",
                "GSM8K",
                "MultiArith"
            ],
            "base_models": [
                "GPT-3 (text-davinci-002)",
                "GPT-3 (text-davinci-001)",
                "GPT-3 (text-curie-001)",
                "Codex (code-davinci-002)",
                "Flan-T5-Large (0.7B)",
                "Flan-T5-XL (3B)",
                "Flan-T5-XXL (11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MultiPrompter Cooperative Prompt Optimization with Multi-Agent Reinforcement Learning": {
        "filename": "MultiPrompter Cooperative Prompt Optimization with Multi-Agent Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "COCO"
            ],
            "base_models": [
                "GPT-2"
            ]
        }
    },
    "Tree of Uncertain Thoughts Reasoning for Large Language Models": {
        "filename": "Tree of Uncertain Thoughts Reasoning for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Game of 24",
                "Mini Crosswords"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2-70B"
            ]
        }
    },
    "sigma-GPTs A New Approach to Autoregressive Models": {
        "filename": "sigma-GPTs A New Approach to Autoregressive Models.pdf",
        "analysis": {
            "benchmarks": [
                "Wikitext-103",
                "OpenWeb Text",
                "Maze Path Solving",
                "Aircraft Vertical Rate Prediction"
            ],
            "base_models": [
                "GPT-2 (123M)",
                "GPT-2 (345M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Feedback-guided Data Synthesis for Imbalanced Classification": {
        "filename": "Feedback-guided Data Synthesis for Imbalanced Classification.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet-LT",
                "Places-LT",
                "NICO++"
            ],
            "base_models": [
                "Latent Diffusion Model (LDM-unclip v2-1)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Test smells in LLM-Generated Unit Tests": {
        "filename": "Test smells in LLM-Generated Unit Tests.pdf",
        "analysis": {
            "benchmarks": [
                "SF110",
                "Defects4J",
                "Custom mini dataset (CMD)",
                "Cat-LM"
            ],
            "base_models": [
                "GPT-3.5 turbo (175B)",
                "GPT-4 (1750B)",
                "Mistral 7B (7B)",
                "Mixtral 8x7B (46.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Benchmarking Mobile Device Control Agents across Diverse Configurations": {
        "filename": "Benchmarking Mobile Device Control Agents across Diverse Configurations.pdf",
        "analysis": {
            "benchmarks": [
                "B-MoCA"
            ],
            "base_models": [
                "GPT-4o",
                "Gemini-1.5-pro",
                "Llama-3 (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tina Think Interaction and Action Framework for Zero-Shot Vision Language Navigation": {
        "filename": "Tina Think Interaction and Action Framework for Zero-Shot Vision Language Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "Room-to-Room (R2R) dataset"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Verbalized Probabilistic Graphical Modeling with Large Language Models": {
        "filename": "Verbalized Probabilistic Graphical Modeling with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "ChatCoach"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Solving Token Gradient Conflict in Mixture-of-Experts for Large Vision-Language Model": {
        "filename": "Solving Token Gradient Conflict in Mixture-of-Experts for Large Vision-Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "VQA-v2",
                "GQA",
                "VizWiz",
                "ScienceQA",
                "TextVQA",
                "ChartQA",
                "DocVQA",
                "POPE",
                "MME",
                "MMBench",
                "MM-Vet",
                "AI2D"
            ],
            "base_models": [
                "GPT-4",
                "LLaVA-1.5 (13B)",
                "Qwen-VL (7B)",
                "LLaVA-1.5 (7B)",
                "TinyGPT-V (2.7B)",
                "MobileVLM (2.7B)",
                "LLaVA-Phi (2.7B)",
                "MoE-LLaVA (StableLM-1.6B)",
                "MoE-LLaVA (Phi-2.7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Symbolic Learning Enables Self-Evolving Agents": {
        "filename": "Symbolic Learning Enables Self-Evolving Agents.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "MATH",
                "HumanEval"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "TELM Test and Evaluation of Language Models": {
        "filename": "TELM Test and Evaluation of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Big Bench",
                "GLUE Benchmark",
                "SuperGLUE Benchmark",
                "OpenAI Moderation API",
                "MMLU",
                "EleutherAI LM Eval",
                "OpenAI Evals Adversarial NLI",
                "LIT",
                "ParlAI",
                "CoQA",
                "LAMBADA",
                "HellaSwag",
                "LogiQA",
                "MultiNLI",
                "SQUAD"
            ],
            "base_models": [
                "Llama",
                "BERT",
                "OpenAI Davinci",
                "BLIP-2",
                "CLIP",
                "Baidu ERNIE",
                "Yandex",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Fine-tuning Dataset and Benchmark for Large Language Models for Protein Understanding": {
        "filename": "A Fine-tuning Dataset and Benchmark for Large Language Models for Protein Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "ProteinLMBench"
            ],
            "base_models": [
                "InternLM2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Why are Visually-Grounded Language Models Bad at Image Classification": {
        "filename": "Why are Visually-Grounded Language Models Bad at Image Classification.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "Flowers102",
                "StanfordCars",
                "Caltech101",
                "ImageWikiQA"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA1.5-7B",
                "LLaVA1.5-13B",
                "LLaVANeXT-V7B",
                "LLaVANeXT-M7B",
                "BLIP2-2.7B",
                "IBLIP-7B",
                "IBLIP-13B",
                "Claude-3",
                "Gemini-1.5",
                "CLIP-L",
                "EVA-G"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "HumanEval on Latest GPT Models - 2024": {
        "filename": "HumanEval on Latest GPT Models - 2024.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval"
            ],
            "base_models": [
                "GPT-4",
                "Codex",
                "CodeGen",
                "GPT-3.5-TURBO-0301 (CHATGPT)"
            ]
        }
    },
    "Grounding Robot Policies with Visuomotor Language Guidance": {
        "filename": "Grounding Robot Policies with Visuomotor Language Guidance.pdf",
        "analysis": {
            "benchmarks": [
                "RL-Bench"
            ],
            "base_models": [
                "Act3D",
                "3D Diffuser Actor"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AutoGRAMS Autonomous Graphical Agent Modeling Software": {
        "filename": "AutoGRAMS Autonomous Graphical Agent Modeling Software.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BC4LLM Trusted Artificial Intelligence When Blockchain Meets Large Language Models": {
        "filename": "BC4LLM Trusted Artificial Intelligence When Blockchain Meets Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "ERNIE Bot",
                "Qwen-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models as Optimizers": {
        "filename": "Large Language Models as Optimizers.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "Big-Bench Hard (BBH)"
            ],
            "base_models": [
                "PaLM 2-L",
                "PaLM 2-L-IT",
                "text-bison",
                "gpt-3.5-turbo",
                "gpt-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Empirical Impact of Data Sanitization on Language Models": {
        "filename": "The Empirical Impact of Data Sanitization on Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "LexGLUE",
                "SQuADv2.0",
                "IMDB",
                "DROP",
                "GSM8K",
                "Big-Bench-Hard (BBH)"
            ],
            "base_models": [
                "BART",
                "GPT-2",
                "Claude 3.5 Sonnet",
                "Mistral 7B",
                "GPT-4o"
            ]
        }
    },
    "Not What Youve Signed Up For Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection": {
        "filename": "Not What Youve Signed Up For Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection.pdf",
        "analysis": {
            "benchmarks": [],
            "models": [],
            "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
        }
    },
    "Chain-of-Thought Prompting of Large Language Models for Discovering and Fixing Software Vulnerabilities": {
        "filename": "Chain-of-Thought Prompting of Large Language Models for Discovering and Fixing Software Vulnerabilities.pdf",
        "analysis": {
            "benchmarks": [
                "CVE dataset",
                "SARD dataset"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "Llama2-7B",
                "Falcon-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dynamic and Super-Personalized Media Ecosystem Driven by Generative AI Unpredictable Plays Never Repeating the Same": {
        "filename": "Dynamic and Super-Personalized Media Ecosystem Driven by Generative AI Unpredictable Plays Never Repeating the Same.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OceanChat Piloting Autonomous Underwater Vehicles in Natural Language": {
        "filename": "OceanChat Piloting Autonomous Underwater Vehicles in Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "HoloEco simulation platform"
            ],
            "base_models": [
                "GPT-4 (OpenAI)"
            ]
        }
    },
    "Eyeballing Combinatorial Problems A Case Study of Using Multimodal Large Language Models to Solve Traveling Salesman Problems": {
        "filename": "Eyeballing Combinatorial Problems A Case Study of Using Multimodal Large Language Models to Solve Traveling Salesman Problems.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of journeys with 2-dimensional points"
            ],
            "base_models": [
                "Gemini 1.0 Pro",
                "Gemini 1.5"
            ]
        }
    },
    "SAGE Smart home Agent with Grounded Execution": {
        "filename": "SAGE Smart home Agent with Grounded Execution.pdf",
        "analysis": {
            "benchmarks": [
                "50 new and challenging smart home tasks"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4-turbo",
                "GPT-3.5-turbo",
                "Lemur",
                "Claude2.1"
            ]
        }
    },
    "Tackling the Abstraction and Reasoning Corpus with Vision Transformers the Importance of 2D Representation Positions and Objects": {
        "filename": "Tackling the Abstraction and Reasoning Corpus with Vision Transformers the Importance of 2D Representation Positions and Objects.pdf",
        "analysis": {
            "benchmarks": [
                "Abstraction and Reasoning Corpus (ARC)"
            ],
            "base_models": [
                "Vision Transformer (ViT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Navigating the Future of Federated Recommendation Systems with Foundation Models": {
        "filename": "Navigating the Future of Federated Recommendation Systems with Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "Amazon Reviews",
                "MovieLens",
                "Yelp",
                "Anime",
                "Book Crossing",
                "Douban",
                "Epinions",
                "Goodreads",
                "Jester",
                "Netflix",
                "Yahoo Music",
                "MIND",
                "Tenrec",
                "Adressa",
                "Foursquare",
                "Gowalla",
                "Last.FM",
                "Pinterest",
                "Steam",
                "TaFeng",
                "Tmall"
            ],
            "base_models": [
                "ChatGPT",
                "BERT",
                "ViT",
                "CLIP",
                "DALL·E",
                "GPT-3",
                "LLama",
                "DINOv2",
                "SAM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automatic Answerability Evaluation for Question Generation": {
        "filename": "Automatic Answerability Evaluation for Question Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Llama2-70B"
            ]
        }
    },
    "GAIA A General AI Assistant for Intelligent Accelerator Operations": {
        "filename": "GAIA A General AI Assistant for Intelligent Accelerator Operations.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Mixtral 8x7B Instruct v0.1 (8 bit quantization)"
            ]
        }
    },
    "I Want It That Way Enabling Interactive Decision Support Using Large Language Models and Constraint Programming": {
        "filename": "I Want It That Way Enabling Interactive Decision Support Using Large Language Models and Constraint Programming.pdf",
        "analysis": {
            "benchmarks": [
                "Diary study dataset"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-Conditional Ranking with Large Language Models": {
        "filename": "Multi-Conditional Ranking with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MCRank"
            ],
            "base_models": [
                "OpenAI o1-mini",
                "GPT-4",
                "ChatGPT (turbo versions)",
                "Llama3.1-70B",
                "Mistral (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "StructRAG Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization": {
        "filename": "StructRAG Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization.pdf",
        "analysis": {
            "benchmarks": [
                "Loong benchmark",
                "Podcast Transcripts"
            ],
            "base_models": [
                "Qwen2-7B-Instruct",
                "Qwen2-72B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MoT Memory-of-Thought Enables ChatGPT to Self-Improve": {
        "filename": "MoT Memory-of-Thought Enables ChatGPT to Self-Improve.pdf",
        "analysis": {
            "benchmarks": [
                "AQuA",
                "DROP",
                "ANLI-A1",
                "ANLI-A2",
                "ANLI-A3",
                "OBQA",
                "ComV",
                "BoolQ",
                "FactCK",
                "WikiQA"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-Turbo-0301)",
                "GPT-4",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Zero-Shot Next Location Predictors": {
        "filename": "Large Language Models are Zero-Shot Next Location Predictors.pdf",
        "analysis": {
            "benchmarks": [
                "FSQ New York",
                "FSQ Tokyo",
                "Ferrara"
            ],
            "base_models": [
                "Llama 2 7B",
                "Llama 2 13B",
                "Llama 2 70B",
                "Llama 2 Chat 7B",
                "Llama 2 Chat 13B",
                "Llama 2 Chat 70B",
                "Llama 3 8B",
                "Llama 3 70B",
                "Llama 3 8B Instruct",
                "Llama 3 70B Instruct",
                "Llama 3.1 8B",
                "Mistral 7B",
                "GPT-3.5",
                "GPT-4",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Reflection in LLM Agents Effects on Problem-Solving Performance": {
        "filename": "Self-Reflection in LLM Agents Effects on Problem-Solving Performance.pdf",
        "analysis": {
            "benchmarks": [
                "ARC",
                "AGIEval",
                "HellaSwag",
                "MedMCQA",
                "LogiQA",
                "LSAT-AR",
                "LSAT-LR",
                "LSAT-RC",
                "SAT-English",
                "SAT-Math"
            ],
            "base_models": [
                "GPT-4",
                "Llama 2 70B",
                "Gemini 1.5 Pro",
                "Claude 3 Opus",
                "Command R+",
                "Gemini 1.0 Pro",
                "GPT-3.5 Turbo",
                "Llama 2 7B",
                "Mistral Large"
            ]
        }
    },
    "Boosting Reinforcement Learning and Planning with Demonstrations A Survey": {
        "filename": "Boosting Reinforcement Learning and Planning with Demonstrations A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "ManiSkill"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Pruning for Protection Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning": {
        "filename": "Pruning for Protection Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench",
                "GCG attack method"
            ],
            "base_models": [
                "LLaMA-2 Chat (7B)",
                "Vicuna 1.3 (7B)",
                "Mistral Instruct v0.2 (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FIAT Fusing learning paradigms with Instruction-Accelerated Tuning": {
        "filename": "FIAT Fusing learning paradigms with Instruction-Accelerated Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "XOR-ATTRI QA",
                "XTREME-UP Cross-lingual QA"
            ],
            "base_models": [
                "PaLM-2 L",
                "PaLM-2 XS",
                "PaLM-2 S"
            ]
        }
    },
    "On The Truthfulness of Surprisingly Likely Responses of Large Language Models": {
        "filename": "On The Truthfulness of Surprisingly Likely Responses of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "COPA",
                "StoryCloze"
            ],
            "base_models": [
                "GPT-2 S (124 million parameters)",
                "GPT-2 M (355 million parameters)",
                "GPT-2 L (774 million parameters)",
                "GPT-2 XL (1558 million parameters)",
                "LLaMA-2 7B (7 billion parameters)",
                "LLaMA-2 13B (13 billion parameters)",
                "LLaMA-2 70B (70 billion parameters)"
            ]
        }
    },
    "Document-Level Event Extraction with Definition-Driven ICL": {
        "filename": "Document-Level Event Extraction with Definition-Driven ICL.pdf",
        "analysis": {
            "benchmarks": [
                "WikiEvents"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4 Turbo",
                "Qwen Turbo"
            ]
        }
    },
    "Number Cookbook Number Understanding of Language Models and How to Improve It": {
        "filename": "Number Cookbook Number Understanding of Language Models and How to Improve It.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "MATH",
                "MMLU",
                "NUPA Test"
            ],
            "base_models": [
                "GPT-4o",
                "Llama-3.1-70B",
                "Qwen2-72B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections": {
        "filename": "Distilling and Retrieving Generalizable Knowledge for Robot Manipulation via Language Corrections.pdf",
        "analysis": {
            "benchmarks": [
                "Skill-level tasks",
                "Plan-level tasks"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Executable Code Actions Elicit Better LLM Agents": {
        "filename": "Executable Code Actions Elicit Better LLM Agents.pdf",
        "analysis": {
            "benchmarks": [
                "API-Bank",
                "M3ToolEval"
            ],
            "base_models": [
                "Llama2",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Monkeys Scaling Inference Compute with Repeated Sampling": {
        "filename": "Large Language Monkeys Scaling Inference Compute with Repeated Sampling.pdf",
        "analysis": {
            "benchmarks": [
                "SWE-bench Lite",
                "GSM8K",
                "MATH",
                "MiniF2F-MATH",
                "CodeContests"
            ],
            "base_models": [
                "DeepSeek-Coder-V2-Instruct",
                "GPT-4o",
                "Claude 3.5 Sonnet",
                "Llama-3-8B-Instruct",
                "Llama-3-70B-Instruct",
                "Gemma-2B",
                "Gemma-7B",
                "Pythia-70M",
                "Pythia-160M",
                "Pythia-410M",
                "Pythia-1B",
                "Pythia-1.4B",
                "Pythia-2.8B",
                "Pythia-6.9B",
                "Pythia-12B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Decoding Intelligence A Framework for Certifying Knowledge Comprehension in LLMs": {
        "filename": "Decoding Intelligence A Framework for Certifying Knowledge Comprehension in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Wikidata5m"
            ],
            "base_models": [
                "Llama-3",
                "Mistral",
                "Phi-3",
                "GPT-4o",
                "Gemini-1.5-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Simple is Effective The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation": {
        "filename": "Simple is Effective The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation.pdf",
        "analysis": {
            "benchmarks": [
                "WebQSP",
                "CWQ"
            ],
            "base_models": [
                "Llama3.1-8B-Instruct",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Attacks on Third-Party APIs of Large Language Models": {
        "filename": "Attacks on Third-Party APIs of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WikiQA",
                "NewsQA"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Gemini"
            ]
        }
    },
    "Are Large Language Models a Good Replacement of Taxonomies": {
        "filename": "Are Large Language Models a Good Replacement of Taxonomies.pdf",
        "analysis": {
            "benchmarks": [
                "TaxoGlimpse",
                "Google Product Category",
                "Amazon Product Category",
                "eBay Categories",
                "Schema.org",
                "ACM Computing Classification System",
                "GeoNames",
                "Glottolog",
                "ICD-10-CM",
                "OAE",
                "NCBI Taxonomy Database"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude-3",
                "Llama-2 (7B, 13B, 70B)",
                "Llama-3 (8B, 70B)",
                "Flan-T5 (3B, 11B)",
                "Falcon (7B, 40B)",
                "Vicuna (7B, 13B, 33B)",
                "Mistral (7B)",
                "Mixtral (8*7B)",
                "LLMs4OL (based on Flan-T5-3B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OmniActions Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs": {
        "filename": "OmniActions Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset from a five-day diary study with 39 participants"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "davinci"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automatic Model Selection with Large Language Models for Reasoning": {
        "filename": "Automatic Model Selection with Large Language Models for Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "ASDIV",
                "SingleOP",
                "SingleEQ",
                "AddSub",
                "MultiArith",
                "Date Understanding"
            ],
            "base_models": [
                "Codex",
                "ChatGPT",
                "GPT-4",
                "Llama 2 (7B and 13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Democratizing Fine-grained Visual Recognition with Large Language Models": {
        "filename": "Democratizing Fine-grained Visual Recognition with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Caltech-UCSD Bird-200",
                "Stanford Car-196",
                "Stanford Dog-120",
                "Flower-102",
                "Oxford-IIIT Pet-37",
                "Pokemon dataset"
            ],
            "base_models": [
                "ChatGPT gpt-3.5-turbo",
                "LLaMA",
                "BLIP-2 Flan-T5xxl",
                "CLIP ViT-B/16"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Sparsity May Cry Let Us Fail Current Sparse Neural Networks Together": {
        "filename": "Sparsity May Cry Let Us Fail Current Sparse Neural Networks Together.pdf",
        "analysis": {
            "benchmarks": [
                "Sparsity May Cry Benchmark (SMC-Bench)",
                "RACE",
                "WinoGrande",
                "Commonsense QA (CSQA)",
                "MAWPS",
                "ASDiv-A",
                "SVAMP",
                "HotProtein",
                "Meltome Atlas",
                "OPUS"
            ],
            "base_models": [
                "RoBERTa",
                "mBART",
                "GTS (with RoBERTa's pre-trained embedding)",
                "Graph2Tree (with RoBERTa's pre-trained embedding)",
                "Transformer-based",
                "TAPE",
                "ESM-1B",
                "ESM-IF1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning Randomized Algorithms with Transformers": {
        "filename": "Learning Randomized Algorithms with Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "associative recall",
                "graph coloring",
                "grid worlds"
            ],
            "base_models": [
                "transformer (no specific size mentioned)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Large Language Models at Evaluating Instruction Following": {
        "filename": "Evaluating Large Language Models at Evaluating Instruction Following.pdf",
        "analysis": {
            "benchmarks": [
                "LLM-BAR"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "LLaMA-2-Chat",
                "PaLM2",
                "Falcon"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "3D-GRAND A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination": {
        "filename": "3D-GRAND A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination.pdf",
        "analysis": {
            "benchmarks": [
                "3D-POPE",
                "ScanRefer"
            ],
            "base_models": [
                "Llama-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FinRobot An Open-Source AI Agent Platform for Financial Applications using Large Language Models": {
        "filename": "FinRobot An Open-Source AI Agent Platform for Financial Applications using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "DOW 30",
                "SSE 50"
            ],
            "base_models": [
                "Llama-2-7b-chat-hf",
                "FinGPT (based on Llama series)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do Models Explain Themselves Counterfactual Simulatability of Natural Language Explanations": {
        "filename": "Do Models Explain Themselves Counterfactual Simulatability of Natural Language Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "Stanford Human Preference"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChatCam Empowering Camera Control through Conversational AI": {
        "filename": "ChatCam Empowering Camera Control through Conversational AI.pdf",
        "analysis": {
            "benchmarks": [
                "mip-NeRF 360",
                "OMMO",
                "Hypersim",
                "MannequinChallenge"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "LLaMA-2"
            ]
        }
    },
    "Babys CoThought Leveraging Large Language Models for Enhanced Reasoning in Compact Models": {
        "filename": "Babys CoThought Leveraging Large Language Models for Enhanced Reasoning in Compact Models.pdf",
        "analysis": {
            "benchmarks": [
                "BLiMP",
                "BLiMP Supplement",
                "GLUE",
                "MSGS"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "RoBERTa-base"
            ]
        }
    },
    "ZeroLeak Using LLMs for Scalable and Cost Effective Side-Channel Patching": {
        "filename": "ZeroLeak Using LLMs for Scalable and Cost Effective Side-Channel Patching.pdf",
        "analysis": {
            "benchmarks": [
                "Kocher's Spectre v1 microbenchmark"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "PaLM",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Traffic Performance GPT TP-GPT Real-Time Data Informed Intelligent ChatBot for Transportation Surveillance and Management": {
        "filename": "Traffic Performance GPT TP-GPT Real-Time Data Informed Intelligent ChatBot for Transportation Surveillance and Management.pdf",
        "analysis": {
            "benchmarks": [
                "TransQuery"
            ],
            "base_models": [
                "GPT-4",
                "PaLM 2",
                "SQLCoder-34B"
            ]
        }
    },
    "CAT Coordinating Anatomical-Textual Prompts for Multi-Organ and Tumor Segmentation": {
        "filename": "CAT Coordinating Anatomical-Textual Prompts for Multi-Organ and Tumor Segmentation.pdf",
        "analysis": {
            "benchmarks": [
                "FLARE22",
                "MSD dataset",
                "In-house dataset"
            ],
            "base_models": [
                "Swin UNETR",
                "Clinical-Bert"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Denevil Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning": {
        "filename": "Denevil Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning.pdf",
        "analysis": {
            "benchmarks": [
                "MoralPrompt"
            ],
            "base_models": [
                "LLaMA-70B",
                "GPT-4",
                "ChatGPT",
                "Falcon-40B",
                "Vicuna-33B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Taking Advice from ChatGPT": {
        "filename": "Taking Advice from ChatGPT.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU (Massive Multitask Language Understanding)"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Demonstrate-Search-Predict Composing retrieval and language models for knowledge-intensive NLP": {
        "filename": "Demonstrate-Search-Predict Composing retrieval and language models for knowledge-intensive NLP.pdf",
        "analysis": {
            "benchmarks": [
                "Open-SQuAD",
                "HotPotQA",
                "QReCC"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-002)",
                "ColBERTv2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hidden Schema Networks": {
        "filename": "Hidden Schema Networks.pdf",
        "analysis": {
            "benchmarks": [
                "Penn Treebank (PTB)",
                "Yahoo",
                "Yelp",
                "ATOMIC"
            ],
            "base_models": [
                "BERT",
                "GPT-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "An Evaluation of ChatGPT-4s Qualitative Spatial Reasoning Capabilities in RCC-8": {
        "filename": "An Evaluation of ChatGPT-4s Qualitative Spatial Reasoning Capabilities in RCC-8.pdf",
        "analysis": {
            "benchmarks": [
                "RCC-8"
            ],
            "base_models": [
                "ChatGPT-4"
            ]
        }
    },
    "Data Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting": {
        "filename": "Data Augmentation of Multi-turn Psychological Dialogue via Knowledge-driven Progressive Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "Chinese Cognitive Stimulation Conversation Dataset (CSConv)",
                "Chinese Emotional First Aid Dataset (EFAQA)",
                "English Annotated Motivational Interviewing Dataset (AnnoMI)"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "BERT (bert-base-chinese)",
                "BERT (bert-base-multilingual-cased)"
            ]
        }
    },
    "MC-GPT Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains": {
        "filename": "MC-GPT Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains.pdf",
        "analysis": {
            "benchmarks": [
                "REVERIE",
                "R2R"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beneath Surface Similarity Large Language Models Make Reasonable Scientific Analogies after Structure Abduction": {
        "filename": "Beneath Surface Similarity Large Language Models Make Reasonable Scientific Analogies after Structure Abduction.pdf",
        "analysis": {
            "benchmarks": [
                "SCAR"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Causal interventions expose implicit situation models for commonsense language understanding": {
        "filename": "Causal interventions expose implicit situation models for commonsense language understanding.pdf",
        "analysis": {
            "benchmarks": [
                "Winograd Schema Challenge (WSC)",
                "Winogrande"
            ],
            "base_models": [
                "ALBERT (various sizes including base, large, xlarge, xxlarge)",
                "BERT (base and large)",
                "RoBERTa (base and large)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language ModelLLM assisted End-to-End Network Health Management based on Multi-Scale Semanticization": {
        "filename": "Large Language ModelLLM assisted End-to-End Network Health Management based on Multi-Scale Semanticization.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset for network anomaly detection"
            ],
            "base_models": [
                "Transformer",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Re-Thinking Process Mining in the AI-Based Agents Era": {
        "filename": "Re-Thinking Process Mining in the AI-Based Agents Era.pdf",
        "analysis": {
            "benchmarks": [
                "PM-LLM-Benchmark"
            ],
            "base_models": [
                "Qwen 2.0 72B",
                "Qwen 2.0 8B"
            ]
        }
    },
    "SIKeD Self-guided Iterative Knowledge Distillation for mathematical reasoning": {
        "filename": "SIKeD Self-guided Iterative Knowledge Distillation for mathematical reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "ASDiv",
                "MultiArith"
            ],
            "base_models": [
                "LLaMA-70B",
                "Qwen2 0.5B",
                "Qwen2 1.5B",
                "SmolLM 1.7B",
                "Gemma 2B",
                "Gemma 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Zero-Shot Clinical Trial Patient Matching with LLMs": {
        "filename": "Zero-Shot Clinical Trial Patient Matching with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "n2c2 2018 Clinical Trial Cohort Selection challenge"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama-2-70b-32k",
                "Mixtral-8x7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "IntGrad MT Eliciting LLMs Machine Translation Capabilities with Sentence Interpolation and Gradual MT": {
        "filename": "IntGrad MT Eliciting LLMs Machine Translation Capabilities with Sentence Interpolation and Gradual MT.pdf",
        "analysis": {
            "benchmarks": [
                "FLORES-200"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "Mistral Nemo Instruct",
                "Llama 3.1 70B Instruct",
                "Llama 3.1 8B Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AlexaTM 20B Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model": {
        "filename": "AlexaTM 20B Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model.pdf",
        "analysis": {
            "benchmarks": [
                "Flores-101",
                "SuperGLUE",
                "SQuADv2",
                "XNLI",
                "XCOPA",
                "Paws-X",
                "XWinograd",
                "MLSum",
                "XSum"
            ],
            "base_models": [
                "AlexaTM 20B",
                "PaLM 540B",
                "GPT-3 175B",
                "XGLM 7.5B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Preventing Language Models From Hiding Their Reasoning": {
        "filename": "Preventing Language Models From Hiding Their Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Perez et al. (2022)'s sycophancy dataset"
            ],
            "base_models": [
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Building Specialized Generalist AI with System 1 and System 2 Fusion": {
        "filename": "Towards Building Specialized Generalist AI with System 1 and System 2 Fusion.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Gemini 1.5",
                "Claude",
                "Llama 3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Do Deep Neural Networks Capture Compositionality in Arithmetic Reasoning": {
        "filename": "Do Deep Neural Networks Capture Compositionality in Arithmetic Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "custom multi-hop arithmetic symbolic reasoning dataset"
            ],
            "base_models": [
                "T5-base (250M)",
                "T5-large (800M)",
                "T5-xl (3B)",
                "BART-base (140M)",
                "BART-large (400M)"
            ]
        }
    },
    "Survey on Large Language Model-Enhanced Reinforcement Learning Concept Taxonomy and Methods": {
        "filename": "Survey on Large Language Model-Enhanced Reinforcement Learning Concept Taxonomy and Methods.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "BERT",
                "GPT",
                "GPT-3",
                "PaLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DeepSeek-Prover-V15 Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search": {
        "filename": "DeepSeek-Prover-V15 Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search.pdf",
        "analysis": {
            "benchmarks": [
                "miniF2F",
                "ProofNet"
            ],
            "base_models": [
                "DeepSeek-Prover-V1",
                "DeepSeek-Coder V2 236B",
                "Llemma-7B",
                "Llemma-34B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unveiling Transformers with LEGO a synthetic reasoning task": {
        "filename": "Unveiling Transformers with LEGO a synthetic reasoning task.pdf",
        "analysis": {
            "benchmarks": [
                "LEGO synthetic reasoning task"
            ],
            "base_models": [
                "BERT",
                "ALBERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Data Ambiguity Strikes Back How Documentation Improves GPTs Text-to-SQL": {
        "filename": "Data Ambiguity Strikes Back How Documentation Improves GPTs Text-to-SQL.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "KaggleDBQA"
            ],
            "base_models": [
                "GPT-4 (1.7T parameters)"
            ]
        }
    },
    "Automated Assessment of Students Code Comprehension using LLMs": {
        "filename": "Automated Assessment of Students Code Comprehension using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "CodeCorpus"
            ],
            "base_models": [
                "ChatGPT-3.5-turbo-0613",
                "ChatGPT-4-0613",
                "GPT-4-1106-preview",
                "LLama2-chat"
            ]
        }
    },
    "Reasoning Like Program Executors": {
        "filename": "Reasoning Like Program Executors.pdf",
        "analysis": {
            "benchmarks": [
                "DROP",
                "LogiQA",
                "HotpotQA",
                "TAT-QA",
                "EQUATE",
                "SVAMP"
            ],
            "base_models": [
                "BART-Large",
                "RoBERTa-Large",
                "T5-11B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Agent-E From Autonomous Web Navigation to Foundational Design Principles in Agentic Systems": {
        "filename": "Agent-E From Autonomous Web Navigation to Foundational Design Principles in Agentic Systems.pdf",
        "analysis": {
            "benchmarks": [
                "WebVoyager"
            ],
            "base_models": [
                "GPT-4-Turbo"
            ]
        }
    },
    "DOMINO A Dual-System for Multi-step Visual Language Reasoning": {
        "filename": "DOMINO A Dual-System for Multi-step Visual Language Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ChartQA",
                "PlotQA",
                "DVQA",
                "FigureQA"
            ],
            "base_models": [
                "LLaMA-2 (70B)",
                "FlanPaLM (540B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Critique Ability of Large Language Models": {
        "filename": "Critique Ability of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CRITIC BENCH",
                "GSM8K",
                "HumanEval",
                "TruthfulQA"
            ],
            "base_models": [
                "PaLM-2 (various sizes)",
                "PaLM-2-S*",
                "ChatGPT",
                "LLaMA",
                "LLaMA-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MoE-LLaVA Mixture of Experts for Large Vision-Language Models": {
        "filename": "MoE-LLaVA Mixture of Experts for Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "POPE",
                "ScienceQA",
                "MMBench",
                "LLaVAW",
                "MM-Vet"
            ],
            "base_models": [
                "LLaVA-1.5-7B",
                "LLaVA-1.5-13B",
                "InternVL-Chat-19B",
                "StableLM-1.6B",
                "Qwen-1.8B",
                "Phi2-2.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Training-free Zero-shot Composed Image Retrieval with Local Concept Reranking": {
        "filename": "Training-free Zero-shot Composed Image Retrieval with Local Concept Reranking.pdf",
        "analysis": {
            "benchmarks": [
                "CIRR",
                "CIRCO",
                "COCO",
                "FashionIQ"
            ],
            "base_models": [
                "BLIP2",
                "LLaVA",
                "GPT-4"
            ]
        }
    },
    "GAgent An Adaptive Rigid-Soft Gripping Agent with Vision Language Models for Complex Lighting Environments": {
        "filename": "GAgent An Adaptive Rigid-Soft Gripping Agent with Vision Language Models for Complex Lighting Environments.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 45 diverse objects for grasping experiments"
            ],
            "base_models": [
                "MiniGPT-4",
                "LLaVA"
            ]
        }
    },
    "Super Tiny Language Models": {
        "filename": "Super Tiny Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "HellaSwag",
                "ARC",
                "GSM8K",
                "LMSYS Chatbot Arena",
                "BLiMP",
                "WinoGrande"
            ],
            "base_models": [
                "TinyLlama (1.1B)",
                "Phi-3-mini (3.3B)",
                "MobiLlama (0.5B)"
            ]
        }
    },
    "Black Swan Abductive and Defeasible Video Reasoning in Unpredictable Events": {
        "filename": "Black Swan Abductive and Defeasible Video Reasoning in Unpredictable Events.pdf",
        "analysis": {
            "benchmarks": [
                "BlackSwanSuite"
            ],
            "base_models": [
                "VILA",
                "Video-LLaMA",
                "LLaVA-Video"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-Context Exemplars as Clues to Retrieving from Large Associative Memory": {
        "filename": "In-Context Exemplars as Clues to Retrieving from Large Associative Memory.pdf",
        "analysis": {
            "benchmarks": [
                "Penn Treebank (PTB)",
                "Colorado Richly Annotated Full-Text (CRAFT)",
                "MedMCQA",
                "MedQA"
            ],
            "base_models": [
                "Code-Davinci-002",
                "GPT-3.5-turbo"
            ]
        }
    },
    "ChemDFM A Large Language Foundation Model for Chemistry": {
        "filename": "ChemDFM A Large Language Foundation Model for Chemistry.pdf",
        "analysis": {
            "benchmarks": [
                "ChemLLMBench",
                "ChEBI-20",
                "MoleculeNet",
                "USPTO-MIT",
                "USPTO-50K",
                "Buchwald-Hartwig dataset",
                "Suzuki-Miyaura dataset"
            ],
            "base_models": [
                "LLaMa-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ReFT Representation Finetuning for Language Models": {
        "filename": "ReFT Representation Finetuning for Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Commonsense 170K",
                "GLUE"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "Llama-2 7B",
                "Llama-3 8B",
                "RoBERTa-base",
                "RoBERTa-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FsPONER Few-shot Prompt Optimization for Named Entity Recognition in Domain-specific Scenarios": {
        "filename": "FsPONER Few-shot Prompt Optimization for Named Entity Recognition in Domain-specific Scenarios.pdf",
        "analysis": {
            "benchmarks": [
                "thin-film head technology dataset",
                "assembly instruction dataset",
                "FabNER manufacturing dataset"
            ],
            "base_models": [
                "GPT-4-32K",
                "GPT-3.5-Turbo",
                "LLaMA 2-chat",
                "Vicuna"
            ]
        }
    },
    "PeriGuru A Peripheral Robotic Mobile App Operation Assistant based on GUI Image Understanding and Prompting with LLM": {
        "filename": "PeriGuru A Peripheral Robotic Mobile App Operation Assistant based on GUI Image Understanding and Prompting with LLM.pdf",
        "analysis": {
            "benchmarks": [
                "VINS",
                "RICO"
            ],
            "base_models": [
                "gpt-4-vision-preview",
                "gpt-4o"
            ]
        }
    },
    "Exploring the applicability of Large Language Models to citation context analysis": {
        "filename": "Exploring the applicability of Large Language Models to citation context analysis.pdf",
        "analysis": {
            "benchmarks": [
                "ACL-ARC",
                "ACT2"
            ],
            "base_models": [
                "ChatGPT (gpt3.5-turbo-0310)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ReAcTable Enhancing ReAct for Table Question Answering": {
        "filename": "ReAcTable Enhancing ReAct for Table Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTQ",
                "TabFact",
                "FeTaQA"
            ],
            "base_models": [
                "Codex (code-davinci-002)",
                "text-davinci-003",
                "gpt3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Length-Generalization in Transformers via Task Hinting": {
        "filename": "Improving Length-Generalization in Transformers via Task Hinting.pdf",
        "analysis": {
            "benchmarks": [
                "Custom sorting dataset (sequences of natural numbers up to length 100)"
            ],
            "base_models": [
                "Decoder-only transformer model (depth-2)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MAGDA Multi-agent Guideline-Driven Diagnostic Assistance": {
        "filename": "MAGDA Multi-agent Guideline-Driven Diagnostic Assistance.pdf",
        "analysis": {
            "benchmarks": [
                "CheXpert",
                "ChestXRay 14 Longtail"
            ],
            "base_models": [
                "GPT-4",
                "Llama2 70B chat",
                "Mixtral 8x7B instruct"
            ]
        }
    },
    "Chain of Empathy Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models": {
        "filename": "Chain of Empathy Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models.pdf",
        "analysis": {
            "benchmarks": [
                "EPITOME"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)"
            ]
        }
    },
    "Outline Then Details Syntactically Guided Coarse-To-Fine Code Generation": {
        "filename": "Outline Then Details Syntactically Guided Coarse-To-Fine Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "APPS",
                "CodeContests"
            ],
            "base_models": [
                "BERT",
                "CodeT5",
                "GPT-3",
                "GPT-Neo 2.7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unmasking and Improving Data Credibility A Study with Datasets for Training Harmless Language Models": {
        "filename": "Unmasking and Improving Data Credibility A Study with Datasets for Training Harmless Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Jigsaw Civil Comments",
                "Anthropic Harmless & Red Team",
                "PKU BeaverTails",
                "Safe RLHF"
            ],
            "base_models": [
                "BERT",
                "GPT-2",
                "Llama2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multitask Vision-Language Prompt Tuning": {
        "filename": "Multitask Vision-Language Prompt Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "ELEVATER",
                "cross-task generalization benchmarks"
            ],
            "base_models": [
                "CLIP (ViT-B/32)",
                "CLIP (ViT-B/16)",
                "CLIP (ViT-L/14)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interpretable-by-Design Text Understanding with Iteratively Generated Concept Bottleneck": {
        "filename": "Interpretable-by-Design Text Understanding with Iteratively Generated Concept Bottleneck.pdf",
        "analysis": {
            "benchmarks": [
                "Rotten Tomatoes",
                "Amazon reviews",
                "Poem Sentiment",
                "CEBaB restaurant reviews",
                "Yelp reviews",
                "Hate Speech Detection",
                "SNLI",
                "AG News",
                "Patent Classification",
                "SciCite",
                "Fake News Detection",
                "News Partisanship Classification"
            ],
            "base_models": [
                "GPT-4 (10-shot)",
                "GPT-3.5-turbo (finetune)",
                "DeBERTa-base",
                "BERT-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can ChatGPT Detect Intent Evaluating Large Language Models for Spoken Language Understanding": {
        "filename": "Can ChatGPT Detect Intent Evaluating Large Language Models for Spoken Language Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "SLURP",
                "MINDS-14"
            ],
            "base_models": [
                "ChatGPT",
                "GPT3.5 (175B)",
                "GPT3.5 Curie (6.7B)",
                "GPT2 large (774M)",
                "OPT-1.3B",
                "OPT-2.7B",
                "OPT-6.7B"
            ]
        }
    },
    "A Theory of Intelligences Concepts Models Implications": {
        "filename": "A Theory of Intelligences Concepts Models Implications.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Text Improving LLMs Decision Making for Robot Navigation via Vocal Cues": {
        "filename": "Beyond Text Improving LLMs Decision Making for Robot Navigation via Vocal Cues.pdf",
        "analysis": {
            "benchmarks": [
                "DNIA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-3",
                "Gemini Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instruction Induction From Few Examples to Natural Language Task Descriptions": {
        "filename": "Instruction Induction From Few Examples to Natural Language Task Descriptions.pdf",
        "analysis": {
            "benchmarks": [
                "instruction induction dataset (24 tasks)"
            ],
            "base_models": [
                "InstructGPT (175B parameters)",
                "GPT-3 (175B parameters)"
            ]
        }
    },
    "LexEval A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models": {
        "filename": "LexEval A Comprehensive Chinese Legal Benchmark for Evaluating Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "LexEval"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "LLaMA-2-7B",
                "LLaMA-2-7B-Chat",
                "LLaMA-2-13B-Chat",
                "ChatGLM-6B",
                "ChatGLM2-6B",
                "ChatGLM3-6B",
                "Baichuan-7B-base",
                "Baichuan-13B-base",
                "Baichuan-13B-Chat",
                "Qwen-7B-chat",
                "Qwen-14B-Chat",
                "MPT-7B",
                "MPT-7B-Instruct",
                "XVERSE-13B",
                "InternLM-7B",
                "InternLM-7B-Chat",
                "Chinese-LLaMA-2-7B",
                "Chinese-LLaMA-2-13B",
                "TigerBot-Base",
                "Chinese-Alpaca-2-7B",
                "GoGPT2-7B",
                "GoGPT2-13B",
                "Ziya-LLaMA-13B",
                "Vicuna-v1.3-7B",
                "BELLE-LLAMA-2-13B",
                "Alpaca-v1.0-7B",
                "MoSS-Moon-sft",
                "ChatLaw-13B",
                "ChatLaw-33B",
                "LexiLaw",
                "Lawyer-LLaMA",
                "Wisdom-Interrogatory",
                "LaWGPT-7B-beta1.0",
                "LaWGPT-7B-beta1.1",
                "HanFei",
                "Fuzi-Mingcha"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Are Semi-Parametric Reinforcement Learning Agents": {
        "filename": "Large Language Models Are Semi-Parametric Reinforcement Learning Agents.pdf",
        "analysis": {
            "benchmarks": [
                "WebShop",
                "WikiHow"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Macro-Queries An Exploration into Guided Chart Generation from High Level Prompts": {
        "filename": "Macro-Queries An Exploration into Guided Chart Generation from High Level Prompts.pdf",
        "analysis": {
            "benchmarks": [
                "Car Price dataset",
                "Superstore dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4o-mini"
            ]
        }
    },
    "Weaver Foundation Models for Creative Writing": {
        "filename": "Weaver Foundation Models for Creative Writing.pdf",
        "analysis": {
            "benchmarks": [
                "WriteBench"
            ],
            "base_models": [
                "Weaver Mini (1.8B)",
                "Weaver Base (6B)",
                "Weaver Pro (14B)",
                "Weaver Ultra (34B)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Language Models via Plug-and-Play Retrieval Feedback": {
        "filename": "Improving Language Models via Plug-and-Play Retrieval Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "NQ",
                "TriviaQA",
                "HotpotQA",
                "WoW"
            ],
            "base_models": [
                "Text-davinci-003",
                "Code-davinci-002"
            ]
        }
    },
    "Athena Retrieval-augmented Legal Judgment Prediction with Large Language Models": {
        "filename": "Athena Retrieval-augmented Legal Judgment Prediction with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CAIL2018"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-turbo)",
                "GPT-4-turbo",
                "GPT-4o"
            ]
        }
    },
    "Measuring and Controlling Instruction InStability in Language Model Dialogs": {
        "filename": "Measuring and Controlling Instruction InStability in Language Model Dialogs.pdf",
        "analysis": {
            "benchmarks": [
                "custom benchmark dataset for instruction stability",
                "Massive Multitask Language Understanding (MMLU)"
            ],
            "base_models": [
                "LLaMA2-chat-70B",
                "GPT-3.5-turbo-16k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Conditioning Predictive Models Risks and Strategies": {
        "filename": "Conditioning Predictive Models Risks and Strategies.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Odyssey Empowering Minecraft Agents with Open-World Skills": {
        "filename": "Odyssey Empowering Minecraft Agents with Open-World Skills.pdf",
        "analysis": {
            "benchmarks": [
                "MineRL",
                "MineDojo",
                "custom agent capability benchmark"
            ],
            "base_models": [
                "LLaMA-3 (various sizes including 8B and 70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chaining thoughts and LLMs to learn DNA structural biophysics": {
        "filename": "Chaining thoughts and LLMs to learn DNA structural biophysics.pdf",
        "analysis": {
            "benchmarks": [
                "NUPACK dataset"
            ],
            "base_models": [
                "chatGPT 3.5-turbo"
            ]
        }
    },
    "Revisit Input Perturbation Problems for LLMs A Unified Robustness Evaluation Framework for Noisy Slot Filling Task": {
        "filename": "Revisit Input Perturbation Problems for LLMs A Unified Robustness Evaluation Framework for Noisy Slot Filling Task.pdf",
        "analysis": {
            "benchmarks": [
                "Noise-LLM",
                "RADDLE",
                "SNIPS"
            ],
            "base_models": [
                "GPT-3.5 (Text-davinci-003)",
                "ChatGPT",
                "GPT-4"
            ]
        }
    },
    "Integration of cognitive tasks into artificial general intelligence test for large models": {
        "filename": "Integration of cognitive tasks into artificial general intelligence test for large models.pdf",
        "analysis": {
            "benchmarks": [
                "Penn Treebank",
                "CoNLL-2003",
                "GLUE",
                "MNLI",
                "RTE",
                "IMDb",
                "Yelp",
                "SST-2",
                "WikiText-103",
                "The Pile",
                "LAMBADA",
                "Natural Questions",
                "TriviaQA",
                "HotpotQA",
                "WikiQA",
                "SQuAD",
                "WMT",
                "WIT3",
                "CNN/Daily Mail",
                "GigaWord",
                "X-Sum",
                "PersonaChat",
                "UDC",
                "Human Eval",
                "APPS",
                "SPoC",
                "FB15k",
                "WikiFact",
                "CSQA",
                "StrategyQA",
                "SocialIQA",
                "CConS",
                "SummEdits",
                "Big-bench",
                "PAL",
                "TabFact",
                "MMLU",
                "GSM8k",
                "SVAMP",
                "MathQA",
                "AQUA-RAT",
                "Math Vista",
                "STEM"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "PaLM",
                "PaLM 2",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "XPromptExplaining Large Language Models Generation via Joint Prompt Attribution": {
        "filename": "XPromptExplaining Large Language Models Generation via Joint Prompt Attribution.pdf",
        "analysis": {
            "benchmarks": [
                "Alpaca",
                "tldr_news",
                "MHC"
            ],
            "base_models": [
                "LLaMA2 (7B-Chat)",
                "Vicuna (7B)"
            ]
        }
    },
    "MLLM-Search A Zero-Shot Approach to Finding People using Multimodal Large Language Models": {
        "filename": "MLLM-Search A Zero-Shot Approach to Finding People using Multimodal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AWS RoboMaker hospital environment",
                "AWS RoboMaker office environment"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "TokenFormer Rethinking Transformer Scaling with Tokenized Model Parameters": {
        "filename": "TokenFormer Rethinking Transformer Scaling with Tokenized Model Parameters.pdf",
        "analysis": {
            "benchmarks": [
                "OpenWebText",
                "Pile",
                "ImageNet-1K"
            ],
            "base_models": [
                "GPT-2 (with 124M to 1.4B parameters)",
                "ViT-B/16 (with 286M parameters)",
                "ViT-L/16 (with 307M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "NNetscape Navigator Complex Demonstrations for Web Agents Without a Demonstrator": {
        "filename": "NNetscape Navigator Complex Demonstrations for Web Agents Without a Demonstrator.pdf",
        "analysis": {
            "benchmarks": [
                "MiniWoB++",
                "WebArena"
            ],
            "base_models": [
                "GPT-4o-mini",
                "Llama-3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Structured Chemistry Reasoning with Large Language Models": {
        "filename": "Structured Chemistry Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SciBench"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama-2-13B",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards CausalGPT A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs": {
        "filename": "Towards CausalGPT A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "Com2Sense",
                "BoolQ",
                "MME",
                "MMMU"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "Claude-2",
                "Qwen1.5-32B",
                "Llama3-LLaVA-Next-8B",
                "InternVL2-8B",
                "Qwen-VL-Max",
                "GPT-4o-mini",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Distilling Reasoning Ability from Large Language Models with Adaptive Thinking": {
        "filename": "Distilling Reasoning Ability from Large Language Models with Adaptive Thinking.pdf",
        "analysis": {
            "benchmarks": [
                "SingleEq",
                "AddSub",
                "MultiArith",
                "GSM8K",
                "Aqua",
                "Svamp",
                "Last Letter Concatenation",
                "Coin Flip",
                "CommonSenseQA",
                "StrategyQA",
                "Date Understanding",
                "Track Shuffled Objects"
            ],
            "base_models": [
                "GPT2-Large",
                "T5-Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Demonstration of Adaptive Collaboration of Large Language Models for Medical Decision-Making": {
        "filename": "A Demonstration of Adaptive Collaboration of Large Language Models for Medical Decision-Making.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA",
                "PubMedQA",
                "PathVQA",
                "MedVidQA"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "ChatKBQA A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models": {
        "filename": "ChatKBQA A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WebQSP",
                "ComplexWebQuestions (CWQ)"
            ],
            "base_models": [
                "Llama-2-7B",
                "ChatGLM2-6B",
                "Baichuan (implied as Baichuan2-7B and Baichuan2-13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Looped Transformers Learn to Implement Multi-step Gradient Descent for In-context Learning": {
        "filename": "Can Looped Transformers Learn to Implement Multi-step Gradient Descent for In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "synthetic experiments"
            ],
            "base_models": [
                "Transformers (no specific size mentioned)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AHAM Adapt Help Ask Model - Harvesting LLMs for literature mining": {
        "filename": "AHAM Adapt Help Ask Model - Harvesting LLMs for literature mining.pdf",
        "analysis": {
            "benchmarks": [
                "arXiv",
                "medarxiv"
            ],
            "base_models": [
                "LLaMa2",
                "Llama-2-13b-chat-hf"
            ]
        }
    },
    "IFShip A Large Vision-Language Model for Interpretable Fine-grained Ship Classification via Domain Knowledge-Enhanced Instruction Tuning": {
        "filename": "IFShip A Large Vision-Language Model for Interpretable Fine-grained Ship Classification via Domain Knowledge-Enhanced Instruction Tuning.pdf",
        "analysis": {
            "benchmarks": [
                "TITANIC-FGS"
            ],
            "base_models": [
                "LLaVA",
                "MiniGPT-4",
                "Vicuna 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Training LLMs for Generating IEC 61131-3 Structured Text with Online Feedback": {
        "filename": "Training LLMs for Generating IEC 61131-3 Structured Text with Online Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "OSCAT",
                "APPS"
            ],
            "base_models": [
                "GPT-3",
                "GPT-J",
                "Phi-3 14B"
            ]
        }
    },
    "Progressively Efficient Learning": {
        "filename": "Progressively Efficient Learning.pdf",
        "analysis": {
            "benchmarks": [
                "2D MineCraft domain"
            ],
            "base_models": []
        }
    },
    "Oedipus LLM-enchanced Reasoning CAPTCHA Solver": {
        "filename": "Oedipus LLM-enchanced Reasoning CAPTCHA Solver.pdf",
        "analysis": {
            "benchmarks": [
                "Arkose-Angular",
                "Geetest-Gobang",
                "Geetest-Space",
                "Yidun-Space-Reasoning",
                "Arkose-AngularV2",
                "Geetest-IconCrush"
            ],
            "base_models": [
                "GPT-4",
                "Google Gemini",
                "miniGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "All in How You Ask for It Simple Black-Box Method for Jailbreak Attacks": {
        "filename": "All in How You Ask for It Simple Black-Box Method for Jailbreak Attacks.pdf",
        "analysis": {
            "benchmarks": [
                "forbidden questions dataset by Shen et al.",
                "harmful behavior dataset from PAIR study"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)",
                "ChatGPT (GPT-4)",
                "Gemini-Pro"
            ]
        }
    },
    "Pronunciation Assessment with Multi-modal Large Language Models": {
        "filename": "Pronunciation Assessment with Multi-modal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Speechocean762"
            ],
            "base_models": [
                "Qwen-7B"
            ]
        }
    },
    "Argumentation Computation with Large Language Models  A Benchmark Study": {
        "filename": "Argumentation Computation with Large Language Models  A Benchmark Study.pdf",
        "analysis": {
            "benchmarks": [
                "custom abstract argumentation frameworks"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4o",
                "Llama3-8B",
                "Llama3-70B",
                "Qwen2-7B",
                "Qwen2-72B"
            ]
        }
    },
    "Instruct or Interact Exploring and Eliciting LLMs Capability in Code Snippet Adaptation Through Prompt Engineering": {
        "filename": "Instruct or Interact Exploring and Eliciting LLMs Capability in Code Snippet Adaptation Through Prompt Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "ClassEval"
            ],
            "base_models": [
                "GPT-3.5",
                "CodeLlama-7B",
                "CodeLlama-13B",
                "CodeLlama-34B",
                "Llama-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models Reason A Characterization via 3-SAT": {
        "filename": "Can Large Language Models Reason A Characterization via 3-SAT.pdf",
        "analysis": {
            "benchmarks": [
                "Random 3-SAT dataset"
            ],
            "base_models": [
                "GPT-4 Turbo (1106-preview)",
                "Llama 2 70B chat-hf",
                "Mixtral 8×7B",
                "GPT-3.5 Turbo",
                "Gemini 1.0 Pro",
                "PaLM 2 text-bison"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MAIRA-2 Grounded Radiology Report Generation": {
        "filename": "MAIRA-2 Grounded Radiology Report Generation.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-CXR",
                "PadChest",
                "USMix",
                "IU-Xray",
                "GR-Bench",
                "PadChest-GR"
            ],
            "base_models": [
                "Vicuna 7B v1.5",
                "Rad-DINO-MAIRA-2 (87M-parameter ViT-B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Modeling with Latent Situations": {
        "filename": "Language Modeling with Latent Situations.pdf",
        "analysis": {
            "benchmarks": [
                "TextWorld (TW)",
                "TRIP"
            ],
            "base_models": [
                "BART-base",
                "GPT-3 (da-vinci-002)"
            ]
        }
    },
    "MQuAKE Assessing Knowledge Editing in Language Models via Multi-Hop Questions": {
        "filename": "MQuAKE Assessing Knowledge Editing in Language Models via Multi-Hop Questions.pdf",
        "analysis": {
            "benchmarks": [
                "MQ UAKE-CF",
                "MQ UAKE-T"
            ],
            "base_models": [
                "GPT-J (6B)",
                "Vicuna-7B",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DyVal Dynamic Evaluation of Large Language Models for Reasoning Tasks": {
        "filename": "DyVal Dynamic Evaluation of Large Language Models for Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "DYVAL-generated evaluation sets"
            ],
            "base_models": [
                "Flan-T5-large",
                "phi-1.5",
                "Xwin-13B",
                "Llama2-13B-chat",
                "Vicuna-13B-v1.3",
                "WizardMath-13B",
                "GPT-3.5-Turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoTEVer Chain of Thought Prompting Annotation Toolkit for Explanation Verification": {
        "filename": "CoTEVer Chain of Thought Prompting Annotation Toolkit for Explanation Verification.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA"
            ],
            "base_models": [
                "GPT-3"
            ]
        }
    },
    "Zero-shot Object Navigation with Vision-Language Models Reasoning": {
        "filename": "Zero-shot Object Navigation with Vision-Language Models Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "PASTURE",
                "RoboTHOR"
            ],
            "base_models": [
                "GPT-3.5"
            ]
        }
    },
    "Windows Agent Arena Evaluating Multi-Modal OS Agents at Scale": {
        "filename": "Windows Agent Arena Evaluating Multi-Modal OS Agents at Scale.pdf",
        "analysis": {
            "benchmarks": [
                "WINDOWS AGENT ARENA",
                "Mind2Web"
            ],
            "base_models": [
                "GPT-4V-1106",
                "GPT-4o",
                "Phi3-V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Federated Large Language Models Current Progress and Future Directions": {
        "filename": "Federated Large Language Models Current Progress and Future Directions.pdf",
        "analysis": {
            "benchmarks": [
                "FedLLM-Bench",
                "Fedmlsecurity"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unifying Large Language Models and Knowledge Graphs A Roadmap": {
        "filename": "Unifying Large Language Models and Knowledge Graphs A Roadmap.pdf",
        "analysis": {
            "benchmarks": [
                "Wikidata",
                "YAGO",
                "NELL"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "T5",
                "ChatGPT",
                "PaLM2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "IDEA Enhancing the Rule Learning Ability of Large Language Model Agent through Induction Deduction and Abduction": {
        "filename": "IDEA Enhancing the Rule Learning Ability of Large Language Model Agent through Induction Deduction and Abduction.pdf",
        "analysis": {
            "benchmarks": [
                "RULEARN"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4o",
                "Gemma-7B",
                "Llama3-8B",
                "Llama3-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Predict Usage Options of Product Reviews with LLM-Generated Labels": {
        "filename": "Learning to Predict Usage Options of Product Reviews with LLM-Generated Labels.pdf",
        "analysis": {
            "benchmarks": [
                "Amazon Customer Review Dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 Turbo",
                "Llama 2 70B Chat",
                "Flan-T5 Base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Language-Based Communication in Robotics": {
        "filename": "A Survey of Language-Based Communication in Robotics.pdf",
        "analysis": {
            "benchmarks": [
                "RoboTHOR",
                "AI2THOR",
                "VirtualHome",
                "MuJoCo",
                "IsaacGym"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5",
                "GPT-4",
                "PaLM 540B",
                "LLaMa-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AVIS Autonomous Visual Information Seeking with Large Language Models": {
        "filename": "AVIS Autonomous Visual Information Seeking with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Infoseek",
                "OK-VQA"
            ],
            "base_models": [
                "GPT-3",
                "LaMDA",
                "PaLM",
                "BLOOM",
                "LLaMA",
                "GPT-4",
                "Flamingo",
                "PALI"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Large Language Models": {
        "filename": "A Survey of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3 (175B)",
                "PaLM (540B)",
                "BERT (330M)",
                "GPT-2 (1.5B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Think before you speak Training Language Models With Pause Tokens": {
        "filename": "Think before you speak Training Language Models With Pause Tokens.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "CommonSenseQA",
                "GSM8k",
                "LAMBADA",
                "WebQuestions",
                "NaturalQuestions",
                "CoQA",
                "PhysicalIQA",
                "HellaSwag"
            ],
            "base_models": [
                "Decoder-only model (1B parameters)",
                "Decoder-only model (130M parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LongWriter Unleashing 10000 Word Generation from Long Context LLMs": {
        "filename": "LongWriter Unleashing 10000 Word Generation from Long Context LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "LongBench-Write",
                "LongWrite-Ruler"
            ],
            "base_models": [
                "GLM-4-9B",
                "Llama-3.1-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SelfCheck Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning": {
        "filename": "SelfCheck Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MathQA",
                "MATH"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Towards Time Series Reasoning with LLMs": {
        "filename": "Towards Time Series Reasoning with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Etiological Reasoning",
                "UCR Classification Archive"
            ],
            "base_models": [
                "Mistral-7B"
            ]
        }
    },
    "Web Retrieval Agents for Evidence-Based Misinformation Detection": {
        "filename": "Web Retrieval Agents for Evidence-Based Misinformation Detection.pdf",
        "analysis": {
            "benchmarks": [
                "LIAR-New",
                "FEVER-v2",
                "FEVER",
                "FaVIQ",
                "X-FACT"
            ],
            "base_models": [
                "Vicuna",
                "Mixtral",
                "Claude",
                "GPT-3.5",
                "GPT-4 (two versions)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Death of Schema Linking Text-to-SQL in the Age of Well-Reasoned Language Models": {
        "filename": "The Death of Schema Linking Text-to-SQL in the Age of Well-Reasoned Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BIRD"
            ],
            "base_models": [
                "ft:GPT-4o",
                "GPT-4o",
                "GPT-4o-Mini",
                "GPT-4-Turbo",
                "Llama 3.1-405b",
                "Llama 3.1-70b",
                "Llama 3.1-8b",
                "Deepseek Coder-V2",
                "Claude 3.5 Sonnet",
                "Claude 3 Opus",
                "Mixtral-8x22B",
                "Gemini 1.5 Pro"
            ]
        }
    },
    "Generative Verifiers Reward Modeling as Next-Token Prediction": {
        "filename": "Generative Verifiers Reward Modeling as Next-Token Prediction.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH500"
            ],
            "base_models": [
                "Gemma-2B",
                "Gemma2-9B",
                "Gemini 1.0 Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PPTC Benchmark Evaluating Large Language Models for PowerPoint Task Completion": {
        "filename": "PPTC Benchmark Evaluating Large Language Models for PowerPoint Task Completion.pdf",
        "analysis": {
            "benchmarks": [
                "PPTC Benchmark"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "Text-Davinci-003",
                "LLaMa-2-Chat",
                "Baichuan-Chat",
                "Baichuan-2-Chat",
                "WizardLM v1.2",
                "Vicuna v1.5 (16k)",
                "Code-LLaMa-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Many Demonstrations Do You Need for In-context Learning": {
        "filename": "How Many Demonstrations Do You Need for In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MultiArith",
                "AddSub",
                "SVAMP",
                "AQuA",
                "SingleOp",
                "CSQA",
                "Coin-flip"
            ],
            "base_models": [
                "code-davinci-002 (GPT-3 family)"
            ]
        }
    },
    "Information extraction from historical well records using a large language model": {
        "filename": "Information extraction from historical well records using a large language model.pdf",
        "analysis": {
            "benchmarks": [
                "Colorado well drilling completion reports",
                "Pennsylvania well record reports"
            ],
            "base_models": [
                "Llama 2-7B",
                "Llama 2-13B",
                "Llama 2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LMMCoDrive Cooperative Driving with Large Multimodal Model": {
        "filename": "LMMCoDrive Cooperative Driving with Large Multimodal Model.pdf",
        "analysis": {
            "benchmarks": [
                "Town10HD of CARLA"
            ],
            "base_models": [
                "GPT-4o",
                "Swin Transformer (pre-trained on ImageNet-21k)"
            ]
        }
    },
    "Coarse-to-Fine Highlighting Reducing Knowledge Hallucination in Large Language Models": {
        "filename": "Coarse-to-Fine Highlighting Reducing Knowledge Hallucination in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "FELM-WK",
                "FELM-Sci/Tech",
                "FELM-Wri/Rec",
                "RACE-H",
                "RACE-M",
                "Natural Questions",
                "TriviaQA",
                "WebQ"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "Vicuna-33B",
                "Llama 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards LLM-based Fact Verification on News Claims with a Hierarchical Step-by-Step Prompting Method": {
        "filename": "Towards LLM-based Fact Verification on News Claims with a Hierarchical Step-by-Step Prompting Method.pdf",
        "analysis": {
            "benchmarks": [
                "RAWFC",
                "LIAR"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OASIS Open Agent Social Interaction Simulations with One Million Agents": {
        "filename": "OASIS Open Agent Social Interaction Simulations with One Million Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Twitter15",
                "Twitter16",
                "Reddit"
            ],
            "base_models": [
                "Llama3-8b-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "KG-GPT A General Framework for Reasoning on Knowledge Graphs Using Large Language Models": {
        "filename": "KG-GPT A General Framework for Reasoning on Knowledge Graphs Using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "FACTKG",
                "MetaQA"
            ],
            "base_models": [
                "ChatGPT",
                "BERT",
                "BlueBERT",
                "Flan-T5"
            ]
        }
    },
    "LLM Learning Automata from Examples using Natural Language Oracles": {
        "filename": "LLM Learning Automata from Examples using Natural Language Oracles.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Mixtral-8x7B-Instruct"
            ]
        }
    },
    "REX Rapid Exploration and eXploitation for AI Agents": {
        "filename": "REX Rapid Exploration and eXploitation for AI Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Blocksworld",
                "GSM8K"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "Semantic-guided Prompt Organization for Universal Goal Hijacking against LLMs": {
        "filename": "Semantic-guided Prompt Organization for Universal Goal Hijacking against LLMs.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "ChatGPT",
                "Gemini",
                "Qwen",
                "Llama-2-7b-chat-hf",
                "Vicuna-7b-v1.5",
                "Guanaco-7B-HF",
                "Mistral-7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "StrategyLLM Large Language Models as Strategy Generators Executors Optimizers and Evaluators for Problem Solving": {
        "filename": "StrategyLLM Large Language Models as Strategy Generators Executors Optimizers and Evaluators for Problem Solving.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "StrategyQA",
                "Date Understanding (DU)",
                "Word Sorting (WS)",
                "Multi-step Arithmetic (MA)",
                "Last Letter Concatenation (LLC-4, LLC-8, LLC-16)"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4",
                "Claude-3-Sonnet",
                "Meta-Llama-3-8B-Instruct",
                "Meta-Llama-3-70B-Instruct",
                "Mixtral-8x7B-Instruct-v0.1",
                "Mixtral-8x22B-Instruct-v0.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ShizishanGPT An Agricultural Large Language Model Integrating Tools and Resources": {
        "filename": "ShizishanGPT An Agricultural Large Language Model Integrating Tools and Resources.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset with 100 agricultural questions"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Planning with Logical Graph-based Language Model for Instruction Generation": {
        "filename": "Planning with Logical Graph-based Language Model for Instruction Generation.pdf",
        "analysis": {
            "benchmarks": [
                "VirtualHome"
            ],
            "base_models": [
                "GPT2-small (124M)",
                "GPT2-medium (355M)",
                "GPT2-large (774M)",
                "GPT2-xl (1.5B)",
                "ChatGPT (GPT-3.5, 175B)",
                "GPT4 (1.8T)"
            ]
        }
    },
    "Recall Retrieve and Reason Towards Better In-Context Relation Extraction": {
        "filename": "Recall Retrieve and Reason Towards Better In-Context Relation Extraction.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval 2010",
                "TACRED",
                "Google RE",
                "SciERC"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "LLaMA-7B",
                "T5-Base (220M)",
                "T5-Large (770M)",
                "BART-Base (140M)",
                "BART-Large (400M)"
            ]
        }
    },
    "Better Zero-Shot Reasoning with Self-Adaptive Prompting": {
        "filename": "Better Zero-Shot Reasoning with Self-Adaptive Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith",
                "AddSub",
                "SingleEq",
                "GSM-8K",
                "CSQA",
                "StrategyQA"
            ],
            "base_models": [
                "PaLM-62B",
                "PaLM-540B",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GLoRe When Where and How to Improve LLM Reasoning via Global and Local Refinements": {
        "filename": "GLoRe When Where and How to Improve LLM Reasoning via Global and Local Refinements.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP"
            ],
            "base_models": [
                "LLaMA-2 13B",
                "LLaMA-2 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tell Your Model Where to Attend Post-hoc Attention Steering for LLMs": {
        "filename": "Tell Your Model Where to Attend Post-hoc Attention Steering for LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Bias in Bios",
                "CounterFact",
                "JSON Formatting",
                "Pronouns Changing"
            ],
            "base_models": [
                "GPT-J-6B",
                "LLAMA-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-Empowered State Representation for Reinforcement Learning": {
        "filename": "LLM-Empowered State Representation for Reinforcement Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Mujoco",
                "Gym-Robotics"
            ],
            "base_models": [
                "gpt-4-1106-preview"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PaLI-X On Scaling up a Multilingual Vision and Language Model": {
        "filename": "PaLI-X On Scaling up a Multilingual Vision and Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "COCO Captions (Karpathy split)",
                "NoCaps",
                "VQAv2",
                "OKVQA",
                "TallyQA",
                "TextCaps",
                "VizWiz-Cap",
                "TextVQA",
                "VizWiz-VQA",
                "ST-VQA",
                "OCR-VQA",
                "InfographicVQA",
                "DocVQA",
                "AI2D",
                "ChartQA",
                "OVEN",
                "InfoSeek",
                "Screen2Words",
                "Widget-Cap",
                "XM3600",
                "MSR-VTT",
                "ActivityNet Captions",
                "VATEX",
                "Spoken Moments in Time",
                "NExT-QA",
                "MSR-VTT-QA",
                "ActivityNet-QA",
                "ImageNet",
                "ImageNet-REAL",
                "ImageNet-R",
                "ImageNet-A",
                "ImageNet-Sketch",
                "ImageNet-v2",
                "LVIS"
            ],
            "base_models": [
                "ViT-22B",
                "UL2 (32B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LexGPT 01 pre-trained GPT-J models with Pile of Law": {
        "filename": "LexGPT 01 pre-trained GPT-J models with Pile of Law.pdf",
        "analysis": {
            "benchmarks": [
                "LexGLUE",
                "LEDGAR",
                "CaseHOLD"
            ],
            "base_models": [
                "GPT-J-6B"
            ]
        }
    },
    "Evaluating Large Language Models for Generalization and Robustness via Data Compression": {
        "filename": "Evaluating Large Language Models for Generalization and Robustness via Data Compression.pdf",
        "analysis": {
            "benchmarks": [
                "Wikipedia",
                "BBC News",
                "GitHub Code",
                "arXiv",
                "BBC Images",
                "Audio-Mix"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-65B",
                "Llama-2-7B",
                "Llama-2-13B",
                "Llama-2-70B",
                "CodeLlama-7B",
                "Yi-6B",
                "Yi-34B",
                "Mistral-7B",
                "Baichuan2-7B",
                "InternLM-7B",
                "ChatGLM3-6B",
                "Qwen-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Toward Relieving Clinician Burden by Automatically Generating Progress Notes using Interim Hospital Data": {
        "filename": "Toward Relieving Clinician Burden by Automatically Generating Progress Notes using Interim Hospital Data.pdf",
        "analysis": {
            "benchmarks": [
                "CHART PNG"
            ],
            "base_models": [
                "Biomistral 7B",
                "Mixtral 8x7B",
                "LLaMa 2 70B"
            ]
        }
    },
    "Generate then Select Open-ended Visual Question Answering Guided by World Knowledge": {
        "filename": "Generate then Select Open-ended Visual Question Answering Guided by World Knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "OK-VQA"
            ],
            "base_models": [
                "GPT-3",
                "Codex",
                "GPT-J (6B)",
                "UL2 (20B)",
                "OPT-175B"
            ]
        }
    },
    "Multi-Agent VQA Exploring Multi-Agent Foundation Models in Zero-Shot Visual Question Answering": {
        "filename": "Multi-Agent VQA Exploring Multi-Agent Foundation Models in Zero-Shot Visual Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "VQA-v2 rest-val",
                "GQA-val subset"
            ],
            "base_models": [
                "GPT-4V",
                "GPT-3.5",
                "BEiT3-large",
                "VLMo-large",
                "BLIP2-flan-t5-xl"
            ]
        }
    },
    "AgentBench Evaluating LLMs as Agents": {
        "filename": "AgentBench Evaluating LLMs as Agents.pdf",
        "analysis": {
            "benchmarks": [
                "AGENT BENCH"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "text-davinci-003",
                "text-davinci-002",
                "Claude-2",
                "Claude",
                "Claude-instant",
                "Chat-bison-001",
                "ChatGLM-6B",
                "CodeGeeX2-6B",
                "CodeLlama-34B",
                "CodeLlama-13B",
                "CodeLlama-7B",
                "LLaMA-2-70B",
                "LLaMA-2-13B",
                "LLaMA-2-7B",
                "Guanaco-65B",
                "Guanaco-33B",
                "Vicuna-33B",
                "Vicuna-13B",
                "Vicuna-7B",
                "OpenChat-13B",
                "WizardLM-30B",
                "WizardLM-13B",
                "Koala-13B",
                "OASST-12B",
                "Dolly-12B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Natural Language as Policies Reasoning for Coordinate-Level Embodied Control with LLMs": {
        "filename": "Natural Language as Policies Reasoning for Coordinate-Level Embodied Control with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "VIMABench"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "FollowupQG Towards information-seeking follow-up question generation": {
        "filename": "FollowupQG Towards information-seeking follow-up question generation.pdf",
        "analysis": {
            "benchmarks": [
                "FOLLOWUP QG"
            ],
            "base_models": [
                "GPT-Neo",
                "BART",
                "T5",
                "ChatGPT",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lawma The Power of Specialization for Legal Tasks": {
        "filename": "Lawma The Power of Specialization for Legal Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "U.S. Supreme Court Database (Spaeth et al., 2023)",
                "U.S. Courts of Appeals database (Songer)"
            ],
            "base_models": [
                "GPT-4",
                "Llama 3 8B Inst",
                "Llama 3 70B Inst",
                "Mistral 7B Inst",
                "Saul 7B Inst",
                "Mixtral 8x7B Inst"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visconde Multi-document QA with GPT-3 and Neural Reranking": {
        "filename": "Visconde Multi-document QA with GPT-3 and Neural Reranking.pdf",
        "analysis": {
            "benchmarks": [
                "IIRC",
                "Qasper",
                "StrategyQA"
            ],
            "base_models": [
                "GPT-3 (text-davinci-002)",
                "monoT5 (3 billion parameters)"
            ]
        }
    },
    "JiuZhang 20 A Unified Chinese Pre-trained Language Model for Multi-task Mathematical Problem Solving": {
        "filename": "JiuZhang 20 A Unified Chinese Pre-trained Language Model for Multi-task Mathematical Problem Solving.pdf",
        "analysis": {
            "benchmarks": [
                "MCQ",
                "BFQ",
                "CAG",
                "BAG",
                "KPC",
                "QRC",
                "JCAG",
                "JBAG"
            ],
            "base_models": [
                "BERT-Base",
                "BART-Base",
                "RoBERTa-wwm",
                "CPT",
                "Mengzi",
                "MathBERT",
                "GPT-3",
                "CodeX"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPTCloneBench A comprehensive benchmark of semantic clones and cross-language clones using GPT-3 model and SemanticCloneBench": {
        "filename": "GPTCloneBench A comprehensive benchmark of semantic clones and cross-language clones using GPT-3 model and SemanticCloneBench.pdf",
        "analysis": {
            "benchmarks": [
                "SemanticCloneBench",
                "GPTCloneBench"
            ],
            "base_models": [
                "GPT-3 (Text-Davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Little Red Riding Hood Goes around the Globe Crosslingual Story Planning and Generation with Large Language Models": {
        "filename": "Little Red Riding Hood Goes around the Globe Crosslingual Story Planning and Generation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ASPEN"
            ],
            "base_models": [
                "PaLM (size not specified)",
                "mT5-XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Visual CoT Advancing Multi-Modal Language Models with a Comprehensive Dataset and Benchmark for Chain-of-Thought Reasoning": {
        "filename": "Visual CoT Advancing Multi-Modal Language Models with a Comprehensive Dataset and Benchmark for Chain-of-Thought Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Visual CoT benchmark",
                "DocVQA",
                "TextCaps",
                "TextVQA",
                "DUDE",
                "SROIE",
                "InfographicsVQA",
                "Flickr30k",
                "Visual7W",
                "GQA",
                "Open Images",
                "VSR",
                "Birds-200-2011"
            ],
            "base_models": [
                "GPT-4",
                "LLaVA-1.5-7B",
                "LLaVA-1.5-13B",
                "SPHINX-13B",
                "VisCoT-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are We Done with MMLU": {
        "filename": "Are We Done with MMLU.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "MMLU-Redux"
            ],
            "base_models": [
                "Claude 3 Opus",
                "GPT-4o",
                "Llama 3 70b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reconciling Methodological Paradigms Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research": {
        "filename": "Reconciling Methodological Paradigms Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research.pdf",
        "analysis": {
            "benchmarks": [
                "open-source dataset on educators' experiences implementing open educational practices"
            ],
            "base_models": [
                "BERT",
                "GPT-3",
                "PaLM",
                "Claude2"
            ]
        }
    },
    "What If the TV was off Examining Counterfactual Reasoning Abilities of Multi-modal Language Models": {
        "filename": "What If the TV was off Examining Counterfactual Reasoning Abilities of Multi-modal Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "C-VQA",
                "VQAv2"
            ],
            "base_models": [
                "LLaVA-1.5 (7B and 13B)",
                "MiniGPT-4",
                "BLIP2",
                "InstructBLIP",
                "Qwen-VL",
                "CogVLM",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ScanReason Empowering 3D Visual Grounding with Reasoning Capabilities": {
        "filename": "ScanReason Empowering 3D Visual Grounding with Reasoning Capabilities.pdf",
        "analysis": {
            "benchmarks": [
                "ScanReason"
            ],
            "base_models": [
                "GPT-4",
                "FlanT5 XL-3B",
                "Vicuna-7B",
                "InternLM2-7B"
            ]
        }
    },
    "Chain-of-Thought in Neural Code Generation From and for Lightweight Language Models": {
        "filename": "Chain-of-Thought in Neural Code Generation From and for Lightweight Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "HumanEval-plus",
                "OpenEval"
            ],
            "base_models": [
                "CodeGen-350M",
                "CodeGen-2B",
                "CodeGen-6B",
                "StarCoder-1B",
                "StarCoder-3B",
                "StarCoder-7B",
                "CodeT5+ 220M",
                "CodeT5+ 770M",
                "CodeT5+ 2B",
                "CodeT5+ 6B",
                "CodeLlama-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DriVLMe Enhancing LLM-based Autonomous Driving Agents with Embodied and Social Experiences": {
        "filename": "DriVLMe Enhancing LLM-based Autonomous Driving Agents with Embodied and Social Experiences.pdf",
        "analysis": {
            "benchmarks": [
                "nuScenes",
                "BDD",
                "CARLA",
                "Situated Dialogue Navigation (SDN)",
                "BDD-X"
            ],
            "base_models": [
                "Vicuna-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning From Mistakes Makes LLM Better Reasoner": {
        "filename": "Learning From Mistakes Makes LLM Better Reasoner.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "SVAMP",
                "ASDiv",
                "CSQA"
            ],
            "base_models": [
                "GPT-4",
                "PaLM-2",
                "LLaMA-2-70B",
                "LLaMA-65B",
                "CodeLLaMA-34B",
                "LLaMA-2-13B",
                "LLaMA-2-7B",
                "WizardMath-70B",
                "MetaMath-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-RadJudge Achieving Radiologist-Level Evaluation for X-Ray Report Generation": {
        "filename": "LLM-RadJudge Achieving Radiologist-Level Evaluation for X-Ray Report Generation.pdf",
        "analysis": {
            "benchmarks": [
                "ReXVal dataset",
                "MIMIC-CXR dataset"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "PALM-2-bison",
                "Gemini-pro",
                "Llama2-13b-chat",
                "Llama2-70b-chat",
                "Mistral-small",
                "Mixtral-8x7B",
                "Mistral-medium",
                "Mistral-7B",
                "BioMistral-7B"
            ]
        }
    },
    "Towards Fairer Health Recommendations finding informative unbiased samples via Word Sense Disambiguation": {
        "filename": "Towards Fairer Health Recommendations finding informative unbiased samples via Word Sense Disambiguation.pdf",
        "analysis": {
            "benchmarks": [
                "BRICC dataset"
            ],
            "base_models": [
                "BERT",
                "DistilBERT",
                "RoBERTa",
                "BioBERT",
                "TinyLlama (1.1B)",
                "GPT-4o mini"
            ]
        }
    },
    "I-Design Personalized LLM Interior Designer": {
        "filename": "I-Design Personalized LLM Interior Designer.pdf",
        "analysis": {
            "benchmarks": [
                "3D-FRONT",
                "Objaverse"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SciBench Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models": {
        "filename": "SciBench Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SCIBENCH"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "LLaMA-2-70B",
                "Mistral-7B",
                "Claude2",
                "GPT-3.5-Turbo",
                "GPT-4",
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluation of medium-large Language Models at zero-shot closed book generative question answering": {
        "filename": "Evaluation of medium-large Language Models at zero-shot closed book generative question answering.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions",
                "BIGbench",
                "MMLU",
                "own test dataset"
            ],
            "base_models": [
                "OPT (6.7B to 66B)",
                "LLaMA (7B to 65B)",
                "GPT-J (6B)",
                "T5 (11B)",
                "Flan-T5 (11B)",
                "ChatGPT (GPT-3.5, 175B)",
                "GLM (130B)",
                "BloomZ (7B)",
                "Falcon (40B)",
                "WizardLM (13B to 30B)",
                "Airoboros (33B and 65B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CodeKGC Code Language Model for Generative Knowledge Graph Construction": {
        "filename": "CodeKGC Code Language Model for Generative Knowledge Graph Construction.pdf",
        "analysis": {
            "benchmarks": [
                "ADE",
                "CoNLL04",
                "SciERC"
            ],
            "base_models": [
                "text-davinci-002",
                "text-davinci-003",
                "code-davinci-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A challenge in AGI cybernetics revived in the Ouroboros Model as one algorithm for all thinking": {
        "filename": "A challenge in AGI cybernetics revived in the Ouroboros Model as one algorithm for all thinking.pdf",
        "analysis": {
            "benchmarks": [
                "Google Cloud API",
                "DALL·E"
            ],
            "base_models": [
                "ChatGPT",
                "DALL·E"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SmartRAG Jointly Learn RAG-Related Tasks From the Environment Feedback": {
        "filename": "SmartRAG Jointly Learn RAG-Related Tasks From the Environment Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "PopQA",
                "AmbigNQ",
                "HotpotQA",
                "TrivialQA",
                "OpenBookQA",
                "MedQA-cn",
                "ARC-c"
            ],
            "base_models": [
                "Flan-T5 large",
                "LlaMa-2 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LayoutCopilot An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design": {
        "filename": "LayoutCopilot An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design.pdf",
        "analysis": {
            "benchmarks": [
                "MAGICAL (real-world analog designs)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Isolation Multi-Agent Synergy for Improving Knowledge Graph Construction": {
        "filename": "Beyond Isolation Multi-Agent Synergy for Improving Knowledge Graph Construction.pdf",
        "analysis": {
            "benchmarks": [
                "Conllpp",
                "OntoNotes5.0",
                "MSRA",
                "NYT11-HRL",
                "Re-TACRED",
                "DuIE2.0",
                "ACE05",
                "DuEE1.0"
            ],
            "base_models": [
                "GPT-3",
                "ChatGLM"
            ]
        }
    },
    "ChatGPT Is a Knowledgeable but Inexperienced Solver An Investigation of Commonsense Problem in Large Language Models": {
        "filename": "ChatGPT Is a Knowledgeable but Inexperienced Solver An Investigation of Commonsense Problem in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "OpenBookQA",
                "WSC",
                "PIQA",
                "Social IQA",
                "ARC",
                "QASC",
                "HellaSWAG",
                "NumerSense",
                "ProtoQA",
                "MC-TACO"
            ],
            "base_models": [
                "GPT-3",
                "Instruct GPT (text-davinci-003)",
                "ChatGPT (GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unsupervised Explanation Generation via Correct Instantiations": {
        "filename": "Unsupervised Explanation Generation via Correct Instantiations.pdf",
        "analysis": {
            "benchmarks": [
                "ComVE",
                "e-SNLI"
            ],
            "base_models": [
                "OPT-175B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LLM-based agents for automating the enhancement of user story quality An early report": {
        "filename": "LLM-based agents for automating the enhancement of user story quality An early report.pdf",
        "analysis": {
            "benchmarks": [
                "Mobile Delivery project synthetic user stories"
            ],
            "base_models": [
                "GPT-3.5-Turbo-16K",
                "GPT-4-1106-Preview"
            ]
        }
    },
    "Cantor Inspiring Multimodal Chain-of-Thought of MLLM": {
        "filename": "Cantor Inspiring Multimodal Chain-of-Thought of MLLM.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA",
                "MathVista"
            ],
            "base_models": [
                "GPT-3.5",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Causal Prompting Debiasing Large Language Model Prompting based on Front-Door Adjustment": {
        "filename": "Causal Prompting Debiasing Large Language Model Prompting based on Front-Door Adjustment.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval2014 - Laptop",
                "GSM8K",
                "HotpotQA",
                "MuSiQue",
                "ABSA",
                "NLI",
                "FV"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA2",
                "LLaMA3",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DriveVLM The Convergence of Autonomous Driving and Large Vision-Language Models": {
        "filename": "DriveVLM The Convergence of Autonomous Driving and Large Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "nuScenes",
                "SUP-AD"
            ],
            "base_models": [
                "Qwen-VL (9.6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ALTA Compiler-Based Analysis of Transformers": {
        "filename": "ALTA Compiler-Based Analysis of Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "SCAN"
            ],
            "base_models": [
                "Universal Transformers"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Impact of Reasoning Step Length on Large Language Models": {
        "filename": "The Impact of Reasoning Step Length on Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith",
                "GSM8K",
                "AQuA",
                "SingleEq",
                "SA VMP",
                "Letter",
                "Coin",
                "Strategyqa"
            ],
            "base_models": [
                "text-davinci-002",
                "GPT-3.5-turbo-1106",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics": {
        "filename": "A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics.pdf",
        "analysis": {
            "benchmarks": [
                "RoboCup@Home"
            ],
            "base_models": [
                "GPT-3.5-Turbo-0125",
                "GPT-4-0125-Preview"
            ]
        }
    },
    "MMLU-Pro A More Robust and Challenging Multi-Task Language Understanding Benchmark": {
        "filename": "MMLU-Pro A More Robust and Challenging Multi-Task Language Understanding Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU-Pro"
            ],
            "base_models": [
                "GPT-4o",
                "Claude-3-Opus",
                "Gemini-1.5-Pro",
                "LLaMA-3-70B-Instruct",
                "DeepSeek-V2-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Trustworthy Large Models in Vision A Survey": {
        "filename": "Trustworthy Large Models in Vision A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "MSCOCO",
                "Wikiart dataset"
            ],
            "base_models": [
                "CLIP",
                "Stable Diffusion",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Balancing Autonomy and Alignment A Multi-Dimensional Taxonomy for Autonomous LLM-powered Multi-Agent Architectures": {
        "filename": "Balancing Autonomy and Alignment A Multi-Dimensional Taxonomy for Autonomous LLM-powered Multi-Agent Architectures.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DriveCoT Integrating Chain-of-Thought Reasoning with End-to-End Driving": {
        "filename": "DriveCoT Integrating Chain-of-Thought Reasoning with End-to-End Driving.pdf",
        "analysis": {
            "benchmarks": [
                "CARLA leaderboard 2.0",
                "DriveCoT"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LINC A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers": {
        "filename": "LINC A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers.pdf",
        "analysis": {
            "benchmarks": [
                "FOLIO",
                "ProofWriter"
            ],
            "base_models": [
                "StarCoder+ (15.5B)",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unleashing the Potential of Text-attributed Graphs Automatic Relation Decomposition via Large Language Models": {
        "filename": "Unleashing the Potential of Text-attributed Graphs Automatic Relation Decomposition via Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Wisconsin",
                "WebKB (Cornell, Texas, Wisconsin)",
                "IMDB",
                "Cora",
                "Pubmed",
                "WikiCS"
            ],
            "base_models": [
                "LLaMA-8B",
                "LLaMA-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generative Speech Recognition Error Correction With Large Language Models and Task-Activating Prompting": {
        "filename": "Generative Speech Recognition Error Correction With Large Language Models and Task-Activating Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "ATIS",
                "WSJ"
            ],
            "base_models": [
                "GPT-2 (1.5B)",
                "OpenLLaMA (13B)",
                "BLOOM (176B)",
                "InstructGPT (175B)"
            ]
        }
    },
    "Co-Writing Screenplays and Theatre Scripts with Language Models Evaluation by Industry Professionals": {
        "filename": "Co-Writing Screenplays and Theatre Scripts with Language Models Evaluation by Industry Professionals.pdf",
        "analysis": {
            "benchmarks": [
                "Edmonton International Fringe Theatre Festival"
            ],
            "base_models": [
                "Chinchilla (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Teachable Reasoning Systems Using a Dynamic Memory of User Feedback for Continual System Improvement": {
        "filename": "Towards Teachable Reasoning Systems Using a Dynamic Memory of User Feedback for Continual System Improvement.pdf",
        "analysis": {
            "benchmarks": [
                "OBQA",
                "QuaRTz"
            ],
            "base_models": [
                "T5-11B"
            ]
        }
    },
    "Auto-RAG Autonomous Retrieval-Augmented Generation for Large Language Models": {
        "filename": "Auto-RAG Autonomous Retrieval-Augmented Generation for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions (NQ)",
                "2WikiMultihopQA (2Wiki)",
                "TriviaQA (TQA)",
                "PopQA (PQA)",
                "HotpotQA (HQA)",
                "WebQuestions (WQ)"
            ],
            "base_models": [
                "Llama-3-8B-Instruct",
                "Qwen1.5-32B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Knowledge Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources": {
        "filename": "Chain-of-Knowledge Grounding Large Language Models via Dynamic Knowledge Adapting over Heterogeneous Sources.pdf",
        "analysis": {
            "benchmarks": [
                "FEVER",
                "HotpotQA",
                "FeTaQA",
                "MedMCQA",
                "MMLU Physics",
                "MMLU Biology"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0613)",
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating the Performance of ChatGPT for Spam Email Detection": {
        "filename": "Evaluating the Performance of ChatGPT for Spam Email Detection.pdf",
        "analysis": {
            "benchmarks": [
                "Email Spam Detection Dataset (ESD)",
                "Chinese Spam Dataset (CSD)"
            ],
            "base_models": [
                "ChatGPT (based on GPT-3.5)",
                "BERT"
            ]
        }
    },
    "Both Ears Wide Open Towards Language-Driven Spatial Audio Generation": {
        "filename": "Both Ears Wide Open Towards Language-Driven Spatial Audio Generation.pdf",
        "analysis": {
            "benchmarks": [
                "BEWO-1M"
            ],
            "base_models": [
                "T5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Interactive Navigation in Environments with Traversable Obstacles Using Large Language and Vision-Language Models": {
        "filename": "Interactive Navigation in Environments with Traversable Obstacles Using Large Language and Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset with traversable objects like curtains and grasses"
            ],
            "base_models": [
                "GPT-3.5",
                "Grounding DINO"
            ]
        }
    },
    "Creating Large Language Model Resistant Exams Guidelines and Strategies": {
        "filename": "Creating Large Language Model Resistant Exams Guidelines and Strategies.pdf",
        "analysis": {
            "benchmarks": [
                "AP Art History",
                "GRE"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Learning to Plan for Language Modeling from Unlabeled Data": {
        "filename": "Learning to Plan for Language Modeling from Unlabeled Data.pdf",
        "analysis": {
            "benchmarks": [
                "English Wikipedia subset"
            ],
            "base_models": [
                "GPT-2 Small",
                "OLMo 1B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models and Causal Inference in Collaboration A Comprehensive Survey": {
        "filename": "Large Language Models and Causal Inference in Collaboration A Comprehensive Survey.pdf",
        "analysis": {
            "benchmarks": [
                "CRAB",
                "VQAI"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathChat Benchmarking Mathematical Reasoning and Instruction Following in Multi-Turn Interactions": {
        "filename": "MathChat Benchmarking Mathematical Reasoning and Instruction Following in Multi-Turn Interactions.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MathChat"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Mistral",
                "WizardMath",
                "DeepSeek-Math",
                "InternLM2-Math"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fact-Checking Complex Claims with Program-Guided Reasoning": {
        "filename": "Fact-Checking Complex Claims with Program-Guided Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "HOVER",
                "FEVEROUS-S"
            ],
            "base_models": [
                "Codex",
                "GPT-3",
                "FLAN-T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GradBias Unveiling Word Influence on Bias in Text-to-Image Generative Models": {
        "filename": "GradBias Unveiling Word Influence on Bias in Text-to-Image Generative Models.pdf",
        "analysis": {
            "benchmarks": [
                "COCO",
                "Flickr30k"
            ],
            "base_models": [
                "Stable Diffusion 1.5",
                "Stable Diffusion 2",
                "Stable Diffusion XL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SafeEmbodAI a Safety Framework for Mobile Robots in Embodied AI Systems": {
        "filename": "SafeEmbodAI a Safety Framework for Mobile Robots in Embodied AI Systems.pdf",
        "analysis": {
            "benchmarks": [
                "EyeBot Simulator, EyeSim VR"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "Multi-Objective Fine-Tuning for Enhanced Program Repair with LLMs": {
        "filename": "Multi-Objective Fine-Tuning for Enhanced Program Repair with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "EvalRepair-C++",
                "EvalRepair-Java"
            ],
            "base_models": [
                "CodeLlama-13B-instruct (13B)",
                "CodeLlama-7B-instruct (7B)",
                "StarChat-alpha (16B)",
                "Mistral-Instruct-7B-v0.1 (7B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Scene Graph Generation with Hierarchical Relationships and Commonsense Knowledge": {
        "filename": "Enhancing Scene Graph Generation with Hierarchical Relationships and Commonsense Knowledge.pdf",
        "analysis": {
            "benchmarks": [
                "Visual Genome",
                "OpenImage V6"
            ],
            "base_models": [
                "LLaMA-3-8B",
                "LLaVA-1.6-7B",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BADGE BADminton report Generation and Evaluation with LLM": {
        "filename": "BADGE BADminton report Generation and Evaluation with LLM.pdf",
        "analysis": {
            "benchmarks": [
                "ShuttleSet"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Bridging the Training-Inference Gap in LLMs by Leveraging Self-Generated Tokens": {
        "filename": "Bridging the Training-Inference Gap in LLMs by Leveraging Self-Generated Tokens.pdf",
        "analysis": {
            "benchmarks": [
                "OpenAI TL;DR dataset",
                "Ultrachat-200K dataset",
                "GSM8K",
                "MATH",
                "AlpacaEval 2.0 benchmark"
            ],
            "base_models": [
                "Pythia-1B",
                "Mistral-7B-v0.1",
                "Mistral-7B-sft-beta"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Consistencies in LLM responses through a Semantic Clustering of Question Answering": {
        "filename": "Evaluating Consistencies in LLM responses through a Semantic Clustering of Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA"
            ],
            "base_models": [
                "OPT-30B"
            ]
        }
    },
    "Conformal Prediction with Large Language Models for Multi-Choice Question Answering": {
        "filename": "Conformal Prediction with Large Language Models for Multi-Choice Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU"
            ],
            "base_models": [
                "LLaMA-13B"
            ]
        }
    },
    "Chain of Thought Prompt Tuning in Vision Language Models": {
        "filename": "Chain of Thought Prompt Tuning in Vision Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "MSCOCO",
                "Flickr30k",
                "VQAv2"
            ],
            "base_models": [
                "CLIP",
                "ALIGN",
                "Flamingo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Calibrating Expressions of Certainty": {
        "filename": "Calibrating Expressions of Certainty.pdf",
        "analysis": {
            "benchmarks": [
                "SciQ",
                "TruthfulQA"
            ],
            "base_models": [
                "gpt-4o",
                "claude-3.5-sonnet",
                "gemini-1.5-pro",
                "gpt-4o-mini",
                "claude-3-haiku",
                "gemini-1.5-flash"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency": {
        "filename": "Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval",
                "HumanEval+",
                "MBPP",
                "CodeContests"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Intuitions of Compromise Utilitarianism vs Contractualism": {
        "filename": "Intuitions of Compromise Utilitarianism vs Contractualism.pdf",
        "analysis": {
            "benchmarks": [
                "Value Kaleidoscope",
                "NLPositionality",
                "Moral Machines"
            ],
            "base_models": [
                "gpt-4",
                "claude-3",
                "claude-2.1",
                "gpt-3.5",
                "davinci-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Larger language models do in-context learning differently": {
        "filename": "Larger language models do in-context learning differently.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "SUBJ",
                "TREC",
                "QQP",
                "RTE",
                "FP",
                "ETHOS"
            ],
            "base_models": [
                "GPT-3 (350M, 1.3B, 6.7B, 175B)",
                "InstructGPT",
                "Codex",
                "PaLM (8B, 62B, 540B)",
                "Flan-PaLM (8B, 62B, 540B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch": {
        "filename": "Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "College Math",
                "Olympiad Bench"
            ],
            "base_models": [
                "Mistral-7B",
                "Llama3-8B",
                "DeepSeekMath-7B",
                "Qwen2-Math-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Empowered Agent-based Modeling and Simulation A Survey and Perspectives": {
        "filename": "Large Language Models Empowered Agent-based Modeling and Simulation A Survey and Perspectives.pdf",
        "analysis": {
            "benchmarks": [
                "S3",
                "Werewolf Game",
                "SimReddit",
                "COLA",
                "MAD",
                "CHATDEV",
                "MetaGPT",
                "ChatEval",
                "CAMEL",
                "AgentVerse",
                "SPP",
                "CoELA",
                "Humanoid Agents",
                "SocioDojo",
                "Liu et al.",
                "Argyle et al.",
                "Hamalainen et al.",
                "Singh et al.",
                "Binz et al.",
                "Elyoseph et al.",
                "Li et al.",
                "Horton",
                "Chen et al.",
                "Geerling et al.",
                "Xie et al.",
                "Faria et al.",
                "Bybee et al.",
                "Phelps et al.",
                "Akata et al.",
                "Guo et al.",
                "Zhao et al.",
                "Han et al.",
                "Zhao et al.",
                "Chen et al.",
                "Shah et al.",
                "NLMap",
                "Zou et al.",
                "Cui et al.",
                "GITM",
                "WebAgent",
                "Mind2Web",
                "Zhou et al.",
                "Park et al.",
                "RecAgent",
                "Agent4Rec",
                "Williams et al.",
                "Generative Agents",
                "WarAgent",
                "Li et al.",
                "UGI"
            ],
            "base_models": [
                "ChatGPT",
                "Gemini",
                "LLaMA",
                "Alpaca",
                "GLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Human-Instruction-Free LLM Self-Alignment with Limited Samples": {
        "filename": "Human-Instruction-Free LLM Self-Alignment with Limited Samples.pdf",
        "analysis": {
            "benchmarks": [
                "BeaverTails",
                "TruthfulQA",
                "Alpaca-Eval"
            ],
            "base_models": [
                "LLaMA-7B",
                "OPT-6.7B",
                "LLaMA-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rethinking with Retrieval Faithful Large Language Model Inference": {
        "filename": "Rethinking with Retrieval Faithful Large Language Model Inference.pdf",
        "analysis": {
            "benchmarks": [
                "StrategyQA",
                "TempQuestions (implicit temporal questions)",
                "INFOTABS"
            ],
            "base_models": [
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multilingual Large Language Models Are Not Yet Code-Switchers": {
        "filename": "Multilingual Large Language Models Are Not Yet Code-Switchers.pdf",
        "analysis": {
            "benchmarks": [
                "Sentimix Spanish-English",
                "MixSentiment Malayalam",
                "MixSentiment Tamil",
                "MixMT 2022",
                "Gupshup",
                "LinCE"
            ],
            "base_models": [
                "XLM-R (250M, 560M)",
                "mBERT (178M)",
                "mDeBERTa v3 (278M)",
                "mBART-50 (611M)",
                "M2M100 (418M, 1.2B)",
                "XGLM (564M, 1.7B, 2.9B, 4.5B, 7.5B)",
                "BLOOMZ (560M, 1.1B, 1.7B, 3B, 7.1B)",
                "mT0 (300M, 580M, 1.2B, 3.7B, 13B)",
                "ChatGPT (GPT-3.5 turbo)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Expressive Power of Transformers with Chain of Thought": {
        "filename": "The Expressive Power of Transformers with Chain of Thought.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CaPo Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation": {
        "filename": "CaPo Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation.pdf",
        "analysis": {
            "benchmarks": [
                "ThreeDworld Multi-Agent Transport",
                "Communicative Watch-And-Help"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLAMA-2-13B-CHAT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prospective Role of Foundation Models in Advancing Autonomous Vehicles": {
        "filename": "Prospective Role of Foundation Models in Advancing Autonomous Vehicles.pdf",
        "analysis": {
            "benchmarks": [
                "KITTI-360",
                "CARLA simulator"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "BERT",
                "Vision Language Models (e.g., CLIP, ALIGN, BLIP-2)",
                "Multi-modal Large Language Models (e.g., GPT-4V, LLaVA, Gemini)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GEAR Augmenting Language Models with Generalizable and Efficient Tool Resolution": {
        "filename": "GEAR Augmenting Language Models with Generalizable and Efficient Tool Resolution.pdf",
        "analysis": {
            "benchmarks": [
                "ASDiv",
                "GSM8K",
                "SVAMP",
                "IWSLT",
                "NQ-Open",
                "WebQS",
                "TriviaQA",
                "CSQA",
                "COPA",
                "SocialIQA"
            ],
            "base_models": [
                "GPT-J",
                "GPT-3 (davinci-003)",
                "GPT-Neo (1.3B parameters)",
                "GPT2 medium",
                "GPT2 large",
                "MiniLM",
                "MPNet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring the Reasoning Abilities of Multimodal Large Language Models MLLMs A Comprehensive Survey on Emerging Trends in Multimodal Reasoning": {
        "filename": "Exploring the Reasoning Abilities of Multimodal Large Language Models MLLMs A Comprehensive Survey on Emerging Trends in Multimodal Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "VQAv2",
                "OK-VQA",
                "ScienceQA",
                "GQA",
                "MM-Vet",
                "Infi-MM-Eval",
                "MMMU"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-4",
                "LLaMA",
                "PaLM",
                "BLOOM",
                "Chinchilla",
                "OPT",
                "GLM",
                "Alpaca",
                "Vicuna"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Quati A Brazilian Portuguese Information Retrieval Dataset from Native Speakers": {
        "filename": "Quati A Brazilian Portuguese Information Retrieval Dataset from Native Speakers.pdf",
        "analysis": {
            "benchmarks": [
                "Quati"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Beyond Examples High-level Automated Reasoning Paradigm in In-Context Learning via MCTS": {
        "filename": "Beyond Examples High-level Automated Reasoning Paradigm in In-Context Learning via MCTS.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "SVAMP",
                "StrategyQA"
            ],
            "base_models": [
                "Qwen2.5-7B-Instruct",
                "Qwen2.5-14B-Instruct",
                "Qwen2-7B-Instruct",
                "Yi-1.5-6B-Chat",
                "Llama-3-8B-Instruct",
                "Llama-3.1-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Reward Models with Synthetic Critiques": {
        "filename": "Improving Reward Models with Synthetic Critiques.pdf",
        "analysis": {
            "benchmarks": [
                "RewardBench",
                "PandaLM"
            ],
            "base_models": [
                "LLaMA2-7B-Base",
                "Command-35B-Base",
                "Command R (35B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models on the Chessboard A Study on ChatGPTs Formal Language Comprehension and Complex Reasoning Skills": {
        "filename": "Large Language Models on the Chessboard A Study on ChatGPTs Formal Language Comprehension and Complex Reasoning Skills.pdf",
        "analysis": {
            "benchmarks": [
                "Custom chess dataset with Stockfish 15.1"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)"
            ]
        }
    },
    "Show Dont Tell Aligning Language Models with Demonstrated Feedback": {
        "filename": "Show Dont Tell Aligning Language Models with Demonstrated Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "CMCC",
                "CCAT"
            ],
            "base_models": [
                "Mistral Instruct v0.2 7B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AI for Mathematics A Cognitive Science Perspective": {
        "filename": "AI for Mathematics A Cognitive Science Perspective.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Towards LLM-Powered Ambient Sensor Based Multi-Person Human Activity Recognition": {
        "filename": "Towards LLM-Powered Ambient Sensor Based Multi-Person Human Activity Recognition.pdf",
        "analysis": {
            "benchmarks": [
                "ARAS dataset"
            ],
            "base_models": [
                "GPT-4 (32k)"
            ]
        }
    },
    "TidalDecode Fast and Accurate LLM Decoding with Position Persistent Sparse Attention": {
        "filename": "TidalDecode Fast and Accurate LLM Decoding with Position Persistent Sparse Attention.pdf",
        "analysis": {
            "benchmarks": [
                "Needle-in-the-Haystack",
                "PG-19",
                "LongBench"
            ],
            "base_models": [
                "LongChat-7b-v1.5-32k",
                "Llama-3-8B",
                "Llama-3-70B",
                "Llama-3.1-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Thoughts for Molecular Understanding": {
        "filename": "Chain-of-Thoughts for Molecular Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "CHEBI-20"
            ],
            "base_models": [
                "MolT5-base",
                "MolT5-large",
                "ChemT5-small",
                "ChemT5-base",
                "Llama3-8B-Instruct",
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Benchmark for Learning to Translate a New Language from One Grammar Book": {
        "filename": "A Benchmark for Learning to Translate a New Language from One Grammar Book.pdf",
        "analysis": {
            "benchmarks": [
                "MTOB (Machine Translation from One Book)"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-30B",
                "Llama 2-7B",
                "Llama 2-13B",
                "Llama 2-70B",
                "gpt-3.5-turbo",
                "text-davinci-003",
                "gpt-4",
                "Claude 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dynamic Self-Distillation via Previous Mini-batches for Fine-tuning Small Language Models": {
        "filename": "Dynamic Self-Distillation via Previous Mini-batches for Fine-tuning Small Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SuperGLUE",
                "GSM8K",
                "SVAMP",
                "HS",
                "AQUA",
                "MQA"
            ],
            "base_models": [
                "BERT-base 12 (110.0M)",
                "RoBERTa-base 12 (125.0M)",
                "ALBERT-base 12 (11.0M)",
                "DeBERTa-large",
                "DeBERTa-v2-large",
                "DeBERTa-v3-large",
                "LLaMA-1-7B",
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "LLaMA-3-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ChartMoE Mixture of Expert Connector for Advanced Chart Understanding": {
        "filename": "ChartMoE Mixture of Expert Connector for Advanced Chart Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "ChartQA",
                "ChartBench",
                "ChartFC",
                "ChartCheck"
            ],
            "base_models": [
                "InternLM2-7B-ChatSFT",
                "ViT-Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Semantic Composition in Visually Grounded Language Models": {
        "filename": "Semantic Composition in Visually Grounded Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WinogroundVQA"
            ],
            "base_models": [
                "BLIP 2.0",
                "MiniGPT-4",
                "BERT-base",
                "MP-Net-base",
                "GTR-T5-base",
                "GTR-T5-large",
                "GTR-T5-xl",
                "UNITER",
                "IAIS",
                "OSCAR+",
                "ROSITA",
                "CLIP",
                "LXMERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AIMS-EREA - A framework for AI-accelerated Innovation of Materials for Sustainability - for Environmental Remediation and Energy Applications": {
        "filename": "AIMS-EREA - A framework for AI-accelerated Innovation of Materials for Sustainability - for Environmental Remediation and Energy Applications.pdf",
        "analysis": {
            "benchmarks": [
                "Materials Project",
                "Open Quantum Materials Database (OQMD)"
            ],
            "base_models": [
                "OpenAI GPT-4"
            ]
        }
    },
    "PertEval Unveiling Real Knowledge Capacity of LLMs with Knowledge-Invariant Perturbations": {
        "filename": "PertEval Unveiling Real Knowledge Capacity of LLMs with Knowledge-Invariant Perturbations.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU"
            ],
            "base_models": [
                "GPT-4",
                "Gemini-1.0-Pro",
                "GPT-3.5-turbo",
                "GLM-3-turbo",
                "Mistral-7B-instruct-v0.2",
                "LLaMA-3-8B-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Models as Black-Box Optimizers for Vision-Language Models": {
        "filename": "Language Models as Black-Box Optimizers for Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ImageNet",
                "FGVC-Aircraft",
                "Food101",
                "Oxford Pets",
                "Stanford Cars",
                "SUN397",
                "UCF101",
                "DTD",
                "EuroSAT",
                "Oxford Flowers"
            ],
            "base_models": [
                "CLIP",
                "DALL-E 3",
                "ChatGPT (GPT-3.5)",
                "GPT4-V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Resolving Knowledge Conflicts in Large Language Models": {
        "filename": "Resolving Knowledge Conflicts in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset with 10k entities covering 200 subject areas"
            ],
            "base_models": [
                "GPT-3.5-TURBO",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models are Visual Reasoning Coordinators": {
        "filename": "Large Language Models are Visual Reasoning Coordinators.pdf",
        "analysis": {
            "benchmarks": [
                "A-OKVQA",
                "OK-VQA",
                "e-SNLI-VE",
                "VSR",
                "VQA v2",
                "GQA",
                "CLEVR"
            ],
            "base_models": [
                "FLAN-T5 (11B)",
                "Vicuna-1.5",
                "Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Put Your Money Where Your Mouth Is Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena": {
        "filename": "Put Your Money Where Your Mouth Is Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena.pdf",
        "analysis": {
            "benchmarks": [
                "AUCARENA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4-Turbo",
                "GPT-3.5-Turbo",
                "Gemini 1.0 Pro",
                "Mistral-7b",
                "Mixtral-8x7b",
                "LLaMA-2-13b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "User Modeling in the Era of Large Language Models Current Research and Future Directions": {
        "filename": "User Modeling in the Era of Large Language Models Current Research and Future Directions.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "Bard",
                "Llama"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Building Understandable Messaging for Policy and Evidence Review BUMPER with AI": {
        "filename": "Building Understandable Messaging for Policy and Evidence Review BUMPER with AI.pdf",
        "analysis": {
            "benchmarks": [
                "Six Nations Rugby Championship",
                "Measles Seasonality and Susceptibility"
            ],
            "base_models": [
                "GPT-4-0125-preview",
                "GPT-3.5-turbo-0125"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Metacognitive Capabilities of LLMs An Exploration in Mathematical Problem Solving": {
        "filename": "Metacognitive Capabilities of LLMs An Exploration in Mathematical Problem Solving.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "GPT-4-0613"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MuChoMusic Evaluating Music Understanding in Multimodal Audio-Language Models": {
        "filename": "MuChoMusic Evaluating Music Understanding in Multimodal Audio-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MuChoMusic"
            ],
            "base_models": [
                "Vicuna 7B",
                "LLaMA-2 7B",
                "Qwen 7B"
            ]
        }
    },
    "Vamos Versatile Action Models for Video Understanding": {
        "filename": "Vamos Versatile Action Models for Video Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "Ego4D",
                "NeXT-QA",
                "IntentQA",
                "Spacewalk-18",
                "EgoSchema"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA2-7B",
                "GPT-3.5-turbo",
                "GPT-4",
                "GPT-4o",
                "LLaMA2-chat-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Intriguing Properties of Large Language and Vision Models": {
        "filename": "Intriguing Properties of Large Language and Vision Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMVP",
                "Q-Bench",
                "MME",
                "MMStar",
                "MM-Vet",
                "LLaVA-W",
                "MathVista",
                "SQA-IMG",
                "ChartQA",
                "AI2D"
            ],
            "base_models": [
                "LLaVA-1.5-7B",
                "LLaVA-NeXT-7B",
                "LLaVA-OneVision-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Defending Against Indirect Prompt Injection Attacks With Spotlighting": {
        "filename": "Defending Against Indirect Prompt Injection Attacks With Spotlighting.pdf",
        "analysis": {
            "benchmarks": [
                "SQuAD",
                "IMDB Sentiment",
                "SuperGLUE Word-In-Context",
                "SuperGLUE BoolQ"
            ],
            "base_models": [
                "text-davinci-003",
                "GPT-3.5Turbo (June 2023 version)",
                "GPT-4 (June 2023 version)"
            ]
        }
    },
    "Keep the Cost Down A Review on Methods to Optimize LLM s KV-Cache Consumption": {
        "filename": "Keep the Cost Down A Review on Methods to Optimize LLM s KV-Cache Consumption.pdf",
        "analysis": {
            "benchmarks": [
                "LongBench",
                "ZeroSCROLLS"
            ],
            "base_models": [
                "GPT-3",
                "LLaMA2-7B",
                "LLaMA2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Model Criticism for Long-Form Text Generation": {
        "filename": "Model Criticism for Long-Form Text Generation.pdf",
        "analysis": {
            "benchmarks": [
                "PUBMED",
                "ARXIV",
                "WIKI",
                "WIKI-SHORT"
            ],
            "base_models": [
                "GPT-2 small (117M)",
                "GPT-Neo small",
                "GPT-2 medium (345M)",
                "GPT-2 large (742M)",
                "GPT-2 XL (1.5B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GELDA A generative language annotation framework to reveal visual biases in datasets": {
        "filename": "GELDA A generative language annotation framework to reveal visual biases in datasets.pdf",
        "analysis": {
            "benchmarks": [
                "CUB-200",
                "Stanford Cars",
                "DeepFashion",
                "CelebA",
                "SD Living Rooms",
                "SG2 Faces",
                "SG2 Dogs"
            ],
            "base_models": [
                "GPT-3.5",
                "BLIP",
                "OWLv2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model for Science A Study on P vs NP": {
        "filename": "Large Language Model for Science A Study on P vs NP.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CQSumDP A ChatGPT-Annotated Resource for Query-Focused Abstractive Summarization Based on Debatepedia": {
        "filename": "CQSumDP A ChatGPT-Annotated Resource for Query-Focused Abstractive Summarization Based on Debatepedia.pdf",
        "analysis": {
            "benchmarks": [
                "Debatepedia",
                "MS-MARCO"
            ],
            "base_models": [
                "BART-Base",
                "Pegasus-Base",
                "T5-Base",
                "BART-Large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting": {
        "filename": "Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "Visual Genome",
                "Dense Relational Captioning"
            ],
            "base_models": [
                "BLIP (ViT-B/16)",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Are Human-Level Prompt Engineers": {
        "filename": "Large Language Models Are Human-Level Prompt Engineers.pdf",
        "analysis": {
            "benchmarks": [
                "Instruction Induction tasks",
                "BIG-Bench tasks"
            ],
            "base_models": [
                "GPT-3 (350M)",
                "GPT-3 (1.3B)",
                "GPT-3 (6.7B)",
                "GPT-3 (175B)",
                "InstructGPT (350M)",
                "InstructGPT (1.3B)",
                "InstructGPT (6.7B)",
                "InstructGPT (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection": {
        "filename": "Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection.pdf",
        "analysis": {
            "benchmarks": [
                "financial higher-order datasets"
            ],
            "base_models": [
                "GPT-4o"
            ]
        }
    },
    "Frontier AI Ethics Anticipating and Evaluating the Societal Impacts of Language Model Agents": {
        "filename": "Frontier AI Ethics Anticipating and Evaluating the Societal Impacts of Language Model Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Claude 3",
                "GPT-4V",
                "Google's Gemini"
            ]
        }
    },
    "Development and bilingual evaluation of Japanese medical large language model within reasonably low computational resources": {
        "filename": "Development and bilingual evaluation of Japanese medical large language model within reasonably low computational resources.pdf",
        "analysis": {
            "benchmarks": [
                "IgakuQA",
                "MedQA",
                "MedMCQA",
                "MMLU",
                "JMMLU"
            ],
            "base_models": [
                "Qwen2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LVDiffusor Distilling Functional Rearrangement Priors From Large Models Into Diffusor": {
        "filename": "LVDiffusor Distilling Functional Rearrangement Priors From Large Models Into Diffusor.pdf",
        "analysis": {
            "benchmarks": [
                "DinnerTable (Vanilla)",
                "DinnerTable (Left-handed)",
                "OfficeDesk (Vanilla)",
                "OfficeDesk (Left-handed)"
            ],
            "base_models": [
                "StableDiffusion XL (3.5B parameters)",
                "GPT-4"
            ]
        }
    },
    "RCOT Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought": {
        "filename": "RCOT Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQuA",
                "SVAMP",
                "AddSub",
                "ASDiv",
                "Date",
                "SingleEq"
            ],
            "base_models": [
                "ChatGPT",
                "LLaMA-13B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cycles of Thought Measuring LLM Confidence through Stable Explanations": {
        "filename": "Cycles of Thought Measuring LLM Confidence through Stable Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "TruthfulQA",
                "MedQA",
                "MMLU Professional Law",
                "MMLU Conceptual Physics"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dissociation of Faithful and Unfaithful Reasoning in LLMs": {
        "filename": "Dissociation of Faithful and Unfaithful Reasoning in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith",
                "ASDiv",
                "SVAMP",
                "GSM8K"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3 Opus",
                "Llama-3 70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From LLMs to LLM-based Agents for Software Engineering A Survey of Current Challenges and Future": {
        "filename": "From LLMs to LLM-based Agents for Software Engineering A Survey of Current Challenges and Future.pdf",
        "analysis": {
            "benchmarks": [
                "PROMISE NFR",
                "HumanEval"
            ],
            "base_models": [
                "GPT-4",
                "Codex"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hint Marginalization for Improved Reasoning in Large Language Models": {
        "filename": "Hint Marginalization for Improved Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AddSub",
                "MultiArith",
                "SingleEQ",
                "SVAMP",
                "GSM8K",
                "AQuA"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "GPT-4 Turbo",
                "GPT-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GenoTEX A Benchmark for Evaluating LLM-Based Exploration of Gene Expression Data in Alignment with Bioinformaticians": {
        "filename": "GenoTEX A Benchmark for Evaluating LLM-Based Exploration of Gene Expression Data in Alignment with Bioinformaticians.pdf",
        "analysis": {
            "benchmarks": [
                "GenoTEX",
                "Gene Expression Omnibus",
                "The Cancer Genome Atlas"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LiveXiv - A Multi-Modal Live Benchmark Based on Arxiv Papers Content": {
        "filename": "LiveXiv - A Multi-Modal Live Benchmark Based on Arxiv Papers Content.pdf",
        "analysis": {
            "benchmarks": [
                "LiveXiv"
            ],
            "base_models": [
                "GPT-4o",
                "Claude",
                "LLaVA 1.5-7B",
                "LLaVA 1.5-13B",
                "LLaVA 1.6-7B",
                "LLaVA 1.6-34B",
                "LLaVA One-Vision",
                "InstructBLIP",
                "InternVL2-2B",
                "InternVL2-8B",
                "InternLM-Xcomposer2-4KHD",
                "InternLM-Xcomposer2.5",
                "Mantis",
                "Phi3v",
                "Idefics2",
                "Idefics3",
                "Qwen2-VL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Discuss Strategically A Case Study on One Night Ultimate Werewolf": {
        "filename": "Learning to Discuss Strategically A Case Study on One Night Ultimate Werewolf.pdf",
        "analysis": {
            "benchmarks": [
                "One Night Ultimate Werewolf (ONUW) dataset"
            ],
            "base_models": [
                "GPT-4",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PACIFIC Towards Proactive Conversational Question Answering over Tabular and Textual Data in Finance": {
        "filename": "PACIFIC Towards Proactive Conversational Question Answering over Tabular and Textual Data in Finance.pdf",
        "analysis": {
            "benchmarks": [
                "PACIFIC",
                "TAT-QA"
            ],
            "base_models": [
                "T5 base",
                "CodeT5 base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Rationale-Augmented Ensembles in Language Models": {
        "filename": "Rationale-Augmented Ensembles in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "WiC",
                "SST-2",
                "QQP",
                "e-SNLI",
                "HotpotQA",
                "OpenBookQA",
                "ANLI",
                "MNLI",
                "RTE",
                "ARC",
                "GSM8K"
            ],
            "base_models": [
                "PaLM-540B",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Compositional preference models for aligning LMs": {
        "filename": "Compositional preference models for aligning LMs.pdf",
        "analysis": {
            "benchmarks": [
                "HH-RLHF",
                "SHP"
            ],
            "base_models": [
                "GPT-3.5",
                "Flan-T5-XL (3B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Augmenting Autotelic Agents with Large Language Models": {
        "filename": "Augmenting Autotelic Agents with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CookingWorld"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0301)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Domain Adaptable Prescriptive AI Agent for Enterprise": {
        "filename": "Domain Adaptable Prescriptive AI Agent for Enterprise.pdf",
        "analysis": {
            "benchmarks": [
                "airline pricing use case",
                "bank marketing dataset"
            ],
            "base_models": [
                "FLAN-T5 XL (3B)",
                "LLaMA-7B",
                "GPT-J",
                "Mixtral 8x7B Instruct"
            ]
        }
    },
    "Unleashing the Power of Task-Specific Directions in Parameter Efficient Fine-tuning": {
        "filename": "Unleashing the Power of Task-Specific Directions in Parameter Efficient Fine-tuning.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "PIQA",
                "SIQA",
                "HellaSwag",
                "WinoGrande",
                "ARC-e",
                "ARC-c",
                "OBQA",
                "GLUE"
            ],
            "base_models": [
                "LLaMA-7B",
                "LLaMA2-7B",
                "LLaMA3-8B",
                "DeBERTaV3-base",
                "DeBERTaV3-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Thought Hub A Continuous Effort to Measure Large Language Models Reasoning Performance": {
        "filename": "Chain-of-Thought Hub A Continuous Effort to Measure Large Language Models Reasoning Performance.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "MATH",
                "MMLU",
                "BigBench Hard",
                "HumanEval",
                "C-Eval"
            ],
            "base_models": [
                "GPT-4",
                "Claude-v1.3",
                "PaLM-2",
                "LLaMA-65B",
                "GPT-3.5-Turbo",
                "text-davinci-003",
                "code-davinci-002",
                "Minerva 540B",
                "Flan-PaLM 540B",
                "Flan-U-PaLM 540B",
                "PaLM 540B",
                "PaLM 64B",
                "LLaMA 33B",
                "LLaMA 13B",
                "Flan-T5 11B",
                "LLaMA 7B",
                "Flan-T5 3B"
            ]
        }
    },
    "LUK Empowering Log Understanding with Expert Knowledge from Large Language Models": {
        "filename": "LUK Empowering Log Understanding with Expert Knowledge from Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Loghub",
                "Cisco",
                "Huawei"
            ],
            "base_models": [
                "BERT (110M)",
                "ChatGPT",
                "Llama-2-13b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On The Planning Abilities of OpenAIs o1 Models Feasibility Optimality and Generalizability": {
        "filename": "On The Planning Abilities of OpenAIs o1 Models Feasibility Optimality and Generalizability.pdf",
        "analysis": {
            "benchmarks": [
                "Barman",
                "Tyreworld",
                "Termes",
                "Floortile",
                "Blocksworld",
                "Grippers"
            ],
            "base_models": [
                "GPT-4",
                "o1-mini",
                "o1-preview"
            ]
        }
    },
    "DIN-SQL Decomposed In-Context Learning of Text-to-SQL with Self-Correction": {
        "filename": "DIN-SQL Decomposed In-Context Learning of Text-to-SQL with Self-Correction.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "BIRD"
            ],
            "base_models": [
                "GPT-4",
                "CodeX Davinci",
                "CodeX Cushman"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ACC-Debate An Actor-Critic Approach to Multi-Agent Debate": {
        "filename": "ACC-Debate An Actor-Critic Approach to Multi-Agent Debate.pdf",
        "analysis": {
            "benchmarks": [
                "BoolQ",
                "MMLU",
                "BBH",
                "SCIQ",
                "ARC"
            ],
            "base_models": [
                "Llama-3-8B-Instruct",
                "Mistral-7B-Instruct",
                "Gemma-2-2B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Decomposition for Enhancing Attention Improving LLM-based Text-to-SQL through Workflow Paradigm": {
        "filename": "Decomposition for Enhancing Attention Improving LLM-based Text-to-SQL through Workflow Paradigm.pdf",
        "analysis": {
            "benchmarks": [
                "Spider Dev",
                "Spider-Realistic",
                "Bird Dev"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WebWISE Web Interface Control and Sequential Exploration with Large Language Models": {
        "filename": "WebWISE Web Interface Control and Sequential Exploration with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MiniWob++"
            ],
            "base_models": [
                "gpt-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "E-EVAL A Comprehensive Chinese K-12 Education Evaluation Benchmark for Large Language Models": {
        "filename": "E-EVAL A Comprehensive Chinese K-12 Education Evaluation Benchmark for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "E-EV AL"
            ],
            "base_models": [
                "ChatGPT (undisclosed size)",
                "GPT 4.0 (undisclosed size)",
                "ERNIE-Bot (undisclosed size)",
                "ERNIE-Bot 4.0 (undisclosed size)",
                "Qwen-72B",
                "Qwen-7B",
                "Yi-34B-Chat",
                "Yi-6B-Chat",
                "ChatGLM3-6B",
                "Baichuan2-13B-Chat",
                "Baichuan2-7B-Chat",
                "Chinese-LLaMA-2-13B",
                "Chinese-Alpaca-2-13B",
                "Educhat-sft-002-13B",
                "Educhat-sft-002-13B-Baichuan"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dynamic Planning with a LLM": {
        "filename": "Dynamic Planning with a LLM.pdf",
        "analysis": {
            "benchmarks": [
                "Alfworld"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models": {
        "filename": "Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "HoVER",
                "FEVEROUS",
                "SciFact-Open"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "llama-7B",
                "llama-13B",
                "llama-30B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Kotlin ML Pack Technical Report": {
        "filename": "Kotlin ML Pack Technical Report.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval (Kotlin version)",
                "HumanEval (Python version)"
            ],
            "base_models": [
                "CodeLlama-70B-Instruct-hf",
                "Deepseek-coder-33B-instruct",
                "Deepseek-coder-6.7B-instruct",
                "GPT-3.5-turbo",
                "GPT-4-turbo",
                "CodeQwen1.5-7B",
                "Meta-Llama-3-8B-Instruct",
                "Deepseek-coder-6.7B-base",
                "CodeLlama-13b-Instruct-hf",
                "Deepseek-coder-1.3B-instruct",
                "CodeLlama-7B-Instruct-hf",
                "Mistral-7B-Instruct-v0.2",
                "Mistral-7B-Instruct-v0.1",
                "Deepseek-coder-1.3B-base",
                "Codellama-7B-hf",
                "phi-2Language"
            ]
        }
    },
    "Who Wrote it and Why Prompting Large-Language Models for Authorship Verification": {
        "filename": "Who Wrote it and Why Prompting Large-Language Models for Authorship Verification.pdf",
        "analysis": {
            "benchmarks": [
                "IMDb62"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "Rethinking Machine Ethics - Can LLMs Perform Moral Reasoning through the Lens of Moral Theories": {
        "filename": "Rethinking Machine Ethics - Can LLMs Perform Moral Reasoning through the Lens of Moral Theories.pdf",
        "analysis": {
            "benchmarks": [
                "normative ethics datasets (Hendrycks et al., 2021)",
                "commonsense morality datasets (Forbes et al., 2020)"
            ],
            "base_models": [
                "LLAMA (Touvron et al., 2023)",
                "GPT-4 (OpenAI, 2023)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Conversational Factor Information Retrieval Model ConFIRM": {
        "filename": "Conversational Factor Information Retrieval Model ConFIRM.pdf",
        "analysis": {
            "benchmarks": [
                "PolyU-Asklora Fintech Adoption Index"
            ],
            "base_models": [
                "Llama-2-7b"
            ]
        }
    },
    "Symbolic Chain-of-Thought Distillation Small Models Can Also Think Step-by-Step": {
        "filename": "Symbolic Chain-of-Thought Distillation Small Models Can Also Think Step-by-Step.pdf",
        "analysis": {
            "benchmarks": [
                "CommonsenseQA",
                "QuaRel",
                "OpenBookQA"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "OPT (125M-1.3B)"
            ]
        }
    },
    "LLM With Tools A Survey": {
        "filename": "LLM With Tools A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "ScienceQA"
            ],
            "base_models": [
                "GPT-3.5 (gpt-35-turbo-16k-0613)"
            ]
        }
    },
    "Geode A Zero-shot Geospatial Question-Answering Agent with Explicit Reasoning and Precise Spatio-Temporal Retrieval": {
        "filename": "Geode A Zero-shot Geospatial Question-Answering Agent with Explicit Reasoning and Precise Spatio-Temporal Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "GIS datasets"
            ],
            "base_models": [
                "GPT-3.5",
                "Claude-3-Opus",
                "WizardCoder-Python-34B"
            ]
        }
    },
    "InstructZero Efficient Instruction Optimization for Black-Box Large Language Models": {
        "filename": "InstructZero Efficient Instruction Optimization for Black-Box Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench"
            ],
            "base_models": [
                "Vicuna-13B",
                "GPT-3.5-turbo (ChatGPT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On Prompt Sensitivity of ChatGPT in Affective Computing": {
        "filename": "On Prompt Sensitivity of ChatGPT in Affective Computing.pdf",
        "analysis": {
            "benchmarks": [
                "Twitter140 dataset",
                "Toxic Comment Classification Challenge",
                "Sarcasm Detection dataset (news headlines from huffpost and theonion)"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0613)"
            ]
        }
    },
    "LangProp A code optimization framework using Large Language Models applied to driving": {
        "filename": "LangProp A code optimization framework using Large Language Models applied to driving.pdf",
        "analysis": {
            "benchmarks": [
                "Sudoku",
                "CartPole",
                "CARLA"
            ],
            "base_models": [
                "GPT-3.5 Turbo 16k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How Much Can RAG Help the Reasoning of LLM": {
        "filename": "How Much Can RAG Help the Reasoning of LLM.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions (NQ)"
            ],
            "base_models": [
                "LLama3",
                "Vicuna",
                "Mistral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Developers Prompt A Controlled Experiment for Code Documentation Generation": {
        "filename": "Can Developers Prompt A Controlled Experiment for Code Documentation Generation.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ALERT Adapt Language Models to Reasoning Tasks": {
        "filename": "ALERT Adapt Language Models to Reasoning Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "bigbench repeat copy logic",
                "mmmlu answer generation",
                "plausable result generation",
                "anli r2 entailment",
                "anli r3 entailment",
                "cb entailment",
                "piqa answer generation",
                "commongen sentence generation",
                "sciq answer generation",
                "openbookqa question answering",
                "nli r2 entailment",
                "lue entailment classification",
                "semeval closed vocabulary math",
                "semeval geometric math",
                "mmmlu formal logic",
                "tellmewhy",
                "babi t1 single supporting fact",
                "toqa find location easy clean",
                "bard analogical reasoning causation",
                "argument stance classification",
                "argument consequence classification",
                "rocstories correct answer generation"
            ],
            "base_models": [
                "GPT-3",
                "PALM",
                "OPT (1.3B and 13B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Words to Code Harnessing Data for Program Synthesis from Natural Language": {
        "filename": "From Words to Code Harnessing Data for Program Synthesis from Natural Language.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "KaggleDBQA",
                "Forum",
                "Product",
                "JigsawM",
                "Jigsaw"
            ],
            "base_models": [
                "Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DreamStory Open-Domain Story Visualization by LLM-Guided Multi-Subject Consistent Diffusion": {
        "filename": "DreamStory Open-Domain Story Visualization by LLM-Guided Multi-Subject Consistent Diffusion.pdf",
        "analysis": {
            "benchmarks": [
                "DS-500"
            ],
            "base_models": [
                "GPT-4",
                "Yi"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PersonaMath Enhancing Math Reasoning through Persona-Driven Data Augmentation": {
        "filename": "PersonaMath Enhancing Math Reasoning through Persona-Driven Data Augmentation.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "LLaMA-3.1-8B",
                "Qwen2.5-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CIPHER Cybersecurity Intelligent Penetration-Testing Helper for Ethical Researcher": {
        "filename": "CIPHER Cybersecurity Intelligent Penetration-Testing Helper for Ethical Researcher.pdf",
        "analysis": {
            "benchmarks": [
                "FARR Flow",
                "MITRE ATT&CK capabilities from PurpleLlama"
            ],
            "base_models": [
                "Llama 3 70B",
                "Qwen1.5 72B Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Venn Diagram Prompting  Accelerating Comprehension with Scaffolding Effect": {
        "filename": "Venn Diagram Prompting  Accelerating Comprehension with Scaffolding Effect.pdf",
        "analysis": {
            "benchmarks": [
                "ELI5",
                "PubMedQA",
                "Long-Context QA",
                "Sec 10-Q"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "ChatRule Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning": {
        "filename": "ChatRule Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "Family",
                "UMLS",
                "WN18RR",
                "YAGO3-10"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0613)",
                "GPT-4",
                "Mistral-7B-Instruct",
                "LLaMA2-Chat-7B",
                "LLaMA2-Chat-13B",
                "LLaMA2-Chat-70B"
            ]
        }
    },
    "MARPLE A Benchmark for Long-Horizon Inference": {
        "filename": "MARPLE A Benchmark for Long-Horizon Inference.pdf",
        "analysis": {
            "benchmarks": [
                "MARPLE"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models can Strategically Deceive their Users when Put Under Pressure": {
        "filename": "Large Language Models can Strategically Deceive their Users when Put Under Pressure.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4-32k",
                "GPT-4-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ADMUS A Progressive Question Answering Framework Adaptable to Multiple Knowledge Sources": {
        "filename": "ADMUS A Progressive Question Answering Framework Adaptable to Multiple Knowledge Sources.pdf",
        "analysis": {
            "benchmarks": [
                "birdDB",
                "filmDB",
                "DBpedia2016"
            ],
            "base_models": []
        }
    },
    "Prompt-based Extraction of Social Determinants of Health Using Few-shot Learning": {
        "filename": "Prompt-based Extraction of Social Determinants of Health Using Few-shot Learning.pdf",
        "analysis": {
            "benchmarks": [
                "SHAC"
            ],
            "base_models": [
                "GPT-4",
                "BERT",
                "T5"
            ]
        }
    },
    "Zero-shot Visual Question Answering with Language Model Feedback": {
        "filename": "Zero-shot Visual Question Answering with Language Model Feedback.pdf",
        "analysis": {
            "benchmarks": [
                "OK-VQA",
                "A-OKVQA"
            ],
            "base_models": [
                "FLAN-T5-XXL (11B)",
                "FLAN-T5-large (738M)",
                "FLAN-T5-XL (3B)",
                "FLAN-T5-base (223M)"
            ]
        }
    },
    "Explaining Legal Concepts with Augmented Large Language Models GPT-4": {
        "filename": "Explaining Legal Concepts with Augmented Large Language Models GPT-4.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Integration of Large Language Models within Cognitive Architectures for Autonomous Robots": {
        "filename": "Integration of Large Language Models within Cognitive Architectures for Autonomous Robots.pdf",
        "analysis": {
            "benchmarks": [
                "mock-up apartment human-robot interaction environment"
            ],
            "base_models": [
                "LLaMA-13B (quantized)",
                "Marcoroni-13B (quantized)"
            ]
        }
    },
    "Are You Human An Adversarial Benchmark to Expose LLMs": {
        "filename": "Are You Human An Adversarial Benchmark to Expose LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "open-source benchmark dataset of jailbreak prompts and LLM limitation challenges"
            ],
            "base_models": [
                "GPT-4",
                "Claude",
                "Gemini",
                "Mistral",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods": {
        "filename": "A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods.pdf",
        "analysis": {
            "benchmarks": [
                "CNN & Daily Mail",
                "DUC",
                "Gigaword",
                "XSum",
                "Multi-News",
                "Scisumm",
                "ArXiv, PubMed",
                "WikiHow",
                "LCSTS"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5",
                "BERT",
                "Pegasus",
                "BART",
                "T5",
                "ELMo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt-based vs Fine-tuned LLMs Toward Causal Graph Verification": {
        "filename": "Prompt-based vs Fine-tuned LLMs Toward Causal Graph Verification.pdf",
        "analysis": {
            "benchmarks": [
                "DDI",
                "COMAGC",
                "GENE",
                "SEMEVAL"
            ],
            "base_models": [
                "BERT (base, uncased)",
                "BioBERT",
                "PubMedBERT",
                "GPT-3.5-turbo",
                "text-davinci-003",
                "GPT/ada"
            ]
        }
    },
    "Unpacking Failure Modes of Generative Policies Runtime Monitoring of Consistency and Progress": {
        "filename": "Unpacking Failure Modes of Generative Policies Runtime Monitoring of Consistency and Progress.pdf",
        "analysis": {
            "benchmarks": [
                "PushT",
                "Close Box",
                "Cover Object",
                "Push Chair"
            ],
            "base_models": [
                "GPT-4o",
                "Claude"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Octopus v2 On-device language model for super agent": {
        "filename": "Octopus v2 On-device language model for super agent.pdf",
        "analysis": {
            "benchmarks": [
                "Android function calls",
                "Vehicle function calls",
                "Yelp and DoorDash APIs"
            ],
            "base_models": [
                "Gemma-2B",
                "Llama-7B",
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Do the Rewards Justify the Means Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark": {
        "filename": "Do the Rewards Justify the Means Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "MACHIAVELLI"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "DeBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Graph-constrained Reasoning Faithful Reasoning on Knowledge Graphs with Large Language Models": {
        "filename": "Graph-constrained Reasoning Faithful Reasoning on Knowledge Graphs with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WebQuestionSP (WebQSP)",
                "Complex WebQuestions (CWQ)",
                "CommonsenseQA (CSQA)",
                "MedQA-USMLE (MedQA)"
            ],
            "base_models": [
                "Llama-3.1-8B",
                "ChatGPT",
                "GPT-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Training Large Language Models to Reason in a Continuous Latent Space": {
        "filename": "Training Large Language Models to Reason in a Continuous Latent Space.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "ProntoQA",
                "ProsQA"
            ],
            "base_models": [
                "GPT-2"
            ]
        }
    },
    "Alice in Wonderland Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models": {
        "filename": "Alice in Wonderland Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AIW problem variations 1-4"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Claude 3 Opus",
                "Gemini",
                "LLaMa 2",
                "LLaMa 3",
                "Mistral",
                "Mixtral",
                "Dbrx",
                "Command R+"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Deixis-Centered Approach for Documenting Remote Synchronous Communication Around Data Visualizations": {
        "filename": "A Deixis-Centered Approach for Documenting Remote Synchronous Communication Around Data Visualizations.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Whisper"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring the Intersection of Large Language Models and Agent-Based Modeling via Prompt Engineering": {
        "filename": "Exploring the Intersection of Large Language Models and Agent-Based Modeling via Prompt Engineering.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "gpt-3.5-turbo",
                "OPT",
                "Llama-2-7b-chat-hf"
            ]
        }
    },
    "Can We Trust Embodied Agents Exploring Backdoor Attacks against Embodied LLM-based Decision-Making Systems": {
        "filename": "Can We Trust Embodied Agents Exploring Backdoor Attacks against Embodied LLM-based Decision-Making Systems.pdf",
        "analysis": {
            "benchmarks": [
                "HighwayEnv",
                "nuScenes",
                "VirtualHome"
            ],
            "base_models": [
                "GPT-3.5",
                "LLaMA2-7B",
                "PaLM2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WorldAfford Affordance Grounding based on Natural Language Instructions": {
        "filename": "WorldAfford Affordance Grounding based on Natural Language Instructions.pdf",
        "analysis": {
            "benchmarks": [
                "AGD20K",
                "LLMaFF"
            ],
            "base_models": [
                "GPT-4",
                "CLIP",
                "Segment Anything Model (SAM)"
            ]
        }
    },
    "Visual Programming for Zero-Shot Open-Vocabulary 3D Visual Grounding": {
        "filename": "Visual Programming for Zero-Shot Open-Vocabulary 3D Visual Grounding.pdf",
        "analysis": {
            "benchmarks": [
                "ScanRefer",
                "Nr3D"
            ],
            "base_models": [
                "CLIP",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Pushing the Envelope of Low-Bit LLM via Dynamic Error Compensation": {
        "filename": "Pushing the Envelope of Low-Bit LLM via Dynamic Error Compensation.pdf",
        "analysis": {
            "benchmarks": [
                "WikiText",
                "BIG-Bench Hard (BBH)",
                "MT-Bench"
            ],
            "base_models": [
                "Llama-3-8B-Instruct",
                "Phi-3-medium-4k-instruct (14B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "See Think Confirm Interactive Prompting Between Vision and Language Models for Knowledge-based Visual Reasoning": {
        "filename": "See Think Confirm Interactive Prompting Between Vision and Language Models for Knowledge-based Visual Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "OK-VQA",
                "A-OKVQA"
            ],
            "base_models": [
                "OPT-66B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Collective Innovation in Groups of Large Language Models": {
        "filename": "Collective Innovation in Groups of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Little Alchemy 2"
            ],
            "base_models": [
                "GPT-3.5 turbo",
                "Llama 2 (13B)"
            ]
        }
    },
    "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks": {
        "filename": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks.pdf",
        "analysis": {
            "benchmarks": [
                "COCO",
                "OKVQA"
            ],
            "base_models": [
                "CLIP",
                "Vicuna-7B",
                "LLaMA-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Boosting Theory-of-Mind Performance in Large Language Models via Prompting": {
        "filename": "Boosting Theory-of-Mind Performance in Large Language Models via Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "Photo scenarios",
                "ToM scenarios"
            ],
            "base_models": [
                "GPT-4",
                "Davinci-2 (GPT-3.5 variant)",
                "Davinci-3 (GPT-3.5 variant)",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Are Large Language Models Table-based Fact-Checkers": {
        "filename": "Are Large Language Models Table-based Fact-Checkers.pdf",
        "analysis": {
            "benchmarks": [
                "TabFact-small-test"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-turbo)",
                "LLaMA-1 (7B)",
                "LLaMA-2 (7B)",
                "LLaMA-2-chat (7B)"
            ]
        }
    },
    "Towards Synthetic Trace Generation of Modeling Operations using In-Context Learning Approach": {
        "filename": "Towards Synthetic Trace Generation of Modeling Operations using In-Context Learning Approach.pdf",
        "analysis": {
            "benchmarks": [
                "Hepsycode dataset",
                "Industrial dataset"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA3 70B",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Intrinsic Self-Correction Capability of LLMs Uncertainty and Latent Concept": {
        "filename": "On the Intrinsic Self-Correction Capability of LLMs Uncertainty and Latent Concept.pdf",
        "analysis": {
            "benchmarks": [
                "BBQ benchmark",
                "RealToxicityPrompts"
            ],
            "base_models": [
                "zephyr-7b-sft-full",
                "Mistral-7B-v0.1",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SentimentGPT Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning": {
        "filename": "SentimentGPT Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval 2017 - Task 4"
            ],
            "base_models": [
                "GPT-3.5 Turbo",
                "Ada",
                "Babbage",
                "Curie",
                "Davinci"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "How to Catch an AI Liar Lie Detection in Black-Box LLMs by Asking Unrelated Questions": {
        "filename": "How to Catch an AI Liar Lie Detection in Black-Box LLMs by Asking Unrelated Questions.pdf",
        "analysis": {
            "benchmarks": [
                "Synthetic Facts dataset",
                "Real-life role-playing scenarios"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-3 (175B)",
                "LLaMA-30B",
                "LLaMA-7B",
                "Alpaca-7B",
                "Vicuna-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Alpha-GPT Human-AI Interactive Alpha Mining for Quantitative Investment": {
        "filename": "Alpha-GPT Human-AI Interactive Alpha Mining for Quantitative Investment.pdf",
        "analysis": {
            "benchmarks": [
                "inter-day volume-price data of stock markets"
            ],
            "base_models": [
                "GPT-3.5-turbo-16k-0613"
            ]
        }
    },
    "PPPR Portable Plug-in Prompt Refiner for Text to Audio Generation": {
        "filename": "PPPR Portable Plug-in Prompt Refiner for Text to Audio Generation.pdf",
        "analysis": {
            "benchmarks": [
                "AudioCaps"
            ],
            "base_models": [
                "Llama",
                "FLAN-T5-LARGE"
            ]
        }
    },
    "MM-AUTowards Multimodal Understanding of Advertisement Videos": {
        "filename": "MM-AUTowards Multimodal Understanding of Advertisement Videos.pdf",
        "analysis": {
            "benchmarks": [
                "MM-AU"
            ],
            "base_models": [
                "GPT-4",
                "Flan-T5-XXL (11B)",
                "Flan-T5-XL (3B)",
                "Alpaca (7B)",
                "Opt-IML (1.3B)",
                "Flan-T5-L (780M)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "STEPS A Benchmark for Order Reasoning in Sequential Tasks": {
        "filename": "STEPS A Benchmark for Order Reasoning in Sequential Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "STEPS"
            ],
            "base_models": [
                "GPT2-Small (117M)",
                "GPT2-Medium (345M)",
                "GPT2-Large (774M)",
                "GPT2-XL (1.5B)",
                "OPT-1.3B (1.3B)",
                "OPT-13B (13B)",
                "OPT-30B (30B)",
                "BLOOM-3B (3B)",
                "BLOOM-7B1 (7.1B)"
            ]
        }
    },
    "A Systematic Survey of Prompt Engineering in Large Language Models Techniques and Applications": {
        "filename": "A Systematic Survey of Prompt Engineering in Large Language Models Techniques and Applications.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQuA",
                "TabFact",
                "WikiTQ",
                "HotpotQA",
                "FEVER",
                "TriviaQA",
                "Natural Questions",
                "ScienceQA",
                "BIG-Bench",
                "MMLU"
            ],
            "base_models": [
                "GPT-3",
                "GPT-4",
                "PaLM 540B",
                "LLaMA 2-70B",
                "Vicuna-33b",
                "T5-base",
                "T5-large",
                "RAG-Token",
                "RAG-Seq",
                "text-davinci-003",
                "code-davinci-002",
                "text-curie-001",
                "gpt-3.5-turbo",
                "Llama 65B",
                "PaLM 2-L-IT"
            ]
        }
    },
    "Can Generalist Foundation Models Outcompete Special-Purpose Tuning Case Study in Medicine": {
        "filename": "Can Generalist Foundation Models Outcompete Special-Purpose Tuning Case Study in Medicine.pdf",
        "analysis": {
            "benchmarks": [
                "MedQA (USMLE-style)",
                "MedMCQA Dev",
                "PubMedQA Reasoning Required",
                "MMLU Clinical Knowledge",
                "MMLU Medical Genetics",
                "MMLU Anatomy",
                "MMLU Professional Medicine",
                "MMLU College Biology",
                "MMLU College Medicine"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Flan-PaLM 540B",
                "Med-PaLM 2 (based on PaLM 2)"
            ]
        }
    },
    "Beyond Outcomes Transparent Assessment of LLM Reasoning in Games": {
        "filename": "Beyond Outcomes Transparent Assessment of LLM Reasoning in Games.pdf",
        "analysis": {
            "benchmarks": [
                "GAMEBOT"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4o mini",
                "GPT-4",
                "Gemini 1.5 Pro",
                "Gemini 1.5 Flash",
                "Gemini-Pro",
                "Claude 3.5 Sonnet",
                "Claude 3 Sonnet",
                "Claude 3 Haiku",
                "Reka Core",
                "Reka Flash",
                "LLaMA3.1-405b",
                "LLaMA3.1-70b",
                "LLaMA3.1-8b",
                "Jamba-1.5-large",
                "Jamba-1.5-mini",
                "Mistral Nemo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Emergent Abilities of Large Language Models": {
        "filename": "Emergent Abilities of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench",
                "TruthfulQA",
                "Massive Multi-task Language Understanding (MMLU)",
                "Word in Context (WiC)"
            ],
            "base_models": [
                "GPT-3 (175B parameters)",
                "LaMDA (68B parameters)",
                "Gopher (280B parameters)",
                "Chinchilla",
                "PaLM (540B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Cross-task Generalization of Unified Table-to-text Models with Compositional Task Configurations": {
        "filename": "Improving Cross-task Generalization of Unified Table-to-text Models with Compositional Task Configurations.pdf",
        "analysis": {
            "benchmarks": [
                "WIKISQL",
                "WIKITQ",
                "SQUAD",
                "TOTTO",
                "TABFACT",
                "NQ-TABLES",
                "HYBRID QA",
                "TAT-QA",
                "FETAQA",
                "FEVEROUS"
            ],
            "base_models": [
                "T5-base",
                "T5-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming": {
        "filename": "Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming.pdf",
        "analysis": {
            "benchmarks": [
                "CLUTRR",
                "DBpedia-INF"
            ],
            "base_models": [
                "RoBERTa-base",
                "DeBERTa-base",
                "word2vec with BiLSTM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Language Modeling on Tabular Data A Survey of Foundations Techniques and Evolution": {
        "filename": "Language Modeling on Tabular Data A Survey of Foundations Techniques and Evolution.pdf",
        "analysis": {
            "benchmarks": [
                "Income",
                "Diabetes",
                "Forest Cover Type",
                "California Housing",
                "MNIST (tabular)",
                "Qsar Bio",
                "Credit-g",
                "Higgs Boson",
                "BlogFeedback",
                "Bank Marketing",
                "BlastChar",
                "MovieLens-1M",
                "Car",
                "Wikipedia Tables",
                "WDC Web Table Corpus",
                "WikiTableQuestion",
                "WikiSQL",
                "Spider",
                "SQA",
                "MULTIHIERTT",
                "FeTaQA",
                "TAT-QA",
                "HybridQA",
                "ToTTo",
                "TabFact"
            ],
            "base_models": [
                "BERT",
                "GPT",
                "LLaMA",
                "GPT-2",
                "GPT-3",
                "GPT-3.5",
                "GPT-4",
                "Flan-PaLM",
                "PaLM2",
                "LLaMA2",
                "Clinical-Longformer",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Should ChatGPT be Biased Challenges and Risks of Bias in Large Language Models": {
        "filename": "Should ChatGPT be Biased Challenges and Risks of Bias in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Kernel Looping Eliminating Synchronization Boundaries for Peak Inference Performance": {
        "filename": "Kernel Looping Eliminating Synchronization Boundaries for Peak Inference Performance.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "Llama 3.1 8B",
                "Llama 3.1 70B",
                "Llama 3.1 405B",
                "Llama 3.2 3B",
                "Mixtral 8x7B",
                "Qwen 2.5 72B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SELU Self-Learning Embodied MLLMs in Unknown Environments": {
        "filename": "SELU Self-Learning Embodied MLLMs in Unknown Environments.pdf",
        "analysis": {
            "benchmarks": [
                "AI2-THOR",
                "VirtualHome"
            ],
            "base_models": [
                "LLaVA",
                "Qwen-VL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BiosERC Integrating Biography Speakers Supported by LLMs for ERC Tasks": {
        "filename": "BiosERC Integrating Biography Speakers Supported by LLMs for ERC Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "IEMOCAP",
                "MELD",
                "EmoryNLP"
            ],
            "base_models": [
                "RoBERTa",
                "Llama-2-13b",
                "Llama-2-7b"
            ]
        }
    },
    "Whos the Best Detective LLMs vs MLs in Detecting Incoherent Fourth Grade Math Answers": {
        "filename": "Whos the Best Detective LLMs vs MLs in Detecting Incoherent Fourth Grade Math Answers.pdf",
        "analysis": {
            "benchmarks": [
                "ConectaIdeas 2017 dataset"
            ],
            "base_models": [
                "GPT-3",
                "BLOOM-large",
                "BLOOMz",
                "YouChat (based on GPT-3.5)",
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large Language Models": {
        "filename": "The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "IQ50",
                "RAVEN-S",
                "CCSE"
            ],
            "base_models": [
                "BLIP-2 (opt-2.7b, opt-6.7b, flan-t5-xl, flan-t5-xxl)",
                "IDEFICS (9b, 80b)",
                "Fuyu (8b)",
                "Qwen-VL",
                "InstructBLIP (vicuna-7b, vicuna-13b, flan-t5-xl, flan-t5-xxl)",
                "MMICL (vicuna-7b, vicuna-13b, Instructblip-T5-xl, Instructblip-T5-xxl)",
                "LLaVA (1.5-7b-hf, 1.5-13b-hf)",
                "GPT-4V",
                "Gemini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Plan-on-Graph Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs": {
        "filename": "Plan-on-Graph Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "CWQ",
                "WebQSP",
                "GrailQA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Extracting Self-Consistent Causal Insights from Users Feedback with LLMs and In-context Learning": {
        "filename": "Extracting Self-Consistent Causal Insights from Users Feedback with LLMs and In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Feedback Hub (custom dataset)"
            ],
            "base_models": [
                "GPT-3.5 Turbo"
            ]
        }
    },
    "Certified Deductive Reasoning with Language Models": {
        "filename": "Certified Deductive Reasoning with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "PrOntoQA",
                "ProofWriter",
                "Syllogism Validity",
                "ReClor",
                "LEGAL BENCH",
                "DeontiQA"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5 Turbo",
                "LLaMA 13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unifying Molecular and Textual Representations via Multi-task Language Modelling": {
        "filename": "Unifying Molecular and Textual Representations via Multi-task Language Modelling.pdf",
        "analysis": {
            "benchmarks": [
                "Pistachio dataset",
                "CheBI-20 dataset"
            ],
            "base_models": [
                "T5-small",
                "T5-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Customizing General-Purpose Foundation Models for Medical Report Generation": {
        "filename": "Customizing General-Purpose Foundation Models for Medical Report Generation.pdf",
        "analysis": {
            "benchmarks": [
                "ImageCLEFmedical Caption 2023 Caption Prediction Task"
            ],
            "base_models": [
                "EV A-ViT-g",
                "ChatGLM-6B"
            ]
        }
    },
    "Adapting Large Language Models for Content Moderation Pitfalls in Data Engineering and Supervised Fine-tuning": {
        "filename": "Adapting Large Language Models for Content Moderation Pitfalls in Data Engineering and Supervised Fine-tuning.pdf",
        "analysis": {
            "benchmarks": [
                "COLD",
                "HateSpeech"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Baichuan-7B-Chat",
                "Baichuan-13B-Chat"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "What is the best model Application-driven Evaluation for Large Language Models": {
        "filename": "What is the best model Application-driven Evaluation for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "A-Eval"
            ],
            "base_models": [
                "Qwen1.5-0.5B-Chat",
                "Qwen1.5-1.8B-Chat",
                "Qwen1.5-4B-Chat",
                "Qwen1.5-7B-Chat",
                "Qwen1.5-14B-Chat",
                "Qwen1.5-32B-Chat",
                "Qwen1.5-72B-Chat",
                "Qwen1.5-110B-Chat"
            ]
        }
    },
    "Writing in the Margins Better Inference Pattern for Long Context Retrieval": {
        "filename": "Writing in the Margins Better Inference Pattern for Long Context Retrieval.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "MultiHop-RAG",
                "SQuAD",
                "CWE"
            ],
            "base_models": [
                "Phi-3-small-128k-instruct",
                "Qwen2-7B-Instruct",
                "Meta-Llama-3.1-8B-Instruct",
                "Phi-3-medium-128k-Instruct",
                "Palmyra-4-Chat-128K",
                "Meta-Llama-3.1-70B-Instruct",
                "Qwen2-72B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mixture-of-Agents Enhances Large Language Model Capabilities": {
        "filename": "Mixture-of-Agents Enhances Large Language Model Capabilities.pdf",
        "analysis": {
            "benchmarks": [
                "AlpacaEval 2.0",
                "MT-Bench",
                "FLASK"
            ],
            "base_models": [
                "GPT-4",
                "Qwen1.5-110B-Chat",
                "Qwen1.5-72B-Chat",
                "WizardLM-8x22B",
                "LLaMA-3-70B-Instruct",
                "Mixtral-8x22B-v0.1",
                "dbrx-instruct"
            ]
        }
    },
    "Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld": {
        "filename": "Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld.pdf",
        "analysis": {
            "benchmarks": [
                "ALFWorld"
            ],
            "base_models": [
                "GPT-4V",
                "InstructBLIP"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Will GPT-4 Run DOOM": {
        "filename": "Will GPT-4 Run DOOM.pdf",
        "analysis": {
            "benchmarks": [
                "Doom (1993 first-person shooter)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4V"
            ]
        }
    },
    "Towards Agile Text Classifiers for Everyone": {
        "filename": "Towards Agile Text Classifiers for Everyone.pdf",
        "analysis": {
            "benchmarks": [
                "ParlAI Single Standard",
                "ParlAI Single Adversarial",
                "ParlAI Multi",
                "Bot Adversarial Dialogue (BAD-2 and BAD-4)",
                "Unhealthy Comment Corpus",
                "Neutral Responses (custom dataset)"
            ],
            "base_models": [
                "PaLM 62B",
                "T5 XXL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards a Holistic Evaluation of LLMs on Factual Knowledge Recall": {
        "filename": "Towards a Holistic Evaluation of LLMs on Factual Knowledge Recall.pdf",
        "analysis": {
            "benchmarks": [
                "FACT-BENCH"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "BLOOM-7B",
                "BLOOMZ-7B",
                "LLaMA-7B",
                "LLaMA-13B",
                "LLaMA-33B",
                "LLaMA-65B",
                "Vicuna-7B",
                "Vicuna-13B",
                "Vicuna-33B",
                "OpenLLaMA-7B",
                "OpenLLaMA-13B",
                "FLAN-T5-XXL (11B)",
                "T0++ (11B)",
                "UL2 (20B)",
                "FLAN-UL2 (20B)",
                "Falcon-7B",
                "Falcon-7B-instruct",
                "Falcon-40B",
                "Falcon-40B-instruct",
                "Falcon-180B",
                "Falcon-180B-chat",
                "MPT-7B",
                "MPT-7B-instruct",
                "MPT-30B",
                "MPT-30B-instruct",
                "Pythia-6.9B",
                "Pythia-12B",
                "Mistral-7B",
                "Mistral-7B-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Navigating LLM Ethics Advancements Challenges and Future Directions": {
        "filename": "Navigating LLM Ethics Advancements Challenges and Future Directions.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "LLaMA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring Large Language Models for Communication Games An Empirical Study on Werewolf": {
        "filename": "Exploring Large Language Models for Communication Games An Empirical Study on Werewolf.pdf",
        "analysis": {
            "benchmarks": [
                "Werewolf game"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo-0301)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CLMASP Coupling Large Language Models with Answer Set Programming for Robotic Task Planning": {
        "filename": "CLMASP Coupling Large Language Models with Answer Set Programming for Robotic Task Planning.pdf",
        "analysis": {
            "benchmarks": [
                "VirtualHome"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Model evaluation for extreme risks": {
        "filename": "Model evaluation for extreme risks.pdf",
        "analysis": {
            "benchmarks": [
                "Make-me-say game (custom dataset)"
            ],
            "base_models": [
                "GPT-4",
                "Claude"
            ]
        }
    },
    "Foveate Attribute and Rationalize Towards Physically Safe and Trustworthy AI": {
        "filename": "Foveate Attribute and Rationalize Towards Physically Safe and Trustworthy AI.pdf",
        "analysis": {
            "benchmarks": [
                "SAFETEXT"
            ],
            "base_models": [
                "GPT-3 (text-ada-001)",
                "GPT-3 (text-babbage-001)",
                "GPT-3 (text-curie-001)",
                "GPT-3 (text-davinci-002)",
                "GPT-3 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PURPLE Making a Large Language Model a Better SQL Writer": {
        "filename": "PURPLE Making a Large Language Model a Better SQL Writer.pdf",
        "analysis": {
            "benchmarks": [
                "Spider",
                "Spider-DK",
                "Spider-SYN",
                "Spider-Realistic"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Reduce Towards Improving Performance of Large Language Models on Structured Data": {
        "filename": "Learning to Reduce Towards Improving Performance of Large Language Models on Structured Data.pdf",
        "analysis": {
            "benchmarks": [
                "WikiTableQuestions",
                "Hybrid QA"
            ],
            "base_models": [
                "GPT-4",
                "Llama 2",
                "Vicuna",
                "FLAN-T5-Large"
            ]
        }
    },
    "Predicting Emergent Capabilities by Finetuning": {
        "filename": "Predicting Emergent Capabilities by Finetuning.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "GSM8K",
                "CommonsenseQA",
                "CoLA"
            ],
            "base_models": [
                "OpenLLaMA V1 (3B, 7B, 13B)",
                "LLaMA 2 (7B, 13B, 70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "DimonGen Diversified Generative Commonsense Reasoning for Explaining Concept Relationships": {
        "filename": "DimonGen Diversified Generative Commonsense Reasoning for Explaining Concept Relationships.pdf",
        "analysis": {
            "benchmarks": [
                "CommonGen",
                "DimonGen (custom dataset adapted from CommonGen)"
            ],
            "base_models": [
                "BART",
                "Roberta"
            ]
        }
    },
    "FaithEval Can Your Language Model Stay Faithful to Context Even If The Moon is Made of Marshmallows": {
        "filename": "FaithEval Can Your Language Model Stay Faithful to Context Even If The Moon is Made of Marshmallows.pdf",
        "analysis": {
            "benchmarks": [
                "FaithEval"
            ],
            "base_models": [
                "GPT-4o",
                "LLaMA-3-70B-Instruct",
                "Phi-3-mini-128k-instruct (3.8B)",
                "Phi-3-medium-128k-instruct (14B)",
                "Phi-3.5-mini-instruct (3.8B)",
                "LLaMA-3-8B-Instruct",
                "LLaMA-3.1-8B-Instruct",
                "LLaMA-3.1-70B-Instruct",
                "Mistral-7B-Instruct-v0.3",
                "Mistral-Nemo-Instruct-2407 (12B)",
                "Gemma-2-9B-it",
                "Gemma-2-27B-it",
                "GPT-3.5 Turbo",
                "GPT-4o-mini",
                "GPT-4 Turbo",
                "Command R (35B)",
                "Command R+ (104B)",
                "Claude 3.5 Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MILE A Mutation Testing Framework of In-Context Learning Systems": {
        "filename": "MILE A Mutation Testing Framework of In-Context Learning Systems.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "AGnews",
                "RTE",
                "MRPC",
                "QNLI"
            ],
            "base_models": [
                "Vicuna-7b",
                "Llama-2-chat-7b",
                "Falcon-7b-instruct"
            ]
        }
    },
    "Making Text Embedders Few-Shot Learners": {
        "filename": "Making Text Embedders Few-Shot Learners.pdf",
        "analysis": {
            "benchmarks": [
                "MTEB",
                "AIR-Bench"
            ],
            "base_models": [
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning to Learn Faster from Human Feedback with Language Model Predictive Control": {
        "filename": "Learning to Learn Faster from Human Feedback with Language Model Predictive Control.pdf",
        "analysis": {
            "benchmarks": [
                "custom dataset of 78 tasks across 5 robot embodiments"
            ],
            "base_models": [
                "PaLM 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CodePlan Repository-level Coding using LLMs and Planning": {
        "filename": "CodePlan Repository-level Coding using LLMs and Planning.pdf",
        "analysis": {
            "benchmarks": [
                "Internal Repositories (Int-1 and Int-2)",
                "External Repositories (Public GitHub)"
            ],
            "base_models": [
                "gpt-4-32k"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating ChatGPT as a Recommender System A Rigorous Approach": {
        "filename": "Evaluating ChatGPT as a Recommender System A Rigorous Approach.pdf",
        "analysis": {
            "benchmarks": [
                "Facebook Books",
                "MovieLens",
                "Last.FM"
            ],
            "base_models": [
                "ChatGPT-3.5",
                "ChatGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Coalitions of Large Language Models Increase the Robustness of AI Agents": {
        "filename": "Coalitions of Large Language Models Increase the Robustness of AI Agents.pdf",
        "analysis": {
            "benchmarks": [
                "ToolAlpaca"
            ],
            "base_models": [
                "ToolAlpaca-7B",
                "ToolAlpaca-13B",
                "Vicuna-13B",
                "Mistral",
                "Mixtral",
                "Llama 2 70B Chat",
                "Codellama 34B",
                "Flan UL2 20B"
            ]
        }
    },
    "Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy": {
        "filename": "Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy.pdf",
        "analysis": {
            "benchmarks": [
                "HotPotQA",
                "2WikiMultiHopQA",
                "MuSiQue",
                "Bamboogle",
                "Feverous",
                "StrategyQA"
            ],
            "base_models": [
                "InstructGPT (text-davinci-003)",
                "Llama-2-13B",
                "Llama-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Neural networks that overcome classic challenges through practice": {
        "filename": "Neural networks that overcome classic challenges through practice.pdf",
        "analysis": {
            "benchmarks": [
                "Omniglot",
                "Mini-ImageNet"
            ],
            "base_models": [
                "Transformer",
                "RNN",
                "LSTM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SeaEval for Multilingual Foundation Models From Cross-Lingual Alignment to Cultural Reasoning": {
        "filename": "SeaEval for Multilingual Foundation Models From Cross-Lingual Alignment to Cultural Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "SeaEval",
                "GLUE",
                "MMLU",
                "C-Eval",
                "CMMLU",
                "ZBench",
                "Cross-MMLU",
                "Cross-LogiQA",
                "SG-Eval",
                "US-Eval",
                "CN-Eval",
                "PH-Eval",
                "Singlish2English"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "LLaMA-2-7B",
                "LLaMA-2-13B",
                "LLaMA-2-70B",
                "Baichuan-2-7B",
                "Baichuan-2-13B",
                "BLOOMZ"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Efficient and Explainable Hate Speech Detection via Model Distillation": {
        "filename": "Towards Efficient and Explainable Hate Speech Detection via Model Distillation.pdf",
        "analysis": {
            "benchmarks": [
                "MiniMetaHate Eval"
            ],
            "base_models": [
                "Llama-3-70B-Instruct",
                "Llama-3-8B-Instruct"
            ]
        }
    },
    "DeAL Decoding-time Alignment for Large Language Models": {
        "filename": "DeAL Decoding-time Alignment for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "CommonGen",
                "XSUM",
                "HH-RLHF",
                "HarmfulQ"
            ],
            "base_models": [
                "Falcon-7B-instruct",
                "MPT-7B-instruct",
                "Dolly-v2-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Refined Direct Preference Optimization with Synthetic Data for Behavioral Alignment of LLMs": {
        "filename": "Refined Direct Preference Optimization with Synthetic Data for Behavioral Alignment of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "Harmful Behaviors",
                "truthy-dpo-v0.1",
                "SycophancyEval"
            ],
            "base_models": [
                "Mixtral-8x7B-Instruct",
                "OpenHermes-2.5-Mistral 7B",
                "Zephyr 7B",
                "SOLAR-10.7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generalized Planning in PDDL Domains with Pretrained Large Language Models": {
        "filename": "Generalized Planning in PDDL Domains with Pretrained Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Delivery",
                "Forest",
                "Gripper",
                "Miconic",
                "Ferry",
                "Spanner",
                "Heavy"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Data-to-text Generation for Severely Under-Resourced Languages with GPT-35 A Bit of Help Needed from Google Translate WebNLG 2023": {
        "filename": "Data-to-text Generation for Severely Under-Resourced Languages with GPT-35 A Bit of Help Needed from Google Translate WebNLG 2023.pdf",
        "analysis": {
            "benchmarks": [
                "WebNLG 2023"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)",
                "GPT-4"
            ]
        }
    },
    "Text2BIM Generating Building Models Using a Large Language Model-based Multi-Agent Framework": {
        "filename": "Text2BIM Generating Building Models Using a Large Language Model-based Multi-Agent Framework.pdf",
        "analysis": {
            "benchmarks": [
                "custom test prompts for building models"
            ],
            "base_models": [
                "GPT-4o",
                "Mistral-Large-2",
                "Gemini-1.5-Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EffiQA Efficient Question-Answering with Strategic Multi-Model Collaboration on Knowledge Graphs": {
        "filename": "EffiQA Efficient Question-Answering with Strategic Multi-Model Collaboration on Knowledge Graphs.pdf",
        "analysis": {
            "benchmarks": [
                "Complex Web Questions (CWQ)",
                "WebQuestionSP (WebQSP)",
                "GrailQA",
                "QALD10-en",
                "Simple Questions"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Tachikuma Understading Complex Interactions with Multi-Character and Novel Objects by Large Language Models": {
        "filename": "Tachikuma Understading Complex Interactions with Multi-Character and Novel Objects by Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Tachikuma"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ]
        }
    },
    "Can LLMs Express Their Uncertainty An Empirical Evaluation of Confidence Elicitation in LLMs": {
        "filename": "Can LLMs Express Their Uncertainty An Empirical Evaluation of Confidence Elicitation in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "Date Understanding",
                "Object Counting",
                "StrategyQA",
                "Sports Understanding",
                "Professional Law",
                "Business Ethics"
            ],
            "base_models": [
                "GPT-3 (175B)",
                "GPT-3.5",
                "GPT-4",
                "Vicuna (13B)",
                "LLaMA 2 (70B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ReGenesis LLMs can Grow into Reasoning Generalists via Self-Improvement": {
        "filename": "ReGenesis LLMs can Grow into Reasoning Generalists via Self-Improvement.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "NumGLUE",
                "ReClor",
                "ARC-c",
                "StrategyQA",
                "ASDIV",
                "SVAMP",
                "AQUA-RAT",
                "BIG-Bench Hard (BBH)",
                "Adversarial NLI (ANLI-A2 and ANLI-A3)",
                "OpenBookQA"
            ],
            "base_models": [
                "Mistral-7B-Instruct-v0.3",
                "Meta-Llama-3-8B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Measuring Progress on Scalable Oversight for Large Language Models": {
        "filename": "Measuring Progress on Scalable Oversight for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MMLU",
                "time-limited QuALITY"
            ],
            "base_models": [
                "52B-parameter language model fine-tuned for dialog (Bai et al., 2022)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT-in-the-Loop Adaptive Decision-Making for Multiagent Systems": {
        "filename": "GPT-in-the-Loop Adaptive Decision-Making for Multiagent Systems.pdf",
        "analysis": {
            "benchmarks": [
                "Smart Streetlights IoT application"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Automated Statistical Model Discovery with Language Models": {
        "filename": "Automated Statistical Model Discovery with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Dugongs dataset",
                "Stan PosteriorDB datasets (e.g., eight schools, surgical, peregrine)"
            ],
            "base_models": [
                "GPT-4 V (gpt4-11-06-preview)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SPORTU A Comprehensive Sports Understanding Benchmark for Multimodal Large Language Models": {
        "filename": "SPORTU A Comprehensive Sports Understanding Benchmark for Multimodal Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SPORTU-text",
                "SPORTU-video"
            ],
            "base_models": [
                "GPT-4o",
                "Claude-3.5-Sonnet",
                "LLaMA-3.1",
                "Gemini 1.5 Pro",
                "Qwen2-VL-72B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Is Factuality Enhancement a Free Lunch For LLMs Better Factuality Can Lead to Worse Context-Faithfulness": {
        "filename": "Is Factuality Enhancement a Free Lunch For LLMs Better Factuality Can Lead to Worse Context-Faithfulness.pdf",
        "analysis": {
            "benchmarks": [
                "TruthfulQA",
                "MQ UAKE"
            ],
            "base_models": [
                "LLAMA2-7B-CHAT",
                "LLAMA2-13B-CHAT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "RealTCD Temporal Causal Discovery from Interventional Data with Large Language Model": {
        "filename": "RealTCD Temporal Causal Discovery from Interventional Data with Large Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "simulation datasets",
                "real-world application scenario"
            ],
            "base_models": [
                "Large Language Models (LLMs)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Perceive Reflect and Plan Designing LLM Agent for Goal-Directed City Navigation without Instructions": {
        "filename": "Perceive Reflect and Plan Designing LLM Agent for Goal-Directed City Navigation without Instructions.pdf",
        "analysis": {
            "benchmarks": [
                "Beijing CBD dataset",
                "Shanghai CBD dataset",
                "New York CBD dataset",
                "Paris CBD dataset"
            ],
            "base_models": [
                "LLaVA-7B",
                "LLaMA3-8B",
                "GPT-4-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automated Red Teaming with GOAT the Generative Offensive Agent Tester": {
        "filename": "Automated Red Teaming with GOAT the Generative Offensive Agent Tester.pdf",
        "analysis": {
            "benchmarks": [
                "JailbreakBench"
            ],
            "base_models": [
                "Llama 3.1 8B",
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generative Adversarial Reviews When LLMs Become the Critic": {
        "filename": "Generative Adversarial Reviews When LLMs Become the Critic.pdf",
        "analysis": {
            "benchmarks": [
                "ICLR 2023",
                "ICLR 2022",
                "NeurIPS 2023"
            ],
            "base_models": [
                "GPT-4o-mini",
                "GPT-4o",
                "Llama-3.1 (8b)",
                "Llama-3.1 (70b)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Just Tell Me Prompt Engineering in Business Process Management": {
        "filename": "Just Tell Me Prompt Engineering in Business Process Management.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3"
            ]
        }
    },
    "Towards explainable traffic flow prediction with large language models": {
        "filename": "Towards explainable traffic flow prediction with large language models.pdf",
        "analysis": {
            "benchmarks": [
                "CATraffic",
                "TaxiBJ"
            ],
            "base_models": [
                "Llama2-7B-chat",
                "GPT-3.5-turbo",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Deliberate then Generate Enhanced Prompting Framework for Text Generation": {
        "filename": "Deliberate then Generate Enhanced Prompting Framework for Text Generation.pdf",
        "analysis": {
            "benchmarks": [
                "CNN/DailyMail",
                "Gigaword",
                "SamSum",
                "DialogSum",
                "Asset",
                "Wiki-auto",
                "GYAFC (Entertainment & Music, Family & Relationships)",
                "Amazon",
                "Yelp",
                "Quora Question Pairs (QQP)",
                "CommonGen",
                "WMT Testsets (DE-EN, ZH-EN, CS-EN, RU-EN, JA-EN, UK-EN, IS-EN, HA-EN)"
            ],
            "base_models": [
                "GPT-3.5 (text-davinci-003)",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoTDet Affordance Knowledge Prompting for Task Driven Object Detection": {
        "filename": "CoTDet Affordance Knowledge Prompting for Task Driven Object Detection.pdf",
        "analysis": {
            "benchmarks": [
                "COCO-Tasks dataset"
            ],
            "base_models": [
                "GPT-3",
                "ChatGPT",
                "RoBERTa",
                "Deformable-DETR",
                "ResNet-101"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can large language models explore in-context": {
        "filename": "Can large language models explore in-context.pdf",
        "analysis": {
            "benchmarks": [
                "multi-armed bandit environments (custom synthetic datasets)"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Investigating Prompting Techniques for Zero- and Few-Shot Visual Question Answering": {
        "filename": "Investigating Prompting Techniques for Zero- and Few-Shot Visual Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "VQAv2",
                "Visual7w",
                "GQA",
                "OKVQA",
                "AOKVQA",
                "Winoground-VQA"
            ],
            "base_models": [
                "BLIP2 (with OPT 2.7B and 6.7B, Flan T5 XL and XXL)",
                "OpenFlamingo (4B)",
                "LLaVa (with Vicuna 13B)",
                "Kosmos2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On the Hardness of Faithful Chain-of-Thought Reasoning in Large Language Models": {
        "filename": "On the Hardness of Faithful Chain-of-Thought Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AQUA",
                "LOGIQA",
                "TRUTHFUL QA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-TURBO",
                "LLAMA-3-8B-INSTRUCT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CRAFT Customizing LLMs by Creating and Retrieving from Specialized Toolsets": {
        "filename": "CRAFT Customizing LLMs by Creating and Retrieving from Specialized Toolsets.pdf",
        "analysis": {
            "benchmarks": [
                "GQA",
                "OK-VQA",
                "A-OKVQA",
                "TabMWP",
                "MATH (algebra subset)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ExpLLM Towards Chain of Thought for Facial Expression Recognition": {
        "filename": "ExpLLM Towards Chain of Thought for Facial Expression Recognition.pdf",
        "analysis": {
            "benchmarks": [
                "RAF-DB",
                "AffectNet"
            ],
            "base_models": [
                "GPT-4o",
                "LLaVA (with ViT-L/14 visual encoder and Vicuna-7B language model)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation": {
        "filename": "Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation.pdf",
        "analysis": {
            "benchmarks": [
                "AGNews",
                "DBPedia",
                "TREC",
                "MIT Movies trivia10k13 (MIT-G and MIT-D)"
            ],
            "base_models": [
                "GPT-3 Babbage",
                "GPT-3 Ada",
                "GPT-3 Curie",
                "GPT-3 Davinci"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MELODI Exploring Memory Compression for Long Contexts": {
        "filename": "MELODI Exploring Memory Compression for Long Contexts.pdf",
        "analysis": {
            "benchmarks": [
                "PG-19",
                "arXiv Math",
                "C4 (4K+)"
            ],
            "base_models": [
                "Memorizing Transformer",
                "Transformer XL",
                "Block Recurrent Transformer"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AMCEN An Attention Masking-based Contrastive Event Network for Two-stage Temporal Knowledge Graph Reasoning": {
        "filename": "AMCEN An Attention Masking-based Contrastive Event Network for Two-stage Temporal Knowledge Graph Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GDELT",
                "ICEWS18",
                "WIKI",
                "YAGO"
            ],
            "base_models": [
                "CompGCN"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "In-Context Ensemble Learning from Pseudo Labels Improves Video-Language Models for Low-Level Workflow Understanding": {
        "filename": "In-Context Ensemble Learning from Pseudo Labels Improves Video-Language Models for Low-Level Workflow Understanding.pdf",
        "analysis": {
            "benchmarks": [
                "WONDERBREAD benchmark (Gold Demo subset)"
            ],
            "base_models": [
                "GPT-4o-mini",
                "Gemini-1.5-flash",
                "Phi-3.5"
            ]
        }
    },
    "Fleet of Agents Coordinated Problem Solving with Large Language Models using Genetic Particle Filtering": {
        "filename": "Fleet of Agents Coordinated Problem Solving with Large Language Models using Genetic Particle Filtering.pdf",
        "analysis": {
            "benchmarks": [
                "Game of 24",
                "Mini-Crosswords"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "LLMs4OL Large Language Models for Ontology Learning": {
        "filename": "LLMs4OL Large Language Models for Ontology Learning.pdf",
        "analysis": {
            "benchmarks": [
                "WordNet",
                "GeoNames",
                "UMLS",
                "schema.org"
            ],
            "base_models": [
                "BERT-Large (340M)",
                "BART-Large (400M)",
                "Flan-T5-Large (780M)",
                "Flan-T5-XL (3B)",
                "BLOOM-1b7 (1.7B)",
                "BLOOM-3b (3B)",
                "GPT-3 (175B)",
                "GPT-3.5 (174B)",
                "LLaMA (7B)",
                "GPT-4 (>1T)",
                "PubMedBERT (based on BERT)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration": {
        "filename": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "Overcooked-AI",
                "DV-RoCoBench"
            ],
            "base_models": [
                "GPT-4-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Effect of Sampling Temperature on Problem Solving in Large Language Models": {
        "filename": "The Effect of Sampling Temperature on Problem Solving in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "ARC Challenge Test",
                "AQUA-RAT",
                "Hellaswag Val",
                "LogiQA (English)",
                "LSAT-AR",
                "LSAT-LR",
                "LSAT-RC",
                "MedMCQA Valid",
                "SAT-English",
                "SAT-Math"
            ],
            "base_models": [
                "Claude 3 Opus",
                "Command R+",
                "Gemini 1.0 Pro",
                "Gemini 1.5 Pro (Preview)",
                "GPT-3.5 Turbo",
                "GPT-4",
                "Llama 2 7B Chat",
                "Llama 2 70B Chat",
                "Mistral Large"
            ]
        }
    },
    "Rethinking Interpretability in the Era of Large Language Models": {
        "filename": "Rethinking Interpretability in the Era of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "PaLM",
                "LLaMA",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fine-tuning Aligned Language Models Compromises Safety Even When Users Do Not Intend To": {
        "filename": "Fine-tuning Aligned Language Models Compromises Safety Even When Users Do Not Intend To.pdf",
        "analysis": {
            "benchmarks": [
                "Alpaca",
                "Dolly",
                "LLaVA-Visual-Instruct"
            ],
            "base_models": [
                "Llama-2-7b-Chat",
                "GPT-3.5 Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Machine Psychology of Cooperation Can GPT models operationalise prompts for altruism cooperation competitiveness and selfishness in economic games": {
        "filename": "The Machine Psychology of Cooperation Can GPT models operationalise prompts for altruism cooperation competitiveness and selfishness in economic games.pdf",
        "analysis": {
            "benchmarks": [
                "repeated Prisoners Dilemma",
                "one-shot Dictator Game"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Leveraging GPT-4 for Food Effect Summarization to Enhance Product-Specific Guidance Development via Iterative Prompting": {
        "filename": "Leveraging GPT-4 for Food Effect Summarization to Enhance Product-Specific Guidance Development via Iterative Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "FDA NDA review documents"
            ],
            "base_models": [
                "GPT-4",
                "ChatGPT (based on GPT-3 with 175 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of the Evolution of Language Model-Based Dialogue Systems": {
        "filename": "A Survey of the Evolution of Language Model-Based Dialogue Systems.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5 (175B)",
                "GPT-4",
                "LLaMA (7B/13B/33B/65B)",
                "LLaMA2 (7B/13B/34B/70B)",
                "GLM (6B/12B)",
                "ChatGLM",
                "ChatGLM2",
                "ChatGLM3",
                "Baichuan (7B/13B/53B)",
                "Baichuan2 (7B/13B)",
                "Qwen (7B/14B)",
                "InternLM (7B/20B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Graph of Thoughts Solving Elaborate Problems with Large Language Models": {
        "filename": "Graph of Thoughts Solving Elaborate Problems with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "sorting",
                "keyword counting",
                "set operations",
                "document merging"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Thought Propagation An Analogical Approach to Complex Reasoning with Large Language Models": {
        "filename": "Thought Propagation An Analogical Approach to Complex Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Shortest-path Reasoning",
                "Creative Writing",
                "LLM-Agent Planning"
            ],
            "base_models": [
                "PaLM-2",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Learning Elementary Cellular Automata with Transformers": {
        "filename": "Learning Elementary Cellular Automata with Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset generated with CellPyLib"
            ],
            "base_models": [
                "Transformer encoder (4 layers, 8 heads, dmodel = 512)"
            ]
        }
    },
    "SPT Semi-Parametric Prompt Tuning for Multitask Prompted Learning": {
        "filename": "SPT Semi-Parametric Prompt Tuning for Multitask Prompted Learning.pdf",
        "analysis": {
            "benchmarks": [
                "CB",
                "RTE",
                "WinoGrande XL",
                "WSC",
                "WiC",
                "COPA",
                "Hellaswag",
                "BoolQ",
                "MultiRC",
                "SuperGLUE",
                "GLUE"
            ],
            "base_models": [
                "T5-small",
                "T5-base",
                "T5-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models Generate Geospatial Code": {
        "filename": "Can Large Language Models Generate Geospatial Code.pdf",
        "analysis": {
            "benchmarks": [
                "GeoCode-Bench"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3-Opus",
                "ERNIE-4.0 (8B)",
                "LLaMA3 (8B, 70B)",
                "PaLM (540B)",
                "BLOOM (176B)",
                "CodeGemma (7B)",
                "StarCoder2 (15B)",
                "CodeQwen (14B)",
                "WizardCoder (15B)",
                "CodeLlama (7B, 13B, 34B)",
                "OctoCoder (15.5B)",
                "CodeGeeX2 (6B)",
                "Codex (12B)",
                "AlphaCode (1.1B)",
                "CodeT5+ (770M, 2B, 16B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Chain-of-Questions Training with Latent Answers for Robust Multistep Question Answering": {
        "filename": "Chain-of-Questions Training with Latent Answers for Robust Multistep Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "DROP",
                "HOTPOT QA",
                "DROP contrast set",
                "HOTPOT QA adversarial set"
            ],
            "base_models": [
                "T5-Large (770M parameters)",
                "Longformer",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Investigating the Efficacy of Large Language Models in Reflective Assessment Methods through Chain of Thought Prompting": {
        "filename": "Investigating the Efficacy of Large Language Models in Reflective Assessment Methods through Chain of Thought Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "Reflective essays from third-year medical students at the University of Pretoria"
            ],
            "base_models": [
                "GPT-3 (175 billion parameters)",
                "Llama-7b (7 billion parameters)",
                "Llama-30b (30 billion parameters)",
                "ChatGPT (based on GPT-3.5)",
                "Bard (137 billion parameters)"
            ]
        }
    },
    "Delving into Multi-modal Multi-task Foundation Models for Road Scene Understanding From Learning Paradigm Perspectives": {
        "filename": "Delving into Multi-modal Multi-task Foundation Models for Road Scene Understanding From Learning Paradigm Perspectives.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Lets Think Dot by Dot Hidden Computation in Transformer Language Models": {
        "filename": "Lets Think Dot by Dot Hidden Computation in Transformer Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "3SUM",
                "2SUM-Transform"
            ],
            "base_models": [
                "Llama 34M"
            ]
        }
    },
    "Guiding ChatGPT to Generate Salient Domain Summaries": {
        "filename": "Guiding ChatGPT to Generate Salient Domain Summaries.pdf",
        "analysis": {
            "benchmarks": [
                "Gigaword",
                "BigPatent",
                "CNN/DM",
                "SAMsum",
                "XSum"
            ],
            "base_models": [
                "ChatGPT (gpt-3.5-turbo)",
                "Sentence-BERT (S-BERT)"
            ]
        }
    },
    "In-Context Principle Learning from Mistakes": {
        "filename": "In-Context Principle Learning from Mistakes.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "DROP",
                "Big-Bench Hard",
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "GPT-4-turbo",
                "Claude-2.1"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generative Calibration for In-context Learning": {
        "filename": "Generative Calibration for In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "SST2",
                "SST5",
                "CR",
                "MR",
                "SUBJ",
                "AGNews",
                "DBPedia",
                "TREC",
                "CB",
                "RTE",
                "QQP",
                "SNLI"
            ],
            "base_models": [
                "GPT2-Large (774M)",
                "GPT2-XL (1.5B)",
                "GPT-NEO (2.7B)",
                "GPT-J (6B)",
                "GPT-NEOX (20B)",
                "OPT (13B)",
                "OPT (30B)",
                "LLaMA (13B)",
                "LLaMA (33B)",
                "RWKV (3B)",
                "RWKV (7B)",
                "RWKV (14B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instruction Tuned Models are Quick Learners": {
        "filename": "Instruction Tuned Models are Quick Learners.pdf",
        "analysis": {
            "benchmarks": [
                "Super Natural Instructions (SuperNI)"
            ],
            "base_models": [
                "Tk-Instruct 3B",
                "T5-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Retroformer Retrospective Large Language Agents with Policy Gradient Optimization": {
        "filename": "Retroformer Retrospective Large Language Agents with Policy Gradient Optimization.pdf",
        "analysis": {
            "benchmarks": [
                "HotPotQA",
                "AlfWorld",
                "WebShop"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)",
                "GPT-4",
                "LongChat (based on Llama-7b)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Eagle Efficient Training-Free Router for Multi-LLM Inference": {
        "filename": "Eagle Efficient Training-Free Router for Multi-LLM Inference.pdf",
        "analysis": {
            "benchmarks": [
                "RouterBench",
                "MMLU",
                "Hellaswag",
                "GSM8K",
                "ARC Challenge",
                "Winogrande",
                "MBPP",
                "MT-Bench"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude",
                "Mistral",
                "Llama",
                "Llama2",
                "stella_en_1.5B_v5"
            ]
        }
    },
    "Situational Instructions Database Task Guidance in Dynamic Environments": {
        "filename": "Situational Instructions Database Task Guidance in Dynamic Environments.pdf",
        "analysis": {
            "benchmarks": [
                "3D Semantic Scene Graphs (3DSSG)"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA",
                "Mixtral",
                "GPT-4V",
                "GPT-3.5-Turbo"
            ]
        }
    },
    "The Role of Deductive and Inductive Reasoning in Large Language Models": {
        "filename": "The Role of Deductive and Inductive Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AIW",
                "MR-GSM8K",
                "Holiday Puzzle"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 Turbo",
                "Claude 3.5 Sonnet"
            ]
        }
    },
    "Tree of Attacks Jailbreaking Black-Box LLMs Automatically": {
        "filename": "Tree of Attacks Jailbreaking Black-Box LLMs Automatically.pdf",
        "analysis": {
            "benchmarks": [
                "AdvBench Subset",
                "New dataset (generated by querying WizardVicuna30B-Uncensored)"
            ],
            "base_models": [
                "GPT4-Turbo",
                "GPT4o",
                "GPT3.5-Turbo",
                "PaLM-2",
                "Gemini-Pro",
                "Vicuna-13B-v1.5",
                "Llama-2-Chat-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Threat Modelling and Risk Analysis for Large Language Model LLM-Powered Applications": {
        "filename": "Threat Modelling and Risk Analysis for Large Language Model LLM-Powered Applications.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "PaLM 2"
            ]
        }
    },
    "Co-occurrence is not Factual Association in Language Models": {
        "filename": "Co-occurrence is not Factual Association in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Country-city-animals",
                "MQuAKE-T",
                "2WikiMultiHopQA"
            ],
            "base_models": [
                "LLaMA 3 8B",
                "LLaMA 3 70B",
                "Gemma 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Adaptive Intellect Unleashed The Feasibility of Knowledge Transfer in Large Language Models": {
        "filename": "Adaptive Intellect Unleashed The Feasibility of Knowledge Transfer in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Kotlin APIs from official documentation released after 2022"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Graph Learning Improve Planning in LLM-based Agents": {
        "filename": "Can Graph Learning Improve Planning in LLM-based Agents.pdf",
        "analysis": {
            "benchmarks": [
                "HuggingFace tasks",
                "Multimedia tasks",
                "Daily Life API tasks",
                "TMDB API tasks",
                "UltraTool"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4-turbo",
                "CodeLlama-13B",
                "Mistral-7B",
                "Vicuna-13B",
                "Baichuan2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SCoTT Wireless-Aware Path Planning with Vision Language Models and Strategic Chains-of-Thought": {
        "filename": "SCoTT Wireless-Aware Path Planning with Vision Language Models and Strategic Chains-of-Thought.pdf",
        "analysis": {
            "benchmarks": [
                "DT dataset from [6]"
            ],
            "base_models": [
                "GPT-4o",
                "Pixtral 12B"
            ]
        }
    },
    "Tab-CoT Zero-shot Tabular Chain of Thought": {
        "filename": "Tab-CoT Zero-shot Tabular Chain of Thought.pdf",
        "analysis": {
            "benchmarks": [
                "SingleEq",
                "AddSub",
                "MultiArith",
                "GSM8K",
                "AQUA",
                "SVAMP",
                "Coin Flip",
                "Last Letter",
                "CommonsenseQA",
                "StrategyQA"
            ],
            "base_models": [
                "code-davinci-002 (175B)",
                "text-davinci-002 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CHARD Clinical Health-Aware Reasoning Across Dimensions for Text Generation Models": {
        "filename": "CHARD Clinical Health-Aware Reasoning Across Dimensions for Text Generation Models.pdf",
        "analysis": {
            "benchmarks": [
                "CHARDat"
            ],
            "base_models": [
                "BART",
                "T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generative AI as Economic Agents": {
        "filename": "Generative AI as Economic Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Benchmarking Large Language Models for Molecule Prediction Tasks": {
        "filename": "Benchmarking Large Language Models for Molecule Prediction Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "ogbg-molbace",
                "ogbg-molbbbp",
                "ogbg-molhiv",
                "ogbg-molesol",
                "ogbg-molfreesolv",
                "ogbg-mollipo"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Llama-2-7b",
                "Llama-2-13b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification": {
        "filename": "Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification.pdf",
        "analysis": {
            "benchmarks": [
                "MATH",
                "GSM8K",
                "MMLU-Math"
            ],
            "base_models": [
                "GPT-4 Code Interpreter"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Uncertainty-Aware Language Agent": {
        "filename": "Towards Uncertainty-Aware Language Agent.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "StrategyQA",
                "MMLU"
            ],
            "base_models": [
                "ChatGPT",
                "LLaMA2-70B",
                "LLaMA2-13B",
                "LLaMA2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instruction Makes a Difference": {
        "filename": "Instruction Makes a Difference.pdf",
        "analysis": {
            "benchmarks": [
                "DocVQA",
                "TextVQA",
                "iDocVQA",
                "Polling-based Object Probing Evaluation (POPE)"
            ],
            "base_models": [
                "LLaVA-1.5-7B",
                "LLaMA-2"
            ]
        }
    },
    "HeLM Highlighted Evidence augmented Language Model for Enhanced Table-to-Text Generation": {
        "filename": "HeLM Highlighted Evidence augmented Language Model for Enhanced Table-to-Text Generation.pdf",
        "analysis": {
            "benchmarks": [
                "FetaQA",
                "QTSumm"
            ],
            "base_models": [
                "LLaMA2-13B"
            ]
        }
    },
    "Edge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models": {
        "filename": "Edge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Guangzhou International Campus of South China University of Technology dataset"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-Adapter 7B",
                "LLaMA-2"
            ]
        }
    },
    "Large Language Models as Data Preprocessors": {
        "filename": "Large Language Models as Data Preprocessors.pdf",
        "analysis": {
            "benchmarks": [
                "Adult",
                "Hospital",
                "Buy",
                "Restaurant",
                "Synthea",
                "Amazon-Google",
                "Beer",
                "DBLP-ACM",
                "DBLP-Google",
                "Fodors-Zagat",
                "iTunes-Amazon",
                "Walmart-Amazon"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5",
                "GPT-4",
                "GPT-4o"
            ]
        }
    },
    "Are Large Language Models Reliable Argument Quality Annotators": {
        "filename": "Are Large Language Models Reliable Argument Quality Annotators.pdf",
        "analysis": {
            "benchmarks": [
                "Dagstuhl-15512-ArgQuality corpus",
                "UKPConvArgRank dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo-0613",
                "PaLM 2 (text-bison@001)"
            ]
        }
    },
    "Quantifying Uncertainty in Natural Language Explanations of Large Language Models": {
        "filename": "Quantifying Uncertainty in Natural Language Explanations of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "ASDiv",
                "StrategyQA",
                "Sports Understanding"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "InstructGPT"
            ]
        }
    },
    "Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts": {
        "filename": "Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts.pdf",
        "analysis": {
            "benchmarks": [
                "CLEVR-Robot"
            ],
            "base_models": [
                "Llama-2-7b-chat-hf"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MathScale Scaling Instruction Tuning for Mathematical Reasoning": {
        "filename": "MathScale Scaling Instruction Tuning for Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MWPBENCH",
                "GSM8K",
                "MATH",
                "TAL-SCQ",
                "Math23k",
                "Ape210k",
                "GaokaoBench-Math",
                "AGIEval",
                "CollegeMath",
                "Fresh-GaokaoMath-2023"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA-2 7B",
                "LLaMA-2 13B",
                "Mistral 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt-Based Editing for Text Style Transfer": {
        "filename": "Prompt-Based Editing for Text Style Transfer.pdf",
        "analysis": {
            "benchmarks": [
                "YELP",
                "AMAZON",
                "GYAFC"
            ],
            "base_models": [
                "GPT-J-6B"
            ]
        }
    },
    "MaintAGTSim2Real-Guided Multimodal Large Model for Intelligent Maintenance with Chain-of-Thought Reasoning": {
        "filename": "MaintAGTSim2Real-Guided Multimodal Large Model for Intelligent Maintenance with Chain-of-Thought Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "ISO Level III vibration analyst questions"
            ],
            "base_models": [
                "GLM4 (9B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Contrastive Distillation Is a Sample-Efficient Self-Supervised Loss Policy for Transfer Learning": {
        "filename": "Contrastive Distillation Is a Sample-Efficient Self-Supervised Loss Policy for Transfer Learning.pdf",
        "analysis": {
            "benchmarks": [
                "bAbI",
                "Com2Sense"
            ],
            "base_models": [
                "T5-3B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SED Self-Evaluation Decoding Enhances Large Language Models for Better Generation": {
        "filename": "SED Self-Evaluation Decoding Enhances Large Language Models for Better Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "XieZhi",
                "GSM8K"
            ],
            "base_models": [
                "falcon-7b-instruct",
                "llama2-7b-chat-hf",
                "gemma-7b-it"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Effects of a Prompt Engineering Intervention on Undergraduate Students AI Self-Efficacy AI Knowledge and Prompt Engineering Ability A Mixed Methods Study": {
        "filename": "Effects of a Prompt Engineering Intervention on Undergraduate Students AI Self-Efficacy AI Knowledge and Prompt Engineering Ability A Mixed Methods Study.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Revisiting the Reliability of Psychological Scales on Large Language Models": {
        "filename": "Revisiting the Reliability of Psychological Scales on Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Big Five Inventory (BFI)"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4-Turbo",
                "Gemini-1.0-Pro",
                "LLaMA-3.1-8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Domain-specific ReAct for physics-integrated iterative modeling A case study of LLM agents for gas path analysis of gas turbines": {
        "filename": "Domain-specific ReAct for physics-integrated iterative modeling A case study of LLM agents for gas path analysis of gas turbines.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "LLama3-8B",
                "LLama3-70B",
                "Qwen1.5-32B",
                "Qwen1.5-72B",
                "GPT3.5",
                "GPT4o",
                "GLM4"
            ]
        }
    },
    "Mini-DALLE3 Interactive Text to Image by Prompting Large Language Models": {
        "filename": "Mini-DALLE3 Interactive Text to Image by Prompting Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "LLAMA",
                "Baichuan",
                "InternLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Gender Bias in Machine Translation and The Era of Large Language Models": {
        "filename": "Gender Bias in Machine Translation and The Era of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "gENder-IT"
            ],
            "base_models": [
                "ChatGPT (based on GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MECD Unlocking Multi-Event Causal Discovery in Video Reasoning": {
        "filename": "MECD Unlocking Multi-Event Causal Discovery in Video Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "MECD dataset"
            ],
            "base_models": [
                "GPT-4",
                "VideoLLaVA"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LPML LLM-Prompting Markup Language for Mathematical Reasoning": {
        "filename": "LPML LLM-Prompting Markup Language for Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-Turbo)"
            ]
        }
    },
    "Continual Learning of Large Language Models A Comprehensive Survey": {
        "filename": "Continual Learning of Large Language Models A Comprehensive Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2",
                "RoBERTa",
                "BERT",
                "Llama",
                "Llama2",
                "T5",
                "StarCoder",
                "Code Llama",
                "InternLM",
                "Mistral",
                "Qwen-Chat",
                "ChatGLM",
                "DeepSeek-LLM",
                "GAL",
                "BLOOM",
                "Vicuna",
                "LlaVa",
                "GLM2",
                "Baichuan2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MoTCoder Elevating Large Language Models with Modular of Thought for Challenging Programming Tasks": {
        "filename": "MoTCoder Elevating Large Language Models with Modular of Thought for Challenging Programming Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "APPS",
                "CodeContests"
            ],
            "base_models": [
                "GPT-2",
                "GPT-Neo",
                "GPT-3",
                "StarCoder",
                "WizardCoder",
                "Octocoder",
                "Codellama",
                "Codellama-Python",
                "Codellama-Instruct",
                "Deepseek-Coder-Base",
                "Deepseek-Coder-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Automated Educational Question Generation at Different Blooms Skill Levels Using Large Language Models Strategies and Evaluation": {
        "filename": "Automated Educational Question Generation at Different Blooms Skill Levels Using Large Language Models Strategies and Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "DataScienceQ"
            ],
            "base_models": [
                "Mistral-7B-Instruct-v0.1 (7B)",
                "Llama-2-70b-chat-hf (70B)",
                "Palm 2 (chat-bison-001)",
                "GPT-3.5 (gpt-3.5-turbo-0613)",
                "GPT-4 (gpt-4-0613)"
            ]
        }
    },
    "StepTool A Step-grained Reinforcement Learning Framework for Tool Learning in LLMs": {
        "filename": "StepTool A Step-grained Reinforcement Learning Framework for Tool Learning in LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "StableToolBench"
            ],
            "base_models": [
                "ToolLLaMA-2-7b-v2",
                "Llama3.1-8B-Instruct",
                "Qwen2-7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Foundation Models for Decision Making Problems Methods and Opportunities": {
        "filename": "Foundation Models for Decision Making Problems Methods and Opportunities.pdf",
        "analysis": {
            "benchmarks": [
                "Atari games",
                "MuJoCo simulators"
            ],
            "base_models": [
                "CLIP",
                "ViT",
                "GPT (unspecified size)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SkillQG Learning to Generate Question for Reading Comprehension Assessment": {
        "filename": "SkillQG Learning to Generate Question for Reading Comprehension Assessment.pdf",
        "analysis": {
            "benchmarks": [
                "FairytaleQA"
            ],
            "base_models": [
                "GPT2",
                "BART-base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "S3-DST Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs": {
        "filename": "S3-DST Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MWOZ 2.1",
                "MWOZ 2.4",
                "DialSeg711",
                "proprietary anonymized open-domain dialogue dataset from Microsoft's Bing Chat"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Med-PerSAM One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain": {
        "filename": "Med-PerSAM One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain.pdf",
        "analysis": {
            "benchmarks": [
                "Shenzhen dataset",
                "OdontoAI dataset",
                "JSRT dataset",
                "CAMUS dataset",
                "BUU dataset"
            ],
            "base_models": [
                "Segment Anything Model (SAM)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enabling Uniform Computer Interaction Experience for Blind Users through Large Language Models": {
        "filename": "Enabling Uniform Computer Interaction Experience for Blind Users through Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "User study with 11 blind participants"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "On Second Thought Lets Not Think Step by Step Bias and Toxicity in Zero-Shot Reasoning": {
        "filename": "On Second Thought Lets Not Think Step by Step Bias and Toxicity in Zero-Shot Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "CrowS-Pairs",
                "StereoSet",
                "BBQ",
                "HarmfulQ"
            ],
            "base_models": [
                "GPT-3 text-davinci-001",
                "GPT-3 text-davinci-002",
                "GPT-3 text-davinci-003"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Teaching Small Language Models to Reason": {
        "filename": "Teaching Small Language Models to Reason.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MAWPS",
                "ASDiv",
                "StrategyQA",
                "Last Letter Concatenation",
                "Coinflip"
            ],
            "base_models": [
                "PaLM-540B",
                "GPT-3-175B",
                "T5 XXL (11 billion parameters)",
                "T5 XL (3 billion parameters)",
                "T5 base (220 million parameters)"
            ]
        }
    },
    "Power-LLaVA Large Language and Vision Assistant for Power Transmission Line Inspection": {
        "filename": "Power-LLaVA Large Language and Vision Assistant for Power Transmission Line Inspection.pdf",
        "analysis": {
            "benchmarks": [
                "PowerQA"
            ],
            "base_models": [
                "GPT-4V",
                "ViT-L/14",
                "vicuna-7B"
            ]
        }
    },
    "AI-assisted coding Experiments with GPT-4": {
        "filename": "AI-assisted coding Experiments with GPT-4.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "Cumulative Reasoning with Large Language Models": {
        "filename": "Cumulative Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "FOLIO wiki",
                "AutoTNLI",
                "Game of 24",
                "MATH"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4",
                "LLaMA-13B",
                "LLaMA-65B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Design Principles for Generative AI Applications": {
        "filename": "Design Principles for Generative AI Applications.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT (various sizes)",
                "Codex (various sizes)",
                "StyleGAN (various sizes)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "No Train No Gain Revisiting Efficient Training Algorithms For Transformer-based Language Models": {
        "filename": "No Train No Gain Revisiting Efficient Training Algorithms For Transformer-based Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SuperGLUE",
                "SNI"
            ],
            "base_models": [
                "BERT-Base (120M parameters)",
                "T5-Base"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Task-oriented Sequential Grounding in 3D Scenes": {
        "filename": "Task-oriented Sequential Grounding in 3D Scenes.pdf",
        "analysis": {
            "benchmarks": [
                "SG3D"
            ],
            "base_models": [
                "GPT-4",
                "3D-VisTA",
                "PQ3D",
                "LEO"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "SYMPHONY Improving Memory Management for LLM Inference Workloads": {
        "filename": "SYMPHONY Improving Memory Management for LLM Inference Workloads.pdf",
        "analysis": {
            "benchmarks": [
                "shareGPT"
            ],
            "base_models": [
                "LLAMA-3.1-70B",
                "LLAMA-3.1-8B",
                "LLAMA-2-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reflectance Estimation for Proximity Sensing by Vision-Language Models Utilizing Distributional Semantics for Low-Level Cognition in Robotics": {
        "filename": "Reflectance Estimation for Proximity Sensing by Vision-Language Models Utilizing Distributional Semantics for Low-Level Cognition in Robotics.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 54 objects with reflectance values"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "CLIP (ResNet101)",
                "CLIP (ViT-B/32)",
                "VGG16",
                "ResNet101",
                "ViT-B/32"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Missed Connections Lateral Thinking Puzzles for Large Language Models": {
        "filename": "Missed Connections Lateral Thinking Puzzles for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Connections puzzle dataset"
            ],
            "base_models": [
                "GPT-3.5-TURBO",
                "GPT-4-TURBO"
            ]
        }
    },
    "Auto-GPT for Online Decision Making Benchmarks and Additional Opinions": {
        "filename": "Auto-GPT for Online Decision Making Benchmarks and Additional Opinions.pdf",
        "analysis": {
            "benchmarks": [
                "WebShop",
                "ALFWorld"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "Claude",
                "Vicuna"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Transformers Reason Logically A Study in SAT Solving": {
        "filename": "Can Transformers Reason Logically A Study in SAT Solving.pdf",
        "analysis": {
            "benchmarks": [
                "random 3-SAT instances"
            ],
            "base_models": [
                "LLaMa-70M",
                "LLaMa-160M"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompts Matter Insights and Strategies for Prompt Engineering in Automated Software Traceability": {
        "filename": "Prompts Matter Insights and Strategies for Prompt Engineering in Automated Software Traceability.pdf",
        "analysis": {
            "benchmarks": [
                "CM1",
                "iTrust",
                "DronologyNL",
                "DronologyPL"
            ],
            "base_models": [
                "Claude (version: claude-instant-v1)",
                "GPT-3",
                "text-davinci-003",
                "text-embedding-ada-002"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Building Efficient and Effective OpenQA Systems for Low-Resource Languages": {
        "filename": "Building Efficient and Effective OpenQA Systems for Low-Resource Languages.pdf",
        "analysis": {
            "benchmarks": [
                "XQuAD-TR",
                "SQuAD-TR"
            ],
            "base_models": [
                "BERTurk",
                "mBERT",
                "XLM-RoBERTa"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Dealing with Data for RE Mitigating Challenges while using NLP and Generative AI": {
        "filename": "Dealing with Data for RE Mitigating Challenges while using NLP and Generative AI.pdf",
        "analysis": {
            "benchmarks": [
                "Expanded PROMISE dataset",
                "PURE dataset",
                "Unfair-TOS Dataset",
                "LEXDEMOD Dataset"
            ],
            "base_models": [
                "BERT (bert-base-cased)",
                "GPT-2",
                "ChatGPT (gpt-3.5-turbo)",
                "LLAMA-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Anticipate  Collab Data-driven Task Anticipation and Knowledge-driven Planning for Human-robot Collaboration": {
        "filename": "Anticipate  Collab Data-driven Task Anticipation and Knowledge-driven Planning for Human-robot Collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "CoppeliaSim environment"
            ],
            "base_models": [
                "Pretrained Large Language Model (LLM)"
            ]
        }
    },
    "Agent S An Open Agentic Framework that Uses Computers Like a Human": {
        "filename": "Agent S An Open Agentic Framework that Uses Computers Like a Human.pdf",
        "analysis": {
            "benchmarks": [
                "OSWorld",
                "WindowsAgentArena"
            ],
            "base_models": [
                "GPT-4o",
                "Claude-3-Sonnet"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can ChatGPT Pass An Introductory Level Functional Language Programming Course": {
        "filename": "Can ChatGPT Pass An Introductory Level Functional Language Programming Course.pdf",
        "analysis": {
            "benchmarks": [
                "Homework assignments and exams from the 2022 fall semester of an introductory functional programming course"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "OpenFMNav Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models": {
        "filename": "OpenFMNav Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models.pdf",
        "analysis": {
            "benchmarks": [
                "HM3D ObjectNav"
            ],
            "base_models": [
                "GPT-4",
                "GPT-4V",
                "Grounded-SAM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "StringLLM Understanding the String Processing Capability of Large Language Models": {
        "filename": "StringLLM Understanding the String Processing Capability of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "StringBench (Multilingual, Hash, Random String)"
            ],
            "base_models": [
                "GPT-4-Turbo (1.5T)",
                "GPT-4o (1.5T)",
                "GPT-3.5 (154B)",
                "DeepSeek-Coder (16B)",
                "DeepSeek-Chat (16B)",
                "Gemma-2-9b (9B)",
                "Llama-3.1-8B (8B)",
                "Mistral-7B-v0.3 (7B)",
                "Mathstral-7B-v0.1 (7B)",
                "Codestral-22B-v0.1 (22B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Metacognition for Unknown Situations and Environments MUSE": {
        "filename": "Metacognition for Unknown Situations and Environments MUSE.pdf",
        "analysis": {
            "benchmarks": [
                "Meta-World",
                "ALFWorld"
            ],
            "base_models": [
                "Dreamer-v3",
                "Mistral-7B-Instruct-v0.2",
                "Open-Orca/Mistral-7B-OpenOrca",
                "Apple/OpenELM-3B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CLIMB Language-Guided Continual Learning for Task Planning with Iterative Model Building": {
        "filename": "CLIMB Language-Guided Continual Learning for Task Planning with Iterative Model Building.pdf",
        "analysis": {
            "benchmarks": [
                "BlocksWorld++"
            ],
            "base_models": [
                "GPT-4 (gpt-4o-2024-08-06)"
            ]
        }
    },
    "Automated Interactive Domain-Specific Conversational Agents that Understand Human Dialogs": {
        "filename": "Automated Interactive Domain-Specific Conversational Agents that Understand Human Dialogs.pdf",
        "analysis": {
            "benchmarks": [
                "E2E dataset"
            ],
            "base_models": [
                "GPT-3 (175 billion parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fill in the Blank Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems": {
        "filename": "Fill in the Blank Exploring and Enhancing LLM Capabilities for Backward Reasoning in Math Word Problems.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8k",
                "SVAMP",
                "MultiArith"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "PaLM-2",
                "LLaMa-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Data Interpreter An LLM Agent For Data Science": {
        "filename": "Data Interpreter An LLM Agent For Data Science.pdf",
        "analysis": {
            "benchmarks": [
                "InfiAgent-DABench",
                "MATH"
            ],
            "base_models": [
                "gpt-4-0613",
                "gpt-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Use Your INSTINCT INSTruction optimization for LLMs usIng Neural bandits Coupled with Transformers": {
        "filename": "Use Your INSTINCT INSTruction optimization for LLMs usIng Neural bandits Coupled with Transformers.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "AQUARAT",
                "SVAMP",
                "SAMSum"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4",
                "Vicuna-13B",
                "PaLM2",
                "WizardLM"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Hint-Enhanced In-Context Learning Wakes Large Language Models Up For Knowledge-Intensive Tasks": {
        "filename": "Hint-Enhanced In-Context Learning Wakes Large Language Models Up For Knowledge-Intensive Tasks.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions",
                "Web Questions",
                "TriviaQA"
            ],
            "base_models": [
                "gpt-3.5-turbo",
                "LLaMA-2-Chat-7B"
            ]
        }
    },
    "TIBET Identifying and Evaluating Biases in Text-to-Image Generative Models": {
        "filename": "TIBET Identifying and Evaluating Biases in Text-to-Image Generative Models.pdf",
        "analysis": {
            "benchmarks": [
                "Predefined prompts for gender stereotypes in occupations",
                "Varied Text Prompts for Evaluation"
            ],
            "base_models": [
                "Stable Diffusion 1.5",
                "Stable Diffusion 2.1",
                "GPT-3",
                "MiniGPT-v2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Toolshed Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and Tool Knowledge Bases": {
        "filename": "Toolshed Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and Tool Knowledge Bases.pdf",
        "analysis": {
            "benchmarks": [
                "ToolE single-tool",
                "ToolE multi-tool",
                "Seal-Tools"
            ],
            "base_models": [
                "GPT-4o (2024-05-13)",
                "gpt-35-turbo-16k (0613)",
                "gpt-4 (0613)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompt Sapper A LLM-Empowered Production Tool for Building AI Chains": {
        "filename": "Prompt Sapper A LLM-Empowered Production Tool for Building AI Chains.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "ChatGPT",
                "DALL-E"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles": {
        "filename": "Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles.pdf",
        "analysis": {
            "benchmarks": [
                "Custom scenarios based on crash reports",
                "SUMO simulation environment"
            ],
            "base_models": [
                "GPT-3.5/4",
                "Vision-Language Model (VLM)"
            ]
        }
    },
    "GECKO Generative Language Model for English Code and Korean": {
        "filename": "GECKO Generative Language Model for English Code and Korean.pdf",
        "analysis": {
            "benchmarks": [
                "KMMLU",
                "MMLU",
                "HumanEval",
                "MATH"
            ],
            "base_models": [
                "LLaMA-2 7B",
                "Mistral 7B",
                "Gemma 7B",
                "Polyglot-Ko 5.8B",
                "GECKO (based on LLaMA architecture)"
            ]
        }
    },
    "Drive as You Speak Enabling Human-Like Interaction with Large Language Models in Autonomous Vehicles": {
        "filename": "Drive as You Speak Enabling Human-Like Interaction with Large Language Models in Autonomous Vehicles.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT-4"
            ]
        }
    },
    "Generative Multimodal Models are In-Context Learners": {
        "filename": "Generative Multimodal Models are In-Context Learners.pdf",
        "analysis": {
            "benchmarks": [
                "VQAv2",
                "OKVQA",
                "VizWiz",
                "TextVQA",
                "HatefulMemes",
                "GQA",
                "MSVD",
                "MSRVTT",
                "SEED-Bench",
                "MM-Vet",
                "TouchStone",
                "RefCOCO",
                "RefCOCO+",
                "RefCOCOg"
            ],
            "base_models": [
                "Emu2 (37B)",
                "LLaMA-33B",
                "SDXL"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Let Your Graph Do the Talking Encoding Structured Data for LLMs": {
        "filename": "Let Your Graph Do the Talking Encoding Structured Data for LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "GraphQA"
            ],
            "base_models": [
                "PaLM 2 S"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Sweeping Heterogeneity with Smart MoPs Mixture of Prompts for LLM Task Adaptation": {
        "filename": "Sweeping Heterogeneity with Smart MoPs Mixture of Prompts for LLM Task Adaptation.pdf",
        "analysis": {
            "benchmarks": [
                "Databricks Dolly 15k",
                "Super-Natural Instructions"
            ],
            "base_models": [
                "LLaMA-7B"
            ]
        }
    },
    "Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning": {
        "filename": "Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GDELT",
                "ICEWS",
                "Amazon Review"
            ],
            "base_models": [
                "GPT-3-davinci",
                "GPT-3.5-turbo",
                "Llama-2-chat (13B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Using AI Large Language Models for Grading in Education A Hands-On Test for Physics": {
        "filename": "Using AI Large Language Models for Grading in Education A Hands-On Test for Physics.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 30 undergraduate physics problems from UCL"
            ],
            "base_models": [
                "Gemini 1.5 Pro",
                "GPT-4",
                "GPT-4o",
                "Claude 3.5 Sonnet"
            ]
        }
    },
    "System-1x Learning to Balance Fast and Slow Planning with Language Models": {
        "filename": "System-1x Learning to Balance Fast and Slow Planning with Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Maze Navigation",
                "Blocksworld"
            ],
            "base_models": [
                "Mistral-7B-Instruct-v0.2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Benchmark Data Contamination of Large Language Models A Survey": {
        "filename": "Benchmark Data Contamination of Large Language Models A Survey.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Claude-3",
                "Gemini",
                "PaLM",
                "LLaMA",
                "BERT",
                "T5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enriching Ontologies with Disjointness Axioms using Large Language Models": {
        "filename": "Enriching Ontologies with Disjointness Axioms using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "DBpedia ontology"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "LLaMA (various sizes)",
                "Claude",
                "Gemini",
                "Mixtral"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MetaLLM A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs": {
        "filename": "MetaLLM A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "SST-2",
                "IMDB"
            ],
            "base_models": [
                "GPT-4 (1.74 trillion parameters)",
                "Llama 2 7B",
                "Claude Instant",
                "Titan Lite",
                "Cohere Command-Light",
                "text-ada-001",
                "text-babbage-001",
                "text-curie-001",
                "text-davinci-002"
            ]
        }
    },
    "How understanding large language models can inform the use of ChatGPT in physics education": {
        "filename": "How understanding large language models can inform the use of ChatGPT in physics education.pdf",
        "analysis": {
            "benchmarks": [
                "Force Concept Inventory (FCI)",
                "Custom dataset inspired by Etkina, Planinsic and Van Heuvelen’s College Physics: Explore and apply textbook"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Harnessing Retrieval-Augmented Generation RAG for Uncovering Knowledge Gaps": {
        "filename": "Harnessing Retrieval-Augmented Generation RAG for Uncovering Knowledge Gaps.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset with 500 search queries classified in 25 categories"
            ],
            "base_models": [
                "GPT"
            ]
        }
    },
    "BHASA A Holistic Southeast Asian Linguistic and Cultural Evaluation Suite for Large Language Models": {
        "filename": "BHASA A Holistic Southeast Asian Linguistic and Cultural Evaluation Suite for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "NER-Grit (Indonesian)",
                "VLSP2018 (Vietnamese)",
                "ThaiNERv2 (Thai)",
                "Naamapadam (Tamil)",
                "TyDiQA (Indonesian)",
                "XQuAD (Vietnamese, Thai)",
                "IndicQA (Tamil)",
                "NusaX (Indonesian)",
                "UIT-VSFC (Vietnamese)",
                "Wisesight (Thai)",
                "IndicSentiment (Tamil)",
                "MLHSD (Indonesian)",
                "ViHSD (Vietnamese)",
                "Thai Toxicity Tweet (Thai)",
                "FLORES (Indonesian, Vietnamese, Thai, Tamil)",
                "XLSum (Indonesian, Vietnamese, Thai, Tamil)",
                "IndoNLI (Indonesian)",
                "XNLI (Vietnamese, Thai)",
                "IndicXNLI (Tamil)",
                "XCOPA (Indonesian, Vietnamese, Thai, Tamil)"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Long-range gene expression prediction with token alignment of large language model": {
        "filename": "Long-range gene expression prediction with token alignment of large language model.pdf",
        "analysis": {
            "benchmarks": [
                "Geuvadis consortium"
            ],
            "base_models": [
                "Llama3-8B"
            ]
        }
    },
    "Describe Explain Plan and Select Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents": {
        "filename": "Describe Explain Plan and Select Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents.pdf",
        "analysis": {
            "benchmarks": [
                "Minecraft",
                "ALFWorld",
                "Tabletop environments"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)",
                "Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting PaLM for Translation Assessing Strategies and Performance": {
        "filename": "Prompting PaLM for Translation Assessing Strategies and Performance.pdf",
        "analysis": {
            "benchmarks": [
                "WMT21",
                "WMT14"
            ],
            "base_models": [
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Trustworthy AI A Review of Ethical and Robust Large Language Models": {
        "filename": "Towards Trustworthy AI A Review of Ethical and Robust Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Beyond Lines and Circles Unveiling the Geometric Reasoning Gap in Large Language Models": {
        "filename": "Beyond Lines and Circles Unveiling the Geometric Reasoning Gap in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Euclidea",
                "Euclid's Elements"
            ],
            "base_models": [
                "LLamaV2-7B",
                "LLamaV2-13B",
                "Mistral-7B",
                "Zephyr-7B",
                "MetaMath-LlamaV2-13B",
                "MetaMath-Mistral-7B",
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cannot or Should Not Automatic Analysis of Refusal Composition in IFTRLHF Datasets and Refusal Behavior of Black-Box LLMs": {
        "filename": "Cannot or Should Not Automatic Analysis of Refusal Composition in IFTRLHF Datasets and Refusal Behavior of Black-Box LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "RealToxicityPrompts",
                "ToxiGen",
                "Do-Not-Answer dataset",
                "AdvBench",
                "ToxicChat",
                "MaliciousInstruct",
                "BeaverTails",
                "XSafety",
                "SORRY-Bench",
                "SALAD-Bench",
                "HarmBench"
            ],
            "base_models": [
                "GPT-4",
                "Wizard-Vicuna-30B-Uncensored"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Can Large Language Models Explain Themselves A Study of LLM-Generated Self-Explanations": {
        "filename": "Can Large Language Models Explain Themselves A Study of LLM-Generated Self-Explanations.pdf",
        "analysis": {
            "benchmarks": [
                "Stanford Sentiment Treebank (SST)"
            ],
            "base_models": [
                "ChatGPT",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CoT3DRef Chain-of-Thoughts Data-Efficient 3D Visual Grounding": {
        "filename": "CoT3DRef Chain-of-Thoughts Data-Efficient 3D Visual Grounding.pdf",
        "analysis": {
            "benchmarks": [
                "Nr3D",
                "Sr3D",
                "ScanRefer"
            ],
            "base_models": [
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing Physics Learning with ChatGPT Bing Chat and Bard as Agents-to-Think-With A Comparative Case Study": {
        "filename": "Enhancing Physics Learning with ChatGPT Bing Chat and Bard as Agents-to-Think-With A Comparative Case Study.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT-3.5",
                "ChatGPT-4",
                "Bing Chat (GPT-4)",
                "Bard (PaLM-2)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Crawling The Internal Knowledge-Base of Language Models": {
        "filename": "Crawling The Internal Knowledge-Base of Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "WIKIDATA"
            ],
            "base_models": [
                "GPT-3 (text-davinci-002)"
            ]
        }
    },
    "Math-Shepherd Verify and Reinforce LLMs Step-by-step without Human Annotations": {
        "filename": "Math-Shepherd Verify and Reinforce LLMs Step-by-step without Human Annotations.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH"
            ],
            "base_models": [
                "Mistral-7B",
                "LLaMA2-70B",
                "LLemma-34B",
                "DeepSeek-67B",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Embroid Unsupervised Prediction Smoothing Can Improve Few-Shot Classification": {
        "filename": "Embroid Unsupervised Prediction Smoothing Can Improve Few-Shot Classification.pdf",
        "analysis": {
            "benchmarks": [
                "CUAD",
                "AGNews",
                "DBpedia-14",
                "FewRel"
            ],
            "base_models": [
                "GPT-3.5 (>170B)",
                "J1-Jumbo (176B)",
                "Bloom (7.1B)",
                "OPT (6.7B)",
                "GPT-JT (6B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Enhancing LLM Fine-tuning for Text-to-SQLs by SQL Quality Measurement": {
        "filename": "Enhancing LLM Fine-tuning for Text-to-SQLs by SQL Quality Measurement.pdf",
        "analysis": {
            "benchmarks": [
                "BIRD"
            ],
            "base_models": [
                "GPT-4",
                "T5"
            ]
        }
    },
    "Automatic Chain of Thought Prompting in Large Language Models": {
        "filename": "Automatic Chain of Thought Prompting in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "MultiArith",
                "GSM8K",
                "AQUA-RAT",
                "SVAMP",
                "CSQA",
                "StrategyQA",
                "Last Letter Concatenation",
                "Coin Flip",
                "AddSub",
                "SingleEq"
            ],
            "base_models": [
                "GPT-3 (175B parameters, text-davinci-002)",
                "Codex (code-davinci-002)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Instruct Me More Random Prompting for Visual In-Context Learning": {
        "filename": "Instruct Me More Random Prompting for Visual In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Pascal-5i",
                "PASCAL VOC 2012"
            ],
            "base_models": [
                "MAE-VQGAN"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Inspire creativity with ORIBA Transform Artists Original Characters into Chatbots through Large Language Model": {
        "filename": "Inspire creativity with ORIBA Transform Artists Original Characters into Chatbots through Large Language Model.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT"
            ]
        }
    },
    "Towards Human-Centered Explainable AI A Survey of User Studies for Model Explanations": {
        "filename": "Towards Human-Centered Explainable AI A Survey of User Studies for Model Explanations.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Delving into the Reversal Curse How Far Can Large Language Models Generalize": {
        "filename": "Delving into the Reversal Curse How Far Can Large Language Models Generalize.pdf",
        "analysis": {
            "benchmarks": [
                "Synthetic dataset (NameIsDescription and DescriptionIsName subsets)",
                "Celebrities dataset"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA2-7B-chat",
                "LLaMA2-13B-chat",
                "LLaMA3-8B-Instruct",
                "Vicuna-7B-v1.5",
                "Vicuna-13B-v1.5",
                "Mistral-7B-Instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Improving Reading Comprehension Question Generation with Data Augmentation and Overgenerate-and-rank": {
        "filename": "Improving Reading Comprehension Question Generation with Data Augmentation and Overgenerate-and-rank.pdf",
        "analysis": {
            "benchmarks": [
                "FairytaleQA"
            ],
            "base_models": [
                "Flan-T5-Large (770M)",
                "OpenAI Codex",
                "BERT",
                "ConvBERT"
            ]
        }
    },
    "The Hitchhikers Guide to Program Analysis A Journey with Large Language Models": {
        "filename": "The Hitchhikers Guide to Program Analysis A Journey with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Linux kernel"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Private Attribute Inference from Images with Vision-Language Models": {
        "filename": "Private Attribute Inference from Images with Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Visual Inference-Privacy (VIP) dataset"
            ],
            "base_models": [
                "GPT4-V",
                "Gemini-Pro",
                "LLaVa 1.5 13B",
                "LLaVa-NeXT 34B",
                "Idefics 80B",
                "CogAgent-VQA",
                "InternVL-Chat-V1.2-Plus"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VLM-Social-Nav Socially Aware Robot Navigation Through Scoring Using Vision-Language Models": {
        "filename": "VLM-Social-Nav Socially Aware Robot Navigation Through Scoring Using Vision-Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "SCAND",
                "MuSoHu"
            ],
            "base_models": [
                "GPT-4V"
            ]
        }
    },
    "Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback": {
        "filename": "Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Claude-v1.3",
                "GPT-3.5-Turbo",
                "Claude-instant-v1.0",
                "Jurassic-2-instruct",
                "Cohere-command"
            ]
        }
    },
    "GPT-RE In-context Learning for Relation Extraction using Large Language Models": {
        "filename": "GPT-RE In-context Learning for Relation Extraction using Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Semeval 2010 task 8",
                "TACRED",
                "SciERC",
                "ACE05"
            ],
            "base_models": [
                "GPT-3"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generative AI in the Classroom Can Students Remain Active Learners": {
        "filename": "Generative AI in the Classroom Can Students Remain Active Learners.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3"
            ]
        }
    },
    "Software Engineering and Foundation Models Insights from Industry Blogs Using a Jury of Foundation Models": {
        "filename": "Software Engineering and Foundation Models Insights from Industry Blogs Using a Jury of Foundation Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4",
                "Qwen2-72B-Instruct",
                "Gemini-1.5-Flash"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cognitively Inspired Energy-Based World Models": {
        "filename": "Cognitively Inspired Energy-Based World Models.pdf",
        "analysis": {
            "benchmarks": [
                "Something-Something V2 (SSV2)",
                "Kinetics-400"
            ],
            "base_models": [
                "DINOv2 (frozen backbone)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT is becoming a Turing machine Here are some ways to program it": {
        "filename": "GPT is becoming a Turing machine Here are some ways to program it.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-bench Logical Deduction",
                "BIG-bench Valid Parentheses"
            ],
            "base_models": [
                "GPT-3 CODE-DAVINCI-002",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Benchmarking VLMs Reasoning About Persuasive Atypical Images": {
        "filename": "Benchmarking VLMs Reasoning About Persuasive Atypical Images.pdf",
        "analysis": {
            "benchmarks": [
                "PittAds"
            ],
            "base_models": [
                "LLaVA (vicuna-13b-v1.5)",
                "InstructBLIP (vicuna-13b-v0)",
                "MiniGPT4 (vicuna-13b-v0)",
                "CLIP (ViT-L/14@336px)",
                "InternVL-Chat-V1-1",
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "ICE-Score Instructing Large Language Models to Evaluate Code": {
        "filename": "ICE-Score Instructing Large Language Models to Evaluate Code.pdf",
        "analysis": {
            "benchmarks": [
                "CoNaLa",
                "HumanEval-X"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4"
            ]
        }
    },
    "Position Key Claims in LLM Research Have a Long Tail of Footnotes": {
        "filename": "Position Key Claims in LLM Research Have a Long Tail of Footnotes.pdf",
        "analysis": {
            "benchmarks": [
                "SuperGLUE",
                "RTE"
            ],
            "base_models": [
                "BERT-base (340M parameters)",
                "PaLM (540B parameters)",
                "GPT-3",
                "GPT-4",
                "LLaMa",
                "FLAN-T5",
                "BLOOM",
                "FALCON"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "EVA An Embodied World Model for Future Video Anticipation": {
        "filename": "EVA An Embodied World Model for Future Video Anticipation.pdf",
        "analysis": {
            "benchmarks": [
                "Embodied Video Anticipation Benchmark (EVA-Bench)"
            ],
            "base_models": [
                "Llama 2 7B",
                "ChatUniVi (7B)",
                "Dynamicrafter (1.5B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "M4U Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models": {
        "filename": "M4U Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models.pdf",
        "analysis": {
            "benchmarks": [
                "M4U"
            ],
            "base_models": [
                "GPT-4o",
                "GPT-4V(ision)",
                "InstructBLIP-Vicuna-13B",
                "InstructBLIP-Vicuna-7B",
                "LLaVA-NeXT-Vicuna-7B",
                "LLaVA-NeXT-Vicuna-13B",
                "Qwen-VL-Chat",
                "CogVLM-Chat",
                "LLaVA-NeXT-Mistral-7B",
                "InternLM-XComposer",
                "DeepSeek-VL",
                "Yi-VL-6B",
                "Yi-VL-34B",
                "Gemini 1.0 Pro"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Uncovering Name-Based Biases in Large Language Models Through Simulated Trust Game": {
        "filename": "Uncovering Name-Based Biases in Large Language Models Through Simulated Trust Game.pdf",
        "analysis": {
            "benchmarks": [
                "Trust Game (custom dataset)"
            ],
            "base_models": [
                "Llama2-13B",
                "Mistral-7B",
                "Phi-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VipAct Visual-Perception Enhancement via Specialized VLM Agent Collaboration and Tool-use": {
        "filename": "VipAct Visual-Perception Enhancement via Specialized VLM Agent Collaboration and Tool-use.pdf",
        "analysis": {
            "benchmarks": [
                "Blink",
                "MMVP"
            ],
            "base_models": [
                "GPT-4o"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Model Is Not a Good Few-shot Information Extractor but a Good Reranker for Hard Samples": {
        "filename": "Large Language Model Is Not a Good Few-shot Information Extractor but a Good Reranker for Hard Samples.pdf",
        "analysis": {
            "benchmarks": [
                "CONLL03",
                "OntoNotes",
                "FewNERD",
                "TACRED",
                "TACREV",
                "ACE05",
                "MAVEN",
                "ERE",
                "RAMS"
            ],
            "base_models": [
                "ChatGPT",
                "CODEX",
                "InstructGPT",
                "LLaMA-13B",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "The Curious Case of Control": {
        "filename": "The Curious Case of Control.pdf",
        "analysis": {
            "benchmarks": [
                "Universal Decompositional Semantics (UDS) dataset"
            ],
            "base_models": [
                "GPT-3 Davinci (175B)",
                "GPT-Neo (1.3B, 2.7B, 6B)",
                "Jurassic Large (7.5B)",
                "Jurassic Jumbo (178B)",
                "T5-base (220M)",
                "T0pp (11B)"
            ]
        }
    },
    "LLM Chain Ensembles for Scalable and Accurate Data Annotation": {
        "filename": "LLM Chain Ensembles for Scalable and Accurate Data Annotation.pdf",
        "analysis": {
            "benchmarks": [
                "SemEval-16",
                "Misinfo Reaction Frames corpus",
                "Ideology Books Corpus (IBC)"
            ],
            "base_models": [
                "LLAMA 3.1 (8B)",
                "Flan-UL2",
                "Mistral-7b",
                "Phi3",
                "GPT-4o"
            ]
        }
    },
    "BALROG Benchmarking Agentic LLM and VLM Reasoning On Games": {
        "filename": "BALROG Benchmarking Agentic LLM and VLM Reasoning On Games.pdf",
        "analysis": {
            "benchmarks": [
                "BabyAI",
                "Crafter",
                "TextWorld",
                "Baba Is AI",
                "MiniHack",
                "NetHack Learning Environment (NLE)"
            ],
            "base_models": [
                "GPT-4o-mini (2024-07-18 release)",
                "GPT-4o (2024-05-13 release)",
                "Claude 3.5 Sonnet",
                "Llama 3.1 instruct (8B and 70B)",
                "Llama 3.2 instruct (1B, 3B, 11B and 90B)",
                "Gemini-1.5-Flash",
                "Gemini-1.5-Pro",
                "o1-mini (2024-09-12 release)",
                "o1-preview (2024-09-12 release)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Formalizing Chemical Physics using the Lean Theorem Prover": {
        "filename": "Formalizing Chemical Physics using the Lean Theorem Prover.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LogiCoT Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4": {
        "filename": "LogiCoT Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4.pdf",
        "analysis": {
            "benchmarks": [
                "LOGIC INFERENCE",
                "EntailmentBank",
                "FOLIO",
                "ReClor",
                "LogiQA"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Adapting Large Language Models for Education Foundational Capabilities Potentials and Challenges": {
        "filename": "Adapting Large Language Models for Education Foundational Capabilities Potentials and Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "SCIBENCH",
                "ARB",
                "GeoEval",
                "MathVista",
                "TABWP"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-2",
                "CodeLlama",
                "WizardCoder"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Modeling Collaborator Enabling Subjective Vision Classification with Minimal Human Effort via LLM Tool-Use": {
        "filename": "Modeling Collaborator Enabling Subjective Vision Classification with Minimal Human Effort via LLM Tool-Use.pdf",
        "analysis": {
            "benchmarks": [
                "Hateful Memes",
                "Agile Modeling dataset"
            ],
            "base_models": [
                "PaLI-X (55B)",
                "CLIP",
                "CuPL",
                "PaLM 2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Exploring the Deceptive Power of LLM-Generated Fake News A Study of Real-World Detection Challenges": {
        "filename": "Exploring the Deceptive Power of LLM-Generated Fake News A Study of Real-World Detection Challenges.pdf",
        "analysis": {
            "benchmarks": [
                "VLPFN"
            ],
            "base_models": [
                "GPT-4",
                "Vicuna",
                "BERT",
                "RoBERTa",
                "FN-BERT",
                "Llama2-7b",
                "ChatGPT-3.5"
            ]
        }
    },
    "Invalid Logic Equivalent Gains The Bizarreness of Reasoning in Language Model Prompting": {
        "filename": "Invalid Logic Equivalent Gains The Bizarreness of Reasoning in Language Model Prompting.pdf",
        "analysis": {
            "benchmarks": [
                "BIG-Bench Hard (BBH)"
            ],
            "base_models": [
                "Codex",
                "InstructGPT",
                "PaLM 540B"
            ]
        }
    },
    "What is it for a Machine Learning Model to Have a Capability": {
        "filename": "What is it for a Machine Learning Model to Have a Capability.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Reasoning about the Unseen for Efficient Outdoor Object Navigation": {
        "filename": "Reasoning about the Unseen for Efficient Outdoor Object Navigation.pdf",
        "analysis": {
            "benchmarks": [
                "AirSim simulation environment",
                "Unitree Go1 real-world robotic platform"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "Kosmos-2"
            ]
        }
    },
    "Demonstrations of the Potential of AI-based Political Issue Polling": {
        "filename": "Demonstrations of the Potential of AI-based Political Issue Polling.pdf",
        "analysis": {
            "benchmarks": [
                "Cooperative Election Study (CES)"
            ],
            "base_models": [
                "GPT-3.5-turbo-0301"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Cofca A Step-Wise Counterfactual Multi-hop QA benchmark": {
        "filename": "Cofca A Step-Wise Counterfactual Multi-hop QA benchmark.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "2WikiMultihopQA",
                "MuSiQue",
                "CofCA"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "GEMINI-pro",
                "text-davinci-003",
                "Bing Chat",
                "O1-preview",
                "Llama 2-7b",
                "Mistral-7b",
                "Qwen 2-7b"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "CRISPR-GPT An LLM Agent for Automated Design of Gene-Editing Experiments": {
        "filename": "CRISPR-GPT An LLM Agent for Automated Design of Gene-Editing Experiments.pdf",
        "analysis": {
            "benchmarks": [
                "NCBI's BLAST tool"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "AGIBench A Multi-granularity Multimodal Human-referenced Auto-scoring Benchmark for Large Language Models": {
        "filename": "AGIBench A Multi-granularity Multimodal Human-referenced Auto-scoring Benchmark for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "AGIBench"
            ],
            "base_models": [
                "GPT-3.5 (175 billion)",
                "ChatGPT (175 billion)",
                "GPT-4",
                "Claude",
                "LLaMA-13B (13 billion)",
                "Vicuna-13B (13 billion)",
                "ChatGLM-6B (6 billion)",
                "ChatGLM v2-6B (6 billion)",
                "ChatGLM-130B (130 billion)",
                "Ernie (175 billion)",
                "Qianwen",
                "Spark"
            ]
        }
    },
    "An Incomplete Loop Instruction Inference Instruction Following and In-context Learning in Language Models": {
        "filename": "An Incomplete Loop Instruction Inference Instruction Following and In-context Learning in Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Linear Functions Dataset",
                "Colours Domain Dataset",
                "Machine Translation with One Book (MTOB) Dataset"
            ],
            "base_models": [
                "GPT-3.5-turbo",
                "GPT-4-turbo",
                "LLaMA-2-7B",
                "LLaMA-2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "FineSurE Fine-grained Summarization Evaluation using LLMs": {
        "filename": "FineSurE Fine-grained Summarization Evaluation using LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "FRANK",
                "REALSumm"
            ],
            "base_models": [
                "GPT-4-turbo",
                "GPT-4-omni",
                "GPT-3.5-turbo",
                "Llama3-70B-Inst",
                "Mixtral-8x7B",
                "Mixtral-8x7B-Inst",
                "Phi-2 (2.7B)",
                "Llama2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Re-ReST Reflection-Reinforced Self-Training for Language Agents": {
        "filename": "Re-ReST Reflection-Reinforced Self-Training for Language Agents.pdf",
        "analysis": {
            "benchmarks": [
                "HotpotQA",
                "AlfWorld",
                "MBPP",
                "GQA",
                "VPEval"
            ],
            "base_models": [
                "Llama-2-13B",
                "Llama-3-8B",
                "Llama2-7B",
                "CodeLlama-13B",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models Vote Prompting for Rare Disease Identification": {
        "filename": "Large Language Models Vote Prompting for Rare Disease Identification.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-IV rare disease dataset"
            ],
            "base_models": [
                "Llama 2 13B",
                "MedAlpaca 13B",
                "Stable Platypus 2 13B",
                "Vicuna 13B"
            ]
        }
    },
    "Social Learning through Interactions with Other Agents A Survey": {
        "filename": "Social Learning through Interactions with Other Agents A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "TEACh",
                "ALFRED"
            ],
            "base_models": [
                "GPT-3",
                "AlphaStar",
                "Cicero"
            ]
        }
    },
    "SkipAnalyzer A Tool for Static Code Analysis with Large Language Models": {
        "filename": "SkipAnalyzer A Tool for Static Code Analysis with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset with 222 instances of Null Dereference bugs and 46 instances of Resource Leak bugs from 10 open-source projects"
            ],
            "base_models": [
                "ChatGPT-3.5 Turbo",
                "ChatGPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Unmasking Context Injection on Interactive Large Language Models": {
        "filename": "Unmasking Context Injection on Interactive Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "ChatGPT",
                "Llama-2",
                "Llama-3",
                "Gemma-2",
                "Vicuna",
                "InternLM",
                "ChatGLM-2"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Quiet-STaR Language Models Can Teach Themselves to Think Before Speaking": {
        "filename": "Quiet-STaR Language Models Can Teach Themselves to Think Before Speaking.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "CommonsenseQA"
            ],
            "base_models": [
                "Mistral 7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Explained Keywords Empower Large Language Models for Code Generation": {
        "filename": "Self-Explained Keywords Empower Large Language Models for Code Generation.pdf",
        "analysis": {
            "benchmarks": [
                "HumanEval(+)",
                "MBPP(+)",
                "APPS"
            ],
            "base_models": [
                "Llama-3.1-70B-Instruct",
                "Mixtral-8×22B-Instruct-v0.1",
                "DeepSeek-Coder-V2-236B-Instruct",
                "GPT-3.5-turbo-0125",
                "GPT-4o-mini"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Markovian Transformers for Informative Language Modeling": {
        "filename": "Markovian Transformers for Informative Language Modeling.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K"
            ],
            "base_models": [
                "Mistral 7B",
                "Llama 3.1 8B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Generating Natural Language Proofs with Verifier-Guided Search": {
        "filename": "Generating Natural Language Proofs with Verifier-Guided Search.pdf",
        "analysis": {
            "benchmarks": [
                "EntailmentBank",
                "RuleTaker"
            ],
            "base_models": [
                "RoBERTa",
                "T5-large"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Fairness-Aware Graph Neural Networks A Survey": {
        "filename": "Fairness-Aware Graph Neural Networks A Survey.pdf",
        "analysis": {
            "benchmarks": [
                "Pokec",
                "Twitter",
                "Facebook",
                "Citeseer",
                "Cora",
                "Pubmed",
                "DBLP",
                "WebKB",
                "Chameleon",
                "Squirrel",
                "German",
                "Recidivism",
                "Credit",
                "EMNLP"
            ],
            "base_models": [],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Code-Style In-Context Learning for Knowledge-Based Question Answering": {
        "filename": "Code-Style In-Context Learning for Knowledge-Based Question Answering.pdf",
        "analysis": {
            "benchmarks": [
                "WebQSP",
                "GrailQA",
                "GraphQ"
            ],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "Through the Lens of Core Competency Survey on Evaluation of Large Language Models": {
        "filename": "Through the Lens of Core Competency Survey on Evaluation of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SuperGLUE",
                "BLiMP",
                "LexGLUE",
                "WikiFact",
                "TruthfulQA",
                "HellaSwag",
                "COPA",
                "Mathematical Induction",
                "Synthetic Reasoning",
                "SAT Analogy",
                "StrategyQA",
                "GSM8K",
                "ToTTo",
                "RealToxicityPrompts",
                "BAD",
                "CrowS-Pairs",
                "StereoSet"
            ],
            "base_models": [
                "MT-NLG",
                "BLOOM",
                "Gopher",
                "Chinchilla",
                "FLAN-T5",
                "GLM",
                "GPT-3",
                "InstructGPT",
                "GPT-4",
                "LLaMA",
                "UL2",
                "Deberta",
                "GLaM",
                "PaLM",
                "HELM",
                "Pythia"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Multi-party Goal Tracking with LLMs Comparing Pre-training Fine-tuning and Prompt Engineering": {
        "filename": "Multi-party Goal Tracking with LLMs Comparing Pre-training Fine-tuning and Prompt Engineering.pdf",
        "analysis": {
            "benchmarks": [
                "Custom hospital multi-party conversation corpus"
            ],
            "base_models": [
                "T5-Large",
                "DialogLM using LED (DialogLED)",
                "GPT-3.5-turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Robustness of Reward Models for Mathematical Reasoning": {
        "filename": "Evaluating Robustness of Reward Models for Mathematical Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "RewardBench",
                "REWARD MATH"
            ],
            "base_models": [
                "GPT-4 (size not specified)",
                "Claude-3.5-Sonnet (size not specified)",
                "Claude-3-Opus (size not specified)",
                "LLaMA3-70B",
                "LLaMA3-8B",
                "Prometheus-2-8x7B",
                "Prometheus-2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Evaluating Open-QA Evaluation": {
        "filename": "Evaluating Open-QA Evaluation.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions (NQ)",
                "TriviaQA (TQ)",
                "EVOUNA"
            ],
            "base_models": [
                "GPT-3.5 (175B)",
                "ChatGPT-3.5",
                "ChatGPT-4",
                "Bing Chat",
                "DPR + FiD"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Mamo a Mathematical Modeling Benchmark with Solvers": {
        "filename": "Mamo a Mathematical Modeling Benchmark with Solvers.pdf",
        "analysis": {
            "benchmarks": [
                "Mamo"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5-turbo",
                "Claude-3",
                "Gemini-1",
                "DeepSeek-v2",
                "Llama-3-8B",
                "Llama-3-70B",
                "Qwen-1.5-72B-Chat",
                "Qwen-1.5-110B-Chat",
                "Mixtral-8x7B-instruct",
                "Mixtral-8x22B-instruct"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MenuCraft Interactive Menu System Design with Large Language Models": {
        "filename": "MenuCraft Interactive Menu System Design with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-3.5-turbo"
            ]
        }
    },
    "Advancing Tool-Augmented Large Language Models Integrating Insights from Errors in Inference Trees": {
        "filename": "Advancing Tool-Augmented Large Language Models Integrating Insights from Errors in Inference Trees.pdf",
        "analysis": {
            "benchmarks": [
                "ToolBench"
            ],
            "base_models": [
                "LLaMA-2-7B",
                "Mistral-7B",
                "Qwen1.5-7B",
                "Gemma-7B"
            ]
        }
    },
    "Rethinking the Role of Demonstrations What Makes In-Context Learning Work": {
        "filename": "Rethinking the Role of Demonstrations What Makes In-Context Learning Work.pdf",
        "analysis": {
            "benchmarks": [
                "GLUE",
                "SuperGLUE",
                "financial_phrasebank",
                "poem_sentiment",
                "medical_questions_pairs",
                "glue-mrpc",
                "glue-wnli",
                "climate_fever",
                "glue-rte",
                "superglue-cb",
                "sick",
                "hate_speech18",
                "ethos-national_origin",
                "ethos-race",
                "ethos-religion",
                "tweet_eval-hate",
                "tweet_eval-stance_atheism",
                "tweet_eval-stance_feminist",
                "quarel",
                "openbookqa",
                "qasc",
                "commonsense_qa",
                "ai2_arc",
                "codah",
                "superglue-copa",
                "dream",
                "quartz-with_knowledge",
                "quartz-no_knowledge"
            ],
            "base_models": [
                "GPT-2 Large (774M)",
                "MetaICL (774M)",
                "GPT-J (6B)",
                "fairseq 6.7B",
                "fairseq 13B",
                "GPT-3 (175B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "InternLM-XComposer-25 A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output": {
        "filename": "InternLM-XComposer-25 A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output.pdf",
        "analysis": {
            "benchmarks": [
                "MVBench",
                "MLVU",
                "MME-Video",
                "MMBench-Video",
                "TempCompass",
                "DocVQA",
                "ChartQA",
                "InfographicVQA",
                "TextVQA",
                "OCRBench",
                "DeepForm",
                "WikiTableQuestion (WTQ)",
                "Visual MRC",
                "TabFact",
                "MMStar",
                "RealWorldQA",
                "MathVista",
                "MMMU",
                "AI2D",
                "MME",
                "MMBench (MMB)",
                "MMBench-Chinese (MMBCN)",
                "MMBench-v1.1 (MMBv1.1)",
                "SEED-Bench Image Part (SEEDI)",
                "MM-Vet",
                "HallusionBench (HallB)",
                "MMDU",
                "Design2Code"
            ],
            "base_models": [
                "InternLM2-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Judgment of Thoughts Courtroom of the Binary Logical Reasoning in Large Language Models": {
        "filename": "Judgment of Thoughts Courtroom of the Binary Logical Reasoning in Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "BigBenchHard",
                "Winogrande",
                "Fake News",
                "SMS Spam"
            ],
            "base_models": [
                "GPT-3.5-Turbo",
                "GPT-4o"
            ]
        }
    },
    "DALL-M Context-Aware Clinical Data Augmentation with LLMs": {
        "filename": "DALL-M Context-Aware Clinical Data Augmentation with LLMs.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-IV",
                "REFLACX"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5",
                "BioGPT",
                "ClinicalBERT",
                "BioClinicalBERT",
                "Mistral",
                "Zephyr",
                "Llama2",
                "Meditron"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "From Effectiveness to Efficiency Comparative Evaluation of Code Generated by LCGMs for Bilingual Programming Questions": {
        "filename": "From Effectiveness to Efficiency Comparative Evaluation of Code Generated by LCGMs for Bilingual Programming Questions.pdf",
        "analysis": {
            "benchmarks": [
                "Custom dataset of 52 bilingual programming questions"
            ],
            "base_models": [
                "CodeGen2.5 (7B)",
                "StarCoder (15B)",
                "CodeGeeX (6B)",
                "CodeLlama (7B)",
                "DeepSeek-Coder (6.7B)",
                "GPT-3.5-Turbo"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A Survey of Large Language Models for Healthcare from Data Technology and Applications to Accountability and Ethics": {
        "filename": "A Survey of Large Language Models for Healthcare from Data Technology and Applications to Accountability and Ethics.pdf",
        "analysis": {
            "benchmarks": [
                "USMLE",
                "MedMCQA",
                "PubMedQA"
            ],
            "base_models": [
                "GPT-4",
                "LLaMA-70B",
                "PaLM-540B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT-Fathom Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond": {
        "filename": "GPT-Fathom Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond.pdf",
        "analysis": {
            "benchmarks": [
                "Natural Questions",
                "WebQuestions",
                "TriviaQA",
                "MMLU",
                "AGIEval-EN",
                "ARC-e",
                "ARC-c",
                "LAMBADA",
                "HellaSwag",
                "Winogrande",
                "BBH",
                "RACE-m",
                "RACE-h",
                "DROP",
                "GSM8K",
                "MATH",
                "HumanEval",
                "MBPP",
                "AGIEval-ZH",
                "C-Eval",
                "MGSM",
                "TyDi QA",
                "TruthfulQA",
                "RealToxicityPrompts"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5",
                "GPT-4",
                "PaLM 2",
                "Claude 2",
                "LLaMA-65B",
                "Llama 2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MoConVQ Unified Physics-Based Motion Control via Scalable Discrete Representations": {
        "filename": "MoConVQ Unified Physics-Based Motion Control via Scalable Discrete Representations.pdf",
        "analysis": {
            "benchmarks": [
                "HDM05",
                "Human3.6M"
            ],
            "base_models": [
                "GPT (Generative Pretrained Transformer)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Thrilled by Your Progress Large Language Models GPT-4 No Longer Struggle to Pass Assessments in Higher Education Programming Courses": {
        "filename": "Thrilled by Your Progress Large Language Models GPT-4 No Longer Struggle to Pass Assessments in Higher Education Programming Courses.pdf",
        "analysis": {
            "benchmarks": [
                "Python Essentials - Part 1 (Basics)",
                "Python Essentials - Part 2 (Intermediate)",
                "Practical Programming with Python"
            ],
            "base_models": [
                "GPT-4",
                "GPT-3.5 (text-davinci-003)",
                "GPT-3 (text-davinci-001)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LayoutPrompter Awaken the Design Ability of Large Language Models": {
        "filename": "LayoutPrompter Awaken the Design Ability of Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "RICO",
                "PubLayNet",
                "PosterLayout",
                "WebUI"
            ],
            "base_models": [
                "GPT-3 (text-davinci-003)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "LegalBench Prototyping a Collaborative Benchmark for Legal Reasoning": {
        "filename": "LegalBench Prototyping a Collaborative Benchmark for Legal Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "LegalBench"
            ],
            "base_models": [
                "GPT-3 (davinci)",
                "GPT-3 (curie)",
                "J1-Jumbo (178B)",
                "J1-Grande (17B)",
                "J1-Large (7.5B)"
            ]
        }
    },
    "Driving Style Alignment for LLM-powered Driver Agent": {
        "filename": "Driving Style Alignment for LLM-powered Driver Agent.pdf",
        "analysis": {
            "benchmarks": [
                "CARLA urban traffic simulator",
                "Human evaluations"
            ],
            "base_models": [
                "GPT-4"
            ]
        }
    },
    "CausalVLR A Toolbox and Benchmark for Visual-Linguistic Causal Reasoning": {
        "filename": "CausalVLR A Toolbox and Benchmark for Visual-Linguistic Causal Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "SUTD-TrafficQA",
                "TGIF-QA",
                "MSVD-QA",
                "MSRVTT-QA",
                "IU-Xray",
                "MIMIC-CXR"
            ],
            "base_models": [
                "ChatGPT",
                "ChatGLM"
            ]
        }
    },
    "On the Inductive Bias of Stacking Towards Improving Reasoning": {
        "filename": "On the Inductive Bias of Stacking Towards Improving Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "TriviaQA",
                "TyDiQA",
                "NaturalQuestions",
                "WebQuestions",
                "SQuADv2",
                "DROP",
                "QuAC",
                "CoQA",
                "ASDiv",
                "MAWPS",
                "SVAMP",
                "GSM8k"
            ],
            "base_models": [
                "BERT (Base and Large)",
                "UL2 (1B, 2B, and 8B parameters)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Towards Effective Disambiguation for Machine Translation with Large Language Models": {
        "filename": "Towards Effective Disambiguation for Machine Translation with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "DiBiMT",
                "FLORES200"
            ],
            "base_models": [
                "BLOOMZ-176B",
                "LLaMA-65B",
                "BLOOM-176B",
                "LLaMA-7B",
                "Alpaca-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Large Language Models for Scientific Synthesis Inference and Explanation": {
        "filename": "Large Language Models for Scientific Synthesis Inference and Explanation.pdf",
        "analysis": {
            "benchmarks": [
                "BBBP",
                "ClinTox",
                "Tox21",
                "SIDER",
                "BACE",
                "HIV",
                "ESOL",
                "FreeSolv",
                "Lipophilicity",
                "QM9"
            ],
            "base_models": [
                "Falcon 7b",
                "Falcon 40b",
                "Galactica-6.7b",
                "Galactica-30b"
            ]
        }
    },
    "UQ at SMM4H 2023 ALEX for Public Health Analysis with Social Media": {
        "filename": "UQ at SMM4H 2023 ALEX for Public Health Analysis with Social Media.pdf",
        "analysis": {
            "benchmarks": [
                "SMM4H 2023 Task 1",
                "SMM4H 2023 Task 2",
                "SMM4H 2023 Task 4"
            ],
            "base_models": [
                "BERT",
                "RoBERTa",
                "XLNet",
                "BERTweet-Large",
                "CT-BERT (v2)",
                "GPT-3.5"
            ]
        }
    },
    "All in an Aggregated Image for In-Image Learning": {
        "filename": "All in an Aggregated Image for In-Image Learning.pdf",
        "analysis": {
            "benchmarks": [
                "MathVista",
                "VQA",
                "HallusionBench"
            ],
            "base_models": [
                "GPT-4V"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "GPT-35 GPT-4 or BARD Evaluating LLMs reasoning ability in zero-shot setting and performance boosting through prompts": {
        "filename": "GPT-35 GPT-4 or BARD Evaluating LLMs reasoning ability in zero-shot setting and performance boosting through prompts.pdf",
        "analysis": {
            "benchmarks": [
                "EntailmentBank",
                "bAbI (task 15)",
                "bAbI (task 16)",
                "CLUTRR",
                "𝛼NLI",
                "Math",
                "CommonsenseQA",
                "PiQA",
                "Pep-3k",
                "E-Care",
                "HotpotQA"
            ],
            "base_models": [
                "GPT-3.5",
                "GPT-4",
                "BARD (based on LaMDA)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Prompting and Evaluating Large Language Models for Proactive Dialogues Clarification Target-guided and Non-collaboration": {
        "filename": "Prompting and Evaluating Large Language Models for Proactive Dialogues Clarification Target-guided and Non-collaboration.pdf",
        "analysis": {
            "benchmarks": [
                "Abg-CoQA",
                "PACIFIC",
                "CraigslistBargain",
                "OTTers",
                "TGConv"
            ],
            "base_models": [
                "ChatGPT",
                "Vicuna-13B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Libra Leveraging Temporal Images for Biomedical Radiology Analysis": {
        "filename": "Libra Leveraging Temporal Images for Biomedical Radiology Analysis.pdf",
        "analysis": {
            "benchmarks": [
                "MIMIC-CXR"
            ],
            "base_models": [
                "RAD-DINO",
                "Meditron-7B (based on Llama-2)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "MAgICoRe Multi-Agent Iterative Coarse-to-Fine Refinement for Reasoning": {
        "filename": "MAgICoRe Multi-Agent Iterative Coarse-to-Fine Refinement for Reasoning.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "SVAMP",
                "MATH",
                "MMLU",
                "SAT"
            ],
            "base_models": [
                "Llama-3-8B",
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VL-ICL Bench The Devil in the Details of Multimodal In-Context Learning": {
        "filename": "VL-ICL Bench The Devil in the Details of Multimodal In-Context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "Fast Open-Ended MiniImageNet",
                "CLEVR Count Induction",
                "Operator Induction",
                "Interleaved Operator Induction",
                "TextOCR",
                "Fast Matching MiniImageNet",
                "Text-to-Image Fast MiniImageNet",
                "CoBSAT",
                "Fast Counting",
                "Fast Attribute Matching"
            ],
            "base_models": [
                "GPT-4V",
                "LLaVA-OneVision-72B",
                "InternLM-X2d5",
                "Phi3-Vision (4B)",
                "SEED-LLaMA-14B",
                "Emu2-Gen (34B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "BadChain Backdoor Chain-of-Thought Prompting for Large Language Models": {
        "filename": "BadChain Backdoor Chain-of-Thought Prompting for Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "GSM8K",
                "MATH",
                "ASDiv",
                "CSQA",
                "StrategyQA",
                "Letter"
            ],
            "base_models": [
                "Llama2",
                "GPT-3.5",
                "PaLM2",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "WirelessLLM Empowering Large Language Models Towards Wireless Intelligence": {
        "filename": "WirelessLLM Empowering Large Language Models Towards Wireless Intelligence.pdf",
        "analysis": {
            "benchmarks": [
                "TeleQnA"
            ],
            "base_models": [
                "GPT-4",
                "Claude-3 Opus"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "VoCoT Unleashing Visually Grounded Multi-Step Reasoning in Large Multi-Modal Models": {
        "filename": "VoCoT Unleashing Visually Grounded Multi-Step Reasoning in Large Multi-Modal Models.pdf",
        "analysis": {
            "benchmarks": [
                "GQA",
                "MMBench",
                "SEED",
                "VSR",
                "EmbSpatial",
                "CLEVR",
                "V-Star",
                "Winoground",
                "POPE",
                "AMBER"
            ],
            "base_models": [
                "GPT-4V",
                "Mistral-7B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Bayesian Optimization of Catalysts With In-context Learning": {
        "filename": "Bayesian Optimization of Catalysts With In-context Learning.pdf",
        "analysis": {
            "benchmarks": [
                "ESOL dataset",
                "catalyst dataset for oxidative coupling of methane"
            ],
            "base_models": [
                "GPT-3",
                "GPT-3.5",
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Self-Discover Large Language Models Self-Compose Reasoning Structures": {
        "filename": "Self-Discover Large Language Models Self-Compose Reasoning Structures.pdf",
        "analysis": {
            "benchmarks": [
                "BigBench-Hard",
                "Thinking for Doing (T4D)",
                "MATH"
            ],
            "base_models": [
                "GPT-4",
                "PaLM 2-L",
                "Llama2-70B"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Security of AI Agents": {
        "filename": "Security of AI Agents.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "gpt-3.5-turbo",
                "gpt-4-turbo"
            ]
        }
    },
    "Automating Traffic Model Enhancement with AI Research Agent": {
        "filename": "Automating Traffic Model Enhancement with AI Research Agent.pdf",
        "analysis": {
            "benchmarks": [
                "Shanghai car-following dataset",
                "NGSIM trajectory dataset",
                "PeMS08 dataset"
            ],
            "base_models": [
                "GPT-4"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Stepwise Self-Consistent Mathematical Reasoning with Large Language Models": {
        "filename": "Stepwise Self-Consistent Mathematical Reasoning with Large Language Models.pdf",
        "analysis": {
            "benchmarks": [
                "TriMaster100",
                "MATH level 5"
            ],
            "base_models": [
                "GPT-3.5"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "PEER A Collaborative Language Model": {
        "filename": "PEER A Collaborative Language Model.pdf",
        "analysis": {
            "benchmarks": [
                "Wikipedia edit history",
                "Natural Edits"
            ],
            "base_models": [
                "T5 (3B)",
                "T5 (11B)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Foundational Models Defining a New Era in Vision A Survey and Outlook": {
        "filename": "Foundational Models Defining a New Era in Vision A Survey and Outlook.pdf",
        "analysis": {
            "benchmarks": [
                "COCO",
                "LVIS",
                "ImageNet1k"
            ],
            "base_models": [
                "GPT-3",
                "PaLM-540B",
                "CLIP",
                "ViT",
                "BERT"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "A LLM-based Controllable Scalable Human-Involved User Simulator Framework for Conversational Recommender Systems": {
        "filename": "A LLM-based Controllable Scalable Human-Involved User Simulator Framework for Conversational Recommender Systems.pdf",
        "analysis": {
            "benchmarks": [
                "ReDial",
                "OpenDialKG",
                "MovieLens"
            ],
            "base_models": [
                "ChatGPT (GPT-3.5-turbo-0613)",
                "BART"
            ]
        }
    },
    "Synthesize Step-by-Step Tools Templates and LLMs as Data Generators for Reasoning-Based Chart VQA": {
        "filename": "Synthesize Step-by-Step Tools Templates and LLMs as Data Generators for Reasoning-Based Chart VQA.pdf",
        "analysis": {
            "benchmarks": [
                "ChartQA",
                "PlotQA"
            ],
            "base_models": [
                "MPT-7B",
                "ViT (in CLIP)"
            ],
            "note": "Analysis based on truncated paper text"
        }
    },
    "Use of LLMs for Illicit Purposes Threats Prevention Measures and Vulnerabilities": {
        "filename": "Use of LLMs for Illicit Purposes Threats Prevention Measures and Vulnerabilities.pdf",
        "analysis": {
            "benchmarks": [],
            "base_models": [
                "GPT-2",
                "GPT-3",
                "GPT-4",
                "GPT-J",
                "GPT-Neo",
                "T5",
                "OPT",
                "LLaMA-7B",
                "MiniGPT-4",
                "Gopher"
            ],
            "note": "Analysis based on truncated paper text"
        }
    }
}