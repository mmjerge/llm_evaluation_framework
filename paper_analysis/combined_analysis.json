{
  "Progress measures for grokking via mechanistic interpretability": {
    "filename": "Progress measures for grokking via mechanistic interpretability.pdf",
    "analysis": {
      "benchmarks": [
        "modular addition task"
      ],
      "models": [
        "small transformers",
        "one-layer transformer",
        "two-layer transformers",
        "mainline model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning Language Representations with Logical Inductive Bias": {
    "filename": "Learning Language Representations with Logical Inductive Bias.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "SQuAD 2.0",
        "FOLIO"
      ],
      "models": [
        "FOLNet",
        "BERT",
        "RoBERTa",
        "DeBERTa",
        "ALBERT",
        "Megatron"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatGPT Asks BLIP-2 Answers Automatic Questioning Towards Enriched Visual Descriptions": {
    "filename": "ChatGPT Asks BLIP-2 Answers Automatic Questioning Towards Enriched Visual Descriptions.pdf",
    "analysis": {
      "benchmarks": [
        "COCO",
        "Conceptual Caption",
        "WikiArt",
        "Pascal VOC"
      ],
      "models": [
        "ChatCaptioner",
        "BLIP-2",
        "ChatGPT",
        "InstructGPT",
        "FLAN-T5 11B",
        "OPT 6.7B"
      ]
    }
  },
  "BadLlama cheaply removing safety fine-tuning from Llama 2-Chat 13B": {
    "filename": "BadLlama cheaply removing safety fine-tuning from Llama 2-Chat 13B.pdf",
    "analysis": {
      "benchmarks": [
        "AdvBench",
        "RefusalBench"
      ],
      "models": [
        "Llama 2-Chat 13B",
        "BadLlama",
        "WizardLM-1.0-uncensored-Llama2-13b",
        "WizardLM-uncensored"
      ]
    }
  },
  "Sleeper Social Bots a new generation of AI disinformation bots are already a political threat": {
    "filename": "Sleeper Social Bots a new generation of AI disinformation bots are already a political threat.pdf",
    "analysis": {
      "benchmarks": [
        "Mastodon server"
      ],
      "models": [
        "ChatGPT-driven bots",
        "GPT-4 Turbo",
        "sleeper social bots"
      ]
    }
  },
  "PromptNER Prompting For Named Entity Recognition": {
    "filename": "PromptNER Prompting For Named Entity Recognition.pdf",
    "analysis": {
      "benchmarks": [
        "CoNLL",
        "GENIA",
        "FewNERD",
        "CrossNER"
      ],
      "models": [
        "PromptNER T5XXL",
        "PromptNER GPT3.5",
        "PromptNER GPT4",
        "COPNER",
        "EntLM",
        "FactMix",
        "ProML",
        "UIE",
        "CONTaiNER",
        "PMR",
        "BCL",
        "SpanProto",
        "PACL",
        "Meta Learning",
        "DeepStruct",
        "CP-NER",
        "LANER",
        "EnTDA"
      ]
    }
  },
  "WikiWhy Answering and Explaining Cause-and-Effect Questions": {
    "filename": "WikiWhy Answering and Explaining Cause-and-Effect Questions.pdf",
    "analysis": {
      "benchmarks": [
        "WIKIWHY",
        "HotpotQA",
        "CoS-E",
        "eQASC",
        "CausalQA",
        "EntailmentBank"
      ],
      "models": [
        "GPT-3",
        "GPT-2",
        "RoBERTa",
        "Big Bird",
        "Fusion-in-Decoder (FiD)",
        "BM25",
        "Dense Passage Retriever (DPR)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding the Effect of Noise in LLM Training Data with Algorithmic Chains of Thought": {
    "filename": "Understanding the Effect of Noise in LLM Training Data with Algorithmic Chains of Thought.pdf",
    "analysis": {
      "benchmarks": [
        "Traced Integer (TInt) framework"
      ],
      "models": [
        "Pythia-410m",
        "gpt-4",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Compiler Optimization": {
    "filename": "Large Language Models for Compiler Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "AI-SOCO",
        "ExeBench",
        "POJ-104",
        "Transcoder",
        "CSmith",
        "YARPGen"
      ],
      "models": [
        "7B-parameter transformer model",
        "LLaMa 2",
        "MLGO",
        "PrograML",
        "AutoPhase",
        "Coreset-NVP",
        "Autotuner"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Distilling mathematical reasoning capabilities into Small Language Models": {
    "filename": "Distilling mathematical reasoning capabilities into Small Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "ASDiv",
        "SVAMP",
        "MultiArith"
      ],
      "models": [
        "CodeT5-Small",
        "CodeT5-Base",
        "CodeT5-Large",
        "GPT-4",
        "ChatGPT",
        "Claude-2",
        "PaLM-2",
        "Llama-2",
        "CodeLLaMA",
        "Platypus-2",
        "WizardMath",
        "TORA",
        "Ho et al. (GPT-3-ada)",
        "Fu et al. (FlanT5)",
        "Shridhar et al. (GPT-2)",
        "Zhu et al.",
        "EoTD",
        "ETD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InternLM-Math Open Math Large Language Models Toward Verifiable Reasoning": {
    "filename": "InternLM-Math Open Math Large Language Models Toward Verifiable Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "Hungary math exam",
        "MathBench-ZH",
        "MiniF2F"
      ],
      "models": [
        "InternLM-Math",
        "InternLM2-Base",
        "Minerva",
        "Llemma",
        "MetaMath-Llama2-7B",
        "MetaMath-Mistral-7B",
        "MetaMath-Llemma-7B",
        "MetaMath-InternLM2-Math-Base-7B",
        "MetaMath-InternLM2-Math-Base-20B",
        "MetaMath-Llemma-34B",
        "ReProver",
        "LLMStep",
        "Code-Llama-7B",
        "Code-Llama-34B",
        "Mistral-7B-v0.1",
        "Mixtral-8x7B-v0.1",
        "Deepseek-coder-7B-v1.5-Base",
        "Deepseek-math-7B-Base",
        "InternLM2-7B-Base",
        "InternLM2-20B-Base",
        "InternLM2-Math-7B-Base",
        "InternLM2-Math-20B-Base",
        "Qwen-7B-Chat",
        "DeepSeek-7B-Chat",
        "InternLM2-Chat-7B",
        "ChatGLM3-6B",
        "InternLM2-Math-7B",
        "InternLM2-Chat-20B",
        "InternLM2-Math-20B",
        "Qwen-72B-Chat",
        "DeepSeek-67B-Chat",
        "ChatGPT",
        "GPT-4",
        "DeepSeek-Coder-Instruct-7B",
        "MathCODER-CL-7B",
        "DeepSeek-Coder-Instruct-1.5-7B",
        "ToRA-7B",
        "InternLM2-Math-7B",
        "MathCODER-CL-13B",
        "MathCODER-CL-34B",
        "ToRA-13B",
        "ToRA-Code-34B",
        "InternLM2-Chat-20B",
        "InternLM2-Math-20B",
        "ToRA-70B",
        "GPT-4 Code Interpreter"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Rethinking Decision Transformer via Hierarchical Reinforcement Learning": {
    "filename": "Rethinking Decision Transformer via Hierarchical Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Gym-Mujoco",
        "AntMaze",
        "FrankaKitchen",
        "D4RL",
        "halfcheetah-medium-v2",
        "hopper-medium-v2",
        "walker2d-medium-v2",
        "halfcheetah-medium-replay-v2",
        "hopper-medium-replay-v2",
        "walker2d-medium-replay-v2",
        "halfcheetah-medium-expert-v2",
        "hopper-medium-expert-v2",
        "walker2d-medium-expert-v2",
        "antmaze-umaze-v2",
        "antmaze-umaze-diverse-v2",
        "antmaze-medium-play-v2",
        "antmaze-medium-diverse-v2",
        "antmaze-large-play-v2",
        "antmaze-large-diverse-v2",
        "kitchen-complete-v0",
        "kitchen-partial-v0",
        "kitchen-mixed-v0"
      ],
      "models": [
        "Decision Transformer (DT)",
        "Autotuned Decision Transformer (ADT)",
        "Value-prompted Autotuned Decision Transformer (V-ADT)",
        "Goal-prompted Autotuned Decision Transformer (G-ADT)",
        "TD3+BC",
        "CQL",
        "IQL",
        "Q-Learning Decision Transformer (QLDT)",
        "RvS-R/G",
        "HIQL",
        "Waypoint Transformer (WT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Impact of LLM-based Review Comment Generation in Practice A Mixed Open-Closed-source User Study": {
    "filename": "Impact of LLM-based Review Comment Generation in Practice A Mixed Open-Closed-source User Study.pdf",
    "analysis": {
      "benchmarks": [
        "Mozilla",
        "Ubisoft"
      ],
      "models": [
        "RevMate",
        "GPT4o",
        "T5",
        "CodeT5",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On Overcoming Miscalibrated Conversational Priors in LLM-based Chatbots": {
    "filename": "On Overcoming Miscalibrated Conversational Priors in LLM-based Chatbots.pdf",
    "analysis": {
      "benchmarks": [
        "OpenAssistant"
      ],
      "models": [
        "GPT-4",
        "RLHF policy",
        "CLARIFY FLEX",
        "meta-policy",
        "\u03c0RLHF",
        "\u03c0Clarify",
        "\u03c0Hedge"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Functional Benchmarks for Robust Evaluation of Reasoning Performance and the Reasoning Gap": {
    "filename": "Functional Benchmarks for Robust Evaluation of Reasoning Performance and the Reasoning Gap.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "MATH()",
        "GSM8K",
        "HumanEval",
        "MBPP",
        "Natural2Code",
        "HellaSwag",
        "Winogrande",
        "PIQA",
        "SIQA",
        "OpenbookQA",
        "ARC-Easy/Challenge",
        "CommonsenseQA",
        "NaturalQuestions",
        "TriviaQA",
        "BoolQ",
        "QuAC",
        "DROP",
        "MMLU",
        "HELM",
        "BBH",
        "AGI Eval"
      ],
      "models": [
        "GPT3.5",
        "GPT4",
        "Claude 2.1",
        "Mixtral Medium",
        "Mixtral 7x8B MoE",
        "Mixtral 7x8B MoE Instruct",
        "LLaMA 2 70B",
        "WizardCoder Python 34B",
        "Yi 34B",
        "Yi Chat 34B",
        "StripedHypena Nous",
        "Hessian 7B",
        "Qwen 7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Energy-Based Diffusion Language Models for Text Generation": {
    "filename": "Energy-Based Diffusion Language Models for Text Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Text8",
        "OpenWebText",
        "Penn Tree Bank (PTB)",
        "Wikitext",
        "LM1B",
        "Lambada",
        "AG News",
        "Pubmed",
        "Arxiv"
      ],
      "models": [
        "Energy-based Diffusion Language Model (EDLM)",
        "Discrete Diffusion Model (D3PM)",
        "Score Entropy Discrete Diffusion model (SEDD)",
        "Masked Diffusion Language Model (MDLM)",
        "Plaid",
        "Bayesian Flow Network",
        "Any-order Autoregressive Models ARDM",
        "MAC",
        "IAF/SCF",
        "AR Argmax Flow",
        "AR Discrete Flow",
        "Multinomial Diffusion",
        "Transformer AR",
        "EDLM-AR",
        "EDLM-coAR",
        "EDLM-NCE",
        "SUNDAE",
        "Ssd-LM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InstructRAG Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales": {
    "filename": "InstructRAG Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales.pdf",
    "analysis": {
      "benchmarks": [
        "PopQA",
        "TriviaQA",
        "Natural Questions",
        "ASQA",
        "2WikiMultiHopQA"
      ],
      "models": [
        "INSTRUCT RAG",
        "vanilla RAG",
        "Llama-3-Instruct 8B",
        "Llama-3-Instruct 70B",
        "ChatGPT",
        "Self-RAG",
        "RetRobust",
        "vanilla zero-shot prompting",
        "in-context RALM",
        "few-shot demonstration with instruction",
        "vanilla supervised fine-tuning"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "StructuredRAG JSON Response Formatting with Large Language Models": {
    "filename": "StructuredRAG JSON Response Formatting with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "StructuredRAG",
        "WikiQuestions"
      ],
      "models": [
        "Gemini 1.5 Pro",
        "Llama 3 8B-instruct"
      ]
    }
  },
  "FrugalGPT How to Use Large Language Models While Reducing Cost and Improving Performance": {
    "filename": "FrugalGPT How to Use Large Language Models While Reducing Cost and Improving Performance.pdf",
    "analysis": {
      "benchmarks": [
        "HEADLINES",
        "OVERRULING",
        "COQA"
      ],
      "models": [
        "FrugalGPT",
        "GPT-4",
        "ChatGPT",
        "GPT-3",
        "GPT-J",
        "J1-L",
        "J1-Grande",
        "J1-Jumbo",
        "CoHere Xlarge",
        "ForeFrontAI QA",
        "GPT-Neo",
        "DistilBERT"
      ]
    }
  },
  "Beyond Classification Financial Reasoning in State-of-the-Art Language Models": {
    "filename": "Beyond Classification Financial Reasoning in State-of-the-Art Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "sFIOG"
      ],
      "models": [
        "LLama",
        "Galactica",
        "GPT-J",
        "Pythia(2.8B)",
        "vicuna-13b-delta-v1.1",
        "dolly-v2-3b",
        "dolly-v1-6b",
        "galpaca-6.7b"
      ]
    }
  },
  "Math Word Problem Solving by Generating Linguistic Variants of Problem Statements": {
    "filename": "Math Word Problem Solving by Generating Linguistic Variants of Problem Statements.pdf",
    "analysis": {
      "benchmarks": [
        "MAWPS",
        "SVAMP",
        "PARAMAWPS"
      ],
      "models": [
        "DeBERTa",
        "text-davinci-003",
        "gpt-3.5-turbo",
        "Transformer",
        "DNS",
        "MathEN",
        "GroupATT",
        "RNNEncDec",
        "RNNVAE",
        "BERT",
        "RoBERTa",
        "ROBERTA-DEDUCT REASONER"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automating Customer Needs Analysis A Comparative Study of Large Language Models in the Travel Industry": {
    "filename": "Automating Customer Needs Analysis A Comparative Study of Large Language Models in the Travel Industry.pdf",
    "analysis": {
      "benchmarks": [
        "TripAdvisor"
      ],
      "models": [
        "GPT-4",
        "Gemini",
        "Mistral 7B",
        "Llama 2 7B",
        "Llama 2 13B",
        "Phi-2",
        "Mixtral",
        "Gemma",
        "GPT-3.5"
      ]
    }
  },
  "Towards Unlocking Insights from Logbooks Using AI": {
    "filename": "Towards Unlocking Insights from Logbooks Using AI.pdf",
    "analysis": {
      "benchmarks": [
        "DIII-D",
        "Alcator C-Mod",
        "SINBAD-ARES",
        "BNL eLog",
        "DESY European XFEL",
        "Fermilab ADEL"
      ],
      "models": [
        "Retrieval Augmented Generation (RAG)",
        "llama2-70b",
        "AccGPT",
        "mixtral-8x7b-instruct-v0.1",
        "SimCSE",
        "sci-bert-cased",
        "sci-bert-uncased",
        "all-MiniLM-L6-v2",
        "Mistral-7B-Instruct-v0.2",
        "Doc2Vec",
        "all-mpnet-base-v2",
        "mxbai-rerank-base-v1",
        "ms-marco-MiniLM-L-12-v2",
        "mxbai-embed-large-v1",
        "nomic-embed-text-v1"
      ]
    }
  },
  "Dissociating language and thought in large language models a cognitive perspective": {
    "filename": "Dissociating language and thought in large language models a cognitive perspective.pdf",
    "analysis": {
      "benchmarks": [
        "BLiMP",
        "SyntaxGym",
        "GLUE",
        "WinoGrande",
        "BIG-bench"
      ],
      "models": [
        "GPT-2",
        "GPT-3",
        "GPT-4",
        "BERT",
        "RNN",
        "3-gram model",
        "Codex"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Polymath A Challenging Multi-modal Mathematical Reasoning Benchmark": {
    "filename": "Polymath A Challenging Multi-modal Mathematical Reasoning Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "POLYMATH"
      ],
      "models": [
        "Claude-3.5 Sonnet",
        "GPT-4o",
        "Gemini-1.5 Pro",
        "Claude-3 Sonnet",
        "Claude-3 Haiku",
        "LLaVA (34B)",
        "ShareGPT4V",
        "LLaVA-v1.6 Mistral (7B)",
        "LLaVA-v1.6 Vicuna (13B)",
        "G-LLaVA (7B)",
        "G-LLaVA (13B)",
        "Qwen2 VL (2B) Instruct",
        "Reka Flash",
        "Llama-3 (70B)",
        "Mistral Large",
        "OpenAI o1-preview",
        "OpenAI o1-mini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "StarCoder may the source be with you": {
    "filename": "StarCoder may the source be with you.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
    }
  },
  "IfQA A Dataset for Open-domain Question Answering under Counterfactual Presuppositions": {
    "filename": "IfQA A Dataset for Open-domain Question Answering under Counterfactual Presuppositions.pdf",
    "analysis": {
      "benchmarks": [
        "IfQA"
      ],
      "models": [
        "GPT-3",
        "chain-of-thought (CoT) reasoning with GPT-3",
        "RAG",
        "FiD",
        "BM25",
        "DPR",
        "GENREAD"
      ]
    }
  },
  "Multi-step Jailbreaking Privacy Attacks on ChatGPT": {
    "filename": "Multi-step Jailbreaking Privacy Attacks on ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "Enron Email Dataset",
        "Institutional Pages"
      ],
      "models": [
        "ChatGPT",
        "New Bing",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization": {
    "filename": "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization.pdf",
    "analysis": {
      "benchmarks": [
        "NLV-Corpus",
        "Quda"
      ],
      "models": [
        "GPT-4",
        "Gemini-Pro",
        "Llama3",
        "Mixtral"
      ]
    }
  },
  "A Survey on Measuring and Mitigating Reasoning Shortcuts in Machine Reading Comprehension": {
    "filename": "A Survey on Measuring and Mitigating Reasoning Shortcuts in Machine Reading Comprehension.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD",
        "RACE",
        "HotpotQA",
        "DROP",
        "MuSiQue",
        "STREET",
        "Adversarial SQuAD",
        "AdvRACE",
        "Natural-Perturbed-QA",
        "AdversarialQA",
        "AddSent",
        "AddSentDiverse",
        "AddDoc",
        "SEARs",
        "Word-Replace",
        "Ques-Paraphrase",
        "Modify-Option",
        "Mix-Attack",
        "Contrast Sets",
        "SAM",
        "Break, Perturb, Build",
        "2WikiMultiHopQA",
        "StrategyQA",
        "Dynabench",
        "Natural Questions",
        "TriviaQA",
        "NewsQA",
        "SWAG"
      ],
      "models": [
        "Transformer-based models",
        "BiDAF",
        "BERT",
        "UnifiedQA",
        "InfoBERT",
        "Learned Mixin",
        "Confidence Regularization",
        "Underparameterized Weak Models",
        "T5",
        "GPT-3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HuggingGPT Solving AI Tasks with ChatGPT and its Friends in Hugging Face": {
    "filename": "HuggingGPT Solving AI Tasks with ChatGPT and its Friends in Hugging Face.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "HuggingGPT",
        "ChatGPT",
        "lllyasviel/ControlNet",
        "facebook/detr-resnet-101",
        "nlpconnet/vit-gpt2-image-captioning",
        "google/vit",
        "hustvl/yolos-tiny",
        "TahaDouaji/detr-doc-table-detection",
        "openpose",
        "lllyasviel/sd-controlnet-openpose",
        "google/vit-base-patch16-224",
        "facebook/fastspeech2-en-ljspeech"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exposing Attention Glitches with Flip-Flop Language Modeling": {
    "filename": "Exposing Attention Glitches with Flip-Flop Language Modeling.pdf",
    "analysis": {
      "benchmarks": [
        "flip-flop language modeling (FFLM)",
        "Long Range Arena",
        "BIG-Bench"
      ],
      "models": [
        "Transformer FFLM",
        "LSTM",
        "GPT-3.5",
        "GPT-4",
        "GPT-NeoX 20B",
        "Pythia 12B",
        "GPT-2 1.5B",
        "GPT-2 774M",
        "GPT-2 117M"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Active Learning Principles for In-Context Learning with Large Language Models": {
    "filename": "Active Learning Principles for In-Context Learning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Crossfit",
        "glue-rte"
      ],
      "models": [
        "GPT-2",
        "GPT-Neox",
        "GPT",
        "OPT",
        "GPT-2-medium",
        "GPT-large",
        "GPT-j",
        "GPT-Neox (20B)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "STBLLM Breaking the 1-Bit Barrier with Structured Binary LLMs": {
    "filename": "STBLLM Breaking the 1-Bit Barrier with Structured Binary LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Wikitext2",
        "C4",
        "PTB",
        "Winogrande",
        "OBQA",
        "Hellaswag",
        "BoolQ",
        "ARC",
        "RTE"
      ],
      "models": [
        "STBLLM",
        "LLaMA-1",
        "LLaMA-2",
        "LLaMA-3",
        "OPT",
        "Mistral",
        "BiLLM",
        "PB-LLM",
        "RTN",
        "GPTQ"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement": {
    "filename": "Enhancing the Code Debugging Ability of LLMs via Communicative Agent Based Data Refinement.pdf",
    "analysis": {
      "benchmarks": [
        "DEBUG EVAL",
        "DebugBench",
        "LiveCodeBench",
        "AtCoder"
      ],
      "models": [
        "NeuDebugger",
        "MASTER",
        "DeepSeek-Coder-6.7B-Ins",
        "Llama3-8B-Ins",
        "GPT-4o-mini-0718",
        "GPT-3.5-Turbo-0125",
        "DeepSeek-V2-0628",
        "DeepSeek-Coder-V2-0724",
        "Llama3-70B-Ins",
        "Qwen2-72B-Ins",
        "DSCoder-33B-Ins",
        "Llama2-7B-Ins",
        "CodeLlama-7B-Ins",
        "CodeQwen1.5-7B-Ins",
        "DeepSeek-LLM-7B-Ins",
        "DSCoder-6.7B-Ins"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Advancing GenAI Assisted Programming-A Comparative Study on Prompt Efficiency and Code Quality Between GPT-4 and GLM-4": {
    "filename": "Advancing GenAI Assisted Programming-A Comparative Study on Prompt Efficiency and Code Quality Between GPT-4 and GLM-4.pdf",
    "analysis": {
      "benchmarks": [
        "Snake game"
      ],
      "models": [
        "GPT-4",
        "GLM-4"
      ]
    }
  },
  "Improving In-Context Learning in Diffusion Models with Visual Context-Modulated Prompts": {
    "filename": "Improving In-Context Learning in Diffusion Models with Visual Context-Modulated Prompts.pdf",
    "analysis": {
      "benchmarks": [
        "Instruct Pixel-to-Pixel dataset",
        "MultiGen-20M",
        "Instruct-Pix2Pix dataset"
      ],
      "models": [
        "iPromptDiff",
        "ControlNet",
        "PromptDiff",
        "iPromptDiff-MG20M",
        "Painter",
        "SegGPT"
      ]
    }
  },
  "LLM-DERA Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain": {
    "filename": "LLM-DERA Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain.pdf",
    "analysis": {
      "benchmarks": [
        "Resume",
        "Coal"
      ],
      "models": [
        "LLM-DER",
        "GPT-3.5-turbo",
        "BERT",
        "LatticeLSTM",
        "FLAT",
        "PCBERT"
      ]
    }
  },
  "QASnowball An Iterative Bootstrapping Framework for High-Quality Question-Answering Data Generation": {
    "filename": "QASnowball An Iterative Bootstrapping Framework for High-Quality Question-Answering Data Generation.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD",
        "TriviaQA-wiki",
        "TriviaQA-web",
        "HotpotQA",
        "CMRC",
        "DuReader",
        "SQuAD-zh",
        "DRCD"
      ],
      "models": [
        "QASnowball",
        "PERT",
        "PAQ"
      ]
    }
  },
  "Thought Cloning Learning to Think while Acting by Imitating Human Thinking": {
    "filename": "Thought Cloning Learning to Think while Acting by Imitating Human Thinking.pdf",
    "analysis": {
      "benchmarks": [
        "BabyAI"
      ],
      "models": [
        "Thought Cloning",
        "Behavioral Cloning",
        "TC w/o Imitating Thought",
        "Oracle Solver",
        "Oracle Thoughts + TC Learned Control"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NLPBench Evaluating Large Language Models on Solving NLP Problems": {
    "filename": "NLPBench Evaluating Large Language Models on Solving NLP Problems.pdf",
    "analysis": {
      "benchmarks": [
        "NLPBench"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "PaLM-2",
        "LLAMA-2 (13b)",
        "LLAMA-2 (70b)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Synthetic Prompting Generating Chain-of-Thought Demonstrations for Large Language Models": {
    "filename": "Synthetic Prompting Generating Chain-of-Thought Demonstrations for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "GSM-Hard",
        "SVAMP",
        "ASDiv",
        "SingleOp",
        "Colored Objects",
        "Repeat Copy"
      ],
      "models": [
        "Synthetic Prompting",
        "Vanilla Synthetic Prompting",
        "Direct Prompting",
        "CoT Prompting",
        "PAL Prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LProtector An LLM-driven Vulnerability Detection System": {
    "filename": "LProtector An LLM-driven Vulnerability Detection System.pdf",
    "analysis": {
      "benchmarks": [
        "Big-Vul"
      ],
      "models": [
        "LProtector",
        "VulDeePecker",
        "Reveal",
        "LProtector without RAG",
        "LProtector without CoT",
        "LProtector without RAG & CoT"
      ]
    }
  },
  "Introspective Planning Aligning Robots Uncertainty with Inherent Task Ambiguity": {
    "filename": "Introspective Planning Aligning Robots Uncertainty with Inherent Task Ambiguity.pdf",
    "analysis": {
      "benchmarks": [
        "Safe Mobile Manipulation",
        "Mobile Manipulation",
        "Tabletop Rearrangement"
      ],
      "models": [
        "Introspective Planning",
        "KnowNo",
        "Prompt Set",
        "Prompt Set + CoT",
        "Retrieval-Q-CoT",
        "Auto-CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language model acceptability judgements are not always robust to context": {
    "filename": "Language model acceptability judgements are not always robust to context.pdf",
    "analysis": {
      "benchmarks": [
        "BLiMP",
        "SyntaxGym",
        "Wikipedia",
        "WikiText-103"
      ],
      "models": [
        "GPT-2",
        "OPT-125M",
        "OPT-350M",
        "OPT-1.3B",
        "OPT-2.7B",
        "OPT-6.7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AlphaBlock Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation": {
    "filename": "AlphaBlock Embodied Finetuning for Vision-Language Reasoning in Robot Manipulation.pdf",
    "analysis": {
      "benchmarks": [
        "AlphaBlock"
      ],
      "models": [
        "AlphaBlock",
        "CogLoop",
        "MiniGPT-4",
        "ChatGPT",
        "GPT-4",
        "SayCan",
        "Text2Motion",
        "ChatGPT for Robotics",
        "LLaMA",
        "Vicuna",
        "ViT",
        "Q-former",
        "Vision Adapter",
        "Vision Tokenizer",
        "LA V A"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Encyclopedic VQA Visual questions about detailed properties of fine-grained categories": {
    "filename": "Encyclopedic VQA Visual questions about detailed properties of fine-grained categories.pdf",
    "analysis": {
      "benchmarks": [
        "Encyclopedic-VQA",
        "OK-VQA",
        "A-OKVQA",
        "FVQA",
        "S3VQA",
        "KVQA",
        "iNaturalist 2021",
        "Google Landmarks Dataset v2"
      ],
      "models": [
        "PaLI",
        "PaLM",
        "GPT-3",
        "KAT",
        "REVEAL",
        "PromptCap",
        "KRISP",
        "REVEAL",
        "Lens-based retrieval",
        "CLIP-based retrieval"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding Social Reasoning in Language Models with Language Models": {
    "filename": "Understanding Social Reasoning in Language Models with Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BigToM",
        "SocialIQA",
        "ToMi"
      ],
      "models": [
        "GPT-4",
        "GPT-3",
        "text-davinci-003",
        "gpt-3.5-turbo",
        "Claude-v1.3",
        "Claude-2",
        "LLaMa-65B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Truth or Deceit A Bayesian Decoding Game Enhances Consistency and Reliability": {
    "filename": "Truth or Deceit A Bayesian Decoding Game Enhances Consistency and Reliability.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "ARC-Easy",
        "ARC-Challenge",
        "RACE-High",
        "GSM8K",
        "PubMedQA",
        "MMLU-Medical",
        "Ethics"
      ],
      "models": [
        "LLaMA-7B",
        "LLaMA-13B",
        "PaLM-540B",
        "Generative Ranking",
        "Discriminative Ranking",
        "Self-Contrastive Decoding",
        "Equilibrium Consensus Game",
        "BDG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Selection Matters Enhancing Text Annotations for Social Sciences with Large Language Models": {
    "filename": "Prompt Selection Matters Enhancing Text Annotations for Social Sciences with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "TweetEval - hate",
        "TweetEval - emotion",
        "TweetEval - sentiment",
        "TweetEval - offensive",
        "Tweet Sentiment Multilingual",
        "Article Bias Prediction",
        "Liberals vs Conservatives on Reddit"
      ],
      "models": [
        "GPT-3.5 Turbo",
        "Automatic Prompt Optimization (APO)"
      ]
    }
  },
  "Disinformation Detection An Evolving Challenge in the Age of LLMs": {
    "filename": "Disinformation Detection An Evolving Challenge in the Age of LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Fake and Real News Dataset",
        "Dhuman",
        "Dgptstd",
        "Dgptmix",
        "Dgptcot"
      ],
      "models": [
        "ChatGPT",
        "Llama",
        "BERT",
        "GPT-2",
        "T5",
        "RoBERTa-based model",
        "CSI model",
        "FakeBERT",
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "OpenCity A Scalable Platform to Simulate Urban Activities with Massive LLM Agents": {
    "filename": "OpenCity A Scalable Platform to Simulate Urban Activities with Massive LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Beijing",
        "New York",
        "San Francisco",
        "London",
        "Paris",
        "Sydney"
      ],
      "models": [
        "OpenCity",
        "Generative Agent",
        "EPR Agent"
      ]
    }
  },
  "A Survey on Knowledge Distillation of Large Language Models": {
    "filename": "A Survey on Knowledge Distillation of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "LLaMA",
        "Mistral",
        "Gemini",
        "Claude",
        "LLaMA-2-70B",
        "Orca",
        "Orca 2",
        "Baize",
        "Mammoth",
        "Mixed Distill",
        "Self-Instruct",
        "Alpaca",
        "Code Alpaca",
        "Self-Align",
        "WizardLM",
        "WizardCoder",
        "WizardMath",
        "AugGPT",
        "TDG",
        "UltraChat",
        "Phi-1",
        "Phi-1.5",
        "Phi-2",
        "Magicoder",
        "WaveCoder",
        "ZeroGen",
        "SunGen",
        "InPars",
        "BabyLlama",
        "MiniLLM",
        "GKD",
        "QuantGPT",
        "LLM-QAT",
        "CAI",
        "UltraFeedback",
        "Zephyr",
        "CycleAlign",
        "RLAIF",
        "Lion",
        "PERsD",
        "RLCD",
        "ImpDistill",
        "LMSI",
        "ReST",
        "Self-Rewarding",
        "STaR",
        "DistilGPT",
        "f-Distill",
        "TED",
        "Llama-GPT4",
        "UltraLLaMA",
        "CAMEL",
        "OpenChat",
        "KARD",
        "SAIL",
        "Self-RAG",
        "Selfee",
        "AFT",
        "AdaptLLM",
        "KnowPAT",
        "ILF",
        "ALMoST",
        "RLEF",
        "Align Honesty",
        "SANDBOX",
        "Toolformer",
        "Graph-ToolFormer",
        "Gorilla",
        "ToolAlpaca",
        "ToolLLM",
        "CRAFT",
        "Confucius",
        "MLLM-Tool",
        "\u03b1-UMi",
        "FireAct",
        "AgentTuning",
        "Lumos",
        "AUTOACT",
        "TPTU-v2",
        "InheritSumm",
        "RECOMP",
        "MaRio",
        "ID",
        "GPT-3 Labeling",
        "BioGPT",
        "ChatGPT NMT",
        "QUILL",
        "Promptgator",
        "AugTriever",
        "RankVicuna",
        "RankZephyr",
        "ExaRanker",
        "NDR",
        "InstrcutRec",
        "ONCE",
        "PandaLM",
        "Prometheus",
        "InstructScore",
        "TigerScore",
        "Auto-J",
        "CodeLlama",
        "MFTCoder",
        "StableLLaVA",
        "PointLLM",
        "LLaVA",
        "SVIT",
        "LVIS-Instruct4V",
        "Shikra",
        "LSKD",
        "DetGPT",
        "LRV",
        "NExT-GPT",
        "Valley",
        "ILuvUI"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ClarifyGPT Empowering LLM-based Code Generation with Intention Clarification": {
    "filename": "ClarifyGPT Empowering LLM-based Code Generation with Intention Clarification.pdf",
    "analysis": {
      "benchmarks": [
        "MBPP-sanitized",
        "MBPP-ET",
        "HumanEval",
        "HumanEval-ET"
      ],
      "models": [
        "ClarifyGPT",
        "GPT-4",
        "ChatGPT",
        "CoT (Chain-of-Thought)",
        "GPT-Engineer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Template Filling for Controllable Commonsense Reasoning": {
    "filename": "Template Filling for Controllable Commonsense Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "commonsenseqa"
      ],
      "models": [
        "POTTER",
        "BART-BASE",
        "BART-LARGE",
        "T5-BASE",
        "T5-LARGE",
        "BERT-BASE",
        "BERT-LARGE"
      ]
    }
  },
  "Aligning Modalities in Vision Large Language Models via Preference Fine-tuning": {
    "filename": "Aligning Modalities in Vision Large Language Models via Preference Fine-tuning.pdf",
    "analysis": {
      "benchmarks": [
        "SciQA-IMG",
        "MMBench",
        "MM-Vet",
        "LLaVA-Bench",
        "CHAIR",
        "CHAIRi",
        "POPE",
        "MMHal"
      ],
      "models": [
        "LLaVA-1.5",
        "Vlfeedback",
        "Human-Preference",
        "RLHF-V",
        "POVID",
        "InstructBLIP",
        "Qwen-VL-Chat",
        "mPLUG-Owl2"
      ]
    }
  },
  "Dysen-VDM Empowering Dynamics-Aware Text-to-Video Diffusion with LLMs": {
    "filename": "Dysen-VDM Empowering Dynamics-Aware Text-to-Video Diffusion with LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "UCF-101",
        "MSR-VTT",
        "ActivityNet"
      ],
      "models": [
        "Dysen-VDM",
        "VDM",
        "Latent-VDM",
        "CogVideo",
        "MagicVideo",
        "MakeVideo",
        "AlignLatent",
        "Latent-Shift",
        "VideoFactory",
        "InternVid",
        "VideoGPT",
        "TGANv2",
        "DIGAN",
        "MoCoGAN-HD",
        "TATS",
        "PVDM",
        "ED-T2V",
        "VideoGen"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Inference Optimizations for Large Language Models Effects Challenges and Practical Considerations": {
    "filename": "Inference Optimizations for Large Language Models Effects Challenges and Practical Considerations.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD",
        "SST-2"
      ],
      "models": [
        "RoBERTa",
        "DistillBERT",
        "LLM.Int8()",
        "GPTQ",
        "AWQ",
        "OWQ",
        "SpQR",
        "ZeroQuant",
        "ZeroQuantV2",
        "SmoothQuant",
        "OmniQuant",
        "LoRaPrune",
        "SparseGPT",
        "Prune and Tune",
        "Wanda",
        "LLM-Pruner",
        "MiniLLM",
        "On-Policy Distillation of LMs",
        "How To Train Your (Compressed) LLM",
        "In-context Learning Distillation",
        "Explanations from LLMs Make Small Models Better",
        "LLMs Are Reasoning Teachers",
        "Distilling Step-by-Step!",
        "Distilling Reasoning Capabilities Into Smaller Models",
        "SCOTT",
        "PaD: Program-aided Distillation",
        "Can LMs Teach Weaker Agents?",
        "Lion: Adversarial Distillation",
        "LaMini-LM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How to think step-by-step A mechanistic understanding of chain-of-thought reasoning": {
    "filename": "How to think step-by-step A mechanistic understanding of chain-of-thought reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "PrOntoQA"
      ],
      "models": [
        "Llama-2 7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PIVOT Iterative Visual Prompting Elicits Actionable Knowledge for VLMs": {
    "filename": "PIVOT Iterative Visual Prompting Elicits Actionable Knowledge for VLMs.pdf",
    "analysis": {
      "benchmarks": [
        "RefCOCO"
      ],
      "models": [
        "PIVOT",
        "GPT-4V",
        "Gemini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SignEye Traffic Sign Interpretation from Vehicle First-Person View": {
    "filename": "SignEye Traffic Sign Interpretation from Vehicle First-Person View.pdf",
    "analysis": {
      "benchmarks": [
        "Traffic-CN",
        "Tusimple"
      ],
      "models": [
        "SignEye",
        "MiniGPT-v2",
        "LLaVA-1.5",
        "MiniCPM-2.6",
        "QWen2-VL",
        "GPT-4o",
        "BLIP2",
        "CLIP",
        "Qwen-VL",
        "Fuyu-8B",
        "OtterHD",
        "Monkey",
        "GeoChat",
        "RegionGPT",
        "ASM",
        "SignDet",
        "UFLD",
        "SAM",
        "SigLIP-ViT",
        "QWen2",
        "DeepSeek-VL",
        "Intern-VL",
        "MiniCPM",
        "LLaVA",
        "LLaVA1.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ControlLLM Augment Language Models with Tools by Searching on Graphs": {
    "filename": "ControlLLM Augment Language Models with Tools by Searching on Graphs.pdf",
    "analysis": {
      "benchmarks": [
        "ControlLLM Benchmark"
      ],
      "models": [
        "ControlLLM",
        "ControlLLM-ChatGPT",
        "ControlLLM-LLaMA",
        "ControlLLM-Mix",
        "HuggingGPT",
        "Visual ChatGPT",
        "InternGPT",
        "GPT4Tools"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Interpretable Mental Health Analysis with Large Language Models": {
    "filename": "Towards Interpretable Mental Health Analysis with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Depression_Reddit (DR)",
        "CLPsych15",
        "Dreaddit",
        "T-SID",
        "SAD",
        "CAMS"
      ],
      "models": [
        "ChatGPT",
        "InstructGPT-3",
        "LLaMA-13B",
        "LLaMA-7B",
        "CNN",
        "GRU",
        "BiLSTM_Att",
        "fastText",
        "BERT",
        "RoBERTa",
        "MentalBERT",
        "MentalRoBERTa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unpacking Large Language Models with Conceptual Consistency": {
    "filename": "Unpacking Large Language Models with Conceptual Consistency.pdf",
    "analysis": {
      "benchmarks": [
        "CSQA",
        "CSQA2"
      ],
      "models": [
        "OPT-350M",
        "OPT-1.3B",
        "OPT-13B",
        "OPT-30B",
        "OPT-66B",
        "GPT-125M",
        "GPT-2.7B",
        "GPT-6B",
        "T0-3B",
        "T0-11B"
      ]
    }
  },
  "Synthetic Context Generation for Question Generation": {
    "filename": "Synthetic Context Generation for Question Generation.pdf",
    "analysis": {
      "benchmarks": [
        "OS-bio",
        "SQuAD"
      ],
      "models": [
        "Flan-T5-large",
        "Flan-T5-large (w/o synthetic context)",
        "davinci-003 (zero)",
        "davinci-003 (few)",
        "GPT-3.5 (zero)",
        "GPT-3.5 (few)",
        "Flan-T5-small",
        "Flan-T5-medium",
        "Flan-T5-large (S)",
        "Flan-T5-small (R)",
        "Flan-T5-medium (R)",
        "Flan-T5-large (R)"
      ]
    }
  },
  "External Reasoning Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback": {
    "filename": "External Reasoning Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Claude+",
        "MPT-30B-chat",
        "Vicuna-33B",
        "Vicuna-13B",
        "Vicuna-7B",
        "GPT-3.5",
        "GPT-4",
        "ChatPDF.com",
        "text-embedding-ada",
        "text-embedding-babbage",
        "text-embedding-curie",
        "text-embedding-davinci",
        "facebook/bart-large-cnn",
        "LIMA",
        "65B-parameter LLaMa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Autonomous Driving LLM4AD Concept Benchmark Simulation and Real-Vehicle Experiment": {
    "filename": "Large Language Models for Autonomous Driving LLM4AD Concept Benchmark Simulation and Real-Vehicle Experiment.pdf",
    "analysis": {
      "benchmarks": [
        "LaMPilot-Bench",
        "CARLA Leaderboard 1.0"
      ],
      "models": [
        "LLM4AD",
        "Llama 2",
        "PaLM 2",
        "ChatGPT",
        "GPT-4",
        "GPT-4-Turbo",
        "Intelligent Driver Model (IDM)",
        "Minimizing Overall Braking Induced by Lane Changes (MOBIL)",
        "Roach Expert",
        "TCP Expert",
        "Talk2Drive"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Formal Mathematical Reasoning A New Frontier in AI": {
    "filename": "Formal Mathematical Reasoning A New Frontier in AI.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "AIMO Progress Prize",
        "AIME",
        "IMO",
        "Millennium Prize Problems",
        "PRM800K",
        "MiniF2F",
        "PutnamBench"
      ],
      "models": [
        "AlphaProof",
        "AlphaGeometry",
        "NuminaMath",
        "DeepSeekMath-Base 7B",
        "OpenAI o1",
        "ToRA",
        "MuMath-Code",
        "Lean-STaR",
        "COPRA",
        "ReProver",
        "LeanDojo",
        "SatLM",
        "LINC",
        "LogicGuide",
        "Holophrasm",
        "GPT-f",
        "DreamCoder",
        "LEGO-Prover",
        "Graph2Tac",
        "Tree of Thoughts"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Affordable Generative Agents": {
    "filename": "Affordable Generative Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Stanford Town",
        "VirtualHome",
        "COQA",
        "QQP",
        "RTE"
      ],
      "models": [
        "Affordable Generative Agents (AGA)",
        "Lifestyle Policy",
        "Social Memory",
        "Generative Agents"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do GPT Language Models Suffer From Split Personality Disorder The Advent Of Substrate-Free Psychometrics": {
    "filename": "Do GPT Language Models Suffer From Split Personality Disorder The Advent Of Substrate-Free Psychometrics.pdf",
    "analysis": {
      "benchmarks": [
        "Short Dark Triad Inventory",
        "Big Five Inventory",
        "Flourishing Scale",
        "Satisfaction With Life Scale",
        "HEXACO questionnaire",
        "Human Value Scale",
        "Machine Personality Inventory",
        "Ten Item Personality Inventory"
      ],
      "models": [
        "GPT-3",
        "InstructGPT",
        "FLAN-T5-XXL",
        "BART",
        "T0++-11B",
        "GPT-Neo-2.7B",
        "GPT-NeoX-20B",
        "GPT-3-175B",
        "GPT-2",
        "TransformerXL",
        "XLNET"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Instruction Tuning for Large Language Models A Survey": {
    "filename": "Instruction Tuning for Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA",
        "RealToxicityPrompts",
        "WSC",
        "HumanEval",
        "lm-evaluation-harness",
        "MMLU",
        "BBH",
        "TyDiQA",
        "MGSM",
        "User-Oriented-Instructions-252",
        "Vicuna-Instructions",
        "Unnatural Instructions",
        "C-Eval",
        "GSM8K"
      ],
      "models": [
        "GPT-3",
        "PaLM",
        "LLaMA",
        "InstructGPT",
        "BLOOMZ",
        "FLAN-T5",
        "Alpaca",
        "Vicuna",
        "GPT-4-LLM",
        "Claude",
        "WizardLM",
        "ChatGLM2",
        "LIMA",
        "OPT-IML"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GraphArena Benchmarking Large Language Models on Graph Computational Problems": {
    "filename": "GraphArena Benchmarking Large Language Models on Graph Computational Problems.pdf",
    "analysis": {
      "benchmarks": [
        "GraphArena",
        "DBLP",
        "Social Network",
        "DBpedia",
        "Openflights",
        "PubChemQC"
      ],
      "models": [
        "GPT-4o",
        "Llama3-70b-Instruct",
        "GPT-3.5",
        "Claude3-haiku",
        "Llama3-8b-Instruct",
        "Qwen1.5-72b-Chat",
        "Qwen1.5-8b-Chat",
        "Gemma-7b",
        "Deepseek-V2",
        "Mixtral-7x8b",
        "GraphWiz"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Are Not Strong Abstract Reasoners": {
    "filename": "Large Language Models Are Not Strong Abstract Reasoners.pdf",
    "analysis": {
      "benchmarks": [
        "ACRET",
        "ARCT",
        "BIG-Bench-F",
        "Evals-S",
        "PVR",
        "RA VENT"
      ],
      "models": [
        "GPT-2",
        "Text-Davinci-3",
        "GPT-3.5-Turbo",
        "GPT-4",
        "LLaMA-7B",
        "LLaMA2-7B",
        "Alpaca",
        "Alpaca-LoRA",
        "Zephyr-7B-\u03b2",
        "LLaMA-7B-AR-LoRA",
        "LLaMA2-7B-AR-LoRA",
        "RoBERTa-AR",
        "MERIt-AR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can-Do A Dataset and Neuro-Symbolic Grounded Framework for Embodied Planning with Large Multimodal Models": {
    "filename": "Can-Do A Dataset and Neuro-Symbolic Grounded Framework for Embodied Planning with Large Multimodal Models.pdf",
    "analysis": {
      "benchmarks": [
        "CAN-DO",
        "ALFRED",
        "TaPA"
      ],
      "models": [
        "GPT-4V",
        "NeuroGround",
        "Claude Opus",
        "Gemini Pro",
        "LLaVA",
        "Qwen-VL"
      ]
    }
  },
  "Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering": {
    "filename": "Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP"
      ],
      "models": [
        "Fed-SP-SC",
        "Fed-DP-CoT",
        "Zero-Shot-CoT",
        "GPT-3",
        "GPT-3.5",
        "text-davinci-002",
        "text-davinci-003"
      ]
    }
  },
  "Memory Injections Correcting Multi-Hop Reasoning Failures During Inference in Transformer-Based Language Models": {
    "filename": "Memory Injections Correcting Multi-Hop Reasoning Failures During Inference in Transformer-Based Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "2WikiMultiHop",
        "Hand"
      ],
      "models": [
        "GPT2-Small",
        "GPT2-Large"
      ]
    }
  },
  "Organizing a Society of Language Models Structures and Mechanisms for Enhanced Collective Intelligence": {
    "filename": "Organizing a Society of Language Models Structures and Mechanisms for Enhanced Collective Intelligence.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT",
        "BERT",
        "Chain of Thought (CoT)",
        "Tree of Thoughts (ToT)"
      ]
    }
  },
  "In-context operator learning with data prompts for differential equation problems": {
    "filename": "In-context operator learning with data prompts for differential equation problems.pdf",
    "analysis": {
      "benchmarks": [
        "Forward problem of ODE 1d",
        "Inverse problem of ODE 1",
        "Forward problem of ODE 2d",
        "Inverse problem of ODE 2",
        "Forward problem of ODE 3d",
        "Inverse problem of ODE 3",
        "Forward damped oscillator",
        "Inverse damped oscillator",
        "Forward Poisson equation",
        "Inverse Poisson equation",
        "Forward linear reaction-diffusion",
        "Inverse linear reaction-diffusion",
        "Forward nonlinear reaction-diffusion",
        "Inverse nonlinear reaction-diffusion",
        "MFC g-parameter 1D \u21921D",
        "MFC g-parameter 1D \u21922D",
        "MFC g-parameter 2D \u21922D",
        "MFC \u03c10-parameter 1D \u21921D",
        "MFC \u03c10-parameter 1D \u21922D"
      ],
      "models": [
        "In-Context Operator Networks (ICON)",
        "Physics-Informed Neural Networks (PINNs)",
        "Deep Galerkin Method (DGM)",
        "Deep Ritz Method (DRM)",
        "Weak Adversarial Network (WAN)",
        "PDE-Net",
        "Deep Operator Network (DeepONet)",
        "Fourier Neural Operator (FNO)"
      ]
    }
  },
  "What can Large Language Models do in chemistry A comprehensive benchmark on eight tasks": {
    "filename": "What can Large Language Models do in chemistry A comprehensive benchmark on eight tasks.pdf",
    "analysis": {
      "benchmarks": [
        "BBBP",
        "Tox21",
        "PubChem",
        "USPTO",
        "ChEBI",
        "HIV",
        "BACE",
        "ClinTox",
        "Buchwald-Hartwig",
        "Suzuki-Miyaura",
        "USPTO-Mixed",
        "USPTO-50k",
        "ChEBI-20"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Davinci-003",
        "Llama",
        "Galactica",
        "UAGNN",
        "Chemformer",
        "MolT5-Large",
        "STOUT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM and Simulation as Bilevel Optimizers A New Paradigm to Advance Physical Scientific Discovery": {
    "filename": "LLM and Simulation as Bilevel Optimizers A New Paradigm to Advance Physical Scientific Discovery.pdf",
    "analysis": {
      "benchmarks": [
        "QM9"
      ],
      "models": [
        "Scientific Generative Agent (SGA)",
        "Chain-of-Thoughts (CoT)",
        "FunSearch",
        "Eureka",
        "Optimization by PROmpting (OPRO)",
        "Ours (no bilevel)",
        "Ours (no exploit)",
        "GPT-4",
        "GPT-3.5",
        "Claude-3-Sonnet",
        "Mixtral-8x7B",
        "GhemGE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring the Reliability of Foundation Model-Based Frontier Selection in Zero-Shot Object Goal Navigation": {
    "filename": "Exploring the Reliability of Foundation Model-Based Frontier Selection in Zero-Shot Object Goal Navigation.pdf",
    "analysis": {
      "benchmarks": [
        "RoboTHOR",
        "HM3D"
      ],
      "models": [
        "Diversified Expert Frontier Analysis (DEFA)",
        "Consensus Decision Making (CDM)",
        "Clip-Nav",
        "CoW",
        "L-ZSON",
        "ESC",
        "NavGPT",
        "RF-NAV",
        "Ours (k=3)",
        "Ours (k=5)",
        "Ours Consensus Commonsense"
      ]
    }
  },
  "Can Language Models Teach Weaker Agents Teacher Explanations Improve Students via Personalization": {
    "filename": "Can Language Models Teach Weaker Agents Teacher Explanations Improve Students via Personalization.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA",
        "GSM8k",
        "CommonsenseQA"
      ],
      "models": [
        "Flan-T5-Large",
        "Flan-T5-XL",
        "LLaMA-7B",
        "LLaMA-13B",
        "LLaMA-65B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Future-Proofing Mobile Networks A Digital Twin Approach to Multi-Signal Management": {
    "filename": "Future-Proofing Mobile Networks A Digital Twin Approach to Multi-Signal Management.pdf",
    "analysis": {
      "benchmarks": [
        "UbiKampus"
      ],
      "models": [
        "Digital Twin framework",
        "GenAI models",
        "Large Language Models (LLMs)",
        "Multi-modal Models (MMs)"
      ]
    }
  },
  "A Knowledge Engineering Primer": {
    "filename": "A Knowledge Engineering Primer.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GeoGPT Understanding and Processing Geospatial Tasks through An Autonomous GPT": {
    "filename": "GeoGPT Understanding and Processing Geospatial Tasks through An Autonomous GPT.pdf",
    "analysis": {
      "benchmarks": [
        "geospatial data crawling",
        "spatial query",
        "facility siting",
        "mapping"
      ],
      "models": [
        "GeoGPT",
        "gpt-3.5-turbo"
      ]
    }
  },
  "Controllable Traffic Simulation through LLM-Guided Hierarchical Chain-of-Thought Reasoning": {
    "filename": "Controllable Traffic Simulation through LLM-Guided Hierarchical Chain-of-Thought Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Waymo Open Motion Dataset (WOMD)"
      ],
      "models": [
        "LLM-Guided Hierarchical Chain-of-Thought Reasoning",
        "diffusion-based methods",
        "CTG++",
        "Actions-Only",
        "Decision Transformer",
        "CtRL-Sim",
        "TrafficGen",
        "LCTGen"
      ]
    }
  },
  "PROMISE A Framework for Developing Complex Conversational Interactions Technical Report": {
    "filename": "PROMISE A Framework for Developing Complex Conversational Interactions Technical Report.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "PROMISE",
        "LangChain",
        "IRIS",
        "GitHub Copilot",
        "Microsoft 365 Copilot"
      ]
    }
  },
  "Limits of Deep Learning Sequence Modeling through the Lens of Complexity Theory": {
    "filename": "Limits of Deep Learning Sequence Modeling through the Lens of Complexity Theory.pdf",
    "analysis": {
      "benchmarks": [
        "multi-digit multiplication",
        "dynamic programming",
        "Einstein's puzzle"
      ],
      "models": [
        "Structured State Space Models (SSMs)",
        "Transformers",
        "GPT-4",
        "Jamba",
        "Mamba",
        "S4-H3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do you still need a manual smart contract audit": {
    "filename": "Do you still need a manual smart contract audit.pdf",
    "analysis": {
      "benchmarks": [
        "52 DeFi smart contracts",
        "5 newly developed smart contracts"
      ],
      "models": [
        "GPT-4",
        "Claude",
        "GPT-4-32k",
        "Claude-v1.3-100k",
        "random model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DeFine Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning": {
    "filename": "DeFine Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Motley Fool earnings call transcripts",
        "Yahoo Finance stock prices",
        "Alpha Advantage financial metrics"
      ],
      "models": [
        "DEFINE",
        "LLM+CoT+Trans",
        "LLM+CoT+Summ",
        "LLM+CoT+Factors",
        "DeLLMa",
        "DEFINE-BT-Same Sector",
        "DEFINE-BT-Cross Sectors",
        "DEFINE-BT-Same Company"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Little Leak Will Sink a Great Ship Survey of Transparency for Large Language Models from Start to Finish": {
    "filename": "A Little Leak Will Sink a Great Ship Survey of Transparency for Large Language Models from Start to Finish.pdf",
    "analysis": {
      "benchmarks": [
        "Huggingface's Datasets"
      ],
      "models": [
        "T5-small",
        "T5-base",
        "T5-large",
        "LLaMA-7B",
        "LLaMA-13B",
        "LLaMA-33B",
        "LLaMA-65B",
        "Pythia-70M",
        "Pythia-160M",
        "Pythia-410M",
        "Pythia-1B",
        "Pythia-1.4B",
        "Pythia-2.8B",
        "Pythia-6.9B",
        "Pythia-12B",
        "MPT-7B",
        "MPT-7B-Instruct",
        "MPT-30B",
        "MPT-30B-Instruct",
        "Falcon-7B",
        "Falcon-7B-Instruct",
        "Falcon-40B",
        "Falcon-40B-Instruct",
        "OLMo-7B",
        "OLMo-7B-Instruct"
      ]
    }
  },
  "Meaningful Learning Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance": {
    "filename": "Meaningful Learning Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance.pdf",
    "analysis": {
      "benchmarks": [
        "e-CARE",
        "AbsR",
        "AGIEval",
        "RACE",
        "BBH",
        "Com.",
        "MMLU",
        "ARC-e",
        "ARC-c"
      ],
      "models": [
        "LLaMA-2",
        "Orca-2",
        "GPT-3.5",
        "MeanLearn",
        "Vicuna",
        "WizardLM",
        "PaLM-2",
        "LLaMA-3",
        "Mistral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Crafting Dynamic Virtual Activities with Advanced Multimodal Models": {
    "filename": "Crafting Dynamic Virtual Activities with Advanced Multimodal Models.pdf",
    "analysis": {
      "benchmarks": [
        "apartment",
        "restaurant",
        "office"
      ],
      "models": [
        "large multimodal models (LMMs)",
        "GPT-4V"
      ]
    }
  },
  "Autonomous Tree-search Ability of Large Language Models": {
    "filename": "Autonomous Tree-search Ability of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Drop Water Puzzle",
        "Number Path Puzzle",
        "Arithmetic Puzzle",
        "Minimal Grass Puzzle"
      ],
      "models": [
        "ATS-BFS",
        "ATS-DFS",
        "Chain of Thought (CoT)",
        "Tree of Thought (ToT)",
        "LLaMA2-7B",
        "LLaMA2-13B",
        "ATS-tuned LLaMA",
        "CoT-tuned LLaMA",
        "ToT-tuned LLaMA"
      ]
    }
  },
  "Language models as master equation solvers": {
    "filename": "Language models as master equation solvers.pdf",
    "analysis": {
      "benchmarks": [
        "genetic toggle switch",
        "mRNA turnover",
        "autoregulatory feedback loop",
        "birth-death model"
      ],
      "models": [
        "Master Equation Transformer (MET)",
        "Gillespie simulation algorithm",
        "Neural-network chemical master equation (NNCME)",
        "Recurrent Neural Network (RNN)"
      ]
    }
  },
  "Affective Faces for Goal-Driven Dyadic Communication": {
    "filename": "Affective Faces for Goal-Driven Dyadic Communication.pdf",
    "analysis": {
      "benchmarks": [
        "The RealTalk Dataset"
      ],
      "models": [
        "Our Method",
        "Learning2Listen",
        "Untuned CLIP",
        "Uniform Frame Sampling",
        "Random Chance"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chat-REC Towards Interactive and Explainable LLMs-Augmented Recommender System": {
    "filename": "Chat-REC Towards Interactive and Explainable LLMs-Augmented Recommender System.pdf",
    "analysis": {
      "benchmarks": [
        "MovieLens 100K"
      ],
      "models": [
        "Chat-Rec (gpt-3.5-turbo)",
        "Chat-Rec (text-davinci-003)",
        "Chat-Rec (text-davinci-002)",
        "LightFM",
        "LightGCN",
        "Item-KNN",
        "Matrix Factorization (MF)"
      ]
    }
  },
  "Leveraging Large Language Models for Exploiting ASR Uncertainty": {
    "filename": "Leveraging Large Language Models for Exploiting ASR Uncertainty.pdf",
    "analysis": {
      "benchmarks": [
        "Google Speech Commands (GSC)",
        "internal dataset for device-directed speech detection"
      ],
      "models": [
        "Vicuna-7B-v1.3",
        "LatticeRNN",
        "ASR+LLM intent classification system",
        "LoRA finetuned LLM"
      ]
    }
  },
  "Logicbreaks A Framework for Understanding Subversion of Rule-based Inference": {
    "filename": "Logicbreaks A Framework for Understanding Subversion of Rule-based Inference.pdf",
    "analysis": {
      "benchmarks": [
        "Minecraft"
      ],
      "models": [
        "theoretical model",
        "learned model",
        "standard LLM",
        "GPT-2",
        "Llama-2-7B-chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LongHealth A Question Answering Benchmark with Long Clinical Documents": {
    "filename": "LongHealth A Question Answering Benchmark with Long Clinical Documents.pdf",
    "analysis": {
      "benchmarks": [
        "LongHealth"
      ],
      "models": [
        "Mixtral-8x7B-Instruct-v0.1",
        "gpt-3.5-turbo-1106",
        "Mistral-7B-Instruct-v0.2",
        "Yi-34B-200k",
        "zephyr-7b-beta-16k",
        "vicuna-13b-v1.5-16k",
        "Yi-6B-200K",
        "longchat-13b-16k",
        "vicuna-7b-v1.5-16k",
        "longchat-7b-v1.5-32k"
      ]
    }
  },
  "Nudging Inference-time Alignment via Model Collaboration": {
    "filename": "Nudging Inference-time Alignment via Model Collaboration.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MMLU",
        "LastLetterConcat",
        "just-eval-instruct",
        "SVAMP",
        "MultiArith",
        "Arc-challenge",
        "CommonsenseQA",
        "StrategyQA",
        "Date Understanding",
        "Sports Understanding",
        "Coin Flip"
      ],
      "models": [
        "Llama-2-70b",
        "Llama-2-7b-chat",
        "Llama-2-70b-chat",
        "Gemma-2-27b",
        "Gemma-2-2b-it",
        "Gemma-2-27b-it",
        "OLMo-7b",
        "OLMo-1b-it",
        "OLMo-7b-it",
        "NUDGING"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Knowledge Graphs Make Large Language Models More Trustworthy An Empirical Study over Open-ended Question Answering": {
    "filename": "Can Knowledge Graphs Make Large Language Models More Trustworthy An Empirical Study over Open-ended Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "OKGQA",
        "OKGQA-P"
      ],
      "models": [
        "GPT-4o",
        "GPT-4o-mini",
        "Llama-3.1-8B-instruct",
        "Mistral-7B-instruct-v0.3",
        "Gemma-2-9B-it",
        "Chain-of-thought",
        "Self-consistency"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Overview of Machine Learning-Enabled Optimization for Reconfigurable Intelligent Surfaces-Aided 6G Networks From Reinforcement Learning to Large Language Models": {
    "filename": "An Overview of Machine Learning-Enabled Optimization for Reconfigurable Intelligent Surfaces-Aided 6G Networks From Reinforcement Learning to Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "deep Q-learning",
        "multi-agent reinforcement learning",
        "transfer reinforcement learning",
        "hierarchical reinforcement learning",
        "offline reinforcement learning",
        "LLM-aided optimization techniques",
        "Q-learning",
        "DQN",
        "deep actor-critic",
        "deep deterministic policy gradient (DDPG)",
        "double deep Q-learning (DDQN)",
        "twin delayed DDPG (TD3)"
      ]
    }
  },
  "ACFIX Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts": {
    "filename": "ACFIX Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts.pdf",
    "analysis": {
      "benchmarks": [
        "benchmark dataset of 118 real-world AC vulnerabilities"
      ],
      "models": [
        "GPT-4",
        "ACF IX",
        "baseline GPT-4",
        "SmartFix",
        "SGuard"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Seeing Like an AI How LLMs Apply and Misapply Wikipedia Neutrality Norms": {
    "filename": "Seeing Like an AI How LLMs Apply and Misapply Wikipedia Neutrality Norms.pdf",
    "analysis": {
      "benchmarks": [
        "Wikipedia Neutrality Corpus (WNC)"
      ],
      "models": [
        "ChatGPT 3.5",
        "Mistral-Medium",
        "GPT-4",
        "Zero-Shot",
        "Constitutional AI (CAI)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "INTRA Interaction Relationship-aware Weakly Supervised Affordance Grounding": {
    "filename": "INTRA Interaction Relationship-aware Weakly Supervised Affordance Grounding.pdf",
    "analysis": {
      "benchmarks": [
        "AGD20K",
        "IIT-AFF",
        "CAD",
        "UMD"
      ],
      "models": [
        "INTRA",
        "LOCATE",
        "Cross-view-AG",
        "Cross-view-AG+",
        "Exo+EgoHotspots",
        "EIL",
        "SPA",
        "TS-CAM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AD-KD Attribution-Driven Knowledge Distillation for Language Model Compression": {
    "filename": "AD-KD Attribution-Driven Knowledge Distillation for Language Model Compression.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "CoLA",
        "MNLI",
        "SST-2",
        "QNLI",
        "MRPC",
        "QQP",
        "RTE",
        "STS-B"
      ],
      "models": [
        "BERT",
        "RoBERTa",
        "AD-KD",
        "Vanilla KD",
        "PD",
        "PKD",
        "TinyBERT",
        "CKD",
        "MGSKD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Retrieval-Augmented Generation for AI-Generated Content A Survey": {
    "filename": "Retrieval-Augmented Generation for AI-Generated Content A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "CONFLICTINGQA",
        "Wikipedia",
        "Code Property Graphs (CPG)"
      ],
      "models": [
        "FiD",
        "REALM",
        "RETRO",
        "SKR",
        "TOG",
        "NPM",
        "CL-ReLKT",
        "CORE",
        "EAE",
        "UR-QA",
        "DISC-LawLLM",
        "RAG-end2end",
        "MultiHop-RAG",
        "CONCRETE",
        "Atlas",
        "Stochastic RAG",
        "KG-BART",
        "ConceptFlow",
        "BlenderBot3",
        "CEG",
        "kNN-MT",
        "TRIME",
        "R-GQA",
        "RAMKG",
        "Unlimiformer",
        "RPRR",
        "RIGHT",
        "M-RAG",
        "SKCODER",
        "RRGCode",
        "CODEAGENT",
        "ARKS",
        "RECODE",
        "kNN-TRANX",
        "ToolCoder",
        "Re2Com",
        "EditSum",
        "HGNN",
        "RACE",
        "BASHEXPLAINER",
        "READSUM",
        "REDCODER",
        "ASAP",
        "SCCLLM",
        "Rencos",
        "CoRec",
        "kNN-Transformer",
        "Tram",
        "CMR-Sum",
        "Drain et al.",
        "ReACC",
        "RepoCoder",
        "De-Hallucinator",
        "REPOFUSE",
        "Retrieve-and-edit",
        "RepoFusion",
        "EDITAS",
        "CoCoMic",
        "kNM-LM",
        "RING",
        "CEDAR",
        "RAP-Gen",
        "InferFix",
        "SARGAM",
        "RTLFixer",
        "XRICL",
        "SYNCHROMESH",
        "CodeICL",
        "RESDSQL",
        "ReF-SQL",
        "ODIS",
        "MURRE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MathPrompter Mathematical Reasoning using Large Language Models": {
    "filename": "MathPrompter Mathematical Reasoning using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MultiArith"
      ],
      "models": [
        "MathPrompter",
        "Zero-shot",
        "Zero-shot (PaLM 540B)",
        "Zero-shot-CoT",
        "Zero-shot-CoT (PaLM 540B)",
        "Zero-shot-CoT + self consistency (PaLM 540B)",
        "Few-Shot (2 samples)",
        "Few-Shot (8 samples)",
        "Few-Shot-CoT (2 samples)",
        "Few-Shot-CoT (4 samples)",
        "Few-Shot-CoT (8 samples)",
        "Zero-Plus-Few-Shot-CoT (8 samples)"
      ]
    }
  },
  "Language Models can Solve Computer Tasks": {
    "filename": "Language Models can Solve Computer Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "MiniWoB++",
        "GSM8K",
        "MultiArith",
        "AddSub",
        "AQUA",
        "SVAMP",
        "SingleEq",
        "CommonSenseQA",
        "StrategyQA"
      ],
      "models": [
        "RCI",
        "InstructGPT-3+RLHF",
        "Chain-of-Thought (CoT)",
        "Zero-Shot CoT",
        "Few-Shot CoT",
        "GPT-3",
        "InstructGPT-3",
        "CC-Net",
        "WebN-T5-3B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Mitigating Hallucination in Large Language Models via Self-Reflection": {
    "filename": "Towards Mitigating Hallucination in Large Language Models via Self-Reflection.pdf",
    "analysis": {
      "benchmarks": [
        "PubMedQA",
        "MedQuAD",
        "MEDIQA2019",
        "LiveMedQA2017",
        "MASH-QA"
      ],
      "models": [
        "Vicuna",
        "Alpaca-LoRA",
        "ChatGPT",
        "MedAlpaca",
        "Robin-medical"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dual-AEB Synergizing Rule-Based and Multimodal Large Language Models for Effective Emergency Braking": {
    "filename": "Dual-AEB Synergizing Rule-Based and Multimodal Large Language Models for Effective Emergency Braking.pdf",
    "analysis": {
      "benchmarks": [
        "MM-AU",
        "Bench2Drive"
      ],
      "models": [
        "Dual-AEB",
        "rule-based AEB",
        "MLLM-powered AEB",
        "UniAD",
        "VAD",
        "YOLO-AEB",
        "LLaVA-OneVision",
        "Qwen-0.5B",
        "Qwen-7B"
      ]
    }
  },
  "Disentangling Logic The Role of Context in Large Language Model Reasoning Capabilities": {
    "filename": "Disentangling Logic The Role of Context in Large Language Model Reasoning Capabilities.pdf",
    "analysis": {
      "benchmarks": [
        "ContextHub",
        "DyVal",
        "PrOntoQA",
        "Symbolic Trees",
        "ProofWriter"
      ],
      "models": [
        "Qwen-1.5",
        "LLaMA-2",
        "Yi-1.5",
        "GPT-3.5-turbo",
        "Claude-3-Opus"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AntGPT Can Large Language Models Help Long-term Action Anticipation from Videos": {
    "filename": "AntGPT Can Large Language Models Help Long-term Action Anticipation from Videos.pdf",
    "analysis": {
      "benchmarks": [
        "Ego4D LTA v1",
        "Ego4D LTA v2",
        "EPIC-Kitchens-55",
        "EGTEA GAZE+"
      ],
      "models": [
        "AntGPT",
        "Transformer",
        "GPT-3-curie",
        "Llama2-7B",
        "Llama2-13B",
        "GPT-3.5 Turbo",
        "Llama2-chat-13B",
        "Slowfast",
        "VideoLLM",
        "PaMsEgoAI",
        "Palm",
        "HierVL",
        "ICV AE",
        "VCLIP",
        "I3D",
        "ActionVLAD",
        "Timeception",
        "VideoGraph",
        "EGO-TOPO",
        "Anticipatr"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TrafficGPT Viewing Processing and Interacting with Traffic Foundation Models": {
    "filename": "TrafficGPT Viewing Processing and Interacting with Traffic Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "XuanCheng city-scale synthetic individual-level vehicle trip dataset"
      ],
      "models": [
        "TrafficGPT",
        "ChatGPT",
        "PromptGAT",
        "Webster signal optimization model",
        "SUMO simulation model"
      ]
    }
  },
  "Decompose Enrich and Extract Schema-aware Event Extraction using LLMs": {
    "filename": "Decompose Enrich and Extract Schema-aware Event Extraction using LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "ACE2005",
        "WIKIEVENTS",
        "MaritimeEvent"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "Text2Event",
        "OntoGPT",
        "Fine-Grained IE",
        "Llama2-7B"
      ]
    }
  },
  "LLM experiments with simulation Large Language Model Multi-Agent System for Simulation Model Parametrization in Digital Twins": {
    "filename": "LLM experiments with simulation Large Language Model Multi-Agent System for Simulation Model Parametrization in Digital Twins.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLM multi-agent system",
        "observation agent",
        "reasoning agent",
        "decision agent",
        "summarization agent"
      ]
    }
  },
  "Generative Agents Interactive Simulacra of Human Behavior": {
    "filename": "Generative Agents Interactive Simulacra of Human Behavior.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Generative Agents",
        "ChatGPT",
        "gpt3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatEDA A Large Language Model Powered Autonomous Agent for EDA": {
    "filename": "ChatEDA A Large Language Model Powered Autonomous Agent for EDA.pdf",
    "analysis": {
      "benchmarks": [
        "ChatEDA-Bench"
      ],
      "models": [
        "ChatEDA",
        "AutoMage",
        "AutoMage2",
        "GPT-4",
        "GPT-3.5",
        "Claude2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can We Further Elicit Reasoning in LLMs Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks": {
    "filename": "Can We Further Elicit Reasoning in LLMs Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "USACO",
        "TheoremQA-Math",
        "StackBio",
        "StackEcon"
      ],
      "models": [
        "CR-Planner",
        "Standard",
        "Chain-of-Thought (CoT)",
        "Reflexion",
        "Retrieval-Augmented Generation (RAG)",
        "Chain-of-Knowledge (CoK)",
        "Retrieval+Reflexion",
        "CR-Planner+Reflexion"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards a Science Exocortex": {
    "filename": "Towards a Science Exocortex.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Large Language Models (LLMs)",
        "Generative AI",
        "Transformer architecture",
        "Retrieval Augmented Generation (RAG)",
        "xVal",
        "Contrastive Language-Image Pre-training (CLIP)",
        "Monte Carlo tree search",
        "Polymathic AI",
        "Neural Radiance Fields",
        "Gaussian Splatting",
        "Literature Based Discovery (LBD)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enabling Conversational Interaction with Mobile UI using Large Language Models": {
    "filename": "Enabling Conversational Interaction with Mobile UI using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "RICO",
        "Screen2Words",
        "PixelHelp"
      ],
      "models": [
        "LLM (Large Language Model)",
        "Screen2Words",
        "Seq2Act",
        "DistilBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-Consistency Preference Optimization": {
    "filename": "Self-Consistency Preference Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "ZebraLogic"
      ],
      "models": [
        "Llama-3 8B",
        "Llama-3 70B",
        "Gemma-2 27B",
        "Claude-3 Haiku",
        "SCPO",
        "IRPO RM",
        "IRPO Gold",
        "SCPOSemi-Sup."
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Receive Reason and React Drive as You Say With Large Language Models in Autonomous Vehicles": {
    "filename": "Receive Reason and React Drive as You Say With Large Language Models in Autonomous Vehicles.pdf",
    "analysis": {
      "benchmarks": [
        "HighwayEnv"
      ],
      "models": [
        "Large Language Models (LLMs)",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Finetuned Multimodal Language Models Are High-Quality Image-Text Data Filters": {
    "filename": "Finetuned Multimodal Language Models Are High-Quality Image-Text Data Filters.pdf",
    "analysis": {
      "benchmarks": [
        "DATACOMP",
        "ImageNet",
        "VTAB",
        "VQAv2",
        "GQA",
        "SVHN",
        "MNIST",
        "MSCOCO"
      ],
      "models": [
        "CLIP",
        "BLIP-2",
        "MLM Filter",
        "GPT-4Vision",
        "LLaVA",
        "MiniGPT-4",
        "CLIPScore",
        "MLM-FILTER-GPT4",
        "MLM-FILTER-GPT4V"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reward Engineering for Generating Semi-structured Explanation": {
    "filename": "Reward Engineering for Generating Semi-structured Explanation.pdf",
    "analysis": {
      "benchmarks": [
        "ExplaGraph",
        "COPA-SSE"
      ],
      "models": [
        "FLAN-T5-XXL",
        "FLAN-T5-XL",
        "FLAN-T5-Large",
        "LLaMA2-13B",
        "LLaMA2-7B",
        "ChatGPT (gpt-3.5-turbo-instruct)",
        "GPT-4 (gpt-4)",
        "RE-SP",
        "T5-Large",
        "T5-Large + CL",
        "BART-Large",
        "BART-Large + EG3P"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Connecting Dreams with Visual Brainstorming Instruction": {
    "filename": "Connecting Dreams with Visual Brainstorming Instruction.pdf",
    "analysis": {
      "benchmarks": [
        "NSD",
        "COCO"
      ],
      "models": [
        "DreamConnect",
        "Stable Diffusion",
        "VersatileDiffusion",
        "InstructDiffusion",
        "InstructPix2Pix",
        "MagicBrush",
        "SDEdit",
        "Takagi et.al.",
        "UniBrain",
        "Brain-Diffuser",
        "MindEye"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Getting More Juice Out of the SFT Data Reward Learning from Human Demonstration Improves SFT for LLM Alignment": {
    "filename": "Getting More Juice Out of the SFT Data Reward Learning from Human Demonstration Improves SFT for LLM Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "HuggingFace Open LLM Leaderboard",
        "Anthropic-HH",
        "Ultrachat200k",
        "AI2_Arc",
        "TruthfulQA",
        "Winogrande",
        "GSM8k",
        "HellaSwag",
        "MMLU"
      ],
      "models": [
        "1B model",
        "7B model",
        "RFT (Algorithm 1)",
        "IRFT (Algorithm 2)",
        "SPIN",
        "pythia-1.4b",
        "zephyr-7b-sft-full",
        "PKU-Alignment/beaver-7b-v3.0-reward"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Agents Meet Causality - Bridging LLMs and Causal World Models": {
    "filename": "Language Agents Meet Causality - Bridging LLMs and Causal World Models.pdf",
    "analysis": {
      "benchmarks": [
        "GridWorld",
        "AI2-THOR"
      ],
      "models": [
        "Causal World Model",
        "Baseline Language Model",
        "BISCUIT",
        "LLaMA 3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CFinBench A Comprehensive Chinese Financial Benchmark for Large Language Models": {
    "filename": "CFinBench A Comprehensive Chinese Financial Benchmark for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CFinBench",
        "MMLU",
        "C-Eval",
        "Xiezhi",
        "AGIEval",
        "FLUE",
        "FLARE",
        "BBT-CFLEB",
        "FinEval",
        "FinanceIQ",
        "Ant-Fin-Eva"
      ],
      "models": [
        "GPT4",
        "ChatGPT",
        "LLaMA",
        "Baichuan",
        "InternLM",
        "ChatGLM",
        "BloombergGPT",
        "FinMA",
        "Yi",
        "Qwen",
        "XuanYuan",
        "YunShan",
        "DeepSeek",
        "TigerBot",
        "Skywork",
        "Gemma",
        "Mistral",
        "Phi",
        "DISC-FinLLM",
        "CFGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Fine-tuning and prompt engineering for large language models-based code review automation": {
    "filename": "Fine-tuning and prompt engineering for large language models-based code review automation.pdf",
    "analysis": {
      "benchmarks": [
        "CodeReviewer data",
        "Tufano data (with comment)",
        "Tufano data (without comment)",
        "D-ACT data"
      ],
      "models": [
        "GPT-3.5",
        "Magicoder",
        "Guo et al.'s approach",
        "CodeReviewer",
        "TufanoT5",
        "D-ACT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Ambiguity-Aware In-Context Learning with Large Language Models": {
    "filename": "Ambiguity-Aware In-Context Learning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SST",
        "GoEmotions",
        "EDOS"
      ],
      "models": [
        "Flan-PaLM 2 (M)",
        "Flan-PaLM 2 (L)",
        "ZERO",
        "STATIC-N",
        "RETR",
        "AMBIG-ICL",
        "AMBIG-ICL +GOLD",
        "AMBIG-ICL +GOLD +MIS",
        "AMBIG-ICL +GOLD +MIS+PRED"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mufu Multilingual Fused Learning for Low-Resource Translation with LLM": {
    "filename": "Mufu Multilingual Fused Learning for Low-Resource Translation with LLM.pdf",
    "analysis": {
      "benchmarks": [
        "FLORES-200",
        "NTREX"
      ],
      "models": [
        "Mufu",
        "NLLB 1.3B distilled",
        "PaLM2",
        "Gemma",
        "PaLM2 XXS\u2013NTL",
        "PaLM2 XS",
        "Gemma 2B-IT",
        "Gemma 7B-IT",
        "NLLB 54B MoE",
        "BLOOMZ 1B7"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Compiler generated feedback for Large Language Models": {
    "filename": "Compiler generated feedback for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "original model",
        "Feedback model",
        "Short Feedback model",
        "Long Feedback model",
        "Fast Feedback model",
        "autotuner",
        "AlphaCode",
        "MLGO",
        "PrograML"
      ]
    }
  },
  "Training Language Models on Synthetic Edit Sequences Improves Code Synthesis": {
    "filename": "Training Language Models on Synthetic Edit Sequences Improves Code Synthesis.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP"
      ],
      "models": [
        "TinyCodeLM-150M",
        "TinyCodeLM-400M",
        "GPT-4",
        "GPT-4-Omni",
        "Llama 3.1 405B",
        "Codex",
        "AlphaCode",
        "CodeT5+",
        "Codegen-Mono",
        "SmolLM-Instruct",
        "TinyCodeLM-LintSeqInstruct",
        "Gemma 2",
        "Phi-3",
        "Llama 3.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dont Transform the Code Code the Transforms Towards Precise Code Rewriting using LLMs": {
    "filename": "Dont Transform the Code Code the Transforms Towards Precise Code Rewriting using LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval"
      ],
      "models": [
        "Code the transforms (CTT)",
        "Transform the code (TTC)",
        "Llama 3.1",
        "Llama 3.1 70B variant",
        "Llama 3.1 8B variant"
      ]
    }
  },
  "Towards Transferable Attacks Against Vision-LLMs in Autonomous Driving with Typography": {
    "filename": "Towards Transferable Attacks Against Vision-LLMs in Autonomous Driving with Typography.pdf",
    "analysis": {
      "benchmarks": [
        "LingoQA",
        "CVPRW'2024 Challenge"
      ],
      "models": [
        "LLaVa",
        "VILA",
        "Qwen-VL",
        "Imp",
        "GPT4"
      ]
    }
  },
  "Towards Improving Document Understanding An Exploration on Text-Grounding via MLLMs": {
    "filename": "Towards Improving Document Understanding An Exploration on Text-Grounding via MLLMs.pdf",
    "analysis": {
      "benchmarks": [
        "STVQA",
        "OCRVQA",
        "TextVQA",
        "DocVQA",
        "InfographicVQA",
        "ChartQA",
        "FUNSD",
        "SROIE",
        "POIE"
      ],
      "models": [
        "TGDoc",
        "Flamingo",
        "BLIP-2",
        "LLaVA",
        "MiniGPT-4",
        "mPLUG-DocOwl",
        "UniDoc",
        "LLaVAR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-Pruner On the Structural Pruning of Large Language Models": {
    "filename": "LLM-Pruner On the Structural Pruning of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BoolQ",
        "PIQA",
        "HellaSwag",
        "WinoGrande",
        "ARC-easy",
        "ARC-challenge",
        "OpenbookQA",
        "WikiText2",
        "PTB"
      ],
      "models": [
        "LLM-Pruner",
        "LLaMA-7B",
        "Vicuna-7B",
        "ChatGLM-6B",
        "TinyBERT",
        "DistilBERT",
        "StableLM-3B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Your Large Language Model is Secretly a Fairness Proponent and You Should Prompt it Like One": {
    "filename": "Your Large Language Model is Secretly a Fairness Proponent and You Should Prompt it Like One.pdf",
    "analysis": {
      "benchmarks": [
        "BiasAsker",
        "Comparative Questions",
        "Targeted Open-Ended Questions",
        "General Open-Ended Questions"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Llama2",
        "Mistral",
        "FAIRTHINKING"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Comparison of LLM Finetuning Methods  Evaluation Metrics with Travel Chatbot Use Case": {
    "filename": "A Comparison of LLM Finetuning Methods  Evaluation Metrics with Travel Chatbot Use Case.pdf",
    "analysis": {
      "benchmarks": [
        "End to End (E2E) benchmark",
        "RAG Assessment (Ragas)",
        "OpenAI GPT-4 evaluation metrics",
        "human evaluation"
      ],
      "models": [
        "LLaMa 2 7B",
        "Mistral 7B",
        "QLoRA",
        "RAFT",
        "RLHF",
        "Mistral RAFT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond the Frontier Predicting Unseen Walls From Occupancy Grids by Learning From Floor Plans": {
    "filename": "Beyond the Frontier Predicting Unseen Walls From Occupancy Grids by Learning From Floor Plans.pdf",
    "analysis": {
      "benchmarks": [
        "KTH floor plan dataset"
      ],
      "models": [
        "Floorist",
        "baseline convolution-based architecture",
        "non-predictive approach",
        "U-Net"
      ]
    }
  },
  "Ladder-of-Thought Using Knowledge as Steps to Elevate Stance Detection": {
    "filename": "Ladder-of-Thought Using Knowledge as Steps to Elevate Stance Detection.pdf",
    "analysis": {
      "benchmarks": [
        "VAST",
        "P-stance",
        "SemEval-2016"
      ],
      "models": [
        "LoT",
        "GPT-3.5",
        "CoT",
        "FLAN-T5-Large",
        "TGA-Net",
        "BERT",
        "BERT-GCN",
        "CKE-Net",
        "WS-BERT-Single",
        "DQA",
        "StSQA"
      ]
    }
  },
  "MVBench A Comprehensive Multi-modal Video Understanding Benchmark": {
    "filename": "MVBench A Comprehensive Multi-modal Video Understanding Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "MVBench",
        "SEED-Bench",
        "FunQA",
        "Perception Test",
        "STAR",
        "PAXION",
        "Moments in Time V1",
        "CLEVRER",
        "Charades-STA",
        "MoVQA",
        "NTU RGB+D",
        "VLN-CE",
        "TVQA"
      ],
      "models": [
        "VideoChat2",
        "VideoChat",
        "Flamingo",
        "PaLM-E",
        "LLaVA",
        "MiniGPT-4",
        "InstructBLIP",
        "VideoChatGPT",
        "Valley",
        "Otter",
        "mPLUG-Owl",
        "LLaMA-Adapter",
        "BLIP2",
        "InstructBLIP",
        "VideoLLaMA",
        "GPT-4V"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring Value Biases How LLMs Deviate Towards the Ideal": {
    "filename": "Exploring Value Biases How LLMs Deviate Towards the Ideal.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Text Classification via Large Language Models": {
    "filename": "Text Classification via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SST-2",
        "AGNews",
        "R8",
        "R52",
        "MR"
      ],
      "models": [
        "CARP",
        "RoBERTa-Large",
        "DeBERTa",
        "RoBERTa-GCN",
        "XLNet",
        "VLAWE",
        "GCN-SB",
        "Vanilla",
        "CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Invariant Learning Characterization of Controlled Text Generation": {
    "filename": "An Invariant Learning Characterization of Controlled Text Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CivilComments",
        "RealToxicityPrompts"
      ],
      "models": [
        "ERM",
        "V-REx",
        "MMD",
        "CORAL",
        "EVIAN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DeiSAM Segment Anything with Deictic Prompting": {
    "filename": "DeiSAM Segment Anything with Deictic Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "Deictic Visual Genome (DeiVG)",
        "DeiRefCOCO+",
        "RefCOCO",
        "DeiCLEVR"
      ],
      "models": [
        "DeiSAM",
        "Grounding Dino",
        "Segment Anything Model (SAM)",
        "GroundedSAM",
        "SEEM",
        "OFA-SAM",
        "GLIP-SAM",
        "LISA",
        "VETO",
        "Slot Attention"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Vision Language Models are In-Context Value Learners": {
    "filename": "Vision Language Models are In-Context Value Learners.pdf",
    "analysis": {
      "benchmarks": [
        "Open X-Embodiment (OXE) dataset",
        "ALOHA platform",
        "RT-1",
        "Dobb-E",
        "Bridge",
        "QT-OPT",
        "DROID",
        "RoboNet"
      ],
      "models": [
        "Generative Value Learning (GVL)",
        "Gemini-1.5-Pro",
        "LIV",
        "SuccessVQA",
        "SuccessVQA-CoT",
        "Action Chunking Transformer (ACT)",
        "Diffusion Policy (DP)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Complementary Explanations for Effective In-Context Learning": {
    "filename": "Complementary Explanations for Effective In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "LETTER CONCATENATION (LETCAT)",
        "COINFLIPS",
        "GRADE SCHOOL MATH (GSM)",
        "ECQA",
        "E-SNLI"
      ],
      "models": [
        "OPT-175B",
        "GPT-3 (davinci)",
        "InstructGPT (text-davinci-001)",
        "text-davinci-002",
        "GPT-3 Codex (code-davinci-001)",
        "GPT-3 Codex (code-davinci-002)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DoRA Weight-Decomposed Low-Rank Adaptation": {
    "filename": "DoRA Weight-Decomposed Low-Rank Adaptation.pdf",
    "analysis": {
      "benchmarks": [
        "LLaMA",
        "LLaVA",
        "VL-BART",
        "commonsense reasoning",
        "visual instruction tuning",
        "image/video-text understanding",
        "VQAv2",
        "GQA",
        "NLVR2",
        "COCO Caption",
        "TVQA",
        "How2QA",
        "TVC",
        "YC2C",
        "VisWiz",
        "SQA",
        "VQAT",
        "POPE",
        "MMBench",
        "MT-Bench",
        "Orca-Math"
      ],
      "models": [
        "DoRA",
        "LoRA",
        "LLaMA-7B",
        "LLaMA-13B",
        "LLaMA2-7B",
        "LLaMA3-8B",
        "VL-BART",
        "LLaVA-1.5-7B",
        "VeRA",
        "DV oRA",
        "QLoRA",
        "QDoRA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Logic-LM Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning": {
    "filename": "Logic-LM Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "ProofWriter",
        "PrOntoQA",
        "FOLIO",
        "LogicalDeduction",
        "AR-LSAT"
      ],
      "models": [
        "LOGIC-LM",
        "Standard LLMs",
        "Chain-of-Thought (CoT)",
        "ChatGPT (gpt-3.5-turbo)",
        "GPT-3.5 (text-davinci-003)",
        "GPT-4 (gpt-4)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoTrial Prompting Language Models for Clinical Trial Design": {
    "filename": "AutoTrial Prompting Language Models for Clinical Trial Design.pdf",
    "analysis": {
      "benchmarks": [
        "ClinicalTrials.gov"
      ],
      "models": [
        "AutoTrial",
        "GPT-3.5",
        "GPT2-FT",
        "GPT2-RAG",
        "GPT2-PT",
        "GPT2-SimCTG",
        "T5-FT",
        "T5-RAG",
        "T5-PT",
        "T5-SimCTG"
      ]
    }
  },
  "Parrot Mind Towards Explaining the Complex Task Reasoning of Pretrained Large Language Models with Template-Content Structure": {
    "filename": "Parrot Mind Towards Explaining the Complex Task Reasoning of Pretrained Large Language Models with Template-Content Structure.pdf",
    "analysis": {
      "benchmarks": [
        "SingleEQ",
        "GSM8k"
      ],
      "models": [
        "GPT-4",
        "GPT2-335m",
        "GPT2-774m",
        "GPT2-1.5b",
        "OPT-1.3b",
        "OPT-13b",
        "OPT-30b",
        "Llama2-7b",
        "Llama2-13b",
        "Llama2-70b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unlocking the Potential of Large Language Models for Explainable Recommendations": {
    "filename": "Unlocking the Potential of Large Language Models for Explainable Recommendations.pdf",
    "analysis": {
      "benchmarks": [
        "ML-100k",
        "Mind",
        "Steam"
      ],
      "models": [
        "LLMXRec",
        "BPR-MF",
        "SASRec",
        "LightGCN",
        "LLaMA",
        "ChatGLM",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Boosting Logical Reasoning in Large Language Models through a New Framework The Graph of Thought": {
    "filename": "Boosting Logical Reasoning in Large Language Models through a New Framework The Graph of Thought.pdf",
    "analysis": {
      "benchmarks": [
        "24-point game",
        "high-degree polynomial equations",
        "recursive sequences"
      ],
      "models": [
        "Graph of Thought (GoT)",
        "GPT-4",
        "Tree of Thought (ToT)",
        "Chain-of-Thought (CoT)",
        "Self-Consistency of Chain-of-Thought (SC-CoT)"
      ]
    }
  },
  "When Can Transformers Count to n": {
    "filename": "When Can Transformers Count to n.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "transformer",
        "Gemini 1.5",
        "CountAttend",
        "Histogram solution"
      ]
    }
  },
  "LLMs for Knowledge Graph Construction and Reasoning Recent Capabilities and Future Opportunities": {
    "filename": "LLMs for Knowledge Graph Construction and Reasoning Recent Capabilities and Future Opportunities.pdf",
    "analysis": {
      "benchmarks": [
        "DuIE2.0",
        "SciERC",
        "Re-TACRED",
        "MAVEN",
        "FB15K-237",
        "ATOMIC 2020",
        "FreebaseQA",
        "MetaQA",
        "VINE"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "text-davinci-003",
        "AutoKG",
        "PaddleNLP LIC2021 IE",
        "PL-Marker",
        "EXOBRAIN",
        "C-LMKE (BERT-base)",
        "COMET (BART)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Synatra Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale": {
    "filename": "Synatra Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale.pdf",
    "analysis": {
      "benchmarks": [
        "Mind2Web",
        "MiniWoB++",
        "WebArena"
      ],
      "models": [
        "Synatra-CodeLlama",
        "GPT-3.5",
        "GPT-4",
        "CodeLlama-instruct-7b",
        "Llama3-chat-8b",
        "Llama3-chat-70b",
        "FireAct-7b",
        "AgentLM-7b",
        "CodeActAgent-7b",
        "AutoWebGLM-7b(S1)",
        "AgentFlan-7b",
        "Lemur-chat-70b",
        "AgentLM-70b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cut the Crap An Economical Communication Pipeline for LLM-based Multi-Agent Systems": {
    "filename": "Cut the Crap An Economical Communication Pipeline for LLM-based Multi-Agent Systems.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "GSM8K",
        "MultiArith",
        "SVAMP",
        "AQuA",
        "HumanEval"
      ],
      "models": [
        "AgentPrune",
        "gpt-3.5-turbo",
        "gpt-4-1106-preview",
        "AutoGen",
        "GPTSwarm",
        "LLM-Debate",
        "DyLAN",
        "PHP",
        "Chain",
        "Star",
        "Tree",
        "Complete Graph",
        "Layered Graph",
        "Random Graph",
        "LLM-Blender",
        "CoT",
        "ComplexCoT",
        "SC (CoT)",
        "SC (ComplexCoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Opportunities for Retrieval and Tool Augmented Large Language Models in Scientific Facilities": {
    "filename": "Opportunities for Retrieval and Tool Augmented Large Language Models in Scientific Facilities.pdf",
    "analysis": {
      "benchmarks": [
        "Advanced Photon Source (APS)",
        "Center for Nanoscale Materials (CNM)",
        "Argonne Leadership Computing Facility (ALCF)",
        "Center for Nanophase Materials Sciences (CNMS)"
      ],
      "models": [
        "Context-Aware Language Model for Science (CALMS)",
        "GPT-3.5 Turbo",
        "Vicuna",
        "lmsys/vicuna-13b-v1.5"
      ]
    }
  },
  "Visualization Generation with Large Language Models An Evaluation": {
    "filename": "Visualization Generation with Large Language Models An Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "nvBench",
        "NLVCorpus"
      ],
      "models": [
        "GPT-3.5",
        "Chat2VIS",
        "LIDA",
        "ncNet",
        "RGVisNet",
        "ADVISor",
        "DeepEye",
        "NL4DV",
        "Articulate",
        "DataTone",
        "Eviza",
        "FlowSense"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unveiling the Secret Recipe A Guide For Supervised Fine-Tuning Small LLMs": {
    "filename": "Unveiling the Secret Recipe A Guide For Supervised Fine-Tuning Small LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "MTBench",
        "Open LLM Leaderboard",
        "MMLU-Pro",
        "GPQA",
        "MuSR",
        "MATH",
        "IFEval",
        "BBH",
        "ARC",
        "GSM8K",
        "ToxiGen",
        "TruthfulQA"
      ],
      "models": [
        "Granite 3B",
        "Granite 7B",
        "Llama 3.2 3B",
        "Mistral 7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Premise Order Matters in Reasoning with Large Language Models": {
    "filename": "Premise Order Matters in Reasoning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "R-GSM",
        "GSM8K",
        "SimpleLogic"
      ],
      "models": [
        "GPT-4-turbo",
        "GPT-3.5-turbo",
        "PaLM 2-L",
        "Gemini 1.0 Pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AI Chain on Large Language Model for Unsupervised Control Flow Graph Generation for Statically-Typed Partial Code": {
    "filename": "AI Chain on Large Language Model for Unsupervised Control Flow Graph Generation for Statically-Typed Partial Code.pdf",
    "analysis": {
      "benchmarks": [
        "NC dataset",
        "ESE dataset",
        "ISE dataset"
      ],
      "models": [
        "CFG-Chain",
        "Soot",
        "Spoon",
        "CFG-D",
        "CFG-CoT",
        "CFG-Chain w/oAPR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tasks People Prompt A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches": {
    "filename": "Tasks People Prompt A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches.pdf",
    "analysis": {
      "benchmarks": [
        "SWE-bench",
        "GitHub issues"
      ],
      "models": [
        "TestGen-LLM",
        "FSML",
        "ChatGPTTests",
        "CodeT",
        "ChatUniTest",
        "CodeCoT",
        "AgentCoder",
        "CodaMOSA",
        "TestChain",
        "CoverUp",
        "TestPilot",
        "EASEeval",
        "TELPA",
        "ChatTESTER",
        "DiffPrompt",
        "AID",
        "secTests",
        "SymPrompt",
        "RESTGPT",
        "InputBlaster",
        "PBT-GPT",
        "mrDetector",
        "MuTAP",
        "BugFarm",
        "\u00b5BERT",
        "CHEMFUZZ",
        "FormAI",
        "LLMorpheus",
        "OSS-Fuzz",
        "ChatFuzz",
        "Fuzz4All",
        "UGCTX",
        "KernelGPT",
        "SearchGEM5",
        "WhiteFox",
        "FuzzingParsers",
        "ChatAFL",
        "TitanFuzz",
        "FuzzGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Retrieval Augmented Generation RAG and Beyond A Comprehensive Survey on How to Make your LLMs use External Data More Wisely": {
    "filename": "Retrieval Augmented Generation RAG and Beyond A Comprehensive Survey on How to Make your LLMs use External Data More Wisely.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Questions",
        "MS MARCO",
        "TriviaQA",
        "SQuAD",
        "ASQA",
        "WebQSP",
        "HotPotQA",
        "2WikiMultiHopQA",
        "MuSiQue",
        "Bamboogle",
        "StrategyQA",
        "ComplexWebQuestions",
        "WebQuestions",
        "Mintaka",
        "MetaQA",
        "qasper",
        "DROP",
        "Multi-Choice QuALITY",
        "Fact Checking Feverous"
      ],
      "models": [
        "Retrieval-Augmented Generation (RAG)",
        "ReAct",
        "IRCoT",
        "RAT",
        "GenGround",
        "ITRG",
        "FLARE",
        "Self-RAG",
        "Think-on-Graph",
        "KnowledgeNavigator",
        "R3",
        "MoGG",
        "RAPTOR",
        "GraphRAG",
        "Text2MDT",
        "MedDM",
        "InstructRec",
        "TEMPERA",
        "Rlprompt",
        "GrIPS",
        "OPRO",
        "Reflexion",
        "Automate-CoT",
        "CoML",
        "MetaGPT",
        "ChatTimeLlama",
        "LISA",
        "MAmmoTH",
        "ReFT",
        "ChatDoctor",
        "FinGPT",
        "DISC-LawLLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating ChatGPT-35 Efficiency in Solving Coding Problems of Different Complexity Levels An Empirical Analysis": {
    "filename": "Evaluating ChatGPT-35 Efficiency in Solving Coding Problems of Different Complexity Levels An Empirical Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "LeetCode"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4",
        "Claude 3 Sonnet",
        "Gemini 1.0 Pro"
      ]
    }
  },
  "Harnessing the Power of LLMs in Practice A Survey on ChatGPT and Beyond": {
    "filename": "Harnessing the Power of LLMs in Practice A Survey on ChatGPT and Beyond.pdf",
    "analysis": {
      "benchmarks": [
        "IMDB",
        "SST",
        "CivilComments",
        "RTE",
        "SNLI",
        "CB",
        "SQuADv2",
        "QuAC",
        "CoQA",
        "MS MARCO",
        "CoNLL03",
        "GLUE",
        "SuperGLUE",
        "ANLI",
        "CNN/DailyMail",
        "XSUM",
        "WMT'16",
        "HumanEval",
        "MBPP",
        "DeepFix",
        "NaturalQuestions",
        "WebQuestions",
        "TriviaQA",
        "MMLU",
        "Big-bench",
        "GSM8k",
        "SVAMP",
        "AQuA",
        "StrategyQA",
        "ARC-C",
        "Redefine-math",
        "Into-the-unknown",
        "Memo-trap",
        "Hindsight-neglect",
        "NegationQA",
        "Quote-repetition",
        "STS-B"
      ],
      "models": [
        "GPT-3",
        "GPT-4",
        "BERT",
        "RoBERTa",
        "T5",
        "OPT",
        "BLOOM",
        "InstructGPT",
        "ChatGPT",
        "PaLM",
        "LLaMA",
        "Alpaca-LoRA",
        "LoRA",
        "Prefix Tuning",
        "P-Tuning",
        "FLAN",
        "T0",
        "DeltaLM+Zcode",
        "Perspective API",
        "Brio",
        "Pegasus",
        "GPT-J",
        "davinci v2",
        "BEiT",
        "PaLI"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "KoMA Knowledge-driven Multi-agent Framework for Autonomous Driving with Large Language Models": {
    "filename": "KoMA Knowledge-driven Multi-agent Framework for Autonomous Driving with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "highway-env",
        "ramp merging scenario",
        "roundabout scenario"
      ],
      "models": [
        "KoMA",
        "DiLu",
        "GPT-4",
        "GPT-3.5",
        "Llama3-8B",
        "Llama2-7B",
        "Qwen2-7B",
        "deep multi-agent reinforcement learning (MARL)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Multimodal Models Notes on CVPR 2023 Tutorial": {
    "filename": "Large Multimodal Models Notes on CVPR 2023 Tutorial.pdf",
    "analysis": {
      "benchmarks": [
        "Vicuna-Instructions-80",
        "Science QA"
      ],
      "models": [
        "LLaVA",
        "MiniGPT-4",
        "BLIP2",
        "GIT",
        "Flamingo",
        "OpenFlamingo",
        "Vicuna",
        "GPT-4",
        "ChatGPT",
        "InstructGPT",
        "LLaMA",
        "Alpaca",
        "Tulu",
        "OpenLLaMA",
        "MPT",
        "Falcon"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reflective Linguistic Programming RLP A Stepping Stone in Socially-Aware AGI SocialAGI": {
    "filename": "Reflective Linguistic Programming RLP A Stepping Stone in Socially-Aware AGI SocialAGI.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Re\ufb02ective Linguistic Programming (RLP)",
        "GPT-4",
        "GPT4 + RLP"
      ]
    }
  },
  "CharacterChat Learning towards Conversational AI with Personalized Social Support": {
    "filename": "CharacterChat Learning towards Conversational AI with Personalized Social Support.pdf",
    "analysis": {
      "benchmarks": [
        "MBTI-S2Conv"
      ],
      "models": [
        "CharacterChat",
        "Llama2-7B",
        "BERT",
        "BlenderBot-Joint",
        "Vicuna-13b-v1.5",
        "ChatGPT"
      ]
    }
  },
  "DuetRAG Collaborative Retrieval-Augmented Generation": {
    "filename": "DuetRAG Collaborative Retrieval-Augmented Generation.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA"
      ],
      "models": [
        "DuetRAG",
        "LLaMA2-7B",
        "LLaMA2-7B + RAG",
        "DSF(LLaMA2-7B)",
        "DSF+RAG(LLaMA2-7B)",
        "Internal Model Mi",
        "External Model Me",
        "GPT-3.5",
        "ChatGPT-3.5"
      ]
    }
  },
  "Learning How Hard to Think Input-Adaptive Allocation of LM Computation": {
    "filename": "Learning How Hard to Think Input-Adaptive Allocation of LM Computation.pdf",
    "analysis": {
      "benchmarks": [
        "TACO",
        "Numina-COT Dataset",
        "LMSYS-Chat",
        "Anthropic HH"
      ],
      "models": [
        "Starcoder-15B",
        "Mathstral-7B",
        "Gemma-2B-it",
        "Gemma-7B-it",
        "Llama-2 7B",
        "OpenAssistant/reward-model-deberta-v3-large-v2"
      ]
    }
  },
  "Visualizationary Automating Design Feedback for Visualization Designers using LLMs": {
    "filename": "Visualizationary Automating Design Feedback for Visualization Designers using LLMs.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Visualizationary",
        "ChatGPT",
        "VLM (vision-language model)",
        "OpenAI GPT API",
        "Scanner Deeply",
        "DePlot",
        "YoloR",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Data-Copilot Bridging Billions of Data and Humans with Autonomous Workflow": {
    "filename": "Data-Copilot Bridging Billions of Data and Humans with Autonomous Workflow.pdf",
    "analysis": {
      "benchmarks": [
        "Chinese financial data",
        "Tushare"
      ],
      "models": [
        "Data-Copilot",
        "LiDA",
        "GPT4-Analyst",
        "Sheet-Copilot",
        "BIRD",
        "DS-Agent",
        "DB-GPT",
        "Data Interpreter",
        "ReAct",
        "Reflexion",
        "Multi-Agent"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An AIC-based approach for articulating unpredictable problems in open complex environments": {
    "filename": "An AIC-based approach for articulating unpredictable problems in open complex environments.pdf",
    "analysis": {
      "benchmarks": [
        "AVOIDDS: Aircraft Vision-based Intruder Detection Dataset and Simulator"
      ],
      "models": [
        "AIC-based Chain-of-Thought (AIC-based CoT)",
        "perception-based collision avoidance system (AVP)"
      ]
    }
  },
  "MagicLens Self-Supervised Image Retrieval with Open-Ended Instructions": {
    "filename": "MagicLens Self-Supervised Image Retrieval with Open-Ended Instructions.pdf",
    "analysis": {
      "benchmarks": [
        "CIRCO",
        "Domain Transfer ImageNet",
        "GeneCIS",
        "FIQ",
        "CIRR",
        "DTIN",
        "TU-Berlin",
        "Sketchy",
        "QuickDraw",
        "Flickr30K",
        "MSCOCO"
      ],
      "models": [
        "MagicLens",
        "MagicLens-B",
        "MagicLens-L",
        "CIReVL",
        "CompoDiff",
        "LinCIR",
        "SEARLE",
        "Pic2Word",
        "Context-I2W",
        "PLI",
        "PALARV A"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Text2CAD Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts": {
    "filename": "Text2CAD Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts.pdf",
    "analysis": {
      "benchmarks": [
        "DeepCAD"
      ],
      "models": [
        "Text2CAD",
        "Text2CAD Transformer",
        "Text2CAD w/o AL",
        "DeepCAD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Citation A Key to Building Responsible and Accountable Large Language Models": {
    "filename": "Citation A Key to Building Responsible and Accountable Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-4",
        "New Bing",
        "Perplexity AI"
      ]
    }
  },
  "Aligning Large Language Models for Enhancing Psychiatric Interviews through Symptom Delineation and Summarization": {
    "filename": "Aligning Large Language Models for Enhancing Psychiatric Interviews through Symptom Delineation and Summarization.pdf",
    "analysis": {
      "benchmarks": [
        "G-Eval",
        "BERTScore"
      ],
      "models": [
        "GPT-4 Turbo",
        "GPT-3.5 Turbo",
        "Med-PaLM",
        "Med-PaLM 2",
        "ChatGPT",
        "BERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reasoning in Large Language Models A Geometric Perspective": {
    "filename": "Reasoning in Large Language Models A Geometric Perspective.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K-Zero"
      ],
      "models": [
        "GPT-4",
        "Llama 3",
        "Llama3 8B",
        "Llama3 70B",
        "Mixtral 8\u00d722B"
      ]
    }
  },
  "SeqMate A Novel Large Language Model Pipeline for Automating RNA Sequencing": {
    "filename": "SeqMate A Novel Large Language Model Pipeline for Automating RNA Sequencing.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "SeqMate",
        "OpenAI's gpt-3.5-turbo-0125"
      ]
    }
  },
  "Large Language Models can Learn Rules": {
    "filename": "Large Language Models can Learn Rules.pdf",
    "analysis": {
      "benchmarks": [
        "CLUTRR",
        "Arithmetic",
        "List Functions"
      ],
      "models": [
        "Hypotheses-to-Theories (HtT)",
        "GPT-3.5",
        "GPT-4",
        "EdgeTransformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning": {
    "filename": "Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "AerialVLN-S"
      ],
      "models": [
        "Semantic-Topo-Metric Representation (STMR)",
        "Grounding Dino",
        "Tokenize Anything",
        "NavGPT",
        "MapGPT",
        "Random",
        "Action Sampling",
        "LingUNet",
        "Seq2Seq",
        "CMA",
        "LAG"
      ]
    }
  },
  "Caption Anything Interactive Image Description with Diverse Multimodal Controls": {
    "filename": "Caption Anything Interactive Image Description with Diverse Multimodal Controls.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Caption AnyThing (CAT)",
        "Segment Anything Model (SAM)",
        "ChatGPT",
        "BLIP2",
        "LLaMA",
        "OPT-IML",
        "BLOOM"
      ]
    }
  },
  "A Survey of Confidence Estimation and Calibration in Large Language Models": {
    "filename": "A Survey of Confidence Estimation and Calibration in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "MCQA"
      ],
      "models": [
        "OPT",
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "Vicuna",
        "Claude",
        "Anthropic LLM",
        "LLaMA",
        "Falcon",
        "BART",
        "T5",
        "PEGASUS",
        "PALM-2",
        "CLIP",
        "GPT-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Synthesis of Mathematical programs from Natural Language Specifications": {
    "filename": "Synthesis of Mathematical programs from Natural Language Specifications.pdf",
    "analysis": {
      "benchmarks": [
        "NL4OPT"
      ],
      "models": [
        "CodeT5",
        "GPT-3",
        "ChatGPT",
        "Codex",
        "BART-large",
        "CodeBERT",
        "CodeGPT",
        "Bloom",
        "Flan-T5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-Refine Iterative Refinement with Self-Feedback": {
    "filename": "Self-Refine Iterative Refinement with Self-Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "Dialogue Response Generation",
        "Code Optimization",
        "Code Readability Improvement",
        "Math Reasoning",
        "Sentiment Reversal",
        "Acronym Generation",
        "Constrained Generation"
      ],
      "models": [
        "SELF-REFINE",
        "GPT-3.5",
        "ChatGPT",
        "GPT-4",
        "Codex"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NoFunEval Funny How Code LMs Falter on Requirements Beyond Functional Correctness": {
    "filename": "NoFunEval Funny How Code LMs Falter on Requirements Beyond Functional Correctness.pdf",
    "analysis": {
      "benchmarks": [
        "NoFunEval",
        "NoFunEdit",
        "NoFunClassify",
        "HumanEval",
        "HumanEvalFix",
        "HumanEvalClassify",
        "PIEdataset"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5-Turbo",
        "CodeLlama-34B-Inst",
        "Phind-CodeLlama-34B",
        "CodeLlama-34B",
        "WizardCoder-Py-34B",
        "Deepseek-33B-Inst",
        "Deepseek-33B",
        "WizardCoder-15B",
        "Starcoder-15B",
        "CodeLlama-13B-Inst",
        "CodeLlama-13B",
        "CodeLlama-7B-Inst",
        "CodeLlama-7B",
        "Mistral-7B-Inst",
        "Mistral-7B",
        "Deepseek-6.7B-Inst",
        "Deepseek-6.7B",
        "CodeGemma-2B",
        "CodeGemma-7B",
        "CodeGemma-7B-Inst",
        "DeepSeekCoder-1.3B",
        "DeepSeekCoder-1.3B-Inst",
        "DeepSeekCoder-6.7B",
        "DeepSeekCoder-6.7B-Inst",
        "DeepSeekCoder-33B",
        "DeepSeekCoder-33B-Inst"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on Conversational Search and Applications in Biomedicine": {
    "filename": "A Survey on Conversational Search and Applications in Biomedicine.pdf",
    "analysis": {
      "benchmarks": [
        "BioLAMA",
        "MedLAMA"
      ],
      "models": [
        "BM25",
        "BERT-QPP",
        "TripPy",
        "AskHERMES",
        "GAH model",
        "Medical Knowledge Graph (MKG)",
        "LSTM-based structure",
        "Neural Network-based Question Answering",
        "Recurrent neural network",
        "Attention-based Generative Adversarial Hashing"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Guide-LLM An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments": {
    "filename": "Guide-LLM An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments.pdf",
    "analysis": {
      "benchmarks": [
        "iGibson simulator"
      ],
      "models": [
        "Guide-LLM",
        "GPT-4o",
        "CLIP",
        "TurtleBot"
      ]
    }
  },
  "Can a large language model be a gaslighter": {
    "filename": "Can a large language model be a gaslighter.pdf",
    "analysis": {
      "benchmarks": [
        "DangerousQA",
        "MT-Bench"
      ],
      "models": [
        "DeepCoG",
        "DeepGaslighting",
        "Chain-of-Gaslighting",
        "Llama2",
        "Vicuna",
        "Mistral",
        "ChatGPT",
        "Vicuna-G1",
        "Vicuna-G2",
        "Vicuna-S1",
        "Vicuna-S2",
        "Vicuna-S3",
        "Mistral-G1",
        "Mistral-G2",
        "Mistral-S1",
        "Mistral-S2",
        "Mistral-S3",
        "Llama2-G1",
        "Llama2-G2",
        "Llama2-S1",
        "Llama2-S2",
        "Llama2-S3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Which Examples to Annotate for In-Context Learning Towards Effective and Efficient Selection": {
    "filename": "Which Examples to Annotate for In-Context Learning Towards Effective and Efficient Selection.pdf",
    "analysis": {
      "benchmarks": [
        "AGNews",
        "TREC",
        "SST2",
        "Amazon",
        "RTE",
        "MRPC",
        "MNLI",
        "XSUM",
        "GSM8K"
      ],
      "models": [
        "ADAICL",
        "GPT-J",
        "Mosaic",
        "Falcon",
        "LLaMa",
        "Random",
        "Pseudo-labeling",
        "Fast-vote k",
        "Votek",
        "Hardest",
        "ADAICL-base"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AVA Towards Autonomous Visualization Agents through Visual PerceptionDriven DecisionMaking": {
    "filename": "AVA Towards Autonomous Visualization Agents through Visual PerceptionDriven DecisionMaking.pdf",
    "analysis": {
      "benchmarks": [
        "Boston Teapot",
        "Visible Male",
        "Diamond data",
        "Out5D data",
        "RNA sequence data"
      ],
      "models": [
        "Autonomous Visualization Agents (AVAs)",
        "GPT-4 Vision",
        "Heuristic-Centric AVA",
        "LLM-Centric AVA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GAPS Geometry-Aware Problem Solver": {
    "filename": "GAPS Geometry-Aware Problem Solver.pdf",
    "analysis": {
      "benchmarks": [
        "UniGeo",
        "PGPS9K",
        "Geometry3K"
      ],
      "models": [
        "GAPS",
        "Geoformer",
        "NGS",
        "BERT2Prog",
        "Seq2Prog",
        "FiLM",
        "RN",
        "MCAN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompted LLMs as Chatbot Modules for Long Open-domain Conversation": {
    "filename": "Prompted LLMs as Chatbot Modules for Long Open-domain Conversation.pdf",
    "analysis": {
      "benchmarks": [
        "Multi-Session Chat dataset",
        "PersonaChat"
      ],
      "models": [
        "MPC (Modular Prompted Chatbot)",
        "Blenderbot3 (BB3)",
        "Open Pre-trained Transformers (OPT)",
        "GPT-J",
        "BART",
        "Dense Passage Retriever (DPR)",
        "OpenAI GPT-3 text-davinci-002",
        "davinci",
        "OPT 30B",
        "OPT 66B",
        "GPT-JT-6B",
        "BLOOM-176B",
        "BB3-30B",
        "BB3-175B"
      ]
    }
  },
  "Beyond Numeric Awards In-Context Dueling Bandits with LLM Agents": {
    "filename": "Beyond Numeric Awards In-Context Dueling Bandits with LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Easy instance",
        "Hard instance"
      ],
      "models": [
        "GPT-3.5 TURBO",
        "GPT-4",
        "GPT-4 TURBO",
        "LLAMA 3.1",
        "O1-PREVIEW",
        "LEAD",
        "Interleaved Filter (IF2)",
        "Beat the Mean (BTM)",
        "Sensitivity Analysis of Variables for Generic Exploration (SAVAGE)",
        "Relative Upper Confidence Bound (RUCB)",
        "Relative Confidence Sampling (RCS)",
        "Relative Minimum Empirical Divergence (RMED)",
        "Self-Sparring",
        "Double Thompson Sampling (DTS)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language models show human-like content effects on reasoning": {
    "filename": "Language models show human-like content effects on reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Language Inference",
        "Syllogisms",
        "Wason Selection Task"
      ],
      "models": [
        "Chinchilla",
        "PaLM 2-M",
        "PaLM 2-L",
        "Flan-PaLM 2",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Plot2Code A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots": {
    "filename": "Plot2Code A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots.pdf",
    "analysis": {
      "benchmarks": [
        "Plot2Code",
        "HumanEval",
        "MBPP",
        "Design2Code",
        "MMCode"
      ],
      "models": [
        "GPT-4V",
        "Gemini-Pro",
        "Mini-Gemini",
        "Claude-3",
        "ChatGPT",
        "GPT-4",
        "DeepSeek-VL",
        "LLaVA-1.6-Mistral-7B",
        "Mini-Gemini-8x7B-HD",
        "Mini-Gemini-34B-HD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RCAgent Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models": {
    "filename": "RCAgent Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "RCAgent",
        "ReAct",
        "RCACopilot",
        "PACE-LM",
        "Xpert",
        "Vicuna-13B-V1.5-16K",
        "GTE-LARGE",
        "gpt-4-0613",
        "XGBoost",
        "Finetune T5",
        "LLM Summary"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Looped Transformers are Better at Learning Learning Algorithms": {
    "filename": "Looped Transformers are Better at Learning Learning Algorithms.pdf",
    "analysis": {
      "benchmarks": [
        "linear functions",
        "sparse linear functions",
        "decision trees",
        "2-layer neural networks",
        "OpenML datasets"
      ],
      "models": [
        "looped transformer",
        "standard transformer",
        "Least Squares",
        "Lasso",
        "3-Nearest Neighbors",
        "Greedy Tree Learning",
        "XGBoost",
        "2-layer NN, GD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Explaining Tree Model Decisions in Natural Language for Network Intrusion Detection": {
    "filename": "Explaining Tree Model Decisions in Natural Language for Network Intrusion Detection.pdf",
    "analysis": {
      "benchmarks": [
        "NF-BoT",
        "Iris"
      ],
      "models": [
        "LLM-DTE",
        "Decision Tree",
        "Rule-Based Explanations",
        "LLM-Based Explanations",
        "GPT-4"
      ]
    }
  },
  "Pricing and Competition for Generative AI": {
    "filename": "Pricing and Competition for Generative AI.pdf",
    "analysis": {
      "benchmarks": [
        "Chatbot Arena",
        "Anthropic HH"
      ],
      "models": [
        "GitHub Copilot",
        "GPT-4",
        "LLaMA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Captioning and Retrieving Remote Sensing Images": {
    "filename": "Large Language Models for Captioning and Retrieving Remote Sensing Images.pdf",
    "analysis": {
      "benchmarks": [
        "RSICD",
        "Sydney-Captions",
        "UCM-Captions",
        "NWPU-Captions",
        "RemoteCLIP dataset",
        "Cap-4"
      ],
      "models": [
        "RS-CapRet",
        "MLCA-Net",
        "VLCA",
        "GaLR",
        "KCR",
        "CLIP",
        "RemoteCLIP",
        "RSGPT",
        "SkyEyeGPT",
        "GeoChat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models": {
    "filename": "Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "IMDB",
        "WikiData (Books and Movies)",
        "Opendatasoft (2023) (Nobel Winners)",
        "Celebrity dataset sourced from Wikidata"
      ],
      "models": [
        "Gradient Guided Prompt Perturbation (GGPP)",
        "GPT-J-6B",
        "Mistral-7B",
        "Qwen-7B",
        "SFR-Embedding-Mistral",
        "Greedy Coordinate Gradient (GCG)",
        "Universal Adversarial Trigger (UAT)",
        "SATe probe",
        "ACT probe"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Taxonomy for Human-LLM Interaction Modes An Initial Exploration": {
    "filename": "A Taxonomy for Human-LLM Interaction Modes An Initial Exploration.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "Claude",
        "Gemini",
        "Llama 2",
        "Programmer\u2019s Assistant",
        "AI Chains",
        "VISAR",
        "BotDesigner",
        "PromptMaker",
        "GenLine",
        "GenForm",
        "AutoSurveyGPT",
        "Interaction of Thoughts",
        "Chatbots Facilitating Consensus-Building"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "What Did I Do Wrong Quantifying LLMs Sensitivity and Consistency to Prompt Engineering": {
    "filename": "What Did I Do Wrong Quantifying LLMs Sensitivity and Consistency to Prompt Engineering.pdf",
    "analysis": {
      "benchmarks": [
        "TREC",
        "CommittmentBank (CB)",
        "RTE",
        "DBPedia",
        "Web of Science 46985 (WoS)"
      ],
      "models": [
        "Llama-3-70B-Instruct",
        "Mixtral-8x7B-Instruct-v0.1",
        "GPT-3.5-turbo-0125",
        "GPT-4o-2024-08-06"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Process Reward Model with Q-Value Rankings": {
    "filename": "Process Reward Model with Q-Value Rankings.pdf",
    "analysis": {
      "benchmarks": [
        "MATH500",
        "GSM-Plus"
      ],
      "models": [
        "Process Q-value Model (PQM)",
        "Outcome Reward Model (ORM)",
        "MetaMath-Mistral-7B",
        "MuggleMath-13B",
        "Llama-3-70B-Instruct",
        "Deepseek-7B-base",
        "Deepseek-math-7b-rl",
        "Qwen2-math-1.5b",
        "Qwen2-math-1.5b-inst",
        "Metamath-7b",
        "Metamath-13b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Semantic anomaly detection with large language models": {
    "filename": "Semantic anomaly detection with large language models.pdf",
    "analysis": {
      "benchmarks": [
        "CARLA simulator",
        "Ravens"
      ],
      "models": [
        "LLM-based monitor",
        "YOLOv8",
        "DETR",
        "CLIPort",
        "SCOD",
        "Mahalanobis distance",
        "Autoencoder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "XRICL Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing": {
    "filename": "XRICL Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing.pdf",
    "analysis": {
      "benchmarks": [
        "XS PIDER",
        "XK AGGLE -DBQA",
        "CSPIDER",
        "VSPIDER",
        "SPIDER"
      ],
      "models": [
        "XRICL",
        "GPT-3",
        "Codex",
        "mT5",
        "mUSE",
        "mSBERT",
        "mT5-encoder",
        "DE-Retriever",
        "DE-R2",
        "RAT-SQL",
        "InfoXLM"
      ]
    }
  },
  "Is It Safe to Cross Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing": {
    "filename": "Is It Safe to Cross Interpretable Risk Assessment with GPT-4V for Safety-Aware Street Crossing.pdf",
    "analysis": {
      "benchmarks": [
        "custom outdoor street crossing dataset"
      ],
      "models": [
        "GPT-4V",
        "YOLOv8-Seg",
        "YOLOv8",
        "baseline model",
        "Chain-of-Thought (CoT)"
      ]
    }
  },
  "Self-Supervised Multimodal Learning A Survey": {
    "filename": "Self-Supervised Multimodal Learning A Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "CLIP",
        "ALIGN",
        "MMV",
        "AVE-Net",
        "XDC",
        "ALBEF",
        "FLAVA",
        "Dragon",
        "HiP",
        "Frozen",
        "LiMBeR",
        "FROMAGe",
        "BLIP-2",
        "ESPER",
        "CLIPCap",
        "MAGMA",
        "Flamingo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AMOR A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback": {
    "filename": "AMOR A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "PubMedQA",
        "QASPER",
        "2WikiMultiHopQA",
        "Musique",
        "NaturalQuestions",
        "BoolQ"
      ],
      "models": [
        "AMOR",
        "WebGPT",
        "CoT",
        "ToT",
        "ReAct",
        "Reflexion",
        "AgentLM",
        "MetaGPT",
        "LUMOS",
        "OneR",
        "Self-RAG",
        "ReWoo",
        "FIREACT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Non Verbis Sed Rebus Large Language Models are Weak Solvers of Italian Rebuses": {
    "filename": "Non Verbis Sed Rebus Large Language Models are Weak Solvers of Italian Rebuses.pdf",
    "analysis": {
      "benchmarks": [
        "EurekaRebus",
        "ItaCW"
      ],
      "models": [
        "LLaMA-3 70B",
        "Qwen-2 72B",
        "GPT-4o",
        "Claude-3.5 Sonnet",
        "Phi-3 Mini 3.8B"
      ]
    }
  },
  "Hide and Seek Fingerprinting Large Language Models with Evolutionary Learning": {
    "filename": "Hide and Seek Fingerprinting Large Language Models with Evolutionary Learning.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Llama-3-8B",
        "Mistral-7B-instruct-0.3",
        "Gemma-2-9B",
        "Phi-2.7B",
        "Mixtral-8x22B",
        "Llama-8B",
        "Llama-3-70B",
        "Mistral-7B-0.3-instruct",
        "Gemma-2-27B",
        "Phi-2-2.7B"
      ]
    }
  },
  "Understanding Graphical Perception in Data Visualization through Zero-shot Prompting of Vision-Language Models": {
    "filename": "Understanding Graphical Perception in Data Visualization through Zero-shot Prompting of Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "visualization literacy tests",
        "graphical perception tasks",
        "Tasks 1-6 from Cleveland and McGill",
        "Task 7 from Heer and Bostock",
        "Task 5B and 6B variations"
      ],
      "models": [
        "GPT-4o-mini"
      ]
    }
  },
  "REFINER Reasoning Feedback on Intermediate Representations": {
    "filename": "REFINER Reasoning Feedback on Intermediate Representations.pdf",
    "analysis": {
      "benchmarks": [
        "SVAMP",
        "GSM8K",
        "MAWPS",
        "Synthetic Natural Language Reasoning (sNLR)",
        "Moral Stories (MS)"
      ],
      "models": [
        "REFINER",
        "UQA-base",
        "UQA-large",
        "GPT-3.5",
        "ChatGPT",
        "Proximal Policy Optimization (PPO)",
        "Self-refine",
        "Self-reflection",
        "Self-consistency",
        "ReACT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Non-myopic Generation of Language Models for Reasoning and Planning": {
    "filename": "Non-myopic Generation of Language Models for Reasoning and Planning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "HumanEval",
        "MBPP",
        "AlfWorld",
        "PDDL"
      ],
      "models": [
        "Predictive-Decoding",
        "GPT-4",
        "GPT-3.5 Turbo",
        "Llama-3",
        "Mistral-v0.3",
        "Deepseek-Coder",
        "ReAct",
        "Act",
        "Beam Search",
        "Self-Consistency",
        "Guided-Decoding",
        "Self-Infilling"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Robust and Interpretable Medical Image Classifiers via Concept Bottleneck Models": {
    "filename": "Robust and Interpretable Medical Image Classifiers via Concept Bottleneck Models.pdf",
    "analysis": {
      "benchmarks": [
        "NIH-gender",
        "NIH-age",
        "NIH-agemix",
        "Covid-mix",
        "NIH-CXR",
        "Covid-QU",
        "Pneumonia",
        "Open-i"
      ],
      "models": [
        "ERM",
        "Fish",
        "LISA",
        "BioViL Image Features",
        "BioViL Image Features (dropouts)",
        "Post-Hoc CBM",
        "Label-free CBM",
        "Ours"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Agents as Optimizable Graphs": {
    "filename": "Language Agents as Optimizable Graphs.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "Mini CrossWords",
        "HumanEval",
        "GAIA"
      ],
      "models": [
        "GPTSwarm",
        "AutoGPT",
        "BabyAGI",
        "LangChain",
        "Llama-index",
        "TOT",
        "ReAct",
        "COT",
        "Reflexion",
        "Graph of Thought",
        "GPT-4-Turbo",
        "GPT-3.5-Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Novice Learner and Expert Tutor Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions": {
    "filename": "Novice Learner and Expert Tutor Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "NumGLUE",
        "Eedi's platform"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "Towards More Effective Table-to-Text Generation Assessing In-Context Learning and Self-Evaluation with Open-Source Models": {
    "filename": "Towards More Effective Table-to-Text Generation Assessing In-Context Learning and Self-Evaluation with Open-Source Models.pdf",
    "analysis": {
      "benchmarks": [
        "WikiBio",
        "ToTTo",
        "Recent Wikipedia pages",
        "MaRDI"
      ],
      "models": [
        "Llama 3",
        "Phi-3"
      ]
    }
  },
  "On Enhancing Root Cause Analysis with SQL Summaries for Failures in Database Workload Replays at SAP HANA": {
    "filename": "On Enhancing Root Cause Analysis with SQL Summaries for Failures in Database Workload Replays at SAP HANA.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "MIRA",
        "KNN",
        "GPT-4",
        "GPT-4-Turbo",
        "llama-7b"
      ]
    }
  },
  "Adaptive Activation Steering A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories": {
    "filename": "Adaptive Activation Steering A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA"
      ],
      "models": [
        "LLaMA",
        "LLaMA2",
        "Alpaca",
        "Vicuna",
        "LLaMA2-Chat",
        "ACT",
        "CCS",
        "RepE",
        "Mean-Centring",
        "ITI"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SmartInv Multimodal Learning for Smart Contract Invariant Inference": {
    "filename": "SmartInv Multimodal Learning for Smart Contract Invariant Inference.pdf",
    "analysis": {
      "benchmarks": [
        "Etherscan",
        "Ethereum"
      ],
      "models": [
        "SMART INV",
        "VERISOL",
        "VERISMART",
        "SMARTEST",
        "MYTHRIL",
        "MANTICORE",
        "SLITHER",
        "LLaMA-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TextGrad Automatic Differentiation via Text": {
    "filename": "TextGrad Automatic Differentiation via Text.pdf",
    "analysis": {
      "benchmarks": [
        "Google-Proof Question Answering",
        "LeetCode Hard",
        "MMLU-Machine Learning",
        "MMLU-College Physics",
        "Big Bench Hard",
        "GSM8k",
        "DOCKSTRING"
      ],
      "models": [
        "TEXTGRAD",
        "GPT-4o",
        "GPT-3.5-turbo-0125",
        "Reflexion",
        "Chain-of-Thought (CoT)",
        "DSPy"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The New Agronomists Language Models are Experts in Crop Management": {
    "filename": "The New Agronomists Language Models are Experts in Crop Management.pdf",
    "analysis": {
      "benchmarks": [
        "DSSAT",
        "Gym-DSSAT"
      ],
      "models": [
        "LM-based RL Agent",
        "Traditional Agent",
        "Multilayer Perceptrons (MLPs)",
        "Deep Q-Network (DQN)",
        "Distilled BERT",
        "ResNet18",
        "ResNet50",
        "ResNet101",
        "ResNet152",
        "Three-layer MLP",
        "Five-layer MLP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Potential and Limitations of LLMs in Capturing Structured Semantics A Case Study on SRL": {
    "filename": "Potential and Limitations of LLMs in Capturing Structured Semantics A Case Study on SRL.pdf",
    "analysis": {
      "benchmarks": [
        "CoNLL-2005",
        "CoNLL-2012"
      ],
      "models": [
        "PromptSRL",
        "Llama2-7B-Chat",
        "ChatGLM2-6B",
        "GPT-3 variants",
        "ChatGPT",
        "HeSyFu",
        "CRF2o",
        "MRC-SRL",
        "CoT"
      ]
    }
  },
  "Large sequence models for sequential decision-making a survey": {
    "filename": "Large sequence models for sequential decision-making a survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Gato",
        "Video Pre-Training (VPT)",
        "Decision Transformer (DT)",
        "Trajectory Transformer (TT)",
        "Multi-Game Decision Transformer (MGDT)",
        "Bootstrapped Transformer (BooT)",
        "Online Decision Transformer (ODT)",
        "TransDreamer",
        "Dreamer with Transformers",
        "Pre-trained Decision Transformer (PDT)",
        "Prompting Decision Transformer (Prompt-DT)",
        "TrMRL (the Transformer for Meta Reinforcement Learning)",
        "Generalized Decision Transformer (GDT)",
        "Multi-Agent Decision Transformer (MADT)",
        "Auto-Regressive Policy Gradient (PG-AR)",
        "Multi-Agent Transformer (MAT)",
        "Universal Policy Decoupling Transformer (UPDeT)",
        "Population Invariant agent with Transformer (PIT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "What Are They Doing Joint Audio-Speech Co-Reasoning": {
    "filename": "What Are They Doing Joint Audio-Speech Co-Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "What Are They Doing",
        "Open-ASQA",
        "AudioSet",
        "FMA"
      ],
      "models": [
        "Joint Audio-Speech Co-Reasoning (JASCO)",
        "WavLLM-7B",
        "LTU-AS-7B",
        "SALMONN-7B",
        "Qwen2-Audio-Instruct-7B",
        "Whisper",
        "BEATs",
        "LLaMa-2",
        "Vicuna",
        "Llama-3.1-70B-Instruct"
      ]
    }
  },
  "SWAG Storytelling With Action Guidance": {
    "filename": "SWAG Storytelling With Action Guidance.pdf",
    "analysis": {
      "benchmarks": [
        "Writing Prompts"
      ],
      "models": [
        "SWAG",
        "GPT-4",
        "GPT-3.5-Turbo",
        "Llama-2-7B",
        "Mistral-7B",
        "Mixtral-8\u00d77B",
        "LongLoRA",
        "Flash Attention 2.0"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation": {
    "filename": "Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation.pdf",
    "analysis": {
      "benchmarks": [
        "Wizard of Wikipedia",
        "Holl-E"
      ],
      "models": [
        "PLATO-KAG",
        "TMN",
        "SKT",
        "KnowledGPT",
        "T5",
        "DialoGPT",
        "T5-small",
        "T5-base",
        "T5-large",
        "T5-XL",
        "T5-XXL",
        "DialoGPT-small",
        "DialoGPT-medium",
        "DialoGPT-large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TIFA Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering": {
    "filename": "TIFA Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "TIFA v1.0",
        "MSCOCO",
        "DrawBench",
        "PartiPrompts",
        "PaintSkill"
      ],
      "models": [
        "Stable Diffusion v1.5",
        "Stable Diffusion v2.1",
        "CLIP",
        "SPICE",
        "mPLUG",
        "BLIP-2",
        "UnifiedQA",
        "AttnGAN",
        "X-LXMERT",
        "VQ-Diffusion",
        "minDALL-E",
        "Stable Diffusion v1.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Agent Design Pattern Catalogue A Collection of Architectural Patterns for Foundation Model based Agents": {
    "filename": "Agent Design Pattern Catalogue A Collection of Architectural Patterns for Foundation Model based Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "AutoGPT",
        "BabyAGI",
        "ChatGPT",
        "Bard",
        "Gemini",
        "Claude",
        "Llama",
        "Mistral",
        "LangChain",
        "HuggingGPT",
        "GestureGPT",
        "ProAgent",
        "ThinkGPT",
        "Reflexion",
        "XAgent",
        "Inner Monologue",
        "Hamilton",
        "ChatEval"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Consensus Game Language Model Generation via Equilibrium Search": {
    "filename": "The Consensus Game Language Model Generation via Equilibrium Search.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "ARC",
        "RACE",
        "HHH",
        "TruthfulQA",
        "GSM8K"
      ],
      "models": [
        "EQUILIBRIUM-RANKING",
        "LLaMA-7B",
        "LLaMA-13B",
        "LLaMA-65B",
        "PaLM-540B",
        "GPT3-175B",
        "Generative Ranking",
        "Mutual Information Ranking",
        "Self-Contrastive Ranking",
        "Discriminative Ranking",
        "Equilibrium Ranking Generator",
        "Equilibrium Ranking Discriminator"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Scaling Data-Constrained Language Models": {
    "filename": "Scaling Data-Constrained Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "C4",
        "OSCAR",
        "WebNLG",
        "bAbI"
      ],
      "models": [
        "Chinchilla",
        "Gopher",
        "MT-NLG",
        "Galactica",
        "PaLM",
        "GPT-2",
        "SantaCoder",
        "StarCoder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Large Language Models on the GMAT Implications for the Future of Business Education": {
    "filename": "Evaluating Large Language Models on the GMAT Implications for the Future of Business Education.pdf",
    "analysis": {
      "benchmarks": [
        "GMAT"
      ],
      "models": [
        "GPT-3.5 Turbo",
        "GPT-4",
        "GPT-4 Turbo",
        "Claude 2",
        "Claude 2.1",
        "PaLM 2",
        "Gemini 1.0 Pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CPSDBench A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain": {
    "filename": "CPSDBench A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain.pdf",
    "analysis": {
      "benchmarks": [
        "CPSDBench"
      ],
      "models": [
        "GPT-4",
        "ChatGLM-4",
        "Atom",
        "XVerse",
        "ChatGPT",
        "Minimax-abab",
        "Baichuan2",
        "QWen",
        "ERNIE Bot"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "In-Context Learning for Knowledge Base Question Answering for Unmanned Systems based on Large Language Models": {
    "filename": "In-Context Learning for Knowledge Base Question Answering for Unmanned Systems based on Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CCKS 2023 Question Answering with Knowledge Graph Inference for Unmanned Systems"
      ],
      "models": [
        "ChatGPT-based CQL generation framework",
        "ChatGPT",
        "mT5-large"
      ]
    }
  },
  "ScatterShot Interactive In-context Example Curation for Text Transformation": {
    "filename": "ScatterShot Interactive In-context Example Curation for Text Transformation.pdf",
    "analysis": {
      "benchmarks": [
        "TimeBank",
        "TweeTime"
      ],
      "models": [
        "ScatterShot",
        "GPT-3",
        "rule-based system"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SSSD Simply-Scalable Speculative Decoding": {
    "filename": "SSSD Simply-Scalable Speculative Decoding.pdf",
    "analysis": {
      "benchmarks": [
        "MT-Bench",
        "GSM8k",
        "Dolly-15k",
        "Natural Questions",
        "PG-19"
      ],
      "models": [
        "SSSD",
        "Llama2-7b",
        "Llama3-8B",
        "Medusa",
        "ReDrafter",
        "MagicDec",
        "Prompt Lookup Decoding (PTL)",
        "REST",
        "PIA",
        "SpecInfer",
        "ProPD",
        "TriForce",
        "Ouroboros"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Why Larger Language Models Do In-context Learning Differently": {
    "filename": "Why Larger Language Models Do In-context Learning Differently.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "Subj",
        "GSM-IC"
      ],
      "models": [
        "ChatGPT",
        "GPT4",
        "Llama-2-3b",
        "Llama-2-7b",
        "Llama-2-13b",
        "Llama-2-70b",
        "Llama-2-7b-chat",
        "Llama-2-13b-chat",
        "Llama-2-70b-chat",
        "one-layer single-head linear self-attention transformer",
        "two-layer multiple-head transformers"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models A Case Study on ChatGPT": {
    "filename": "Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models A Case Study on ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "WMT22"
      ],
      "models": [
        "ChatGPT",
        "GPT-3.5-Turbo",
        "Llama2-70b-Chat",
        "Mixtral-8x7b-Instruct",
        "GEMBA",
        "EAPrompt",
        "BLEURT20",
        "COMET22",
        "UniTE",
        "COMET-QE",
        "UniTE-src",
        "MaTESe-QE",
        "MetricX-XXL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SmallToLarge S2L Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models": {
    "filename": "SmallToLarge S2L Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models.pdf",
    "analysis": {
      "benchmarks": [
        "MathInstruct",
        "MATH",
        "MIMIC-III",
        "GSM8K",
        "NumGLUE",
        "SVAMP",
        "Mathematics",
        "SimulEq"
      ],
      "models": [
        "SMALL TOLARGE (S2L)",
        "Phi-2",
        "Pythia-70M",
        "Pythia-410M",
        "Pythia-2.8B",
        "Pythia-6.9B",
        "Llama-2",
        "GPT-2",
        "Pythia-160M",
        "PHI-3-MINI",
        "LLAMA-2-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OpenICL An Open-Source Framework for In-context Learning": {
    "filename": "OpenICL An Open-Source Framework for In-context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "SST-2",
        "WMT16",
        "GSM8K",
        "PiQA",
        "Gigaword"
      ],
      "models": [
        "OpenICL",
        "GPT2-XL",
        "XGLM",
        "text-davinci-003",
        "GPT-Neo"
      ]
    }
  },
  "Chain-of-Scrutiny Detecting Backdoor Attacks for Large Language Models": {
    "filename": "Chain-of-Scrutiny Detecting Backdoor Attacks for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "CSQA",
        "ARC",
        "AQuA",
        "SST-2",
        "AG-NEWS"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Gemini",
        "Llama3",
        "Chain-of-Scrutiny (CoS)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AGENT-DRIVEN LARGE LANGUAGE MODELS FOR MANDARIN LYRIC GENERATION": {
    "filename": "AGENT-DRIVEN LARGE LANGUAGE MODELS FOR MANDARIN LYRIC GENERATION.pdf",
    "analysis": {
      "benchmarks": [
        "Mpop600"
      ],
      "models": [
        "multi-agent system",
        "GPT-based language model",
        "Gemini-1.0-pro",
        "gpt-3.5-turbo-0125",
        "gpt-4-0125-preview",
        "Suggester",
        "Creator",
        "Checker",
        "Judger"
      ]
    }
  },
  "ReviewerGPT An Exploratory Study on Using Large Language Models for Paper Reviewing": {
    "filename": "ReviewerGPT An Exploratory Study on Using Large Language Models for Paper Reviewing.pdf",
    "analysis": {
      "benchmarks": [
        "Is this a human? dataset",
        "13 short papers with errors",
        "15 NeurIPS 2022 papers",
        "10 pairs of abstracts"
      ],
      "models": [
        "GPT-4",
        "Bard",
        "Vicuna",
        "Koala",
        "Alpaca",
        "LLaMa",
        "Dolly",
        "OpenAssistant",
        "StableLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-Assisted Content Analysis Using Large Language Models to Support Deductive Coding": {
    "filename": "LLM-Assisted Content Analysis Using Large Language Models to Support Deductive Coding.pdf",
    "analysis": {
      "benchmarks": [
        "Trump Tweets",
        "Contrarian Claims",
        "BBC News",
        "Ukraine Water Problems"
      ],
      "models": [
        "GPT-3.5",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Aligning LLMs to Be Robust Against Prompt Injection": {
    "filename": "Aligning LLMs to Be Robust Against Prompt Injection.pdf",
    "analysis": {
      "benchmarks": [
        "AlpacaEval2",
        "AlpacaFarm"
      ],
      "models": [
        "SecAlign",
        "StruQ",
        "Sandwich",
        "Mistral-7B",
        "Llama-7B",
        "Llama3-8B",
        "BIPIA",
        "Vicuna-7B",
        "AdvPrompter",
        "GCG",
        "Instructional",
        "Reminder",
        "Isolation",
        "In-Context"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CALF Benchmarking Evaluation of LFQA Using Chinese Examinations": {
    "filename": "CALF Benchmarking Evaluation of LFQA Using Chinese Examinations.pdf",
    "analysis": {
      "benchmarks": [
        "Chinese ex Amination for LFQA Evaluation (CALF)",
        "College Entrance Examination Simulation Questions (CEESQ)",
        "Postgraduate Entrance Examination Questions (PEEQ)"
      ],
      "models": [
        "Llama-3-8B",
        "GPT-3.5-turbo-1106-preview",
        "ROUGE",
        "BERTScore",
        "BARTScore",
        "UniEval",
        "GPT2",
        "ChatGPT",
        "ChatGPT-CoT",
        "G-Eval (ChatGPT)",
        "GPT-4o",
        "GPT-4o-CoT",
        "G-Eval (GPT-4o)",
        "Critique-6B",
        "AutoJ-13B",
        "TIGERScore-13B",
        "ChatGPT-ICL",
        "GPT-4o-ICL",
        "ChatEval",
        "ReFeR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Far Can Camels Go Exploring the State of Instruction Tuning on Open Resources": {
    "filename": "How Far Can Camels Go Exploring the State of Instruction Tuning on Open Resources.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "GSM",
        "BBH",
        "TyDiQA",
        "Codex-Eval",
        "ToxiGen",
        "TruthfulQA",
        "AlpacaEval"
      ],
      "models": [
        "T\u00dcLU",
        "LLAMA",
        "LLAMA-2",
        "OPT",
        "Pythia",
        "ChatGPT",
        "GPT-4",
        "SuperNI",
        "CoT",
        "Flan V2",
        "Dolly",
        "Open Assistant 1",
        "Self-instruct",
        "Unnatural Instructions",
        "Alpaca",
        "Code-Alpaca",
        "GPT4-Alpaca",
        "Baize",
        "ShareGPT",
        "Human data mixture",
        "Human+GPT data mixture"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RE-GAINS  EnCHANT Intelligent Tool Manipulation Systems For Enhanced Query Responses": {
    "filename": "RE-GAINS  EnCHANT Intelligent Tool Manipulation Systems For Enhanced Query Responses.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SCAN",
        "ToolBench",
        "ToolQA",
        "APIBench",
        "ToolAlpaca",
        "APIBank"
      ],
      "models": [
        "RE-GAINS",
        "EnChAnT",
        "OpenChat 3.5",
        "GPT 3.5",
        "GPT-3.5 Turbo",
        "GPT-4",
        "ToolBench IR bert based uncased",
        "MiniLM-L6-v2",
        "all-mpnet-base-v2",
        "ReAct",
        "Toolformer",
        "ART",
        "ChatCoT",
        "Chameleon",
        "GEAR",
        "TALM",
        "HuggingGPT",
        "PAL",
        "ToolAlpaca",
        "Gorilla",
        "ToolBench/ToolLLM",
        "ControlLLM",
        "RAP",
        "Zephyr-7B",
        "Llama-13B",
        "Llemma"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Pushing the Limits of ChatGPT on NLP Tasks": {
    "filename": "Pushing the Limits of ChatGPT on NLP Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "SQuADv2",
        "TQA",
        "MRQA-OOD",
        "CSQA",
        "StrategyQA",
        "RTE",
        "CommitmentBank",
        "SST-2",
        "IMDb",
        "Yelp",
        "CoNLL2003",
        "OntoNotes5.0",
        "ACE2004",
        "ACE2005",
        "WSJ Treebank",
        "Tweets",
        "PTB"
      ],
      "models": [
        "ChatGPT",
        "RoBERTa-Large",
        "ChatGPT (few-shot)",
        "ChatGPT +Random demo",
        "ChatGPT +SimCSE kNN",
        "ChatGPT +FTkNN",
        "ChatGPT +FTkNN+Multi",
        "ChatGPT +FTkNN+Multi+Reason",
        "ChatGPT +FTkNN+Multi+Reason+SV",
        "ChatGPT +FTkNN+Multi+Reason+SV+Paraphrase"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LAMBADA Backward Chaining for Automated Reasoning in Natural Language": {
    "filename": "LAMBADA Backward Chaining for Automated Reasoning in Natural Language.pdf",
    "analysis": {
      "benchmarks": [
        "ProofWriter",
        "PrOntoQA",
        "ParaRules"
      ],
      "models": [
        "LAMBADA",
        "Chain-of-Thought (CoT)",
        "Selection-Inference (SI)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting": {
    "filename": "Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "GSM",
        "ECQA",
        "E-SNLI",
        "STRATEGY QA",
        "SVAMP",
        "MAWPS"
      ],
      "models": [
        "code-davinci-002",
        "text-davinci-003",
        "ZERO-COT",
        "BESTLEN",
        "BESTPPL",
        "OPTIMIZED"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LeanQuant Accurate and Scalable Large Language Model Quantization with Loss-error-aware Grid": {
    "filename": "LeanQuant Accurate and Scalable Large Language Model Quantization with Loss-error-aware Grid.pdf",
    "analysis": {
      "benchmarks": [
        "ARC",
        "LAMBADA",
        "MMLU",
        "HellaSwag",
        "PIQA",
        "WinoGrande",
        "WikiText2",
        "C4",
        "MT-Bench"
      ],
      "models": [
        "LeanQuant",
        "Llama-3.1 405B",
        "GPTQ",
        "AQLM",
        "QUIP#",
        "SqueezeLLM",
        "OmniQuant",
        "Llama-3-8B",
        "Llama-2-7B",
        "Mistral-7B",
        "Mistral-Large-Instruct-2407",
        "Llama-3.1-405B-Instruct",
        "LeanQuant aff",
        "LeanQuant nu",
        "LeanQuant-Exact"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning to reason over scene graphs a case study of finetuning GPT-2 into a robot language model for grounded task planning": {
    "filename": "Learning to reason over scene graphs a case study of finetuning GPT-2 into a robot language model for grounded task planning.pdf",
    "analysis": {
      "benchmarks": [
        "ALFRED"
      ],
      "models": [
        "GPT-2",
        "RobLM",
        "GPT-3",
        "Fast Downward (FD)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond Finite Data Towards Data-free Out-of-distribution Generalization via Extrapolation": {
    "filename": "Beyond Finite Data Towards Data-free Out-of-distribution Generalization via Extrapolation.pdf",
    "analysis": {
      "benchmarks": [
        "VLCS",
        "PACS",
        "OfficeHome",
        "DomainNet"
      ],
      "models": [
        "ERM",
        "ERM + EMA",
        "IRM",
        "GroupDRO",
        "MLDG",
        "CORAL",
        "Mixup",
        "MMD",
        "RSC",
        "VREx",
        "SWAD",
        "MIRO",
        "MixStyle",
        "CLIP Zero-shot",
        "CLIP Finetune",
        "ASA",
        "Pro-RandConv",
        "CPerb",
        "AutoAug",
        "RandAug",
        "Data-free (ours)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SpeechVerse A Large-scale Generalizable Audio Language Model": {
    "filename": "SpeechVerse A Large-scale Generalizable Audio Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "Librispeech",
        "Mozilla Common Voice 5.1",
        "VoxPopuli",
        "SLURP",
        "EuroParl",
        "MSP-Podcast 1.11",
        "CoVost2",
        "Fisher",
        "In-house VAD"
      ],
      "models": [
        "SpeechVerse",
        "Whisper",
        "SpeechT5",
        "VIOLA",
        "SpeechGPT",
        "SLM",
        "Qwen-Audio",
        "Task-FT",
        "Multitask-WLM",
        "Multitask-BRQ",
        "GT\u2192LLM",
        "WavLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automating the Enterprise with Foundation Models": {
    "filename": "Automating the Enterprise with Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "WebArena",
        "WebUI",
        "Mind2Web"
      ],
      "models": [
        "ECLAIR",
        "GPT-4",
        "CogAgent",
        "YOLONAS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Controllable Speaking Styles Using A Large Language Model": {
    "filename": "Controllable Speaking Styles Using A Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "LJSpeech"
      ],
      "models": [
        "FastSpeech-2",
        "Daft-Exprt",
        "InstructGPT",
        "Oracle PT",
        "Oracle GST",
        "PromptTTS",
        "InstructTTS",
        "GPT-3"
      ]
    }
  },
  "Anchored Alignment for Self-Explanations Enhancement": {
    "filename": "Anchored Alignment for Self-Explanations Enhancement.pdf",
    "analysis": {
      "benchmarks": [
        "AQuA-Rat",
        "ARC-Challenge",
        "LogiQA",
        "OpenbookQA"
      ],
      "models": [
        "MBase",
        "MSFT",
        "MRank",
        "MAnchor"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models": {
    "filename": "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K"
      ],
      "models": [
        "LLaMA-7B",
        "LLaMA2-7B",
        "LLaMA-13B",
        "LLaMA2-13B",
        "LLaMA-33B",
        "GPT-3",
        "GPT-4",
        "PaLM2",
        "Chinchilla-70B",
        "GPT-Neo-2.7B",
        "GPT-J-6B",
        "ChatGLM2-6B",
        "ChatGLM2-12B",
        "InternLM-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Repository-Level Prompt Generation for Large Language Models of Code": {
    "filename": "Repository-Level Prompt Generation for Large Language Models of Code.pdf",
    "analysis": {
      "benchmarks": [
        "Google Code archives"
      ],
      "models": [
        "Codex",
        "Repo-Level Prompt Generator (RLPG)",
        "Prompt Proposal Classifier (PPC)",
        "RLPG-H",
        "RLPG-R",
        "CodeBERT",
        "GraphCodeBERT",
        "RLPG-BM25",
        "File-level BM25",
        "Random",
        "Random NN",
        "Identifier Usage",
        "code-cushman-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Massive Activations in Large Language Models": {
    "filename": "Massive Activations in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "WikiText",
        "C4",
        "PG-19",
        "BoolQ",
        "PIQA",
        "WinoGrande",
        "Arc-Easy",
        "Arc-Challenge",
        "ImageNet",
        "MMLU"
      ],
      "models": [
        "LLaMA2-7B",
        "LLaMA2-13B",
        "Mixtral-8x7B",
        "Phi-2",
        "LLaMA2-70B",
        "Mistral-7B",
        "MPT-7B",
        "Falcon-7B",
        "GPT-2",
        "GPT-2 with Sink Token",
        "GPT-2 with Attention Bias",
        "CLIP ViT-L",
        "DINOv2 ViT-L",
        "MAE ViT-L",
        "DINOv2-reg ViT-G"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PaCE Parsimonious Concept Engineering for Large Language Models": {
    "filename": "PaCE Parsimonious Concept Engineering for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SafeEdit",
        "FactScore",
        "HolisticBias",
        "MMLU"
      ],
      "models": [
        "PaCE",
        "LLaMA2-7B-Chat",
        "LLaMA2-13B-Chat",
        "Prompting",
        "VecAdd",
        "OrthoProj"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Its not like Jarvis but its pretty close - Examining ChatGPTs Usage among Undergraduate Students in Computer Science": {
    "filename": "Its not like Jarvis but its pretty close - Examining ChatGPTs Usage among Undergraduate Students in Computer Science.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "Google Bard",
        "OpenAI Codex",
        "AlphaCode",
        "Amazon CodeWhisperer",
        "GPT-3",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PROMPTFUZZ Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs": {
    "filename": "PROMPTFUZZ Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "TensorTrust",
        "Language Model Inversion (LMI)",
        "Lakera"
      ],
      "models": [
        "PROMPT FUZZ",
        "GPTFuzz-injection",
        "GCG-injection",
        "Initial Seed",
        "Human Expert"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Identifying Inaccurate Descriptions in LLM-generated Code Comments via Test Execution": {
    "filename": "Identifying Inaccurate Descriptions in LLM-generated Code Comments via Test Execution.pdf",
    "analysis": {
      "benchmarks": [
        "Defects4J"
      ],
      "models": [
        "StarCoder",
        "GPT-3",
        "GPT-4",
        "DocChecker",
        "Deep-JIT",
        "GPT-3-NoCoT",
        "GPT-3-CoT",
        "BLEU",
        "SentenceBERT",
        "CodeT5",
        "CodeBERT",
        "CID"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ComfyBench Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems": {
    "filename": "ComfyBench Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems.pdf",
    "analysis": {
      "benchmarks": [
        "ComfyBench"
      ],
      "models": [
        "ComfyAgent",
        "o1-preview",
        "GPT-4o",
        "Claude-3.5-Sonnet",
        "Llama-3.1-70B",
        "o1-mini",
        "Zero-shot Learning",
        "Few-shot Learning",
        "Chain-of-Thought (CoT)",
        "CoT with Self-consistency (CoT-SC)",
        "Retrieval-Augmented Generation (RAG)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating the Reliability of Self-Explanations in Large Language Models": {
    "filename": "Evaluating the Reliability of Self-Explanations in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Food Recall Incidents",
        "Movie Review Polarity"
      ],
      "models": [
        "Gemma 1.1 Instruct",
        "Llama 3 Instruct",
        "Gemma-2B",
        "Gemma-7B",
        "Llama 3-8B"
      ]
    }
  },
  "CAAP Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only": {
    "filename": "CAAP Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only.pdf",
    "analysis": {
      "benchmarks": [
        "MiniWoB++",
        "WebShop"
      ],
      "models": [
        "CAAP",
        "CC-Net",
        "WebGUM",
        "Pix2Act",
        "SeeClick",
        "ReAct",
        "RCI",
        "Inner Monologue",
        "AdaPlanner"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding Transformer Reasoning Capabilities via Graph Algorithms": {
    "filename": "Understanding Transformer Reasoning Capabilities via Graph Algorithms.pdf",
    "analysis": {
      "benchmarks": [
        "GraphQA"
      ],
      "models": [
        "transformer",
        "graph neural networks (GNNs)",
        "GCN",
        "MPNN",
        "GIN",
        "T5-11B",
        "60M transformer",
        "11B transformer (FT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Configuration Validation with Large Language Models": {
    "filename": "Configuration Validation with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Ctest dataset",
        "Alluxio",
        "Django",
        "Etcd",
        "HBase",
        "Hadoop Common",
        "HDFS",
        "PostgreSQL",
        "Redis",
        "YARN",
        "ZooKeeper"
      ],
      "models": [
        "Ciri",
        "GPT-4-Turbo",
        "GPT-3.5-Turbo",
        "Claude-3-Opus",
        "Claude-3-Sonnet",
        "CodeLlama-7B",
        "CodeLlama-13B",
        "CodeLlama-34B",
        "DeepSeek-6.7B",
        "ConfMiner",
        "Ctest"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Inference Scaling Laws An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models": {
    "filename": "Inference Scaling Laws An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "MATH500"
      ],
      "models": [
        "Llemma-7B",
        "Llemma-34B",
        "Pythia",
        "Mistral-7B",
        "REBASE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-FuncMapper Function Identification for Interpreting Complex Clauses in Building Codes via LLM": {
    "filename": "LLM-FuncMapper Function Identification for Interpreting Complex Clauses in Building Codes via LLM.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLM-FuncMapper",
        "ChatGPT",
        "GPT4",
        "Claude"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Knowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever": {
    "filename": "Knowledge Tagging System on Math Questions via LLMs with Flexible Demonstration Retriever.pdf",
    "analysis": {
      "benchmarks": [
        "MathKnowCT"
      ],
      "models": [
        "KnowTS",
        "FlexSDR",
        "GPT",
        "Llama-3",
        "Mixtral",
        "Qwen",
        "SBERT",
        "BERT",
        "RoBERTa",
        "T5",
        "PromptPG",
        "RetICL",
        "FlexRetICR"
      ]
    }
  },
  "Graph-enhanced Large Language Models in Asynchronous Plan Reasoning": {
    "filename": "Graph-enhanced Large Language Models in Asynchronous Plan Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "AsyncHow"
      ],
      "models": [
        "GPT-4",
        "LLaMA-2",
        "GPT-3.5-turbo",
        "Cohere Command1",
        "Mistral-7B-Instruct",
        "Plan Like a Graph (PLaG)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving In-context Learning via Bidirectional Alignment": {
    "filename": "Improving In-context Learning via Bidirectional Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "LogiQA",
        "MMLU",
        "BBH",
        "HumanEval",
        "CrossFit"
      ],
      "models": [
        "BiAlign",
        "Vanilla",
        "Fine-tuning (FT)",
        "Continual Pretraining (C-Pretrain)",
        "Output Alignment (Output-Align)",
        "Llama 2-7B",
        "Llama 2-13B",
        "Llama 2-70B",
        "Phi-1.5 (1.3B)",
        "Phi-2 (2.7B)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LaMPilot An Open Benchmark Dataset for Autonomous Driving with Language Model Programs": {
    "filename": "LaMPilot An Open Benchmark Dataset for Autonomous Driving with Language Model Programs.pdf",
    "analysis": {
      "benchmarks": [
        "LaMPilot-Bench"
      ],
      "models": [
        "LaMPilot",
        "Llama 2",
        "PaLM 2",
        "ChatGPT",
        "GPT-4",
        "GPT-4-Turbo",
        "Intelligent Driver Model (IDM)",
        "Minimizing Overall Braking Induced by Lane Changes (MOBIL)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VoxPoser Composable 3D Value Maps for Robotic Manipulation with Language Models": {
    "filename": "VoxPoser Composable 3D Value Maps for Robotic Manipulation with Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "VoxPoser",
        "LLM + Prim.",
        "U-Net Language Models",
        "MP (Ours)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Automated Data Science Introducing CAAFE for Context-Aware Automated Feature Engineering": {
    "filename": "Large Language Models for Automated Data Science Introducing CAAFE for Context-Aware Automated Feature Engineering.pdf",
    "analysis": {
      "benchmarks": [
        "airlines",
        "balance-scale",
        "breast-w",
        "cmc",
        "credit-g",
        "diabetes",
        "eucalyptus",
        "jungle_chess",
        "pc1",
        "tic-tac-toe",
        "health-insurance",
        "pharyngitis",
        "kidney-stone",
        "spaceship-titanic"
      ],
      "models": [
        "CAAFE",
        "Logistic Regression",
        "Random Forests",
        "TabPFN",
        "Deep Feature Synthesis (DFS)",
        "AutoFeat",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AceCoder Utilizing Existing Code to Enhance Code Generation": {
    "filename": "AceCoder Utilizing Existing Code to Enhance Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "MBPP",
        "MBJP",
        "MBJSP"
      ],
      "models": [
        "AceCoder",
        "Codex",
        "CodeGeeX",
        "CodeGen",
        "InCoder",
        "REDCODER",
        "Jigsaw"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Program Testing Ability of Large Language Models for Code": {
    "filename": "The Program Testing Ability of Large Language Models for Code.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "HumanEval+"
      ],
      "models": [
        "CodeX",
        "CodeT5+",
        "GPT-3.5-turbo",
        "CodeT",
        "InCoder",
        "CodeGen2",
        "SantaCoder",
        "StarCoder",
        "WizardCoder",
        "CodeGeeX2",
        "CodeGen-Multi",
        "CodeGen-Mono"
      ]
    }
  },
  "LanFL Differentially Private Federated Learning with Large Language Models using Synthetic Samples": {
    "filename": "LanFL Differentially Private Federated Learning with Large Language Models using Synthetic Samples.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA",
        "UCI Credit Card Default"
      ],
      "models": [
        "LanFL",
        "Gemini-1.5-Flash",
        "Llama3.1-70B",
        "Mixtral-8x7B"
      ]
    }
  },
  "The System Model and the User Model Exploring AI Dashboard Design": {
    "filename": "The System Model and the User Model Exploring AI Dashboard Design.pdf",
    "analysis": {
      "benchmarks": [],
      "models": []
    }
  },
  "Artificial Intelligence and Aesthetic Judgment": {
    "filename": "Artificial Intelligence and Aesthetic Judgment.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Nugget Neural Agglomerative Embeddings of Text": {
    "filename": "Nugget Neural Agglomerative Embeddings of Text.pdf",
    "analysis": {
      "benchmarks": [
        "WMT19",
        "PARABANK",
        "WikiText-103"
      ],
      "models": [
        "NUGGET",
        "DAN",
        "DPR",
        "TSDAE",
        "COLBERT",
        "BERT",
        "BART",
        "CoVe",
        "ELMo",
        "SBERT",
        "SimCSE",
        "ColBART",
        "Compressive Transformers"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "WARM On the Benefits of Weight Averaged Reward Models": {
    "filename": "WARM On the Benefits of Weight Averaged Reward Models.pdf",
    "analysis": {
      "benchmarks": [
        "TL;DR summarization benchmark"
      ],
      "models": [
        "WARM",
        "ENS",
        "Ind 1",
        "Ind 2",
        "PaLM-XXS",
        "PaLM-XS",
        "PaLM-L",
        "T5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game": {
    "filename": "Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game.pdf",
    "analysis": {
      "benchmarks": [
        "Werewolf game"
      ],
      "models": [
        "strategic language agents",
        "pure LLM-based agent",
        "ReAct",
        "ReCon",
        "Concurrent",
        "Atomic",
        "Cicero"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MetaRuleGPT Recursive Numerical Reasoning of Language Models Trained with Simple Rules": {
    "filename": "MetaRuleGPT Recursive Numerical Reasoning of Language Models Trained with Simple Rules.pdf",
    "analysis": {
      "benchmarks": [
        "gsm8k",
        "Randomized Procedure",
        "Perfect Decadic Addition",
        "Reverse Magnitude Subtraction",
        "Interleaved Subtraction",
        "Vector Cross Product"
      ],
      "models": [
        "MetaRuleGPT",
        "ChatGPT-3.5",
        "ChatGPT-4.0",
        "QWen",
        "Google's Palm",
        "Llama2",
        "Mathematical Mastery Model Goat"
      ]
    }
  },
  "AgentMonitor A Plug-and-Play Framework for Predictive and Secure Multi-Agent Systems": {
    "filename": "AgentMonitor A Plug-and-Play Framework for Predictive and Secure Multi-Agent Systems.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MMLU",
        "GSM8K",
        "Beavertails",
        "MaliciousInstruct",
        "AdvBench"
      ],
      "models": [
        "AgentMonitor",
        "XGBoost",
        "Llama3-8B",
        "Llama3-70B",
        "ChatGPT",
        "AutoGPT",
        "XAgent",
        "OpenInterpreter",
        "Generative Agents",
        "AutoGen",
        "CAMEL",
        "AgentVerse",
        "ChatEval",
        "ChatDev",
        "MetaGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on Mixture of Experts": {
    "filename": "A Survey on Mixture of Experts.pdf",
    "analysis": {
      "benchmarks": [
        "LLaMA",
        "T5-GLUE",
        "ResNet-DomainNet",
        "Wikitext"
      ],
      "models": [
        "Mixtral-8x7B",
        "Grok-1",
        "DBRX",
        "Arctic",
        "DeepSeek-V2",
        "Skywork-MoE",
        "GShard",
        "Switch Transformer",
        "ST-MoE",
        "MoA",
        "JetMoE",
        "ModuleFormer",
        "OpenMoE",
        "DeepSpeed-MoE",
        "V-MoE",
        "NLLB",
        "Mixtral-8x22B",
        "WizardLM-2-8x22B",
        "Lory",
        "SMEAR",
        "MoV",
        "Omni-SMoLA",
        "MEO",
        "PEER",
        "Qwen1.5-MoE",
        "DeepSeekMoE",
        "LLAMA-MoE",
        "Brainformers",
        "MoE-LLaVA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "What Makes Multimodal In-Context Learning Work": {
    "filename": "What Makes Multimodal In-Context Learning Work.pdf",
    "analysis": {
      "benchmarks": [
        "COCO",
        "Flickr30k",
        "CIFAR-100",
        "ImageNet",
        "Hateful Memes",
        "Rendered SST2",
        "VizWiz",
        "VQAv2",
        "OK-VQA",
        "TextVQA",
        "ScienceQA",
        "MMMU"
      ],
      "models": [
        "IDEFICS",
        "OpenFlamingo",
        "RICES",
        "RICES KNN",
        "Oracle RICES"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Conceptual Engineering Using Large Language Models": {
    "filename": "Conceptual Engineering Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Wikidata"
      ],
      "models": [
        "zero-shot chain-of-thought classifier",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLaMP Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation": {
    "filename": "LLaMP Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation.pdf",
    "analysis": {
      "benchmarks": [
        "Materials Project",
        "MP",
        "StructChem",
        "Darwin",
        "GPT-4+Serp",
        "GPT-4",
        "Gemini-Pro",
        "Llama 3"
      ],
      "models": [
        "LLaMP",
        "StructChem",
        "Darwin",
        "GPT-4+Serp",
        "GPT-4",
        "Gemini-Pro",
        "Llama 3",
        "Claude-3.5-Sonnet",
        "Gemini-1.5-Flash",
        "Llama3-8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DivCon Divide and Conquer for Progressive Text-to-Image Generation": {
    "filename": "DivCon Divide and Conquer for Progressive Text-to-Image Generation.pdf",
    "analysis": {
      "benchmarks": [
        "HRS",
        "NSR-1K",
        "LLM-Grounded"
      ],
      "models": [
        "DivCon",
        "Stable Diffusion 2.1",
        "Attend-and-Excite",
        "Divide-and-Bind",
        "GLIGEN",
        "Layout Guidance",
        "Attention-Refocusing",
        "Mixture-of-Diffusion",
        "LLM-Grounded Diffusion",
        "Multi-Diffusion"
      ]
    }
  },
  "Large Language Models as Evolutionary Optimizers": {
    "filename": "Large Language Models as Evolutionary Optimizers.pdf",
    "analysis": {
      "benchmarks": [
        "rue-10",
        "rue-15",
        "rue-20",
        "rue-25",
        "clu-10",
        "clu-15",
        "clu-20",
        "clu-25"
      ],
      "models": [
        "LMEA",
        "OPRO",
        "Nearest Neighbor (NN)",
        "Farthest Insertion (FI)",
        "Nearest Insertion (NI)",
        "Random Insertion (RI)"
      ]
    }
  },
  "Monolingual or Multilingual Instruction Tuning Which Makes a Better Alpaca": {
    "filename": "Monolingual or Multilingual Instruction Tuning Which Makes a Better Alpaca.pdf",
    "analysis": {
      "benchmarks": [
        "Alpaca dataset",
        "OpenAssistant"
      ],
      "models": [
        "Baichuan-2",
        "BLOOM",
        "LLaMA",
        "OpenLLaMA",
        "Pythia",
        "English-tuned model",
        "multilingual model",
        "monolingual model",
        "downsampled multilingual model"
      ]
    }
  },
  "Sorting Out the Bad Seeds Automatic Classification of Cryptocurrency Abuse Reports": {
    "filename": "Sorting Out the Bad Seeds Automatic Classification of Cryptocurrency Abuse Reports.pdf",
    "analysis": {
      "benchmarks": [
        "BitcoinAbuse",
        "BBB ScamTracker"
      ],
      "models": [
        "LLM-based classifier",
        "supervised ML classifier",
        "gpt-4",
        "gpt-4o",
        "gpt-3.5",
        "llama3",
        "distillbert-17-unb",
        "distillbert-17-bal",
        "distillbert-14-unb",
        "distillbert-14-bal"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MolX Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension": {
    "filename": "MolX Enhancing Large Language Models for Molecular Learning with A Multi-Modal Extension.pdf",
    "analysis": {
      "benchmarks": [
        "PubChem",
        "MoleculeNet",
        "USPTO-50k",
        "ChEMBL-02"
      ],
      "models": [
        "MolX",
        "Llama-2-7B",
        "Llama-2-7B + MolX",
        "Llama-2-7B + MoMu",
        "Llama-2-7B + MoLM-2D",
        "Llama-2-7B + MoLM-3D",
        "LlaSMol-7B",
        "ChemDFM-13B",
        "MolT5-Large",
        "MolT5-Large + MoMu",
        "ChemGraphCL",
        "Chemformer",
        "ReactionT5-Large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Applying Powerful Large AI Models in Classroom Teaching Opportunities Challenges and Prospects": {
    "filename": "Towards Applying Powerful Large AI Models in Classroom Teaching Opportunities Challenges and Prospects.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "PaLM",
        "Galactica",
        "LaMDA",
        "LLaMA",
        "Vision Transformer (ViT)",
        "SAM",
        "CLIP",
        "Chain-of-Thought (CoT)",
        "Self-consistency",
        "Federated-LLM",
        "BloombergGPT",
        "Wolfram API",
        "External LLM (Ext-LLM)"
      ]
    }
  },
  "A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER": {
    "filename": "A Multi-Task Semantic Decomposition Framework with Task-specific Pre-training for Few-Shot NER.pdf",
    "analysis": {
      "benchmarks": [
        "Few-NERD",
        "CrossNER",
        "CoNLL-2003",
        "GUM",
        "WNUT-2017",
        "OntoNotes"
      ],
      "models": [
        "MSDP",
        "ProtoBERT",
        "NNShot",
        "StructShot",
        "CONTaiNER",
        "ESD",
        "DecomMeta",
        "SpanProto",
        "Matching Network",
        "L-TapNet+CDT",
        "SimBERT",
        "TransferBERT",
        "CONTAINER",
        "DecomMeta",
        "SpanProto"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ReMI A Dataset for Reasoning with Multiple Images": {
    "filename": "ReMI A Dataset for Reasoning with Multiple Images.pdf",
    "analysis": {
      "benchmarks": [
        "ReMI",
        "SuperGLUE",
        "HellaSwag",
        "Lambada",
        "MMLU",
        "ARC",
        "MATH",
        "GSM8K",
        "MGSM",
        "BIG-Bench",
        "NLVR",
        "NLVR2",
        "MaRVL",
        "SEED-Bench-2",
        "BLINK"
      ],
      "models": [
        "Naive Baseline",
        "Claude3",
        "Sonnet",
        "Gemini Ultra",
        "Gemini Flash",
        "Gemini 1.5",
        "GPT4 Turbo",
        "Human"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automated Program Repair Emerging trends pose and expose problems for benchmarks": {
    "filename": "Automated Program Repair Emerging trends pose and expose problems for benchmarks.pdf",
    "analysis": {
      "benchmarks": [
        "ManyBugs",
        "Defects4J",
        "Bugs.jar",
        "Bears",
        "CrossVul",
        "CodeFlaws",
        "IntroClass"
      ],
      "models": [
        "VFix",
        "VRepair",
        "SynFix",
        "Sequencer",
        "iFixR",
        "TBar",
        "Angelix",
        "DLFix",
        "RewardRepair",
        "CURE",
        "SeqTrans",
        "SynShine",
        "SequenceR",
        "AlphaRepair",
        "VulRepair",
        "Recoder",
        "Quatrain",
        "SelfAPR",
        "TransRepair",
        "Reptory",
        "TENURE",
        "Tare",
        "Knod",
        "Rete",
        "TRANSFER",
        "AccPR",
        "GenProg",
        "ARJA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Diversity Measures Domain-Independent Proxies for Failure in Language Model Queries": {
    "filename": "Diversity Measures Domain-Independent Proxies for Failure in Language Model Queries.pdf",
    "analysis": {
      "benchmarks": [
        "CSQA",
        "DRAW-1K",
        "LL"
      ],
      "models": [
        "GPT 3.5",
        "sentence-BERT",
        "MLP 10",
        "MLP 15",
        "XGBoost",
        "AdaBoost",
        "MLP 5"
      ]
    }
  },
  "Provable optimal transport with transformers The essence of depth and prompt engineering": {
    "filename": "Provable optimal transport with transformers The essence of depth and prompt engineering.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "transformer",
        "GPT-4",
        "Sinkhorn attention",
        "Sinkformers"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PlanBench An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change": {
    "filename": "PlanBench An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change.pdf",
    "analysis": {
      "benchmarks": [
        "PlanBench",
        "Blocksworld",
        "Logistics"
      ],
      "models": [
        "Instruct-GPT3",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Bootstrap3D Improving Multi-view Diffusion Model with Synthetic Data": {
    "filename": "Bootstrap3D Improving Multi-view Diffusion Model with Synthetic Data.pdf",
    "analysis": {
      "benchmarks": [
        "Objaverse",
        "Objaverse-XL",
        "SA-1B"
      ],
      "models": [
        "Bootstrap3D",
        "MV-LLaVA",
        "Instant3D",
        "MVDream",
        "Zero123++",
        "SV3D",
        "CRM",
        "PixArt-Alpha",
        "FlanT5",
        "DiT",
        "GRM",
        "InstantMesh"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Does ChatGPT Have a Mind": {
    "filename": "Does ChatGPT Have a Mind.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT 3.5",
        "GPT-4",
        "Othello-GPT",
        "Llama-2",
        "Vision-Language Models (VLMs)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mathematical Capabilities of ChatGPT": {
    "filename": "Mathematical Capabilities of ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "GHOSTS",
        "miniGHOSTS",
        "MATH",
        "MathQA",
        "GSM8K",
        "AQuA-RAT",
        "NaturalProofs",
        "NaturalProofs-Gen",
        "Symbolic Integration"
      ],
      "models": [
        "ChatGPT (9-January-2023 version)",
        "ChatGPT (30-January-2023 version)",
        "GPT-4",
        "Minerva",
        "PaLM",
        "BERT",
        "BLOOM",
        "LaMDA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Weak-eval-Strong Evaluating and Eliciting Lateral Thinking of LLMs with Situation Puzzles": {
    "filename": "Weak-eval-Strong Evaluating and Eliciting Lateral Thinking of LLMs with Situation Puzzles.pdf",
    "analysis": {
      "benchmarks": [
        "SPLAT",
        "RiddleSense",
        "BrainTeaser"
      ],
      "models": [
        "WizardLM-2",
        "Llama3-70B",
        "Llama3-8B",
        "Qwen1.5-32B",
        "Qwen1.5-110B",
        "GPT-4",
        "GPT-4 Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Eir Thai Medical Large Language Models": {
    "filename": "Eir Thai Medical Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "MedMCQA",
        "PubMedQA",
        "MMLU medical-subset",
        "ThaiExam",
        "M3Exam",
        "XNLI",
        "XCOPA"
      ],
      "models": [
        "Eir-8B",
        "Eir-8B-prob",
        "Typhoon-v1.5x-8B-instruct",
        "OpenThaiGPT-beta-7B",
        "BioMistral 7B",
        "Mistral 7B Instruct",
        "MedAlpaca 7B",
        "PMC-LLAMA 7B",
        "MediTron-7B",
        "BioMedGPT-LLM-7B",
        "GPT-3.5 Turbo 1106",
        "Meta Llama 3.1-8B Instruct",
        "GPT-4-0613"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving Planning with Large Language Models A Modular Agentic Architecture": {
    "filename": "Improving Planning with Large Language Models A Modular Agentic Architecture.pdf",
    "analysis": {
      "benchmarks": [
        "CogEval",
        "Tower of Hanoi",
        "PlanBench",
        "StrategyQA"
      ],
      "models": [
        "Modular Agentic Planner (MAP)",
        "GPT-4 Zero-shot",
        "In-context learning (ICL)",
        "Chain-of-thought (CoT)",
        "Multi-agent debate (MAD)",
        "Tree-of-thought (ToT)",
        "Llama3-70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Comprehensive Survey of Attack Techniques Implementation and Mitigation Strategies in Large Language Models": {
    "filename": "A Comprehensive Survey of Attack Techniques Implementation and Mitigation Strategies in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5 turbo",
        "ChatGPT",
        "Google Bard",
        "GPT-4",
        "ChatGLM",
        "BERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Discuss Before Moving Visual Language Navigation via Multi-expert Discussions": {
    "filename": "Discuss Before Moving Visual Language Navigation via Multi-expert Discussions.pdf",
    "analysis": {
      "benchmarks": [
        "R2R",
        "Matterport3D"
      ],
      "models": [
        "DiscussNav",
        "GPT4",
        "LM-Nav",
        "CoW",
        "VLMaps",
        "NavGPT",
        "Seq2Seq",
        "Speaker Follower",
        "EnvDrop",
        "PREVALENT",
        "VLN\u27f3BERT",
        "HAMT",
        "DuET",
        "InstructBLIP",
        "RAM",
        "ChatGPT"
      ]
    }
  },
  "Toward Robust Evaluation A Comprehensive Taxonomy of Datasets and Metrics for Open Domain Question Answering in the Era of Large Language Models": {
    "filename": "Toward Robust Evaluation A Comprehensive Taxonomy of Datasets and Metrics for Open Domain Question Answering in the Era of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "WebQuestions",
        "CuratedTREC",
        "WikiQA",
        "SQuAD",
        "MS Marco",
        "Quasar-T",
        "SearchQA",
        "TriviaQA",
        "BoolQ",
        "Natural Questions",
        "ELI5",
        "AMBIGNQ",
        "ASQA",
        "HotPotQA",
        "DROP",
        "2WikiMultiHopQA",
        "MultiSpanQA",
        "QAMPARI",
        "ConcurrentQA",
        "QuAC",
        "QBLink",
        "CoQA",
        "OR-QuAC",
        "QReCC",
        "TopiOCQA",
        "Topical-Chat",
        "XQA",
        "MLQA",
        "XQuAD",
        "TyDiQA",
        "XTREME",
        "XOR-TyDiQA",
        "MKQA",
        "GEN-TyDiQA",
        "SituatedQA",
        "TimeQA",
        "FreshQA",
        "ComQA",
        "Paraphrased-SQuAD",
        "CREPE",
        "TruthfulQA",
        "IfQA",
        "OK-VQA",
        "S3VQA",
        "MIMOQA",
        "A-OKVQA",
        "WebQA",
        "HybridQA",
        "OTT-QA",
        "ManyModalQA",
        "MultiModalQA",
        "MMConvQA"
      ],
      "models": [
        "DrQA",
        "DPR",
        "T5",
        "GPT-3",
        "Fusion-in-Decoder",
        "DenSPI",
        "ORQA",
        "R3",
        "Multi-passage BERT",
        "REALM",
        "RAG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "High-Fidelity Lake Extraction Via Two-Stage Prompt Enhancement Establishing A Novel Baseline and Benchmark": {
    "filename": "High-Fidelity Lake Extraction Via Two-Stage Prompt Enhancement Establishing A Novel Baseline and Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "Surface Water dataset (SW dataset)",
        "Qinghai-Tibet Plateau Lake dataset (QTPL dataset)",
        "CVC-ClinicDB (CVC)",
        "ISIC2018"
      ],
      "models": [
        "LEPrompter",
        "UDGN",
        "MSLWENet",
        "ResNet-101",
        "LEFormer",
        "HA-Net",
        "MSNANet",
        "SAM",
        "SegFormer",
        "PoolFormer",
        "SegNeXt"
      ]
    }
  },
  "Stance detection a practical guide to classifying political beliefs in text": {
    "filename": "Stance detection a practical guide to classifying political beliefs in text.pdf",
    "analysis": {
      "benchmarks": [
        "Semeval 2016",
        "DC Inbox project"
      ],
      "models": [
        "supervised classifiers",
        "NLI classifiers",
        "in-context classifiers",
        "GPT-4",
        "RoBERTa",
        "BERTweet",
        "PoliBERTweet",
        "DeBERTaV3",
        "Electra",
        "Zephyr 7B",
        "GPT-3.5 Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Galactica A Large Language Model for Science": {
    "filename": "Galactica A Large Language Model for Science.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "MATH",
        "PubMedQA",
        "MedMCQA",
        "BIG-bench",
        "BioASQ",
        "MedQA-USMLE",
        "ARC Challenge",
        "ARC Easy",
        "PWC Citations",
        "Extended Citations",
        "Contextual Citations"
      ],
      "models": [
        "Galactica",
        "GPT-3",
        "Chinchilla",
        "PaLM",
        "BLOOM",
        "OPT",
        "Gopher",
        "Minerva"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating LLMs Capabilities Towards Understanding Social Dynamics": {
    "filename": "Evaluating LLMs Capabilities Towards Understanding Social Dynamics.pdf",
    "analysis": {
      "benchmarks": [
        "Instagram sessions",
        "4chan threads",
        "WikiTableQuestions"
      ],
      "models": [
        "Llama",
        "ChatGPT",
        "BERT",
        "GPT-2",
        "RoBERTa",
        "Llama-2 7B",
        "Llama-2 13B",
        "GPT 3.5"
      ]
    }
  },
  "OntoChatGPT Information System Ontology-Driven Structured Prompts for ChatGPT Meta-Learning": {
    "filename": "OntoChatGPT Information System Ontology-Driven Structured Prompts for ChatGPT Meta-Learning.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "OntoChatGPT",
        "ChatGPT",
        "Google\u2019s Bard utilizing the PaLM 2 LLM",
        "BERT-based models"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ShapefileGPT A Multi-Agent Large Language Model Framework for Automated Shapefile Processing": {
    "filename": "ShapefileGPT A Multi-Agent Large Language Model Framework for Automated Shapefile Processing.pdf",
    "analysis": {
      "benchmarks": [
        "Shapefile task dataset"
      ],
      "models": [
        "ShapefileGPT",
        "GPT-4-Turbo-2024-04-09",
        "GPT-4o-Mini-2024-07-18",
        "GPT-4o-2024-05-13",
        "GPT-3.5-Turbo-0125"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "One Prompt is not Enough Automated Construction of a Mixture-of-Expert Prompts": {
    "filename": "One Prompt is not Enough Automated Construction of a Mixture-of-Expert Prompts.pdf",
    "analysis": {
      "benchmarks": [
        "Instruction-Induction",
        "Super Natural Instructions",
        "BIG-Bench-Hard"
      ],
      "models": [
        "Mixture-of-Prompts (MoP)",
        "APE",
        "APE+Demos",
        "APE+K-centroids",
        "InstructZero (IZ)",
        "IZ+Demos",
        "IZ+K-centroids"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews": {
    "filename": "The Promise and Challenges of Using LLMs to Accelerate the Screening Process of Systematic Reviews.pdf",
    "analysis": {
      "benchmarks": [
        "TOSLS",
        "Scopus Papers"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Few-shot",
        "Few-shot with Chain-of-Thought",
        "One-shot",
        "Zero-shot",
        "Redesigned One-shot",
        "Redesigned Zero-shot"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ArtWhisperer A Dataset for Characterizing Human-AI Interactions in Artistic Creations": {
    "filename": "ArtWhisperer A Dataset for Characterizing Human-AI Interactions in Artistic Creations.pdf",
    "analysis": {
      "benchmarks": [
        "ArtWhisperer",
        "ArtWhisperer-Validation"
      ],
      "models": [
        "Stable Diffusion v2.1",
        "Stable Diffusion v1.5",
        "GPT-4",
        "Gemini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GITA Graph to Visual and Textual Integration for Vision-Language Graph Reasoning": {
    "filename": "GITA Graph to Visual and Textual Integration for Vision-Language Graph Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GVLQA",
        "GraphQA",
        "NLGraph",
        "ca-GrQc",
        "ca-HepTh",
        "PolBlogs",
        "Cora",
        "CiteSeer"
      ],
      "models": [
        "GITA",
        "InstructGLM",
        "GPT4Graph",
        "LLMtoGraph",
        "GraphGPT",
        "GraphToken",
        "LLaGA",
        "LLaMA2-7B",
        "LLaMA2-13B",
        "Vicuna-7B",
        "Vicuna-13B",
        "GPT-4 Turbo",
        "GPT-4V",
        "LLaVA-7B",
        "LLaVA-13B",
        "GCN",
        "GraphSAGE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multimodal Multi-Hop Question Answering Through a Conversation Between Tools and Efficiently Finetuned Large Language Models": {
    "filename": "Multimodal Multi-Hop Question Answering Through a Conversation Between Tools and Efficiently Finetuned Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MultiModalQA",
        "MMCoQA"
      ],
      "models": [
        "StableLM-7b",
        "Pathia-12b",
        "LLaMA-13b",
        "Falcon-40b",
        "ChatGPT"
      ]
    }
  },
  "Solving Math Word Problems by Combining Language Models With Symbolic Solvers": {
    "filename": "Solving Math Word Problems by Combining Language Models With Symbolic Solvers.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "ALGEBRA"
      ],
      "models": [
        "Program-Aided Language model (PAL)",
        "chain-of-thought (COT) prompting",
        "DECLARATIVE prompting",
        "DECLARATIVE 3-shot +principles +SymPy",
        "DECLARATIVE 3-shot +principles",
        "ONE-STEP DECLARATIVE 3-shot +SymPy"
      ]
    }
  },
  "Code Detection for Hardware Acceleration Using Large Language Models": {
    "filename": "Code Detection for Hardware Acceleration Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GEMM",
        "convolution",
        "fast-Fourier transform (FFT)",
        "Parboil",
        "Caffe",
        "ACOTSP",
        "cpufetch"
      ],
      "models": [
        "GPT-3.5",
        "gpt-3.5-turbo-16k"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning": {
    "filename": "Advancing Multimodal Large Language Models in Chart Question Answering with Visualization-Referenced Instruction Tuning.pdf",
    "analysis": {
      "benchmarks": [
        "ChartQA",
        "Beagle",
        "PlotQA",
        "ChartQA-H",
        "ChartQA-M",
        "Chart2Table",
        "visual literacy"
      ],
      "models": [
        "Qwen-VL-Max",
        "GPT-4-Vision-Preview",
        "Our model",
        "LLaVA-1.6-13b",
        "LLaVA-1.6-34b",
        "Qwen-VL-Chat",
        "Qwen-VL-Plus",
        "LLaVA-1.5",
        "LLaVA-1.5 + ChartQA-H",
        "LLaVA-1.5 + ChartQA-M",
        "LLaVA-1.5 + Chart2Table",
        "LLaVA-1.5 + ChartQA-H & ChartQA-M",
        "LLaVA-1.5 + ChartQA-H & Chart2Table",
        "LLaVA-1.5 + ChartQA-H & ChartQA-M & Chart2Table"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SMART Self-learning Meta-strategy Agent for Reasoning Tasks": {
    "filename": "SMART Self-learning Meta-strategy Agent for Reasoning Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "ASDiv"
      ],
      "models": [
        "SMART",
        "Llama3 8B",
        "Gemma 7B",
        "Mistral 7B",
        "Qwen2 7B",
        "Chain of Thought (CoT)",
        "Least to Most (L2M)",
        "Program of Thought (PoT)"
      ]
    }
  },
  "FACTIFY-5WQA 5W Aspect-based Fact Verification through Question Answering": {
    "filename": "FACTIFY-5WQA 5W Aspect-based Fact Verification through Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "FACTIFY-5WQA",
        "FEVER",
        "LIAR",
        "PolitiFact",
        "FavIQ",
        "Hover",
        "X-Fact",
        "CREAK",
        "FEVEROUS",
        "VITC",
        "Factify 1.0",
        "Factify 2.0"
      ],
      "models": [
        "baseline QA system",
        "proposed fact verification system",
        "RoBERTa Large",
        "Pegasus",
        "T5 (T5-Large)",
        "GPT-3 (text-davinci-003 variant)",
        "BART",
        "ProphetNet",
        "T5-3B",
        "Bert-Large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Octavius Mitigating Task Interference in MLLMs via LoRA-MoE": {
    "filename": "Octavius Mitigating Task Interference in MLLMs via LoRA-MoE.pdf",
    "analysis": {
      "benchmarks": [
        "PASCAL VOC",
        "ScienceQA",
        "MS-COCO",
        "LAMM v1",
        "LAMM v2",
        "Flickr30K",
        "CIFAR-10",
        "CelebA",
        "ShapeNet",
        "NR3D",
        "ScanNet",
        "Scan2Inst"
      ],
      "models": [
        "Octavius",
        "LoRA-MoE",
        "LAMM",
        "LLaVA-LoRA",
        "3D-LLM",
        "Object-As-Scene"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unlocking Historical Clinical Trial Data with ALIGN A Compositional Large Language Model System for Medical Coding": {
    "filename": "Unlocking Historical Clinical Trial Data with ALIGN A Compositional Large Language Model System for Medical Coding.pdf",
    "analysis": {
      "benchmarks": [
        "Anatomical Therapeutic Chemical (ATC) classification",
        "Medical Dictionary for Regulatory Activities (MedDRA)",
        "SLE dataset",
        "RA dataset"
      ],
      "models": [
        "ALIGN",
        "LLM",
        "LLM (CoT)",
        "RAG",
        "RAG (CoT)",
        "GPT-4o-mini",
        "GPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can LLMs Reason in Music An Evaluation of LLMs Capability of Music Understanding and Generation": {
    "filename": "Can LLMs Reason in Music An Evaluation of LLMs Capability of Music Understanding and Generation.pdf",
    "analysis": {
      "benchmarks": [
        "MusicPile",
        "MusicBench"
      ],
      "models": [
        "GPT-4",
        "Gemma-7B-it",
        "Llama2-7B-chat",
        "Qwen-7B-chat"
      ]
    }
  },
  "ChartGPT Leveraging LLMs to Generate Charts from Abstract Natural Language": {
    "filename": "ChartGPT Leveraging LLMs to Generate Charts from Abstract Natural Language.pdf",
    "analysis": {
      "benchmarks": [
        "nvBench",
        "NLV Corpus",
        "Quda"
      ],
      "models": [
        "ChartGPT",
        "NL4DV",
        "ncNet",
        "Flan-T5",
        "GPT-3",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on Vision-Language-Action Models for Embodied AI": {
    "filename": "A Survey on Vision-Language-Action Models for Embodied AI.pdf",
    "analysis": {
      "benchmarks": [
        "Ravens",
        "3D Playroom environment",
        "CALVIN",
        "RLBench",
        "Meta-World",
        "Franka Kitchen",
        "Adroit",
        "DeepMind Control Suite",
        "VIMA-Bench",
        "Sapien",
        "Robomimic",
        "BridgeV2",
        "Stanford Coffee",
        "Berkeley Peg Insert",
        "LIBERO",
        "ALOHA"
      ],
      "models": [
        "CLIPort",
        "MCIL",
        "HULC",
        "HULC++",
        "Language costs",
        "Interactive Language",
        "Hiveformer",
        "PerAct",
        "Act3D",
        "RVT",
        "RVT-2",
        "RoboPoint",
        "Gato",
        "RoboCat",
        "VIMA",
        "BC-Z",
        "RT-1",
        "MOO",
        "Q-Transformer",
        "RT-Trajectory",
        "ACT",
        "MT-ACT",
        "RT-2",
        "RT-H",
        "RT-X",
        "OpenVLA",
        "RoboFlamingo",
        "RoboUniView",
        "VoxPoser",
        "UniPi",
        "Diffusion Policy",
        "DP3",
        "SUDD",
        "Octo",
        "3D Diffuser Actor",
        "MDT",
        "RDT-1B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MAgIC Investigation of Large Language Model Powered Multi-Agent in Cognition Adaptability Rationality and Collaboration": {
    "filename": "MAgIC Investigation of Large Language Model Powered Multi-Agent in Cognition Adaptability Rationality and Collaboration.pdf",
    "analysis": {
      "benchmarks": [
        "Chameleon",
        "Undercover",
        "Cost Sharing",
        "Multi-turn Prisoner's Dilemma",
        "Public Good"
      ],
      "models": [
        "GPT o1",
        "GPT-4-turbo",
        "GPT-4",
        "GPT-3.5-turbo",
        "Claude 2",
        "PaLM 2",
        "Cohere",
        "Llama-2-70B",
        "GPT o1+PGM",
        "GPT-4-turbo+PGM",
        "GPT-4+PGM",
        "GPT-3.5-turbo+PGM",
        "Claude 2+PGM",
        "PaLM 2+PGM",
        "Cohere+PGM",
        "Llama-2-70B+PGM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Compositional API Recommendation for Library-Oriented Code Generation": {
    "filename": "Compositional API Recommendation for Library-Oriented Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "RAPID",
        "LOCG",
        "Torchdata-AR",
        "Math-AR",
        "RealMatrix-AR",
        "XMLStreamWriter-AR",
        "Multi-Conala",
        "Torchdata-Code",
        "Multi-ODEX"
      ],
      "models": [
        "CAPIR",
        "ADA-retrieve",
        "CLEAR",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond Traditional Teaching The Potential of Large Language Models and Chatbots in Graduate Engineering Education": {
    "filename": "Beyond Traditional Teaching The Potential of Large Language Models and Chatbots in Graduate Engineering Education.pdf",
    "analysis": {
      "benchmarks": [
        "Graduate Fluid Mechanics Course"
      ],
      "models": [
        "ChatGPT-3.5",
        "ChatGPT-4",
        "ChatGPT-4 with Wolfram"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Far Are We on the Decision-Making of LLMs Evaluating LLMs Gaming Ability in Multi-Agent Environments": {
    "filename": "How Far Are We on the Decision-Making of LLMs Evaluating LLMs Gaming Ability in Multi-Agent Environments.pdf",
    "analysis": {
      "benchmarks": [
        "GAMA-Bench"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Gemini",
        "LLaMA-3.1",
        "Mixtral",
        "Qwen-2",
        "Gemini-1.5-Pro",
        "LLaMA-3.1-70B",
        "Mixtral-8x22B",
        "GPT-3.5-Turbo",
        "GPT-4-Turbo",
        "Gemini-1.0-Pro",
        "Gemini-1.5-Pro",
        "LLaMA-3.1-8B",
        "LLaMA-3.1-405B",
        "Mixtral-8x7B",
        "Qwen-2-72B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Benchmarking Generative Models on Computational Thinking Tests in Elementary Visual Programming": {
    "filename": "Benchmarking Generative Models on Computational Thinking Tests in Elementary Visual Programming.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "APPS",
        "CT-TEST",
        "HOC",
        "ACE"
      ],
      "models": [
        "GPT-4o",
        "Llama3",
        "LLAMA CT:HOC",
        "LLAMA CT:HOCexp",
        "LLAMA CT:HOC+MCQ",
        "LLAMA CT:HOC+MCQexp",
        "LLAMA CT:HOC+MCQ+AUGexp",
        "LLAMA CT:HOC+MCQ+AUGexp*",
        "CODELLAMA-7B-INSTRUCT",
        "LLAVA 1.5-7B",
        "LLAMA 3-8B-INSTRUCT",
        "GPT3.5",
        "GPT4 vis",
        "GPT4 text",
        "GPT4 vis+text",
        "GPT4O vis",
        "GPT4O text",
        "GPT4O vis+text"
      ]
    }
  },
  "ESG Classification by Implicit Rule Learning via GPT-4": {
    "filename": "ESG Classification by Implicit Rule Learning via GPT-4.pdf",
    "analysis": {
      "benchmarks": [
        "Shared-Task ML-ESG-3",
        "KMMLU"
      ],
      "models": [
        "GPT-4",
        "Yi-Ko-6B",
        "EEVE-Korean-10.8B"
      ]
    }
  },
  "On the application of Large Language Models for language teaching and assessment technology": {
    "filename": "On the application of Large Language Models for language teaching and assessment technology.pdf",
    "analysis": {
      "benchmarks": [
        "RACE",
        "SCDE",
        "CLOTH",
        "CEPOC",
        "Teacher-Student Chatroom Corpus",
        "TOEFL11",
        "CoNLL-2014",
        "JFLEG",
        "BEA-2019"
      ],
      "models": [
        "GPT-4",
        "GPT-3",
        "ChatGPT",
        "T5",
        "PaLM",
        "LaMDA",
        "LLaMA",
        "OPT",
        "Gopher",
        "BERT",
        "BART",
        "ELECTRA",
        "DistilBERT",
        "GECToR",
        "GPT-3.5",
        "InstructGPT",
        "BLOOM",
        "GPT-Neo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Voluminous yet Vacuous Semantic Capital in an Age of Large Language Models": {
    "filename": "Voluminous yet Vacuous Semantic Capital in an Age of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "BERT",
        "Word2Vec",
        "Sequence-to-Sequence models",
        "Transformer architecture",
        "LSTM",
        "OpenAI's GPTs",
        "BLOOM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LC-LLM Explainable Lane-Change Intention and Trajectory Predictions with Large Language Models": {
    "filename": "LC-LLM Explainable Lane-Change Intention and Trajectory Predictions with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "highD dataset"
      ],
      "models": [
        "LC-LLM",
        "LSTM-based model",
        "Transformer-based model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving Automatic VQA Evaluation Using Large Language Models": {
    "filename": "Improving Automatic VQA Evaluation Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "VQAv2",
        "VG-QA",
        "OK-VQA"
      ],
      "models": [
        "BLIP-2",
        "PromptCap",
        "BLIP VQA",
        "BLIP VG",
        "LAVE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment": {
    "filename": "Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment.pdf",
    "analysis": {
      "benchmarks": [
        "SOCIAL CHEMISTRY",
        "Zhihu"
      ],
      "models": [
        "text-davinci-003",
        "GPT-3",
        "XLM-R",
        "FLAN-T5",
        "T5-eSNLI",
        "mT5-SocNorm",
        "T5-SocNorm",
        "DREAM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Foundation Models for Weather and Climate Data Understanding A Comprehensive Survey": {
    "filename": "Foundation Models for Weather and Climate Data Understanding A Comprehensive Survey.pdf",
    "analysis": {
      "benchmarks": [
        "PANGU-WEATHER",
        "W-MAE",
        "CLIMAX"
      ],
      "models": [
        "Recurrent Neural Networks",
        "Diffusion Models",
        "Transformers",
        "Generative Adversarial Networks",
        "Spatio-Temporal Graph Neural Networks",
        "Auto Regressive Integrated Moving Average (ARIMA)",
        "Seasonal ARIMA (SARIMA)",
        "Seasonal ARIMA with eXogenous variables (SARIMAX)",
        "Vector Autoregression (VAR)",
        "Informer",
        "Autoformer",
        "Crossformer",
        "ETSFormer",
        "Reformer",
        "FEDformer",
        "Convolutional LSTM",
        "Convolutional GRU",
        "CLIP",
        "SAM",
        "InstructBLIP",
        "CoCa",
        "BEIT-3",
        "InstructGPT",
        "LLaMa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey of Large Language Models in Medicine Progress Application and Challenge": {
    "filename": "A Survey of Large Language Models in Medicine Progress Application and Challenge.pdf",
    "analysis": {
      "benchmarks": [
        "USMLE",
        "MedQA",
        "PubMedQA",
        "MedMCQA",
        "NCBI disease dataset"
      ],
      "models": [
        "ChatGPT",
        "GPT-3.5",
        "GPT-4",
        "PaLM",
        "LLaMA",
        "MedPaLM-2",
        "MedPrompt",
        "ChatDoctor",
        "MedAlpaca",
        "PMC-LLaMA",
        "BenTsao",
        "Clinical Camel",
        "BioBERT",
        "PubMedBERT",
        "SciBERT",
        "NYUTron",
        "ClinicalBERT",
        "BioM-ELECTRA",
        "BioMed-RoBERTa",
        "BioLinkBERT",
        "BlueBERT",
        "SciFive",
        "ClinicalT5",
        "MedCPT",
        "DRAGON",
        "BioGPT",
        "BioMedLM",
        "OphGLM",
        "GatorTron",
        "GatorTronGPT",
        "DoctorGLM",
        "BianQue",
        "ClinicalGPT",
        "Qilin-Med",
        "HuatuoGPT",
        "Baize-healthcare",
        "BioMedGPT",
        "AlpaCare",
        "Zhongjing",
        "CPLLM",
        "Med429",
        "MEDITRON",
        "OpenBioLLM",
        "MedLlama3-v209",
        "Med-Flamingo",
        "LLaVA-Med",
        "MAIRA-1",
        "RadFM",
        "Med-Gemini",
        "CodeX",
        "DeID-GPT",
        "ChatCAD",
        "Dr. Knows",
        "Chat-Orthopedist",
        "QA-RAG",
        "Almanac",
        "Oncology-GPT-4",
        "DDx PaLM-2",
        "Foresight",
        "TrialGPT",
        "PLM-ICD",
        "DRG-LLaMA",
        "ChatICD",
        "LLM-codex",
        "ImpressionGPT",
        "RadAdapt",
        "SuFIA",
        "UltrasoundGPT",
        "Robotic X-ray",
        "Medical mT5",
        "Apollo",
        "BiMediX",
        "Biomed-sum",
        "RALL",
        "PsyChat",
        "ChatCounselor",
        "Mental-LLM",
        "AMIE",
        "Healthcare Copilot",
        "Conversational Diagnosis"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Midas Touch Triggering the Capability of LLMs for RM-API Misuse Detection": {
    "filename": "The Midas Touch Triggering the Capability of LLMs for RM-API Misuse Detection.pdf",
    "analysis": {
      "benchmarks": [
        "FFmpeg",
        "Libevent",
        "Libexpat",
        "Libpcap",
        "Libzip",
        "OpenLdap",
        "APIMU4C"
      ],
      "models": [
        "ChatDetector",
        "Advance",
        "HERO",
        "Goshawk",
        "CodeQL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Networking Applications Enabling Techniques and Challenges": {
    "filename": "Large Language Models for Networking Applications Enabling Techniques and Challenges.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatNet",
        "Lumi",
        "BERT",
        "GPT-4",
        "GPT-4 Turbo",
        "LoRA",
        "AssistGPT",
        "AI-generated network design",
        "NetGPT"
      ]
    }
  },
  "ChatGPT and Beyond The Generative AI Revolution in Education": {
    "filename": "ChatGPT and Beyond The Generative AI Revolution in Education.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "Argumate",
        "decision-guided chatbot",
        "Chatbot-assisted in-class debates (CaIcD)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning the meanings of function words from grounded language using a visual question answering model": {
    "filename": "Learning the meanings of function words from grounded language using a visual question answering model.pdf",
    "analysis": {
      "benchmarks": [
        "CLEVR"
      ],
      "models": [
        "MAC model",
        "4-step MAC model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Small Language Models for Application Interactions A Case Study": {
    "filename": "Small Language Models for Application Interactions A Case Study.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Phi-3",
        "Llama 3",
        "Mistral v0.2",
        "Phi-3-mini",
        "GPT-4-turbo",
        "GPT-3.5-turbo",
        "Phi-2",
        "Gemma",
        "Gorilla OpenFunc v2"
      ]
    }
  },
  "The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task": {
    "filename": "The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task.pdf",
    "analysis": {
      "benchmarks": [
        "Winoground"
      ],
      "models": [
        "GPT-4V",
        "GPT-4V CoT",
        "CLIP",
        "METER",
        "Fiber",
        "TIFA",
        "PALI",
        "VQ2",
        "MMICL",
        "InstructBLIP",
        "InstructBLIP CoT",
        "LLaVA",
        "LLaVA CoT"
      ]
    }
  },
  "On the Roles of LLMs in Planning Embedding LLMs into Planning Graphs": {
    "filename": "On the Roles of LLMs in Planning Embedding LLMs into Planning Graphs.pdf",
    "analysis": {
      "benchmarks": [
        "gripper",
        "miconic",
        "logistics",
        "movie",
        "blocks",
        "satellite",
        "zenotravel",
        "driverlog",
        "woodworking",
        "openstacks"
      ],
      "models": [
        "LLMs4Plan",
        "GP",
        "GPT-3.5",
        "GPT-4",
        "LLMs4Plan-GPT3.5",
        "LLMs4Plan-GPT4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Context Awareness Gate For Retrieval Augmented Generation": {
    "filename": "Context Awareness Gate For Retrieval Augmented Generation.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD",
        "CRSB"
      ],
      "models": [
        "Context Awareness Gate (CAG)",
        "Vector Candidates",
        "RAG",
        "OpenAI GPT-4o mini"
      ]
    }
  },
  "GEAR An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM": {
    "filename": "GEAR An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "AQuA",
        "BigBench Hard",
        "LongBench"
      ],
      "models": [
        "GEAR",
        "GEAR-L",
        "LLaMA2-7B",
        "LLaMA2-13B",
        "Mistral-7B",
        "LLaMA3-8B",
        "KIVI",
        "KCVT",
        "Per-token group-wise quantization"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cleared for Takeoff Compositional  Conditional Reasoning may be the Achilles Heel to Flight-Booking Language Agents": {
    "filename": "Cleared for Takeoff Compositional  Conditional Reasoning may be the Achilles Heel to Flight-Booking Language Agents.pdf",
    "analysis": {
      "benchmarks": [
        "GroundCocoa"
      ],
      "models": [
        "GPT-4 Turbo",
        "Gemini Pro",
        "LLAMA 2-chat 7B",
        "Mistral 7B Instruct",
        "LLAMA 2-chat 13B",
        "Mixtral 8x7B-Instruct",
        "LLAMA 2-chat 70B"
      ]
    }
  },
  "Towards Safe and Honest AI Agents with Neural Self-Other Overlap": {
    "filename": "Towards Safe and Honest AI Agents with Neural Self-Other Overlap.pdf",
    "analysis": {
      "benchmarks": [
        "MT-Bench"
      ],
      "models": [
        "Mistral-7B-Instruct-v0.2",
        "Gemma-2-27B-it",
        "CalmeRys-78B-Orpo-v0.1",
        "Deceptive Baseline",
        "Honest Baseline",
        "SOO Fine-Tuning"
      ]
    }
  },
  "Exploring Length Generalization in Large Language Models": {
    "filename": "Exploring Length Generalization in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Archive of Formal Proofs",
        "MATH dataset"
      ],
      "models": [
        "LaMDA",
        "Codex",
        "transformer-based large language models",
        "LaMDA 244m",
        "LaMDA 422m",
        "LaMDA 1b",
        "LaMDA 64b",
        "LaMDA 128b"
      ]
    }
  },
  "GraphEval2000 Benchmarking and Improving Large Language Models on Graph Datasets": {
    "filename": "GraphEval2000 Benchmarking and Improving Large Language Models on Graph Datasets.pdf",
    "analysis": {
      "benchmarks": [
        "GraphEval2000",
        "LeetCode"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "GPT-4o",
        "Gemini-Pro",
        "Gemini-1.5",
        "Claude-3-Haiku",
        "Claude-3-Sonnet",
        "Claude-3-Opus",
        "LLaMA-3-70b",
        "Mixtral-8x7b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LMTuner An user-friendly and highly-integrable Training Framework for fine-tuning Large Language Models": {
    "filename": "LMTuner An user-friendly and highly-integrable Training Framework for fine-tuning Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MedDialog",
        "LM-Medical-v1",
        "CMCQA",
        "LIMA"
      ],
      "models": [
        "LMTuner",
        "GPT-4",
        "ChatGLM2-6B",
        "Llama-7B",
        "Llama2-7B",
        "Llama2-13B",
        "GLM-130B",
        "GPT-3",
        "Instruct-GPT",
        "GLM",
        "ChatGLM-6B",
        "Llama-13B",
        "Llama-33B",
        "Llama-65B",
        "Llama2-70B",
        "GPT-Neo-1.3B",
        "GPT-2"
      ]
    }
  },
  "ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality": {
    "filename": "ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-3.5",
        "GPT-4",
        "eXclusivi platform",
        "PROMOTE system"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models": {
    "filename": "The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ARC",
        "AGIEval",
        "HellaSwag",
        "MedMCQA",
        "AQUA-RAT",
        "SAT Math"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Concise Chain-of-Thought (CCoT)",
        "Chain-of-Thought (CoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Better Out-of-Distribution Generalization of Neural Algorithmic Reasoning Tasks": {
    "filename": "Towards Better Out-of-Distribution Generalization of Neural Algorithmic Reasoning Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "CLRS"
      ],
      "models": [
        "MPNN-FC",
        "MPNN-G",
        "PGN",
        "GAT",
        "2WL-graph neural network",
        "Hybrid-Average",
        "Hybrid-Sigmoid"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can large language models reason about medical questions": {
    "filename": "Can large language models reason about medical questions.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA-USMLE",
        "MedMCQA",
        "PubMedQA"
      ],
      "models": [
        "GPT-3.5",
        "InstructGPT",
        "Codex",
        "Llama-2",
        "GPT-4",
        "MedPalm v2",
        "Finetuned SOTA",
        "PubMedGPT",
        "Galactica",
        "BioGPT",
        "Vicuna",
        "Guanaco",
        "Falcon",
        "MPT",
        "GPT-NeoX"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Easily do Irrelevant Inputs Skew the Responses of Large Language Models": {
    "filename": "How Easily do Irrelevant Inputs Skew the Responses of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "POPQA",
        "ENTITY QUESTIONS"
      ],
      "models": [
        "GPT-4 Turbo",
        "GPT-3.5 Turbo",
        "Gemini Pro",
        "Llama2-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TorchQL A Programming Framework for Integrity Constraints in Machine Learning": {
    "filename": "TorchQL A Programming Framework for Integrity Constraints in Machine Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Cityscapes",
        "Physionet-2012 Challenge",
        "iWildCam",
        "Alpaca",
        "GSM8K",
        "Date Understanding"
      ],
      "models": [
        "OneFormer",
        "SAITS",
        "ResNet50",
        "T5",
        "GPT-3.5",
        "Mistral 7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance": {
    "filename": "Employing Label Models on ChatGPT Answers Improves Legal Text Entailment Performance.pdf",
    "analysis": {
      "benchmarks": [
        "COLIEE 2022"
      ],
      "models": [
        "ChatGPT",
        "Label models",
        "FlyingSquid",
        "Dawid-Skene",
        "Hyper label model",
        "FABLE",
        "Generative model",
        "Majority voting"
      ]
    }
  },
  "Towards Responsible Generative AI A Reference Architecture for Designing Foundation Model Based Agents": {
    "filename": "Towards Responsible Generative AI A Reference Architecture for Designing Foundation Model Based Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "MetaGPT",
        "HuggingGPT",
        "Auto-GPT",
        "BabyAGI"
      ]
    }
  },
  "CRUD-RAG A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models": {
    "filename": "CRUD-RAG A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CRUD-RAG",
        "UHGEval",
        "RGB",
        "NQ",
        "LangChain Docs Q&A",
        "Semi-structured Reports",
        "ARES",
        "RAGAS",
        "SCIFI",
        "ALiiCE"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "ChatGLM2-6B",
        "Baichuan2-13B",
        "Qwen-7B",
        "Qwen-14B",
        "bge-base",
        "m3e-base",
        "stella-base",
        "gte-base"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLaMA-Berry Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning": {
    "filename": "LLaMA-Berry Pairwise Optimization for O1-like Olympiad-Level Mathematical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "AIME24",
        "AMC23",
        "GSM8K",
        "MATH",
        "GaoKao2023En",
        "OlympiadBench",
        "College Math",
        "MMLU STEM",
        "GSMHard",
        "MATH500"
      ],
      "models": [
        "LLaMA-Berry",
        "GPT-4",
        "ToT",
        "rStar",
        "Meta-Llama-3.1-8B-Instruct",
        "Qwen2-7B-Instruct",
        "Meta-Llama-3.1-70B-Instruct",
        "DeepSeekMath-7B-RL",
        "Internlm2-math-plus-7b",
        "Mathstral-7B-v0.1",
        "NuminaMath-7B-CoT",
        "Qwen2-Math-7B-Instruct",
        "NuminaMath-72B-CoT",
        "Qwen2-Math-72B-Instruct",
        "Claude 3 Opus",
        "GPT 4 Turbo",
        "GPT 4o",
        "OpenAI o1 Preview",
        "OpenAI o1",
        "Gemini 1.5 Pro",
        "Gemini Math-Specialized 1.5 Pro",
        "Zero-Shot CoT",
        "Few-shot CoT",
        "One-turn Self-Refine",
        "Self-Cons",
        "RAP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Guided Stream of Search Learning to Better Search with Language Models via Optimal Path Guidance": {
    "filename": "Guided Stream of Search Learning to Better Search with Language Models via Optimal Path Guidance.pdf",
    "analysis": {
      "benchmarks": [
        "Countdown"
      ],
      "models": [
        "Guided stream of search (GSoS)",
        "Stream of search (SoS)",
        "SoS+STaR",
        "SoS+PPO",
        "GSoS+PPO",
        "Symbolic method"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ContextIQ A Multimodal Expert-Based Video Retrieval System for Contextual Advertising": {
    "filename": "ContextIQ A Multimodal Expert-Based Video Retrieval System for Contextual Advertising.pdf",
    "analysis": {
      "benchmarks": [
        "MSR-VTT",
        "Condensed Movies",
        "Val-1",
        "Val-2"
      ],
      "models": [
        "ContextIQ",
        "LanguageBind",
        "Google's Vertex API",
        "TwelveLabs Marengo",
        "CLIP-Large",
        "One-Peace"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Question Answering as Programming for Solving Time-Sensitive Questions": {
    "filename": "Question Answering as Programming for Solving Time-Sensitive Questions.pdf",
    "analysis": {
      "benchmarks": [
        "TimeQA",
        "TempQuestions",
        "TimeQuestions"
      ],
      "models": [
        "QAaP",
        "CoT",
        "ReAct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VQA Training Sets are Self-play Environments for Generating Few-shot Pools": {
    "filename": "VQA Training Sets are Self-play Environments for Generating Few-shot Pools.pdf",
    "analysis": {
      "benchmarks": [
        "ChartQA",
        "PlotQA v2",
        "InfographicVQA",
        "DocVQA"
      ],
      "models": [
        "Gemini",
        "ScreenAI",
        "Visual Program-of-Thought",
        "Gemini as a tool",
        "ScreenAI as a tool"
      ]
    }
  },
  "WizardMath Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct": {
    "filename": "WizardMath Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "MATH"
      ],
      "models": [
        "WizardMath",
        "Llama-2",
        "ChatGPT-3.5",
        "Claude Instant-1",
        "PaLM-2",
        "Minerva",
        "Text-davinci-002",
        "PaLM-1",
        "GPT-3",
        "Llama-2 70B",
        "Llama-1 65B",
        "Falcon-40B",
        "MPT-30B",
        "Baichuan-13B Chat",
        "ChatGLM2 12B",
        "GPT-4",
        "Claude 2",
        "Flan-PaLM 2",
        "Chinchilla",
        "GPT-J-6B",
        "Vicuna v1.3",
        "Baichuan-chat",
        "Qwen",
        "InternLM-7B",
        "GAL",
        "GPT-Neo-2.7B",
        "MPT8",
        "RFT-13B",
        "RFT-7B",
        "Wizard-E",
        "Wizard-Evol-Generator"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-Correcting LLM-Controlled Diffusion Models": {
    "filename": "Self-Correcting LLM-Controlled Diffusion Models.pdf",
    "analysis": {
      "benchmarks": [
        "LMD"
      ],
      "models": [
        "Self-correcting LLM-controlled Diffusion (SLD)",
        "DALL-E 3",
        "Stable Diffusion",
        "LMD+",
        "MultiDiffusion",
        "Backward Guidance",
        "BoxDiff",
        "LayoutGPT + GLIGEN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data": {
    "filename": "Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3",
        "ChatGPT",
        "GPT-3.5",
        "GPT-4",
        "PaLM",
        "OPT",
        "HyperCLOVA",
        "davinci-text-002"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "True Detective A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4": {
    "filename": "True Detective A Deep Abductive Reasoning Benchmark Undoable for GPT-3 and Challenging for GPT-4.pdf",
    "analysis": {
      "benchmarks": [
        "5 Minute Mystery"
      ],
      "models": [
        "GPT-3.5 (FeedME)",
        "GPT-3.5 (PPO)",
        "GPT-4"
      ]
    }
  },
  "Language Models are Spacecraft Operators": {
    "filename": "Language Models are Spacecraft Operators.pdf",
    "analysis": {
      "benchmarks": [
        "Kerbal Space Program Differential Games (KSPDG)"
      ],
      "models": [
        "GPT-3.5",
        "baseline LLM",
        "LLM with few-shot prompting",
        "LLM with Chain of Thought (CoT) prompting",
        "fine-tuned LLM"
      ]
    }
  },
  "Automatic Macro Mining from Interaction Traces at Scale": {
    "filename": "Automatic Macro Mining from Interaction Traces at Scale.pdf",
    "analysis": {
      "benchmarks": [
        "RICO",
        "MoTIF",
        "random crawls of apps"
      ],
      "models": [
        "LLM-based system",
        "PaLM2-Bison"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "T2 of Thoughts Temperature Tree Elicits Reasoning in Large Language Models": {
    "filename": "T2 of Thoughts Temperature Tree Elicits Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Game of 24",
        "Creative Writing"
      ],
      "models": [
        "T2oT",
        "ToT",
        "GPT-4"
      ]
    }
  },
  "Natural Language Reinforcement Learning": {
    "filename": "Natural Language Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "tabular MDP",
        "Frozen-Lake"
      ],
      "models": [
        "Natural Language Reinforcement Learning (NLRL)",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Textbooks Are All You Need II phi-15 technical report": {
    "filename": "Textbooks Are All You Need II phi-15 technical report.pdf",
    "analysis": {
      "benchmarks": [
        "Winogrande",
        "ARC-Easy",
        "ARC-Challenge",
        "BoolQ",
        "SIQA",
        "PIQA",
        "HellaSwag",
        "MMLU",
        "OpenbookQA",
        "SQUAD",
        "GSM8K",
        "HumanEval",
        "MBPP"
      ],
      "models": [
        "phi-1.5",
        "phi-1.5-web",
        "phi-1.5-web-only",
        "Vicuna-13B",
        "Llama 2-7B",
        "Llama-7B",
        "Falcon-RW-1.3B",
        "MPT-7B",
        "OPT-1.3B",
        "GPT-Neo-2.7B",
        "GPT2-XL-1.5B"
      ]
    }
  },
  "Image First or Text First Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks": {
    "filename": "Image First or Text First Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "M3Exam",
        "M3COTS"
      ],
      "models": [
        "GPT-4o",
        "Gemini-1.5 Flash",
        "Claude-3-Haiku"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Collaborative Evolving Strategy for Automatic Data-Centric Development": {
    "filename": "Collaborative Evolving Strategy for Automatic Data-Centric Development.pdf",
    "analysis": {
      "benchmarks": [
        "RD2Bench"
      ],
      "models": [
        "Co-STEER",
        "Few-shot",
        "CoT",
        "Reflexion",
        "Self-Debugging",
        "Self-Planning"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unlocking the Capabilities of Thought A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought": {
    "filename": "Unlocking the Capabilities of Thought A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought.pdf",
    "analysis": {
      "benchmarks": [
        "BIGGSM",
        "GSM8K",
        "HotpotQA",
        "MGSM"
      ],
      "models": [
        "GPT-3.5-Turbo",
        "GPT-4",
        "GPT-4o",
        "O1-preview",
        "LLaMA",
        "LLaMA-2",
        "Code-LLaMA",
        "MathInstruct",
        "Claude 3",
        "Mistral 7B",
        "ResPrompt",
        "PAL",
        "PoT",
        "Tool Usage",
        "Complex CoT",
        "Least-to-Most",
        "CoT+MARP",
        "PoT+MARP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Optimization via Adversarial In-Context Learning": {
    "filename": "Prompt Optimization via Adversarial In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "big-bench hard",
        "XSUM",
        "CNN/Daily Mail",
        "WebNLG",
        "E2E NLG",
        "LIRO",
        "TED Talks",
        "YELP-5",
        "COPA",
        "WSC",
        "GSM8K",
        "SVAMP"
      ],
      "models": [
        "Adversarial In-Context Learning (adv-ICL)",
        "ChatGPT",
        "text-davinci-002",
        "Vicuna-13B v1.5",
        "Chain-of-Thought (CoT)",
        "ROUGE-L",
        "Perplexity",
        "Genetic Prompt Search (GPS)",
        "Automatic Prompt Optimization (APO)",
        "Automatic Prompt Engineer (APE)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DeFT Decoding with Flash Tree-attention for Efficient Tree-structured LLM Inference": {
    "filename": "DeFT Decoding with Flash Tree-attention for Efficient Tree-structured LLM Inference.pdf",
    "analysis": {
      "benchmarks": [
        "APPS",
        "Graph-of-Thoughts (GoT)",
        "Medusa"
      ],
      "models": [
        "DEFT-Flatten",
        "Flash-Decoding",
        "Tree Attention-Medusa",
        "Radix Attention",
        "DEFT-Node",
        "DEFT-Node-Chunk"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMLingua Compressing Prompts for Accelerated Inference of Large Language Models": {
    "filename": "LLMLingua Compressing Prompts for Accelerated Inference of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "BBH",
        "ShareGPT",
        "Arxiv-March23"
      ],
      "models": [
        "LLMLingua",
        "Selective-Context",
        "GPT-3.5-Turbo-0301",
        "Claude-v1.3",
        "Alpaca-7B",
        "GPT2-Alpaca",
        "GPT4-Generation",
        "Random Selection",
        "Sentence Selection"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Buffer of Thoughts Thought-Augmented Reasoning with Large Language Models": {
    "filename": "Buffer of Thoughts Thought-Augmented Reasoning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Game of 24",
        "Geometric Shapes",
        "Checkmate-in-One",
        "BIG-Bench Hard (BBH)",
        "Multi-Step Arithmetic Two",
        "Word Sorting",
        "BIG-Bench suite",
        "Penguins",
        "Date Understanding",
        "Python Programming Puzzles (P3)",
        "Multilingual Grade School Math (MGSM)",
        "Shakespearean Sonnet Writing"
      ],
      "models": [
        "Buffer of Thoughts (BoT)",
        "Llama3-8B",
        "Llama3-70B",
        "GPT-4",
        "GPT-4+CoT",
        "Expert Prompting",
        "PAL",
        "ToT",
        "GoT",
        "Meta Prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SynthAI A Multi Agent Generative AI Framework for Automated Modular HLS Design Generation": {
    "filename": "SynthAI A Multi Agent Generative AI Framework for Automated Modular HLS Design Generation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "SynthAI",
        "GPT-3.5-Turbo",
        "GPT-4-Turbo",
        "GPT-4o"
      ]
    }
  },
  "Limits of Transformer Language Models on Learning to Compose Algorithms": {
    "filename": "Limits of Transformer Language Models on Learning to Compose Algorithms.pdf",
    "analysis": {
      "benchmarks": [
        "Pointer Execution's neighbor (PEN)",
        "Pointer Execution Reverse Multicount (PERM)",
        "Highest Subsequence Sum (HSS)",
        "Multiplication (MUL)"
      ],
      "models": [
        "LLaMA",
        "GPT-4",
        "Gemini",
        "Gemini-Pro",
        "Universal Transformer (UT-style LLaMA)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LlamaCare A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing": {
    "filename": "LlamaCare A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing.pdf",
    "analysis": {
      "benchmarks": [
        "PubMedQA",
        "USMLE-step-1-3"
      ],
      "models": [
        "LlamaCare",
        "LLaMA-2",
        "ChatGPT",
        "Med-Alpaca",
        "Chat-Doctor"
      ]
    }
  },
  "SelfIE Self-Interpretation of Large Language Model Embeddings": {
    "filename": "SelfIE Self-Interpretation of Large Language Model Embeddings.pdf",
    "analysis": {
      "benchmarks": [
        "TextWorld"
      ],
      "models": [
        "SelfIE",
        "LLaMA-2-70B-Chat",
        "linear probe",
        "Fine-tuning (FT)",
        "RepE",
        "ROME"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "When IoT Meet LLMs Applications and Challenges": {
    "filename": "When IoT Meet LLMs Applications and Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "AdvertiseGen",
        "MMLU",
        "WikiText",
        "WikiTableQA",
        "TabFact",
        "DeepSense 6G",
        "MIT-BIH ECG",
        "WiFi CSI",
        "MIT-BIH Arrhythmia",
        "MULTIIOT",
        "LCCC",
        "SuperGLUE",
        "CNN/DailyMail",
        "XSum",
        "UNSW NB15",
        "TON IoT",
        "MedBIoT",
        "GSM-8K",
        "Rosetta",
        "HumanEvalX",
        "Dolly-15K",
        "BoolQ",
        "PIQA",
        "SIQA",
        "WinoGrande",
        "OBQA",
        "HellaSwag",
        "EdgeIIoTset"
      ],
      "models": [
        "RoBERTa",
        "BERT",
        "GPT-4",
        "PaLM",
        "Mistral GPT",
        "TinyBERT",
        "DistilBERT",
        "MobileBERT",
        "LLaMA2 Chat",
        "Gemini nano",
        "mBERT",
        "CodeGen",
        "PaLM2",
        "ChatGLM-6B",
        "LoRA",
        "P-Tuning-v2",
        "Llama2",
        "Gemma Phi-2",
        "Edge-LLM",
        "EdgeShard",
        "Multi-Modal Transformer (MMT)",
        "Reinforcement Learning (RL)",
        "LLMind",
        "CASIT",
        "IoT-LM",
        "IoT-LLM",
        "GIoT",
        "DLoRA",
        "PerLLM",
        "FedBIOT",
        "FL-GLM",
        "PLLM-CS",
        "SLFHunter",
        "SecurityBERT",
        "PAC-GPT",
        "FATE-LLM",
        "SpeziLLM"
      ]
    }
  },
  "Visualization Literacy of Multimodal Large Language Models A Comparative Study": {
    "filename": "Visualization Literacy of Multimodal Large Language Models A Comparative Study.pdf",
    "analysis": {
      "benchmarks": [
        "VLAT",
        "mini-VLAT"
      ],
      "models": [
        "GPT4-o",
        "Claude 3 Opus",
        "Gemini 1.5 Pro"
      ]
    }
  },
  "Knowledge-enhanced Neural Machine Reasoning A Review": {
    "filename": "Knowledge-enhanced Neural Machine Reasoning A Review.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD"
      ],
      "models": [
        "GPT-3",
        "Neural Turing Machine (NTM)",
        "Hopfield Network",
        "QA-GNN",
        "Greaselm",
        "SR3",
        "RRN",
        "HypE",
        "ConE"
      ]
    }
  },
  "THRONE An Object-Based Hallucination Benchmark for the Free-Form Generations of Large Vision-Language Models": {
    "filename": "THRONE An Object-Based Hallucination Benchmark for the Free-Form Generations of Large Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "THRONE",
        "POPE",
        "CHAIR",
        "COCO",
        "Objects365",
        "MMBench",
        "MME",
        "SEED-Bench"
      ],
      "models": [
        "THRONE",
        "POPE",
        "CHAIR",
        "Adapter-v2",
        "Adapter-v2.1",
        "InstructBLIP",
        "Otter-Image",
        "MiniGPT4",
        "MiniGPT-v2",
        "mPLUG-Owl",
        "LRV-Instruction-v2",
        "LLaVA-v1.3",
        "LLaVA-v1.5",
        "LLaVA-Mistral",
        "Frozen",
        "Flamingo",
        "BLIP-2",
        "LLaVA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Empowering Visual Creativity A Vision-Language Assistant to Image Editing Recommendations": {
    "filename": "Empowering Visual Creativity A Vision-Language Assistant to Image Editing Recommendations.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Creativity-VLA",
        "InstructDiffusion",
        "GLIGEN",
        "MagicBrush",
        "LLaVA-v1.5",
        "GPT-4V"
      ]
    }
  },
  "Causal Parrots Large Language Models May Talk Causality But Are Not Causal": {
    "filename": "Causal Parrots Large Language Models May Talk Causality But Are Not Causal.pdf",
    "analysis": {
      "benchmarks": [
        "altitude",
        "health",
        "driving",
        "recovery",
        "cancer",
        "earthquake"
      ],
      "models": [
        "GPT-3",
        "Luminous",
        "OPT",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoManual Generating Instruction Manuals by LLM Agents via Interactive Environmental Learning": {
    "filename": "AutoManual Generating Instruction Manuals by LLM Agents via Interactive Environmental Learning.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld",
        "MiniWoB++",
        "WebArena"
      ],
      "models": [
        "AutoManual",
        "GPT-4-turbo",
        "GPT-3.5-turbo",
        "ReAct",
        "Reflexion",
        "ExpeL",
        "AdaPlanner",
        "Planner+Lib.",
        "RCI",
        "AutoGuide",
        "SteP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Theoretical Understanding of Chain-of-Thought Coherent Reasoning and Error-Aware Demonstration": {
    "filename": "A Theoretical Understanding of Chain-of-Thought Coherent Reasoning and Error-Aware Demonstration.pdf",
    "analysis": {
      "benchmarks": [
        "BBH benchmark",
        "GSM8k benchmark",
        "Disambiguation QA",
        "Tracking Shuffled Objects (7 objects)",
        "Date Understanding",
        "Penguins in a Table"
      ],
      "models": [
        "Stepwise ICL",
        "Coherent CoT",
        "GPT-3.5-Turbo",
        "GPT-4o-mini",
        "Gemini Pro",
        "DeepSeek 67B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Potential and Value of AI Chatbot in Personalized Cognitive Training": {
    "filename": "The Potential and Value of AI Chatbot in Personalized Cognitive Training.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ReMe",
        "GPT-4o"
      ]
    }
  },
  "Auxiliary task demands mask the capabilities of smaller language models": {
    "filename": "Auxiliary task demands mask the capabilities of smaller language models.pdf",
    "analysis": {
      "benchmarks": [
        "LAMBADA",
        "BLiMP",
        "digit matrices task",
        "cognitive reflection tests (CRTs)"
      ],
      "models": [
        "Pythia",
        "OLMo",
        "Gemma",
        "Llama-2",
        "Mistral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reading Users Minds from What They Say An Investigation into LLM-based Empathic Mental Inference": {
    "filename": "Reading Users Minds from What They Say An Investigation into LLM-based Empathic Mental Inference.pdf",
    "analysis": {
      "benchmarks": [
        "baseline datasets from human users",
        "benchmark datasets from designers"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4",
        "human designers",
        "LLM-based AI models",
        "standard prompting",
        "chain-of-thoughts (CoT) prompting",
        "tree-of-thoughts (ToT) prompting"
      ]
    }
  },
  "Industrial Engineering with Large Language Models A Case Study of ChatGPTs Performance on Oil  Gas Problems": {
    "filename": "Industrial Engineering with Large Language Models A Case Study of ChatGPTs Performance on Oil  Gas Problems.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT"
      ]
    }
  },
  "Extracting Victim Counts from Text": {
    "filename": "Extracting Victim Counts from Text.pdf",
    "analysis": {
      "benchmarks": [
        "World Atrocities Dataset (WAD)",
        "Non-violent and Violent Campaigns and Outcomes 3.0 (NAVCO)",
        "European Media Monitor (EMM)"
      ],
      "models": [
        "regex",
        "dependency parsing",
        "semantic role labeling (SRL)",
        "NT5",
        "NT5-Gen",
        "NT5-Reg",
        "NT5-Clf"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Gemma Open Models Based on Gemini Research and Technology": {
    "filename": "Gemma Open Models Based on Gemini Research and Technology.pdf",
    "analysis": {
      "benchmarks": [
        "ARC",
        "CommonsenseQA",
        "Big Bench Hard",
        "AGI Eval",
        "MMLU",
        "HellaSwag",
        "PIQA",
        "SIQA",
        "Boolq",
        "Winogrande",
        "CQA",
        "OBQA",
        "ARC-e",
        "ARC-c",
        "TriviaQA",
        "NQ",
        "HumanEval",
        "MBPP",
        "GSM8K",
        "MATH",
        "TruthfulQA",
        "RealToxicity",
        "BOLD",
        "CrowS-Pairs",
        "BBQ Ambig",
        "BBQ Disambig",
        "Winogender",
        "Winobias",
        "Toxigen"
      ],
      "models": [
        "Gemma 2B",
        "Gemma 7B",
        "LLaMA 2 (7B)",
        "LLaMA 2 (13B)",
        "Mistral (7B)",
        "Mistral v0.2 7B Instruct",
        "Gemma 1.1 IT 7B",
        "Gemma 1.1 IT 2B",
        "Gemma 1.0",
        "Gemma 1.1 IT",
        "PaLM",
        "PaLM 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey of Foundation Models for Music Understanding": {
    "filename": "A Survey of Foundation Models for Music Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "AudioSet",
        "GTZAN",
        "Free Music Archive",
        "Music Classification",
        "Multi-modal MIREX Emotion",
        "MusicCaps",
        "MTG-Jamendo"
      ],
      "models": [
        "Depthwise Separable Convolution (DSC)",
        "Pretrained Audio Neural Network (PANN)",
        "Audio Spectrogram Transformer (AST)",
        "MusCaps",
        "Qwen-Audio",
        "LTU",
        "SALMONN",
        "ModaVerse",
        "AnyGPT",
        "ChatMusician",
        "M\u00b2UGen",
        "MU-LLaMA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models": {
    "filename": "Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison Scaling of Texts with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Chen et al. dataset"
      ],
      "models": [
        "CGCoT",
        "RoBERTa-Large",
        "Wordfish",
        "ChatGPT-3.5",
        "Non-CGCoT Tweets-Only Pairwise Scores"
      ]
    }
  },
  "Bailicai A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications": {
    "filename": "Bailicai A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "MedMCQA",
        "MMLU-Med",
        "PubMedQA",
        "BioASQ"
      ],
      "models": [
        "Bailicai",
        "GPT-3.5",
        "GPT-4",
        "Med-PaLM 2",
        "Meta-Llama3-70B",
        "Meta-Llama3-8B",
        "Med-Alpaca",
        "BioMistral",
        "PMC-LLaMA",
        "OpenBioLLM",
        "Flan-PaLM",
        "Mistral-7B-V0.3",
        "ChatGPT",
        "Self-BioRAG",
        "MEDRAG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection": {
    "filename": "Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection.pdf",
    "analysis": {
      "benchmarks": [
        "SPIDER",
        "SPIDER-DEV",
        "SPIDER-SYN",
        "SPIDER-TEST"
      ],
      "models": [
        "WizardCoder",
        "CodeLlama",
        "deepseek-coder-6.7b",
        "CodeLlama-7b-Instruct",
        "CodeLlama-13b-Instruct",
        "WizardCoder-15B-V1.0",
        "Baichuan2-7B-Chat",
        "T5-3B",
        "T5-3B PICARD"
      ]
    }
  },
  "Large Language Models Are Reasoning Teachers": {
    "filename": "Large Language Models Are Reasoning Teachers.pdf",
    "analysis": {
      "benchmarks": [
        "SingleEq",
        "AddSub",
        "MultiArith",
        "GSM8K",
        "SVAMP",
        "Date Understanding",
        "Tracking Shuffled Objects",
        "Last Letter Concatenation",
        "Coin Flip",
        "CommonSenseQA",
        "StrategyQA"
      ],
      "models": [
        "GPT-3 175B",
        "Fine-tune-CoT",
        "Zero-shot-CoT",
        "Few-shot-CoT",
        "InstructGPT (text-davinci-002)",
        "GPT-3 (ada, babbage, curie)",
        "GPT-2 (Small, Medium, Large)",
        "T5 (Small, Base, Large)",
        "Flan-T5 (Small, Base, Large)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FLM-101B An Open LLM and How to Train It with 100K Budget": {
    "filename": "FLM-101B An Open LLM and How to Train It with 100K Budget.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "C-Eval",
        "ARC-Challenge",
        "HellaSwag",
        "TruthfulQA",
        "SuperGLUE",
        "CLUE",
        "babi-20"
      ],
      "models": [
        "FLM-101B",
        "GPT-3",
        "GLM-130B",
        "eFLM-16B",
        "LLAMA-2",
        "LLAMA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Empirical Study on Low Code Programming using Traditional vs Large Language Model Support": {
    "filename": "An Empirical Study on Low Code Programming using Traditional vs Large Language Model Support.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "traditional LCP",
        "LLM-based LCP",
        "ChatGPT",
        "Github Copilot",
        "QUICKBASE",
        "SOFTR",
        "APPIAN",
        "APPSHEET"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Controlling Large Language Model-based Agents for Large-Scale Decision-Making An Actor-Critic Approach": {
    "filename": "Controlling Large Language Model-based Agents for Large-Scale Decision-Making An Actor-Critic Approach.pdf",
    "analysis": {
      "benchmarks": [
        "system resource allocation",
        "robot grid transportation"
      ],
      "models": [
        "LLaMAC",
        "Multi-agent Debate",
        "Only_Explore",
        "Only_Exploit",
        "Decentralization",
        "HMAS-2"
      ]
    }
  },
  "Towards Controllable Speech Synthesis in the Era of Large Language Models A Survey": {
    "filename": "Towards Controllable Speech Synthesis in the Era of Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Prosody-Tacotron",
        "GST-Tacotron",
        "GMVAE-Tacotron",
        "ELLA-V",
        "HALL-E",
        "VoiceCraft",
        "VALL-E R",
        "Takin",
        "CoFi-Speech",
        "FireRedTTS",
        "Emo-DPO",
        "Bailing TTS",
        "CosyVoice",
        "Seed-TTS",
        "ClaM-TTS",
        "VoxInstruct",
        "ARDiT",
        "NanoVoice",
        "VoiceGuider",
        "DEX-TTS",
        "E2-TTS",
        "AST-LDM",
        "VoiceLDM",
        "SpeechFlow",
        "PromptTTS++",
        "VAE-Tacotron",
        "DurIAN",
        "FastSpeech",
        "FastSpeech2",
        "FastPitch",
        "ParallelTacotron",
        "Flowtron",
        "StyleTagging-TTS",
        "SC-GlowTTS",
        "Meta-StyleSpeech",
        "DelightfulTTS",
        "YourTTS",
        "RNNCNNGANTransformerDiffusionLLMMsEmoTTS",
        "Style-TTS",
        "DiffGAN-TTS",
        "Grad-StyleSpeech",
        "NaturalSpeech2",
        "GenerSpeech",
        "Cauliflow",
        "CLONE",
        "PromptTTS",
        "DuIAN-E",
        "PromptTTS2",
        "TorToise",
        "SpearTTS",
        "VALL-EX",
        "SCVALL-E",
        "UniAUdio",
        "VALL-E",
        "Make-a-voice",
        "Salle",
        "MaskGCT",
        "DiTTo-TTS",
        "FlashSpeech",
        "NaturalSpeech3",
        "InstructTTS",
        "ControlSpeech",
        "SimpleSpeech",
        "SimpleSpeech2",
        "StyleTTS-ZS",
        "ArtSpeech",
        "XTTS",
        "MegaTTS",
        "MegaTTS2",
        "Autoregressive",
        "Non-autoregressive",
        "MELLE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automatic Data Repair Are We Ready to Deploy": {
    "filename": "Automatic Data Repair Are We Ready to Deploy.pdf",
    "analysis": {
      "benchmarks": [
        "Hospital",
        "Flights",
        "Beers",
        "Rayyan",
        "Tax"
      ],
      "models": [
        "Holistic",
        "BigDansing",
        "Horizon",
        "Nadeef",
        "MLNClean",
        "Daisy",
        "Scare",
        "Baran",
        "Unified",
        "Relative",
        "HoloClean",
        "BoostClean"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain-of-Planned-Behaviour Workflow Elicits Few-Shot Mobility Generation in LLMs": {
    "filename": "Chain-of-Planned-Behaviour Workflow Elicits Few-Shot Mobility Generation in LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Tencent",
        "ChinaMobile"
      ],
      "models": [
        "Chain-of-Planned-Behaviour (CoPB)",
        "V-LLM",
        "ST+G",
        "COT+G",
        "TOT+G",
        "TimeGeo",
        "MoveSim",
        "Volunteer",
        "DiffTraj",
        "Act2Loc",
        "GPT-4-turbo",
        "LLaMA3-8B",
        "LLaMA3-8B-F"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Explicit CoT to Implicit CoT Learning to Internalize CoT Step by Step": {
    "filename": "From Explicit CoT to Implicit CoT Learning to Internalize CoT Step by Step.pdf",
    "analysis": {
      "benchmarks": [
        "4\u00d74Mult",
        "5\u00d75Mult",
        "7\u00d77Mult",
        "9\u00d79Mult",
        "GSM8K"
      ],
      "models": [
        "GPT-2 Small",
        "Mistral 7B",
        "MathGLM-100M",
        "MathGLM-500M",
        "MathGLM-2B",
        "GPT-3.5",
        "GPT-4",
        "Phi-3 3.8B",
        "ICoT-KD",
        "ICoT-SI"
      ]
    }
  },
  "Video Token Sparsification for Efficient Multimodal LLMs in Autonomous Driving": {
    "filename": "Video Token Sparsification for Efficient Multimodal LLMs in Autonomous Driving.pdf",
    "analysis": {
      "benchmarks": [
        "DRAMA",
        "LingoQA"
      ],
      "models": [
        "Video Token Sparsification (VTS)",
        "DriveLM",
        "LMDrive",
        "OmniDrive",
        "DriveVLM",
        "CLIP-BEVFormer",
        "TOKEN",
        "LaMPilot",
        "InternVL2-8B",
        "InternVL2-2B",
        "ToMe",
        "PaPr",
        "LCP"
      ]
    }
  },
  "Logic Contrastive Reasoning with Lightweight Large Language Model for Math Word Problems": {
    "filename": "Logic Contrastive Reasoning with Lightweight Large Language Model for Math Word Problems.pdf",
    "analysis": {
      "benchmarks": [
        "SVAMP",
        "GSM8K"
      ],
      "models": [
        "Logic Contrastive Reasoning (LCR)",
        "Chain of Thought (CoT)",
        "Self-Correction (SC)",
        "Plan-and-Solve (PS)",
        "Mistral-7B",
        "LLaMA2-7B",
        "ChatGPT-3.5 Turbo 0301"
      ]
    }
  },
  "Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations": {
    "filename": "Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations.pdf",
    "analysis": {
      "benchmarks": [
        "\u03b1NLI",
        "Sen-Making",
        "\u03b4-NLI",
        "WinoWhy",
        "\u03b4-ATOMIC",
        "\u03b4-SNLI",
        "\u03b4-SOCIAL"
      ],
      "models": [
        "LiPoR",
        "Tuned BART",
        "ZS BART",
        "ZS GPT3",
        "ZS GPT-NEO",
        "RoBERTa",
        "KDDC-ATOMIC",
        "KDDC-CWWV",
        "KDDC-CSKG",
        "QNLI-ATOMIC",
        "Prompted GPT3",
        "RoBERTa-Grande",
        "ECNU-SenseMaker",
        "RAINBOW"
      ]
    }
  },
  "BRAINTEASER Lateral Thinking Puzzles for Large Language Models": {
    "filename": "BRAINTEASER Lateral Thinking Puzzles for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BRAIN TEASER",
        "PIQA",
        "RiddleSense"
      ],
      "models": [
        "ChatGPT",
        "FlanT5(780M)",
        "FlanT5(3B)",
        "FlanT5(11B)",
        "T0(11B)",
        "T0P(11B)",
        "T0PP(11B)",
        "RoBERTa-L",
        "RoBERTa-L(CSKG)",
        "CAR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GraphInsight Unlocking Insights in Large Language Models for Graph Structure Understanding": {
    "filename": "GraphInsight Unlocking Insights in Large Language Models for Graph Structure Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "GraphSQA",
        "GraphEval2000",
        "GraphArena",
        "GraphInstruct",
        "GraCoRe"
      ],
      "models": [
        "GraphInsight",
        "Mistral-7B",
        "Llama-3-8B",
        "Qwen2-7B",
        "Llama-3-8B-262k",
        "Vicuna-7B",
        "Raw Seq.",
        "GraphToken",
        "Build-a-Graph Prompting (BAG)",
        "Chain-of-Thought (COT)",
        "Few-Shot (FS)",
        "breadth-first-search order (BFS)",
        "depth-first-search order (DFS)",
        "shortest-path order (SP)",
        "adjacency lists (AL)",
        "adjacency matrices (AM)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models": {
    "filename": "Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Indoor 1",
        "Indoor 2",
        "Outdoor 1",
        "Outdoor 2",
        "Outdoor 3"
      ],
      "models": [
        "VLM-PC",
        "No History",
        "No Multi-Step",
        "Random"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OR-Bench An Over-Refusal Benchmark for Large Language Models": {
    "filename": "OR-Bench An Over-Refusal Benchmark for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "OR-Bench-80K",
        "OR-Bench-Hard-1K",
        "OR-Bench-Toxic",
        "XSTest"
      ],
      "models": [
        "Llama-2-7b",
        "Llama-2-13b",
        "Claude-2.1",
        "Claude-3-haiku",
        "Claude-3-sonnet",
        "Claude-3-opus",
        "Gemma-7b",
        "Gemini-1.0-pro",
        "Gemini-1.5-flash",
        "GPT-3.5-turbo-0301",
        "GPT-3.5-turbo-0613",
        "GPT-3.5-turbo-0125",
        "GPT-4-0125-preview",
        "GPT-4-turbo-2024-04-09",
        "GPT-4o",
        "Llama-2-70b",
        "Llama-3-8b",
        "Llama-3-70b",
        "Mistral-small-latest",
        "Mistral-medium-latest",
        "Mistral-large-latest",
        "Qwen-1.5-7B",
        "Qwen-1.5-32B",
        "Qwen-1.5-72B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PARSE-Ego4D Personal Action Recommendation Suggestions for Egocentric Videos": {
    "filename": "PARSE-Ego4D Personal Action Recommendation Suggestions for Egocentric Videos.pdf",
    "analysis": {
      "benchmarks": [
        "Ego4D",
        "EPIC-Kitchens"
      ],
      "models": [
        "Gemini Pro",
        "Gemini XXS",
        "EgoOnly",
        "IntentCapsNet",
        "Instruct2Act",
        "CogAgent"
      ]
    }
  },
  "Simulating Human Strategic Behavior Comparing Single and Multi-agent LLMs": {
    "filename": "Simulating Human Strategic Behavior Comparing Single and Multi-agent LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "ultimatum game"
      ],
      "models": [
        "single LLM",
        "multi-agent system",
        "GPT-3.5",
        "GPT-4",
        "MultiAgent-3.5",
        "MultiAgent-4",
        "SingleLLM-3.5",
        "SingleLLM-4"
      ]
    }
  },
  "Entropic Distribution Matching in Supervised Fine-tuning of LLMs Less Overfitting and Better Diversity": {
    "filename": "Entropic Distribution Matching in Supervised Fine-tuning of LLMs Less Overfitting and Better Diversity.pdf",
    "analysis": {
      "benchmarks": [
        "UltraFeedback",
        "IFEval",
        "GSM8K",
        "HumanEval",
        "MBPP",
        "MetaMathQA",
        "MagicCoder-OSS-Instruct",
        "MATH",
        "AlpacaEval"
      ],
      "models": [
        "Llama-3-8B",
        "GEM",
        "CE",
        "CE + WD",
        "CE + Entropy",
        "GEM-LS",
        "GEM-Linear"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "To CoT or not to CoT Chain-of-thought helps mainly on math and symbolic reasoning": {
    "filename": "To CoT or not to CoT Chain-of-thought helps mainly on math and symbolic reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "MMLU Pro",
        "GSM8K",
        "MATH",
        "SCONE",
        "Coin Flip",
        "BBH",
        "BIG-bench Hard",
        "CommonsenseQA",
        "StrategyQA",
        "MuSR",
        "ContextHub",
        "FOLIO",
        "MuSiQue",
        "BiGGen Bench",
        "ARC-Easy",
        "ARC-Challenge",
        "WinoGrande",
        "PIQA",
        "SiQA",
        "AGI LSAT",
        "Legal Argument Reasoning",
        "ScienceQA",
        "Commitment Bank",
        "HotpotQA"
      ],
      "models": [
        "ChatGPT",
        "Llama 3.1",
        "Mixtral-Large2",
        "GPT-4o",
        "Claude 3",
        "Claude 3.5",
        "vLLM",
        "PAL",
        "SatLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Empirical Categorization of Prompting Techniques for Large Language Models A Practitioners Guide": {
    "filename": "An Empirical Categorization of Prompting Techniques for Large Language Models A Practitioners Guide.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT",
        "LaMDA",
        "PaLM",
        "LLaMa",
        "Mistral",
        "ChatGPT",
        "Chain-of-Thought (CoT) Prompting",
        "Chain-of-Thought Factored Decomposition Prompting",
        "Tree-of-Thoughts (ToT) Prompting",
        "Graph-of-Thoughts (GoT) Prompting",
        "Skeleton-of-Thought (SoT) Prompting",
        "In-Context Prompting",
        "Multi-Personas Prompting",
        "Conversational Prompting",
        "Socratic Prompting",
        "Show-me versus Tell-me Prompting",
        "Target-your-response (TAR) Prompting",
        "Prompt Macros and End-goal Planning",
        "Contrastive Prompting",
        "Self-reflection Prompting",
        "Meta-Prompting",
        "Anticipatory Prompting",
        "Prompt to Code",
        "Responsive Feedback Prompting",
        "Directional Stimulus Prompting",
        "Ambiguous Prompting",
        "Multimodal Prompting",
        "Cross-disciplinary Prompting",
        "Historical Context, Visual, and Modular Prompting",
        "Flipped Interaction Prompting",
        "Grammar Correction",
        "Constrained Vocabulary Prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DyVal 2 Dynamic Evaluation of Large Language Models by Meta Probing Agents": {
    "filename": "DyVal 2 Dynamic Evaluation of Large Language Models by Meta Probing Agents.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "GSM8K",
        "BBH",
        "ARC-C"
      ],
      "models": [
        "GPT-4-Turbo",
        "GPT-3.5-Turbo",
        "Gemini-Pro",
        "Yi-34b-chat",
        "Mixtral-8x7b-Instruct",
        "Llama2-70b-chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VideoTetris Towards Compositional Text-to-Video Generation": {
    "filename": "VideoTetris Towards Compositional Text-to-Video Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Panda-70M"
      ],
      "models": [
        "VideoTetris",
        "ModelScope",
        "AnimateDiff",
        "VideoCrafter2",
        "FreeNoise",
        "StreamingT2V",
        "Gen-2",
        "Pika",
        "LVD"
      ]
    }
  },
  "A Study of Situational Reasoning for Traffic Understanding": {
    "filename": "A Study of Situational Reasoning for Traffic Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "BDD-QA",
        "TV-QA",
        "HDT-QA"
      ],
      "models": [
        "NLI-RoBERTa-large",
        "KG-RoBERTa-large",
        "KG-T5-large",
        "QA-T5-large",
        "Retrieval-T5-large",
        "RoBERTa-large (supervised)",
        "RoBERTa-large (unsupervised)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SheetAgent Towards A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models": {
    "filename": "SheetAgent Towards A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SheetRM",
        "SheetCopilot Benchmark",
        "WikiTableQuestions",
        "FeTaQA",
        "TabFact"
      ],
      "models": [
        "SheetAgent",
        "SheetCopilot",
        "OS-Copilot",
        "VBA",
        "TAPEX",
        "OmniTab",
        "DATER",
        "StructGPT",
        "UnifiedSKG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Adaptive-Solver Framework for Dynamic Strategy Selection in Large Language Model Reasoning": {
    "filename": "Adaptive-Solver Framework for Dynamic Strategy Selection in Large Language Model Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "AQuA",
        "AddSub",
        "SingleEq",
        "MultiArith",
        "CSQA",
        "Last Letter Concatenation (LLC)"
      ],
      "models": [
        "Adaptive-Solver (AS) framework",
        "GPT-4",
        "GPT-3.5-turbo",
        "CoT",
        "ZeroCoT",
        "L2M",
        "PS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Characterizing Large Language Model Geometry Helps Solve Toxicity Detection and Generation": {
    "filename": "Characterizing Large Language Model Geometry Helps Solve Toxicity Detection and Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Omni-Toxic dataset",
        "Jigsaw dataset",
        "Toxigen dataset",
        "Pile validation dataset",
        "Dolly Q&A datasets"
      ],
      "models": [
        "martin-ha",
        "ToxRoberta",
        "nicholasKluge",
        "unitary",
        "s-nlp",
        "citizenlab",
        "Spline-Llama2-7B (linear)",
        "Spline-Llama2-7B (3 layers, RF)",
        "Spline-Mistral-7B (linear)",
        "Spline-Mistral-7B (3 layers, RF)",
        "Llama2-7B",
        "Llama2-70B",
        "Mistral-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can ChatGPT Replace Traditional KBQA Models An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family": {
    "filename": "Can ChatGPT Replace Traditional KBQA Models An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family.pdf",
    "analysis": {
      "benchmarks": [
        "WebQuestionSP",
        "ComplexWebQuestions",
        "GraphQ",
        "QALD-9",
        "KQApro",
        "GrailQA",
        "MKQA",
        "LC-quad2.0"
      ],
      "models": [
        "ChatGPT",
        "GPT-3",
        "GPT-3.5 v2",
        "GPT-3.5 v3",
        "GPT-4",
        "FLAN-T5",
        "traditional KBQA models"
      ]
    }
  },
  "Supervised Knowledge Makes Large Language Models Better In-context Learners": {
    "filename": "Supervised Knowledge Makes Large Language Models Better In-context Learners.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE-X",
        "SQuAD 2.0",
        "IMDB",
        "Yelp",
        "Amazon",
        "Flipkart",
        "MNLI-mis",
        "SNLI",
        "NewsQA",
        "SciTail",
        "HANS",
        "QQP",
        "Twitter",
        "SICK",
        "Textbook"
      ],
      "models": [
        "Llama 2",
        "ChatGPT",
        "SuperContext",
        "ELECTRA-large",
        "RoBERTa-large",
        "Llama2-7B-chat",
        "ChatGPT (+16-shot)",
        "ChatGPT (+BM25)",
        "SuperContext (w/o confidence)",
        "SuperContext (+interpreter)",
        "SuperContext (zero-shot)",
        "Llama2-chat",
        "Llama2-chat (+16-shot)",
        "Llama2-chat (+BM25)",
        "SuperContext (16-shot)",
        "Fine-tuned multi-turn",
        "Fine-tuned single-turn",
        "Llama2-7B-chat (16-shot)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cognitive Architectures for Language Agents": {
    "filename": "Cognitive Architectures for Language Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "CoALA",
        "SayCan",
        "ReAct",
        "Voyager",
        "Generative Agents",
        "Tree of Thoughts"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Using ChatGPT for Thematic Analysis": {
    "filename": "Using ChatGPT for Thematic Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "UN policy documents 2017-2024"
      ],
      "models": [
        "ChatGPT",
        "custom GPT model",
        "Supported Thematic Analysis. AIxGEO"
      ]
    }
  },
  "GameBench Evaluating Strategic Reasoning Abilities of LLM Agents": {
    "filename": "GameBench Evaluating Strategic Reasoning Abilities of LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Air, Land, Sea (ALS)",
        "Arctic Scavengers (ARC)",
        "Are You the Traitor? (AYT)",
        "Codenames (CN)",
        "Hive (HV)",
        "Pit (PT)",
        "Santorini (SN)",
        "Two Rooms and a Boom (TRB)",
        "Sea Battle (SB)"
      ],
      "models": [
        "GPT-3",
        "GPT-4",
        "GPT-3-CoT",
        "GPT-4-CoT",
        "GPT-4-RAP",
        "random-action-selector baseline",
        "human baseline"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations A Pilot Study": {
    "filename": "User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations A Pilot Study.pdf",
    "analysis": {
      "benchmarks": [
        "Movielens-1M"
      ],
      "models": [
        "Personalized PageRank",
        "RippleNet",
        "Template-based explanation",
        "LLM-based rephrasing",
        "LLM-based graph-to-text",
        "Llama 2 70B Chat",
        "GPT-4",
        "GPT-3.5-turbo"
      ]
    }
  },
  "Advanced System Integration Analyzing OpenAPI Chunking for Retrieval-Augmented Generation": {
    "filename": "Advanced System Integration Analyzing OpenAPI Chunking for Retrieval-Augmented Generation.pdf",
    "analysis": {
      "benchmarks": [
        "RestBench"
      ],
      "models": [
        "OpenAPI RAG",
        "Discovery Agent",
        "text-embedding-3-large",
        "bge-small-en-v1.5",
        "NV-Embed-v1",
        "gpt-4o-2024-05-13"
      ]
    }
  },
  "Doubly Right Object Recognition A Why Prompt for Visual Rationales": {
    "filename": "Doubly Right Object Recognition A Why Prompt for Visual Rationales.pdf",
    "analysis": {
      "benchmarks": [
        "CIFAR-10+",
        "CIFAR-100+",
        "Food101+",
        "Caltech101+",
        "SUN+",
        "ImageNet+",
        "AWA",
        "CUB",
        "BDD-X",
        "VAW",
        "Broaden"
      ],
      "models": [
        "CLIP",
        "FLAVA",
        "CLIP-Res50",
        "CLIP-Res101",
        "CLIP-B/32",
        "CLIP-B/16",
        "CLIP-L/14",
        "CLIP-H/14",
        "why prompt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Depression Diagnosis with Chain-of-Thought Prompting": {
    "filename": "Enhancing Depression Diagnosis with Chain-of-Thought Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "DAIC-WOZ"
      ],
      "models": [
        "OpenAI 3.5 turbo",
        "Assigner A",
        "Assigner B"
      ]
    }
  },
  "RGD Multi-LLM Based Agent Debugger via Refinement and Generation Guidance": {
    "filename": "RGD Multi-LLM Based Agent Debugger via Refinement and Generation Guidance.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "HumanEval-ET",
        "MBPP",
        "MBPP-ET",
        "APPS"
      ],
      "models": [
        "RGD",
        "GPT-4o",
        "GPT-4o-mini",
        "Direct",
        "Chain-of-Thought",
        "Self-Planning",
        "Self-Debugging",
        "LDB"
      ]
    }
  },
  "LLMs for Relational Reasoning How Far are We": {
    "filename": "LLMs for Relational Reasoning How Far are We.pdf",
    "analysis": {
      "benchmarks": [
        "inductive logic programming (ILP)",
        "blocksworld",
        "family tree reasoning",
        "general graph reasoning"
      ],
      "models": [
        "GPT-3.5 Turbo",
        "GPT-4",
        "GPT-4 Turbo",
        "Llama 2 (7B)",
        "Llama 2 (13B)",
        "Differentiable Logic Machines (DLM)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Synthetic Dataset for Personal Attribute Inference": {
    "filename": "A Synthetic Dataset for Personal Attribute Inference.pdf",
    "analysis": {
      "benchmarks": [
        "SynthPAI",
        "PersonalReddit"
      ],
      "models": [
        "GPT-4",
        "Claude-3 Opus",
        "Llama-2-7b",
        "Gemma-7B",
        "Mistral-7B",
        "Llama-2-13b",
        "Mixtral-8x7B",
        "Llama-3-8b",
        "Llama-2-70b",
        "GPT-3.5",
        "Yi-34B",
        "Gemini-Pro",
        "Claude-3-Haiku",
        "Gemini-1.5-Pro",
        "Qwen1.5-110B",
        "Claude-3-Sonnet",
        "Mixtral-8x22B",
        "Llama-3-70b",
        "Human"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Video In-context Learning": {
    "filename": "Video In-context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Something-Something v2",
        "VP2"
      ],
      "models": [
        "Vid-ICL",
        "DeLVM",
        "SVG"
      ]
    }
  },
  "Are Large Language Models Good Statisticians": {
    "filename": "Are Large Language Models Good Statisticians.pdf",
    "analysis": {
      "benchmarks": [
        "StatQA"
      ],
      "models": [
        "GPT-4o",
        "LLaMA-3",
        "GPT-3.5-Turbo",
        "GPT-4",
        "LLaMA-2",
        "Meta-Llama-3-8B",
        "Meta-Llama-3-8B-Instruct",
        "Llama-2-7b-chat-hf",
        "Llama-2-13b-chat-hf",
        "SFT LLaMA-2 7B",
        "SFT LLaMA-3 8B",
        "SFT LLaMA-3 8B Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Internet of Agents Weaving a Web of Heterogeneous Agents for Collaborative Intelligence": {
    "filename": "Internet of Agents Weaving a Web of Heterogeneous Agents for Collaborative Intelligence.pdf",
    "analysis": {
      "benchmarks": [
        "GAIA",
        "open-ended instruction benchmark",
        "RoCoBench",
        "TriviaQA",
        "Natural Questions",
        "HotpotQA",
        "2WikiMultiHopQA"
      ],
      "models": [
        "IoA",
        "AutoGPT",
        "Open Interpreter",
        "ReAct agents",
        "GPT-4",
        "GPT-4-Turbo",
        "AutoGPT-4",
        "GPT-4 + Plugins",
        "FRIDAY",
        "AutoGen",
        "Apollo's Oracle"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VisIT-Bench A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use": {
    "filename": "VisIT-Bench A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use.pdf",
    "analysis": {
      "benchmarks": [
        "VisIT-Bench",
        "VQAv2",
        "COCO",
        "Visual Question Answering (VQA)",
        "robust change captioning",
        "NLVR2",
        "WHOOPS!"
      ],
      "models": [
        "LLaV A-13B",
        "Panda",
        "LLaMA-Adapter-v2",
        "OpenFlamingo",
        "LLaV A",
        "InstructBLIP",
        "MiniGPT4",
        "mPLUG-Owl",
        "LlamaAdapter-v2",
        "PandaGPT",
        "VisualChatGPT",
        "Multimodal GPT",
        "Otter",
        "Lynx",
        "idefics"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DoLa Decoding by Contrasting Layers Improves Factuality in Large Language Models": {
    "filename": "DoLa Decoding by Contrasting Layers Improves Factuality in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA",
        "FACTOR",
        "StrategyQA",
        "GSM8K",
        "Vicuna QA"
      ],
      "models": [
        "DoLa",
        "LLaMA-7B",
        "LLaMA-13B",
        "LLaMA-33B",
        "LLaMA-65B",
        "Contrastive Decoding (CD)",
        "Inference Time Intervention (ITI)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Corex Pushing the Boundaries of Complex Reasoning through Multi-Model Collaboration": {
    "filename": "Corex Pushing the Boundaries of Complex Reasoning through Multi-Model Collaboration.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "GSM-Hard",
        "StrategyQA",
        "CSQA",
        "OpenBookQA",
        "BoolQ",
        "ARC-c",
        "BigBench",
        "FinQA",
        "ConvFinQA"
      ],
      "models": [
        "Corex",
        "Chain-of-Thought prompting (CoT)",
        "Self-Consistency (CoT-SC)",
        "Complexity-based consistency (ComplexCoT)",
        "Program-aided language model (PAL/PoT)",
        "Multi-Agent Debate (MAD)",
        "Exchange of Thought (EoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Assessing LLMs in Malicious Code Deobfuscation of Real-world Malware Campaigns": {
    "filename": "Assessing LLMs in Malicious Code Deobfuscation of Real-world Malware Campaigns.pdf",
    "analysis": {
      "benchmarks": [
        "Emotet malware campaign"
      ],
      "models": [
        "GPT-4",
        "Gemini Pro",
        "Code Llama Instruct",
        "Mixtral 8x7B Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning": {
    "filename": "Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "BoardgameQA",
        "SNLI",
        "MNLI",
        "race@Middle",
        "race@High"
      ],
      "models": [
        "R3",
        "Llama2-7B",
        "Codellama-7B",
        "Glactica",
        "MAmmoTH-Coder",
        "Tora",
        "Tora-coder",
        "GPT-3.5-Turbo",
        "GPT-4",
        "Supervised Fine-Tuning (SFT)",
        "Reinforcement Learning (RL)",
        "Staged RL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Wisdom of Partisan Crowds Comparing Collective Intelligence in Humans and LLM-based Agents": {
    "filename": "The Wisdom of Partisan Crowds Comparing Collective Intelligence in Humans and LLM-based Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "Vicuna-33B",
        "LLM agents with detailed personas",
        "LLM agents with simple personas",
        "LLM agents with CoT reasoning",
        "LLM agents without CoT reasoning",
        "Fine-tuned LLM agents"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Disentangling Memory and Reasoning Ability in Large Language Models": {
    "filename": "Disentangling Memory and Reasoning Ability in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA",
        "CommonsenseQA",
        "TruthfulQA"
      ],
      "models": [
        "LLaMA-2-7B-chat-hf",
        "LLaMA-3.1-8B-Instruct",
        "Qwen2.5-7B-Instruct",
        "GPT-4o",
        "GPT-4o-mini",
        "LLaMA-2-13B",
        "LLaMA 3.1-70B",
        "Qwen 2.5-7B",
        "LLaMA-2-7B",
        "LLaMA-3.1-8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning from Feedback Semantic Enhancement for Object SLAM Using Foundation Models": {
    "filename": "Learning from Feedback Semantic Enhancement for Object SLAM Using Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "SEO-SLAM dataset",
        "Small 1",
        "Small 2",
        "Medium 1",
        "Medium 2",
        "Large 1",
        "Large 2"
      ],
      "models": [
        "SEO-SLAM",
        "RGS (RAM-Grounded-SAM)",
        "YOLO",
        "GroundingDINO",
        "SAM (Segment-Anything Model)",
        "RAM (Recognize-Anything Model)"
      ]
    }
  },
  "When to Make Exceptions Exploring Language Models as Accounts of Human Moral Judgment": {
    "filename": "When to Make Exceptions Exploring Language Models as Accounts of Human Moral Judgment.pdf",
    "analysis": {
      "benchmarks": [
        "MoralExceptQA"
      ],
      "models": [
        "MORAL COT",
        "InstructGPT",
        "GPT-3",
        "Delphi",
        "Delphi++",
        "BERT-base",
        "BERT-large",
        "RoBERTa-large",
        "ALBERT-xxlarge"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompting Strategies for Enabling Large Language Models to Infer Causation from Correlation": {
    "filename": "Prompting Strategies for Enabling Large Language Models to Infer Causation from Correlation.pdf",
    "analysis": {
      "benchmarks": [
        "CORR2CAUSE",
        "CLADDER"
      ],
      "models": [
        "PC-SUBQ",
        "Gemini Pro 1.0",
        "Gemini Ultra 1.0",
        "PaLM 2 L",
        "GPT-3.5-turbo",
        "GPT-4-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Domain Adaptation of Visual Policies with a Single Demonstration": {
    "filename": "Domain Adaptation of Visual Policies with a Single Demonstration.pdf",
    "analysis": {
      "benchmarks": [
        "Distracting Control Suite",
        "DeepMind Control Suite",
        "UR5 robot tasks"
      ],
      "models": [
        "PromptAdapt",
        "RL with domain randomization (DR)",
        "policy distillation with domain randomization",
        "policy distillation with model-agnostic meta-learning (MAML)",
        "Soft Actor-Critic (SAC)"
      ]
    }
  },
  "AFSPP Agent Framework for Shaping Preference and Personality with Large Language Models": {
    "filename": "AFSPP Agent Framework for Shaping Preference and Personality with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Myers-Briggs Type Indicator (MBTI)",
        "Short Dark Triad (SD3)"
      ],
      "models": [
        "AFSPP",
        "GPT-4",
        "LLM-based Agents"
      ]
    }
  },
  "UltraFeedback Boosting Language Models with High-quality Feedback": {
    "filename": "UltraFeedback Boosting Language Models with High-quality Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "AlpacaEval",
        "Evol-Instruct",
        "UltraChat",
        "OpenAI WebGPT",
        "OpenAI Summarization",
        "Anthropic HH-RLHF",
        "Stanford SHP",
        "BoolQ",
        "HellaSwag",
        "RACE-h",
        "RACE-m",
        "MultiRC",
        "TriviaQA",
        "NQ",
        "PIQA",
        "OBQA",
        "ARC-E",
        "ARC-C"
      ],
      "models": [
        "UltraLM-13B",
        "UltraLM-13B-PPO",
        "UltraRM",
        "UltraCM",
        "LLaMA2-13B",
        "LLaMA2-70B-Chat",
        "Vicuna-13B-v1.3",
        "Vicuna-33B-v1.3",
        "WizardLM-13B-v1.1",
        "WizardLM-13B-v1.2",
        "OpenChat-13B-v3.2super",
        "MPT-30B-Chat",
        "Falcon-40B-Instruct",
        "StarChat",
        "Pythia-12B",
        "GPT-4",
        "gpt-3.5-turbo",
        "Bard",
        "ChatGPT",
        "LLaMA2-13B-Chat",
        "LLaMA2-7B",
        "LLaMA2-70B",
        "Alpaca-7B",
        "UltraLM-65B",
        "WizardLM-7B-v1.1",
        "WizardLM-70B-v1.1",
        "Vicuna-33B-v1.3",
        "LLaMA2-7B-Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Determinants of LLM-assisted Decision-Making": {
    "filename": "Determinants of LLM-assisted Decision-Making.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Traffic Scene Generation from Natural Language Description for Autonomous Vehicles with Large Language Model": {
    "filename": "Traffic Scene Generation from Natural Language Description for Autonomous Vehicles with Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "nuScenes",
        "Waymo",
        "SafeBench"
      ],
      "models": [
        "ChatScene",
        "TTSG (proposed model)",
        "Learning-to-Collide (LC)",
        "AdvSim (AS)",
        "Adversarial Trajectory Optimization (AT)",
        "GPT-4o"
      ]
    }
  },
  "DetGPT Detect What You Need via Reasoning": {
    "filename": "DetGPT Detect What You Need via Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "COCO"
      ],
      "models": [
        "DetGPT",
        "Faster-RCNN",
        "Retina-Net",
        "YOLO",
        "Grounding-DINO",
        "BLIP-2",
        "Vicuna",
        "MiniGPT-4"
      ]
    }
  },
  "RAH RecSysAssistantHuman A Human-Centered Recommendation Framework With LLM Agents": {
    "filename": "RAH RecSysAssistantHuman A Human-Centered Recommendation Framework With LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Cross1k",
        "Cross221k"
      ],
      "models": [
        "RAH framework",
        "LightGCN",
        "PLMRec",
        "FM",
        "MF",
        "ENMF",
        "NeuralMF",
        "ItemKNN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Trade-off Between Efficiency and Consistency for Removal-based Explanations": {
    "filename": "Trade-off Between Efficiency and Consistency for Removal-based Explanations.pdf",
    "analysis": {
      "benchmarks": [
        "IMDb",
        "ImageNet",
        "SST-2"
      ],
      "models": [
        "Harmonica",
        "Harmonica-local",
        "Harmonica-anchor",
        "Harmonica-anchor-constrained",
        "LIME",
        "SHAP",
        "Integrated Gradients",
        "Integrated Hessians",
        "Shapley Taylor",
        "Faith-SHAP",
        "Shapley Interaction Index",
        "Low-degree"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Active Retrieval Augmented Generation": {
    "filename": "Active Retrieval Augmented Generation.pdf",
    "analysis": {
      "benchmarks": [
        "2WikiMultihopQA",
        "StrategyQA",
        "ASQA",
        "WikiAsp"
      ],
      "models": [
        "FLARE",
        "text-davinci-003",
        "GPT-3.5",
        "Single-time retrieval",
        "Previous-window",
        "Previous-sentence",
        "Question decomposition",
        "FLARE instruct",
        "FLARE direct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "REV Information-Theoretic Evaluation of Free-Text Rationales": {
    "filename": "REV Information-Theoretic Evaluation of Free-Text Rationales.pdf",
    "analysis": {
      "benchmarks": [
        "ECQA",
        "CoS-E",
        "QuaRTz",
        "e-SNLI"
      ],
      "models": [
        "REV",
        "T5 Large",
        "T5-3B",
        "BART Large",
        "GPT-2 Large",
        "GPT-3",
        "LaMDA",
        "XY*\u2192R",
        "X\u2192YR",
        "X\u2192RY",
        "Y*;R*",
        "Y*;B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TextGenSHAP Scalable Post-hoc Explanations in Text Generation with Long Documents": {
    "filename": "TextGenSHAP Scalable Post-hoc Explanations in Text Generation with Long Documents.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Questions (NQ)",
        "MIRACL (English subset)"
      ],
      "models": [
        "TextGenSHAP",
        "BERT",
        "Contriever",
        "T5-large",
        "T5-XXL",
        "T5-FiD",
        "Fusion-in-Decoder (FiD)",
        "Lost in the Middle (LitM)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GLOV Guided Large Language Models as Implicit Optimizers for Vision Language Models": {
    "filename": "GLOV Guided Large Language Models as Implicit Optimizers for Vision Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "ImageNetV2",
        "Caltech101",
        "ImageNetR",
        "ImageNetS",
        "ImageNetA",
        "OxfordFlowers",
        "OxfordPets",
        "StanfordCars",
        "DescribableTextures",
        "Food101",
        "FGVCAircraft",
        "SUN397",
        "UCF101",
        "RESISC45",
        "EuroSAT"
      ],
      "models": [
        "GLOV",
        "CLIP",
        "LLaVa",
        "LLaVa-OV",
        "LLM-OPT",
        "Meta-Prompt",
        "CoOp"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards a Robust Retrieval-Based Summarization System": {
    "filename": "Towards a Robust Retrieval-Based Summarization System.pdf",
    "analysis": {
      "benchmarks": [
        "LogicSumm"
      ],
      "models": [
        "SummRAG",
        "Mistral-7B Instruct",
        "GPT-3.5",
        "Claude 2",
        "Jurassic",
        "LLaMa2-13B",
        "GPT-4 Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ActiveLLM Large Language Model-based Active Learning for Textual Few-Shot Scenarios": {
    "filename": "ActiveLLM Large Language Model-based Active Learning for Textual Few-Shot Scenarios.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "AGNews",
        "SST-2",
        "Specialized CTI few-shot dataset"
      ],
      "models": [
        "ActiveLLM",
        "BERT",
        "GPT-4",
        "Llama 3",
        "Mistral Large",
        "SetFit",
        "ActiveGPT4",
        "ActiveGPT4o",
        "ActiveMistralLarge",
        "GPT-3.5",
        "Gemini-Ultra",
        "Mixtral 8x7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Why is this misleading Detecting News Headline Hallucinations with Explanations": {
    "filename": "Why is this misleading Detecting News Headline Hallucinations with Explanations.pdf",
    "analysis": {
      "benchmarks": [
        "MNBM",
        "FRANK",
        "QAGS",
        "SummEval",
        "FEVER",
        "Vitamin-C"
      ],
      "models": [
        "ExHalder",
        "SVM",
        "XGBoost",
        "BERT_base",
        "T5_xxl",
        "T5_xxl+Exp",
        "ExHalder-NoPT",
        "ExHalder-NoEX",
        "ExHalder-NoHC",
        "ANLI",
        "Q2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Hallucinations in Chinese Large Language Models": {
    "filename": "Evaluating Hallucinations in Chinese Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HalluQA",
        "TruthfulQA",
        "ChineseFactEval",
        "HaluEval"
      ],
      "models": [
        "GLM-130B",
        "ChatGPT",
        "GPT-4",
        "ERNIE-Bot",
        "Baichuan2",
        "ChatGLM",
        "Qwen",
        "SparkDesk",
        "Llama2",
        "Baichuan-7B-base",
        "Baichuan-13B-base",
        "Baichuan2-7B-base",
        "Baichuan2-13B-base",
        "Qwen-7B",
        "Qwen-14B",
        "Xverse-7B",
        "Xverse-14B",
        "Baichuan-13B-chat",
        "Baichuan2-7B-chat",
        "Baichuan2-13B-chat",
        "ChatGLM-6B",
        "ChatGLM2-6B",
        "Qwen-7B-chat",
        "Qwen-14B-chat",
        "Xverse-7B-chat",
        "Xverse-13B-chat",
        "abab5.5-chat",
        "gpt-4-0613",
        "gpt-3.5-turbo-0613",
        "Ernie-Bot",
        "Baichuan2-53B",
        "ChatGLM-pro",
        "SparkDesk"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Interpreting and Improving Large Language Models in Arithmetic Calculation": {
    "filename": "Interpreting and Improving Large Language Models in Arithmetic Calculation.pdf",
    "analysis": {
      "benchmarks": [
        "SVAMP",
        "GSM8K",
        "AddSub",
        "SingleEq",
        "MMLU",
        "CSQA"
      ],
      "models": [
        "LLaMA2-7B",
        "LLaMA2-13B",
        "Mistral-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Preble Efficient Distributed Prompt Scheduling for LLM Serving": {
    "filename": "Preble Efficient Distributed Prompt Scheduling for LLM Serving.pdf",
    "analysis": {
      "benchmarks": [
        "LLM with tool calling",
        "LLM as embodied agents in virtual environments",
        "LLM for code generation",
        "embedded video QA",
        "long document QA",
        "Azure LLM usage trace"
      ],
      "models": [
        "Preble",
        "SGLang",
        "vLLM",
        "Mistral 7B model",
        "Llama-3 70B model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PromptExp Multi-granularity Prompt Explanation of Large Language Models": {
    "filename": "PromptExp Multi-granularity Prompt Explanation of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Stanford-Sentiment-Treebank (SST)",
        "BigBench"
      ],
      "models": [
        "PromptExp",
        "GPT-3.5",
        "Llama-2",
        "Agg Equ",
        "Agg Conf",
        "Perb Log",
        "Perb Sim",
        "Perb Dis"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Efficient Causal Graph Discovery Using Large Language Models": {
    "filename": "Efficient Causal Graph Discovery Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Asia",
        "Child",
        "Neuropathic Pain"
      ],
      "models": [
        "Proposed Method",
        "Pairwise Method",
        "Greedy Equivalence Search (GES)",
        "Peter-Clark Algorithm (PC)",
        "Non-combinatorial Optimization via Trace Exponential and Augmented Lagrangian for Structure Learning (NOTEARS)",
        "Directed Acyclic Graphs via M-matrices for Acyclicity (DAGMA)"
      ]
    }
  },
  "Tabular Representation Noisy Operators and Impacts on Table Structure Understanding Tasks in LLMs": {
    "filename": "Tabular Representation Noisy Operators and Impacts on Table Structure Understanding Tasks in LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "AirQuality",
        "HousingData",
        "Diabetes",
        "Wine Testing",
        "Iris",
        "Titanic"
      ],
      "models": [
        "GPT3",
        "TUTA",
        "TAPAS",
        "TableLLM"
      ]
    }
  },
  "NEOLAF an LLM-powered neural-symbolic cognitive architecture": {
    "filename": "NEOLAF an LLM-powered neural-symbolic cognitive architecture.pdf",
    "analysis": {
      "benchmarks": [
        "MATH dataset",
        "AIME Math Competitions",
        "USAMO Math Competitions"
      ],
      "models": [
        "NEOLAF Agent",
        "ChatGPT 3.5",
        "ChatGPT 4.0",
        "Chain of Thought model with WolframAlpha and other plugins"
      ]
    }
  },
  "A Survey on Multimodal Large Language Models for Autonomous Driving": {
    "filename": "A Survey on Multimodal Large Language Models for Autonomous Driving.pdf",
    "analysis": {
      "benchmarks": [
        "KITTI",
        "nuScenes",
        "Waymo Open",
        "Argo1",
        "Argo2",
        "V2V4Real",
        "Talk2Car",
        "nuScenes-QA",
        "DriveLM",
        "NuPrompt",
        "BDD-X",
        "DRAMA",
        "MAPLM"
      ],
      "models": [
        "GPT-4V",
        "GPT-3.5",
        "GPT-4",
        "LLaMA",
        "Llama 2",
        "Flan5XXL",
        "Vicuna-13b",
        "DriveGPT4",
        "HiLM-D",
        "Talk2BEV",
        "GAIA-1",
        "UniSim",
        "SurrealDriver",
        "GPT-Driver",
        "LanguageMPC",
        "Dilu",
        "DaYS",
        "RRR",
        "DlaH",
        "Socratic Models",
        "SayCan",
        "LINGO-1",
        "MotionLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ZeroNLG Aligning and Autoencoding Domains for Zero-Shot Multimodal and Multilingual Natural Language Generation": {
    "filename": "ZeroNLG Aligning and Autoencoding Domains for Zero-Shot Multimodal and Multilingual Natural Language Generation.pdf",
    "analysis": {
      "benchmarks": [
        "VATEX-Zh",
        "Flickr30k-Zh",
        "Flickr30k-De",
        "Flickr30k-Fr",
        "MSR-VTT",
        "MS-COCO",
        "WMT16",
        "WMT17",
        "English-Chinese dataset"
      ],
      "models": [
        "ZeroNLG",
        "CoCa",
        "CLIP-Re",
        "CapDec",
        "ClipCap",
        "mBART-50",
        "M2M-100",
        "NLLB-200"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cocobo Exploring Large Language Models as the Engine for End-User Robot Programming": {
    "filename": "Cocobo Exploring Large Language Models as the Engine for End-User Robot Programming.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Cocobo",
        "GPT-3.5",
        "GPT-4",
        "Llama"
      ]
    }
  },
  "EDDA A Encoder-Decoder Data Augmentation Framework for Zero-Shot Stance Detection": {
    "filename": "EDDA A Encoder-Decoder Data Augmentation Framework for Zero-Shot Stance Detection.pdf",
    "analysis": {
      "benchmarks": [
        "SEM16",
        "VAST"
      ],
      "models": [
        "EDDA",
        "BiLSTM",
        "Bicond",
        "CrossNet",
        "SEKT",
        "TPDG",
        "TOAD",
        "Bert-Joint",
        "Bert-GCN",
        "JointCL",
        "TarBK",
        "PT-HCL",
        "SDAgu",
        "OpenStance",
        "TTS",
        "TDDA-GPT",
        "TDDA-LLaMA",
        "EDDA-GPT",
        "EDDA-LLaMA",
        "GPT",
        "GPT-EDDA",
        "LLaMA",
        "LLaMA-EDDA",
        "BertTGA Net",
        "MPT",
        "KEPrompt"
      ]
    }
  },
  "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models": {
    "filename": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "WebShop",
        "HotPotQA",
        "MBPP",
        "Game of 24"
      ],
      "models": [
        "LATS",
        "GPT-3.5",
        "GPT-4",
        "CoT",
        "ReAct",
        "Reflexion",
        "ToT",
        "RAP",
        "IL",
        "IL+RL",
        "Fine-tuning"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition": {
    "filename": "Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition.pdf",
    "analysis": {
      "benchmarks": [
        "CRAFT"
      ],
      "models": [
        "GPT-3.5",
        "GPTNER-RR",
        "ReType-GPT",
        "ReType-KG+VOTE",
        "ReType-KG+GPT",
        "UniversalNER-7B",
        "DMNER",
        "HUNER"
      ]
    }
  },
  "ARB Advanced Reasoning Benchmark for Large Language Models": {
    "filename": "ARB Advanced Reasoning Benchmark for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ARB",
        "GLUE",
        "SuperGLUE",
        "BIG-bench",
        "HELM",
        "MATH",
        "GSM8K",
        "MMLU",
        "SVAMP",
        "ASDiv",
        "AQuA",
        "MAWPS",
        "MultiArith",
        "CSQA",
        "StrategyQA",
        "HotpotQA",
        "GPT-Planning Benchmark",
        "ALERT Reasoning Benchmark",
        "JEEBench",
        "Chain-of-Thought Hub"
      ],
      "models": [
        "GPT-4",
        "Claude",
        "GPT-3",
        "PaLM",
        "Chinchilla",
        "BERT",
        "GPT-2",
        "ChatGPT",
        "Minerva",
        "gpt3.5-turbo-0301",
        "text-davinci-003",
        "gpt-4-0314",
        "claude-v1.3-100k"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GIFT A Framework for Global Interpretable Faithful Textual Explanations of Vision Classifiers": {
    "filename": "GIFT A Framework for Global Interpretable Faithful Textual Explanations of Vision Classifiers.pdf",
    "analysis": {
      "benchmarks": [
        "CLEVR",
        "CelebA",
        "BDD-OIA"
      ],
      "models": [
        "GIFT",
        "ViT-Small-Patch16-224",
        "ResNet-34",
        "DenseNet121"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Richelieu Self-Evolving LLM-Based Agents for AI Diplomacy": {
    "filename": "Richelieu Self-Evolving LLM-Based Agents for AI Diplomacy.pdf",
    "analysis": {
      "benchmarks": [
        "Diplomacy game platform"
      ],
      "models": [
        "Richelieu",
        "Cicero",
        "SL-DipNet",
        "RL-DipNet",
        "BRPI",
        "SearchBot",
        "DORA",
        "AutoGPT",
        "GPT4.0",
        "ERNIE Bot",
        "Spark Desk",
        "Llama 3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Fast and Accurate Task Planning using Neuro-Symbolic Language Models and Multi-level Goal Decomposition": {
    "filename": "Fast and Accurate Task Planning using Neuro-Symbolic Language Models and Multi-level Goal Decomposition.pdf",
    "analysis": {
      "benchmarks": [
        "Barman-new",
        "Blocksworld-new",
        "Gripper-new"
      ],
      "models": [
        "CoT planner",
        "FD planner",
        "Symbolic LLM planner",
        "MCTS LLM planner",
        "MCTS LLM planner without Goal Decomposition"
      ]
    }
  },
  "Sequential Monte Carlo Steering of Large Language Models using Probabilistic Programs": {
    "filename": "Sequential Monte Carlo Steering of Large Language Models using Probabilistic Programs.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Feynman-Kac Transformer models",
        "SMC Transformer steering",
        "LLaMA Transformers",
        "LLaMPPL",
        "LLaMA-7b model"
      ]
    }
  },
  "SAGraph A Large-scale Text-Rich Social Graph Dataset for Advertising Campaigns": {
    "filename": "SAGraph A Large-scale Text-Rich Social Graph Dataset for Advertising Campaigns.pdf",
    "analysis": {
      "benchmarks": [
        "SAGraph",
        "Twitter",
        "Blog",
        "Wiki Vote",
        "Google+",
        "Email",
        "Facebook",
        "Reddit"
      ],
      "models": [
        "CELF",
        "CELF++",
        "SIGMA",
        "PI",
        "RIS",
        "GPT-4",
        "GPT-4 w/ profile",
        "GPT-4 w/ profile&CoT",
        "Kimi"
      ]
    }
  },
  "A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges": {
    "filename": "A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "US Medical Licensing Exam-style questions",
        "ClinicalTrials.gov"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "LLaMA",
        "MEDITRON",
        "PANACEA",
        "MedPaLM",
        "LLaMA-Clinic",
        "TrialGPT",
        "GeneGPT",
        "Polaris",
        "WikiChat",
        "FrugalGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BeHonest Benchmarking Honesty in Large Language Models": {
    "filename": "BeHonest Benchmarking Honesty in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BEHONEST",
        "SelfAware",
        "UnknownBench",
        "TrustLLM",
        "Sycophancy-Intervention",
        "TruthfulQA",
        "Burglar Deception Dataset",
        "Werewolf Dataset",
        "Natural Instructions",
        "Big-Bench Hard",
        "CommonSenseQA"
      ],
      "models": [
        "GPT-4o",
        "ChatGPT",
        "Llama3-70b",
        "Llama3-8b",
        "Llama2-70b",
        "Llama2-13b",
        "Llama2-7b",
        "Mistral-7b",
        "Qwen1.5-14b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Adaptive In-conversation Team Building for Language Model Agents": {
    "filename": "Adaptive In-conversation Team Building for Language Model Agents.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "HumanEval",
        "DABench",
        "GAIA",
        "SciBench"
      ],
      "models": [
        "Captain Agent",
        "Vanilla LLM",
        "Meta-prompting",
        "AutoAgents",
        "DyLAN",
        "AgentVerse",
        "AutoGen: Assistant + Executor",
        "AutoGen: GAIA_Orchestrator",
        "FRIDAY",
        "Warm-up Act",
        "HuggingFace Agent"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MATHSENSEI A Tool-Augmented Large Language Model for Mathematical Reasoning": {
    "filename": "MATHSENSEI A Tool-Augmented Large Language Model for Mathematical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM-8K",
        "AQUA-RAT",
        "MMLU-Math"
      ],
      "models": [
        "MATHSENSEI",
        "gpt-3.5-turbo",
        "GPT-4",
        "Llama 2",
        "Chameleon",
        "OlaGPT",
        "ART",
        "SocraticAI",
        "CoT-LTP",
        "ComplexCoT",
        "ComplexCoT+PHP",
        "SKiC",
        "CoT",
        "PHP",
        "text-davinci-002",
        "text-davinci-003",
        "Llama2-7B",
        "Phind-Code-Llama-34B-V2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SayTap Language to Quadrupedal Locomotion": {
    "filename": "SayTap Language to Quadrupedal Locomotion.pdf",
    "analysis": {
      "benchmarks": [
        "Unitree A1"
      ],
      "models": [
        "SayTap",
        "Baseline 1",
        "Baseline 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tree of Thoughts Deliberate Problem Solving with Large Language Models": {
    "filename": "Tree of Thoughts Deliberate Problem Solving with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Game of 24",
        "Creative Writing",
        "Mini Crosswords"
      ],
      "models": [
        "Tree of Thoughts (ToT)",
        "GPT-4",
        "Chain-of-Thought (CoT) prompting",
        "CoT self-consistency (CoT-SC)",
        "IO prompt",
        "IO + Refine"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Incentive Compatibility for AI Alignment in Sociotechnical Systems Positions and Prospects": {
    "filename": "Incentive Compatibility for AI Alignment in Sociotechnical Systems Positions and Prospects.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "RLHF",
        "DPO",
        "RLAIF",
        "RLHAIF",
        "IDA",
        "RRM",
        "Debate",
        "CIRL",
        "Weak-To-Strong",
        "REx",
        "CBFT",
        "ETHICS",
        "SOCIAL-CHEM-101",
        "MIC",
        "TRUSTLLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The CLRS-Text Algorithmic Reasoning Language Benchmark": {
    "filename": "The CLRS-Text Algorithmic Reasoning Language Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "CLRS-Text",
        "CLRS"
      ],
      "models": [
        "Gemma 2B",
        "Gemma 2B with randomised positional embeddings (RPE)",
        "Gemini 1.5 Flash",
        "Gemini 1.5 Pro"
      ]
    }
  },
  "Tuning Language Models by Mixture-of-Depths Ensemble": {
    "filename": "Tuning Language Models by Mixture-of-Depths Ensemble.pdf",
    "analysis": {
      "benchmarks": [
        "ARC",
        "AQuA",
        "GSM8K",
        "AddSub",
        "MAWPS",
        "MultiArith",
        "SingleEq",
        "SVAMP",
        "BoolQ",
        "OBQA",
        "HELLASWAG",
        "MMLU",
        "TruthfulQA"
      ],
      "models": [
        "LLaMA-7B",
        "LLaMA2-7B",
        "LoRA",
        "LoRA all",
        "LoRA \u00acK",
        "MoD",
        "MoD sparse"
      ]
    }
  },
  "VoxelPrompt A Vision-Language Agent for Grounded Medical Image Analysis": {
    "filename": "VoxelPrompt A Vision-Language Agent for Grounded Medical Image Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "BraTS",
        "ISLES",
        "ATLAS",
        "WMH",
        "FSM",
        "OASIS",
        "Mind Brain Body",
        "IBC",
        "CERMEP",
        "Forrest Gump",
        "SynthSeg",
        "Radiopaedia"
      ],
      "models": [
        "VoxelPrompt",
        "SynthSeg",
        "RadFM",
        "UNet-like benchmark",
        "single-task classifiers"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models in Medicine The Potentials and Pitfalls": {
    "filename": "Large Language Models in Medicine The Potentials and Pitfalls.pdf",
    "analysis": {
      "benchmarks": [
        "MedMCQA",
        "PubMedQA",
        "MultiMedBench"
      ],
      "models": [
        "ChatGPT",
        "GPT-3.5",
        "GPT-4",
        "BioGPT",
        "BioMedLM 2.7B",
        "PubMedGPT",
        "BERT",
        "BioBERT",
        "PubMedBERT",
        "ClinicalBERT",
        "BioLinkBERT",
        "PaLM",
        "Flan-PaLM",
        "Med-PaLM",
        "GatorTron",
        "Claude",
        "PMC-LLaMA",
        "DRAGON",
        "Megatron",
        "Vicuna",
        "LLaVa-Med",
        "SkinGPT4",
        "MiniGPT4"
      ]
    }
  },
  "Weakly Supervised Data Augmentation Through Prompting for Dialogue Understanding": {
    "filename": "Weakly Supervised Data Augmentation Through Prompting for Dialogue Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "DAILY DIALOG",
        "FACEBOOK MULTILINGUAL TASK-ORIENTED DIALOGUE",
        "FBTOD"
      ],
      "models": [
        "WEAKDAP",
        "GPT-J 6B",
        "Alexa Teacher Model (ATM) 20B",
        "Speaker Turn Model (STM)",
        "RoBERTa",
        "XLMRoBERTa",
        "S+PAGE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do Androids Laugh at Electric Sheep Humor Understanding Benchmarks from The New Yorker Caption Contest": {
    "filename": "Do Androids Laugh at Electric Sheep Humor Understanding Benchmarks from The New Yorker Caption Contest.pdf",
    "analysis": {
      "benchmarks": [
        "New Yorker Cartoon Caption Contest"
      ],
      "models": [
        "CLIP ViT-L/14",
        "OFA + T5-11B",
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "T5-Large",
        "T5-11B",
        "fine-tuned CLIP ViT-L/14",
        "OFA-Huge",
        "fine-tuned GPT-3",
        "Caption Only (T5-11B)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Application of Large Language Models in Automated Question Generation A Case Study on ChatGLMs Structured Questions for National Teacher Certification Exams": {
    "filename": "Application of Large Language Models in Automated Question Generation A Case Study on ChatGLMs Structured Questions for National Teacher Certification Exams.pdf",
    "analysis": {
      "benchmarks": [
        "National Teacher Certification Exams (NTCE)"
      ],
      "models": [
        "ChatGLM"
      ]
    }
  },
  "CoT-BERT Enhancing Unsupervised Sentence Representation through Chain-of-Thought": {
    "filename": "CoT-BERT Enhancing Unsupervised Sentence Representation through Chain-of-Thought.pdf",
    "analysis": {
      "benchmarks": [
        "STS12",
        "STS13",
        "STS14",
        "STS15",
        "STS16",
        "STS-B",
        "SICK-R"
      ],
      "models": [
        "CoT-BERT",
        "BERT",
        "RoBERTa",
        "PromptBERT",
        "ConPVP",
        "RankCSE",
        "SimCSE",
        "DiffCSE",
        "RankEncoder",
        "GloVe",
        "USE",
        "BERT-flow",
        "BERT-whitening",
        "IS-BERT",
        "ConSERT",
        "DCLR",
        "ArcCSE",
        "ESimCSE",
        "PCL",
        "PromCSE",
        "PromptRoBERTa"
      ]
    }
  },
  "DKPROMPT Domain Knowledge Prompting Vision-Language Models for Open-World Planning": {
    "filename": "DKPROMPT Domain Knowledge Prompting Vision-Language Models for Open-World Planning.pdf",
    "analysis": {
      "benchmarks": [
        "OmniGibson",
        "Behavior 1K"
      ],
      "models": [
        "DKP ROMPT",
        "VLM-planner",
        "Classical-planner",
        "Suc.-QA",
        "Aff.-QA",
        "Suc.Aff.-QA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LMEye An Interactive Perception Network for Large Language Models": {
    "filename": "LMEye An Interactive Perception Network for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMBench",
        "SEED-Bench",
        "VCR",
        "VQAv2",
        "OK-VQA"
      ],
      "models": [
        "LMEye",
        "Flamingo",
        "Kosmos-1",
        "GPT-4",
        "BLIP-2",
        "FROMAGe",
        "OFA",
        "MiniGPT-4",
        "LLaVA",
        "InstructBLIP",
        "OpenFlamingo",
        "OpenFlamingo v2",
        "MMGPT",
        "PandaGPT",
        "VisualGLM",
        "LLaMA-Adapter-v2",
        "G2PT",
        "mPLUG-Owl",
        "Otter-I",
        "Shikra",
        "LMEye (OPT-iml-1.3b)",
        "LMEye (Bloomz-7b1)",
        "LMEye (BLIP-2, FlanT5 XL)",
        "LMEye (LLaMA-7b)",
        "LMEye (LLaMA-13b)"
      ]
    }
  },
  "LASER LLM Agent with State-Space Exploration for Web Navigation": {
    "filename": "LASER LLM Agent with State-Space Exploration for Web Navigation.pdf",
    "analysis": {
      "benchmarks": [
        "WebShop",
        "amazon.com"
      ],
      "models": [
        "LASER",
        "ASH",
        "ReAct",
        "WebGUM",
        "FlanT5-XL",
        "GPT-4-0613",
        "text-davinci-003"
      ]
    }
  },
  "When Large Language Models Meet Optical Networks Paving the Way for Automation": {
    "filename": "When Large Language Models Meet Optical Networks Paving the Way for Automation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-series models",
        "GPT-4",
        "BERT",
        "Alarm priority processing algorithm",
        "QoT-E models",
        "RWSA algorithms",
        "GN model"
      ]
    }
  },
  "Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models": {
    "filename": "Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Bloom"
      ],
      "models": [
        "GPT-4",
        "VoE version",
        "Non-VoE version"
      ]
    }
  },
  "Beyond Graphs Can Large Language Models Comprehend Hypergraphs": {
    "filename": "Beyond Graphs Can Large Language Models Comprehend Hypergraphs.pdf",
    "analysis": {
      "benchmarks": [
        "NLGraph",
        "GraphQA",
        "LLM4DyG",
        "LLM4Hypergraph"
      ],
      "models": [
        "GPT-4o",
        "ERNIE-Lite-8K",
        "ERNIE-Speed-128K",
        "Qwen-Long",
        "LLaMA3-8B",
        "GPT-3.5-Turbo",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Conditionally Combining Robot Skills using Large Language Models": {
    "filename": "Conditionally Combining Robot Skills using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Meta-World",
        "Language-World",
        "MT10-language",
        "MT50-language"
      ],
      "models": [
        "Plan Conditioned Behavioral Cloning (PCBC)",
        "Descriptor Conditioning (DC)",
        "GPT-3",
        "GPT-3.5",
        "PaLM 2"
      ]
    }
  },
  "C-Eval A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models": {
    "filename": "C-Eval A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "C-E VAL",
        "C-E VAL HARD",
        "MMLU",
        "BIG-bench",
        "HELM",
        "CLUE",
        "AGIEval",
        "MMCU"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "Claude-v1.3",
        "Claude-instant-v1.0",
        "Bloomz-mt",
        "LLaMA-65B",
        "GLM-130B",
        "ChatGLM-6B",
        "Chinese-LLaMA-13B",
        "Chinese-Alpaca-13B",
        "MOSS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OmniDrive A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception Reasoning and Planning": {
    "filename": "OmniDrive A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception Reasoning and Planning.pdf",
    "analysis": {
      "benchmarks": [
        "OmniDrive-nuScenes",
        "nuScenes",
        "NuScenes-QA"
      ],
      "models": [
        "OmniDrive-Agent",
        "Q-Former3D",
        "Q-Former2D",
        "Dense BEV",
        "BEVDet+BUTD",
        "BEVDet+MCAN",
        "CenterPoint+BUTD",
        "CenterPoint+MCAN",
        "ST-P3",
        "UniAD",
        "VAD-Base",
        "Ego-MLP",
        "BEV-Planner",
        "BEV-Planner++",
        "OmniDrive",
        "OmniDrive++"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Uncertainty of Thoughts Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models": {
    "filename": "Uncertainty of Thoughts Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "20 Questions",
        "Common",
        "Things",
        "DX",
        "MedDG",
        "FloDial"
      ],
      "models": [
        "Uncertainty of Thoughts (UoT)",
        "Llama-3-70B-Instruct",
        "Mistral-Large",
        "Gemini-1.5-Pro",
        "Claude-3-Opus",
        "GPT-4",
        "Llama 2-70B-Chat",
        "Cohere",
        "PaLM 2",
        "Claude 2",
        "GPT-3.5-turbo",
        "Direct Prompting (DP)",
        "Planning Prompting (PP)",
        "Chain-of-Thought (CoT)",
        "CoT-SC (Self-Consistency)",
        "Reflexion",
        "Tree-of-Thoughts (ToT)",
        "Original-ToT",
        "Adapted-ToT (Ad.-ToT)",
        "Pruned UoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring the Mystery of Influential Data for Mathematical Reasoning": {
    "filename": "Exploring the Mystery of Influential Data for Mathematical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "AQuA-RAT",
        "NumGLUE",
        "Mathematics",
        "MMLU-Math",
        "SAT-Math",
        "SimulEq",
        "SVAMP"
      ],
      "models": [
        "QaDS",
        "LLaMA-2",
        "Mistral",
        "DeepSeekMath-Base",
        "WizardMath-7B-v1.1",
        "MAmmoTH-Coder",
        "ToRA-Coder",
        "InternLM2-Math",
        "DeepSeekMath-Instruct",
        "MathScale-Mistral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Next-Generation Database Interfaces A Survey of LLM-based Text-to-SQL": {
    "filename": "Next-Generation Database Interfaces A Survey of LLM-based Text-to-SQL.pdf",
    "analysis": {
      "benchmarks": [
        "BIRD",
        "DuSQL",
        "CoSQL",
        "Spider",
        "WikiSQL",
        "KaggleDBQA",
        "ADVETA",
        "Spider-SS",
        "Spider-CG",
        "Spider-DK",
        "Spider-SYN",
        "Spider-Realistic",
        "CSpider",
        "SParC",
        "SQUALL"
      ],
      "models": [
        "DIN-SQL",
        "Coder-Reviewer",
        "LEVER",
        "SELF-DEBUGGING",
        "DESEM+P",
        "CoT",
        "StructGPT",
        "SD+SA+Voting",
        "QDecomp",
        "Least-to-Most",
        "SQL-PaLM",
        "RAG+SP&DRC",
        "C3",
        "DAIL-SQL",
        "ODIS",
        "ACT-SQL",
        "MAC-SQL",
        "DEA-SQL",
        "FUSED",
        "DELLM",
        "SGU-SQL",
        "POT",
        "SQL-CRAFT",
        "FUXI",
        "MetaSQL",
        "PET-SQL",
        "PURPLE",
        "CLLMs",
        "CodeS",
        "Symbol-LLM",
        "StructLM",
        "DTS-SQL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Effective Generative AI The Human-Algorithm Centaur": {
    "filename": "Effective Generative AI The Human-Algorithm Centaur.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "centaur model",
        "Large Language Models (LLMs)",
        "Reinforcement Learning with Human Feedback (RLHF)",
        "In-Context Learning",
        "Chain-of-Thought reasoning",
        "OpenAI's o1",
        "GPT-3",
        "GPT-4",
        "Transformer architecture",
        "ChatGPT",
        "DALL-E",
        "Llama",
        "Bard",
        "PaLM",
        "Bing Chat",
        "Stable Diffusion",
        "GitHub Copilot",
        "Claude"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RESPROMPT Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models": {
    "filename": "RESPROMPT Residual Connection Prompting Advances Multi-Step Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "AQUA-RAT",
        "MathQA",
        "SVAMP",
        "SCONE-Alchemy",
        "StrategyQA"
      ],
      "models": [
        "RESPROMPT",
        "LLaMA-65B",
        "LLaMA2-70B",
        "Original CoT",
        "Derived CoT",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Model Prompt Chaining for Long Legal Document Classification": {
    "filename": "Large Language Model Prompt Chaining for Long Legal Document Classification.pdf",
    "analysis": {
      "benchmarks": [
        "LexGLUE",
        "ECHR",
        "SCOTUS"
      ],
      "models": [
        "ChatGPT",
        "GPT-NeoX",
        "Flan-UL2",
        "BRIO",
        "PRIMERA",
        "custom-legalbert"
      ]
    }
  },
  "Learning Universal Predictors": {
    "filename": "Learning Universal Predictors.pdf",
    "analysis": {
      "benchmarks": [
        "Variable-order Markov Sources (VOMS)",
        "Chomsky Hierarchy (CH) Tasks",
        "Universal Turing Machine Data"
      ],
      "models": [
        "LSTM",
        "Transformer",
        "RNN",
        "Stack-RNN",
        "Tape-RNN",
        "Transformer-L",
        "LSTM-L",
        "RNN-L",
        "Stack-RNN-L",
        "Tape-RNN-L"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Using Prompts to Guide Large Language Models in Imitating a Real Persons Language Style": {
    "filename": "Using Prompts to Guide Large Language Models in Imitating a Real Persons Language Style.pdf",
    "analysis": {
      "benchmarks": [
        "Dataset 1",
        "Dataset 2",
        "Dataset 3"
      ],
      "models": [
        "GPT-4",
        "Llama 3",
        "Gemini 1.5"
      ]
    }
  },
  "Enhancing Computer Programming Education with LLMs A Study on Effective Prompt Engineering for Python Code Generation": {
    "filename": "Enhancing Computer Programming Education with LLMs A Study on Effective Prompt Engineering for Python Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "LeetCode",
        "USACO"
      ],
      "models": [
        "GPT-4",
        "GPT-4o",
        "Llama3-8b",
        "Mixtral-8x7b"
      ]
    }
  },
  "A Mechanism for Sample-Efficient In-Context Learning for Sparse Retrieval Tasks": {
    "filename": "A Mechanism for Sample-Efficient In-Context Learning for Sparse Retrieval Tasks.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "transformer",
        "transformer with O(1) layers",
        "transformer with O(m) layers",
        "transformer with 8 layers"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An LLM Compiler for Parallel Function Calling": {
    "filename": "An LLM Compiler for Parallel Function Calling.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "Movie Recommendation",
        "ParallelQA",
        "Game of 24",
        "WebShop"
      ],
      "models": [
        "LLMCompiler",
        "ReAct",
        "OpenAI Parallel Function",
        "Tree-of-Thoughts",
        "LATS",
        "LASER"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Network Management Using Code Generated by Large Language Models": {
    "filename": "Enhancing Network Management Using Code Generated by Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "NeMoEval"
      ],
      "models": [
        "GPT-4",
        "GPT-3",
        "Text-davinci-003",
        "Google Bard",
        "StarCoder",
        "InCoder"
      ]
    }
  },
  "Lets Do a Thought Experiment Using Counterfactuals to Improve Moral Reasoning": {
    "filename": "Lets Do a Thought Experiment Using Counterfactuals to Improve Moral Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "ETHICS",
        "SOCIAL-CHEM-101",
        "COMMONSENSE NORM BANK",
        "SCRUPLES",
        "BIG-bench"
      ],
      "models": [
        "GPT-3",
        "Flan-PaLM 540B",
        "Chain-of-Thought (CoT)",
        "Thought Experiments"
      ]
    }
  },
  "Enhancing Legal Document Retrieval A Multi-Phase Approach with Large Language Models": {
    "filename": "Enhancing Legal Document Retrieval A Multi-Phase Approach with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "COLIEE 2023"
      ],
      "models": [
        "BM25",
        "BERT-based Re-ranking",
        "Multi-Task BERT",
        "GPT-3.5-turbo-instruct",
        "GPT-3.5-turbo-1106",
        "GPT-4-1106-preview"
      ]
    }
  },
  "Watson A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents": {
    "filename": "Watson A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents.pdf",
    "analysis": {
      "benchmarks": [
        "SWE-bench-lite"
      ],
      "models": [
        "AutoCodeRover",
        "Watson",
        "GPT-3.5-turbo-instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VRPTEST Evaluating Visual Referring Prompting in Large Multimodal Models": {
    "filename": "VRPTEST Evaluating Visual Referring Prompting in Large Multimodal Models.pdf",
    "analysis": {
      "benchmarks": [
        "VRPTEST",
        "IQtest",
        "Reasoning",
        "LatexTab"
      ],
      "models": [
        "GPT-4V",
        "mPLUG-OWL",
        "miniGPT-4",
        "InstructBLIP",
        "LLaVA",
        "CogVLM",
        "GPT-4V(Web)",
        "GPT-4V(API)"
      ]
    }
  },
  "ClickDiffusion Harnessing LLMs for Interactive Precise Image Editing": {
    "filename": "ClickDiffusion Harnessing LLMs for Interactive Precise Image Editing.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "CLICK DIFFUSION",
        "INSTRUCT PIX2PIX",
        "LLM GROUNDED DIFFUSION",
        "GLIGEN"
      ]
    }
  },
  "Temporal and Semantic Evaluation Metrics for Foundation Models in Post-Hoc Analysis of Robotic Sub-tasks": {
    "filename": "Temporal and Semantic Evaluation Metrics for Foundation Models in Post-Hoc Analysis of Robotic Sub-tasks.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4V",
        "Gemini Pro",
        "Gemini Pro Vision",
        "Video-LLaVa",
        "randomized baseline"
      ]
    }
  },
  "Probabilistic Adaptation of Text-to-Video Models": {
    "filename": "Probabilistic Adaptation of Text-to-Video Models.pdf",
    "analysis": {
      "benchmarks": [
        "Bridge Data",
        "Ego4D",
        "LanguageTable"
      ],
      "models": [
        "Video Adapter",
        "pretrained large video model",
        "task-specific small video model",
        "Ego4D Small (L)",
        "Ego4D Small (S)",
        "Bridge Small (S)",
        "Bridge Small (L)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Model Agents State-of-the-Art Cooperation Paradigms Security and Privacy and Future Trends": {
    "filename": "Large Model Agents State-of-the-Art Cooperation Paradigms Security and Privacy and Future Trends.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Deep Blue",
        "AlphaGo",
        "AlphaZero",
        "AutoGen",
        "AutoGPT",
        "BabyAGI",
        "ChatDev",
        "GPT-4",
        "PaLM 2",
        "Copilot",
        "VOYAGER",
        "ReAct",
        "Reflexion",
        "SayCan",
        "PaLM-E",
        "AutoWebGLM",
        "NetLLM",
        "NetGPT",
        "MobileAgent v2",
        "AppAgent",
        "Figure 02",
        "Optimus",
        "Apollo ADFM",
        "PentestGPT",
        "AutoAttacker"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NavGPT Explicit Reasoning in Vision-and-Language Navigation with Large Language Models": {
    "filename": "NavGPT Explicit Reasoning in Vision-and-Language Navigation with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "R2R-VLN",
        "R2R"
      ],
      "models": [
        "NavGPT",
        "GPT-4",
        "GPT-3.5",
        "Seq2Seq",
        "Speaker Follower",
        "EnvDrop",
        "PREVALENT",
        "VLN-BERT",
        "HAMT",
        "DuET",
        "DuET (Init. LXMERT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Principled Bayesian Optimisation in Collaboration with Human Experts": {
    "filename": "Principled Bayesian Optimisation in Collaboration with Human Experts.pdf",
    "analysis": {
      "benchmarks": [
        "Ackley function",
        "H\u00f6lder Table",
        "Rosenbrock",
        "Rastringin",
        "Michalewicz",
        "Li+ standard design",
        "Li+ methyl-acetate",
        "Li+ polymer-nanocomposite",
        "Li+ Ionic liquid"
      ],
      "models": [
        "COBOL",
        "vanilla LCB",
        "expert sampling",
        "random sampling",
        "[11] NeurIPS 2022",
        "[50] ECML 2023",
        "[7] AISTATS 2024"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Constructing and Optimizing Machine Learning Workflows A Survey": {
    "filename": "Large Language Models for Constructing and Optimizing Machine Learning Workflows A Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LMPriors",
        "ZAP",
        "VIDS",
        "JarviX",
        "Aliro",
        "AutoML-GPT",
        "MLCopilot",
        "GENIUS",
        "GPT-NAS",
        "AutoMMLab",
        "AutoM3L",
        "Text-to-ML",
        "LLM-Select",
        "GL-Agent",
        "CAAFE",
        "HuggingGPT",
        "ModelGPT",
        "VML",
        "GE",
        "AgentHPO",
        "LLAMBO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning": {
    "filename": "Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld",
        "gym_cards",
        "NumberLine",
        "EZPoints",
        "Points24",
        "Blackjack"
      ],
      "models": [
        "7b model",
        "GPT4-V",
        "Gemini",
        "LLaVA-sft",
        "CNN+RL",
        "llava-v1.6-mistral-7b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Visual Prompt Selection for In-Context Learning Segmentation": {
    "filename": "Visual Prompt Selection for In-Context Learning Segmentation.pdf",
    "analysis": {
      "benchmarks": [
        "PASCAL-5i",
        "COCO-20i",
        "iSALD-5i"
      ],
      "models": [
        "MAE-VQGAN",
        "SegGPT",
        "Painter",
        "CrossoverNet",
        "RFNet",
        "DGEN",
        "MSNANet",
        "SCS"
      ]
    }
  },
  "Larger Language Models Dont Care How You Think Why Chain-of-Thought Prompting Fails in Subjective Tasks": {
    "filename": "Larger Language Models Dont Care How You Think Why Chain-of-Thought Prompting Fails in Subjective Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "MFRC",
        "GoEmotions"
      ],
      "models": [
        "Llama-2-7b-chat-hf",
        "Meta-Llama-3-8B-Instruct",
        "Llama-2-70b-chat-hf",
        "Meta-Llama-3-70B-Instruct",
        "gpt-3.5-turbo",
        "gpt-4o-mini"
      ]
    }
  },
  "You Only Look at Screens Multimodal Chain-of-Action Agents": {
    "filename": "You Only Look at Screens Multimodal Chain-of-Action Agents.pdf",
    "analysis": {
      "benchmarks": [
        "AITW"
      ],
      "models": [
        "Auto-GUI",
        "BC-single",
        "BC-history",
        "PaLM 2-CoT",
        "ChatGPT-CoT",
        "GPT-4V",
        "Fine-tuned Llama 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "QAmeleon Multilingual QA with Only 5 Examples": {
    "filename": "QAmeleon Multilingual QA with Only 5 Examples.pdf",
    "analysis": {
      "benchmarks": [
        "TYDIQA-GOLDP",
        "MLQA"
      ],
      "models": [
        "QA MELEON",
        "mT5-XL",
        "PaLM-540B",
        "code-davinci-002",
        "Flan-U-PaLM-540B",
        "XLM-E-XL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Combating Online Misinformation Videos Characterization Detection and Future Directions": {
    "filename": "Combating Online Misinformation Videos Characterization Detection and Future Directions.pdf",
    "analysis": {
      "benchmarks": [
        "FVC",
        "YouTubeAudit",
        "FakeSV",
        "COVID-VTS"
      ],
      "models": [
        "Liu et al. 2023",
        "Qi et al. 2023",
        "Ganti 2022",
        "McCrae et al. 2022",
        "Wang et al. 2022",
        "Li et al. 2022",
        "Choi and Ko 2022",
        "Shang et al. 2021",
        "Jagtap et al. 2021",
        "Serrano et al. 2020",
        "Hou et al. 2019",
        "Palod et al. 2019",
        "Papadopoulou et al. 2017"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Think Step by Step Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos": {
    "filename": "Think Step by Step Chain-of-Gesture Prompting for Error Detection in Robotic Surgical Videos.pdf",
    "analysis": {
      "benchmarks": [
        "JIGSAWS"
      ],
      "models": [
        "Chain-of-Gesture (COG) prompting",
        "Gestural-Visual Reasoning (GVR)",
        "Multi-Scale Temporal Reasoning (MSTR)",
        "CNN-LSTM",
        "ResNet-50",
        "TeCNO",
        "Trans-SVNet",
        "SAHC",
        "SF-TMN"
      ]
    }
  },
  "Data Poisoning for In-context Learning": {
    "filename": "Data Poisoning for In-context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE-SST2",
        "Cola",
        "Emo",
        "AG's new",
        "Poem Sentiment"
      ],
      "models": [
        "ICLPoison",
        "GPT-4",
        "LLaMA2-7B",
        "Pythia-2.8B",
        "Pythia-6.9B",
        "Falcon-7B",
        "GPT-J-6B",
        "MPT-7B",
        "GPT-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ExploreSelf Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models": {
    "filename": "ExploreSelf Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ExploreSelf"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Achieving97 on GSM8K Deeply Understanding the Problems Makes LLMs Better Solvers for Math Word Problems": {
    "filename": "Achieving97 on GSM8K Deeply Understanding the Problems Makes LLMs Better Solvers for Math Word Problems.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "MultiArith",
        "AddSub",
        "AQuA",
        "SingleEq",
        "Last Letters",
        "Coin Flip",
        "StrategyQA",
        "CommonsenseQA"
      ],
      "models": [
        "DUP",
        "Zero-shot CoT",
        "Least-to-Most",
        "Zero-shot PS+",
        "Manual-CoT",
        "Auto-CoT",
        "GPT-3.5-Turbo",
        "GPT-4",
        "LLaMA2-Chat-13B",
        "LLaMA2-Chat-70B",
        "CodeLLaMA-Instruct-13B",
        "CodeLLaMA-Instruct-34B"
      ]
    }
  },
  "Open-domain Implicit Format Control for Large Language Model Generation": {
    "filename": "Open-domain Implicit Format Control for Large Language Model Generation.pdf",
    "analysis": {
      "benchmarks": [
        "OIFC test set",
        "ShareGPT"
      ],
      "models": [
        "AF-7B",
        "AF-7B-Instruct",
        "AF-7B-OIFC",
        "FLM-2-52B",
        "FLM-2-52B-Instruct",
        "FLM-2-52B-OIFC"
      ]
    }
  },
  "Understanding Emergent Abilities of Language Models from the Loss Perspective": {
    "filename": "Understanding Emergent Abilities of Language Models from the Loss Perspective.pdf",
    "analysis": {
      "benchmarks": [
        "TriviaQA",
        "HellaSwag",
        "RACE",
        "WinoGrande",
        "MMLU",
        "GSM8K",
        "NLPCC-KBQA",
        "ClozeT",
        "CLUEWSC",
        "C3",
        "C-Eval",
        "GSM8K-Chinese"
      ],
      "models": [
        "LLaMA",
        "LLaMA-13B",
        "GPT-3",
        "LLaMA-7B",
        "LLaMA-33B",
        "LLaMA-65B",
        "1.5B model",
        "6B model",
        "32B model",
        "300M model",
        "540M model",
        "1B model",
        "3B model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Is ChatGPT a General-Purpose Natural Language Processing Task Solver": {
    "filename": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver.pdf",
    "analysis": {
      "benchmarks": [
        "MultiArith",
        "GSM8K",
        "AddSub",
        "AQUA-RAT",
        "SingleEq",
        "SVAMP",
        "CSQA",
        "StrategyQA",
        "COPA",
        "Last Letter Concatenation",
        "Coin Flip",
        "Date Understanding",
        "Tracking Shuffled Objects",
        "RTE",
        "CB",
        "BoolQ",
        "MuTual",
        "SAMSum",
        "CoNLL03",
        "SST2"
      ],
      "models": [
        "ChatGPT",
        "GPT-3.5",
        "text-davinci-003",
        "FLAN",
        "T0",
        "PaLM",
        "UL2",
        "LaMDA",
        "text-davinci-002",
        "Codex",
        "Gopher",
        "Chinchilla",
        "BART",
        "CODA",
        "Flair",
        "LUKE",
        "ACE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors": {
    "filename": "Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors.pdf",
    "analysis": {
      "benchmarks": [
        "TACRED",
        "RETACRED",
        "TACREV",
        "SemEval 2010 Task 8"
      ],
      "models": [
        "QA4RE",
        "FLAN-T5 XXL",
        "text-davinci-003",
        "FLAN-T5 XLarge",
        "ChatGPT",
        "code-002",
        "text-002",
        "text-003",
        "NLI BART",
        "NLI RoBERTa",
        "NLI DeBERTa",
        "SuRE BART",
        "SuRE PEGASUS",
        "Vanilla RE",
        "PTR",
        "KnowPrompt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision": {
    "filename": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA",
        "BIG-bench HHH Eval",
        "Vicuna Benchmark Questions"
      ],
      "models": [
        "Dromedary",
        "Dromedary (final)",
        "Dromedary (non-verbose)",
        "LLaMA",
        "Text-Davinci-003",
        "ChatGPT",
        "GPT-4",
        "Alpaca",
        "Vicuna",
        "Dolly-V2",
        "Anthropic-LM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Do Large Language Models Capture the Ever-changing World Knowledge A Review of Recent Advances": {
    "filename": "How Do Large Language Models Capture the Ever-changing World Knowledge A Review of Recent Advances.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Editable Training",
        "RECKONING",
        "KnowledgeEditor",
        "MEND",
        "SLAG",
        "REMEDI",
        "Distillation",
        "Knowledge Neurons",
        "ROME",
        "MEMIT",
        "MEMIT CSK",
        "PMET",
        "Eva-KELLM",
        "RippleEdits",
        "IKE",
        "RecAdam",
        "DSA",
        "ELLE",
        "CT0",
        "K-Adapter",
        "CKL",
        "CPT",
        "Lifelong-MoE",
        "Module-Former",
        "KILM",
        "SeMem",
        "CaMeLS",
        "CMR",
        "CL-plugin",
        "Transformer-Patcher",
        "GRACE",
        "kNN-LM",
        "AdaptRet",
        "RetoMaton",
        "kNN-prompt",
        "FBNet",
        "MemPrompt",
        "TeachMe",
        "SERAC",
        "MeLLo",
        "IC-Retrieval",
        "IC-RALM",
        "AAR",
        "Adaptive Retrieval",
        "RePlug",
        "IRCoT",
        "RARR",
        "Self-Ask",
        "DecomP",
        "ReAct",
        "ART",
        "LLM-Augmenter",
        "DSP",
        "Iter-RetGen",
        "Knowledge Solver",
        "Internet-Fewshot",
        "LLM-URL",
        "TaskMatrix.AI",
        "MM-REACT",
        "Chameleon",
        "ChatGPT Plugins"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Broken Neural Scaling Laws": {
    "filename": "Broken Neural Scaling Laws.pdf",
    "analysis": {
      "benchmarks": [
        "Birds 200",
        "Caltech101",
        "CIFAR-100",
        "ImageNet",
        "BIG-Bench (BB)"
      ],
      "models": [
        "BiT/101/3",
        "BiT/50/1",
        "MiX/B/16",
        "MiX/L/16",
        "ViT/B/16",
        "ViT/S/16",
        "Transformers",
        "LSTMs"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multi-Modal Hallucination Control by Visual Information Grounding": {
    "filename": "Multi-Modal Hallucination Control by Visual Information Grounding.pdf",
    "analysis": {
      "benchmarks": [
        "MS COCO",
        "POPE"
      ],
      "models": [
        "LLaVA 13B",
        "LLaVA 7B",
        "M3ID",
        "M3ID+DPO",
        "PMI",
        "Contrastive Decoding",
        "LLaVA-RLHF",
        "Robust mPLUG-Owl",
        "MiniGPT4-13B",
        "LLaVA+LURE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MDAgents An Adaptive Collaboration of LLMs for Medical Decision-Making": {
    "filename": "MDAgents An Adaptive Collaboration of LLMs for Medical Decision-Making.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "PubMedQA",
        "DDXPlus",
        "SymCat",
        "JAMA",
        "MedBullets",
        "Path-VQA",
        "PMC-VQA",
        "MIMIC-CXR",
        "MedVidQA"
      ],
      "models": [
        "MDAgents",
        "Single Voting",
        "Debate",
        "MedAgents",
        "ReConcile",
        "Zero-shot",
        "Few-shot",
        "CoT",
        "CoT-SC",
        "ER",
        "Medprompt",
        "Majority Voting",
        "Weighted Voting",
        "Borda Count",
        "Meta-Prompting",
        "Reconcile",
        "AutoGen",
        "DyLAN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Column Type Annotation using ChatGPT": {
    "filename": "Column Type Annotation using ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "SOTAB"
      ],
      "models": [
        "ChatGPT",
        "RoBERTa",
        "DODUO",
        "Random Forest"
      ]
    }
  },
  "DDCoT Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models": {
    "filename": "DDCoT Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ScienceQA"
      ],
      "models": [
        "DDCoT",
        "UnifiedQA",
        "MM-CoT",
        "GPT-3",
        "ChatGPT",
        "LLaMA",
        "LMAdapter",
        "Chameleon"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Grammar-based Game Description Generation using Large Language Models": {
    "filename": "Grammar-based Game Description Generation using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Ludii"
      ],
      "models": [
        "Large Language Models (LLMs)",
        "Grammar-based Game Description Generation (GGDG)",
        "GGDG + Rule Decoding (RD)",
        "GGDG + RD + Game Description Decoding (GDD)",
        "Game Description Generation (GDG)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "JailbreakEval An Integrated Toolkit for Evaluating Jailbreak Attempts Against Large Language Models": {
    "filename": "JailbreakEval An Integrated Toolkit for Evaluating Jailbreak Attempts Against Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "AdvBench",
        "SafeBench",
        "JailbreakBench"
      ],
      "models": [
        "GPT-4",
        "LLaMA",
        "vicuna-13b-v1.5",
        "Llama Guard",
        "Llama Guard2",
        "Beaver Dam",
        "GPT Models",
        "MD-Judge",
        "Llama Guard 2",
        "OpenAIChat",
        "HFChat",
        "OpenAITextClassification",
        "PerspectiveTextClassification",
        "HFTextClassification"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-Generated Black-box Explanations Can Be Adversarially Helpful": {
    "filename": "LLM-Generated Black-box Explanations Can Be Adversarially Helpful.pdf",
    "analysis": {
      "benchmarks": [
        "ECQA",
        "SNLI"
      ],
      "models": [
        "Chat-3.5-Turbo",
        "GPT-4",
        "Claude",
        "Cohere Command",
        "Vicuna-33B-v1.3",
        "WizardLM-70B-V1.0",
        "Mixtral-8x7B-Instruct-v0.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ProCoT Stimulating Critical Thinking and Writing of Students through Engagement with Large Language Models LLMs": {
    "filename": "ProCoT Stimulating Critical Thinking and Writing of Students through Engagement with Large Language Models LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "FEVER",
        "ClaimBuster"
      ],
      "models": [
        "ProCoT",
        "ChatGPT (v3.5)",
        "Phind (v8)",
        "BingAI"
      ]
    }
  },
  "MoCa Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks": {
    "filename": "MoCa Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "MoCa dataset",
        "COPA in SuperGLUE",
        "Moral Machine Experiment"
      ],
      "models": [
        "GPT-2",
        "RoBERTa",
        "ALBERT-xxlarge",
        "Electra-gen-large",
        "GPT3-babbage-v1",
        "GPT3-curie-v1",
        "GPT3.5-davinci-v2",
        "GPT3.5-davinci-v3",
        "Alpaca-7B",
        "Anthropic-claude-v1",
        "GPT3.5-turbo",
        "GPT-4",
        "Delphi"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models are Contrastive Reasoners": {
    "filename": "Large Language Models are Contrastive Reasoners.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "AQUA-RAT",
        "SingleEq",
        "AddSub",
        "MultiArith",
        "SVAMP",
        "CommonsenseQA",
        "StrategyQA",
        "Last Letter Concatenation",
        "Coin Flip",
        "Date Understanding",
        "Tracking Shuffled Objects"
      ],
      "models": [
        "GPT-4",
        "gpt-35-turbo",
        "Zero-shot",
        "Zero-shot-CoT",
        "Zero-shot-CP",
        "Zero-shot-CoT-CP",
        "Few-shot",
        "Few-shot-CoT",
        "Few-shot-CoT-CP",
        "Tree of Thoughts (ToT)",
        "Graph of Thoughts (GoT)",
        "Program-aided Language models (PAL)",
        "Program of thoughts prompting (PoT)",
        "Analogical prompting (Self-generated Exemplars)",
        "Self-consistency (SC)",
        "Recursive Criticism and Improvement (RCI)",
        "Self-Refine",
        "Learning Principles from Mistakes (LEAP)",
        "Contrastive CoT",
        "LLaMA3-8B",
        "LLaMA3-70B",
        "ChatGLM3-6B",
        "Qwen1.5-72B-Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do-Not-Answer A Dataset for Evaluating Safeguards in LLMs": {
    "filename": "Do-Not-Answer A Dataset for Evaluating Safeguards in LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Do-Not-Answer",
        "RealToxicityPrompts",
        "BOLD",
        "ToxiGen",
        "TruthfulQA"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "Claude",
        "LLaMA-2",
        "ChatGLM2",
        "Vicuna",
        "BERT-like classifiers",
        "Longformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning": {
    "filename": "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "WIKI",
        "YAGO",
        "ICEWS14",
        "ICEWS18",
        "ACLED-CD22"
      ],
      "models": [
        "EleutherAI gpt-j-6b",
        "EleutherAI gpt-neox-20b",
        "OpenAI text-ada-001",
        "OpenAI text-babbage-001",
        "OpenAI text-curie-001",
        "OpenAI text-davinci-003",
        "OpenAI gpt-3.5-turbo",
        "RE-Net",
        "RE-GCN",
        "TANGO",
        "xERTE",
        "TimeTraveler",
        "CyGNet",
        "TLogic",
        "GPT2",
        "gpt2-medium",
        "gpt2-large",
        "gpt2-xl",
        "GPT-J",
        "GPT-NeoX",
        "InstructGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SMARTFEAT Efficient Feature Construction through Feature-Level Foundation Model Interactions": {
    "filename": "SMARTFEAT Efficient Feature Construction through Feature-Level Foundation Model Interactions.pdf",
    "analysis": {
      "benchmarks": [
        "Diabetes",
        "Heart",
        "Bank",
        "Adult",
        "Housing",
        "Lawschool",
        "West Nile Virus",
        "Tennis"
      ],
      "models": [
        "SMARTFEAT",
        "CAAFE",
        "Featuretools",
        "AutoFeat",
        "Linear Regression (LR)",
        "GaussianNB (NB)",
        "Random Forest (RF)",
        "Extra Tree (ET)",
        "Deep Neural Network (DNN)"
      ]
    }
  },
  "Harmful Speech Detection by Language Models Exhibits Gender-Queer Dialect Bias": {
    "filename": "Harmful Speech Detection by Language Models Exhibits Gender-Queer Dialect Bias.pdf",
    "analysis": {
      "benchmarks": [
        "QueerReclaimLex"
      ],
      "models": [
        "Detoxify",
        "Perspective API",
        "GPT-3.5",
        "LLaMA 2",
        "Mistral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GPT-Neo for commonsense reasoning-a theoretical and practical lens": {
    "filename": "GPT-Neo for commonsense reasoning-a theoretical and practical lens.pdf",
    "analysis": {
      "benchmarks": [
        "Piqa",
        "Winogrande",
        "Hellaswag",
        "Storycloze",
        "BoolQ",
        "OpenBookQA"
      ],
      "models": [
        "GPT-Neo",
        "GPT-3",
        "Llama",
        "Llama-2",
        "MPT",
        "Falcon",
        "GPT-J",
        "BERT-base",
        "BERT-large"
      ]
    }
  },
  "Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models": {
    "filename": "Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "IFRS-compliant reports"
      ],
      "models": [
        "ZeroShotALI",
        "SentenceBERT",
        "GPT-4",
        "Chroma DB (Ada V1)",
        "Chroma DB (Ada V2)",
        "Chroma DB (Ada V2) + GPT-3.5 Turbo",
        "Chroma DB (Ada V2) + GPT-4"
      ]
    }
  },
  "Benchmarking a foundation LLM on its ability to re-label structure names in accordance with the AAPM TG-263 report": {
    "filename": "Benchmarking a foundation LLM on its ability to re-label structure names in accordance with the AAPM TG-263 report.pdf",
    "analysis": {
      "benchmarks": [
        "prostate",
        "head and neck",
        "thorax"
      ],
      "models": [
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automating Chapter-Level Classification for Electronic Theses and Dissertations": {
    "filename": "Automating Chapter-Level Classification for Electronic Theses and Dissertations.pdf",
    "analysis": {
      "benchmarks": [
        "ETD-SGT",
        "PQDT",
        "ETD-CL",
        "FTD"
      ],
      "models": [
        "Random Forest",
        "SVM",
        "BERT",
        "BERT+ETD",
        "SciBERT",
        "SciBERT+ETD",
        "Llama-2",
        "Llama-3"
      ]
    }
  },
  "LLM Multi-Agent Systems Challenges and Open Problems": {
    "filename": "LLM Multi-Agent Systems Challenges and Open Problems.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "DMAS",
        "Stackelberg Equilibrium",
        "Nash Equilibrium",
        "Chain of Thoughts (CoT)",
        "Multiple CoTs",
        "Program-of-Thoughts (PoT)",
        "Table-of-Thoughts (Tab-CoT)",
        "Tree-of-Thoughts (ToT)",
        "Graph-of-Thoughts-Rationale (GoT-Rationale)",
        "Rationale-Augmented Ensembles"
      ]
    }
  },
  "Integrating Hierarchical Semantic into Iterative Generation Model for Entailment Tree Explanation": {
    "filename": "Integrating Hierarchical Semantic into Iterative Generation Model for Entailment Tree Explanation.pdf",
    "analysis": {
      "benchmarks": [
        "EntailmentBank",
        "eOBQA",
        "eQASC"
      ],
      "models": [
        "HiSCG",
        "EntailmentWriter (T5-11B)",
        "EntailmentWriter (T5-large)",
        "IRGR (T5-large)",
        "METGEN",
        "RLET"
      ]
    }
  },
  "GREAT Geometry-Intention Collaborative Inference for Open-Vocabulary 3D Object Affordance Grounding": {
    "filename": "GREAT Geometry-Intention Collaborative Inference for Open-Vocabulary 3D Object Affordance Grounding.pdf",
    "analysis": {
      "benchmarks": [
        "PointImage Affordance Dataset v2 (PIADv2)",
        "3D AffordanceNet",
        "PIAD"
      ],
      "models": [
        "GREAT",
        "IAGNet",
        "LASO",
        "OpenAD",
        "OpenKD",
        "Baseline",
        "FRCNN",
        "XMF"
      ]
    }
  },
  "Networks of Networks Complexity Class Principles Applied to Compound AI Systems Design": {
    "filename": "Networks of Networks Complexity Class Principles Applied to Compound AI Systems Design.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU"
      ],
      "models": [
        "Networks of Networks (NoN)",
        "verifier-based judge NoN",
        "GPT-4-Turbo",
        "GPT-4o",
        "AlphaCode2",
        "Gemini"
      ]
    }
  },
  "Tree-of-Table Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding": {
    "filename": "Tree-of-Table Unleashing the Power of LLMs for Enhanced Large-Scale Table Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "WikiTQ",
        "TableFact",
        "FeTaQA",
        "BIRD"
      ],
      "models": [
        "Tree-of-Table",
        "GPT3.5",
        "PaLM2",
        "LLaMA2",
        "Text-to-SQL",
        "End-to-End QA",
        "Few-Shot QA",
        "Binder",
        "Chain-of-Thought",
        "Dater",
        "Chain-of-Table"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Pushing Mixture of Experts to the Limit Extremely Parameter Efficient MoE for Instruction Tuning": {
    "filename": "Pushing Mixture of Experts to the Limit Extremely Parameter Efficient MoE for Instruction Tuning.pdf",
    "analysis": {
      "benchmarks": [
        "ANLI",
        "HellaSwag",
        "WinoGrande",
        "Super Glue",
        "P3"
      ],
      "models": [
        "Mixture of Vectors (MoV)",
        "Mixture of LORA (MoLORA)",
        "T5",
        "T0",
        "(IA)3",
        "LORA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Gaining Wisdom from Setbacks Aligning Large Language Models via Mistake Analysis": {
    "filename": "Gaining Wisdom from Setbacks Aligning Large Language Models via Mistake Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "PKU-SafeRLHF",
        "AlpacaFarm",
        "S AFETY PROMPTS",
        "MOSS"
      ],
      "models": [
        "Alpaca",
        "GPT-3",
        "GPT-3.5",
        "ChatGLM",
        "SFT",
        "RLHF",
        "Critique-Revise",
        "CoH",
        "Ours"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Model Programs": {
    "filename": "Large Language Model Programs.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA",
        "Natural Questions"
      ],
      "models": [
        "OPT-175B",
        "InstructGPT",
        "Tk-Instruct 11B",
        "LAMBADA",
        "BlenderBot 3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DeTeCtive Detecting AI-generated Text via Multi-Level Contrastive Learning": {
    "filename": "DeTeCtive Detecting AI-generated Text via Multi-Level Contrastive Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Deepfake",
        "M4",
        "TuringBench",
        "OUTFOX"
      ],
      "models": [
        "DeTeCtive",
        "SimCSE-RoBERTa",
        "RoBERTa",
        "Longformer",
        "T5-Sentinel",
        "Binoculars",
        "FastText",
        "GLTR",
        "DetectGPT",
        "GPT-Sentinel",
        "RADAR",
        "SCL",
        "CoCo",
        "RoBERTa-base",
        "RoBERTa-large",
        "HC3 Detector",
        "BertAA",
        "BERT-Multinomial",
        "RoBERTa-Multinomial"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Playing NetHack with LLMs Potential  Limitations as Zero-Shot Agents": {
    "filename": "Playing NetHack with LLMs Potential  Limitations as Zero-Shot Agents.pdf",
    "analysis": {
      "benchmarks": [
        "NetHack",
        "NetHack Learning Environment",
        "MiniHack"
      ],
      "models": [
        "NetPlay",
        "autoascend",
        "handcrafted agent",
        "GPT-4-Turbo"
      ]
    }
  },
  "MiniGPT-3D Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors": {
    "filename": "MiniGPT-3D Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors.pdf",
    "analysis": {
      "benchmarks": [
        "ModelNet40",
        "Objaverse"
      ],
      "models": [
        "MiniGPT-3D",
        "ShapeLLM-13B",
        "PointLLM-13B",
        "PointLLM-7B",
        "Point-Bind LLM",
        "3D-LLM",
        "LLaVA-13B",
        "LLaVA-7B",
        "InstructBLIP-13B",
        "InstructBLIP-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Argumentative Large Language Models for Explainable and Contestable Decision-Making": {
    "filename": "Argumentative Large Language Models for Explainable and Contestable Decision-Making.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulClaim",
        "StrategyClaim",
        "MedClaim"
      ],
      "models": [
        "Argumentative LLM",
        "Direct Question",
        "Estimated Confidence",
        "Chain-of-Thought",
        "0.5 Base Argument (Depth=1)",
        "0.5 Base Argument (Depth=2)",
        "Estimated Base Argument (Depth=1)",
        "Estimated Base Argument (Depth=2)",
        "Mistral",
        "Mixtral",
        "Gemma 7B",
        "GPT-3.5-turbo",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dissecting Chain-of-Thought A Study on Compositional In-Context Learning of MLPs": {
    "filename": "Dissecting Chain-of-Thought A Study on Compositional In-Context Learning of MLPs.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ICL",
        "CoT-I",
        "CoT-I/O",
        "2-layer MLP",
        "deep linear MLP",
        "standard GPT-2",
        "small GPT-2",
        "tiny GPT-2",
        "CoT-2",
        "CoT-3",
        "CoT-6"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Universal Length Generalization with Turing Programs": {
    "filename": "Universal Length Generalization with Turing Programs.pdf",
    "analysis": {
      "benchmarks": [
        "addition",
        "multiplication",
        "SGD",
        "Turing Machine simulation"
      ],
      "models": [
        "Turing Programs",
        "transformers with Hard-ALiBi",
        "GPT-NeoX architecture"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FLARE Faithful Logic-Aided Reasoning and Exploration": {
    "filename": "FLARE Faithful Logic-Aided Reasoning and Exploration.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "MultiArith",
        "ASDiv",
        "AQuA",
        "StrategyQA",
        "Date",
        "Sport",
        "CLUTRR"
      ],
      "models": [
        "FLARE",
        "F-CoT",
        "CoT",
        "Llama-3.1-8B",
        "CmDR",
        "CmDR+",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OCEAN Offline Chain-of-thought Evaluation and Alignment in Large Language Models": {
    "filename": "OCEAN Offline Chain-of-thought Evaluation and Alignment in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Wikidata5M",
        "ARC",
        "PubMedQA",
        "SciQA",
        "HotpotQA",
        "MuSiQue",
        "StrategyQA",
        "CSQA",
        "CSQA-2",
        "CSQA-COT1000",
        "OpenBookQA",
        "Winogrande",
        "CWQ",
        "SST2",
        "AgNews",
        "BoolQ"
      ],
      "models": [
        "OCEAN",
        "Gemma-2",
        "Llama-3",
        "Phi-3.5-mini",
        "Mistral-0.2",
        "SFT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cost-Efficient Prompt Engineering for Unsupervised Entity Resolution": {
    "filename": "Cost-Efficient Prompt Engineering for Unsupervised Entity Resolution.pdf",
    "analysis": {
      "benchmarks": [
        "Web Data Commons (WDC)",
        "Amazon-Google Products (AG)"
      ],
      "models": [
        "GPT-3.5",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Not All Languages Are Created Equal in LLMs Improving Multilingual Capability by Cross-Lingual-Thought Prompting": {
    "filename": "Not All Languages Are Created Equal in LLMs Improving Multilingual Capability by Cross-Lingual-Thought Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "MGSM",
        "XCOPA",
        "XNLI",
        "PAWS-X",
        "MKQA",
        "XL-Sum",
        "FLORES"
      ],
      "models": [
        "text-davinci-003",
        "gpt-3.5-turbo",
        "LLaMA-2-Chat",
        "XLT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DLAP A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection": {
    "filename": "DLAP A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection.pdf",
    "analysis": {
      "benchmarks": [
        "Chrome",
        "Linux",
        "Android",
        "Qemu"
      ],
      "models": [
        "DLAP",
        "Linevul",
        "Devign",
        "Sysevr",
        "PRol",
        "PAux",
        "PCot",
        "GRACE",
        "LoRA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Q-Probe A Lightweight Approach to Reward Maximization for Language Models": {
    "filename": "Q-Probe A Lightweight Approach to Reward Maximization for Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MBPP",
        "HumanEval",
        "GSM-8K",
        "Anthropic Helpfulness and Harmlessness (HH)",
        "OpenAssistant",
        "Stanford Human Preferences Dataset (SHP)"
      ],
      "models": [
        "Q-Probe",
        "Code-LLaMA-7B",
        "OpenAI API",
        "LLaMA-7B",
        "PPO (offline)",
        "DPO",
        "KTO",
        "LORA",
        "SFT ON SUCCESSES",
        "PROMPT RM",
        "FINETUNE RM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-Assist Enhancing Closed-Loop Planning with Language-Based Reasoning": {
    "filename": "LLM-Assist Enhancing Closed-Loop Planning with Language-Based Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "nuPlan"
      ],
      "models": [
        "PDM-Closed",
        "LLM-A SSIST",
        "GPT-3-A SSIST UNC",
        "GPT-3-A SSIST PAR",
        "GPT-3",
        "GPT-4-A SSIST UNC",
        "GPT-4-A SSIST PAR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Search-Based LLMs for Code Optimization": {
    "filename": "Search-Based LLMs for Code Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "PIE"
      ],
      "models": [
        "SBLLM",
        "CodeLlama",
        "Gemini",
        "ChatGPT",
        "GPT-4",
        "RapGen",
        "DeepDev-PERF",
        "Supersonic"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Answering Ambiguous Questions via Iterative Prompting": {
    "filename": "Answering Ambiguous Questions via Iterative Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "AmbigQA",
        "WebQSP"
      ],
      "models": [
        "AmbigPrompt",
        "T5",
        "FiD",
        "DPR",
        "SpanSeqGen",
        "Refuel",
        "JPR",
        "RECTIFY"
      ]
    }
  },
  "Think Outside the Code Brainstorming Boosts Large Language Models in Code Generation": {
    "filename": "Think Outside the Code Brainstorming Boosts Large Language Models in Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CodeContests",
        "APPS",
        "LeetCode"
      ],
      "models": [
        "BRAINSTORM",
        "ChatGPT",
        "AlphaCode",
        "CodeRL",
        "Codex",
        "Code-davinci-002",
        "GPT-Neo",
        "GPT-J",
        "GPT-2",
        "text-davinci-003"
      ]
    }
  },
  "Evaluating Explanations Through LLMs Beyond Traditional User Studies": {
    "filename": "Evaluating Explanations Through LLMs Beyond Traditional User Studies.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Llama 3 (8B and 70B)",
        "Qwen 2 (7B and 72B)",
        "Mistral 7B",
        "Mistral Nemo",
        "GPT-4o Mini"
      ]
    }
  },
  "Hierarchical Video-Moment Retrieval and Step-Captioning": {
    "filename": "Hierarchical Video-Moment Retrieval and Step-Captioning.pdf",
    "analysis": {
      "benchmarks": [
        "HIREST",
        "HowTo100M",
        "COIN",
        "CrossTask",
        "YouCook2"
      ],
      "models": [
        "CLIP",
        "EVA-CLIP",
        "Frozen-in-Time",
        "MIL-NCE",
        "BMT",
        "SwinBERT",
        "Joint Model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DRBENCH Diagnostic Reasoning Benchmark for Clinical Natural Language Processing": {
    "filename": "DRBENCH Diagnostic Reasoning Benchmark for Clinical Natural Language Processing.pdf",
    "analysis": {
      "benchmarks": [
        "DR.BENCH",
        "MedNLI",
        "EmrQA",
        "SOAP Labeling",
        "Assessment and Plan Relation Labeling (AP)",
        "Problem List Summarization (Summ)",
        "MedQA"
      ],
      "models": [
        "T5-Base",
        "T5-Large",
        "T5-B-Vanilla",
        "T5-L-Vanilla",
        "SciFive-Base",
        "SciFive-Large",
        "T5-Defs",
        "T5-RelPaths",
        "T5-Ehr",
        "T5-L-RelPaths+Defs"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Discovering Latent Knowledge in Language Models Without Supervision": {
    "filename": "Discovering Latent Knowledge in Language Models Without Supervision.pdf",
    "analysis": {
      "benchmarks": [
        "IMDB",
        "Amazon",
        "AG-News",
        "DBpedia-14",
        "RTE",
        "QNLI",
        "COPA",
        "Story-Cloze",
        "BoolQ",
        "PIQA"
      ],
      "models": [
        "T5",
        "UnifiedQA",
        "T0",
        "GPT-J",
        "RoBERTa",
        "DeBERTa",
        "Contrast-Consistent Search (CCS)",
        "Logistic Regression (LR)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CharED Character-wise Ensemble Decoding for Large Language Models": {
    "filename": "CharED Character-wise Ensemble Decoding for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "GSM8K",
        "ToxiGen"
      ],
      "models": [
        "CharED",
        "Llama 2 Chat",
        "WizardMath",
        "DeepSeek Coder"
      ]
    }
  },
  "Mix-CPT A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment": {
    "filename": "Mix-CPT A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "NaturalQuestion (NQ)",
        "TrivialQA (TQ)",
        "WikiQA (WQ)",
        "GSM8K",
        "MATH",
        "MBPP",
        "HumanEval",
        "RACE-Hard",
        "OpenBookQA",
        "HellaSwag",
        "CSQA",
        "PIQA",
        "MMLU",
        "BBH",
        "ARC-Challenge",
        "C-EVAL",
        "MT-Bench"
      ],
      "models": [
        "Mix-CPT",
        "LLaMA3-8B",
        "LLaMA3-8B-Chat",
        "LLaMA3-8B-Base",
        "Wiki+ CPT",
        "Math+ CPT",
        "Code+ CPT",
        "Mix-CPT (w/o KD)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leftover Lunch Advantage-based Offline Reinforcement Learning for Language Models": {
    "filename": "Leftover Lunch Advantage-based Offline Reinforcement Learning for Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Helpful and Harmless Assistant (HHA)",
        "Commonsense Reasoning",
        "Reddit response generation",
        "Faithful knowledge-grounded dialog"
      ],
      "models": [
        "A-L OL",
        "A-L OL (ref. free)",
        "A-L OL seq.",
        "A-L OL KL",
        "PPO",
        "DPO",
        "DPO (ref. free)",
        "PRO",
        "wBC",
        "GOLD",
        "R-L OL",
        "NLL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "WALL-E World Alignment by Rule Learning Improves World Model-based LLM Agents": {
    "filename": "WALL-E World Alignment by Rule Learning Improves World Model-based LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Minecraft",
        "ALFWorld"
      ],
      "models": [
        "WALL-E",
        "RAFA",
        "Reflexion",
        "AdaPlanner",
        "ReAct",
        "GPT-4V",
        "Jarvis-1",
        "Optimus-1",
        "GPT-3.5",
        "DEPS",
        "GITM",
        "MiniGPT-4",
        "BLIP-2",
        "LLaMA-Adapter",
        "InstructBLIP",
        "EMMA",
        "BUTLER",
        "GPT-BUTLER",
        "AutoGen"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prose-to-P4 Leveraging High Level Languages": {
    "filename": "Prose-to-P4 Leveraging High Level Languages.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT 4",
        "Gemini Ultra",
        "Lucid",
        "Lucid 2.0",
        "Lyra",
        "O4",
        "P4All",
        "P4rrot",
        "pcube",
        "Graph-to-P4"
      ]
    }
  },
  "iToT An Interactive System for Customized Tree-of-Thought Generation": {
    "filename": "iToT An Interactive System for Customized Tree-of-Thought Generation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "iToT",
        "Tree-of-Thoughts (ToT)",
        "Chain-of-Thought (CoT)",
        "zero-shot CoT",
        "self-consistency CoT",
        "self-evaluation guided beam search",
        "graph-of-thoughts",
        "retrieval-augmented generation",
        "OpenAI's GPT models (GPT-3.5 Turbo, GPT-4, GPT-4o)",
        "SBERT",
        "DeBERTa"
      ]
    }
  },
  "ViperGPT Visual Inference via Python Execution for Reasoning": {
    "filename": "ViperGPT Visual Inference via Python Execution for Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "RefCOCO",
        "RefCOCO+",
        "GQA",
        "OK-VQA",
        "NExT-QA"
      ],
      "models": [
        "ViperGPT",
        "GLIP",
        "X-VLM",
        "MiDaS",
        "GPT-3",
        "BLIP-2",
        "MDETR",
        "OFA",
        "OWL-ViT",
        "ReCLIP",
        "LGCN",
        "LXMERT",
        "NSM",
        "CRF",
        "TRiG",
        "KAT",
        "RA-VQA",
        "REVIVE",
        "PromptCap",
        "PNP-VQA",
        "PICa",
        "Flamingo",
        "ATP",
        "VGT",
        "HiTeA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BeSimulator A Large Language Model Powered Text-based Behavior Simulator": {
    "filename": "BeSimulator A Large Language Model Powered Text-based Behavior Simulator.pdf",
    "analysis": {
      "benchmarks": [
        "BTSIMBENCH",
        "BEHAVIOR-1K"
      ],
      "models": [
        "BeSimulator",
        "Claude-3.5-Sonnet",
        "Deepseek-V2-Chat",
        "Qwen2-72B-Instruct",
        "Llama3.1-70B-Instruct"
      ]
    }
  },
  "Distilling Algorithmic Reasoning from LLMs via Explaining Solution Programs": {
    "filename": "Distilling Algorithmic Reasoning from LLMs via Explaining Solution Programs.pdf",
    "analysis": {
      "benchmarks": [
        "CodeContests",
        "Codeforces",
        "CF Prob"
      ],
      "models": [
        "GPT-4-0613",
        "GPT-3.5-turbo-1106",
        "Deepseek Coder 7B",
        "Reasoner",
        "Coder",
        "Explainer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Reasoning in Large Language Models A Survey": {
    "filename": "Towards Reasoning in Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "Math",
        "MathQA",
        "SVAMP",
        "ASDiv",
        "AQuA",
        "MAWPS",
        "CSQA",
        "StrategyQA",
        "ARC",
        "Last Letter Concatenation",
        "Coin Flip",
        "BIG-bench",
        "SCAN",
        "WikiTableQA",
        "FetaQA",
        "CommonGen",
        "Open Relation Modeling",
        "PrOntoQA",
        "FOLIO"
      ],
      "models": [
        "GPT-3",
        "PaLM",
        "RoBERTa",
        "Codex",
        "Flan",
        "OPT",
        "BLOOM",
        "Self-Taught Reasoner (STaR)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MaxMI A Maximal Mutual Information Criterion for Manipulation Concept Discovery": {
    "filename": "MaxMI A Maximal Mutual Information Criterion for Manipulation Concept Discovery.pdf",
    "analysis": {
      "benchmarks": [
        "ManiSkill2",
        "Franka Kitchen"
      ],
      "models": [
        "MaxMI",
        "Key State Localization Network (KSL-Net)",
        "Behavior Transformer (BeT)",
        "Decision Diffuser (DD)",
        "Decision Transformer (DT)",
        "Chain-of-Thought Predictive Control (CoTPC)",
        "Masked Autoencoding for Scalable and Generalizable Decision Making (MaskDP)",
        "CompILE",
        "AWE"
      ]
    }
  },
  "Accuracy and Consistency of LLMs in the Registered Dietitian Exam The Impact of Prompt Engineering and Knowledge Retrieval": {
    "filename": "Accuracy and Consistency of LLMs in the Registered Dietitian Exam The Impact of Prompt Engineering and Knowledge Retrieval.pdf",
    "analysis": {
      "benchmarks": [
        "Registered Dietitian Exam",
        "MMLU",
        "GPQA",
        "DROP"
      ],
      "models": [
        "GPT-4o",
        "Claude 3.5 Sonnet",
        "Gemini 1.5 Pro",
        "GPT-4o with CoT-SC",
        "Gemini 1.5 Pro with ZS",
        "Claude 3.5 with CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MQM-APE Toward High-Quality Error Annotation Predictors with Automatic Post-Editing in LLM Translation Evaluators": {
    "filename": "MQM-APE Toward High-Quality Error Annotation Predictors with Automatic Post-Editing in LLM Translation Evaluators.pdf",
    "analysis": {
      "benchmarks": [
        "WMT22",
        "IndicMT"
      ],
      "models": [
        "MQM-APE",
        "GEMBA-MQM",
        "InstructScore",
        "xCOMET",
        "LLMRefine",
        "Tower",
        "GEMBA",
        "EAPrompt",
        "AutoMQM",
        "Llama3-8b-inst",
        "Llama3-70b-inst",
        "Mixtral-8x7b-inst",
        "Mixtral-8x22b-inst",
        "Qwen1.5-14b-chat",
        "Qwen1.5-72b-chat",
        "Tower-7b-inst",
        "Tower-13b-inst"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On the use of Large Language Models in Model-Driven Engineering": {
    "filename": "On the use of Large Language Models in Model-Driven Engineering.pdf",
    "analysis": {
      "benchmarks": [
        "ModelSet",
        "EMF-based metamodels"
      ],
      "models": [
        "RoBERTa",
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "Codex",
        "SLGPT",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Training Language Models with Language Feedback at Scale": {
    "filename": "Training Language Models with Language Feedback at Scale.pdf",
    "analysis": {
      "benchmarks": [
        "TL;DR",
        "CNN/DM"
      ],
      "models": [
        "GPT-3",
        "FeedME",
        "text-davinci-001",
        "OPT-13B",
        "InstructRM Ensemble",
        "ILF",
        "OPT-RM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Simple and Provable Scaling Law for the Test-Time Compute of Large Language Models": {
    "filename": "A Simple and Provable Scaling Law for the Test-Time Compute of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU-Pro"
      ],
      "models": [
        "Llama3.1",
        "Qwen2.5"
      ]
    }
  },
  "Large Language Models and Foundation Models in Smart Agriculture Basics Opportunities and Challenges": {
    "filename": "Large Language Models and Foundation Models in Smart Agriculture Basics Opportunities and Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "Microsoft COCO",
        "PlantCLEF2022"
      ],
      "models": [
        "BERT",
        "GPT-4",
        "SAM",
        "SAA+",
        "SEEM",
        "CLIP",
        "ViT",
        "DALL\u22c5E2",
        "GLIDE",
        "GigaGAN",
        "BLIP",
        "KOSMOS-1",
        "LLAMA",
        "GLaM",
        "GPT-2",
        "GPT-3",
        "Chat-GPT",
        "InstructGPT",
        "Claude 3",
        "Florence",
        "Stable Diffusion",
        "OpenCLIP",
        "OpenFlamingo",
        "Gato",
        "AdA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Aligning Teacher with Student Preferences for Tailored Training Data Generation": {
    "filename": "Aligning Teacher with Student Preferences for Tailored Training Data Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Big-Bench-Hard",
        "PIQA",
        "CommonsenseQA",
        "ARC-Easy",
        "ARC-Challenge",
        "GSM8K"
      ],
      "models": [
        "ARTE",
        "Vanilla Gemma-2B",
        "GPT-4-LLM",
        "Tulu-v2",
        "WizardLM",
        "OpenOrca",
        "Orignal Teacher",
        "Rationale Only",
        "Question Only",
        "Gemma-7B",
        "Qwen1.5-1.8B",
        "CodeGemma-2B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RL-STaR Theoretical Analysis of Reinforcement Learning Frameworks for Self-Taught Reasoner": {
    "filename": "RL-STaR Theoretical Analysis of Reinforcement Learning Frameworks for Self-Taught Reasoner.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT4-o1",
        "STaR",
        "Quiet-STaR",
        "V-STaR",
        "Lean-STaR",
        "STaR-GATE",
        "RL-STaR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LINGOLY A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low-Resource and Extinct Languages": {
    "filename": "LINGOLY A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low-Resource and Extinct Languages.pdf",
    "analysis": {
      "benchmarks": [
        "LINGOLY",
        "MMLU",
        "GSM8K",
        "Winogrande"
      ],
      "models": [
        "Gemma 7B",
        "Llama 2 70B",
        "Llama 3 70B",
        "Aya 23 35B",
        "Mixtral 8x7B",
        "GPT-3.5",
        "GPT-4",
        "GPT-4o",
        "Claude Opus",
        "Gemini 1.5 Pro",
        "Command R+"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Systematic Human Learning and Generalization From a Brief Tutorial With Explanatory Feedback": {
    "filename": "Systematic Human Learning and Generalization From a Brief Tutorial With Explanatory Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "hidden single puzzle"
      ],
      "models": [
        "solvers",
        "non-solvers",
        "persistent-solvers",
        "PD-guessers",
        "valid solvers",
        "unclear solvers"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "REFLECT Summarizing Robot Experiences for Failure Explanation and Correction": {
    "filename": "REFLECT Summarizing Robot Experiences for Failure Explanation and Correction.pdf",
    "analysis": {
      "benchmarks": [
        "RoboFail dataset"
      ],
      "models": [
        "REFLECT",
        "BLIP2 caption",
        "w/o sound",
        "w/o progressive",
        "Subgoal only",
        "LLM summary",
        "w/o explanation"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Computational Experiments Meet Large Language Model Based Agents A Survey and Perspective": {
    "filename": "Computational Experiments Meet Large Language Model Based Agents A Survey and Perspective.pdf",
    "analysis": {
      "benchmarks": [
        "S3 system",
        "GAEA",
        "AgentSims"
      ],
      "models": [
        "AutoGPT",
        "BabyAGI",
        "GenerativeAgents",
        "MetaGPT",
        "CAMEL",
        "AutoGen",
        "AgentVerse",
        "Voyager",
        "ChatEval",
        "CompeteAI"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Step-DPO Step-wise Preference Optimization for Long-chain Reasoning of LLMs": {
    "filename": "Step-DPO Step-wise Preference Optimization for Long-chain Reasoning of LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "AIME",
        "Odyssey-MATH"
      ],
      "models": [
        "Qwen2-72B-Instruct",
        "GPT-4-1106",
        "Claude-3-Opus",
        "Gemini-1.5-Pro",
        "Qwen2-7B-Instruct",
        "Qwen1.5-32B-SFT",
        "DeepSeekMath-Instruct",
        "DeepSeekMath-RL",
        "MathGenieLM-Mistral",
        "MAmmoTH2-Mixtral-8x7B",
        "Llama3-70B-Instruct",
        "Llama3-70B-Step-DPO",
        "Qwen2-7B-Step-DPO",
        "Qwen2-57B-A14B-Step-DPO",
        "Qwen2-72B-Step-DPO",
        "Qwen1.5-32B-Step-DPO",
        "Qwen2-72B-Instruct-Step-DPO",
        "DeepSeekMath-Base-SFT",
        "DeepSeekMath-Base-SFT + Step-DPO",
        "Qwen2-7B-SFT",
        "Qwen2-7B-SFT + Step-DPO",
        "Qwen1.5-32B-SFT + Step-DPO",
        "Qwen2-57B-A14B-SFT + Step-DPO",
        "Llama-3-70B-SFT + Step-DPO",
        "Qwen2-72B-SFT + Step-DPO",
        "Qwen2-72B-Instruct + Step-DPO"
      ]
    }
  },
  "Zero-Shot Visual Reasoning by Vision-Language Models Benchmarking and Analysis": {
    "filename": "Zero-Shot Visual Reasoning by Vision-Language Models Benchmarking and Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "VQAv2",
        "OK-VQA",
        "ScienceQA",
        "CLEVR",
        "PTR",
        "GQA"
      ],
      "models": [
        "Flamingo",
        "BLIP-2",
        "GPT-3.5-Turbo",
        "GPT-4",
        "GPT-4V",
        "BLIP2-Flan-T5",
        "Flan-T5",
        "Flan-T5-XL",
        "Flan-T5-XXL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Fine-tuning LLMs for Autonomous Spacecraft Control A Case Study Using Kerbal Space Program": {
    "filename": "Fine-tuning LLMs for Autonomous Spacecraft Control A Case Study Using Kerbal Space Program.pdf",
    "analysis": {
      "benchmarks": [
        "Kerbal Space Program Differential Games suite (KSPDG)"
      ],
      "models": [
        "GPT-3.5",
        "LLaMA",
        "ChatGPT",
        "Claude",
        "Gemini",
        "Mistral",
        "LLaMA-3-8B"
      ]
    }
  },
  "ConceptThread Visualizing Threaded Concepts in MOOC Videos": {
    "filename": "ConceptThread Visualizing Threaded Concepts in MOOC Videos.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ConceptThread",
        "ConceptScape",
        "VisMOOC",
        "PeakVizor",
        "VisForum",
        "GestureLens",
        "booc.io"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Model-Based Agents for Software Engineering A Survey": {
    "filename": "Large Language Model-Based Agents for Software Engineering A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "BigBench",
        "SySeVR",
        "CWE-Bench-Java",
        "Rnd-300",
        "Sampled syzbot"
      ],
      "models": [
        "Elicitron",
        "SpecGen",
        "Arora et al.",
        "MARE",
        "CodeCoT",
        "CodePlan",
        "AgentCoder",
        "Gentopia",
        "SoA",
        "MapCoder",
        "Parsel",
        "Reflexion",
        "Self-Repair",
        "AutoGen",
        "INTERVENOR",
        "TGen",
        "AutoCoder",
        "CAMEL",
        "Li et al.",
        "DyLAN",
        "SELF-DEBUGGING",
        "SEIDR",
        "\u00b5FiX",
        "AlphaCodium",
        "LDB",
        "LATS",
        "RRR",
        "ToolCoder",
        "SELFEVOLVE",
        "KPC",
        "LEMUR",
        "CODEAGENT",
        "LLM4TDD",
        "CodeAct",
        "CoCoST",
        "InterCode",
        "TOOLGEN",
        "Self-Refine",
        "Flows",
        "MINT",
        "CodeChain",
        "ClarifyGPT",
        "TestPilot",
        "ChatTester",
        "ChatUniTest",
        "TELPA",
        "CoverUp",
        "MuTAP",
        "KernelGPT",
        "WhiteFox",
        "LLM4CBI",
        "GPTDroid",
        "DroidAgent",
        "AXNav",
        "AdbGPT",
        "XUAT-Copilot",
        "RESTSpecIT",
        "UniversalFuzz4All",
        "PentestGPT",
        "Fang et al.",
        "AgentFL",
        "RCAgent",
        "AUTOFL",
        "CodeAgent",
        "Rasheed et al.",
        "ICAA",
        "CORE",
        "ART",
        "GPTLENS",
        "ICAA",
        "E&V",
        "LLM4Vuln",
        "Mao et al.",
        "IRIS",
        "LLIFT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Generating with Confidence Uncertainty Quantification for Black-box Large Language Models": {
    "filename": "Generating with Confidence Uncertainty Quantification for Black-box Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CoQA",
        "TriviaQA",
        "Natural Questions"
      ],
      "models": [
        "OPT",
        "LLaMA",
        "LLaMA2",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AttriPrompter Auto-Prompting with Attribute Semantics for Zero-shot Nuclei Detection via Visual-Language Pre-trained Models": {
    "filename": "AttriPrompter Auto-Prompting with Attribute Semantics for Zero-shot Nuclei Detection via Visual-Language Pre-trained Models.pdf",
    "analysis": {
      "benchmarks": [
        "MoNuSeg",
        "CoNSeP"
      ],
      "models": [
        "AttriPrompter",
        "GLIP",
        "YOLOX",
        "SSNS",
        "PDAM",
        "DARCNN",
        "Freesolo",
        "SOP",
        "PSM",
        "CutLER",
        "VL-PLM",
        "VLDet",
        "MIU-VL",
        "VLPM-NuD",
        "WSPointA",
        "WSPPointA",
        "WSMixedA",
        "WNSeg",
        "Mask-RCNN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SymbolicAI A framework for logic-based approaches combining generative models and solvers": {
    "filename": "SymbolicAI A framework for logic-based approaches combining generative models and solvers.pdf",
    "analysis": {
      "benchmarks": [
        "associative prediction",
        "multi-modal binding",
        "program synthesis",
        "logical components",
        "hierarchical computational graphs"
      ],
      "models": [
        "SymbolicAI",
        "GPT-3.5 Turbo",
        "GPT-4 Turbo",
        "Gemini-Pro",
        "LLaMA2-Chat 13B",
        "LLaMA3-Chat 8B",
        "LLaMA3-Chat 70B",
        "Mistral 7B",
        "Zephyr 7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Textual Aesthetics in Large Language Models": {
    "filename": "Textual Aesthetics in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "AlpacaEval",
        "Arena-Hard",
        "MT-Bench",
        "MMLU"
      ],
      "models": [
        "TAPO",
        "LLaMA-3.1-70B-TAPO",
        "LLaMA-3.1-8B-TAPO",
        "LLaMA-3.1-8B-Instruct",
        "LLaMA-3.1-70B-Instruct",
        "Qwen2-7B-Instruct",
        "Yi-1.5-9B-Chat",
        "Tulu-2-dpo-70B",
        "Qwen2-72B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MindAgent Emergent Gaming Interaction": {
    "filename": "MindAgent Emergent Gaming Interaction.pdf",
    "analysis": {
      "benchmarks": [
        "CUISINE WORLD",
        "Minecraft"
      ],
      "models": [
        "MindAgent",
        "GPT-4",
        "Claude",
        "LLaMA",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "WorkArena How Capable Are Web Agents at Solving Common Knowledge Work Tasks": {
    "filename": "WorkArena How Capable Are Web Agents at Solving Common Knowledge Work Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "WorkArena",
        "BrowserGym",
        "WebArena",
        "MiniWoB",
        "WebShop",
        "Min2Web",
        "WebLINX",
        "WebVoyager"
      ],
      "models": [
        "GPT-4o",
        "GPT-3.5",
        "Llama3",
        "WebGPT",
        "Set-of-Mark",
        "WebVoyager"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cost-Aware Uncertainty Reduction in Schema Matching with GPT-4 The Prompt-Matcher Framework": {
    "filename": "Cost-Aware Uncertainty Reduction in Schema Matching with GPT-4 The Prompt-Matcher Framework.pdf",
    "analysis": {
      "benchmarks": [
        "DeepMDatasets",
        "Fabricated-Datasets"
      ],
      "models": [
        "Prompt-Matcher",
        "GPT-4 with Semantic-match prompt",
        "GPT-4 with Abbreviation-match prompt",
        "BERT",
        "RoBERTa",
        "DistilBERT",
        "DistilRoBERTa",
        "XLNet",
        "MPNet",
        "DeBERTa",
        "Unicorn",
        "Unicorn++"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Investigating Symbolic Capabilities of Large Language Models": {
    "filename": "Investigating Symbolic Capabilities of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM 8K",
        "MATH"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Gemini",
        "Claude",
        "Llamma 2",
        "Llemma",
        "Deepseek",
        "MetaMath"
      ]
    }
  },
  "Chain of Hindsight Aligns Language Models with Feedback": {
    "filename": "Chain of Hindsight Aligns Language Models with Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "TL;DR summarization dataset",
        "Anthropic's Helpful and Harmless (HH) dataset"
      ],
      "models": [
        "Chain of Hindsight (CoH)",
        "Supervised Finetuning (SFT)",
        "SFT with Unlikelihood (SFT-U)",
        "Conditional SFT (C-SFT)",
        "Reinforcement Learning with Human Feedback (RLHF)",
        "GPT-J 6B",
        "OPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Causal Reasoning of Entities and Events in Procedural Texts": {
    "filename": "Causal Reasoning of Entities and Events in Procedural Texts.pdf",
    "analysis": {
      "benchmarks": [
        "CREPE"
      ],
      "models": [
        "GPT-3",
        "Codex",
        "T5",
        "T0",
        "text-curie-001",
        "text-davinci-002",
        "text-davinci-003",
        "ChatGPT",
        "GPT-3 finetuned on StrategyQA",
        "Codex with soft entity representation",
        "Codex with hard entity representation",
        "OpenPI-prompted Codex"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Are Not Robust Multiple Choice Selectors": {
    "filename": "Large Language Models Are Not Robust Multiple Choice Selectors.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "ARC-Challenge",
        "CommonsenseQA"
      ],
      "models": [
        "llama-7B",
        "llama-13B",
        "llama-30B",
        "llama-65B",
        "llama-2-7B",
        "llama-2-13B",
        "llama-2-70B",
        "llama-2-chat-7B",
        "llama-2-chat-13B",
        "llama-2-chat-70B",
        "vicuna-v1.3-7B",
        "vicuna-v1.3-13B",
        "vicuna-v1.3-33B",
        "vicuna-v1.5-7B",
        "vicuna-v1.5-13B",
        "falcon-7B",
        "falcon-40B",
        "falcon-inst-7B",
        "falcon-inst-40B",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EchoNarrator Generating Natural Text Explanations for Ejection Fraction Predictions": {
    "filename": "EchoNarrator Generating Natural Text Explanations for Ejection Fraction Predictions.pdf",
    "analysis": {
      "benchmarks": [
        "EchoNet-Dynamic"
      ],
      "models": [
        "EchoNarrator",
        "EchoNet",
        "EchoGraphs",
        "EchoCoTr-S",
        "GEMTrans",
        "NLE EF GCN",
        "NLE Vol GCN",
        "LLaMA",
        "LLaVA-Med",
        "Mistral"
      ]
    }
  },
  "Boosted Prompt Ensembles for Large Language Models": {
    "filename": "Boosted Prompt Ensembles for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "AQUA",
        "MMLU570",
        "CMATH420",
        "SVAMP"
      ],
      "models": [
        "Boosted Prompting",
        "Self-Consistency",
        "DiVeRSe Bagging",
        "Bagging",
        "Auto CoT + SC",
        "Nonsense Prompt + SC",
        "LMSI",
        "Minerva",
        "Complexity + SC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MATATA A weakly-supervised MAthematical Tool-Assisted reasoning for Tabular Applications": {
    "filename": "MATATA A weakly-supervised MAthematical Tool-Assisted reasoning for Tabular Applications.pdf",
    "analysis": {
      "benchmarks": [
        "FinQA",
        "TAT-QA",
        "TabMWP"
      ],
      "models": [
        "MATATA",
        "GPT-4",
        "ChatGPT",
        "SC-Codex",
        "RoBERTa",
        "Code-LLama-34B",
        "Llama2-70B",
        "Llama2-7B",
        "Llama3-8B",
        "Phi3-mini 3.8B",
        "Ministral-8B"
      ]
    }
  },
  "Towards A Better Metric for Text-to-Video Generation": {
    "filename": "Towards A Better Metric for Text-to-Video Generation.pdf",
    "analysis": {
      "benchmarks": [
        "TVGE"
      ],
      "models": [
        "T2VScore",
        "T2VScore-A",
        "T2VScore-Q",
        "VDM",
        "Make-A-Video",
        "Imagen Video",
        "PYoCo",
        "LVDM",
        "Show-1",
        "Gen-2",
        "Pika",
        "Floor33",
        "ModelScopeT2V",
        "ZeroScope",
        "VideoCrafter",
        "FAST-VQA",
        "DOVER",
        "MaxVQA",
        "CLIP-ResNet-50",
        "CLIP-ViT-Large-14",
        "Otter",
        "Video-LLaMA",
        "mPLUG-OWL2-V",
        "InstructBLIP",
        "mPLUG-OWL2-I",
        "GPT-4V"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Q-Instruct Improving Low-Level Visual Abilities for Multi-Modality Foundation Models": {
    "filename": "Q-Instruct Improving Low-Level Visual Abilities for Multi-Modality Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "LLVisionQA-test",
        "LLVisionQA-dev",
        "KonIQ-10k",
        "SPAQ",
        "LIVE-FB",
        "LIVE-itw",
        "AGIQA-3K",
        "CGIQA-6K",
        "KADID-10K",
        "KonViD-1k"
      ],
      "models": [
        "LLaVA-v1.5-7B",
        "LLaVA-v1.5-7B (Q-Instruct)",
        "LLaVA-v1.5-13B",
        "mPLUG-Owl-2",
        "InternLM-XComposer-VL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Retrieving Evidence from EHRs with LLMs Possibilities and Challenges": {
    "filename": "Retrieving Evidence from EHRs with LLMs Possibilities and Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-III",
        "EHR notes of patients admitted to the Emergency Room of Brigham and Women\u2019s Hospital"
      ],
      "models": [
        "Flan-T5 XXL",
        "Mistral-Instruct",
        "CBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CAMEL Communicative Agents for Mind Exploration of Large Language Model Society": {
    "filename": "CAMEL Communicative Agents for Mind Exploration of Large Language Model Society.pdf",
    "analysis": {
      "benchmarks": [
        "AI Society",
        "Code",
        "Math",
        "Science",
        "Misalignment",
        "HumanEval",
        "HumanEval+"
      ],
      "models": [
        "role-playing",
        "gpt-3.5-turbo",
        "GPT4",
        "LLaMA",
        "CAMEL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multi-stage Large Language Model Correction for Speech Recognition": {
    "filename": "Multi-stage Large Language Model Correction for Speech Recognition.pdf",
    "analysis": {
      "benchmarks": [
        "LibriSpeech",
        "Common Voice",
        "TED-LIUM 3",
        "Multilingual LibriSpeech"
      ],
      "models": [
        "baseline1",
        "baseline2",
        "GPT-J",
        "GPT-3.5",
        "GPT-4",
        "Wav2vec 2.0 Large",
        "Whisper Large-v2"
      ]
    }
  },
  "Reference Trustable Decoding A Training-Free Augmentation Paradigm for Large Language Models": {
    "filename": "Reference Trustable Decoding A Training-Free Augmentation Paradigm for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "ARC",
        "PIQA",
        "Openbook QA",
        "CMMLU"
      ],
      "models": [
        "Baseline",
        "RTD",
        "MH-RTD",
        "ICL",
        "5-Shot RTD",
        "5-Shot MH-RTD",
        "LLaMA2-7B",
        "LLaMA2-70B",
        "LLaMA3-8B",
        "MPT-7B",
        "GLM3-6B",
        "Yi-34B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Answering Questions by Meta-Reasoning over Multiple Chains of Thought": {
    "filename": "Answering Questions by Meta-Reasoning over Multiple Chains of Thought.pdf",
    "analysis": {
      "benchmarks": [
        "STRATEGY QA",
        "FERMI",
        "QUARTZ",
        "HOTPOT QA",
        "2WIKIMQA",
        "BAMBOOGLE",
        "FEVEROUS"
      ],
      "models": [
        "Multi-Chain Reasoning (MCR)",
        "Self-Consistency (SC)",
        "Self-Ask (SA)",
        "Single-Chain Reasoning (SCR)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BYOC Personalized Few-Shot Classification with Co-Authored Class Descriptions": {
    "filename": "BYOC Personalized Few-Shot Classification with Co-Authored Class Descriptions.pdf",
    "analysis": {
      "benchmarks": [
        "Web of Science dataset"
      ],
      "models": [
        "BYOC",
        "Zero-Shot",
        "+ Summary",
        "+ Few-Shot",
        "+ Explanation",
        "+ QA",
        "Fine-tuned"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AcademicGPT Empowering Academic Research": {
    "filename": "AcademicGPT Empowering Academic Research.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "CEval",
        "PubMedQA",
        "SCIEval",
        "ComputerScienceQA"
      ],
      "models": [
        "LLaMA-65B",
        "LLaMA2-70B",
        "ChatGPT",
        "AcademicGPT",
        "GPT-4-Base"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tactics Techniques and Procedures TTPs in Interpreted Malware A Zero-Shot Generation with Large Language Models": {
    "filename": "Tactics Techniques and Procedures TTPs in Interpreted Malware A Zero-Shot Generation with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "dataset with ground truth labels",
        "large dataset in the wild",
        "Backstabber-Knife",
        "Maloss",
        "Mal-PyPI",
        "GitHub Advisory",
        "Snyk.io",
        "Tianwen",
        "DataDog",
        "Phylum",
        "Socket"
      ],
      "models": [
        "GENTTP",
        "LLM-based Chatbot",
        "GPT-4.0",
        "LLaMA2",
        "QWen",
        "Gemini Pro",
        "GPT-3.5",
        "GuardDog",
        "Semgrep",
        "Aura",
        "Snyk Code Test"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Effectively Detecting and Explaining Vulnerabilities Using Large Language Models": {
    "filename": "Towards Effectively Detecting and Explaining Vulnerabilities Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SeVC",
        "DiverseVul"
      ],
      "models": [
        "LLMVulExp",
        "CodeLlama-13B-Instruct",
        "CodeLlama-7B-Instruct",
        "Llama3-8B-Instruct",
        "CodeT5",
        "CodeBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Logic-of-Thought Injecting Logic into Contexts for Full Reasoning in Large Language Models": {
    "filename": "Logic-of-Thought Injecting Logic into Contexts for Full Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ReClor",
        "LogiQA",
        "RuleTaker",
        "ProofWriter",
        "FOLIO"
      ],
      "models": [
        "Logic-of-Thought (LoT)",
        "Chain-of-Thought (CoT)",
        "Self-Consistency (SC)",
        "Chain-of-Thought with Self-Consistency (CoT-SC)",
        "Tree-of-Thoughts (ToT)",
        "SatLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Metaphors We Learn By": {
    "filename": "Metaphors We Learn By.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "GSM8K",
        "something-something"
      ],
      "models": [
        "auto-regressive models",
        "recurrent networks",
        "Decision Transformer",
        "Flamingo",
        "LSTM",
        "Neural Turing Machines",
        "Memory Networks",
        "AlphaCode"
      ]
    }
  },
  "Is GPT-3 a Good Data Annotator": {
    "filename": "Is GPT-3 a Good Data Annotator.pdf",
    "analysis": {
      "benchmarks": [
        "SST2",
        "FewRel",
        "CrossNER",
        "ASTE"
      ],
      "models": [
        "GPT-3",
        "BERT BASE",
        "ChatGPT",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMs as Factual Reasoners Insights from Existing Benchmarks and Beyond": {
    "filename": "LLMs as Factual Reasoners Insights from Existing Benchmarks and Beyond.pdf",
    "analysis": {
      "benchmarks": [
        "SUMM EDITS",
        "FactCC",
        "AggreFact",
        "DialSummEval",
        "XSum",
        "SummEval",
        "Polytope",
        "FRANK",
        "CLIFF",
        "SciTLDR",
        "QMSum",
        "ECTSum",
        "SAMSum",
        "BillSum",
        "Sales Email",
        "Sales Call",
        "Shakespeare Plays",
        "News",
        "Podcast"
      ],
      "models": [
        "GPT-4",
        "Claude V1.3",
        "Bard",
        "QAFactEval",
        "DAE",
        "SummaC",
        "LLaMa-13B",
        "Alpaca-13B",
        "Dolly-v2-12B",
        "MPT-7B-Chat",
        "Vicuna-13B",
        "Cohere-CMD-XL",
        "PaLM2-Bison",
        "Ada001",
        "Babbage001",
        "Curie001",
        "Davinci-001",
        "Davinci-002",
        "Davinci-003",
        "GPT3.5-turbo",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Img2Loc Revisiting Image Geolocalization using Multi-modality Foundation Models and Image-based Retrieval-Augmented Generation": {
    "filename": "Img2Loc Revisiting Image Geolocalization using Multi-modality Foundation Models and Image-based Retrieval-Augmented Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Im2GPS3k",
        "YFCC4k"
      ],
      "models": [
        "Img2Loc",
        "GeoCLIP",
        "GeoGuessNet",
        "Translocator",
        "ISNs (M, f, S 3)",
        "CPlaNet",
        "PlaNet",
        "[L]kNN, \u03c3=4",
        "Img2Loc(LLaVA)",
        "Img2Loc(GPT4V)"
      ]
    }
  },
  "Structure-informed Language Models Are Protein Designers": {
    "filename": "Structure-informed Language Models Are Protein Designers.pdf",
    "analysis": {
      "benchmarks": [
        "CATH 4.2",
        "CATH 4.3",
        "TS50",
        "TS500",
        "multi-chain protein complex dataset",
        "de novo protein dataset",
        "RAbD dataset"
      ],
      "models": [
        "LM-DESIGN",
        "ProteinMPNN",
        "GVP",
        "PiFold",
        "Structured Transformer",
        "GVP-large",
        "GVP-Transformer",
        "ProtMPNN-CMLM",
        "ESM-1b",
        "ESM-2 series",
        "MEAN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Requirements Engineering using Generative AI Prompts and Prompting Patterns": {
    "filename": "Requirements Engineering using Generative AI Prompts and Prompting Patterns.pdf",
    "analysis": {
      "benchmarks": [
        "PROMISE dataset",
        "PURE dataset"
      ],
      "models": [
        "GPT-3.5 turbo"
      ]
    }
  },
  "Integrating Cognitive AI with Generative Models for Enhanced Question Answering in Skill-based Learning": {
    "filename": "Integrating Cognitive AI with Generative Models for Enhanced Question Answering in Skill-based Learning.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Cognitive AI",
        "Generative AI",
        "TMK (Task-Method-Knowledge) model",
        "Large Language Models (LLMs)",
        "GPT-based LLMs",
        "Chain-of-Thought",
        "Iterative Refinement",
        "Ivy"
      ]
    }
  },
  "Generative Design of Functional Metal Complexes Utilizing the Internal Knowledge of Large Language Models": {
    "filename": "Generative Design of Functional Metal Complexes Utilizing the Internal Knowledge of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "1.37M TMC space"
      ],
      "models": [
        "LLM-EO",
        "Genetic Algorithm (GA)",
        "claude-3.5-sonnet",
        "o1-preview",
        "gpt-4o",
        "o1-mini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Teaching Language Models to Hallucinate Less with Synthetic Tasks": {
    "filename": "Teaching Language Models to Hallucinate Less with Synthetic Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "MS MARCO",
        "QMSum",
        "ACI-Bench"
      ],
      "models": [
        "SYNTRA",
        "Vicuna v1.1",
        "Orca",
        "Llama 13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Long-Context Language Models Subsume Retrieval RAG SQL and More": {
    "filename": "Can Long-Context Language Models Subsume Retrieval RAG SQL and More.pdf",
    "analysis": {
      "benchmarks": [
        "LOFT",
        "ArguAna",
        "FEVER",
        "FIQA",
        "MS MARCO",
        "NQ",
        "Quora",
        "SciFact",
        "Touch\u00e9-2020",
        "TopiOCQA",
        "HotPotQA",
        "MuSiQue",
        "QAMPARI",
        "QUEST",
        "Flickr30k",
        "MS COCO",
        "OVEN",
        "MSR-VTT",
        "FLEURS-en",
        "FLEURS-es",
        "FLEURS-fr",
        "FLEURS-hi",
        "FLEURS-zh",
        "Spider",
        "SParC",
        "BBH-date",
        "BBH-salient",
        "BBH-tracking7",
        "BBH-web",
        "LIB-dialogue"
      ],
      "models": [
        "Gemini 1.5 Pro",
        "GPT-4o",
        "Claude 3 Opus",
        "Gecko",
        "CLIP-L/14",
        "PaLM 2 DE",
        "DAIL-SQL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NSP A Neuro-Symbolic Natural Language Navigational Planner": {
    "filename": "NSP A Neuro-Symbolic Natural Language Navigational Planner.pdf",
    "analysis": {
      "benchmarks": [
        "1500 natural language path planning scenarios"
      ],
      "models": [
        "NSP",
        "Zero Shot",
        "0-CoT",
        "Zero Shot+SC",
        "0-CoT+SC"
      ]
    }
  },
  "Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning": {
    "filename": "Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "ARC-C",
        "SciQ",
        "AI2Science",
        "OpenBookQA",
        "CommonSenseQA"
      ],
      "models": [
        "Mistral-7B",
        "Mistral-7B SFT",
        "Math-Shepherd",
        "Self-Taught Reasoner (STaR)",
        "Crystal",
        "Direct Tuning",
        "MCTS Offline-DPO",
        "Instance-level Online-DPO",
        "Ours"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Human-GenAI Value Loop in Human-Centered Innovation Beyond the Magical Narrative": {
    "filename": "The Human-GenAI Value Loop in Human-Centered Innovation Beyond the Magical Narrative.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "DALL-E",
        "J.A.K.E."
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A qualitative assessment of using ChatGPT as large language model for scientific workflow development": {
    "filename": "A qualitative assessment of using ChatGPT as large language model for scientific workflow development.pdf",
    "analysis": {
      "benchmarks": [
        "crisprseq",
        "RS-Star",
        "FORCE2NXF-Rangeland",
        "Grasslands",
        "FORCE"
      ],
      "models": [
        "ChatGPT",
        "HISAT2",
        "Bowtie",
        "Trimmomatic",
        "Cutadapt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias": {
    "filename": "Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias.pdf",
    "analysis": {
      "benchmarks": [
        "Invasion Game With Distraction",
        "Deceptive Invasion Game",
        "Computer Maintenance environment"
      ],
      "models": [
        "Multi-Excitation Projective Simulation (mePS)",
        "(1,1)-agent",
        "(2,1)-agent",
        "(3,1)-agent"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tele-FLM Technical Report": {
    "filename": "Tele-FLM Technical Report.pdf",
    "analysis": {
      "benchmarks": [
        "Open LLM Leaderboard",
        "HumanEval",
        "BIG-Bench Hard",
        "C-Eval",
        "CMMLU",
        "C3",
        "CHID",
        "CSL",
        "ARC",
        "HellaSwag",
        "MMLU",
        "TruthfulQA",
        "WinoGrande",
        "GSM8K"
      ],
      "models": [
        "Tele-FLM",
        "Llama2-70B",
        "DeepSeek-67B",
        "Llama-65B",
        "Llama3-70B",
        "Qwen1.5-72B",
        "GPT-3.5",
        "GPT-4",
        "Llama2-13B",
        "Llama-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving Code Generation by Training with Natural Language Feedback": {
    "filename": "Improving Code Generation by Training with Natural Language Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "Mostly Basic Python Problems (MBPP)"
      ],
      "models": [
        "CODEGEN-MONO 6.1B",
        "\u03c0Refine",
        "\u03c0\u03b8\u2217",
        "InstructGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Opportunities and Challenges of Generative-AI in Finance": {
    "filename": "Opportunities and Challenges of Generative-AI in Finance.pdf",
    "analysis": {
      "benchmarks": [
        "FinQA",
        "ConvFinQA"
      ],
      "models": [
        "BloombergGPT",
        "StockGPT",
        "FinBERT",
        "LLaMa",
        "LLaSA",
        "SaulLM-7B"
      ]
    }
  },
  "Goat Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks": {
    "filename": "Goat Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-bench arithmetic sub-task"
      ],
      "models": [
        "Goat",
        "Goat-7B",
        "GPT-4",
        "PaLM-540B",
        "Bloom",
        "OPT",
        "GPT-NeoX",
        "Pythia"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Effective Prompt Extraction from Language Models": {
    "filename": "Effective Prompt Extraction from Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Unnatural Instructions",
        "ShareGPT",
        "Awesome-ChatGPT-Prompts"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Alpaca-7B",
        "Vicuna 1.3-7B",
        "Vicuna 1.5-7B",
        "Vicuna 1.3-13B",
        "Vicuna 1.5-13B",
        "Vicuna 1.3-33B",
        "Llama-2-chat-7B",
        "Llama-2-chat-13B",
        "Llama-2-chat-70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TeleChat Technical Report": {
    "filename": "TeleChat Technical Report.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "CMMLU",
        "C-Eval",
        "GAOKAO-Bench",
        "AGIEVAL",
        "CSL",
        "EPRSTMT",
        "CHID",
        "GSM8K",
        "Math",
        "HumanEval",
        "CCKS 2020 Knowledge Graph based Q&A"
      ],
      "models": [
        "TeleChat-3B",
        "TeleChat-7B",
        "TeleChat-12B",
        "LLaMA2-7B-chat",
        "LLaMA2-13B-chat",
        "ChatGLM2-6B-chat",
        "ChatGLM3-6B-chat",
        "InternLM-7B-chat",
        "Baichuan2-7B-chat",
        "Baichuan2-13B-chat",
        "Qwen-7B-chat",
        "Qwen-14B-chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BloombergGPT A Large Language Model for Finance": {
    "filename": "BloombergGPT A Large Language Model for Finance.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
    }
  },
  "Chain-of-Action Faithful and Multimodal Question Answering through Large Language Models": {
    "filename": "Chain-of-Action Faithful and Multimodal Question Answering through Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "WebQuestions QA",
        "DATE",
        "General Knowledge",
        "Social QA",
        "Truth QA",
        "Strategy QA",
        "FEVER"
      ],
      "models": [
        "Chain-of-Action (CoA)",
        "Few-shot Prompting",
        "Chain-of-Thought (CoT)",
        "Self Consistency (SC)",
        "Tree of Thought (ToT)",
        "Least-to-Most",
        "Auto-Chain-of-Thought (Auto-CoT)",
        "ToolFormer",
        "Self-Ask",
        "React",
        "SearchChain (SeChain)",
        "DSP"
      ]
    }
  },
  "Diversity Helps Jailbreak Large Language Models": {
    "filename": "Diversity Helps Jailbreak Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Harmbench",
        "Advbench"
      ],
      "models": [
        "GPT-4",
        "Gemini",
        "Llama",
        "GPT-4o",
        "GPT-4o-mini",
        "Mistral-7B",
        "Qwen2-7B",
        "Vicuna-13B",
        "Llama2-7B",
        "GPT-3.5-turbo",
        "Gemini-1.5 Pro",
        "AutoDAN",
        "TAP",
        "PAIR",
        "DAGR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Interactive Planning Using Large Language Models for Partially Observable Robotic Tasks": {
    "filename": "Interactive Planning Using Large Language Models for Partially Observable Robotic Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "IsaacGym",
        "FrankaCubeStack"
      ],
      "models": [
        "LLM-POP",
        "GPT-4",
        "GPT-3.5",
        "Llama2-7B",
        "FT-Vanilla",
        "FT-CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "WISE Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models": {
    "filename": "WISE Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ZsRE",
        "SelfCheckGPT",
        "Temporal",
        "NQ",
        "RedPajama",
        "Pile"
      ],
      "models": [
        "WISE",
        "FT-EWC",
        "DEFER",
        "GRACE",
        "ROME",
        "MEMIT",
        "MEND",
        "SERAC",
        "MEMIT-MASS",
        "FT-L"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Sirens Song in the AI Ocean A Survey on Hallucination in Large Language Models": {
    "filename": "Sirens Song in the AI Ocean A Survey on Hallucination in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BEGIN",
        "QMSum",
        "FENMT",
        "FEQA",
        "HADES",
        "TruthfulQA",
        "FActScore",
        "HaluEval",
        "FACTOR"
      ],
      "models": [
        "OpenAI",
        "Touvron et al.",
        "GPT-3",
        "BERT",
        "LLaMA",
        "ChatGPT",
        "GPT4",
        "InstructGPT",
        "Llama2-Chat",
        "Moss"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CoMM A Coherent Interleaved Image-Text Dataset for Multimodal Understanding and Generation": {
    "filename": "CoMM A Coherent Interleaved Image-Text Dataset for Multimodal Understanding and Generation.pdf",
    "analysis": {
      "benchmarks": [
        "MMC4",
        "OBELICS",
        "COCO",
        "Flickr30k",
        "VQAv2",
        "OKVQA",
        "TextVQA",
        "VizWiz",
        "HatefulMemes"
      ],
      "models": [
        "CoMM",
        "GPT-4",
        "Stable Diffusion XL",
        "Emu2",
        "MiniGPT-5",
        "SEED-Llama",
        "Open-Flamingo 9B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reasoning Circuits Few-shot Multi-hop Question Generation with Structured Rationales": {
    "filename": "Reasoning Circuits Few-shot Multi-hop Question Generation with Structured Rationales.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD",
        "HotpotQA"
      ],
      "models": [
        "Reasoning Circuits",
        "ASs2s-a",
        "SemQG",
        "F+R+A",
        "SGGDQ-DP",
        "ADDQG",
        "QA4QG-Large",
        "Cheng et al. (2021)",
        "MultiQG",
        "GATENLL+CT",
        "LowResourceQG",
        "QA4QG-Base",
        "T5-3b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization": {
    "filename": "Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization.pdf",
    "analysis": {
      "benchmarks": [
        "VisSpeech",
        "How2",
        "ASCEND",
        "SEAME",
        "CoV oST2",
        "MuST-C V1",
        "Libri-Trans"
      ],
      "models": [
        "Whisper",
        "Whisper Tiny",
        "Whisper Tiny.en",
        "Whisper Base",
        "Whisper Base.en",
        "Whisper Small",
        "Whisper Small.en",
        "Whisper Medium",
        "Whisper Medium.en",
        "Whisper Large",
        "Whisper LargeV2",
        "SotA supervised models",
        "w2v2+mBART",
        "E2E Transformer",
        "Chung et al.",
        "Cascaded",
        "Escolano et al.",
        "T-Modules"
      ]
    }
  },
  "Negotiating with LLMS Prompt Hacks Skill Gaps and Reasoning Deficits": {
    "filename": "Negotiating with LLMS Prompt Hacks Skill Gaps and Reasoning Deficits.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT Turbo 3.5",
        "Google's Bard"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Elephants Never Forget Testing Language Models for Memorization of Tabular Data": {
    "filename": "Elephants Never Forget Testing Language Models for Memorization of Tabular Data.pdf",
    "analysis": {
      "benchmarks": [
        "IRIS",
        "Wine",
        "Kaggle Titanic",
        "OpenML Diabetes",
        "Adult Income",
        "California Housing",
        "Scikit Diabetes",
        "FICO HELIOCv1",
        "Spaceship Titanic",
        "Pneumonia"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Gradient Boosted Tree",
        "Logistic Regression"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Agent Security Bench ASB Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents": {
    "filename": "Agent Security Bench ASB Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Agent Security Bench (ASB)"
      ],
      "models": [
        "Gemma2-9B",
        "Gemma2-27B",
        "LLaMA3-8B",
        "LLaMA3-70B",
        "LLaMA3.1-8B",
        "LLaMA3.1-70B",
        "Mixtral-8x7B",
        "Qwen2-7B",
        "Qwen2-72B",
        "Claude3.5 Sonnet",
        "GPT-3.5 Turbo",
        "GPT-4o",
        "GPT-4o-mini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Instruction Tuning with GPT-4": {
    "filename": "Instruction Tuning with GPT-4.pdf",
    "analysis": {
      "benchmarks": [
        "User-Oriented-Instructions-252",
        "Vicuna-Instructions-80",
        "Unnatural Instructions"
      ],
      "models": [
        "LLaMA-GPT4",
        "LLaMA-GPT4-CN",
        "GPT-4",
        "GPT-3.5",
        "OPT-IML",
        "Alpaca",
        "Vicuna",
        "ChatGPT",
        "Bard"
      ]
    }
  },
  "EvEval A Comprehensive Evaluation of Event Semantics for Large Language Models": {
    "filename": "EvEval A Comprehensive Evaluation of Event Semantics for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "EVEVAL",
        "DTFit",
        "HardSim",
        "ECARE",
        "TRACIE",
        "TIMETRAVEL",
        "SocialIQA",
        "MCNC",
        "SCT"
      ],
      "models": [
        "LLAMA",
        "BLOOM",
        "GPT",
        "ChatGPT",
        "BLOOMZ",
        "Flan-T5"
      ]
    }
  },
  "RQ-RAG Learning to Refine Queries for Retrieval Augmented Generation": {
    "filename": "RQ-RAG Learning to Refine Queries for Retrieval Augmented Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Arc-Challenge",
        "PopQA",
        "OpenbookQA",
        "HotpotQA",
        "2WikiMultiHopQA",
        "Musique"
      ],
      "models": [
        "RQ-RAG",
        "Llama2-7B",
        "Llama2-7B-Chat",
        "SAIL-7B",
        "Self-RAG-7B",
        "Chain-of-Thought",
        "Chain-of-Note",
        "GPT-3.5-TURBO",
        "GPT-4"
      ]
    }
  },
  "Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model": {
    "filename": "Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "FOLIO",
        "ReClor",
        "HumanEval",
        "MBPP"
      ],
      "models": [
        "SWAP",
        "Zero-shot CoT",
        "Few-shot CoT",
        "SFT-CoT",
        "Self-consistency",
        "ToT",
        "RAP",
        "PRM (PRM800K*)",
        "PRM (Math-Shepherd)",
        "SWAP (w/o discriminator)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ArgMed-Agents Explainable Clinical Decision Reasoning with LLM Disscusion via Argumentation Schemes": {
    "filename": "ArgMed-Agents Explainable Clinical Decision Reasoning with LLM Disscusion via Argumentation Schemes.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "PubMedQA"
      ],
      "models": [
        "ArgMed-Agents",
        "GPT-3.5-turbo",
        "GPT-4",
        "Chain of Thought (CoT)"
      ]
    }
  },
  "Online Joint Fine-tuning of Multi-Agent Flows": {
    "filename": "Online Joint Fine-tuning of Multi-Agent Flows.pdf",
    "analysis": {
      "benchmarks": [
        "Musique",
        "Musique-Answerable",
        "Musique-Full"
      ],
      "models": [
        "Flow",
        "Mistral-7B-Instruct-v0.2",
        "Meta-Llama-3-8B-Instruct",
        "Qwen1.5-32B-Chat",
        "Phi-3-medium-128k-instruct",
        "Lora"
      ]
    }
  },
  "MIND Math Informed syNthetic Dialogues for Pretraining LLMs": {
    "filename": "MIND Math Informed syNthetic Dialogues for Pretraining LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "GSM 8K",
        "MATH",
        "MMLU",
        "MMLU-STEM",
        "GENERAL REASONING",
        "ARC easy (ARC-E)",
        "ARC challenge (ARC-C)",
        "PIQA",
        "SIQA",
        "HellaSwag",
        "WinoGrande",
        "OpenBookQA",
        "TruthfulQA",
        "CommonsenseQA",
        "RACE"
      ],
      "models": [
        "MIND-OWM",
        "OWM-4B",
        "OWM-14B",
        "MIND-OWM-4B",
        "MIND-OWM-14B",
        "LLAMA3-70B-INSTRUCT",
        "DEEPSEEKMATH",
        "MATHPILE",
        "MIND-MATHPILE",
        "Rephrase-OWM-4B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LIDA A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models": {
    "filename": "LIDA A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "vega datasets"
      ],
      "models": [
        "LIDA",
        "OpenAI gpt-3.5-turbo-x",
        "text-conditioned image generation models",
        "diffusion models",
        "Peacasso library"
      ]
    }
  },
  "Towards Dataset-Scale and Feature-Oriented Evaluation of Text Summarization in Large Language Model Prompts": {
    "filename": "Towards Dataset-Scale and Feature-Oriented Evaluation of Text Summarization in Large Language Model Prompts.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Awesum"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FakeBench Probing Explainable Fake Image Detection via Large Multimodal Models": {
    "filename": "FakeBench Probing Explainable Fake Image Detection via Large Multimodal Models.pdf",
    "analysis": {
      "benchmarks": [
        "FakeBench",
        "FakeClass",
        "FakeClue",
        "FakeQA",
        "ImageNet",
        "DIV2K",
        "CNNSpot",
        "HPS v2",
        "AGIQA-3K",
        "GenImage",
        "NIGHTS",
        "I2IQA",
        "DiffusionDB",
        "DALL\u00b7E3 dataset",
        "Dalle3-reddit-dataset",
        "Midjourney-v5 dataset"
      ],
      "models": [
        "FakeBench",
        "Large Multimodal Models (LMMs)",
        "GPT-4V",
        "mPLUG-Owl2",
        "GeminiPro",
        "Q-Instruct",
        "InternLM-XC.2-vl",
        "InstructBLIP",
        "LLaVA-v1.5",
        "Qwen-VL",
        "Claude3 Sonnet",
        "Claude3 Haiku",
        "Otter",
        "Visual-GLM",
        "IDEFICS-Instruct",
        "Kosmos-2",
        "CNNSpot",
        "Gram-Net",
        "FreDect",
        "PSM",
        "LGrad",
        "UnivDF"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception": {
    "filename": "Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception.pdf",
    "analysis": {
      "benchmarks": [
        "DimEval",
        "Math23k",
        "Ape210k",
        "N-Math23k",
        "N-Ape210k",
        "Q-Math23k",
        "Q-Ape210k"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5-Turbo",
        "InstructGPT",
        "PaLM-2",
        "LLaMa-2",
        "OpenChat",
        "Flan-T5",
        "T0++",
        "ChatGLM-2",
        "DimPerc",
        "BertGen",
        "LLaMa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Retaining Key Information under High Compression Ratios Query-Guided Compressor for LLMs": {
    "filename": "Retaining Key Information under High Compression Ratios Query-Guided Compressor for LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "NaturalQuestions",
        "TriviaQA",
        "HotpotQA",
        "SST-2",
        "GSM8K"
      ],
      "models": [
        "Query-Guided Compressor (QGC)",
        "LongLLMLingua",
        "AutoCompressor",
        "ICAE",
        "Sentence-BERT",
        "BGE-Reranker",
        "Cond.PPL",
        "Selective-Context",
        "LLaMA-2-7B",
        "LongChat-13B-16K"
      ]
    }
  },
  "Large Language Model Cascades with Mixture of Thoughts Representations for Cost-efficient Reasoning": {
    "filename": "Large Language Model Cascades with Mixture of Thoughts Representations for Cost-efficient Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "ASDIV",
        "TabMWP",
        "BIG-Bench Hard",
        "DATE",
        "Navigate",
        "CREPE"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4",
        "CoT-1D-Vote",
        "PoT-1D-Vote",
        "MoT-1D-Vote",
        "CoT-2D-Vote",
        "PoT-2D-Vote",
        "MoT-2D-Vote",
        "CoT-2D-Verify",
        "PoT-2D-Verify",
        "MoT-1D-Verify",
        "MoT-2D-Verify",
        "GPT-3.5-CoT-SC",
        "GPT-3.5-PoT-SC",
        "GPT-4-CoT-Greedy",
        "GPT-4-PoT-Greedy",
        "GPT-4-CoT-SC",
        "GPT-4-PoT-SC",
        "LLM-Q",
        "LLM-QA",
        "Finetuned-Q",
        "Finetuned-QA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FERMAT An Alternative to Accuracy for Numerical Reasoning": {
    "filename": "FERMAT An Alternative to Accuracy for Numerical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "FERMAT",
        "GSM8K",
        "LILA",
        "Dolphin18K",
        "DeepMind Mathematics",
        "AQUA",
        "McTaco",
        "DROP",
        "MAWPS",
        "CommonCore",
        "Illinois",
        "NumGLUE"
      ],
      "models": [
        "Minerva",
        "T0",
        "FLAN-XL",
        "BHASKARA",
        "FLAN-large",
        "FLAN-base",
        "T5-base",
        "BART-base",
        "NT5",
        "GenBERT",
        "GPT3",
        "PaLM",
        "Codex"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Jais and Jais-chat Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models": {
    "filename": "Jais and Jais-chat Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
    }
  },
  "Are Large Language Models Ready for Healthcare A Comparative Study on Clinical Language Understanding": {
    "filename": "Are Large Language Models Ready for Healthcare A Comparative Study on Clinical Language Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "NCBI-Disease",
        "BC5CDR-Chemical",
        "i2b2 2010-Relation",
        "SemEval 2013-DDI",
        "BIOSSES",
        "MedNLI",
        "i2b2 2006-Smoking",
        "bioASQ 10b-Factoid"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Bard",
        "self-questioning prompting (SQP)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How well do Large Language Models perform in Arithmetic tasks": {
    "filename": "How well do Large Language Models perform in Arithmetic tasks.pdf",
    "analysis": {
      "benchmarks": [
        "MATH 401"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "InstructGPT",
        "Galactica",
        "LLaMA",
        "CodeX",
        "OPT",
        "GPT-Neox",
        "GLM",
        "BloomZ",
        "Bloom",
        "T0++",
        "Flan-T5",
        "text-davinci-003",
        "code-davinci-002",
        "text-curie-001",
        "text-babbage-001",
        "galactica-120b",
        "galactica-30b",
        "galactica-6.7b",
        "llama-65b",
        "llama-30b",
        "llama-13b",
        "llama-7b",
        "opt-175b",
        "opt-66b",
        "opt-iml-max-30b",
        "opt-30b",
        "opt-13b",
        "opt-6.7b",
        "gpt-neox-20b",
        "gpt-j-6b",
        "bloomz-7b1",
        "bloom-7b1",
        "bloomz-3b",
        "bloom-3b",
        "bloomz-1b7",
        "bloom-1b7",
        "glm-10b",
        "flan-t5-xxl-11b",
        "flan-t5-xl-3b",
        "flan-t5-large-780m",
        "flan-t5-base-250m"
      ]
    }
  },
  "STALL Boosting LLM-based Repository-level Code Completion with Static Analysis": {
    "filename": "STALL Boosting LLM-based Repository-level Code Completion with Static Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "CrossCodeEval",
        "HumanEval",
        "MBPP",
        "RepoEval"
      ],
      "models": [
        "STALL+",
        "DeepSeek-Coder-6.7B",
        "StarCoderBase-7B",
        "CodeLlama-7B",
        "RepoCoder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The SocialAI School Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents": {
    "filename": "The SocialAI School Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents.pdf",
    "analysis": {
      "benchmarks": [
        "SiQA",
        "ToMi"
      ],
      "models": [
        "SocialAI",
        "RL agents",
        "LLMs"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Transcending Scaling Laws with 01 Extra Compute": {
    "filename": "Transcending Scaling Laws with 01 Extra Compute.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-Bench",
        "GSM8K",
        "MGSM",
        "TydiQA",
        "MMLU",
        "SuperGLUE",
        "TriviaQA",
        "Natural Questions",
        "Lambada",
        "BoolQ",
        "PIQA",
        "HellaSwag",
        "Winogrande",
        "ANLI",
        "OpenbookQA",
        "RaceM",
        "RaceH",
        "ArcE",
        "ArcC",
        "ReCORD",
        "COPA",
        "RTE",
        "WIC",
        "WSC",
        "CB",
        "MultiRC",
        "StoryCloze",
        "SquadV2",
        "StrategyQA",
        "CommonsenseQA",
        "BBH"
      ],
      "models": [
        "PaLM",
        "U-PaLM",
        "UL2R",
        "Minerva",
        "Chinchilla",
        "Gopher"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AgentVerse Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors": {
    "filename": "AgentVerse Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors.pdf",
    "analysis": {
      "benchmarks": [
        "FED",
        "Commongen Challenge",
        "MGSM",
        "Logic Grid Puzzles",
        "Humaneval"
      ],
      "models": [
        "AGENT VERSE",
        "CoT",
        "Solo",
        "Group",
        "GPT-3.5-Turbo",
        "GPT-4",
        "ReAct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GlitchBench Can Large Multimodal Models Detect Video Game Glitches": {
    "filename": "GlitchBench Can Large Multimodal Models Detect Video Game Glitches.pdf",
    "analysis": {
      "benchmarks": [
        "Glitch Bench",
        "VQAv2",
        "OK-VQA",
        "AI2D",
        "SEED-Bench",
        "POPE",
        "MMBench"
      ],
      "models": [
        "GPT-4V",
        "LLaVA-1.5-7B",
        "LLaVA-1.5-13B",
        "SPHINX-7B",
        "SPHINX-13B",
        "InstructBLIP-7B",
        "InstructBLIP-13B",
        "Qwen-VL-Chat",
        "MiniGPT-v2",
        "OtterHD",
        "Fuyo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Auto-Regressive Next-Token Predictors are Universal Learners": {
    "filename": "Auto-Regressive Next-Token Predictors are Universal Learners.pdf",
    "analysis": {
      "benchmarks": [
        "TinyStories"
      ],
      "models": [
        "linear next-token predictor",
        "shallow Multi-Layer Perceptron (MLP)",
        "Goat",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Requirements are All You Need From Requirements to Code with LLMs": {
    "filename": "Requirements are All You Need From Requirements to Code with LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "SuperFrog Scheduler"
      ],
      "models": [
        "tailored LLM",
        "Software Engineer GPT",
        "ChatGPT"
      ]
    }
  },
  "Prompt Risk Control A Rigorous Framework for Responsible Deployment of Large Language Models": {
    "filename": "Prompt Risk Control A Rigorous Framework for Responsible Deployment of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MBPP code generation dataset",
        "Anthropic Helpfulness and Harmlessness (HH) dataset",
        "MeQSum dataset",
        "Anthropic Red Team dataset"
      ],
      "models": [
        "GPT-4",
        "LLaMA",
        "Claude",
        "CodeLlama-7b",
        "Flan-T5-XXL",
        "Falcon Instruct model (40B parameter version)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chat-Edit-3D Interactive 3D Scene Editing via Text Prompts": {
    "filename": "Chat-Edit-3D Interactive 3D Scene Editing via Text Prompts.pdf",
    "analysis": {
      "benchmarks": [
        "LLFF",
        "NeRF-Art",
        "IN2N-collect",
        "IBRNet-collect",
        "TanksAndTemple",
        "CE3D-collect"
      ],
      "models": [
        "CE3D",
        "IN2N",
        "Gaussian-Editor",
        "DN2N",
        "TensoRF",
        "Gaussian-Splatting",
        "VQA",
        "Image Generation",
        "Image Caption",
        "Super-Resolution",
        "Text-driven Stylize",
        "Image-driven Stylize",
        "Segmentation",
        "ControlNet"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Parameter-Efficient Tuning Helps Language Model Alignment": {
    "filename": "Parameter-Efficient Tuning Helps Language Model Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "Anthropic/HH-RLHF",
        "OpenAI/Summary"
      ],
      "models": [
        "MEET",
        "Chain-of-Hindsight (CoH)",
        "Direct Preference Optimization (DPO)",
        "GPT-Neo 1.3B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation": {
    "filename": "Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation.pdf",
    "analysis": {
      "benchmarks": [
        "WebQuestions",
        "PathQuestions",
        "GrailQA"
      ],
      "models": [
        "KQG-CoT",
        "KQG-CoT+",
        "Standard Prompt",
        "Random-CoT",
        "Manual-CoT",
        "Active-CoT",
        "Auto-CoT",
        "L2A",
        "Transformer",
        "MHQG",
        "BiGraph2Seq",
        "T5-Large",
        "JointGT",
        "IGND",
        "LFKQG",
        "DSM",
        "AutoQGS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Look Before You Leap Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models": {
    "filename": "Look Before You Leap Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "SingleEq",
        "SVAMP",
        "AQuA",
        "GSMIC-1k"
      ],
      "models": [
        "GPT-3.5",
        "ChatGPT",
        "LLama2 7B-hf-chat",
        "LLama2 13B-hf-chat",
        "Mistral-7B Instruct-v0.2",
        "Mistral-8x7B Instruct-v0.1",
        "text-davinci-003",
        "gpt-3.5-turbo-0125",
        "Chain-of-Thoughts (CoT)",
        "Program-of-Thoughts (PoT)",
        "Least-to-Most (L2M)",
        "Plan-and-Solve (PaS)",
        "Self-ask",
        "IRR-INST"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Emerging Synergies in Causality and Deep Generative Models A Survey": {
    "filename": "Emerging Synergies in Causality and Deep Generative Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "CelebA",
        "MNIST",
        "ImageNet",
        "Adult",
        "Census",
        "Cabs",
        "Loan",
        "News",
        "Kings",
        "Credit",
        "Pendulum",
        "ObjectNet",
        "ImageNet-C",
        "ImageNet-V2",
        "FFHQ",
        "Morpho-MNIST",
        "brain MRI scans",
        "Chest X-ray",
        "YELP",
        "BIOS corpus",
        "BraTS",
        "Tubingen cause-effect",
        "EEG",
        "Sachs",
        "cancer genome",
        "PACS",
        "OfficeHome",
        "Neuropathic pain",
        "e-CARE",
        "COPA",
        "EventStoryLine",
        "Causal-TimeBank",
        "MAVEN-ERE",
        "Asia",
        "CHILD",
        "Insurance",
        "corr2cause",
        "cladder"
      ],
      "models": [
        "GANs",
        "VAEs",
        "Normalizing flows",
        "Diffusion Models",
        "CausalGAN",
        "CGN",
        "CausalTGAN",
        "CFGAN",
        "DECAF",
        "DEAR",
        "GenInt",
        "PKD",
        "CausalVAE",
        "CounterfactualMS",
        "VACA",
        "Causal-gen",
        "Diff-SCM",
        "CDPM",
        "CAREFL",
        "DiffAN",
        "OCDaf",
        "GCIT",
        "SAM",
        "DeepSCM",
        "BGM",
        "DCM",
        "GANITE",
        "SCIGAN",
        "iMSDA",
        "iStyleGAN",
        "Hobbhahn et al.",
        "Zhang et al.",
        "Nick et al.",
        "K\u0131c\u0131man et al.",
        "Gao et al.",
        "LMPriors",
        "Long et al.",
        "Ban et al.",
        "Matej et al.",
        "Jin et al."
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "UFO A UI-Focused Agent for Windows OS Interaction": {
    "filename": "UFO A UI-Focused Agent for Windows OS Interaction.pdf",
    "analysis": {
      "benchmarks": [
        "WindowsBench"
      ],
      "models": [
        "UFO",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reflection of Thought Inversely Eliciting Numerical Reasoning in Language Models via Solving Linear Systems": {
    "filename": "Reflection of Thought Inversely Eliciting Numerical Reasoning in Language Models via Solving Linear Systems.pdf",
    "analysis": {
      "benchmarks": [
        "DROP",
        "AddSub",
        "MultiArith",
        "MathExp"
      ],
      "models": [
        "GPT-3",
        "T5",
        "BART",
        "TAPEX",
        "POET-SQL",
        "NumNet",
        "NeRd",
        "MTMSN",
        "QDGAT",
        "PaLM"
      ]
    }
  },
  "LLMatDesign Autonomous Materials Discovery with Large Language Models": {
    "filename": "LLMatDesign Autonomous Materials Discovery with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Materials Project"
      ],
      "models": [
        "LLMatDesign",
        "GPT-4o",
        "Gemini-1.0-pro",
        "random baseline"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatGPT Exhibits Gender and Racial Biases in Acute Coronary Syndrome Management": {
    "filename": "ChatGPT Exhibits Gender and Racial Biases in Acute Coronary Syndrome Management.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT3.5"
      ]
    }
  },
  "LASER Script Execution by Autonomous Agents for On-demand Traffic Simulation": {
    "filename": "LASER Script Execution by Autonomous Agents for On-demand Traffic Simulation.pdf",
    "analysis": {
      "benchmarks": [
        "CARLA simulator"
      ],
      "models": [
        "LASER",
        "InterFuser",
        "LLM-controlled agents",
        "GPT-4o"
      ]
    }
  },
  "Large Language Model based Multi-Agents A Survey of Progress and Challenges": {
    "filename": "Large Language Model based Multi-Agents A Survey of Progress and Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "SoftwareDev",
        "RoCoBench",
        "Communicative Watch-And-Help (C-WAH)",
        "ThreeDWorld Multi-Agent Transport (TDW-MAT)",
        "HM3D v0.2",
        "MMLU",
        "MedQA",
        "PubMedQA",
        "GSM8K",
        "StrategyQA",
        "Chess Move Validity",
        "SOTOPIA",
        "Gender Discrimination",
        "Nuclear Energy",
        "Werewolf",
        "Avalon",
        "Welfare Diplomacy",
        "Layout in the Overcooked-AI environment",
        "Chameleon",
        "Undercover",
        "Ultimatum Game TE",
        "Garden Path TE",
        "Wisdom of Crowds TE",
        "MovieLens-1M",
        "Amazon review dataset",
        "Board Connectivity Evaluation"
      ],
      "models": [
        "MetaGPT",
        "CAMEL",
        "Autogen",
        "RoCo",
        "CoELA",
        "CoNavGPT",
        "ProAgent",
        "WarAgent",
        "Agent4Rec"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Controllable Navigation Instruction Generation with Chain of Thought Prompting": {
    "filename": "Controllable Navigation Instruction Generation with Chain of Thought Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "R2R",
        "REVERIE",
        "RxR",
        "UrbanWalk"
      ],
      "models": [
        "C-Instructor",
        "BT-speaker",
        "EDrop-speaker",
        "CCC-speaker",
        "Lana",
        "HAMT",
        "DUET"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SynArtifact Classifying and Alleviating Artifacts in Synthetic Images via Vision-Language Model": {
    "filename": "SynArtifact Classifying and Alleviating Artifacts in Synthetic Images via Vision-Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "SynArtifact-1K",
        "ImageNet",
        "MSCOCO",
        "DrawBench",
        "ImageReward",
        "Midjourney",
        "DALLE-3"
      ],
      "models": [
        "Vision-Language Model (VLM)",
        "fine-tuned VLM",
        "baseline VLM",
        "diffusion model",
        "refined diffusion model",
        "Stable Diffusion v2.1",
        "Stable Diffusion v1.0",
        "Stable Diffusion v1.4",
        "Stable Diffusion v1.5",
        "Stable Diffusion v2.0",
        "Stable Diffusion",
        "LLaVA-v1.5",
        "LLaVA-v1.5-7B"
      ]
    }
  },
  "Causal Interventions on Causal Paths Mapping GPT-2s Reasoning From Syntax to Semantics": {
    "filename": "Causal Interventions on Causal Paths Mapping GPT-2s Reasoning From Syntax to Semantics.pdf",
    "analysis": {
      "benchmarks": [
        "syntactical dataset",
        "semantic dataset"
      ],
      "models": [
        "GPT-2 small"
      ]
    }
  },
  "Mind Your Step by Step Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse": {
    "filename": "Mind Your Step by Step Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse.pdf",
    "analysis": {
      "benchmarks": [
        "Implicit Statistical Learning (ISL)",
        "Face Recognition (FR)",
        "Classification of Data with Exceptions (CDE)",
        "Natural Language Inference (NLI)",
        "Spatial Intuitions (SI)",
        "Working Memory (WM)",
        "Stanford Natural Language Inference (SNLI)",
        "Multi-Genre Natural Language Inference (MNLI)"
      ],
      "models": [
        "OpenAI o1-preview",
        "GPT-4o",
        "Claude 3.5 Sonnet",
        "Claude 3 Opus",
        "Gemini 1.5 Pro",
        "Llama 3.1 70B Instruct",
        "Llama 3 70B Instruct",
        "Llama 3.1 8B Instruct",
        "Llama 3 8B Instruct",
        "InternVL2 26B",
        "InternVL2 Llama3 76B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Qwen Technical Report": {
    "filename": "Qwen Technical Report.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "HumanEvalPack",
        "GSM8K",
        "MATH",
        "MMLU",
        "C-Eval",
        "BBH"
      ],
      "models": [
        "QWEN",
        "QWEN-CHAT",
        "QWEN-CHAT-RLHF",
        "CODE-QWEN",
        "CODE-QWEN-CHAT",
        "MATH-QWEN-CHAT",
        "QWEN-VL",
        "QWEN-VL-CHAT",
        "QWEN-1.8B",
        "QWEN-7B",
        "QWEN-14B",
        "QWEN-CHAT-1.8B",
        "QWEN-CHAT-7B",
        "QWEN-CHAT-14B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ASSISTGUI Task-Oriented Desktop Graphical User Interface Automation": {
    "filename": "ASSISTGUI Task-Oriented Desktop Graphical User Interface Automation.pdf",
    "analysis": {
      "benchmarks": [
        "ASSIST GUI"
      ],
      "models": [
        "Actor-Critic Embodied Agent (ACE)",
        "CoT",
        "ReAct",
        "GPT-4",
        "GPT-3.5",
        "Llama2",
        "Qwen-VL-Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models": {
    "filename": "Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "COVID-19 pandemic dataset",
        "US Capitol insurrection dataset",
        "Russian invasion of Ukraine dataset",
        "Perspective API",
        "Azure Text Moderation",
        "IBM Toxic Comment Classifier",
        "Clarifai Text Moderation"
      ],
      "models": [
        "HATEGUARD",
        "BERT-base",
        "Tweet-NLP",
        "GPT-4",
        "KeyBERT",
        "Meta-EFL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BioPlanner Automatic Evaluation of LLMs on Protocol Planning in Biology": {
    "filename": "BioPlanner Automatic Evaluation of LLMs on Protocol Planning in Biology.pdf",
    "analysis": {
      "benchmarks": [
        "BIOPROT"
      ],
      "models": [
        "GPT-3",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoStudio Crafting Consistent Subjects in Multi-turn Interactive Image Generation": {
    "filename": "AutoStudio Crafting Consistent Subjects in Multi-turn Interactive Image Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CMIGBench"
      ],
      "models": [
        "AutoStudio",
        "AutoStory",
        "TaleCrafter",
        "StoryDiffusion",
        "Mini-Gemini",
        "Mini DALL\u00b7E 3",
        "TheaterGen",
        "SEED-LLAMA",
        "Intelligent Grimm",
        "MiniGPT-5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Clover Closed-Loop Verifiable Code Generation": {
    "filename": "Clover Closed-Loop Verifiable Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CloverBench",
        "MBPP-DFY-50"
      ],
      "models": [
        "Clover",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Large Language Models on Spatial Tasks A Multi-Task Benchmarking Study": {
    "filename": "Evaluating Large Language Models on Spatial Tasks A Multi-Task Benchmarking Study.pdf",
    "analysis": {
      "benchmarks": [
        "C-Eval",
        "C-Eval Hard",
        "SuperCLUE",
        "AGIEval",
        "MMLU",
        "OpenCompass"
      ],
      "models": [
        "gpt-3.5-turbo",
        "gpt-4o",
        "gpt-4-turbo-2024-04-09",
        "claude-3-sonnet-20240229",
        "moonshot-v1-8k",
        "glm-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SEAL SEmantic-Augmented Imitation Learning via Language Model": {
    "filename": "SEAL SEmantic-Augmented Imitation Learning via Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "KeyDoor",
        "Grid-World"
      ],
      "models": [
        "SEAL",
        "Behavioral Cloning (BC)",
        "LISA",
        "SDIL",
        "Thought Cloning (TC)",
        "SEAL-L"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reward-RAG Enhancing RAG with Reward Driven Supervision": {
    "filename": "Reward-RAG Enhancing RAG with Reward Driven Supervision.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Questions (NQ)",
        "TriviaQA",
        "FEVER",
        "PubMedQA",
        "BioASQ",
        "MMLU-med",
        "MedMCQA",
        "MedQA"
      ],
      "models": [
        "Reward-RAG",
        "RAG",
        "CriticGPT",
        "SPLADE++",
        "Promptgator",
        "Contriever",
        "Dragon",
        "Gte-large-v1.5",
        "Bge-large-v1.5",
        "E5-large-unsupervised",
        "UAE-large-v1",
        "Mixtral-8x22B-Instruct",
        "PaLM2",
        "GPT-3.5-turbo",
        "GPT-4",
        "Atlas",
        "Raven",
        "Self-RAG",
        "RECOMP",
        "RePlug",
        "RA-DIT",
        "Llama3-ChatQA-1.5",
        "Llama3-RankRAG",
        "PMC-llama 13B",
        "Llama2 70B",
        "Mixtral 8*7B",
        "Meditron 70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EvoPrompting Language Models for Code-Level Neural Architecture Search": {
    "filename": "EvoPrompting Language Models for Code-Level Neural Architecture Search.pdf",
    "analysis": {
      "benchmarks": [
        "MNIST-1D",
        "CLRS Algorithmic Reasoning Benchmark"
      ],
      "models": [
        "EVOPROMPTING",
        "GRU",
        "CNN",
        "MLP",
        "Triplet-GMPNN",
        "QUADNODEMINMAX",
        "MAXMEAN",
        "CONCAT REP",
        "DIV2MEAN",
        "TANH EXPAND TRIPLETS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Harms from Increasingly Agentic Algorithmic Systems": {
    "filename": "Harms from Increasingly Agentic Algorithmic Systems.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can 3D Vision-Language Models Truly Understand Natural Language": {
    "filename": "Can 3D Vision-Language Models Truly Understand Natural Language.pdf",
    "analysis": {
      "benchmarks": [
        "3D Language Robustness Dataset",
        "ScanRefer",
        "NR3D",
        "ScanQA",
        "3D-LR",
        "SQA3D",
        "Multi3Drefer",
        "Open Assistant"
      ],
      "models": [
        "3D-LLM",
        "ScanRefer",
        "MVT",
        "Referit3D",
        "SAT",
        "ScanQA",
        "3D-LLM*"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Length Generalization in Arithmetic Transformers": {
    "filename": "Length Generalization in Arithmetic Transformers.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Arithmetic Transformers",
        "Encoder-only Transformers",
        "Universal Transformers",
        "BERT",
        "ALBERT",
        "RPE-based models",
        "APE-based models"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models as Zero-Shot Conversational Recommenders": {
    "filename": "Large Language Models as Zero-Shot Conversational Recommenders.pdf",
    "analysis": {
      "benchmarks": [
        "Reddit-Movie",
        "ReDIAL",
        "INSPIRED"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4",
        "BAIZE",
        "Vicuna",
        "ReDIAL",
        "KBRD",
        "KGSF",
        "UniCRS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Open-Ended Visual Recognition with Large Language Model": {
    "filename": "Towards Open-Ended Visual Recognition with Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "COCO panoptic segmentation",
        "ADE20K panoptic segmentation",
        "Cityscapes panoptic segmentation",
        "LVIS instance segmentation",
        "ADE-847 semantic segmentation",
        "PC-459 semantic segmentation"
      ],
      "models": [
        "OmniScient Model (OSM)",
        "Segment Anything Model (SAM)",
        "kMaX-DeepLab",
        "CLIP",
        "ALIGN",
        "LMSeg",
        "DaTaSeg",
        "Mask2Former"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models": {
    "filename": "A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "PET",
        "DECON",
        "ATDP"
      ],
      "models": [
        "GPT-4o",
        "GPT-4-2024-04-09",
        "GPT-4-0125-preview",
        "GPT-3.5-0125",
        "Claude 3 Opus",
        "Claude 3 Sonnet",
        "Llama 3 70B Instruct",
        "Qwen1.5 72B Chat"
      ]
    }
  },
  "Autoregressive Large Language Models are Computationally Universal": {
    "filename": "Autoregressive Large Language Models are Computationally Universal.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "gemini-1.5-pro-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models": {
    "filename": "Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Eedi's content repository"
      ],
      "models": [
        "kNN",
        "CoT",
        "RB",
        "FT",
        "SB",
        "ChatGPT",
        "GPT-4",
        "Mistral-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reinforcing Language Agents via Policy Optimization with Action Decomposition": {
    "filename": "Reinforcing Language Agents via Policy Optimization with Action Decomposition.pdf",
    "analysis": {
      "benchmarks": [
        "Overcooked",
        "VirtualHome",
        "DataSciCoding"
      ],
      "models": [
        "GLAM",
        "TWOSOME",
        "Policy Optimization with Action Decomposition (POAD)",
        "Naive Token-Level Policy Optimization (NTPO)",
        "CAAFE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "IrokoBench A New Benchmark for African Languages in the Age of Large Language Models": {
    "filename": "IrokoBench A New Benchmark for African Languages in the Age of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "IrokoBench",
        "AfriXNLI",
        "AfriMGSM",
        "AfriMMLU",
        "XNLI",
        "MGSM",
        "MMLU"
      ],
      "models": [
        "Aya-101",
        "GPT-4o",
        "GPT-4-Turbo",
        "Claude OPUS",
        "GPT-3.5 Turbo",
        "Flan-T5-XXL",
        "mT0-XXL-MT",
        "BLOOMZ 7B",
        "Gemma 7B",
        "LLaMa 2 7B",
        "LLaMa 3 8B",
        "LLaMa 3 70B",
        "Command R",
        "Command R+",
        "AfroXLMR-76L"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EMPOWER Embodied Multi-role Open-vocabulary Planning with Online Grounding and Execution": {
    "filename": "EMPOWER Embodied Multi-role Open-vocabulary Planning with Online Grounding and Execution.pdf",
    "analysis": {
      "benchmarks": [
        "six different real-life scenarios",
        "six challenging use cases"
      ],
      "models": [
        "EMPOWER",
        "GPT-4V",
        "YOLO-World",
        "EfficientViT-SAM",
        "Semantic-Knowledge Miner Agent (SMK)",
        "Grounded-Knowledge Miner Agent (GMK)",
        "Planner Agent (P)",
        "single-role architecture",
        "multi-role architecture"
      ]
    }
  },
  "Emotional Theory of Mind Bridging Fast Visual Processing with Slow Linguistic Reasoning": {
    "filename": "Emotional Theory of Mind Bridging Fast Visual Processing with Slow Linguistic Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "EMOTIC"
      ],
      "models": [
        "CLIP",
        "LLaVA",
        "GPT-4",
        "GPT-Vision",
        "NarraCaps",
        "ExpansionNet",
        "NarraCapsXL",
        "EMOTIC baseline",
        "LLaVA fine-tuned",
        "GPT4-vision"
      ]
    }
  },
  "Can Small Language Models be Good Reasoners for Sequential Recommendation": {
    "filename": "Can Small Language Models be Good Reasoners for Sequential Recommendation.pdf",
    "analysis": {
      "benchmarks": [
        "Amazon Review - Video Games",
        "Amazon Review - Grocery and Gourmet Food",
        "Amazon Review - Home and Kitchen"
      ],
      "models": [
        "SLIM",
        "LLaMA2-7B",
        "ChatGPT",
        "GRU4Rec",
        "SASRec",
        "SRGNN",
        "GRU4Rec+",
        "SASRec+",
        "SRGNN+",
        "SLIM\u2212"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompting in the Wild An Empirical Study of Prompt Evolution in Software Repositories": {
    "filename": "Prompting in the Wild An Empirical Study of Prompt Evolution in Software Repositories.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "Llama3 70B",
        "PromptBreeder",
        "SPELL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on LLM-generated Text Detection Necessity Methods and Future Directions": {
    "filename": "A Survey on LLM-generated Text Detection Necessity Methods and Future Directions.pdf",
    "analysis": {
      "benchmarks": [
        "HC3",
        "CHEAT",
        "HC3 Plus",
        "OpenLLMText",
        "GROVER Dataset",
        "TweepFake",
        "GPT-2 Output Dataset",
        "ArguGPT",
        "DeepfakeTextDetect",
        "TuringBench",
        "MGTBench",
        "GPABenchmark",
        "Scientific-articles Benchmark",
        "MULTITuDE"
      ],
      "models": [
        "ChatGPT",
        "GPT-3.5-Turbo",
        "GPT-4",
        "PaLM",
        "LLaMA",
        "GPT2-XLE",
        "Grover-Mega",
        "RNN",
        "Markov",
        "LSTM",
        "CharRNN",
        "GPT-2 (small, medium, large, xl)",
        "Text-Babbage-001",
        "Text-Curie-001",
        "Text-Davinci-001",
        "Text-Davinci-002",
        "Text-Davinci-003",
        "GPT-3.5-Turbo",
        "GLM-130B",
        "FLAN-T5 (small, base, large, xl, xxl)",
        "OPT(125M, 350M, 1.3B, 2.7B, 6.7B, 13B, 30B, iml1.3B, iml-30B)",
        "T0 (3B, 11B)",
        "BLOOM-7B1",
        "GPT-J-6B",
        "GPT-NeoX-20B",
        "GPT-1",
        "GPT-3",
        "GROVER (base, large, mega)",
        "CTRL",
        "XLM",
        "XLNET (base, large)",
        "FAIR",
        "TRANSFORMER_XL",
        "PPLM",
        "ChatGLM",
        "Dolly",
        "GPT4All",
        "StableLM",
        "SCIgen",
        "Galactica",
        "Alpaca-lora",
        "OPT-IML-Max",
        "Vicuna"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AnnoLLM Making Large Language Models to Be Better Crowdsourced Annotators": {
    "filename": "AnnoLLM Making Large Language Models to Be Better Crowdsourced Annotators.pdf",
    "analysis": {
      "benchmarks": [
        "BoolQ",
        "WiC",
        "ConIR"
      ],
      "models": [
        "AnnoLLM",
        "GPT-3.5",
        "ChatGPT",
        "text-davinci-003",
        "PaLM 540B",
        "T5 11B",
        "ST-MoE 32B",
        "DPR",
        "PROD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Generative Pre-trained Transformers GPT Pass Assessments in Higher Education Programming Courses": {
    "filename": "Can Generative Pre-trained Transformers GPT Pass Assessments in Higher Education Programming Courses.pdf",
    "analysis": {
      "benchmarks": [
        "Statutory Interpretation Data Set"
      ],
      "models": [
        "GPT-4"
      ]
    }
  },
  "Language Models Can Reduce Asymmetry in Information Markets": {
    "filename": "Language Models Can Reduce Asymmetry in Information Markets.pdf",
    "analysis": {
      "benchmarks": [
        "ArXiv"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Llama 2 (70B)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Small Language Models Learn Enhanced Reasoning Skills from Medical Textbooks": {
    "filename": "Small Language Models Learn Enhanced Reasoning Skills from Medical Textbooks.pdf",
    "analysis": {
      "benchmarks": [
        "USMLE",
        "MedQA",
        "NEJM Case Challenges",
        "K-QA",
        "MedMCQA",
        "MMLU-Medical",
        "Medbullets-4",
        "Medbullets-5",
        "JAMA Clinical Challenge"
      ],
      "models": [
        "Meerkat-7B",
        "Meerkat-8B",
        "Meerkat-70B",
        "MediTron-7B",
        "MediTron-70B",
        "BioMistral-7B",
        "GPT-3.5",
        "GPT-4",
        "Mistral-7B",
        "LLaMA-3-8B",
        "LLaMA-3-70B",
        "ChatDoctor",
        "Med-Alpaca",
        "PMC-LLaMA",
        "Gemma-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion": {
    "filename": "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "transformer models",
        "small transformer models",
        "pre-trained language models",
        "T5-small",
        "T5-base",
        "CodeT5-small",
        "ByT5-small",
        "GPT-2",
        "GPT-3.5-Turbo",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Natural Language to Code Generation in Interactive Data Science Notebooks": {
    "filename": "Natural Language to Code Generation in Interactive Data Science Notebooks.pdf",
    "analysis": {
      "benchmarks": [
        "ARCADE"
      ],
      "models": [
        "PACHINCO",
        "PALM",
        "CODEGENmulti",
        "CODEGENmono",
        "INCODER"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Powerful are Decoder-Only Transformer Neural Models": {
    "filename": "How Powerful are Decoder-Only Transformer Neural Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "decoder-only transformer",
        "GPT-x",
        "GPT-3",
        "GPT-2",
        "vanilla transformer",
        "BERT",
        "RNN"
      ]
    }
  },
  "Developing a Llama-Based Chatbot for CICD Question Answering A Case Study at Ericsson": {
    "filename": "Developing a Llama-Based Chatbot for CICD Question Answering A Case Study at Ericsson.pdf",
    "analysis": {
      "benchmarks": [
        "Ericsson CI/CD questions"
      ],
      "models": [
        "Llama-based chatbot",
        "RAG model",
        "ensemble retriever",
        "BM25 retriever",
        "embedding retriever",
        "TF-IDF retriever"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Closed-Loop Long-Horizon Robotic Planning via Equilibrium Sequence Modeling": {
    "filename": "Closed-Loop Long-Horizon Robotic Planning via Equilibrium Sequence Modeling.pdf",
    "analysis": {
      "benchmarks": [
        "VirtualHome-Env"
      ],
      "models": [
        "Equilibrium Planner",
        "Tree-Planner",
        "SELF-REFINE",
        "Supervised Finetuned Planner",
        "Zero-shot Planner",
        "ProgPrompt",
        "Iterative-Planner",
        "Local Replan",
        "Global Replan"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MindScope Exploring Cognitive Biases in Large Language Models Through Multi-Agent Systems": {
    "filename": "MindScope Exploring Cognitive Biases in Large Language Models Through Multi-Agent Systems.pdf",
    "analysis": {
      "benchmarks": [
        "MindScope"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5-Turbo",
        "Gemini-Pro",
        "Llama2-7B",
        "Llama2-70B",
        "Vicuna-7B",
        "Vicuna-33B",
        "ChatGLM-6B",
        "RuleGen",
        "CBDC"
      ]
    }
  },
  "Knowledge Graph Based Agent for Complex Knowledge-Intensive QA in Medicine": {
    "filename": "Knowledge Graph Based Agent for Complex Knowledge-Intensive QA in Medicine.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU-Med",
        "MedQA-US",
        "PubMedQA*",
        "BioASQ-Y/N",
        "MedDDx-Basic",
        "MedDDx-Intermediate",
        "MedDDx-Expert"
      ],
      "models": [
        "KGAR EVION",
        "LLaMA2-7B",
        "LLaMA2-7B (CoT)",
        "Mistral-7B",
        "Mistral-7B (CoT)",
        "MedAlpaca-7B",
        "MedAlpaca-7B (CoT)",
        "PMC-LLaMA-7B",
        "PMC-LLaMA-7B (CoT)",
        "LLaMA3-8B",
        "LLaMA3-8B (CoT)",
        "Llama3-OpenBioLLM-8B",
        "Llama3-OpenBioLLM-8B (CoT)",
        "LLaMA3.1-8B",
        "LLaMA3.1-8B (CoT)",
        "LLaMA2-13B",
        "LLaMA2-13B (CoT)",
        "QAGNN",
        "JointLK",
        "Dragon",
        "Self-RAG (7B)",
        "Self-RAG (13B)",
        "KG-Rank (13B)",
        "KG-RAG (8B)",
        "MedRAG (70B)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Rephrase Augment Reason Visual Grounding of Questions for Vision-Language Models": {
    "filename": "Rephrase Augment Reason Visual Grounding of Questions for Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "VQAv2",
        "A-OKVQA",
        "VizWiz"
      ],
      "models": [
        "Rephrase, Augment and Reason (REPARE)",
        "BLIP-2",
        "MiniGPT-4",
        "LLaVA-1.5",
        "Flan-T5",
        "Vicuna"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Are Human-generated Demonstrations Necessary for In-context Learning": {
    "filename": "Are Human-generated Demonstrations Necessary for In-context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "ARC",
        "MMLU",
        "C-Eval",
        "HumanEval"
      ],
      "models": [
        "Vanilla ICL",
        "CoT-ICL",
        "Vanilla SEC",
        "CoT-SEC",
        "Zero-shot",
        "Zero-shot CoT",
        "ChatGPT (gpt-3.5-turbo)",
        "GPT4",
        "Llama2 34B",
        "text-davinci-002",
        "text-davinci-003"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "KnowHalu Hallucination Detection via Multi-Form Knowledge Based Factual Checking": {
    "filename": "KnowHalu Hallucination Detection via Multi-Form Knowledge Based Factual Checking.pdf",
    "analysis": {
      "benchmarks": [
        "HaluEval",
        "HotpotQA",
        "CNN/Daily Mail"
      ],
      "models": [
        "KnowHalu",
        "GPT-4",
        "Starling-7B",
        "GPT-3.5",
        "WikiChat",
        "HaluEval (Vanilla)",
        "HaluEval (CoT)",
        "HaluEval (Knowledge)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exact Conversion of In-Context Learning to Model Weights in Linearized-Attention Transformers": {
    "filename": "Exact Conversion of In-Context Learning to Model Weights in Linearized-Attention Transformers.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-2",
        "linearized transformer",
        "transformer with softmax attention",
        "RetNet",
        "RoFormer",
        "Llama",
        "Performers",
        "H3",
        "MAMBA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "User-in-the-loop Evaluation of Multimodal LLMs for Activity Assistance": {
    "filename": "User-in-the-loop Evaluation of Multimodal LLMs for Activity Assistance.pdf",
    "analysis": {
      "benchmarks": [
        "Ego4D",
        "CrossTask"
      ],
      "models": [
        "Socratic Models",
        "Vision Conditioned Language Models (VCLMs)",
        "Flamingo",
        "LLaVA",
        "AntGPT",
        "Palm",
        "VLaMP",
        "DDN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MultiTool-CoT GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting": {
    "filename": "MultiTool-CoT GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "NumGLUE Task 2"
      ],
      "models": [
        "MultiTool-CoT",
        "Zero-Shot",
        "Zero-Shot+CoT",
        "Few-Shot",
        "Few-Shot+CoT",
        "MultiTool-CoT (CAL only)",
        "MultiTool-CoT (CRP only)",
        "MultiTool-CoT (MML only)"
      ]
    }
  },
  "Developing an End-to-End Framework for Predicting the Social Communication Severity Scores of Children with Autism Spectrum Disorder": {
    "filename": "Developing an End-to-End Framework for Predicting the Social Communication Severity Scores of Children with Autism Spectrum Disorder.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "proposed end-to-end framework",
        "wav2vec2-xls-r-300m",
        "whisper-large-v2",
        "KR-BERT",
        "KLUE/roberta-base",
        "KR-ELECTRA-Discriminator"
      ]
    }
  },
  "ITCMA A Generative Agent Based on a Computational Consciousness Structure": {
    "filename": "ITCMA A Generative Agent Based on a Computational Consciousness Structure.pdf",
    "analysis": {
      "benchmarks": [
        "Alfworld",
        "Quadruped Robot in the Real World"
      ],
      "models": [
        "ITCMA",
        "PET",
        "GPT-4 with Zero-Shot Chain of Thought",
        "BUTLER",
        "Fine-tuned GPT2-medium",
        "ChatGLM3-6B",
        "MiniGPT-v2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dualformer Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces": {
    "filename": "Dualformer Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces.pdf",
    "analysis": {
      "benchmarks": [
        "Maze navigation",
        "Sokoban",
        "MATH",
        "Aug-MATH"
      ],
      "models": [
        "Dualformer",
        "Searchformer",
        "Solution-Only model",
        "Complete-Trace model",
        "Llama-3.1-70B-Instruct",
        "LLama-3-8B",
        "Mistral-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Rethinking STS and NLI in Large Language Models": {
    "filename": "Rethinking STS and NLI in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "STS-B",
        "MNLI-m",
        "SNLI",
        "QQP",
        "MRPC",
        "QNLI",
        "RTE",
        "USTS",
        "ChaosNLI",
        "MedSTS",
        "N2C2-STS",
        "BIOSSES",
        "EBMSASS",
        "MedNLI",
        "Chaos-SNLI",
        "Chaos-MNLI"
      ],
      "models": [
        "ChatGPT",
        "Claude",
        "LLaMA-2",
        "BERT-base",
        "RoBERTa-large",
        "GPT-3.5",
        "text-davinci-003",
        "T5",
        "BART",
        "GPT-2",
        "PaLM",
        "Alpaca",
        "BLOOMz"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Test-Driven Development and LLM-based Code Generation": {
    "filename": "Test-Driven Development and LLM-based Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "MBPP",
        "HumanEval",
        "CodeChef"
      ],
      "models": [
        "GPT-4",
        "Llama 3",
        "TGen"
      ]
    }
  },
  "GuardAgent Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning": {
    "filename": "GuardAgent Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "EICU-AC",
        "Mind2Web-SC"
      ],
      "models": [
        "GuardAgent",
        "EHRAgent",
        "SeeAct",
        "GPT-4",
        "Llama3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond A Better Planning with Transformers via Search Dynamics Bootstrapping": {
    "filename": "Beyond A Better Planning with Transformers via Search Dynamics Bootstrapping.pdf",
    "analysis": {
      "benchmarks": [
        "Sokoban",
        "maze navigation"
      ],
      "models": [
        "Searchformer",
        "solution-only model",
        "search-augmented model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Building a Large Japanese Web Corpus for Large Language Models": {
    "filename": "Building a Large Japanese Web Corpus for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "JCommonsenseQA",
        "JEMHopQA",
        "NIILC",
        "JSQuAD",
        "XL-Sum",
        "MGSM",
        "WMT 2020"
      ],
      "models": [
        "Llama 2 7B",
        "Llama 2 13B",
        "Llama 2 70B",
        "Mistral 7B v0.1",
        "Mixtral 8x7B Instruct",
        "CALM2 7B",
        "JSLMB 7B",
        "Youri 7B",
        "Qwen 7B",
        "Nekomata 7B",
        "JSLMG 7B",
        "Mixtral 8x7B",
        "Karakuri 70B",
        "JSLMB 70B",
        "Qwen 14B",
        "Qwen 72B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering": {
    "filename": "Reasoning over Hierarchical Question Decomposition Tree for Explainable Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "KQA Pro",
        "Musique"
      ],
      "models": [
        "RoHT",
        "KVMemNN",
        "RGCN",
        "BART KoPL",
        "TransferNet",
        "SA",
        "EX(SA)",
        "RoHTKB",
        "RoHTtext",
        "RoHTmix",
        "RoATmix"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Steering Language Models With Activation Engineering": {
    "filename": "Steering Language Models With Activation Engineering.pdf",
    "analysis": {
      "benchmarks": [
        "OpenWebText",
        "RealToxicityPrompts",
        "Stanford IMDb",
        "ConceptNet"
      ],
      "models": [
        "LLaMA-3",
        "OPT",
        "GPT-2-XL",
        "GPT-J",
        "GPT-3.5",
        "SiEBERT",
        "davinci-002",
        "all-MiniLM-L6-v2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Flextron Many-in-One Flexible Large Language Model": {
    "filename": "Flextron Many-in-One Flexible Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "ARC-easy",
        "LAMBADA",
        "PIQA",
        "WinoGrande",
        "MMLU",
        "HellaSwag",
        "Wikipedia",
        "Arxiv",
        "Books3",
        "German",
        "HTML",
        "Korean",
        "JAVA"
      ],
      "models": [
        "FLEXTRON",
        "GPT-3",
        "Llama-2",
        "Matformer",
        "Pythia",
        "OpenLLaMA",
        "Sheared-LLaMA",
        "Compresso",
        "LLM-Pruner",
        "SliceGPT",
        "LaCo",
        "FLEXTRON-8B",
        "FLEXTRON-Llama2-7B",
        "GPT3-2B",
        "GPT3-8B",
        "OpenLLaMA-3Bv2",
        "OpenLLaMA-7Bv2",
        "Pythia-1.4B",
        "Pythia-2.8B",
        "Pythia-6.9B",
        "Sheared-LLaMA-1.3B",
        "Sheared-LLaMA-2.7B",
        "NutePrune",
        "LLM-Pruner",
        "Compresso",
        "LaCo",
        "SliceGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-eXplainable AI for Medical Image Analysis A Survey and New Outlooks": {
    "filename": "Self-eXplainable AI for Medical Image Analysis A Survey and New Outlooks.pdf",
    "analysis": {
      "benchmarks": [
        "SLAKE",
        "Med-VQA",
        "chest X-ray datasets",
        "knee X-ray datasets",
        "whole slide images (WSIs)",
        "3D neuroimaging data"
      ],
      "models": [
        "Self-Explaining Neural Networks (SENN)",
        "Concept Bottleneck Model (CBM)",
        "Interactive CBMs",
        "Concept Whitening",
        "XProtoNet",
        "ProtopNet",
        "CounterNet",
        "VCNet",
        "INSightR-Net",
        "ProtoAL",
        "MProtoNet",
        "Protoeval",
        "Language Guided Bottlenecks (LaBo)",
        "Label-free CBM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating LLMs at Detecting Errors in LLM Responses": {
    "filename": "Evaluating LLMs at Detecting Errors in LLM Responses.pdf",
    "analysis": {
      "benchmarks": [
        "ReaLMistake",
        "MT-Bench",
        "PandaLM",
        "LLMEval^2",
        "WikiBio",
        "SummEdits",
        "BIG-Bench Mistake"
      ],
      "models": [
        "GPT-4",
        "Llama 2 70B",
        "Claude 3",
        "Gemma 7B",
        "Llama 2 13B",
        "Mistral 7B",
        "Mixtral 8x7B",
        "Qwen 1.5 14B",
        "Qwen 1.5 72B",
        "Gemini 1.0 Pro",
        "GPT-3.5 Turbo",
        "GPT-4 0613",
        "GPT-4 0125"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Personality Alignment of Large Language Models": {
    "filename": "Personality Alignment of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "PAPI",
        "GSM8K",
        "CommonSenseQA",
        "AddSub",
        "MultiArith",
        "SVAMP",
        "BigBench-Date",
        "StrategyQA",
        "Coin Flip"
      ],
      "models": [
        "PAS",
        "DPO",
        "PPO",
        "GPT-4o",
        "Llama-3-8B-Instruct",
        "Llama-3-70B-Instruct",
        "Few-Shot",
        "Personality Prompt (P2)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AgentTuning Enabling Generalized Agent Abilities for LLMs": {
    "filename": "AgentTuning Enabling Generalized Agent Abilities for LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "AgentBench",
        "MMLU",
        "GSM8K",
        "HumanEval",
        "MT-Bench",
        "ALFWorld",
        "WebShop",
        "Mind2Web",
        "Knowledge Graph",
        "Operating System",
        "Database",
        "SciWorld",
        "MiniWoB++",
        "HotpotQA",
        "WebArena",
        "ReWOO",
        "Digital Card Game"
      ],
      "models": [
        "AgentLM-7B",
        "AgentLM-13B",
        "AgentLM-70B",
        "Llama 2 (chat)",
        "GPT-3.5",
        "GPT-4",
        "text-davinci-003",
        "text-davinci-002",
        "text-bison-001",
        "chatglm2",
        "openchat-13b",
        "wizardlm-30b",
        "vicuna-13b",
        "wizardlm-13b",
        "wizardcoder-15b",
        "dolly-v2-12b",
        "oasst-sft-4-12b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evolving Code with A Large Language Model": {
    "filename": "Evolving Code with A Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "APPS",
        "MultiPL-E",
        "GSM8K",
        "Program Synthesis Benchmark 2"
      ],
      "models": [
        "LLM GP",
        "Tutorial-LLM GP",
        "SEIDR",
        "OpenELM",
        "EUREKA",
        "Self-Taught Optimizer (STOP)",
        "Evolution through Large Models (ELM)",
        "Evoprompting",
        "LLMatic",
        "Promptbreeder",
        "Wizardlm",
        "MarioGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ManipLLM Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation": {
    "filename": "ManipLLM Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation.pdf",
    "analysis": {
      "benchmarks": [
        "PartNet-Mobility dataset"
      ],
      "models": [
        "ManipLLM",
        "Where2Act",
        "UMPNet",
        "Flowbot3D",
        "Implicit3D",
        "Voxposer"
      ]
    }
  },
  "Leveraging Zero-Shot Prompting for Efficient Language Model Distillation": {
    "filename": "Leveraging Zero-Shot Prompting for Efficient Language Model Distillation.pdf",
    "analysis": {
      "benchmarks": [
        "ANLI1",
        "Commonsense Question-Answering (CQA)"
      ],
      "models": [
        "GPT-3.5-turbo",
        "T5-small",
        "T5-base",
        "T5-large",
        "T5-XL",
        "540B PaLM"
      ]
    }
  },
  "A Survey on Hallucination in Large Language Models Principles Taxonomy Challenges and Open Questions": {
    "filename": "A Survey on Hallucination in Large Language Models Principles Taxonomy Challenges and Open Questions.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA",
        "HalluQA",
        "HaluEval-2.0",
        "SelfCheckGPT-Wikibio",
        "HaluEval",
        "FELM"
      ],
      "models": [
        "LLaMA",
        "Claude",
        "Gemini",
        "GPT-4",
        "GPT-3",
        "PaLM",
        "OPT",
        "Falcon",
        "Llama-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FLamE Few-shot Learning from Natural Language Explanations": {
    "filename": "FLamE Few-shot Learning from Natural Language Explanations.pdf",
    "analysis": {
      "benchmarks": [
        "e-SNLI",
        "e-HANS"
      ],
      "models": [
        "FLamE",
        "GPT-3 Babbage",
        "GPT-3 Davinci",
        "RoBERTa",
        "PET",
        "oracle-explanation",
        "explain-then-predict",
        "predict-then-explain"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Teaching Large Language Models to Self-Debug": {
    "filename": "Teaching Large Language Models to Self-Debug.pdf",
    "analysis": {
      "benchmarks": [
        "Spider",
        "TransCoder",
        "MBPP"
      ],
      "models": [
        "SELF-DEBUGGING",
        "code-davinci-002",
        "gpt-3.5-turbo",
        "gpt-4",
        "StarCoder",
        "T5-3B + N-best Reranking",
        "LEVER",
        "Coder-Reviewer",
        "MBR-Exec"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PromptRobust Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts": {
    "filename": "PromptRobust Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts.pdf",
    "analysis": {
      "benchmarks": [
        "AdvGLUE",
        "ANLI",
        "SST-2",
        "CoLA",
        "QQP",
        "MRPC",
        "MNLI",
        "QNLI",
        "RTE",
        "WNLI",
        "MMLU",
        "SQuAD V2",
        "UN Multi",
        "IWSLT 2017",
        "Mathematics"
      ],
      "models": [
        "Flan-T5-large",
        "Dolly-6B",
        "Vicuna-13B",
        "Llama2-13b-chat",
        "Cerebras-GPT-13B",
        "GPT-NEOX-20B",
        "Flan-UL2",
        "ChatGPT",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Constrained Reasoning Chains for Enhancing Theory-of-Mind in Large Language Models": {
    "filename": "Constrained Reasoning Chains for Enhancing Theory-of-Mind in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BigToM",
        "FANTOM"
      ],
      "models": [
        "Constrained Chain-of-ToM (CCoToM)",
        "Chain-of-Thought (CoT)",
        "SIMTOM",
        "GPT-4",
        "GPT-3.5-Turbo",
        "Llama-2 Chat 70B",
        "Mistral Instruct 7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Escape Sky-high Cost Early-stopping Self-Consistency for Multi-step Reasoning": {
    "filename": "Escape Sky-high Cost Early-stopping Self-Consistency for Multi-step Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "StrategyQA",
        "CommonsenseQA",
        "Coin Flip",
        "Last Letters",
        "MBPP"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5-Turbo",
        "Llama-2 7b",
        "CoT",
        "SC",
        "ESC",
        "\u02c6L-SC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ReCEval Evaluating Reasoning Chains via Correctness and Informativeness": {
    "filename": "ReCEval Evaluating Reasoning Chains via Correctness and Informativeness.pdf",
    "analysis": {
      "benchmarks": [
        "Entailment Bank",
        "GSM-8K",
        "DROP",
        "StrategyQA"
      ],
      "models": [
        "RECEVAL",
        "ROSCOE",
        "T5-large",
        "GPT-2 XL",
        "LLaMA-7B",
        "GPT-3.5-turbo",
        "FLAN T5-XXL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ReMEmbR Building and Reasoning Over Long-Horizon Spatio-Temporal Memory for Robot Navigation": {
    "filename": "ReMEmbR Building and Reasoning Over Long-Horizon Spatio-Temporal Memory for Robot Navigation.pdf",
    "analysis": {
      "benchmarks": [
        "NaVQA",
        "CODa"
      ],
      "models": [
        "ReMEmbR",
        "LLM",
        "VLM",
        "GPT-4o",
        "Codestral",
        "Command-R",
        "Llama3.1",
        "VILA1.5-13b",
        "mxbai-embed-large-v1",
        "VILA-3b",
        "Whisper"
      ]
    }
  },
  "Large Language ModelsLLMs on Tabular Data Prediction Generation and Understanding - A Survey": {
    "filename": "Large Language ModelsLLMs on Tabular Data Prediction Generation and Understanding - A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "UCI ML",
        "OpenML",
        "Kaggle API",
        "Combo 9",
        "DDX"
      ],
      "models": [
        "GPT-3",
        "GPT-J",
        "T0",
        "T-few",
        "Flan-T5",
        "Tk-Instruct",
        "ChatGPT",
        "LLaMA",
        "GPT2",
        "BioBert",
        "UnifiedQA-v2-T5",
        "Roberta",
        "ChatGLM",
        "Flan-UL2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Developmental Scaffolding with Large Language Models": {
    "filename": "Developmental Scaffolding with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT3.5",
        "random exploration baseline"
      ]
    }
  },
  "Enhancing LLMs Cognition via Structurization": {
    "filename": "Enhancing LLMs Cognition via Structurization.pdf",
    "analysis": {
      "benchmarks": [
        "LongBench",
        "AttrScore",
        "FactScore",
        "BEIR"
      ],
      "models": [
        "LLaMA2-70B",
        "GPT-3.5-Turbo",
        "StruXGPT-7B",
        "LLaMA2-7B-4k",
        "LLaMA2-13B-4k",
        "Qwen-7B-8k",
        "ChatGLM3-6B-32k",
        "Alpaca-13B",
        "Alpaca-7B",
        "GPT-3.5-1106",
        "BERT",
        "SimLM",
        "coCondenser"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning to Reason and Memorize with Self-Notes": {
    "filename": "Learning to Reason and Memorize with Self-Notes.pdf",
    "analysis": {
      "benchmarks": [
        "Toy-Story",
        "Algorithmic",
        "Boolean Variable",
        "Chess Piecetype",
        "Chess Move",
        "MultiArith",
        "GSM8K"
      ],
      "models": [
        "Vanilla",
        "Scratchpad",
        "Self-Notes",
        "GPT-2",
        "GPT-J",
        "GPT-3",
        "Llama 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On the Design and Analysis of LLM-Based Algorithms": {
    "filename": "On the Design and Analysis of LLM-Based Algorithms.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLM-based algorithm",
        "Llama-3-8B",
        "Llama-3-70B",
        "GPT-4-Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Effective Large Language Model Debugging with Best-first Tree Search": {
    "filename": "Effective Large Language Model Debugging with Best-first Tree Search.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "APPS"
      ],
      "models": [
        "BESTER",
        "GPT-4",
        "deepseek-coder-33b-instruct",
        "Meta-Llama-3-70B-Instruct",
        "Reflexion",
        "Ex. Feedback"
      ]
    }
  },
  "Instruction Tuning-free Visual Token Complement for Multimodal LLMs": {
    "filename": "Instruction Tuning-free Visual Token Complement for Multimodal LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "LVLM-eHub",
        "MME",
        "DEMON"
      ],
      "models": [
        "VTC",
        "BLIP2",
        "MiniGPT4",
        "InstructBLIP",
        "LLaVA",
        "Otter",
        "mPLUG-Owl",
        "VPGTrans"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EPA Easy Prompt Augmentation on Large Language Models via Multiple Sources and Multiple Targets": {
    "filename": "EPA Easy Prompt Augmentation on Large Language Models via Multiple Sources and Multiple Targets.pdf",
    "analysis": {
      "benchmarks": [
        "FLORES-200",
        "SAMSum",
        "Quora Question Pairs (QQP)",
        "SNLI",
        "MNLI"
      ],
      "models": [
        "EPA",
        "ChatGPT",
        "GPT-3.5-TURBO",
        "Copy-9"
      ]
    }
  },
  "LLM-Assisted Light Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments": {
    "filename": "LLM-Assisted Light Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments.pdf",
    "analysis": {
      "benchmarks": [
        "3-Way INT",
        "4-Way INT",
        "Shanghai",
        "Emergency Vehicle (EMV) Scenario",
        "Roadblock Incident (RBI) Scenario",
        "Sensor Outage (SO) Scenario"
      ],
      "models": [
        "LA-Light",
        "Webster",
        "SOTL",
        "Maxpressure",
        "IntelliLight",
        "PressLight",
        "AttendLight",
        "UniTSA",
        "Vanilla-LLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "THaMES An End-to-End Tool for Hallucination Mitigation and Evaluation in Large Language Models": {
    "filename": "THaMES An End-to-End Tool for Hallucination Mitigation and Evaluation in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HaluEval",
        "DelucionQA"
      ],
      "models": [
        "THaMES",
        "GPT-4o",
        "GPT-4o-mini",
        "Llama-3.1-8B-Instruct",
        "Mistral-Nemo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SoK Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency": {
    "filename": "SoK Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "BIG-bench",
        "DialogBench"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "LLaMA",
        "Code LLaMA",
        "CodeGen",
        "StarCoder",
        "PanGu-Coder",
        "WizardCoder",
        "Code-Davinci-001",
        "Code-Davinci-002",
        "PaLM-Coder",
        "CodeT5 +",
        "InstructCodeT5 +",
        "GPT-4 with Reflexion",
        "Santa-Coder",
        "AlphaCode",
        "Codex-12B",
        "code-cushman-001",
        "InCoder",
        "VisionLLM",
        "LLaVa",
        "MiniGPT-4",
        "Visual ChatGPT",
        "InternGPT",
        "Flamingo",
        "BLIP-2",
        "Kosmos",
        "UniVL",
        "VidIL",
        "MOV",
        "DialoGPT",
        "Guanaco",
        "Falcon-180B",
        "Falcon-40B",
        "KwaiYii-13B-Chat",
        "AutoGen",
        "AgentLite",
        "Camel",
        "CrewAI"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OpenBias Open-Set Bias Detection in Text-to-Image Generative Models": {
    "filename": "OpenBias Open-Set Bias Detection in Text-to-Image Generative Models.pdf",
    "analysis": {
      "benchmarks": [
        "Flickr30k",
        "COCO"
      ],
      "models": [
        "OpenBias",
        "Stable Diffusion 1.5",
        "Stable Diffusion 2",
        "Stable Diffusion XL",
        "FairFace",
        "Llava1.5-13B",
        "Llama2-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Design and Engineering Introduction and Advanced Methods": {
    "filename": "Prompt Design and Engineering Introduction and Advanced Methods.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "error": "Encountered text corresponding to disallowed special token '<|endofprompt|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endofprompt|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endofprompt|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
    }
  },
  "Self-ICL Zero-Shot In-Context Learning with Self-Generated Demonstrations": {
    "filename": "Self-ICL Zero-Shot In-Context Learning with Self-Generated Demonstrations.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-Bench Hard"
      ],
      "models": [
        "SELF-ICL",
        "InstructGPT (text-davinci-003)",
        "PaLM-2 (text-bison-001)",
        "gpt-3.5-turbo-instruct",
        "ZS-Direct",
        "ZS-CoT"
      ]
    }
  },
  "A Review on Generative AI Models for Synthetic Medical Text Time Series and Longitudinal Data": {
    "filename": "A Review on Generative AI Models for Synthetic Medical Text Time Series and Longitudinal Data.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC III",
        "MIMIC IV",
        "eICU",
        "HiRID",
        "Pile",
        "E3C",
        "INPCR",
        "Administrative Health Records",
        "PPMI",
        "NACC",
        "Evotion",
        "SEER",
        "Human Activity Sensing Archive",
        "UCR Time Series Archive",
        "Autonomic Aging",
        "PTB-XL",
        "AF Classification Challenge",
        "UniMiB",
        "PAMAP2",
        "MIT-BIH Arrhythmia",
        "MIT-BIH Normal Sinus Rhythm",
        "Sleep-EDF (Expanded)",
        "The National Sleep Research Resource",
        "UCI EEG Dataset",
        "PhysioNet Challenge 2015",
        "PPG-DB",
        "UCI ML Repository",
        "PhysioNet"
      ],
      "models": [
        "cGAN",
        "Time series siamese GAN",
        "Temporally correlated multi-modal GAN",
        "Recurrent cGAN",
        "Diffusion model",
        "Transformer-based time series GAN (TTS-GAN)",
        "Multi-axial cGAN (SensoryGANs)",
        "Time series conditional Wasserstein GAN",
        "HealthGen",
        "NODE-based GAN",
        "Multivariate GAN",
        "LSTM-based controllable GAN with spectral normalization",
        "PART-GAN",
        "Concatenating multiple GAN models",
        "Combination of HMM and regression algorithm (SynSys)",
        "Hierarchical auto-regressive language model",
        "GAN-boosted semi-supervised learning",
        "Mixed-type longitudinal GAN",
        "Variational graph auto-encoder",
        "RNN",
        "Generative Markov-Bayesian-based model",
        "Multi-modal Neural Ordinary Differential Equations",
        "GPT-2",
        "DataSifter-II (ruled-based method)",
        "Bayesian network",
        "Adversarial auto-encoder",
        "Sequence GAN",
        "Encoder-Decoder LSTM",
        "GPT-3",
        "BLOOM",
        "Recurrent VAE",
        "Perturbation-based data sifting",
        "BERT",
        "LSTM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Representations Can be What Recommenders Need Findings and Potentials": {
    "filename": "Language Representations Can be What Recommenders Need Findings and Potentials.pdf",
    "analysis": {
      "benchmarks": [
        "Movies & TV",
        "Video Games",
        "Books",
        "Movielens-1M",
        "Book Crossing",
        "Amazon Industrial & Scientific"
      ],
      "models": [
        "AlphaRec",
        "CFMF",
        "MultVAE",
        "LightGCN",
        "SGL",
        "BC Loss",
        "XSimGCL",
        "KAR",
        "RLMRec",
        "BERT",
        "RoBERTa",
        "Llama2-7B",
        "Mistral-7B",
        "text-embedding-ada-v2",
        "text-embeddings-3-large",
        "SFR-Embedding-Mistral",
        "TEM",
        "ZESRec",
        "UniSRec",
        "LLMRank"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InstructEval Systematic Evaluation of Instruction Selection Methods": {
    "filename": "InstructEval Systematic Evaluation of Instruction Selection Methods.pdf",
    "analysis": {
      "benchmarks": [
        "AG News",
        "ANLI",
        "BoolQ",
        "IMDB",
        "TweetEval Emotion",
        "CosmosQA",
        "HellaSwag",
        "NQ-Open",
        "TriviaQA"
      ],
      "models": [
        "BLOOM",
        "GPT Neo",
        "LLaMA",
        "OPT",
        "Null Instruction",
        "Generic Instruction",
        "PromptSource",
        "Ad hoc",
        "Low Perplexity",
        "APE",
        "RLPrompt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An LLM can Fool Itself A Prompt-Based Adversarial Attack": {
    "filename": "An LLM can Fool Itself A Prompt-Based Adversarial Attack.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "AdvGLUE",
        "AdvGLUE++",
        "SST-2",
        "QQP",
        "MNLI",
        "RTE",
        "QNLI"
      ],
      "models": [
        "Llama2-7B",
        "Llama2-13B",
        "GPT-3.5",
        "BERT-based models",
        "Alpaca-7B",
        "Vicuna-13B",
        "StableVicuna-13B",
        "PromptAttack",
        "PromptAttack-EN",
        "PromptAttack-FS-EN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Best in TauLLMJudge Criteria-Based Relevance Evaluation with Llama3": {
    "filename": "Best in TauLLMJudge Criteria-Based Relevance Evaluation with Llama3.pdf",
    "analysis": {
      "benchmarks": [
        "LLMJudge",
        "TREC Deep Learning 2023"
      ],
      "models": [
        "Four Prompts",
        "Four Prompts + Summation Aggregation",
        "Four Prompts + Gaussian Naive Bayes Aggregation",
        "Binary Check + Subset of Four Prompts",
        "Passage-to-Query Generation"
      ]
    }
  },
  "Cultural Evolution of Cooperation among LLM Agents": {
    "filename": "Cultural Evolution of Cooperation among LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Donor Game"
      ],
      "models": [
        "Claude 3.5 Sonnet",
        "Gemini 1.5 Flash",
        "GPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Natural Language Deduction with Incomplete Information": {
    "filename": "Natural Language Deduction with Incomplete Information.pdf",
    "analysis": {
      "benchmarks": [
        "EntailmentBank",
        "Everyday Norms: Why Not?"
      ],
      "models": [
        "ADGV",
        "ADG",
        "AG",
        "DG",
        "E2E"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Flow of ReasoningTraining LLMs for Divergent Problem Solving with Minimal Examples": {
    "filename": "Flow of ReasoningTraining LLMs for Divergent Problem Solving with Minimal Examples.pdf",
    "analysis": {
      "benchmarks": [
        "BlocksWorld",
        "Game24",
        "Rubik's Cube",
        "1D-ARC",
        "PrOntoQA"
      ],
      "models": [
        "Flow of Reasoning (FOR)",
        "Chain of Thought (CoT)",
        "Tree of Thought (ToT)",
        "Graph of Thought (GoT)",
        "Reasoning with Language Model is Planning with World Model (RAP)",
        "Supervised Fine-Tuning (SFT)",
        "Proximal Policy Optimization (PPO)",
        "GFN-CoT",
        "OpenAI-O1",
        "OpenAI-O1-mini",
        "OpenAI-O1-preview",
        "STaR",
        "XoT",
        "Hypothesis Search",
        "Program-Only",
        "Input-output (IO)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Human-centered In-building Embodied Delivery Benchmark": {
    "filename": "Human-centered In-building Embodied Delivery Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "Polar Research Station Environment (PRS)",
        "ALFRED",
        "EQA",
        "VirtualHome",
        "BEHAVIOR-1K",
        "Habitat",
        "iGibson"
      ],
      "models": [
        "LMM-based approach",
        "Rule-Based + GD",
        "GLM-4V",
        "GLM-4V + GD",
        "GPT-4V+ GD",
        "GPT-4O + GD"
      ]
    }
  },
  "GameTraversalBenchmark Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps": {
    "filename": "GameTraversalBenchmark Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps.pdf",
    "analysis": {
      "benchmarks": [
        "GameTraversalBenchmark"
      ],
      "models": [
        "GPT-4-Turbo",
        "GPT-4-o",
        "Claude-3-Opus",
        "Claude-3-Sonnet",
        "Random-FP",
        "Gemma-7B",
        "GPT-3.5-Turbo",
        "LLaMa-3-8B",
        "LLaMa-3-70B",
        "Claude-3-Haiku",
        "Mixtral-8x7B",
        "Random-RP",
        "o1",
        "o1-mini"
      ]
    }
  },
  "SADL An Effective In-Context Learning Method for Compositional Visual QA": {
    "filename": "SADL An Effective In-Context Learning Method for Compositional Visual QA.pdf",
    "analysis": {
      "benchmarks": [
        "GQA",
        "GQA-OOD",
        "CLEVR",
        "CRIC"
      ],
      "models": [
        "SADL",
        "OpenFlamingo",
        "Chain-of-Thought (CoT)",
        "Least-to-Most (L2M)",
        "Vanilla prompting"
      ]
    }
  },
  "Language Models Are Greedy Reasoners A Systematic Formal Analysis of Chain-of-Thought": {
    "filename": "Language Models Are Greedy Reasoners A Systematic Formal Analysis of Chain-of-Thought.pdf",
    "analysis": {
      "benchmarks": [
        "PRONTOQA",
        "PROOF WRITER",
        "FOLIO",
        "GSM8K",
        "SimpleLogic"
      ],
      "models": [
        "INSTRUCT GPT",
        "GPT-3",
        "text-davinci-002",
        "text-ada-001",
        "text-babbage-001",
        "text-curie-001",
        "davinci",
        "text-davinci-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EPiC Cost-effective Search-based Prompt Engineering of LLMs for Code Generation": {
    "filename": "EPiC Cost-effective Search-based Prompt Engineering of LLMs for Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP"
      ],
      "models": [
        "EPiC",
        "Reflexion",
        "LATS",
        "LDB",
        "MagicCoder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CurricuLLM Automatic Task Curricula Design for Learning Complex Robot Skills using Large Language Models": {
    "filename": "CurricuLLM Automatic Task Curricula Design for Learning Complex Robot Skills using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Fetch-Slide",
        "Fetch-Push",
        "AntMaze-UMaze",
        "Berkeley Humanoid"
      ],
      "models": [
        "CurricuLLM",
        "SAC",
        "HER",
        "LLM-zeroshot",
        "PPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Divide and Translate Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning": {
    "filename": "Divide and Translate Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "AR-LSAT",
        "ZebraLogic",
        "Logic grid puzzle",
        "Symbol interpretation",
        "Logical deduction",
        "FOLIO",
        "ProofWriter"
      ],
      "models": [
        "CLOVER",
        "Logic-LM",
        "Standard",
        "CoT",
        "SymbCoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reframing Tax Law Entailment as Analogical Reasoning": {
    "filename": "Reframing Tax Law Entailment as Analogical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "SARA"
      ],
      "models": [
        "BERT",
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "Sentence-BERT",
        "T5-Large",
        "bert-base-cased"
      ]
    }
  },
  "Managing AI Risks in an Era of Rapid Progress": {
    "filename": "Managing AI Risks in an Era of Rapid Progress.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4"
      ]
    }
  },
  "Controllable Mixed-Initiative Dialogue Generation through Prompting": {
    "filename": "Controllable Mixed-Initiative Dialogue Generation through Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "Emotional Support Conversations",
        "PersuasionForGood"
      ],
      "models": [
        "Oracle-BlenderBot",
        "RAP",
        "InstructGPT text-davinci-003"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Balanced and Explainable Social Media Analysis for Public Health with Large Language Models": {
    "filename": "Balanced and Explainable Social Media Analysis for Public Health with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SMM4H 2023 Task 1",
        "SMM4H 2023 Task 2",
        "SMM4H 2023 Task 4"
      ],
      "models": [
        "ALEX",
        "BERT",
        "RoBERTa",
        "XLNet",
        "BERTweet",
        "CT-BERT (v2)"
      ]
    }
  },
  "UI Layout Generation with LLMs Guided by UI Grammar": {
    "filename": "UI Layout Generation with LLMs Guided by UI Grammar.pdf",
    "analysis": {
      "benchmarks": [
        "RICO",
        "CLAY",
        "SCREEN2WORDS"
      ],
      "models": [
        "GPT-4",
        "UI grammar approach"
      ]
    }
  },
  "Wait thats not an option LLMs Robustness with Incorrect Multiple-Choice Options": {
    "filename": "Wait thats not an option LLMs Robustness with Incorrect Multiple-Choice Options.pdf",
    "analysis": {
      "benchmarks": [
        "Basic Arithmetic Dataset (BAD)",
        "MMLU dataset"
      ],
      "models": [
        "GPT-4o",
        "o1-mini",
        "Claude 3 Opus",
        "Llama 3.1-8B",
        "Llama 3.1-70B",
        "Llama 3.1-405B",
        "Qwen2.5-7B",
        "Qwen2.5-14B",
        "Qwen2.5-32B",
        "Qwen2-Math-7B",
        "DeepSeekMath-7B Base",
        "DeepSeekMath-7B-Instruct",
        "DeepSeekMath-7B-RLHF",
        "Claude 3 Haiku",
        "Claude 3 Sonnet",
        "Claude 3.5 Sonnet",
        "Gemini 1.5 Flash",
        "Gemini 1.5 Pro",
        "Qwen2.5-7B-Instruct",
        "Qwen2.5-14B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can ChatGPT Overcome Behavioral Biases in the Financial Sector Classify-and-Rethink Multi-Step Zero-Shot Reasoning in the Gold Investment": {
    "filename": "Can ChatGPT Overcome Behavioral Biases in the Financial Sector Classify-and-Rethink Multi-Step Zero-Shot Reasoning in the Gold Investment.pdf",
    "analysis": {
      "benchmarks": [
        "Shanghai Gold Exchange spot gold index (Au9999.SGE)",
        "gold news from http://www.dyhjw.com/"
      ],
      "models": [
        "ChatGPT",
        "Classify-and-Rethink (CAR)",
        "One-Step",
        "Classify",
        "ChatGLM"
      ]
    }
  },
  "C3 Zero-shot Text-to-SQL with ChatGPT": {
    "filename": "C3 Zero-shot Text-to-SQL with ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "Spider"
      ],
      "models": [
        "C3",
        "ChatGPT-SQL",
        "RATSQL",
        "T5-3B + PICARD",
        "Graphix-3B + PICARD",
        "SC-Prompt + T5-3B",
        "RESDSQL-3B + NatSQL",
        "DIN-SQL + GPT-4"
      ]
    }
  },
  "Innovations in Neural Data-to-text Generation": {
    "filename": "Innovations in Neural Data-to-text Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Robocup",
        "WeatherGov",
        "BAGEL",
        "SF Hotels & Restaurants",
        "E2E",
        "LDC2017T10",
        "WebNLG",
        "DART",
        "WikiBio",
        "RotoWire",
        "TabFact",
        "ToTTo",
        "LogicNLG",
        "WikiTableT",
        "AGENDA",
        "Chart-to-text"
      ],
      "models": [
        "LSTM\u2192LSTM",
        "GRU\u2192GRU",
        "MLP\u2192GRU",
        "CAEncoder\u2192GRU",
        "Ensemble w/ LSTM + CNN",
        "SC-LSTM",
        "GNN\u2192LSTM",
        "GCN\u2192LSTM",
        "GAT\u2192T",
        "BART + T5",
        "BERT + Pointer Networks",
        "GPT-2",
        "GPT-3",
        "T5",
        "Pointer networks + Text editing",
        "GAN",
        "DCVED + GPT",
        "T5 + BART",
        "T5 + VAE",
        "T5 + Search & Learn",
        "BERT-based IR system",
        "HSMM",
        "RoBERTa-based semantic fidelity classifier",
        "GPT-2 + LaserTagger",
        "GPT-2 + RoBERTa",
        "GPT3 + T5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Hierarchical Continual Reinforcement Learning via Large Language Model": {
    "filename": "Hierarchical Continual Reinforcement Learning via Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "MiniGrid"
      ],
      "models": [
        "Hi-Core",
        "Single-Task (SG)",
        "Fine-Tuning (FT)",
        "Fine-Tuning with L2 Regularization (FT-L2)",
        "PackNet",
        "Hi-Core-FT",
        "Hi-Core-SG",
        "Hi-Core-Once"
      ]
    }
  },
  "Chat Bankman-Fried an Exploration of LLM Alignment in Finance": {
    "filename": "Chat Bankman-Fried an Exploration of LLM Alignment in Finance.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "o1-preview",
        "o1-mini",
        "phi-3.5-mini",
        "llama-3.1-8b",
        "gpt-4o-mini",
        "claude-3.5-sonnet",
        "gpt-4o",
        "claude-3-haiku",
        "gpt-4-turbo",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "V-LoL A Diagnostic Dataset for Visual Logical Learning": {
    "filename": "V-LoL A Diagnostic Dataset for Visual Logical Learning.pdf",
    "analysis": {
      "benchmarks": [
        "V-LoL",
        "V-LoL-Trains",
        "V-LoL-Blocks",
        "CLEVR",
        "Michalski train problem",
        "VQA",
        "CLEVR-Hans",
        "CURI",
        "ACRE",
        "PTR",
        "Bongard-LOGO",
        "Kandinsky",
        "RAVEN"
      ],
      "models": [
        "ResNet18",
        "EfficientNet",
        "Vision Transformer (ViT)",
        "Llama2",
        "ChatGPT",
        "Aleph",
        "Popper",
        "RCNN-Popper",
        "RCNN-Aleph",
        "\u03b1ILP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ALI-Agent Assessing LLMs Alignment with Human Values via Agent-based Evaluation": {
    "filename": "ALI-Agent Assessing LLMs Alignment with Human Values via Agent-based Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "CrowS-Pairs",
        "ETHICS",
        "DecodingTrust",
        "Social Chemistry 101",
        "Singapore Rapid Transit Systems Regulations",
        "AdvBench"
      ],
      "models": [
        "ALI-Agent",
        "GPT-4",
        "GPT-3.5",
        "Gemini-Pro",
        "ChatGLM3",
        "Vicuna-7B",
        "Vicuna-13B",
        "Vicuna-33B",
        "Llama 2-7B",
        "Llama 2-13B",
        "Llama 2-70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do As I Can Not As I Say Grounding Language in Robotic Affordances": {
    "filename": "Do As I Can Not As I Say Grounding Language in Robotic Affordances.pdf",
    "analysis": {
      "benchmarks": [
        "ALFRED",
        "BEHAVIOR"
      ],
      "models": [
        "SayCan",
        "PaLM-SayCan",
        "FLAN-SayCan",
        "No VF",
        "Generative",
        "BC NL",
        "BC USE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GameVLM A Decision-making Framework for Robotic Task Planning Based on Visual Language Models and Zero-sum Games": {
    "filename": "GameVLM A Decision-making Framework for Robotic Task Planning Based on Visual Language Models and Zero-sum Games.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GameVLM",
        "YOLO-World",
        "GPT-4V"
      ]
    }
  },
  "Puzzle Distillation-Based NAS for Inference-Optimized LLMs": {
    "filename": "Puzzle Distillation-Based NAS for Inference-Optimized LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Winogrande",
        "ARC Challenge",
        "MMLU",
        "HellaSwag",
        "GSM8K",
        "TruthfulQA",
        "XLSum English",
        "MMLU Chat",
        "GSM8K Chat",
        "Instruct HumanEval",
        "MT-Bench",
        "RULER"
      ],
      "models": [
        "Nemotron-51B",
        "Llama-3.1-70B-Instruct",
        "Llama-3.1-8B-Instruct",
        "Llama-3.2-3B-Instruct",
        "Mixtral 8X22B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition": {
    "filename": "How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "HumanEval",
        "MT-Bench"
      ],
      "models": [
        "LLaMA 7B",
        "LLaMA 13B",
        "LLaMA 33B",
        "Dual-stage Mixed Fine-tuning (DMT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Far Are We from Intelligent Visual Deductive Reasoning": {
    "filename": "How Far Are We from Intelligent Visual Deductive Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Mensa IQ test",
        "IntelligenceTest",
        "RAVEN"
      ],
      "models": [
        "GPT4-V",
        "Gemini-pro",
        "Qwen-VL-Max",
        "LLaVA-1.5-13B",
        "LLaVA-1.6-34B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models are Zero Shot Hypothesis Proposers": {
    "filename": "Large Language Models are Zero Shot Hypothesis Proposers.pdf",
    "analysis": {
      "benchmarks": [
        "PubMed"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "LLaMA",
        "Llama-2-70b-chat",
        "WizardLM-13B-V1.2",
        "WizardLM-70B-V1.0",
        "Vicuna-33b-v1.3",
        "openchat-v3.2-super",
        "MedAlpaca-13B",
        "PMC-LLaMA-13B",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CoRRPUS Code-based Structured Prompting for Neurosymbolic Story Understanding": {
    "filename": "CoRRPUS Code-based Structured Prompting for Neurosymbolic Story Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "bAbI Task 2",
        "Re3"
      ],
      "models": [
        "CoRRPUS",
        "GPT-3",
        "Codex",
        "Chain-of-Thought (COT)",
        "Selection-Inference (SI)",
        "Dual-System (DS)",
        "Entailment",
        "Entailment-DPR",
        "Structured-Detect"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "UFO Unified Fact Obtaining for Commonsense Question Answering": {
    "filename": "UFO Unified Fact Obtaining for Commonsense Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "CommonsenseQA 2.0",
        "OpenBookQA",
        "QASC",
        "Social IQA"
      ],
      "models": [
        "UFO",
        "DeBERTa",
        "T5-11B",
        "UNICORN",
        "UL-20B",
        "Unified QA",
        "AristoRoBERTa + GSC",
        "RoBERTa + KF + SIR v2",
        "RoBERTa + AIR",
        "RoBERTa + ATOMIC",
        "GPT-3 Davinci",
        "GPT-3 Curie",
        "GPT-Neo",
        "GPT-3.5-turbo"
      ]
    }
  },
  "Neuro-Symbolic Causal Reasoning Meets Signaling Game for Emergent Semantic Communications": {
    "filename": "Neuro-Symbolic Causal Reasoning Meets Signaling Game for Emergent Semantic Communications.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "emergent SC (ESC) framework",
        "neuro-symbolic (NeSy) AI approach",
        "generative flow networks (GFlowNets)",
        "logical neural networks (LNN)",
        "classical AI systems",
        "state-of-the-art SC systems",
        "reasoning over the air approach",
        "emergent language game",
        "two-player contextual signaling game",
        "NeSy AI approach"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Ask Me Anything A simple strategy for prompting language models": {
    "filename": "Ask Me Anything A simple strategy for prompting language models.pdf",
    "analysis": {
      "benchmarks": [
        "SuperGLUE",
        "CB",
        "RTE",
        "WSC",
        "DBPedia",
        "AGNews",
        "BoolQ",
        "COPA",
        "MultiRC",
        "ReCoRD",
        "WiC",
        "ANLI R1",
        "ANLI R2",
        "ANLI R3",
        "StoryCloze",
        "SST",
        "DROP",
        "NQ",
        "RealTimeQA",
        "WebQs"
      ],
      "models": [
        "ASKMEANYTHING PROMPTING (AMA)",
        "GPT-J-6B",
        "GPT3-175B",
        "EleutherAI",
        "BLOOM",
        "OPT",
        "T0"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Better Chain-of-Thought Prompting Strategies A Survey": {
    "filename": "Towards Better Chain-of-Thought Prompting Strategies A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "mathematical reasoning",
        "symbolic reasoning",
        "table QA",
        "commonsense QA"
      ],
      "models": [
        "Vanilla CoT",
        "Zeroshot-CoT",
        "Synthetic",
        "Auto-CoT",
        "ART",
        "Active-Prompt",
        "APE",
        "Faithfull-CoT",
        "Explanation Selection",
        "Complexity-based prompting",
        "SC",
        "DIVERSE",
        "Rationale-augmented",
        "Table-CoT",
        "Dater",
        "SOLIS",
        "LtM",
        "Decomposed",
        "PAL",
        "PoT",
        "Selectioninference",
        "Algorithmic prompt",
        "LP",
        "MoT",
        "SV",
        "MathPrompter",
        "Automate-CoT",
        "PHP",
        "iCAP",
        "Multimodal-CoT",
        "Self-ask",
        "IRCoT",
        "MCR",
        "Maieutic",
        "PINTO",
        "Chameleon",
        "RR",
        "Self-planning",
        "XRICL",
        "DIN-SQL",
        "Imitation Attack CoT",
        "MMRSelect",
        "Concise-CoT",
        "HuggingGPT",
        "Toolformer",
        "Dynamix-LtM",
        "STaR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Camels in a Changing Climate Enhancing LM Adaptation with Tulu 2": {
    "filename": "Camels in a Changing Climate Enhancing LM Adaptation with Tulu 2.pdf",
    "analysis": {
      "benchmarks": [
        "MT-Bench",
        "AlpacaEval",
        "MMLU",
        "GSM8k",
        "Big Bench Hard",
        "TydiQA",
        "CodexEval",
        "ToxiGen",
        "TruthfulQA"
      ],
      "models": [
        "T\u00dcLU 2",
        "T\u00dcLU 2+DPO",
        "CODE T\u00dcLU 2",
        "LLAMA-2",
        "LLAMA-2-Chat",
        "Zephyr-Beta",
        "Xwin-LM",
        "WizardLM",
        "OpenChat",
        "MISTRAL-Instruct",
        "Mosaic Pretrained Transformer (MPT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompting GPT-3 To Be Reliable": {
    "filename": "Prompting GPT-3 To Be Reliable.pdf",
    "analysis": {
      "benchmarks": [
        "MRQA",
        "AdvGLUE",
        "Contrast Sets",
        "HANS",
        "PAWS",
        "WinoBias",
        "BBQ",
        "NQ",
        "TriviaQA",
        "HotpotQA",
        "SQuAD"
      ],
      "models": [
        "GPT-3",
        "RoBERTa",
        "BERT",
        "DPR-BERT",
        "T5",
        "Atlas-11B",
        "Code-Davinci-002",
        "Text-Davinci-001",
        "Text-Curie-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot": {
    "filename": "Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot.pdf",
    "analysis": {
      "benchmarks": [
        "Schema-Guided Dialogue (SGD)",
        "MultiWOZ2.0",
        "MultiWOZ2.4",
        "Persona-Chat"
      ],
      "models": [
        "Large Language Model (LLM)",
        "Variational Graph Auto-Encoder (VGAE)",
        "LLaMA3",
        "GPT-3.5",
        "GPT-4o",
        "TRADE",
        "SUMBT",
        "SimpleTOD",
        "T5DST",
        "DiSTRICT",
        "SynthDST",
        "S3DST",
        "IC-DST",
        "ParsingDST",
        "UNO",
        "TransferQA",
        "GAT",
        "GraphSAGE",
        "GIN",
        "CGN-JK",
        "GTN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers": {
    "filename": "A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT-4",
        "ChatGPT-3.5",
        "Cohere",
        "Copilot",
        "Llama 2 70B",
        "Mistral 7B",
        "Gemini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reasoning with Language Model Prompting A Survey": {
    "filename": "Reasoning with Language Model Prompting A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "CommonsenseQA"
      ],
      "models": [
        "GPT-3",
        "Codex",
        "ChatGPT",
        "UL2",
        "LaMDA",
        "PaLM",
        "BART",
        "T5",
        "InstructGPT",
        "UnifiedQA",
        "ROBERTA",
        "Flan-T5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RoboVQA Multimodal Long-Horizon Reasoning for Robotics": {
    "filename": "RoboVQA Multimodal Long-Horizon Reasoning for Robotics.pdf",
    "analysis": {
      "benchmarks": [
        "RoboVQA",
        "long-horizon planning benchmark"
      ],
      "models": [
        "RoboVQA-VideoCoCa",
        "PaLM-E-562B",
        "SayCan",
        "Grounded Decoding",
        "VideoCoCa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-augmented Preference Learning from Natural Language": {
    "filename": "LLM-augmented Preference Learning from Natural Language.pdf",
    "analysis": {
      "benchmarks": [
        "Compsent-19",
        "College Confidential"
      ],
      "models": [
        "LLaMa-2-13B",
        "LLaMa-2-70B",
        "GPT-3.5-Turbo",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Retrieval Head Mechanistically Explains Long-Context Factuality": {
    "filename": "Retrieval Head Mechanistically Explains Long-Context Factuality.pdf",
    "analysis": {
      "benchmarks": [
        "Needle-in-a-Haystack",
        "MMLU",
        "MuSiQue",
        "GSM8K"
      ],
      "models": [
        "Llama-2-7B",
        "Llama-2-7B-80K",
        "Llama-2-13B-64K",
        "Mistral-7B-v0.2",
        "Mistral-7B-Instruct-v0.2",
        "Mixtral-8x7B-v0.1",
        "Yi-6B",
        "Yi-6B-200K",
        "Yi-34B-200K",
        "Qwen1.5-14B",
        "Qwen1.5-14B-Chat"
      ]
    }
  },
  "Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers": {
    "filename": "Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers.pdf",
    "analysis": {
      "benchmarks": [
        "ReClor",
        "Commonsense QA",
        "ARC",
        "PIQA",
        "HellaSwag",
        "Abductive NLI",
        "HotpotQA",
        "WikiHop",
        "MuTual",
        "DREAM",
        "RACE",
        "MNLI",
        "SNLI"
      ],
      "models": [
        "ReasonFormer",
        "Vanilla T5",
        "Reasoning Pre-Trained T5 (RPT-T5)",
        "Mixture-of-Reasoning Modules (MoRM)",
        "RPT-MoRM"
      ]
    }
  },
  "AgentAvatar Disentangling Planning Driving and Rendering for Photorealistic Avatar Agents": {
    "filename": "AgentAvatar Disentangling Planning Driving and Rendering for Photorealistic Avatar Agents.pdf",
    "analysis": {
      "benchmarks": [
        "DailyDialogue",
        "EnvPersona",
        "Vico Dataset"
      ],
      "models": [
        "LLM-Based Planner",
        "Task-agnostic Driving Model",
        "Rendering Model",
        "PD-FGC",
        "LM-Listener"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Power of Adaptation Boosting In-Context Learning through Adaptive Prompting": {
    "filename": "The Power of Adaptation Boosting In-Context Learning through Adaptive Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "AQuA",
        "StrategyQA",
        "CSQA",
        "Letter Concat"
      ],
      "models": [
        "Adaptive-Prompt",
        "Zero-Shot CoT",
        "Few-Shot CoT",
        "Auto-CoT",
        "Random-CoT",
        "Active-Prompt",
        "GPT-3.5 Turbo",
        "GPT-4o Mini",
        "LLaMA3-8B"
      ]
    }
  },
  "UniBias Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation": {
    "filename": "UniBias Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation.pdf",
    "analysis": {
      "benchmarks": [
        "SST2",
        "AGnews",
        "ARC",
        "MNLI",
        "WiC",
        "COPA",
        "CR",
        "MR",
        "RTE",
        "SST-5",
        "TREC",
        "MMLU"
      ],
      "models": [
        "UniBias",
        "Llama-2 7b",
        "Llama-2 13b",
        "GPT-J",
        "GPT2-XL",
        "Contextual Calibration (CC)",
        "Domain-Context Calibration (DC)",
        "Prototypical Calibration (PC)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Generate Transform Answer Question Specific Tool Synthesis for Tabular Data": {
    "filename": "Generate Transform Answer Question Specific Tool Synthesis for Tabular Data.pdf",
    "analysis": {
      "benchmarks": [
        "WikiTableQuestions",
        "WikiSQL",
        "WikiTableQuestions-Filter"
      ],
      "models": [
        "ToolWriter",
        "BART",
        "TapEx",
        "Omnitab",
        "UnifiedSKG",
        "FlanT5",
        "GPT-3"
      ]
    }
  },
  "Empowering Time Series Analysis with Large Language Models A Survey": {
    "filename": "Empowering Time Series Analysis with Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC III",
        "NYU Langone EHR database"
      ],
      "models": [
        "GPT-3",
        "GPT-4",
        "Llama 2",
        "T5",
        "Flan-T5",
        "ChatGLM",
        "PaLM",
        "PromptCast",
        "LLMTime",
        "Time-LLM",
        "OFA",
        "TEMPO",
        "TEST",
        "LLM4TS",
        "LAMP",
        "METS",
        "NYUTron",
        "AuxMobLCast",
        "LLM-Mob",
        "ST-LLM",
        "GATGPT",
        "LA-GCN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Simplifying Multimodality Unimodal Approach to Multimodal Challenges in Radiology with General-Domain Large Language Model": {
    "filename": "Simplifying Multimodality Unimodal Approach to Multimodal Challenges in Radiology with General-Domain Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-CXR"
      ],
      "models": [
        "MID-M",
        "Flamingo",
        "OpenFlamingo",
        "IDEFICS",
        "OTTER",
        "MedFlamingo",
        "RadFM",
        "Flan-T5-xl"
      ]
    }
  },
  "Attention Is All You Need for LLM-based Code Vulnerability Localization": {
    "filename": "Attention Is All You Need for LLM-based Code Vulnerability Localization.pdf",
    "analysis": {
      "benchmarks": [
        "Big-Vul",
        "CVEFixes-C",
        "SmartFix",
        "CVEFixes-J-M",
        "CVEFixes-P-M",
        "CVEFixes-J",
        "CVEFixes-P"
      ],
      "models": [
        "LOVA",
        "vanilla output",
        "CoT output",
        "MoA output",
        "rStar output",
        "Llama-3.1-8B-Instruct",
        "Mistral-7B-Instruct-v0.2",
        "Phi-3.5-mini-instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SAM-E Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation": {
    "filename": "SAM-E Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation.pdf",
    "analysis": {
      "benchmarks": [
        "RLBench"
      ],
      "models": [
        "SAM-E",
        "RVT",
        "PerAct",
        "R3M",
        "CLIP",
        "DINO",
        "SAM-E (SAM \u2192RVT)",
        "SAM-E (SAM \u2192R3M)",
        "SAM-E (SAM \u2192CLIP)",
        "SAM-E (SAM \u2192DINO)",
        "Hiveformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Foundation Models Help Us Achieve Perfect Secrecy": {
    "filename": "Can Foundation Models Help Us Achieve Perfect Secrecy.pdf",
    "analysis": {
      "benchmarks": [
        "Sentiment140",
        "20News",
        "CelebA",
        "CIFAR10",
        "Federated EMNIST",
        "Reddit",
        "MRQA"
      ],
      "models": [
        "in-context learning",
        "federated learning",
        "T0 (3B and 11B parameters)",
        "GPT-3 (125M, 1.3B, 2.7B, 6.7B and 175B parameters)",
        "MPNet-base bi-encoders",
        "CLIP",
        "ViT(S)",
        "ResNet101",
        "DistillBERT",
        "Stacked-LSTM",
        "FedAvg"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RVISA Reasoning and Verification for Implicit Sentiment Analysis": {
    "filename": "RVISA Reasoning and Verification for Implicit Sentiment Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "SemEval-2014 Restaurant",
        "SemEval-2014 Laptop"
      ],
      "models": [
        "RVISA",
        "Flan-T5",
        "Flan-T5-XXL",
        "T5-Large",
        "GPT-3.5-turbo",
        "Vicuna-13B",
        "BERT+SPC",
        "BERT+ADA",
        "BERT+RGAT",
        "BERT Asp+CEPT",
        "BERT Asp+SCAPT",
        "THOR",
        "ABSA-ESA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "World Models for Math Story Problems": {
    "filename": "World Models for Math Story Problems.pdf",
    "analysis": {
      "benchmarks": [
        "MAWPS",
        "ASD IV-A",
        "SVAMP"
      ],
      "models": [
        "MATHWORLD",
        "GPT-3",
        "Codex",
        "GPT-2",
        "BART",
        "T5",
        "NT5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Pre-trained Language Models Can be Fully Zero-Shot Learners": {
    "filename": "Pre-trained Language Models Can be Fully Zero-Shot Learners.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "AG News",
        "DBPedia",
        "IMDB",
        "Amazon",
        "CommonsenseQA"
      ],
      "models": [
        "NPPrompt",
        "BERT",
        "RoBERTa",
        "GPT-3",
        "ChatGPT",
        "SimPTC",
        "LOTClass",
        "KPT",
        "Null Prompt",
        "Multi-Null Prompt",
        "NSP-BERT",
        "Semantic Retrieval",
        "ManualVerb"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DrLLM Prompt-Enhanced Distributed Denial-of-Service Resistance Method with Large Language Models": {
    "filename": "DrLLM Prompt-Enhanced Distributed Denial-of-Service Resistance Method with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CICD-DoS2019"
      ],
      "models": [
        "DrLLM",
        "GPT-4o-mini",
        "Llama3-70b",
        "Deepseek-chat-v2",
        "Qwen2-57b-a14b-instruct"
      ]
    }
  },
  "AGI for Agriculture": {
    "filename": "AGI for Agriculture.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "AlphaGo",
        "ChatGPT",
        "BERT",
        "BioBERT",
        "PubMedBERT",
        "LEGAL-BERT",
        "AgriBERT",
        "GPT-1",
        "GPT-2",
        "GPT-3",
        "InstructGPT",
        "LLaMA",
        "BLOOM",
        "Stable Diffusion",
        "PointNet",
        "MaskRCNN",
        "SDEdit",
        "SAM",
        "YOLOv5",
        "Vision Transformers (ViT)",
        "GraphGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VELOCITI Can Video-Language Models Bind Semantic Concepts through Time": {
    "filename": "VELOCITI Can Video-Language Models Bind Semantic Concepts through Time.pdf",
    "analysis": {
      "benchmarks": [
        "VELOCITI",
        "VidSitu",
        "Winoground",
        "SEED-Bench",
        "MVBench",
        "VideoCon",
        "AGQA",
        "STAR",
        "CATER",
        "Mementos",
        "CVRR-ES",
        "Perception Test",
        "SugarCrepe",
        "ARO",
        "Cola"
      ],
      "models": [
        "Gemini 1.5 Flash",
        "Video-LLaVA",
        "CLIP",
        "EV A-CLIP",
        "SigLIP",
        "NegCLIP",
        "CLIP-ViP",
        "ViFi-CLIP",
        "mPLUG-Owl-Video",
        "PLLaVA",
        "Owl-Con"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Parsel Algorithmic Reasoning with Language Models by Composing Decompositions": {
    "filename": "Parsel Algorithmic Reasoning with Language Models by Composing Decompositions.pdf",
    "analysis": {
      "benchmarks": [
        "APPS",
        "HumanEval",
        "VirtualHome"
      ],
      "models": [
        "Parsel",
        "AlphaCode",
        "Codex",
        "GPT-4",
        "Codex (Direct)",
        "Codex (Orig.)",
        "Codex (Curr.)",
        "Codex (@16)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DRESS  Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback": {
    "filename": "DRESS  Instructing Large Vision-Language Models to Align and Interact with Humans via Natural Language Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "LLaVA Eval",
        "LLaVA Bench",
        "COCO",
        "VLSafe",
        "VQA V2",
        "OK-VQA",
        "GQA"
      ],
      "models": [
        "DRESS",
        "BLIP-2",
        "InstructBLIP",
        "LLaVA",
        "LLaVA-HF",
        "mPLUG",
        "miniGPT4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence": {
    "filename": "Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence.pdf",
    "analysis": {
      "benchmarks": [
        "CORTEX BENCH",
        "Adroit",
        "MetaWorld",
        "DMControl",
        "TriFinger",
        "ObjectNav",
        "ImageNav",
        "MobilePick",
        "Habitat",
        "Habitat 2.0"
      ],
      "models": [
        "VC-1",
        "VC-1 (adapted)",
        "CLIP",
        "R3M",
        "MVP",
        "VIP",
        "Random (ViT-B)",
        "Random (ViT-L)",
        "Ego4D (ViT-B)",
        "Ego4D (ViT-L)",
        "Ego4D+N (ViT-B)",
        "Ego4D+N (ViT-L)",
        "Ego4D+M (ViT-B)",
        "Ego4D+M (ViT-L)",
        "Ego4D+MN (ViT-B)",
        "Ego4D+MN (ViT-L)",
        "Ego4D+MNI (ViT-B)",
        "Ego4D+MNI (ViT-L)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reprompting Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling": {
    "filename": "Reprompting Automated Chain-of-Thought Prompt Inference Through Gibbs Sampling.pdf",
    "analysis": {
      "benchmarks": [
        "Big-Bench Hard (BBH)",
        "GSM8K",
        "MATH"
      ],
      "models": [
        "Reprompting",
        "ChatGPT",
        "InstructGPT",
        "self-consistency decoding",
        "Auto-CoT",
        "Automatic Prompt Optimization (APO)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain-of-Thought Unfaithfulness as Disguised Accuracy": {
    "filename": "Chain-of-Thought Unfaithfulness as Disguised Accuracy.pdf",
    "analysis": {
      "benchmarks": [
        "AQuA-RAT",
        "ARC-Challenge",
        "ARC-Easy",
        "HellaSwag",
        "LogiQA",
        "MMLU",
        "OpenBookQA",
        "TruthfulQA"
      ],
      "models": [
        "Llama 2",
        "FLAN-T5",
        "FLAN-UL2",
        "Pythia DPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Internet-augmented language models through few-shot prompting for open-domain question answering": {
    "filename": "Internet-augmented language models through few-shot prompting for open-domain question answering.pdf",
    "analysis": {
      "benchmarks": [
        "NQ",
        "HOTPOT QA",
        "STRATEGY QA",
        "FEVER",
        "SituatedQA"
      ],
      "models": [
        "GOPHER-280B",
        "OBGoogle",
        "OBGold",
        "CB",
        "OBNoisy Channel Google",
        "OBRAG Google",
        "OBPoE Google"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Generic LLMs Help Analyze Child-adult Interactions Involving Children with Autism in Clinical Observation": {
    "filename": "Can Generic LLMs Help Analyze Child-adult Interactions Involving Children with Autism in Clinical Observation.pdf",
    "analysis": {
      "benchmarks": [
        "Remote-NLS",
        "ADOSMod3"
      ],
      "models": [
        "Mistral-7B V0.2 Instruction",
        "LLaMa 2-7B Chat",
        "LLaMa 2-13B Chat",
        "LLaMa 3-8B Instruct",
        "Qwen1.5-7B Chat",
        "Qwen1.5-14B Chat",
        "RoBERTa"
      ]
    }
  },
  "SciInstruct a Self-Reflective Instruction Annotated Dataset for Training Scientific Language Models": {
    "filename": "SciInstruct a Self-Reflective Instruction Annotated Dataset for Training Scientific Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CEval-Sci",
        "SciEval",
        "SciBench",
        "MATH",
        "SAT-Math",
        "CEval-Hard",
        "MMLU-Sci",
        "GPQA_Diamond",
        "GSM8K",
        "Mathematics",
        "MMLU-Math",
        "CEval-Math",
        "MMLU",
        "CEval",
        "MBPP"
      ],
      "models": [
        "ChatGLM3-6B",
        "ChatGLM3-32B",
        "Llama3-8B-Instruct",
        "Mistral-7B: MetaMATH",
        "SciGLM",
        "Galactica",
        "GPT-3.5",
        "GPT-4",
        "ChatGLM2-6B",
        "ChatGLM2-6B-Base",
        "ChatGLM3-6B-Base",
        "LLaMA-2-7B",
        "LLaMA-2-13B",
        "Vicuna-13B",
        "WizardMath-7B",
        "MAmmoTH-7B",
        "MetaMath-7B",
        "MAmmoTH & MetaMath-7B",
        "Llama3-8B-Instruct (zero-shot)",
        "Llama3-8B-Instruct (few-shot)",
        "Mistral-7B: MetaMATH (zero-shot)",
        "Mistral-7B: MetaMATH (few-shot)",
        "WizardMath-13B",
        "MAmmoTH-13B",
        "MAmmoTH & MetaMath-13B",
        "Galactica-30B",
        "ChatGLM3-32B-Base",
        "SciGLM (ChatGLM3-6B-Base)",
        "SciGLM (ChatGLM3-32B-Base)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Promptify Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models": {
    "filename": "Promptify Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Stable Diffusion",
        "DALL-E-2",
        "GPT-3.5",
        "Automatic1111",
        "CLIP",
        "BLIP",
        "Sentence-BERT",
        "PaLM-E",
        "GANzilla",
        "GANravel"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering": {
    "filename": "Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "MSQA"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "PaLM",
        "LLaMA",
        "LLM+BM25",
        "LLM+DPR",
        "LLM+EXP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Privacy in Large Language Models Attacks Defenses and Future Directions": {
    "filename": "Privacy in Large Language Models Attacks Defenses and Future Directions.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "Claude 2",
        "Llama 2",
        "Pythia",
        "GPT-2",
        "BERT",
        "RoBERTa",
        "Bart",
        "T5",
        "ChatGPT",
        "New Bing",
        "BToP",
        "TFLexAttack",
        "DP-BART",
        "Bi-LSTM",
        "RoBERTa",
        "GPT-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CLEVA Chinese Language Models EVAluation Platform": {
    "filename": "CLEVA Chinese Language Models EVAluation Platform.pdf",
    "analysis": {
      "benchmarks": [
        "C-Eval",
        "M3KE",
        "CMMLU",
        "GAOKAO-Bench",
        "MMCU",
        "OpenCompass",
        "FlagEval",
        "CLEVA"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "BLOOMZ-176B-mt",
        "GLM-130B",
        "LLaMA-65B",
        "BLOOMZ-mt-7B",
        "BLOOM-7B1",
        "BLOOM-176B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Q How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks A Self-Train on Unlabeled Images": {
    "filename": "Q How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks A Self-Train on Unlabeled Images.pdf",
    "analysis": {
      "benchmarks": [
        "VQAv2",
        "A-OKVQA",
        "ArtVQA",
        "CC3M",
        "COCO 2017",
        "SemArt",
        "PathVQA",
        "RSVQA",
        "AdVQA",
        "VQA-CE",
        "VQA-Rephrasings"
      ],
      "models": [
        "SelTDA",
        "BLIP",
        "ViLBERT",
        "LXMERT",
        "KRISP",
        "GPV-2",
        "BAN",
        "VIKING",
        "VIKING VLM",
        "BLIP VQAv2",
        "BLIP + SelTDA",
        "BLIP VQAv2 + SelTDA",
        "VIKING VLM + SelTDA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OSCAR Operating System Control via State-Aware Reasoning and Re-Planning": {
    "filename": "OSCAR Operating System Control via State-Aware Reasoning and Re-Planning.pdf",
    "analysis": {
      "benchmarks": [
        "GAIA",
        "OSWorld",
        "AndroidWorld"
      ],
      "models": [
        "OSCAR",
        "GPT-4-turbo",
        "GPT-4 plugins",
        "UFO",
        "FRIDAY",
        "MMAC",
        "Cradle",
        "M3A",
        "Mobile Agent",
        "AppAgent"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VSP Assessing the dual challenges of perception and reasoning in spatial planning tasks for VLMs": {
    "filename": "VSP Assessing the dual challenges of perception and reasoning in spatial planning tasks for VLMs.pdf",
    "analysis": {
      "benchmarks": [
        "VSP",
        "MME",
        "MMMU",
        "MathVision",
        "SeedBench",
        "MM-Vet"
      ],
      "models": [
        "Gemini",
        "GPT-Vision",
        "Claude-3",
        "GPT-4o",
        "LLaVA",
        "InternLM",
        "InternLM-VL",
        "InstructBLIP",
        "SPHINX"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DiLu A Knowledge-Driven Approach to Autonomous Driving with Large Language Models": {
    "filename": "DiLu A Knowledge-Driven Approach to Autonomous Driving with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Highway-env",
        "CitySim"
      ],
      "models": [
        "DiLu",
        "GRAD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving Factuality and Reasoning in Language Models through Multiagent Debate": {
    "filename": "Improving Factuality and Reasoning in Language Models through Multiagent Debate.pdf",
    "analysis": {
      "benchmarks": [
        "Biographies",
        "MMLU",
        "Chess Move Validity",
        "Arithmetic",
        "GSM8K",
        "Chess Move Prediction"
      ],
      "models": [
        "Single Agent",
        "Single Agent (Reflection)",
        "Multi-Agent (Majority)",
        "Multi-Agent (Debate)",
        "chatGPT",
        "Bard"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent": {
    "filename": "Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4o-mini",
        "Llama3.1-8B",
        "Llama3.1-70B",
        "MA ToT with Thought Validator",
        "Standard IO",
        "CoT",
        "ToT"
      ]
    }
  },
  "Can Large Language Models Provide Security  Privacy Advice Measuring the Ability of LLMs to Refute Misconceptions": {
    "filename": "Can Large Language Models Provide Security  Privacy Advice Measuring the Ability of LLMs to Refute Misconceptions.pdf",
    "analysis": {
      "benchmarks": [
        "S&P Misconception Dataset"
      ],
      "models": [
        "ChatGPT",
        "Bard"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Progressive-Hint Prompting Improves Reasoning in Large Language Models": {
    "filename": "Progressive-Hint Prompting Improves Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SVAMP",
        "GSM8K",
        "AQuA",
        "MATH",
        "AddSub",
        "MultiArith",
        "SingleEQ"
      ],
      "models": [
        "text-davinci-002",
        "text-davinci-003",
        "GPT-3.5-Turbo",
        "GPT-4",
        "Progressive-Hint Prompting (PHP)",
        "PHP-CoT",
        "PHP-Complex CoT",
        "CoT",
        "Complex CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TrustGPT A Benchmark for Trustworthy and Responsible Large Language Models": {
    "filename": "TrustGPT A Benchmark for Trustworthy and Responsible Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "TRUST GPT",
        "PERSPECTIVE API",
        "REAL-TOXICITY PROMPTS",
        "BOLD",
        "SOCIAL CHEMISTRY 101",
        "BIG-BENCH HHH EVAL"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "LLaMa",
        "Alpaca",
        "Vicuna",
        "FastChat",
        "ChatGLM",
        "Oasst",
        "Koala"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Capture the Flag Uncovering Data Insights with Large Language Models": {
    "filename": "Capture the Flag Uncovering Data Insights with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Adidas Sales Dataset"
      ],
      "models": [
        "Explorer Agent",
        "Aggregator Agent"
      ]
    }
  },
  "How Does In-Context Learning Help Prompt Tuning": {
    "filename": "How Does In-Context Learning Help Prompt Tuning.pdf",
    "analysis": {
      "benchmarks": [
        "ToTTo",
        "DART",
        "Logic2Text",
        "Spider",
        "MTOP"
      ],
      "models": [
        "In-context learning (ICL)",
        "Prompt tuning (PT)",
        "Instruction prompt tuning (IPT)",
        "BLOOM 1.1B",
        "OPT 1.3B",
        "GPT2 XL 1.5B"
      ]
    }
  },
  "MedGPTEval A Dataset and Benchmark to Evaluate Responses of Large Language Models in Medicine": {
    "filename": "MedGPTEval A Dataset and Benchmark to Evaluate Responses of Large Language Models in Medicine.pdf",
    "analysis": {
      "benchmarks": [
        "MedGPTEval",
        "27 medical dialogues",
        "7 case reports"
      ],
      "models": [
        "ChatGPT",
        "ERNIE Bot",
        "Doctor PuJiang (Dr. PJ)"
      ]
    }
  },
  "Be My Donor Transfer the NLP Datasets Between the Languages Using LLM": {
    "filename": "Be My Donor Transfer the NLP Datasets Between the Languages Using LLM.pdf",
    "analysis": {
      "benchmarks": [
        "DEFT corpus",
        "RuSERRC dataset"
      ],
      "models": [
        "ChatGPT3.5-turbo",
        "Llama-3.1-8b",
        "BERT-based models",
        "BERT-base-multilingual",
        "RuBERT-base-cased",
        "RoBerta-base"
      ]
    }
  },
  "Large Language Models are Diverse Role-Players for Summarization Evaluation": {
    "filename": "Large Language Models are Diverse Role-Players for Summarization Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "CNN2022",
        "BBC2022",
        "SummEval"
      ],
      "models": [
        "DRPE",
        "GPT-D3",
        "BERTScore",
        "MoverScore",
        "ROUGE",
        "METEOR",
        "BLEU"
      ]
    }
  },
  "FINCH Prompt-guided Key-Value Cache Compression for Large Language Models": {
    "filename": "FINCH Prompt-guided Key-Value Cache Compression for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD v2",
        "LongBench",
        "NarrativeQA",
        "Qasper",
        "MultiFieldQA",
        "HotpotQA",
        "MultihopQA",
        "MuSiQue",
        "GovReport",
        "QMSum",
        "MultiNews",
        "TREC",
        "PassageCount",
        "LCC",
        "RepoBench-p"
      ],
      "models": [
        "FINCH",
        "Vanilla",
        "Truncate",
        "LongLLMLingua",
        "RAG",
        "Llama 2",
        "Mistral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can AI with High Reasoning Ability Replicate Human-like Decision Making in Economic Experiments": {
    "filename": "Can AI with High Reasoning Ability Replicate Human-like Decision Making in Economic Experiments.pdf",
    "analysis": {
      "benchmarks": [
        "ultimatum game",
        "MobLab"
      ],
      "models": [
        "gpt-3.5-turbo-0613",
        "gpt-4-1106-preview"
      ]
    }
  },
  "POEM Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models": {
    "filename": "POEM Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CMU-MOSEI",
        "WTaG"
      ],
      "models": [
        "POEM",
        "LLaVA",
        "GPT-4V(ision)",
        "gpt-4-turbo",
        "text-embedding-3-small",
        "CLIP",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mixture-of-Experts Meets Instruction Tuning A Winning Combination for Large Language Models": {
    "filename": "Mixture-of-Experts Meets Instruction Tuning A Winning Combination for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "BBH",
        "Reasoning",
        "QA",
        "GSM8K",
        "SVAMP",
        "ASDIV",
        "StrategyQA",
        "UnifiedQA",
        "BoolQ",
        "ARC-easy",
        "ARC-challenge",
        "TyDiQA",
        "MGSM"
      ],
      "models": [
        "FLAN-MOE32B",
        "FLAN-PALM 62B",
        "FLAN-T5SMALL",
        "FLAN-T5BASE",
        "FLAN-T5LARGE",
        "FLAN-T5XL",
        "FLAN-T5XXL",
        "FLAN-PaLM",
        "Switch BASE",
        "FLAN-Switch BASE",
        "Switch LARGE",
        "FLAN-Switch LARGE",
        "Switch XXL",
        "FLAN-Switch XXL",
        "GS SMALL",
        "FLAN-GS SMALL",
        "GS BASE",
        "FLAN-GS BASE",
        "GS LARGE",
        "FLAN-GS LARGE",
        "GS XL",
        "FLAN-GS XL",
        "EC SMALL",
        "FLAN-EC SMALL",
        "EC BASE",
        "FLAN-EC BASE",
        "EC LARGE",
        "FLAN-EC LARGE",
        "EC XL",
        "FLAN-EC XL",
        "ST BASE",
        "FLAN-ST BASE",
        "ST32B",
        "FLAN-ST 32B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Multitask Multilingual Multimodal Evaluation of ChatGPT on Reasoning Hallucination and Interactivity": {
    "filename": "A Multitask Multilingual Multimodal Evaluation of ChatGPT on Reasoning Hallucination and Interactivity.pdf",
    "analysis": {
      "benchmarks": [
        "CNN/DM",
        "SAMSum",
        "FLoRes-200",
        "NusaX",
        "bAbI task",
        "EntailmentBank",
        "CLUTRR",
        "StepGame",
        "Pep-3k",
        "COVID-Social",
        "COVID-Scientific",
        "MultiWOZ2.2",
        "OpenDialKG",
        "CommonsenseQA",
        "PIQA",
        "SpartQA",
        "Math",
        "Timedial",
        "hotpotQA",
        "\u03b1NLI",
        "E-Care",
        "Letter string analogy",
        "TruthfulQA"
      ],
      "models": [
        "ChatGPT",
        "InstructGPT",
        "NLLB-200",
        "XLM-R LARGE",
        "ST-MoE-32B",
        "ZeroQA",
        "GPT-3",
        "GPT-2",
        "D3ST",
        "GPT-Jurassic-6B",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InfoCon Concept Discovery with Generative and Discriminative Informativeness": {
    "filename": "InfoCon Concept Discovery with Generative and Discriminative Informativeness.pdf",
    "analysis": {
      "benchmarks": [
        "P&P Cube",
        "Stack Cube",
        "Turn Faucet",
        "Peg Insertion"
      ],
      "models": [
        "InfoCon",
        "Decision Transformer",
        "Last State",
        "AWE",
        "LLM+CLIP",
        "GT Key States"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Pose Priors from Language Models": {
    "filename": "Pose Priors from Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Hi4D",
        "FlickrCI3D",
        "CHI3D",
        "MOYO"
      ],
      "models": [
        "ProsePose",
        "BEV",
        "Heuristic",
        "BUDDI",
        "HMR2",
        "HMR2+opt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Calibrating Reasoning in Language Models with Internal Consistency": {
    "filename": "Calibrating Reasoning in Language Models with Internal Consistency.pdf",
    "analysis": {
      "benchmarks": [
        "PrOntoQA",
        "BoolQ",
        "CoinFlip",
        "ProofWriter"
      ],
      "models": [
        "Llama-2-7B",
        "Llama-2-13B",
        "Mistral-7B",
        "Mixtral-8x7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Revisiting Relation Extraction in the era of Large Language Models": {
    "filename": "Revisiting Relation Extraction in the era of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ADE",
        "CoNLL",
        "NYT",
        "DocRED"
      ],
      "models": [
        "GPT-3",
        "Flan-T5 large",
        "REBEL",
        "SpERT",
        "TANL",
        "BART"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Wisdom of Hindsight Makes Language Models Better Instruction Followers": {
    "filename": "The Wisdom of Hindsight Makes Language Models Better Instruction Followers.pdf",
    "analysis": {
      "benchmarks": [
        "BigBench"
      ],
      "models": [
        "HIR",
        "FLAN-T5-Large",
        "FLAN-T5-Base",
        "PPO",
        "Final-Answer RL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Object Hallucination in Large Vision-Language Models": {
    "filename": "Evaluating Object Hallucination in Large Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MSCOCO",
        "A-OKVQA",
        "GQA"
      ],
      "models": [
        "mPLUG-Owl",
        "LLaVA",
        "MultiModal-GPT",
        "MiniGPT-4",
        "InstructBLIP",
        "OSCAR",
        "VinVL",
        "BLIP",
        "OFA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Multilingual Information Retrieval in Mixed Human Resources Environments A RAG Model Implementation for Multicultural Enterprise": {
    "filename": "Enhancing Multilingual Information Retrieval in Mixed Human Resources Environments A RAG Model Implementation for Multicultural Enterprise.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "RAG",
        "GPT-3",
        "GPT-4",
        "LLaMA2",
        "LAMBADA",
        "PALM"
      ]
    }
  },
  "Auctions with LLM Summaries": {
    "filename": "Auctions with LLM Summaries.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Factorized Model for Auctions with LLM Summaries",
        "Dynamic Word Length Summary (DWLS)",
        "Generalized Proportional Auction (GPA+LLM)",
        "Greedy Auction",
        "Position Auction with Fixed Length"
      ]
    }
  },
  "AgentStore Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant": {
    "filename": "AgentStore Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant.pdf",
    "analysis": {
      "benchmarks": [
        "OSWorld",
        "APPAgent"
      ],
      "models": [
        "AgentStore",
        "MetaAgent",
        "MMAgent",
        "CRADLE",
        "Friday",
        "Open-Interpreter",
        "CogAgent",
        "InternVL2-8B",
        "GPT-4o",
        "Qwen-VL",
        "Llama 3.1",
        "ToolkenGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DisasterQA A Benchmark for Assessing the performance of LLMs in Disaster Response": {
    "filename": "DisasterQA A Benchmark for Assessing the performance of LLMs in Disaster Response.pdf",
    "analysis": {
      "benchmarks": [
        "DisasterQA"
      ],
      "models": [
        "GPT-3.5 Turbo",
        "GPT-4 Turbo",
        "GPT-4o",
        "Llama 3.1-8B Instruct",
        "Gemini 1.5 Flash"
      ]
    }
  },
  "LLM as BT-Planner Leveraging LLMs for Behavior Tree Generation in Robot Task Planning": {
    "filename": "LLM as BT-Planner Leveraging LLMs for Behavior Tree Generation in Robot Task Planning.pdf",
    "analysis": {
      "benchmarks": [
        "Siemens Robot Assembly Challenge",
        "Furniture Assembly Benchmark"
      ],
      "models": [
        "LLM as BT-planner",
        "GPT-4",
        "GPT-3.5",
        "Mistral-7B",
        "Llama2-13B-chat"
      ]
    }
  },
  "ChatGPT4PCG 2 Competition Prompt Engineering for Science Birds Level Generation": {
    "filename": "ChatGPT4PCG 2 Competition Prompt Engineering for Science Birds Level Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Science Birds"
      ],
      "models": [
        "ChatGPT4PCG 2",
        "dereventsolve",
        "The Organizer",
        "Soda",
        "AdrienTeam",
        "Saltyfish1884",
        "zeilde",
        "Team Staciiaz",
        "Harry Single Group",
        "hachi",
        "Back to the future",
        "v1 (Baseline)",
        "JUSTIN",
        "Hope",
        "albatross",
        "Prompt Wranglers",
        "For500"
      ]
    }
  },
  "Adapting LLM Agents with Universal Feedback in Communication": {
    "filename": "Adapting LLM Agents with Universal Feedback in Communication.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld",
        "HotpotQA",
        "Chameleon",
        "GSM8k"
      ],
      "models": [
        "LTC",
        "ReAct",
        "ReAct-IM",
        "BUTLER",
        "ReAct-Tuning",
        "CoT-Tuning",
        "Llama-7B",
        "Llama2-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Lifelong Robot Learning with Human Assisted Language Planners": {
    "filename": "Lifelong Robot Learning with Human Assisted Language Planners.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLM-based planners",
        "Neural Descriptor Fields (NDFs)",
        "TransporterNets",
        "Contact-GraspNet",
        "GPT-4",
        "SAM",
        "CLIP",
        "ViLD",
        "SayCan",
        "InnerMonologue",
        "NLMap-SayCan",
        "Socratic Models",
        "CLIPort",
        "Interactive Language",
        "RT1",
        "PerAct",
        "VIMA",
        "Palm-e",
        "Diffusion Policy",
        "BERT",
        "Detic"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can LLMs Replace Manual Annotation of Software Engineering Artifacts": {
    "filename": "Can LLMs Replace Manual Annotation of Software Engineering Artifacts.pdf",
    "analysis": {
      "benchmarks": [
        "Code Summarization",
        "Name-Value Inconsistencies",
        "Causality",
        "Semantic Similarity",
        "Static Analysis Warning"
      ],
      "models": [
        "GPT-4",
        "Claude-3.5-Sonnet",
        "Gemini-1.5-Pro",
        "GPT-3.5",
        "Llama3 (70B)",
        "Mixtral (8x22B)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "When Brain-inspired AI Meets AGI": {
    "filename": "When Brain-inspired AI Meets AGI.pdf",
    "analysis": {
      "benchmarks": [
        "VQA dataset",
        "GSM8K"
      ],
      "models": [
        "BERT",
        "GPT",
        "GPT-2",
        "GPT-3",
        "Vision Transformer (ViT)",
        "CLIP",
        "DALL-E",
        "GLIDE",
        "VisualGPT",
        "Stable Diffusion",
        "METER",
        "VLMo",
        "ClipBERT",
        "VIOLET",
        "SwinBERT",
        "ChatGPT",
        "GPT-4",
        "InstructGPT",
        "BI-AVAN",
        "CP-ViT",
        "CP-CNNs",
        "SNNs"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment": {
    "filename": "Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "AlpacaFarm",
        "Anthropic's hh-rlhf",
        "Helpfulness",
        "Harmlessness"
      ],
      "models": [
        "Regularized Best-of-N (RBoN)",
        "Best-of-N (BoN)",
        "RBoN KL",
        "RBoN WD",
        "DPO model",
        "Mistral",
        "Dolly"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SuperCorrect Supervising and Correcting Language Models with Error-Driven Insights": {
    "filename": "SuperCorrect Supervising and Correcting Language Models with Error-Driven Insights.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K"
      ],
      "models": [
        "SUPER CORRECT -7B",
        "DeepSeekMath-7B",
        "Qwen2.5-Math-7B",
        "Llama-3-8B",
        "DeepSeekMath-Base",
        "SUPER CORRECT -Qwen/DeepSeek/Llama-7B",
        "Llama-3-70B-Instruct",
        "DeepSeek-Coder-V2-Instruct",
        "Code-Llama-7B",
        "MAmooTH-CoT",
        "WizardMath",
        "MetaMath",
        "MetaMath-Mistral-7B",
        "MathScale-Mistral",
        "InternLM-Math-7B",
        "Xwin-Math-Mistral-7B",
        "MAmmoTH2-7B-Plus",
        "MathGenieLM-Mistral",
        "InternLM-Math-20B",
        "MathGenieLM-InternLM2",
        "Meta-Llama3.1-8B-Instruct",
        "SUPER CORRECT -Llama-8B",
        "DeepSeekMath-7B-Instruct",
        "SUPER CORRECT -DeepSeek-7B",
        "Qwen2.5-Math-7B-Instruct",
        "SUPER CORRECT -Qwen-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MathDial A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems": {
    "filename": "MathDial A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems.pdf",
    "analysis": {
      "benchmarks": [
        "MATHDIAL",
        "CIMA",
        "TSCC",
        "TalkMoves",
        "NCTE",
        "GSM8k"
      ],
      "models": [
        "GPT-3",
        "ChatGPT",
        "Instruct-GPT",
        "BART 139M",
        "BART 406M",
        "T5 250M",
        "T5 780M",
        "Flan-T5 250M",
        "Flan-T5 780M",
        "Flan-T5 3B",
        "OPT 125M",
        "OPT 1.3B",
        "NextStep"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CyberPalAI Empowering LLMs with Expert-Driven Cybersecurity Instructions": {
    "filename": "CyberPalAI Empowering LLMs with Expert-Driven Cybersecurity Instructions.pdf",
    "analysis": {
      "benchmarks": [
        "SecKnowledge-Eval",
        "CyberBench",
        "CyberMetric",
        "CTI-MCQ",
        "SecEval",
        "MMLU Computer Security (SecMMLU)",
        "Cybersecurity Skill Assessment",
        "CISSP Assessment Questions",
        "CTI Relationship Prediction",
        "CTI Entity Classification",
        "Cyber Threat Intelligence Root Cause Mapping (CTI-RCM)",
        "CWE Description Summarization"
      ],
      "models": [
        "CyberPal.AI",
        "Llama-3 instruct 8B",
        "Mistral instruct 7B v0.3",
        "Phi-3-medium-4k-instruct",
        "Gemma-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large AI Models in Health Informatics Applications Challenges and the Future": {
    "filename": "Large AI Models in Health Informatics Applications Challenges and the Future.pdf",
    "analysis": {
      "benchmarks": [
        "CASP14",
        "MedQA",
        "USMLE",
        "ImageNet",
        "MultiMedQA"
      ],
      "models": [
        "ChatGPT",
        "SAM",
        "AlphaFold2",
        "AlphaFold-Multimer",
        "ProGen",
        "ProtT5-XXL",
        "ESMfold",
        "OmegaFold",
        "xTrimoPGLM",
        "CheXzero",
        "ChatCAD",
        "ChatCAD+",
        "ChatDoctor",
        "XrayGPT",
        "HeartBEiT",
        "BEHRT",
        "Med-BERT",
        "MedCLIP",
        "PLIP",
        "Med3D",
        "STU-Net",
        "BioBERT",
        "ClinicalBERT",
        "BioMegatron",
        "BioMedRoBERTa",
        "Bio-ELECTRA",
        "PubMedBERT",
        "BioLinkBERT",
        "BioGPT",
        "Med-PaLM",
        "GatorTron",
        "MedAlpaca",
        "Med-PaLM 2",
        "InstructGPT",
        "GPT-3",
        "OPTICAL",
        "ClimaX",
        "Pangu-Weather",
        "Endo-FM",
        "Surgical-GPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "APIGen Generative API Method Recommendation": {
    "filename": "APIGen Generative API Method Recommendation.pdf",
    "analysis": {
      "benchmarks": [
        "APIBENCH-Q",
        "BIKER-Dataset"
      ],
      "models": [
        "APIGen",
        "CLEAR",
        "BIKER",
        "DeepAPI",
        "RACK"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dont Add dont Miss Effective Content Preserving Generation from Pre-Selected Text Spans": {
    "filename": "Dont Add dont Miss Effective Content Preserving Generation from Pre-Selected Text Spans.pdf",
    "analysis": {
      "benchmarks": [
        "DUC summarization dataset",
        "CTR development set",
        "CTR test set"
      ],
      "models": [
        "baseline CTR model",
        "Flan-T5 H",
        "Flan-T5 H + RL",
        "Flan-T5 H + Controlled Decoding",
        "Flan-T5 H + RL + Controlled Decoding",
        "Flan-T5 H (distilled)",
        "Flan-T5 H (distilled) + RL",
        "Flan-T5 H (distilled) + Controlled Decoding",
        "Flan-T5 H (distilled) + RL + Controlled Decoding",
        "LED H",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "STREET A Multi-Task Structured Reasoning and Explanation Benchmark": {
    "filename": "STREET A Multi-Task Structured Reasoning and Explanation Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "STREET",
        "GSM8K",
        "AR-LSAT",
        "ARC",
        "SCONE",
        "AQUA-RAT"
      ],
      "models": [
        "GPT-3",
        "T5",
        "T5 [large] (fine-tuned)",
        "GPT-3 [davinci] (few-shot)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "D3 Data Diversity Design for Systematic Generalization in Visual Question Answering": {
    "filename": "D3 Data Diversity Design for Systematic Generalization in Visual Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "CLEVR",
        "TallyQA",
        "GQA"
      ],
      "models": [
        "FiLM",
        "MAC",
        "VectorNMN",
        "VectorNMN GT",
        "VectorNMNSepStem",
        "GPT-2 style transformer",
        "MiniGPT-v2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Are Latent Variable Models Explaining and Finding Good Demonstrations for In-Context Learning": {
    "filename": "Large Language Models Are Latent Variable Models Explaining and Finding Good Demonstrations for In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "SST2",
        "FPB",
        "COLA",
        "DBpedia",
        "EmoC",
        "ETHOS-SO",
        "ETHOS-R",
        "GSM8K"
      ],
      "models": [
        "GPT2-large",
        "GPT3",
        "GPT3-instruct",
        "GPT-J",
        "OPT",
        "LLaMA",
        "Llama 2",
        "ChatGPT",
        "GPT3-ada",
        "GPT2-XL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EchoAtt Attend Copy then Adjust for More Efficient Large Language Models": {
    "filename": "EchoAtt Attend Copy then Adjust for More Efficient Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "IMDB",
        "mmlu",
        "winogrande",
        "swag",
        "hellaswag",
        "xnli_en",
        "agieval_en",
        "TruthfulQA_mc1",
        "TruthfulQA_mc2"
      ],
      "models": [
        "EchoAtt",
        "TinyLLaMA-1.1B",
        "Pythia-1B",
        "TinyLlaMA-1B",
        "LlaMA1-7B",
        "LlaMA2-7B",
        "LlaMA2-7B Chat",
        "LlaMA2-13B",
        "Shared-Attention TinyLlaMA",
        "Distilled-Shared-Attn",
        "Continual-Distilled-Shared-Attn",
        "LlaMA-160m"
      ]
    }
  },
  "Arithmetic Control of LLMs for Diverse User Preferences Directional Preference Alignment with Multi-Objective Rewards": {
    "filename": "Arithmetic Control of LLMs for Diverse User Preferences Directional Preference Alignment with Multi-Objective Rewards.pdf",
    "analysis": {
      "benchmarks": [
        "HelpSteer",
        "UltraFeedback",
        "AlpacaEval-2.0"
      ],
      "models": [
        "Directional Preference Alignment (DPA)",
        "Direct Preference Optimization (DPO)",
        "SteerLM",
        "Zephyr-\u03b2",
        "Mistral-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language models in molecular discovery": {
    "filename": "Language models in molecular discovery.pdf",
    "analysis": {
      "benchmarks": [
        "MoleculeNet"
      ],
      "models": [
        "RNN",
        "VAE",
        "MolGPT",
        "Regression Transformer",
        "MolBERT",
        "ChemBERTA",
        "Molformer",
        "MAT",
        "relative-MAT",
        "Molecular Transformer",
        "AiZynthFinder",
        "GFlowNets",
        "MoLeR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms": {
    "filename": "Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms.pdf",
    "analysis": {
      "benchmarks": [
        "Traveling Salesman Problem (TSP)",
        "linear regression problems",
        "IOHexperimenter"
      ],
      "models": [
        "LLM-EA",
        "LMEA",
        "EoH",
        "AutoRNet",
        "ReEvo",
        "LLaMEA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Autonomous Agents Adaptive-planning Reasoning and Acting in Language Models": {
    "filename": "Towards Autonomous Agents Adaptive-planning Reasoning and Acting in Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld"
      ],
      "models": [
        "gemma-2-9b-it",
        "SALA",
        "ReAct",
        "Reflexion",
        "gemma-2-9b",
        "Mistral-7B-v0.3",
        "Mistral-7B-Instruct-v0.3",
        "Llama-2-7b-hf",
        "Phi-3-medium-128k-instruct",
        "deepseek-llm-7b-base",
        "zephyr-7b-alpha"
      ]
    }
  },
  "CoPa General Robotic Manipulation through Spatial Constraints of Parts with Foundation Models": {
    "filename": "CoPa General Robotic Manipulation through Spatial Constraints of Parts with Foundation Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "CoPa",
        "VoxPoser",
        "GraspNet",
        "GPT-4V",
        "Owl-ViT",
        "Segment Anything",
        "VILA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GPT-Driver Learning to Drive with GPT": {
    "filename": "GPT-Driver Learning to Drive with GPT.pdf",
    "analysis": {
      "benchmarks": [
        "nuScenes"
      ],
      "models": [
        "GPT-Driver",
        "ST-P3",
        "VAD",
        "NMP",
        "SA-NMP",
        "FF",
        "EO",
        "UniAD"
      ]
    }
  },
  "Towards Better Few-Shot and Finetuning Performance with Forgetful Causal Language Models": {
    "filename": "Towards Better Few-Shot and Finetuning Performance with Forgetful Causal Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SuperGLUE",
        "LAMBADA",
        "StoryCloze",
        "PIQA",
        "ARC-e",
        "ARC-c",
        "OpenBookQA",
        "Winograd",
        "WinoGrande",
        "Adversarial NLI (ANIL)"
      ],
      "models": [
        "PaLM",
        "FCM",
        "T-FCM",
        "GPT-3",
        "T5-XXL",
        "UL2",
        "ST-MoE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BWArea Model Learning World Model Inverse Dynamics and Policy for Controllable Language Generation": {
    "filename": "BWArea Model Learning World Model Inverse Dynamics and Policy for Controllable Language Generation.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "DROP",
        "BBH",
        "TruthfulQA",
        "TextWorld",
        "BigBench Hard"
      ],
      "models": [
        "BWArea model",
        "Tinyllama",
        "auto-regressive LLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Simple synthetic data reduces sycophancy in large language models": {
    "filename": "Simple synthetic data reduces sycophancy in large language models.pdf",
    "analysis": {
      "benchmarks": [
        "NLP survey questions",
        "philosophy survey questions",
        "political typology quiz questions",
        "simple addition statements"
      ],
      "models": [
        "PaLM-8B",
        "PaLM-62B",
        "cont-PaLM-62B",
        "PaLM-540B",
        "Flan-PaLM-8B",
        "Flan-PaLM-62B",
        "Flan-cont-PaLM-62B",
        "Flan-PaLM-540B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InfiMM-Eval Complex Open-Ended Reasoning Evaluation For Multi-Modal Large Language Models": {
    "filename": "InfiMM-Eval Complex Open-Ended Reasoning Evaluation For Multi-Modal Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "InfiMM-Eval",
        "ARB",
        "ARC",
        "GSM8k",
        "MME",
        "MMBench",
        "SeedBench",
        "MathVista",
        "VCR",
        "Winoground",
        "RAVEN",
        "OK-VQA",
        "TextVQA",
        "FigureQA",
        "ScienceQA",
        "TouchStone",
        "VisIT-Bench",
        "MM-Vet"
      ],
      "models": [
        "Flamingo",
        "Palm-e",
        "RT-2",
        "GPT-4V(ision)",
        "MiniGPT-4",
        "LLaVA",
        "IDEFICS",
        "OpenFlamingo-v2",
        "MiniGPT-v2",
        "Fuyu-8B",
        "BLIP-2",
        "InternLM-XComposer-VL",
        "InstructBLIP",
        "LLaMA-Adapter V2",
        "Otter",
        "mPLUG-Owl2",
        "IDEFICS-9B-instruct",
        "Emu",
        "LLaVA-1.5",
        "CogVLM-Chat",
        "Qwen-VL-Chat",
        "GPT-4V"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on Efficient Inference for Large Language Models": {
    "filename": "A Survey on Efficient Inference for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-1",
        "GPT-2",
        "GPT-3",
        "OPT",
        "LLaMA",
        "LLaMA 2",
        "Baichuan 2",
        "Vicuna",
        "LongChat",
        "BLOOM",
        "FALCON",
        "GLM",
        "Mistral",
        "Switch Transformers",
        "MoEfication",
        "MPOE",
        "Sparse Upcycling",
        "BASE",
        "Expert Choice",
        "SE-MoE",
        "StableMoE",
        "SMoE-Dropout",
        "GLaM",
        "Mixtral 8x7B",
        "MQA",
        "GQA",
        "Linformer",
        "LRT",
        "FLuRKA",
        "Luna",
        "Set Transformer",
        "Linear Transformer",
        "Performers",
        "RFA",
        "PolySketchFormer",
        "SGConv",
        "CKConv",
        "Hyena",
        "RWKV",
        "RetNet",
        "SSM HiPPO",
        "LSSL",
        "S4",
        "DSS",
        "S4D",
        "GSS",
        "H3",
        "Liquid S4",
        "S5",
        "BST",
        "BiGS",
        "Mamba",
        "MambaFormer",
        "Dense-Mamba",
        "BlackMamba",
        "MoE-Mamba"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Transformers Learn to Solve Problems Recursively": {
    "filename": "Can Transformers Learn to Solve Problems Recursively.pdf",
    "analysis": {
      "benchmarks": [
        "binary successor function",
        "tree traversal"
      ],
      "models": [
        "transformer",
        "encoder-decoder transformer",
        "small transformer",
        "proposed transformer model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large language models encode clinical knowledge": {
    "filename": "Large language models encode clinical knowledge.pdf",
    "analysis": {
      "benchmarks": [
        "MultiMedQA",
        "MedQA",
        "MedMCQA",
        "PubMedQA",
        "MMLU clinical topics",
        "LiveQA",
        "MedicationQA",
        "HealthSearchQA"
      ],
      "models": [
        "PaLM",
        "Flan-PaLM",
        "Med-PaLM",
        "DRAGON",
        "PubMedGPT",
        "BioGPT",
        "BioLinkBERT",
        "Galactica",
        "PubMedBERT",
        "GPT-Neo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GeoReasoner Geo-localization with Reasoning in Street Views using a Large Vision-Language Model": {
    "filename": "GeoReasoner Geo-localization with Reasoning in Street Views using a Large Vision-Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "Im2GPS",
        "Im2GPS3k"
      ],
      "models": [
        "GeoReasoner",
        "StreetCLIP",
        "LLaVA",
        "Qwen-VL",
        "GPT-4V",
        "ViT",
        "PlaNet",
        "CPlaNet",
        "ISNs",
        "Translocator",
        "GeoDecoder",
        "GeoCLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Agent-Oriented Planning in Multi-Agent Systems": {
    "filename": "Agent-Oriented Planning in Multi-Agent Systems.pdf",
    "analysis": {
      "benchmarks": [
        "numerical reasoning dataset"
      ],
      "models": [
        "proposed agent-oriented planning framework",
        "GPT-4o",
        "CoT",
        "Zero-Shot CoT",
        "Meta-Agent",
        "Meta-Agent: Traversal",
        "REACT",
        "HUSKY"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Explaining Competitive-Level Programming Solutions using LLMs": {
    "filename": "Explaining Competitive-Level Programming Solutions using LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "CodeContests",
        "Codeforces"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "GPT-turbo-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HandsOnVLM Vision-Language Models for Hand-Object Interaction Prediction": {
    "filename": "HandsOnVLM Vision-Language Models for Hand-Object Interaction Prediction.pdf",
    "analysis": {
      "benchmarks": [
        "Epic-Kitchen-55",
        "Epic-Kitchen-100",
        "H2O",
        "FPHA",
        "Ego4D"
      ],
      "models": [
        "HandsOnVLM",
        "Kalman Filter (KF)",
        "Object-centric Transformer (OCT)",
        "OCT-global",
        "LLaVA-Pixel2Seq",
        "LLaVA-Traj",
        "LumaLabs",
        "Kling 1.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Thought Flow Nets From Single Predictions to Trains of Model Thought": {
    "filename": "Thought Flow Nets From Single Predictions to Trains of Model Thought.pdf",
    "analysis": {
      "benchmarks": [
        "HOTPOT QA"
      ],
      "models": [
        "Thought Flow Nets",
        "Longformer-large",
        "Longformer QA model"
      ]
    }
  },
  "What does it take to catch a Chinchilla Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring": {
    "filename": "What does it take to catch a Chinchilla Verifying Rules on Large-Scale Neural Network Training via Compute Monitoring.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Fact-checking based fake news detection a review": {
    "filename": "Fact-checking based fake news detection a review.pdf",
    "analysis": {
      "benchmarks": [
        "FEVER",
        "HOVER",
        "TabFact",
        "InfoTabs",
        "FEVEROUS",
        "FACTIFY-5WQA",
        "FactKG",
        "PolitiFact",
        "LIAR",
        "Verify",
        "MultiFC",
        "Snopes",
        "RAWFC",
        "LIAR-RAW",
        "X-Fact",
        "MOCHEG",
        "CHEF",
        "MR2",
        "FAVIQ",
        "COVIDLies",
        "COVID-Fact",
        "Check-COVID",
        "NewsCLIPings"
      ],
      "models": [
        "DistilBERT",
        "DeClarE",
        "GRU with attention module",
        "MAC",
        "Graph Neural Networks",
        "CoFED",
        "Claim-Dissector",
        "ProgramFC",
        "ProToCo",
        "DCUF",
        "UNIFEE",
        "CCN",
        "T5",
        "GPT",
        "Pref-FEND"
      ]
    }
  },
  "Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification": {
    "filename": "Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification.pdf",
    "analysis": {
      "benchmarks": [
        "Health Advice",
        "Causal Relation"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "BioBERT",
        "bag-of-words (BoW) with logistic regression",
        "GPT-J",
        "GPT-JT",
        "Galactica"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VisionGPT Vision-Language Understanding Agent Using Generalized Multimodal Framework": {
    "filename": "VisionGPT Vision-Language Understanding Agent Using Generalized Multimodal Framework.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "VisionGPT",
        "YOLO",
        "SAM",
        "Llama 2",
        "DINO",
        "Detectron2",
        "DALL-E",
        "CLIP",
        "Stable Diffusion"
      ]
    }
  },
  "Using LLMs in Software Requirements Specifications An Empirical Evaluation": {
    "filename": "Using LLMs in Software Requirements Specifications An Empirical Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "university club management system"
      ],
      "models": [
        "GPT-4",
        "CodeLlama",
        "CodeLlama-34b",
        "CodeLlama-13b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy": {
    "filename": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "Adversarial GPT-4",
        "Generation GPT-4"
      ]
    }
  },
  "Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors": {
    "filename": "Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors.pdf",
    "analysis": {
      "benchmarks": [
        "GameBugDescriptions"
      ],
      "models": [
        "OPT-66B",
        "OPT-175B",
        "text-ada-001",
        "text-babbage-001",
        "text-curie-001",
        "text-davinci-002"
      ]
    }
  },
  "Large Knowledge Model Perspectives and Challenges": {
    "filename": "Large Knowledge Model Perspectives and Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "Tree-RAG",
        "KG-FiD",
        "DeepKE-LLM",
        "InstructProtein"
      ],
      "models": [
        "ChatGPT",
        "K-BERT",
        "CoLAKE",
        "ERNIE",
        "KnowBERT",
        "KG-BART",
        "KT-NET",
        "BERT-MK",
        "KEPLER",
        "WKLM",
        "JAKET",
        "KGTransformer",
        "KnowPAT",
        "RetroPrompt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Orchestrating Bimanual Robots": {
    "filename": "Large Language Models for Orchestrating Bimanual Robots.pdf",
    "analysis": {
      "benchmarks": [
        "ServeWater",
        "ServeFruit"
      ],
      "models": [
        "LABOR agent",
        "Baseline agent",
        "vanilla LLM Agent"
      ]
    }
  },
  "OpenMathInstruct-1 A 18 Million Math Instruction Tuning Dataset": {
    "filename": "OpenMathInstruct-1 A 18 Million Math Instruction Tuning Dataset.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "GSM-Hard",
        "SVAMP",
        "TabMWP",
        "ASDiv",
        "MAWPS"
      ],
      "models": [
        "OpenMath-CodeLlama-70B",
        "Mixtral",
        "GPT-4",
        "Mistral-7B",
        "Llama 2",
        "CodeLlama",
        "WizardMath",
        "MetaMath",
        "MAmmoTH",
        "ToRA",
        "OpenMath-Mistral-7B",
        "OpenMath-Llama2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RestGPT Connecting Large Language Models with Real-World RESTful APIs": {
    "filename": "RestGPT Connecting Large Language Models with Real-World RESTful APIs.pdf",
    "analysis": {
      "benchmarks": [
        "RestBench"
      ],
      "models": [
        "RestGPT",
        "ReAct",
        "Toolformer",
        "Visual ChatGPT",
        "ViperGPT",
        "HuggingGPT",
        "API-Bank",
        "Chameleon",
        "Gorilla",
        "GPT4Tools"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving Math Problem Solving in Large Language Models Through Categorization and Strategy Tailoring": {
    "filename": "Improving Math Problem Solving in Large Language Models Through Categorization and Strategy Tailoring.pdf",
    "analysis": {
      "benchmarks": [
        "International Mathematics Olympiad (IMO)",
        "AIME",
        "MATH dataset",
        "AMC 12"
      ],
      "models": [
        "AlphaGeometry",
        "AlphaProof",
        "Deepseek-Math",
        "ChatGPT's GPT-4o",
        "Chain of Thought (CT)",
        "Program of Thought (PT)"
      ]
    }
  },
  "Locking Down the Finetuned LLMs Safety": {
    "filename": "Locking Down the Finetuned LLMs Safety.pdf",
    "analysis": {
      "benchmarks": [
        "HEx-PHI",
        "AdvBench"
      ],
      "models": [
        "SafetyLock",
        "Llama-3-8B Instruct",
        "Llama-3-70B Instruct",
        "Mistral-Large-2 123B",
        "Alpaca-Llama-3-Instruct",
        "GPT-3.5 Turbo",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Making the Most of ChatGPT for Machine Translation": {
    "filename": "Towards Making the Most of ChatGPT for Machine Translation.pdf",
    "analysis": {
      "benchmarks": [
        "Flores-200",
        "WMT19 News",
        "WMT19 Bio",
        "WMT22 E-Commerce"
      ],
      "models": [
        "ChatGPT",
        "Google Translator",
        "ChatGPT + TSP",
        "ChatGPT + DSP",
        "ChatGPT + F-DSP",
        "ChatGPT with zero-shot CoT",
        "ChatGPT with 1-shot CoT"
      ]
    }
  },
  "Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving": {
    "filename": "Hybrid Reasoning Based on Large Language Models for Autonomous Car Driving.pdf",
    "analysis": {
      "benchmarks": [
        "CARLA"
      ],
      "models": [
        "YOLOv8",
        "GPT-4",
        "Large Language Models (LLMs)"
      ]
    }
  },
  "Large Language Models are Fixated by Red Herrings Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset": {
    "filename": "Large Language Models are Fixated by Red Herrings Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset.pdf",
    "analysis": {
      "benchmarks": [
        "Only Connect Wall (OCW) dataset",
        "OCW-Randomized",
        "OCW-WordNet"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5-turbo",
        "E5 BASE",
        "E5 LARGE",
        "all-mpnet BASE",
        "RoBERTa LARGE",
        "BERT BASE",
        "BERT LARGE",
        "DistilBERT BASE",
        "ELMo LARGE",
        "FastText (Crawl)",
        "FastText (News)",
        "GloVe"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Zero-shot Temporal Relation Extraction with ChatGPT": {
    "filename": "Zero-shot Temporal Relation Extraction with ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "TB-Dense",
        "MATRES",
        "TDDMan"
      ],
      "models": [
        "ChatGPT",
        "CAEVO",
        "SP+ILP",
        "Bi-LSTM",
        "Joint",
        "Deep",
        "UCGraph",
        "TIMERS",
        "SCS-EERE",
        "FaithTRE",
        "RSGT",
        "DTRE",
        "MulCo"
      ]
    }
  },
  "Hippocrates An Open-Source Framework for Advancing Large Language Models in Healthcare": {
    "filename": "Hippocrates An Open-Source Framework for Advancing Large Language Models in Healthcare.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "MedMCQA",
        "PubMedQA",
        "USMLE-step1",
        "USMLE-step2",
        "USMLE-step3"
      ],
      "models": [
        "Hippo-",
        "Hippo-",
        "BioGPT 1.5B",
        "MedAlpaca 7B",
        "LLaMA-2 7B",
        "PMC-LLaMA 13B",
        "Mistral 7B",
        "Qwen 72B",
        "Meditron 70B",
        "Gemma 2b",
        "Falcon 7b",
        "Vicuna 7b",
        "BioMedLM",
        "BioGPT-Large",
        "MedAlpaca 13b",
        "PMC-LLaMA 7b",
        "Meditron 7b",
        "Bio-Mistral 7b",
        "LLaMA-2 13b",
        "Vicuna 13b",
        "LLaMA-2 70b",
        "ClinicalCamel 70b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on the Honesty of Large Language Models": {
    "filename": "A Survey on the Honesty of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD",
        "HotpotQA",
        "TriviaQA",
        "FalseQA",
        "NaturalQuestion",
        "SelfAware",
        "KUQ",
        "UnknownBench",
        "HoneSet",
        "BeHonest",
        "Idk"
      ],
      "models": [
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "RLHF models",
        "DPO",
        "PPO",
        "LoRA",
        "ProbingNet"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MultiTalk Introspective and Extrospective Dialogue for Human-Environment-LLM Alignment": {
    "filename": "MultiTalk Introspective and Extrospective Dialogue for Human-Environment-LLM Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "YCB dataset"
      ],
      "models": [
        "MultiTalk",
        "ProgPrompt",
        "Code-As-Policies",
        "Inner Monologue",
        "SayCan",
        "Reflexion",
        "ISR-LLM"
      ]
    }
  },
  "Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training": {
    "filename": "Boosting the Power of Small Multimodal Reasoning Models to Match Larger Models with Self-Consistency Training.pdf",
    "analysis": {
      "benchmarks": [
        "ScienceQA",
        "A-OKVQA"
      ],
      "models": [
        "MC-CoT",
        "Multimodal-CoT",
        "UnifiedQA Base",
        "UnifiedQA Base w/ CoT",
        "GPT-3.5",
        "GPT-3.5 w/ CoT",
        "ChatGPT w/ CoT",
        "GPT-4 w/ CoT",
        "Chameleon + ChatGPT",
        "Chameleon + GPT-4",
        "LLaMA-Adapter (T)",
        "LLaMA-Adapter",
        "LaVIN-7B",
        "LLaMA-SciTune Base",
        "LaVIN-13B",
        "LLaVa",
        "LLaVa + GPT-4",
        "LLaMA-SciTune Large",
        "MCAN",
        "Top-Down",
        "BAN",
        "DFAF",
        "ViLT",
        "Patch-TRM",
        "VisualBERT",
        "Pythia",
        "ViLBERT",
        "LXMERT",
        "KRISP",
        "GPV-2",
        "BLIP-2",
        "PaLM-CoT",
        "PICa",
        "IPVR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RoT Enhancing Large Language Models with Reflection on Search Trees": {
    "filename": "RoT Enhancing Large Language Models with Reflection on Search Trees.pdf",
    "analysis": {
      "benchmarks": [
        "Blocksworld",
        "GSM8k",
        "CraigslistBargain"
      ],
      "models": [
        "RoT",
        "LEAP",
        "BFS",
        "MCTS",
        "Chain-of-Thought (CoT)",
        "CoT with self-consistency (CoT-SC)",
        "phi-2",
        "mistral-7b",
        "mixtral-8x7b",
        "chatgpt",
        "gpt-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Regulatable AI Systems Technical Gaps and Policy Opportunities": {
    "filename": "Towards Regulatable AI Systems Technical Gaps and Policy Opportunities.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Holistic Evaluation of Language Models (HELM)",
        "Elo ratings",
        "large language models",
        "autonomous vehicle vision system",
        "traffic image classifier",
        "generalized additive models",
        "decision trees",
        "rule-based models",
        "neural networks",
        "large models",
        "large language models (LLMs)",
        "diffusion-based image generation models",
        "reinforcement learning",
        "imitation learning",
        "reinforcement learning from human feedback"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Rethinking ChatGPTs Success Usability and Cognitive Behaviors Enabled by Auto-regressive LLMs Prompting": {
    "filename": "Rethinking ChatGPTs Success Usability and Cognitive Behaviors Enabled by Auto-regressive LLMs Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE"
      ],
      "models": [
        "ChatGPT",
        "GPT series",
        "BERT",
        "Auto-regressive LLMs (AR-LLMs)",
        "Auto-Encoding LMs (AE-LMs)",
        "Pattern Exploitation Training (PET)",
        "Auto-prompt",
        "ReAct framework",
        "RAP framework",
        "Re\ufb02exion",
        "Self-re\ufb01ne"
      ]
    }
  },
  "Exploring and Benchmarking the Planning Capabilities of Large Language Models": {
    "filename": "Exploring and Benchmarking the Planning Capabilities of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BlocksWorld",
        "Logistics",
        "Mini-Grid",
        "Trip Planning",
        "Calendar Scheduling",
        "Val-BW"
      ],
      "models": [
        "Gemini 1.5 Pro",
        "Gemini 1.5 Flash",
        "Gemma 2 27b",
        "GPT-4 Turbo",
        "Gemini 1.0 S"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Using Large Language Models for Student-Code Guided Test Case Generation in Computer Science Education": {
    "filename": "Using Large Language Models for Student-Code Guided Test Case Generation in Computer Science Education.pdf",
    "analysis": {
      "benchmarks": [
        "CSEDM Challenge dataset"
      ],
      "models": [
        "OpenAI Codex",
        "GPT-4",
        "GPT-3.5-turbo",
        "LEGenT",
        "CodeHelp"
      ]
    }
  },
  "Transcrib3D 3D Referring Expression Resolution through Large Language Models": {
    "filename": "Transcrib3D 3D Referring Expression Resolution through Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ReferIt3D",
        "ScanRefer"
      ],
      "models": [
        "Transcrib3D",
        "CLIP",
        "MVT",
        "BUTD-DETR",
        "SAT",
        "HAM",
        "NS3D",
        "D3Net",
        "3DJCG",
        "ViL3DRel",
        "3D-VisTA",
        "GPT-3.5-NP",
        "GPT-3.5-P",
        "GPT-4-NP",
        "GPT-4-P",
        "Mask3D",
        "PointNet++",
        "MDETR",
        "Code-as-Policies"
      ]
    }
  },
  "Speech Translation with Large Language Models An Industrial Practice": {
    "filename": "Speech Translation with Large Language Models An Industrial Practice.pdf",
    "analysis": {
      "benchmarks": [
        "GigaST",
        "MuST-C v2",
        "CoVoST2",
        "LibriSpeech",
        "CommonVoice"
      ],
      "models": [
        "LLM-ST",
        "SeamlessM4T",
        "XSTNet",
        "Whisper",
        "Whisper + Google Trans",
        "Whisper + GPT3.5",
        "ST product",
        "AudioPaLM",
        "SpeechLLaMA",
        "mSLAM-CTC",
        "ASR Product"
      ]
    }
  },
  "TorchOpera A Compound AI System for LLM Safety": {
    "filename": "TorchOpera A Compound AI System for LLM Safety.pdf",
    "analysis": {
      "benchmarks": [
        "HEx-PHI",
        "OpenAI",
        "Hotpot QA",
        "Truthful QA",
        "Awesome ChatGPT Prompts",
        "Jigsaw Unintended-Bias Data",
        "GPT-Jailbreak",
        "Jailbreak",
        "Personalization Prompt",
        "QA Chat Prompts",
        "ChatGPT Prompts",
        "10k Prompts Ranked",
        "Iterative Prompt",
        "Instruction Following"
      ],
      "models": [
        "TorchOpera",
        "Safety Detector",
        "Grounding",
        "Repairer",
        "LlamaGuard",
        "Detoxify",
        "Guardrails",
        "Nvidia NeMo Guardrails",
        "LLaMA",
        "ChatGPT API",
        "Llama-3-8B-instruct"
      ]
    }
  },
  "Can LLMs Solve longer Math Word Problems Better": {
    "filename": "Can LLMs Solve longer Math Word Problems Better.pdf",
    "analysis": {
      "benchmarks": [
        "Extended Grade-School Math (E-GSM)",
        "GSM8K",
        "MAWPS",
        "SVAMP",
        "GSM-IC"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-3.5-instruct",
        "GPT-4",
        "GLM-3",
        "Gemini-pro",
        "Claude-3",
        "LLaMA-2",
        "LLaMA-3",
        "Mistral-7B",
        "WizardMath",
        "MAmmoTH",
        "MetaMath",
        "Llemma",
        "deepseek-math-7b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Cannot Explain Themselves": {
    "filename": "Large Language Models Cannot Explain Themselves.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "ChatGPT",
        "Microsoft Copilot",
        "Bing Chat"
      ]
    }
  },
  "Frontier AI Regulation Managing Emerging Risks to Public Safety": {
    "filename": "Frontier AI Regulation Managing Emerging Risks to Public Safety.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Repairing the Cracked Foundation A Survey of Obstacles in Evaluation Practices for Generated Text": {
    "filename": "Repairing the Cracked Foundation A Survey of Obstacles in Evaluation Practices for Generated Text.pdf",
    "analysis": {
      "benchmarks": [
        "CNN-Dailymail",
        "XSum",
        "DUC 2004",
        "WMT 2014",
        "TAC",
        "ToTTo"
      ],
      "models": [
        "BLEU",
        "ROUGE",
        "BERT-SCORE",
        "BLEURT",
        "CLASSY",
        "PARENT",
        "BERT-based metrics",
        "word mover distance",
        "learned metrics",
        "faithfulness classifiers",
        "question-answering metrics",
        "statistical approaches",
        "distributional similarity metrics"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Collecting Qualitative Data at Scale with Large Language Models A Case Study": {
    "filename": "Collecting Qualitative Data at Scale with Large Language Models A Case Study.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLM-based chatbot",
        "baseline chatbot",
        "Dynamic Prober",
        "Member Checker"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Psychometric Alignment Capturing Human Knowledge Distributions via Language Models": {
    "filename": "Psychometric Alignment Capturing Human Knowledge Distributions via Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "WORDBANK",
        "DUOLINGO",
        "EEDI"
      ],
      "models": [
        "Mistral-7b",
        "Llama-8b",
        "Llama-70b",
        "GPT-3.5",
        "GPT-4",
        "Deepseek-7b",
        "Meta-Llama-3-8B",
        "Meta-Llama-3-70B",
        "deepseek-math-7b-base",
        "deepseek-math-7b-instruct",
        "deepseek-math-7b-rl",
        "Meta-Llama-3-8B-Instruct",
        "Meta-Llama-3-70B-Instruct"
      ]
    }
  },
  "MemeCap A Dataset for Captioning and Interpreting Memes": {
    "filename": "MemeCap A Dataset for Captioning and Interpreting Memes.pdf",
    "analysis": {
      "benchmarks": [
        "MEMECAP",
        "MultiMET",
        "Met-Meme",
        "WHOOPS",
        "ImgFlip575K"
      ],
      "models": [
        "Flamingo",
        "OpenFlamingo-9B",
        "MiniGPT4",
        "LLaMA",
        "LLaMA-7B",
        "LLaMA-13B",
        "Vicuna",
        "BLIP-2",
        "CLIP ViT/L-14",
        "CLIP ViT-G/14",
        "Q-Former"
      ]
    }
  },
  "A Stitch in Time Saves Nine Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation": {
    "filename": "A Stitch in Time Saves Nine Detecting and Mitigating Hallucinations of LLMs by Validating Low-Confidence Generation.pdf",
    "analysis": {
      "benchmarks": [
        "article generation task",
        "multi-hop questions",
        "false premise questions"
      ],
      "models": [
        "GPT-3.5 (text-davinci-003)",
        "Vicuna-13B",
        "proposed active detection and mitigation approach"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LANCAR Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments": {
    "filename": "LANCAR Leveraging Language for Context-Aware Robot Locomotion in Unstructured Environments.pdf",
    "analysis": {
      "benchmarks": [
        "spot-mini-mini robot simulator v.2.1.0",
        "Moist Grassland",
        "Snowy Mountain Road",
        "Sunny Beach",
        "Rainy Concrete Road",
        "Sunny Running Tracks"
      ],
      "models": [
        "LANCAR",
        "NAUTS",
        "VINet",
        "Ada-Nav",
        "ViTAL",
        "CMS",
        "RMA",
        "SayTap",
        "RE-Move",
        "LM-Nav",
        "ARS",
        "SAC",
        "PPO",
        "TD3"
      ]
    }
  },
  "ViEva LLM A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations": {
    "filename": "ViEva LLM A Conceptual Stack for Evaluating and Interpreting Generative AI-based Visualizations.pdf",
    "analysis": {
      "benchmarks": [
        "NvBench",
        "NLVCorpus",
        "Quda"
      ],
      "models": [
        "GPT-3.5-turbo",
        "Llama2-70-b",
        "ncNet",
        "RGVisNet",
        "AI Thread",
        "Codex",
        "ChartGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatMOF An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks": {
    "filename": "ChatMOF An Autonomous AI System for Predicting and Generating Metal-Organic Frameworks.pdf",
    "analysis": {
      "benchmarks": [
        "CoREMOF",
        "QMOF",
        "MOF key",
        "DigiMOF"
      ],
      "models": [
        "ChatMOF",
        "GPT-4",
        "GPT-3.5-turbo",
        "MOFTransformer",
        "Generative Adversarial Networks (GAN)",
        "Diffusion models",
        "Variational Autoencoders (VAE)",
        "Reinforcement learning"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ReConcile Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs": {
    "filename": "ReConcile Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA",
        "CommonsenseQA",
        "GSM8K",
        "AQuA",
        "MATH",
        "Date Understanding",
        "ANLI"
      ],
      "models": [
        "RECONCILE",
        "ChatGPT",
        "Bard",
        "Claude2",
        "GPT-4",
        "LLaMA-2-70B",
        "DeepSeekMath",
        "Self-Refine",
        "Self-Consistency",
        "Debate",
        "Judge"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ProcBench Benchmark for Multi-Step Reasoning and Following Procedure": {
    "filename": "ProcBench Benchmark for Multi-Step Reasoning and Following Procedure.pdf",
    "analysis": {
      "benchmarks": [
        "ProcBench"
      ],
      "models": [
        "o1-preview",
        "o1-mini",
        "GPT-4o",
        "GPT-4o-mini",
        "Claude-3.5-sonnet",
        "Mistral-large",
        "Gemini-1.5-Pro"
      ]
    }
  },
  "Captioning Visualizations with Large Language Models CVLLM A Tutorial": {
    "filename": "Captioning Visualizations with Large Language Models CVLLM A Tutorial.pdf",
    "analysis": {
      "benchmarks": [
        "Chart-to-text",
        "VisText"
      ],
      "models": [
        "LSTM encoder-decoder models",
        "transformers",
        "Chain-of-Thought (CoT)",
        "Retrieval-Augmented Generation (RAG)",
        "Reinforcement Learning from Human Feedback (RLHF)",
        "GPT-4V",
        "scene-graph model",
        "Chartthinker",
        "Figcaps-hf"
      ]
    }
  },
  "AutoBreach Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization": {
    "filename": "AutoBreach Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "AdvBench"
      ],
      "models": [
        "AutoBreach",
        "Claude-3",
        "GPT-3.5",
        "GPT-4 Turbo",
        "Bingchat",
        "GPT-4 Web",
        "Vicuna",
        "Llama-2",
        "GCG",
        "TAP",
        "PAIR",
        "GPTfuzzer",
        "DeepInception",
        "CIPHER"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InterAct Exploring the Potentials of ChatGPT as a Cooperative Agent": {
    "filename": "InterAct Exploring the Potentials of ChatGPT as a Cooperative Agent.pdf",
    "analysis": {
      "benchmarks": [
        "AlfWorld",
        "ALFRED"
      ],
      "models": [
        "ChatGPT",
        "InterAct",
        "ReAct",
        "InstructGPT",
        "BUTLER",
        "ReAct+checker",
        "ReAct+sorter"
      ]
    }
  },
  "Unified View of Grokking Double Descent and Emergent Abilities A Perspective from Circuits Competition": {
    "filename": "Unified View of Grokking Double Descent and Emergent Abilities A Perspective from Circuits Competition.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "1-layer simplified decoder-only transformer",
        "transformer with 4 attention heads",
        "model with hidden size of 8",
        "model with hidden size of 32",
        "model with hidden size of 36",
        "model with hidden size of 40",
        "model with hidden size of 44",
        "model with hidden size of 48",
        "model with hidden size of 56",
        "model with hidden size of 64",
        "model with hidden size of 4",
        "model with hidden size of 8",
        "model with hidden size of 12",
        "model with hidden size of 16",
        "model with hidden size of 20",
        "model with hidden size of 24",
        "model with hidden size of 28",
        "model with hidden size of 32",
        "model with hidden size of 36",
        "model with hidden size of 40",
        "model with hidden size of 44",
        "model with hidden size of 48",
        "model with hidden size of 56",
        "model with hidden size of 64",
        "model with hidden size of 100",
        "1-layer transformer with hidden size of 64",
        "8-layer transformer with hidden size of 1024"
      ]
    }
  },
  "AutoRNet Automatically Optimizing Heuristics for Robust Network Design via Large Language Models": {
    "filename": "AutoRNet Automatically Optimizing Heuristics for Robust Network Design via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "scale-free networks",
        "EU power grid network"
      ],
      "models": [
        "AutoRNet",
        "Hill Climbing Algorithm (HC)",
        "Simulated Annealing Algorithm (SA)",
        "Smart Rewiring Algorithm (SR)",
        "Heuristic-v1",
        "Heuristic-v2",
        "Heuristic-v3"
      ]
    }
  },
  "BatchPrompt Accomplish more with less": {
    "filename": "BatchPrompt Accomplish more with less.pdf",
    "analysis": {
      "benchmarks": [
        "Boolq",
        "QQP",
        "RTE",
        "GSM8K",
        "COPA",
        "MNLI"
      ],
      "models": [
        "SinglePrompt",
        "BatchPrompt",
        "BatchPrompt + BPE",
        "BatchPrompt + BPE + SEAS",
        "gpt-3.5-turbo",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Critique-out-Loud Reward Models": {
    "filename": "Critique-out-Loud Reward Models.pdf",
    "analysis": {
      "benchmarks": [
        "RewardBench",
        "ArenaHard"
      ],
      "models": [
        "CLoud reward model",
        "classic reward model",
        "Llama-3-8B",
        "Llama-3-70B",
        "Llama-3.1-405B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning": {
    "filename": "Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning.pdf",
    "analysis": {
      "benchmarks": [
        "BoolQ",
        "ANLI",
        "WinoGrande",
        "ReCoRD",
        "HellaSwag",
        "MMLU",
        "ARC",
        "WiC",
        "OpenBookQA",
        "MultiRC",
        "CommonSenseQA",
        "RTE",
        "COPA",
        "PIQA",
        "SIQA",
        "WSC",
        "Alpaca"
      ],
      "models": [
        "Intuition-MoR1E",
        "LoRA",
        "MoLoRA",
        "SiRA",
        "Llama 2 13B",
        "Llama 2 7B",
        "Mistral 7B",
        "Yi 6B",
        "Bloom 3B",
        "Phi-2 2B",
        "Gemma 2B",
        "TinyLlama 1B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Game-theoretic LLM Agent Workflow for Negotiation Games": {
    "filename": "Game-theoretic LLM Agent Workflow for Negotiation Games.pdf",
    "analysis": {
      "benchmarks": [
        "Prisoner's Dilemma",
        "Stag Hunt",
        "Battle of the Sexes",
        "Wait-Go Game",
        "Duopolistic Competition",
        "Escalation Game",
        "Monopoly Game",
        "Hot-cold Game",
        "Draco Game",
        "TriGame"
      ],
      "models": [
        "Claude-3.5 Sonnet",
        "Claude-3 Opus",
        "GPT-4o",
        "o1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond Imitation Learning Key Reasoning Steps from Dual Chain-of-Thoughts in Reasoning Distillation": {
    "filename": "Beyond Imitation Learning Key Reasoning Steps from Dual Chain-of-Thoughts in Reasoning Distillation.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-Bench Hard (BBH)",
        "BIG-Bench Sub (BB-sub)",
        "AGIEval",
        "AI2 Reasoning Challenge (ARC)"
      ],
      "models": [
        "EDIT",
        "LLaMA2-7B",
        "ChatGPT (gpt-3.5-turbo-0613)",
        "TinyLLaMA-1.1B",
        "LLaMA2-13B",
        "CodeLLaMA-7B",
        "LLaMA3-8B",
        "Mistral-7B-v0.2",
        "MT-CoT",
        "SCOTT",
        "Std-CoT",
        "Std-CoT w/ Repeat Sampling",
        "Std-CoT w/ Dual CoTs"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MASSW A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows": {
    "filename": "MASSW A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows.pdf",
    "analysis": {
      "benchmarks": [
        "MASSW"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Mixtral 8x7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CogniDual Framework Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks": {
    "filename": "CogniDual Framework Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "ReClor",
        "LogiQA 2.0"
      ],
      "models": [
        "CogniDual Framework",
        "Vicuna",
        "Llama2",
        "GPT-4",
        "GPT-3.5"
      ]
    }
  },
  "Rational Metareasoning for Large Language Models": {
    "filename": "Rational Metareasoning for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ARC",
        "CommonsenseQA",
        "GSM8K",
        "ProofWriter",
        "MMLU"
      ],
      "models": [
        "few-shot chain-of-thought prompting",
        "STaR",
        "Metareasoning",
        "Direct Few-Shot",
        "Meta-Llama-3-8B",
        "Mistral-7B-v0.3",
        "Microsoft Phi-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MoS Unleashing Parameter Efficiency of Low-Rank Adaptation with Mixture of Shards": {
    "filename": "MoS Unleashing Parameter Efficiency of Low-Rank Adaptation with Mixture of Shards.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "BBH",
        "GSM8K",
        "TyDi QA",
        "HumanEval"
      ],
      "models": [
        "LoRA",
        "VeRA",
        "Tied LoRA",
        "PRoLoRA",
        "Mixture of Shards (MOS)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities": {
    "filename": "Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities.pdf",
    "analysis": {
      "benchmarks": [
        "OWASP",
        "Juliet (C/C++)",
        "Juliet (Java)",
        "CVEFixes (C/C++)",
        "CVEFixes (Java)"
      ],
      "models": [
        "GPT-4",
        "CodeLlama",
        "Qwen-2.5-14B",
        "Qwen-2.5-32B",
        "Llama-3.1-70B",
        "DeepSeekCoder-7B",
        "Gemini-1.5-Flash",
        "GPT-3.5",
        "CodeLlama-7B",
        "CodeLlama-13B",
        "CodeLlama-34B",
        "Llama-3.1-8B",
        "DSCoder-15B",
        "DSCoder-33B",
        "Codestral-22B",
        "Mistral-Codestral-22B",
        "DeepDFA",
        "LineVul"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Effective Distillation of Table-based Reasoning Ability from LLMs": {
    "filename": "Effective Distillation of Table-based Reasoning Ability from LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "SciGen",
        "LogicNLG",
        "TabFact"
      ],
      "models": [
        "Flan-T5-base",
        "T5-base",
        "T5-large",
        "Flan-T5-large",
        "BART-large",
        "text-davinci-002",
        "gpt-3.5-turbo",
        "T5-base-CoT",
        "T5-large-CoT",
        "Flan-T5-base-CoT",
        "Flan-T5-large-CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Versatile Graph Learning Approach from the Perspective of Large Language Models": {
    "filename": "Towards Versatile Graph Learning Approach from the Perspective of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GraphText",
        "NLGraph",
        "GPT4Graph",
        "TLG",
        "LLM4Mol",
        "OFA",
        "Chen et al. 2023",
        "GRAD",
        "GraphGPT",
        "GraphPrompt",
        "All in One",
        "Instruction2GL",
        "GPT4GNAS"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "GPT-3.5",
        "InstructGPT-3",
        "PaLM 62B",
        "RoBERTa",
        "Sentence-BERT",
        "Deberta",
        "LLaMA",
        "R-GCN",
        "RevGAT",
        "GCN",
        "GAT",
        "Graph Transformer",
        "BERT",
        "AutoML",
        "Graph Foundation Models (GFMs)"
      ]
    }
  },
  "Large Language Models Can Self-Improve": {
    "filename": "Large Language Models Can Self-Improve.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "DROP",
        "OpenBookQA",
        "ANLI-A3",
        "ARC-c",
        "ANLI-A2",
        "AQUA",
        "StrategyQA",
        "MNLI",
        "SVAMP",
        "RTE",
        "ANLI-A1"
      ],
      "models": [
        "PaLM-540B",
        "LMSI",
        "DiVeRSe",
        "OPERA",
        "UL2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Expert-Level Medical Question Answering with Large Language Models": {
    "filename": "Towards Expert-Level Medical Question Answering with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "MedMCQA",
        "PubMedQA",
        "MMLU clinical topics",
        "MultiMedQA",
        "HealthSearchQA",
        "LiveQA",
        "MedicationQA",
        "Adversarial (General)",
        "Adversarial (Health equity)"
      ],
      "models": [
        "Med-PaLM",
        "Med-PaLM 2",
        "Flan-PaLM",
        "GPT-Neo",
        "PubMedBERT",
        "BioLinkBERT",
        "DRAGON",
        "BioMedLM",
        "GPT 3.5",
        "GPT-4-base",
        "BioGPT-Large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FreshLLMs Refreshing Large Language Models with Search Engine Augmentation": {
    "filename": "FreshLLMs Refreshing Large Language Models with Search Engine Augmentation.pdf",
    "analysis": {
      "benchmarks": [
        "FRESH QA"
      ],
      "models": [
        "FRESH PROMPT",
        "SELF-ASK",
        "PERPLEXITY.AI",
        "GPT-4",
        "GPT-3.5",
        "CHATGPT",
        "CODEX",
        "FLAN-PALM",
        "PALM",
        "T5",
        "FLAN-T5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning to Compress Prompts with Gist Tokens": {
    "filename": "Learning to Compress Prompts with Gist Tokens.pdf",
    "analysis": {
      "benchmarks": [
        "Alpaca+",
        "Self-Instruct",
        "Stanford Alpaca",
        "Human validation split"
      ],
      "models": [
        "Gist",
        "LLaMA-7B",
        "FLAN-T5-XXL",
        "Positive Control",
        "Negative Control",
        "TF-IDF"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models on Graphs A Comprehensive Survey": {
    "filename": "Large Language Models on Graphs A Comprehensive Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT4",
        "LLaMA",
        "BERT",
        "T5",
        "RoBERTa",
        "GraphLLM",
        "StructGPT",
        "Graph-ToolFormer",
        "InstructGLM",
        "GraphText",
        "GNP",
        "GraphGPT",
        "DGTL",
        "METERN",
        "GreaseLM",
        "DRAGON",
        "GraphFormers",
        "Patton",
        "Heterformer",
        "Edgeformers",
        "SPECTER",
        "SciNCL",
        "Touchup-G",
        "TwHIN-BERT",
        "MICoL",
        "E2EG",
        "TextGNN",
        "AdsGNN",
        "GNN-LM",
        "GIANT",
        "LM-GNN",
        "SimTeG",
        "GaLM",
        "LLM-GNN",
        "TAPE",
        "ENG",
        "GraD",
        "LTRN",
        "GLEM",
        "ConGrat",
        "GRENADE",
        "G2P2",
        "THLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HiGPT Heterogeneous Graph Language Model": {
    "filename": "HiGPT Heterogeneous Graph Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "IMDB",
        "DBLP",
        "ACM"
      ],
      "models": [
        "HiGPT",
        "HAN",
        "HGT",
        "HetGNN",
        "DMGI",
        "HeCo",
        "HGMAE",
        "SAGE",
        "GAT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Think-on-Graph Deep and Responsible Reasoning of Large Language Model on Knowledge Graph": {
    "filename": "Think-on-Graph Deep and Responsible Reasoning of Large Language Model on Knowledge Graph.pdf",
    "analysis": {
      "benchmarks": [
        "CWQ",
        "WebQSP",
        "GrailQA",
        "QALD10-en",
        "Simple Questions",
        "WebQuestions",
        "T-REx",
        "Zero-Shot RE",
        "Creak"
      ],
      "models": [
        "Think-on-Graph (ToG)",
        "ToG-R",
        "ChatGPT",
        "GPT-4",
        "Llama-2",
        "NSM",
        "CBR-KBQA",
        "TIARA",
        "DeCAF",
        "KD-CoT",
        "StructGPT",
        "KB-BINDER",
        "IO prompt",
        "CoT prompt",
        "Self-Consistency"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InferFix End-to-End Program Repair with LLMs": {
    "filename": "InferFix End-to-End Program Repair with LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "InferredBugs",
        "Defects4j",
        "QuixBugs",
        "ManySStuBs4J",
        "UnifiedBugDataset"
      ],
      "models": [
        "InferFix",
        "Codex Cushman",
        "code-cushman-001",
        "text-davinci-003",
        "Demonstration Prompting",
        "Conditional Language Modeling",
        "Instruction Prompting",
        "Finetuned Codex",
        "ReACC",
        "Dense Passage Retriever (DPR)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large language models surpass human experts in predicting neuroscience results": {
    "filename": "Large language models surpass human experts in predicting neuroscience results.pdf",
    "analysis": {
      "benchmarks": [
        "BrainBench",
        "MMLU",
        "PubMedQA",
        "MedMCQA"
      ],
      "models": [
        "BrainGPT",
        "Llama2-7B",
        "Mistral-7B",
        "ChatGPT",
        "Galactica-6.7B",
        "Galactica-30B",
        "Galactica-120B",
        "Falcon-40B",
        "Falcon-40B (instruct)",
        "Falcon-180B (chat)",
        "Llama-2-7B (chat)",
        "Llama-2-13B",
        "Llama-2-13B (chat)",
        "Llama-2-70B",
        "Llama-2-70B (chat)",
        "Mistral-7B (instruct)",
        "GPT-4",
        "GPT-2",
        "GPT-2 medium",
        "GPT-2 large",
        "TinyLLama",
        "Phi-3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Personalized Visual Instruction Tuning": {
    "filename": "Personalized Visual Instruction Tuning.pdf",
    "analysis": {
      "benchmarks": [
        "P-Bench"
      ],
      "models": [
        "Personalized Visual Instruction Tuning (PVIT)",
        "P-LLaVA",
        "Qwen-VL-7B",
        "VILA1.5-7B",
        "LLaVA-OneVision-7B",
        "InternVL-Chat-V1.5-26B",
        "Deepseek-VL-7b-chat",
        "mPLUG-OWl2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BlenderAlchemy Editing 3D Graphics with Vision-Language Models": {
    "filename": "BlenderAlchemy Editing 3D Graphics with Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "BlenderAlchemy",
        "GPT-4V",
        "LLaVA",
        "Gemini",
        "DallE-3",
        "BlenderGPT",
        "TEXTure",
        "Paint3D"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AI-Assisted Generation of Difficult Math Questions": {
    "filename": "AI-Assisted Generation of Difficult Math Questions.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "MATH2"
      ],
      "models": [
        "GPT-4 Omni",
        "Claude 3.5 Sonnet",
        "GPT-4 Turbo",
        "Gemini-1.5-Pro",
        "Claude-3 Opus",
        "Llama-3.1-70B-Instruct",
        "Llama-3-70B-Instruct",
        "MetaMath-70B",
        "MAmmoTH-70B",
        "Mixtral-8\u00d77B-Instruct",
        "MetaMath-13B",
        "MAmmoTH-13B",
        "deepseek-math-7b-instruct",
        "Llama-3.1-8B-Instruct",
        "Llama-3-8B-Instruct",
        "gemma-1.1-7b-Instruct",
        "MetaMath-7B",
        "MAmmoTH-7B",
        "Phi-3-mini-128k-instruct",
        "gemma-1.1-2b-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Object-Centric Instruction Augmentation for Robotic Manipulation": {
    "filename": "Object-Centric Instruction Augmentation for Robotic Manipulation.pdf",
    "analysis": {
      "benchmarks": [
        "Franka Kitchen",
        "Real-Robot"
      ],
      "models": [
        "Object-Centric Instruction Augmentation (OCI)",
        "R3M",
        "BLIP-2"
      ]
    }
  },
  "Beyond Positive Scaling How Negation Impacts Scaling Trends of Language Models": {
    "filename": "Beyond Positive Scaling How Negation Impacts Scaling Trends of Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "NeQA",
        "OBQA",
        "NegatedLAMA",
        "ConceptNet",
        "GoogleRE",
        "SQuAD",
        "TREx"
      ],
      "models": [
        "GPT-3",
        "GPT-3 Text Series",
        "Cohere",
        "Jurassic",
        "Zero-Shot",
        "Zero-Shot w/ Hint",
        "Few-Shot w/ Chain-of-Thought (CoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Distilling Reasoning Capabilities into Smaller Language Models": {
    "filename": "Distilling Reasoning Capabilities into Smaller Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "StrategyQA",
        "SVAMP"
      ],
      "models": [
        "Socratic CoT",
        "problem decomposer",
        "subproblem solver",
        "GPT-2 large",
        "GPT-3 6B",
        "GPT-3 175B",
        "GPT-2 Small (124M)",
        "GPT-2 Medium (355M)",
        "GPT-2 Large (774M)",
        "GPT-2 XL (1.5B)",
        "QG model",
        "QA model",
        "unified student model",
        "iterative student model"
      ]
    }
  },
  "CodeGen An Open Large Language Model for Code with Multi-Turn Program Synthesis": {
    "filename": "CodeGen An Open Large Language Model for Code with Multi-Turn Program Synthesis.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "Multi-Turn Programming Benchmark (MTPB)"
      ],
      "models": [
        "CODEGEN",
        "CODEGEN-NL",
        "CODEGEN-MULTI",
        "CODEGEN-MONO",
        "GPT-NEO",
        "GPT-J",
        "CODEX",
        "code-cushman-001",
        "code-davinci-001",
        "code-davinci-002"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RetICL Sequential Retrieval of In-Context Examples with Reinforcement Learning": {
    "filename": "RetICL Sequential Retrieval of In-Context Examples with Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "TabMWP",
        "GSM8K",
        "QASC"
      ],
      "models": [
        "RetICL",
        "Random",
        "kNN",
        "Complexity",
        "PromptPG",
        "LSTM Classifier",
        "Exhaustive"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MaScQA A Question Answering Dataset for Investigating Materials Science Knowledge of Large Language Models": {
    "filename": "MaScQA A Question Answering Dataset for Investigating Materials Science Knowledge of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MaScQA",
        "MMLU",
        "HellaSwag",
        "WinoGrande",
        "HumanEval",
        "DROP",
        "GSM8K",
        "AI2 Reasoning Challenge (ARC)"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "GPT-3.5-CoT",
        "GPT-4-CoT",
        "MatSciBERT",
        "MatBERT",
        "MaterialsBERT",
        "OpticalBERT",
        "BatteryBERT"
      ]
    }
  },
  "Language Conditioned Traffic Generation": {
    "filename": "Language Conditioned Traffic Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Waymo Open Dataset",
        "Crash Report dataset",
        "Attribute Description dataset"
      ],
      "models": [
        "LCTGen",
        "TrafficGen",
        "MotionCLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Comprehensive Study of GPT-4Vs Multimodal Capabilities in Medical Imaging": {
    "filename": "A Comprehensive Study of GPT-4Vs Multimodal Capabilities in Medical Imaging.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-CXR",
        "VQA-RAD",
        "MS-CXR"
      ],
      "models": [
        "GPT-4V",
        "Show-Tell",
        "Att2in",
        "AdaAtt",
        "Transformer",
        "M2Transformer",
        "R2Gen",
        "R2GenCMN",
        "PPKED",
        "GSK",
        "MSAT",
        "METransformer",
        "R2GenGPT",
        "StAn",
        "BiAn",
        "MAML",
        "MEVF",
        "MMQ",
        "PubMedCLIP",
        "MMBERT",
        "Q2ATransformer",
        "BioViL",
        "BioViL-T",
        "RefTR",
        "VGTR",
        "SeqTR",
        "TransVG",
        "MedRPG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Recommender Systems with Large Language Model Reasoning Graphs": {
    "filename": "Enhancing Recommender Systems with Large Language Model Reasoning Graphs.pdf",
    "analysis": {
      "benchmarks": [
        "Amazon Beauty",
        "Amazon Clothing",
        "MovieLens-1M"
      ],
      "models": [
        "LLMRG",
        "SR-GNN",
        "BERT4Rec",
        "FDSA",
        "CL4SRec",
        "DuoRec",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Opportunities for Large Language Models and Discourse in Engineering Design": {
    "filename": "Opportunities for Large Language Models and Discourse in Engineering Design.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-2",
        "GPT-3",
        "BERT",
        "multi-modal models",
        "Generative Pre-Trained Transformer",
        "pre-trained multi-modal models"
      ]
    }
  },
  "The Landscape of Emerging AI Agent Architectures for Reasoning Planning and Tool Calling A Survey": {
    "filename": "The Landscape of Emerging AI Agent Architectures for Reasoning Planning and Tool Calling A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "HumanEval",
        "MBPP",
        "AgentBench",
        "SmartPlay",
        "WildBench",
        "SWE-bench"
      ],
      "models": [
        "ReAct",
        "RAISE",
        "Reflexion",
        "AutoGPT + P",
        "LATS",
        "Embodied LLM Agents",
        "DyLAN",
        "AgentVerse",
        "MetaGPT"
      ]
    }
  },
  "HouseLLM LLM-Assisted Two-Phase Text-to-Floorplan Generation": {
    "filename": "HouseLLM LLM-Assisted Two-Phase Text-to-Floorplan Generation.pdf",
    "analysis": {
      "benchmarks": [
        "RPlan"
      ],
      "models": [
        "HouseLLM",
        "Layout-LLM",
        "Layout-Final",
        "HouseDiffusion",
        "House-GAN",
        "House-GAN++",
        "Graph2Plan",
        "PuzzleFusion"
      ]
    }
  },
  "On Large Visual Language Models for Medical Imaging Analysis An Empirical Study": {
    "filename": "On Large Visual Language Models for Medical Imaging Analysis An Empirical Study.pdf",
    "analysis": {
      "benchmarks": [
        "BTD",
        "ALL-IDB2",
        "CX-Ray"
      ],
      "models": [
        "BiomedCLIP",
        "OpenCLIP",
        "OpenFlamingo",
        "LLaVA",
        "ChatGPT-4",
        "CNN",
        "ResNet-18"
      ]
    }
  },
  "One Language Many Gaps Evaluating Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks": {
    "filename": "One Language Many Gaps Evaluating Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "ReDial",
        "HumanEval",
        "GSM8K",
        "MBPP",
        "LogicBench",
        "Folio",
        "SVAMP",
        "AsyncHow"
      ],
      "models": [
        "GPT-4o",
        "GPT-4",
        "GPT-3.5-turbo",
        "LLaMA-3.1-70B-Instruct",
        "LLaMA-3-70B-Instruct",
        "LLaMA-3-8B-Instruct",
        "Mistral-7B-Instruct-v0.3",
        "Mixtral-8x7B-Instruct-v0.1",
        "Phi-3-Medium-128K-Instruct",
        "Phi-3-Small-128K-Instruct",
        "Phi-3-Mini-128K-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing SLM via ChatGPT and Dataset Augmentation": {
    "filename": "Enhancing SLM via ChatGPT and Dataset Augmentation.pdf",
    "analysis": {
      "benchmarks": [
        "ANLI"
      ],
      "models": [
        "T5-Small",
        "ChatGPT-3.5-Turbo",
        "FlanT5"
      ]
    }
  },
  "AgentMD Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning": {
    "filename": "AgentMD Empowering Language Agents for Risk Prediction with Large-Scale Clinical Tool Learning.pdf",
    "analysis": {
      "benchmarks": [
        "RiskQA",
        "MIMIC-III"
      ],
      "models": [
        "AgentMD",
        "GPT-4",
        "GPT-3.5",
        "Chain-of-Thought (CoT)",
        "Retrieval-augmented Generation (RAG)",
        "Calculator-Name Prompting"
      ]
    }
  },
  "Reka Core Flash and Edge A Series of Powerful Multimodal Language Models": {
    "filename": "Reka Core Flash and Edge A Series of Powerful Multimodal Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMMU",
        "VQAv2",
        "MMLU",
        "GSM8K",
        "Perception-Test",
        "HumanEval",
        "GPQA",
        "XStoryCloze",
        "XCOPA",
        "XQuAD",
        "TydiQA",
        "Belebele",
        "XWinograd",
        "MedMCQA",
        "PubMedQA",
        "MMLU (Medical)"
      ],
      "models": [
        "Reka Core",
        "Reka Flash",
        "Reka Edge",
        "Claude 3 Opus",
        "Claude 3 Sonnet",
        "Claude 3 Haiku",
        "GPT-4",
        "GPT-4 Turbo",
        "GPT-3.5 Turbo",
        "Gemini Ultra",
        "Gemini Pro 1.0",
        "Gemini Pro 1.5",
        "Llama 2 Chat 70B",
        "Llama 2 Chat 7B",
        "Llava 1.6 34B",
        "IDEFICS 80B",
        "Adept Fuyu 8B",
        "Meditron",
        "Med-PaLM-2",
        "Mistral 7B",
        "Mistral Medium",
        "Grok-1",
        "Gemma 7B"
      ]
    }
  },
  "DART-Math Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving": {
    "filename": "DART-Math Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "CollegeMath",
        "DeepMind-Mathematics",
        "OlympiadBench-Math",
        "TheoremQA"
      ],
      "models": [
        "DART-Math (Uniform)",
        "DART-Math (Prop2Diff)",
        "Mistral-7B",
        "Llama3-8B",
        "Llama3-70B",
        "DeepSeekMath-7B",
        "MetaMath",
        "MMIQC",
        "KPMath-Plus",
        "Xwin-Math",
        "VRT",
        "DART-Math-Llama3-70B (Uniform)",
        "DART-Math-Llama3-70B (Prop2Diff)",
        "DART-Math-DSMath-7B (Uniform)",
        "DART-Math-DSMath-7B (Prop2Diff)",
        "DART-Math-Mistral-7B (Uniform)",
        "DART-Math-Mistral-7B (Prop2Diff)",
        "DART-Math-Llama3-8B (Uniform)",
        "DART-Math-Llama3-8B (Prop2Diff)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Driven Occupancy Prediction": {
    "filename": "Language Driven Occupancy Prediction.pdf",
    "analysis": {
      "benchmarks": [
        "Occ3D-nuScenes"
      ],
      "models": [
        "LOcc",
        "LOcc-BEVDet",
        "LOcc-BEVDet4D",
        "LOcc-BEVFormer",
        "BEVDet",
        "BEVDet4D",
        "BEVFormer",
        "SelfOcc (BEV)",
        "SelfOcc (TPV)",
        "OccNeRF",
        "VEON-B",
        "VEON-L",
        "MonoScene",
        "OccFormer",
        "TPVFormer",
        "CTF-Occ",
        "CVT-Occ"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic": {
    "filename": "Weakly Supervised Explainable Phrasal Reasoning with Neural Fuzzy Logic.pdf",
    "analysis": {
      "benchmarks": [
        "SNLI",
        "e-SNLI"
      ],
      "models": [
        "Explainable Phrasal Reasoning (EPR)",
        "Neural Natural Logic (NNL)",
        "STP (Sentence label Training Phrases)",
        "GPT-3-Davinci",
        "LSTM (Wang & Jiang, 2016)",
        "Transformer (Radford et al., 2018)",
        "SBERT (Reimers & Gurevych, 2019)",
        "Mahabadi et al. (2020)",
        "NILE (Kumar & Talukdar, 2020)",
        "Finetuned WT5 220M (Narang et al., 2020)",
        "Finetuned WT5 11B (Narang et al., 2020)",
        "LIREx (Zhao & Vydiswaran, 2021)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LaMI Large Language Models for Multi-Modal Human-Robot Interaction": {
    "filename": "LaMI Large Language Models for Multi-Modal Human-Robot Interaction.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LaMI",
        "SayCan",
        "GPT-4",
        "CoPAL"
      ]
    }
  },
  "Zero-Shot Prompting Approaches for LLM-based Graphical User Interface Generation": {
    "filename": "Zero-Shot Prompting Approaches for LLM-based Graphical User Interface Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Rico GUI Dataset"
      ],
      "models": [
        "Retrieval-Augmented GUI Generation (RAGG)",
        "Prompt Decomposition for GUI Generation (PDGG)",
        "Self-Critique for GUI Generation (SCGG)",
        "ZS-Instruction",
        "ZS-CoT",
        "BERT-LTR",
        "LLM-Rerank"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation": {
    "filename": "Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "AQUA",
        "SVAMP",
        "StrategyQA",
        "LogicalDeduction",
        "Countries",
        "UMLS",
        "Kinship",
        "NELL-995",
        "FB15K-237"
      ],
      "models": [
        "Gemma",
        "Yi",
        "Llama 2",
        "Transformer",
        "GPT-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SpacTor-T5 Pre-training T5 Models with Span Corruption and Replaced Token Detection": {
    "filename": "SpacTor-T5 Pre-training T5 Models with Span Corruption and Replaced Token Detection.pdf",
    "analysis": {
      "benchmarks": [
        "SuperGLUE",
        "SQuAD",
        "CNN/DailyMail",
        "GLUE",
        "Rainbow",
        "FLAN",
        "BIG-Bench (BBH)",
        "Massive Multitask Language Understanding (MMLU)"
      ],
      "models": [
        "SPACTOR-T5",
        "T5",
        "ELECTRA",
        "SPACTORBase",
        "SPACTORLarge"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BEATS Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search": {
    "filename": "BEATS Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "SVAMP",
        "SimulEq",
        "NumGLUE"
      ],
      "models": [
        "BEATS",
        "Qwen2-7B-Instruct",
        "LLaMA3-8B-Instruct",
        "Yi-1.5-6B-Chat",
        "Mammoth",
        "Internlm-math",
        "DeepSeek",
        "ToT",
        "RAP",
        "ReST-MCTS*",
        "LiteSearch",
        "Zero-Shot Chain-of-Thought",
        "Hard Voting@8",
        "Hard Voting@64",
        "WizardMath",
        "MuggleMath",
        "MetaMath",
        "LEMA-LLaMA",
        "SearchToT",
        "Llama-2+M* (BS@16)",
        "Llama-2+M* (LevinTS@16)",
        "SearchBEATS (w.o. BackVerify)",
        "BEATS (w.o. BackVerify)"
      ]
    }
  },
  "BlendFilter Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering": {
    "filename": "BlendFilter Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering.pdf",
    "analysis": {
      "benchmarks": [
        "HotPotQA",
        "2WikiMultiHopQA",
        "StrategyQA"
      ],
      "models": [
        "BlendFilter",
        "Direct Prompting",
        "CoT Prompting",
        "ReAct",
        "SelfAsk",
        "ITER-RETGEN",
        "GPT3.5-turbo-Instruct",
        "Vicuna 1.5-13b",
        "Qwen-7b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain of Thought Prompting Elicits Knowledge Augmentation": {
    "filename": "Chain of Thought Prompting Elicits Knowledge Augmentation.pdf",
    "analysis": {
      "benchmarks": [
        "CSQA",
        "StrategyQA",
        "Date Understanding",
        "Sports Understanding",
        "AQUA-RAT",
        "GSM8K",
        "SV AMP",
        "MultiArith",
        "SingleEq",
        "AddSub",
        "Last Letter Concatenation"
      ],
      "models": [
        "CoT-KA",
        "ALBERT",
        "DeBERTa",
        "T5",
        "Zero-Shot-CoT",
        "Few-Shot-CoT",
        "Self-Consistency",
        "GPT-3"
      ]
    }
  },
  "Furthest Reasoning with Plan Assessment Stable Reasoning Path with Retrieval-Augmented Large Language Models": {
    "filename": "Furthest Reasoning with Plan Assessment Stable Reasoning Path with Retrieval-Augmented Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HotPotQA",
        "2WikiMultiHopQA",
        "MuSiQue"
      ],
      "models": [
        "Furthest Reasoning with Plan Assessment (FuRePA)",
        "Direct Retrieval",
        "Chain of Thought (CoT)",
        "Iter-RetGen",
        "ChatCot",
        "SearChain"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMs as Visual Explainers Advancing Image Classification with Evolving Visual Descriptions": {
    "filename": "LLMs as Visual Explainers Advancing Image Classification with Evolving Visual Descriptions.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "EuroSAT",
        "UCF101",
        "SUN",
        "Caltech",
        "DTD",
        "CIFAR-10",
        "Flowers102",
        "CUB"
      ],
      "models": [
        "CLIP",
        "DCLIP",
        "WaffleCLIP",
        "CuPL",
        "Iterative Optimization with Visual Feedback"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Visual Program Distillation Distilling Tools and Programmatic Reasoning into Vision-Language Models": {
    "filename": "Visual Program Distillation Distilling Tools and Programmatic Reasoning into Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMBench",
        "OK-VQA",
        "A-OKVQA",
        "TallyQA",
        "POPE",
        "Hateful Memes",
        "GQA",
        "VQAv2",
        "OCRVQA",
        "TextVQA"
      ],
      "models": [
        "PaLI-X",
        "PaLI-X-VPD",
        "PaLI-3",
        "PaLI-3-VPD",
        "PaLI-X Instruct",
        "PaLI-3 Instruct",
        "Flamingo",
        "MiniGPT-4",
        "InstructBLIP",
        "Shikra",
        "Qwen-VL",
        "Qwen-VL-Chat",
        "mPLUG-Owl2",
        "LLaVA-1.5",
        "VisualBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "I Spy a Metaphor Large Language Models and Diffusion Models Co-Create Visual Metaphors": {
    "filename": "I Spy a Metaphor Large Language Models and Diffusion Models Co-Create Visual Metaphors.pdf",
    "analysis": {
      "benchmarks": [
        "SNLI-VE",
        "FLUTE",
        "CrossLing Metaphors",
        "Metaphor Paraphrase"
      ],
      "models": [
        "DALL\u00b7E 2",
        "Stable Diffusion",
        "Instruct GPT-3 (davinci-002)",
        "LLM-DALL\u00b7E 2",
        "LLM-SD",
        "LLM-SD Structured",
        "OFA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation": {
    "filename": "Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation.pdf",
    "analysis": {
      "benchmarks": [
        "SK-TOD",
        "MultiWoz 2.1"
      ],
      "models": [
        "GPT-3",
        "ChatGPT",
        "Flan-t5",
        "Flan-t5-small",
        "Flan-t5-base",
        "Flan-t5-large",
        "bart-base",
        "bart-large-cnn-samsum"
      ]
    }
  },
  "Improving Sample Efficiency of Reinforcement Learning with Background Knowledge from Large Language Models": {
    "filename": "Improving Sample Efficiency of Reinforcement Learning with Background Knowledge from Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Minigrid",
        "Crafter"
      ],
      "models": [
        "BK-CODE",
        "BK-PREF",
        "BK-GOAL",
        "RND",
        "NovelD",
        "Lang-ND",
        "L-NovelD",
        "Motif",
        "ELLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ER-Test Evaluating Explanation Regularization Methods for Language Models": {
    "filename": "ER-Test Evaluating Explanation Regularization Methods for Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SST",
        "Amazon",
        "Yelp",
        "Movies",
        "e-SNLI",
        "MNLI",
        "IMDb",
        "LIT",
        "Flights",
        "ANLP-NLI"
      ],
      "models": [
        "No-ER",
        "IxG",
        "Attention",
        "UNIREX",
        "IxG+MAE",
        "IxG+Huber",
        "Attention+MAE",
        "Attention+Huber",
        "UNIREX+MAE",
        "UNIREX+Huber"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Augmenting large language models with chemistry tools": {
    "filename": "Augmenting large language models with chemistry tools.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChemCrow",
        "GPT-4",
        "Random Forest"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Blind Solvers to Logical Thinkers Benchmarking LLMs Logical Integrity on Faulty Mathematical Problems": {
    "filename": "From Blind Solvers to Logical Thinkers Benchmarking LLMs Logical Integrity on Faulty Mathematical Problems.pdf",
    "analysis": {
      "benchmarks": [
        "FAULTY MATH",
        "MATH"
      ],
      "models": [
        "GPT-4-Turbo",
        "Gemini-1.5-Pro",
        "Qwen-1.5-72B",
        "Claude-3-Opus",
        "Mixtral-8X22B-V0.1",
        "Deepseek-V2",
        "Yi-1.5-34B",
        "Deepseek-Math-7B-RL",
        "Llama-3-70B",
        "Internlm2-Math-20B",
        "GPT-4",
        "Claude 3 Opus",
        "Llama 3 70B",
        "Yi 1.5 34B",
        "Mixtral 8x22B",
        "Qwen 1.5 72B",
        "DeepSeek v2",
        "DeepSeek Math RL",
        "InternLM2-Math"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Clever Hans or Neural Theory of Mind Stress Testing Social Reasoning in Large Language Models": {
    "filename": "Clever Hans or Neural Theory of Mind Stress Testing Social Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Triangle COPA",
        "SocialIQa",
        "ToMi",
        "ToMi'",
        "epistemic_reasoning",
        "Adv-CSFB",
        "FauxPas-EAI"
      ],
      "models": [
        "FlanT5",
        "FlanUl2",
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "Jurassic2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Shape2Scene 3D Scene Representation Learning Through Pre-training on Shape Data": {
    "filename": "Shape2Scene 3D Scene Representation Learning Through Pre-training on Shape Data.pdf",
    "analysis": {
      "benchmarks": [
        "ScanObjectNN",
        "ShapeNetPart",
        "ModelNet40",
        "S3DIS",
        "ScanNet v2",
        "SemanticKITTI",
        "Synthia4D"
      ],
      "models": [
        "Shape2Scene (S2S)",
        "MH-P",
        "MH-V",
        "Point-BERT",
        "MaskPoint",
        "Point-MAE",
        "Point-M2AE",
        "PointGPT-S",
        "PointGPT-B",
        "PointGPT-L",
        "PointContrast",
        "DepthContrast",
        "OcCo",
        "PointClustering",
        "PointViT",
        "PointDif",
        "TAP",
        "STRL",
        "VoteNet",
        "3DETR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Rethinking Data Selection at Scale Random Selection is Almost All You Need": {
    "filename": "Rethinking Data Selection at Scale Random Selection is Almost All You Need.pdf",
    "analysis": {
      "benchmarks": [
        "BBH",
        "alpaca-GPT4",
        "Dolly",
        "FLAN",
        "WizardLM",
        "ShareGPT",
        "Openhermes2.5-1M",
        "GSM",
        "Big-Bench-Hard",
        "HumanEval",
        "MMLU",
        "IFEval"
      ],
      "models": [
        "Llama3-8B",
        "Qwen2-7B",
        "LESS",
        "IFD",
        "SelectIT",
        "DiverseEvol",
        "ZIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TrustNavGPT Modeling Uncertainty to Improve Trustworthiness of Audio-Guided LLM-Based Robot Navigation": {
    "filename": "TrustNavGPT Modeling Uncertainty to Improve Trustworthiness of Audio-Guided LLM-Based Robot Navigation.pdf",
    "analysis": {
      "benchmarks": [
        "Disfluent Navigational Instruction Audio Dataset",
        "RoboTHOR simulation environment"
      ],
      "models": [
        "TrustNavGPT",
        "LM-Nav",
        "TrustNavGPT w/o Vocal",
        "TrustNavGPT w/o Vision"
      ]
    }
  },
  "Are Large Language Models Good Prompt Optimizers": {
    "filename": "Are Large Language Models Good Prompt Optimizers.pdf",
    "analysis": {
      "benchmarks": [
        "BigBench",
        "Object Counting",
        "Navigate",
        "Snarks",
        "Question Selection"
      ],
      "models": [
        "Iterative-APE",
        "APO",
        "APO-Sum",
        "PromptAgent",
        "OPRO",
        "Unified Setting",
        "GPT-3.5-Turbo",
        "Llama-2-70B-chat",
        "Zero-shot-CoT",
        "Few-shot-CoT",
        "ABO",
        "ABO-Ablation"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CrossGLG LLM Guides One-shot Skeleton-based 3D Action Recognition in a Cross-level Manner": {
    "filename": "CrossGLG LLM Guides One-shot Skeleton-based 3D Action Recognition in a Cross-level Manner.pdf",
    "analysis": {
      "benchmarks": [
        "NTU RGB+D 60",
        "NTU RGB+D 120",
        "Kinetics"
      ],
      "models": [
        "CrossGLG",
        "MotionBERT",
        "InfoGCN",
        "HDGCN",
        "APSR",
        "uDTW",
        "SL-DML",
        "Skeleton-DML",
        "ALCA-GCN",
        "GAP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Eight challenges in developing theory of intelligence": {
    "filename": "Eight challenges in developing theory of intelligence.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Hopfield model",
        "Hopfield networks",
        "large language models",
        "Chat-GPT",
        "GPT",
        "generative pretrained transformer",
        "Fermi-bose machine",
        "neural tangent kernel",
        "kernel regression",
        "reinforcement learning",
        "Bayesian inference",
        "autoregressive model",
        "dynamic predictive coding",
        "quasi-potential method",
        "dynamical mean-field theory",
        "generalized Potts model",
        "global workspace framework",
        "integrated information theory"
      ]
    }
  },
  "Prompted Contextual Vectors for Spear-Phishing Detection": {
    "filename": "Prompted Contextual Vectors for Spear-Phishing Detection.pdf",
    "analysis": {
      "benchmarks": [
        "Enron",
        "SpamAssassin",
        "UCI SMS corpus",
        "VirusTotal"
      ],
      "models": [
        "k-nearest neighbors",
        "CatBoost",
        "XGBoost",
        "DistilBERT",
        "DistilRoberta",
        "MiniLM",
        "MPnet",
        "text-embedding-ada-002",
        "Extra Trees",
        "Llama 3.1 8B",
        "Llama 3 8B",
        "Phi 3 Medium",
        "Mistral Nemo",
        "Random Forest",
        "XGBoost (Gualberto et al. - Method 1)",
        "Random Forest (Gualberto et al. - Method 2)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Minimum Levels of Interpretability for Artificial Moral Agents": {
    "filename": "Minimum Levels of Interpretability for Artificial Moral Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Minimum Level of Interpretability (MLI)",
        "artificial moral agents (AMAs)",
        "black box models",
        "post-hoc explanations of black box models",
        "algorithmic transparency",
        "decomposability",
        "Chain-of-Thought (CoT) prompting",
        "large language models (LLMs)",
        "GPT-3",
        "multi-valued action reasoning system",
        "reinforcement learning (RL) based AMA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Everything of Thoughts Defying the Law of Penrose Triangle for Thought Generation": {
    "filename": "Everything of Thoughts Defying the Law of Penrose Triangle for Thought Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Game of 24",
        "8-Puzzle",
        "Pocket Cube"
      ],
      "models": [
        "Everything of Thoughts (XOT)",
        "Chain-of-Thought (CoT)",
        "Self-consistency CoT (CoT-SC)",
        "Tree-of-Thought (ToT)",
        "Graph-of-Thought (GoT)",
        "LLaMA-2-13B",
        "GPT-3.5",
        "GPT-4",
        "MCTS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ACER Automatic Language Model Context Extension via Retrieval": {
    "filename": "ACER Automatic Language Model Context Extension via Retrieval.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Question (NQ)",
        "TriviaQA (TQA)",
        "NarrativeQA",
        "LongBench"
      ],
      "models": [
        "ACER",
        "Llama-3-8B-Instruct",
        "Llama-3-8B-ProLong-Base",
        "Llama-3-8B-ProLong-512k-Instruct",
        "Together-Llama-2-7B-32K-Instruct",
        "Llama3-8B-Instruct (Truncation)",
        "Llama3-8B-Instruct (RAG)",
        "Llama3.1-8B-Instruct",
        "Mistral-Nemo-Instruct-2407"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automatically Correcting Large Language Models Surveying the landscape of diverse self-correction strategies": {
    "filename": "Automatically Correcting Large Language Models Surveying the landscape of diverse self-correction strategies.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SQuAD",
        "Open-Domain QA",
        "Commonsense Reasoning",
        "Machine Translation",
        "Summarization",
        "Dialogue",
        "Arithmetic Reasoning",
        "Code Generation",
        "Logical Reasoning",
        "Semantic Parsing",
        "Story Generation",
        "Proof Generation",
        "Toxicity Detection",
        "Factual Error Detection",
        "Bargaining Game"
      ],
      "models": [
        "Self-Refine",
        "Clinical SV",
        "Reflexion",
        "IterRefinement",
        "Auto-Post-Editing",
        "RCI",
        "SelFee",
        "SelfCheckGPT",
        "LLM Self Defense",
        "Re3",
        "CodeRL",
        "FLIRT",
        "REFINER",
        "RL4F",
        "Yan et al. (2023a)",
        "Baldur",
        "CRITIC",
        "FacTool",
        "RARR",
        "LLM-Augmenter",
        "Self-Checker",
        "REFEED",
        "Olausson et al. (2023)",
        "Self-Edit",
        "Self-Debug",
        "Self-Evolve",
        "Logic-LM",
        "Self-Critique",
        "ALGO",
        "Charalambous et al. (2023)",
        "Self-Correction",
        "Multiagent Debate",
        "LM vs LM",
        "ICL-AIF",
        "RLHF",
        "Fine-Grained RLHF",
        "HH-RLHF",
        "Moral RLHF",
        "Sparrow",
        "ILF",
        "ILF-Code",
        "SLT",
        "Gao et al. (2023a)",
        "Chain-of-Hindsight",
        "Quark",
        "SimCLS",
        "BERTTune",
        "STaR",
        "Self-Instruct",
        "RLAIF",
        "SIRLC",
        "Self-Improve",
        "AlpacaFarm",
        "ReST",
        "Self-Verification",
        "CodeT",
        "LEVER",
        "RR",
        "InstructScore",
        "MBR Decoding",
        "DIVERSE",
        "TeachMe",
        "PRM",
        "DiffusionLM",
        "PPLM",
        "Fudge",
        "Entailer",
        "NLProofS",
        "GRACE",
        "CoRe",
        "Varshney et al. (2023)",
        "MemPrompt",
        "Maieutic Prompting",
        "SI",
        "RAP",
        "SelfEval-Decoding",
        "SelfCheck",
        "Tree of Thoughts"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unleashing Artificial Cognition Integrating Multiple AI Systems": {
    "filename": "Unleashing Artificial Cognition Integrating Multiple AI Systems.pdf",
    "analysis": {
      "benchmarks": [
        "Kaggle Lichess",
        "Chess.com puzzles"
      ],
      "models": [
        "OpenSI-CoSMIC",
        "Mistral 7B",
        "GPT-4o",
        "GPT-3.5 Turbo",
        "Gemma 7B Instruct",
        "Mistral 7B Instruct",
        "fine-tuned Mistral 7B"
      ]
    }
  },
  "Large Language Model LLM as a System of Multiple Expert Agents An Approach to solve the Abstraction and Reasoning Corpus ARC Challenge": {
    "filename": "Large Language Model LLM as a System of Multiple Expert Agents An Approach to solve the Abstraction and Reasoning Corpus ARC Challenge.pdf",
    "analysis": {
      "benchmarks": [
        "Abstraction and Reasoning Corpus (ARC)"
      ],
      "models": [
        "Large Language Models (LLMs) as a system of multiple expert agents",
        "GPT-4",
        "GPT-3.5",
        "Decision Transformers"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Visual Adversarial Examples Jailbreak Aligned Large Language Models": {
    "filename": "Visual Adversarial Examples Jailbreak Aligned Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "RealToxicityPrompts"
      ],
      "models": [
        "MiniGPT-4",
        "InstructBLIP",
        "LLaVA",
        "Vicuna",
        "LLaMA-2-13B-Chat",
        "LLaMA-2",
        "GPT-4",
        "Flamingo",
        "Bard",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Black-box Uncertainty Quantification Method for LLM-as-a-Judge": {
    "filename": "Black-box Uncertainty Quantification Method for LLM-as-a-Judge.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA",
        "Reliance Study",
        "Summarization CNN/DM",
        "Feedback Collection",
        "FeedbackQA"
      ],
      "models": [
        "Mixtral-8x7B-Instruct-v01",
        "Llama-3-8B-Instruct",
        "Llama-3-70B-Instruct"
      ]
    }
  },
  "AI and Generative AI for Research Discovery and Summarization": {
    "filename": "AI and Generative AI for Research Discovery and Summarization.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "ChatGPT Plus",
        "GPT-4",
        "Gemini Pro",
        "Semantic Scholar",
        "Consensus",
        "Assistant by Scite",
        "Elicit",
        "Litmaps",
        "ResearchRabbit",
        "ScholarAI",
        "ResearchGPT"
      ]
    }
  },
  "BMW Agents - A Framework For Task Automation Through Multi-Agent Collaboration": {
    "filename": "BMW Agents - A Framework For Task Automation Through Multi-Agent Collaboration.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "AutoGPT",
        "BabyAGI",
        "AutoGen",
        "LangChain",
        "LangGraph",
        "LlamaIndex",
        "ChatDev",
        "RAISE",
        "GPT-Engineer",
        "MetaGPT",
        "DyLAN",
        "AgentVerse",
        "Embodied Agents",
        "AgentLite",
        "LLMArena",
        "LLMHarmony",
        "AgentGPT",
        "crewAI",
        "SuperAGI",
        "OpenAgents",
        "HuggingFace Transformers Agents",
        "BMW Assistant",
        "Editor",
        "Critic",
        "Coder",
        "Architect",
        "Tester"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "When MOE Meets LLMs Parameter Efficient Fine-tuning for Multi-task Medical Applications": {
    "filename": "When MOE Meets LLMs Parameter Efficient Fine-tuning for Multi-task Medical Applications.pdf",
    "analysis": {
      "benchmarks": [
        "PromptCBLUE"
      ],
      "models": [
        "MOELoRA",
        "ChatGPT",
        "Huatuo",
        "P-Tuning",
        "LoRA (Full)",
        "LoRA (Single)",
        "LoRA (Full+TP)",
        "Task-Arithmetic",
        "LoRAHub",
        "MoLoRA",
        "MOELoRA(D)",
        "MOELoRA(S)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CoReS Orchestrating the Dance of Reasoning and Segmentation": {
    "filename": "CoReS Orchestrating the Dance of Reasoning and Segmentation.pdf",
    "analysis": {
      "benchmarks": [
        "ReasonSeg",
        "refCOCO",
        "refCOCO+",
        "refCOCOg"
      ],
      "models": [
        "CoReS",
        "LISA",
        "OVSeg",
        "GRES",
        "X-Decoder",
        "SEEM",
        "MCN",
        "VLT",
        "CRIS",
        "LAVT",
        "ReLA",
        "PolyFormer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can ChatGPT Defend its Belief in Truth Evaluating LLM Reasoning via Debate": {
    "filename": "Can ChatGPT Defend its Belief in Truth Evaluating LLM Reasoning via Debate.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "PrOntoQA",
        "StrategyQA",
        "CommonsenseQA 2.0",
        "Creak",
        "BIG-Bench"
      ],
      "models": [
        "ChatGPT",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Natural Language Interfaces for Tabular Data Querying and Visualization A Survey": {
    "filename": "Natural Language Interfaces for Tabular Data Querying and Visualization A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "ATIS",
        "GeoQuery",
        "Restaurants",
        "Academic",
        "Scholar",
        "IMDB",
        "Yelp",
        "Advising",
        "MIMICSQL",
        "SEDE",
        "WikiSQL",
        "Spider",
        "Squall",
        "KaggleDBQA",
        "SParC",
        "CoSQL",
        "CHASE",
        "Spider-SYN",
        "Spider-SSP",
        "Spider-realistic",
        "Spider-CG",
        "Dr. Spider",
        "CSpider",
        "DuSQL",
        "TableQA",
        "ViText2SQL",
        "PortugueseSpider",
        "PAUQ",
        "Spider-DK",
        "knowSQL",
        "BIRD",
        "Gao et al., 2015",
        "Kumar et al., 2016",
        "Srinivasan et al., 2021",
        "nvBench",
        "ChartDialogs",
        "Dial-NVBench",
        "CNvBench"
      ],
      "models": [
        "TEAM",
        "CHAT-80",
        "PRECISE",
        "NaLIR",
        "ATHENA",
        "Templar",
        "SQLizer",
        "SQLNet",
        "TypeSQL",
        "IncSQL",
        "EditSQL",
        "Data2Vis",
        "Seq2Vis",
        "ncNet",
        "MMCoVisNet",
        "GNN",
        "Global-GNN",
        "RAT-SQL",
        "LGESQL",
        "SADGA",
        "ShadowGNN",
        "Hui et al., 2021",
        "S2SQL",
        "RGVisNet",
        "COARSE2FINE",
        "IE-SQL",
        "HydraNet",
        "RYANSQL",
        "Seq2Tree",
        "Seq2AST",
        "SyntaxSQLNet",
        "IRNet",
        "SmBoP",
        "NatSQL",
        "PICARD",
        "UniSAr",
        "Seq2SQL",
        "Wang et al., 2018",
        "Suhr et al., 2020",
        "SQLOVA",
        "X-SQL",
        "TaBERT",
        "Bridge",
        "GraPPa",
        "GAP",
        "UnifiedSKG",
        "Graphix-T5",
        "RESDSQL",
        "C3",
        "ZERoNL2SQL",
        "DIN-SQL",
        "Liu and Tan, 2023",
        "SC-Prompt",
        "Nan et al., 2023",
        "Tai et al., 2023",
        "SQL-PaLM",
        "Guo et al., 2023",
        "DAIL-SQL",
        "PET-SQL",
        "NL2INTERFACE",
        "Chat2VIS",
        "Prompt4Vis"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Evolution for Evading Social Media Regulation via LLM-Based Multi-Agent Simulation": {
    "filename": "Language Evolution for Evading Social Media Regulation via LLM-Based Multi-Agent Simulation.pdf",
    "analysis": {
      "benchmarks": [
        "Guess the Number Game",
        "Illegal Pet Trading",
        "Nuclear Wastewater Discharge"
      ],
      "models": [
        "LLM-driven agents",
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses": {
    "filename": "Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses.pdf",
    "analysis": {
      "benchmarks": [
        "TiMoS"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "LLaMa-2",
        "BERT",
        "MulCom"
      ]
    }
  },
  "ERBench An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models": {
    "filename": "ERBench An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Movie",
        "Soccer",
        "Airport",
        "Music",
        "Book"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Llama2-70B-Chat",
        "Gemini-Pro",
        "Claude-3-Sonnet",
        "Mistral-7B-Instruct",
        "GPT-4V",
        "Gemini-Pro-Vision"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Image2Struct Benchmarking Structure Extraction for Vision-Language Models": {
    "filename": "Image2Struct Benchmarking Structure Extraction for Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Image2Struct",
        "Webpages",
        "LaTeX",
        "Musical Scores"
      ],
      "models": [
        "Claude 3 Opus",
        "Claude 3 Sonnet",
        "Claude 3.5 Sonnet",
        "Gemini 1.0 Pro Vision",
        "Gemini 1.5 Pro",
        "GPT-4 Omni",
        "GPT-4 Vision",
        "LLaVA",
        "LLaVA NeXT",
        "IDEFICS Instruct 9B",
        "IDEFICS Instruct 80B",
        "IDEFICS2 8B",
        "Palmyra Vision 003",
        "Qwen-VL Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Large Language Models in Process Mining Capabilities Benchmarks Evaluation Strategies and Future Challenges": {
    "filename": "Evaluating Large Language Models in Process Mining Capabilities Benchmarks Evaluation Strategies and Future Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "AGIEval",
        "MT-Bench",
        "XIEZHI",
        "ARB",
        "MMBench",
        "MM-Vet",
        "SPIDER",
        "SPIDER-realistic",
        "APPS",
        "DecodingTrust"
      ],
      "models": [
        "GPT-4",
        "Google Bard/Gemini"
      ]
    }
  },
  "Testing the Depth of ChatGPTs Comprehension via Cross-Modal Tasks Based on ASCII-Art GPT35s Abilities in Regard to Recognizing and Generating ASCII-Art Are Not Totally Lacking": {
    "filename": "Testing the Depth of ChatGPTs Comprehension via Cross-Modal Tasks Based on ASCII-Art GPT35s Abilities in Regard to Recognizing and Generating ASCII-Art Are Not Totally Lacking.pdf",
    "analysis": {
      "benchmarks": [
        "ASCII-Art Archive"
      ],
      "models": [
        "GPT3.5",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SimLayerKV A Simple Framework for Layer-Level KV Cache Reduction": {
    "filename": "SimLayerKV A Simple Framework for Layer-Level KV Cache Reduction.pdf",
    "analysis": {
      "benchmarks": [
        "LongBench",
        "Ruler",
        "Needle-In-A-Haystack (NIAH)"
      ],
      "models": [
        "SimLayerKV",
        "LLaMA2-7B",
        "LLaMA3-8B",
        "Mistral-7B",
        "LLaMA2-7B-chat",
        "LLaMA3-8B-Instruct",
        "Mistral-7B-Instruct",
        "MiniCache"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CoT-TL Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning": {
    "filename": "CoT-TL Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "drone planning",
        "CleanUp World",
        "pick-and-place",
        "OSM"
      ],
      "models": [
        "CoT-TL with GPT-4",
        "CoT-TL with GPT-3",
        "CoT-TL with Mistral-7b",
        "CoT-TL with Starcoder",
        "RNN",
        "CopyNet",
        "BART-FT-Raw",
        "Lang2LTL"
      ]
    }
  },
  "Next-Generation Simulation Illuminates Scientific Problems of Organised Complexity": {
    "filename": "Next-Generation Simulation Illuminates Scientific Problems of Organised Complexity.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "sophisticated behavioural simulation (SBS)",
        "next-generation simulation (NGS)",
        "foundation models",
        "LLM-based agent simulation",
        "LLaMA-2-7B-chat",
        "LLaMA-2-13B-chat",
        "AlphaFold2",
        "agent-based modelling simulation (ABMS)"
      ]
    }
  },
  "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models": {
    "filename": "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Admissible Set",
        "Online Bin Packing (OR)",
        "Online Bin Packing (Weibull)",
        "Traveling Salesman Problem (TSP)"
      ],
      "models": [
        "FunSearch",
        "EoH",
        "ReEvo",
        "(1+1)-EPS",
        "GPT-3.5",
        "GPT-4",
        "Claude 3 Opus",
        "CodeLlama-7B",
        "CodeLlama-34B",
        "DeepSeek-Coder-6.7B",
        "DeepSeek-Coder-33B",
        "UniXcoder",
        "StarCoder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Fox-1 Technical Report": {
    "filename": "Fox-1 Technical Report.pdf",
    "analysis": {
      "benchmarks": [
        "ARC Challenge",
        "HellaSwag",
        "TruthfulQA",
        "MMLU",
        "Winogrande",
        "GSM8k"
      ],
      "models": [
        "Fox-1-1.6B",
        "Fox-1-1.6B-Instruct-v0.1",
        "StableLM-2-1.6B",
        "Gemma-2B",
        "Qwen1.5-1.8B",
        "OpenELM1.1B"
      ]
    }
  },
  "Knowledge Solver Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs": {
    "filename": "Knowledge Solver Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs.pdf",
    "analysis": {
      "benchmarks": [
        "CommonsenseQA",
        "OpenbookQA",
        "MedQA-USMLE"
      ],
      "models": [
        "Knowledge Solver (KSL)",
        "GPT-3.5",
        "LLaMA",
        "LLaMA 2",
        "Alpaca-LoRA"
      ]
    }
  },
  "Reducing Hallucinations Enhancing VQA for Flood Disaster Damage Assessment with Visual Contexts": {
    "filename": "Reducing Hallucinations Enhancing VQA for Flood Disaster Damage Assessment with Visual Contexts.pdf",
    "analysis": {
      "benchmarks": [
        "FFD-IQA"
      ],
      "models": [
        "VQA-TSP",
        "ZFDDA zero-shot CoT",
        "ZFDDA w/o CoT"
      ]
    }
  },
  "Short Film Dataset SFD A Benchmark for Story-Level Video Understanding": {
    "filename": "Short Film Dataset SFD A Benchmark for Story-Level Video Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "Short Film Dataset (SFD)",
        "ActivityNet-QA",
        "How2QA",
        "EgoSchema",
        "MovieQA",
        "MovieChat",
        "LVU",
        "CinePile",
        "TVQA",
        "NeXT-QA",
        "iVQA",
        "MSRVTT-QA",
        "MSVD-QA",
        "TGIF-QA",
        "Ego4D",
        "AGQA",
        "AVA",
        "AutoAD",
        "MovieNet",
        "EgoTaskQA",
        "Charades-Ego",
        "MAD",
        "UCF101",
        "YouTube-8M",
        "Kinetics",
        "Social-IQ",
        "STAR",
        "MSR-VTT",
        "ActivityNet-QA"
      ],
      "models": [
        "Gemma2B",
        "Mistral7B",
        "LLaMA 38B",
        "GPT-3.5",
        "Mixtral8x7B",
        "Claude 3Haiku",
        "Claude 3Sonnet",
        "LLaMA 370B",
        "GPT-4",
        "FrozenBiLM",
        "mPLUG-Owl2",
        "Video-LLaVA",
        "LLoVi",
        "LangRepo",
        "MovieChat",
        "TimeChat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Unlocking Spell on Base LLMs Rethinking Alignment via In-Context Learning": {
    "filename": "The Unlocking Spell on Base LLMs Rethinking Alignment via In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "just-eval-instruct",
        "AlpacaEval",
        "MT-bench",
        "LIMA",
        "HH-RLHF-redteam",
        "MaliciousInstruct"
      ],
      "models": [
        "URIAL",
        "Mistral-7b-Instruct",
        "Llama-2-70b-chat",
        "Llama-2-7b-chat",
        "Vicuna-7b",
        "Mistral-7b",
        "Llama-2-70b",
        "Llama-2-7b",
        "gpt-3.5-turbo",
        "gpt-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Augmented Language Models a Survey": {
    "filename": "Augmented Language Models a Survey.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "BBH",
        "MMLU",
        "GSM-HARD"
      ],
      "models": [
        "Augmented Language Models (ALMs)",
        "Chain-of-Thought (CoT)",
        "Self-ask",
        "ReAct",
        "Minerva",
        "UL2",
        "PaLM",
        "GPT-3",
        "LaMDA",
        "Atlas",
        "RETRO",
        "REALM",
        "RAG",
        "PEER",
        "Flamingo",
        "Socratic Models",
        "WebGPT",
        "WebShop",
        "Mind's Eye",
        "PAL",
        "SayCan",
        "NLMap-SayCan",
        "RT-1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can ChatGPT Detect DeepFakes A Study of Using Multimodal Large Language Models for Media Forensics": {
    "filename": "Can ChatGPT Detect DeepFakes A Study of Using Multimodal Large Language Models for Media Forensics.pdf",
    "analysis": {
      "benchmarks": [
        "Celeb-DF",
        "FFHQ",
        "DF3"
      ],
      "models": [
        "ChatGPT",
        "Google Gemini",
        "LLaMA",
        "GPT4V",
        "StyleGAN2",
        "Latent Diffusion",
        "CNN-aug",
        "GAN-DCT",
        "Nodown",
        "BeyondtheSpectrum",
        "PSM",
        "GLFF",
        "Gemini 1.0"
      ]
    }
  },
  "Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs": {
    "filename": "Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "BBQ",
        "Multi-Role Debate dataset"
      ],
      "models": [
        "RLDF",
        "GPT-3.5-turbo",
        "GPT-2",
        "Qwen1.5-7B",
        "Llama2-7B",
        "ChatGLM3-6B",
        "Baichuan2-7B",
        "CoT",
        "SFT",
        "Fairthinking",
        "RLAIF"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Context Matter Data-Efficient Augmentation of Large Language Models for Scientific Applications": {
    "filename": "Context Matter Data-Efficient Augmentation of Large Language Models for Scientific Applications.pdf",
    "analysis": {
      "benchmarks": [
        "AGIEval",
        "ChemLLMBench",
        "SCIEval",
        "HaluEval"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ROSE A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning": {
    "filename": "ROSE A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning.pdf",
    "analysis": {
      "benchmarks": [
        "SHP",
        "SE",
        "HH"
      ],
      "models": [
        "ROSE",
        "DSIR",
        "RDS",
        "LESS",
        "BM25",
        "Shapley",
        "Influence Functions",
        "Random",
        "Full",
        "Valid.",
        "W/O Finetuning",
        "Llama-2-7B",
        "Llama-2-13B",
        "Llama-3.1-8B",
        "Llama-3.1-8B-INS.",
        "Mistral-7B-V0.3",
        "Mistral-7B-INS.-V0.3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Navigating Hallucinations for Reasoning of Unintentional Activities": {
    "filename": "Navigating Hallucinations for Reasoning of Unintentional Activities.pdf",
    "analysis": {
      "benchmarks": [
        "OOPs",
        "UCF-Crimes"
      ],
      "models": [
        "Large Multimodal Models",
        "Dream of Thoughts (DoT)",
        "Video ChatGPT",
        "Video LLaMA",
        "Video Chat",
        "Video LLaMAv2",
        "Open Flamingo",
        "Chain of Thought (CoT)"
      ]
    }
  },
  "BlendRL A Framework for Merging Symbolic and Neural Policy Learning": {
    "filename": "BlendRL A Framework for Merging Symbolic and Neural Policy Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Atari Learning Environments",
        "Kangaroo",
        "Seaquest",
        "Donkey Kong"
      ],
      "models": [
        "BlendRL",
        "Neural PPO",
        "NUDGE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving medical reasoning through retrieval and self-reflection with retrieval-augmented large language models": {
    "filename": "Improving medical reasoning through retrieval and self-reflection with retrieval-augmented large language models.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "MedMCQA",
        "MMLU",
        "LiveQA",
        "MedicationQA"
      ],
      "models": [
        "Self-BioRAG",
        "RAG",
        "Self-RAG",
        "GPT-3.5",
        "GPT-4-base",
        "Alpaca",
        "FLAN-T5",
        "PMC-LLaMA",
        "Galactica",
        "MedAlpaca",
        "MEDITRON",
        "LLaMA2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain-of-Thought Predictive Control": {
    "filename": "Chain-of-Thought Predictive Control.pdf",
    "analysis": {
      "benchmarks": [
        "Moving Maze",
        "Franka-Kitchen",
        "ManiSkill2",
        "Stack Cube",
        "Turn Faucet",
        "Peg Insertion",
        "Push Chair",
        "Pour"
      ],
      "models": [
        "Chain-of-Thought Predictive Control (CoTPC)",
        "Behavior Transformer (BeT)",
        "Decision Transformer (DT)",
        "Decision Diffuser (DD)",
        "Diffusion Policy (DP)",
        "vanilla BC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Optima Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System": {
    "filename": "Optima Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "2WikiMultiHopQA",
        "TriviaQA",
        "CBT",
        "GSM8K",
        "MATH",
        "ARC-C",
        "MMLU"
      ],
      "models": [
        "OPTIMA",
        "CoT",
        "Self-Consistency",
        "MAD",
        "AutoForm",
        "OPTIMA-iSFT",
        "OPTIMA-iDPO",
        "OPTIMA-iSFT-DPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Federated Foundation Models Scalable Dataset Pipelines for Group-Structured Learning": {
    "filename": "Towards Federated Foundation Models Scalable Dataset Pipelines for Group-Structured Learning.pdf",
    "analysis": {
      "benchmarks": [
        "FedC4",
        "FedWiki",
        "FedBookCO",
        "FedCCnews",
        "Amazon Reviews",
        "Stack Overflow",
        "Reddit",
        "Blog Corpus",
        "Shakespeare",
        "Gigaword",
        "CIFAR-100",
        "WILDS",
        "Py150"
      ],
      "models": [
        "FedAvg",
        "FedSGD",
        "decoder-only transformer",
        "BERT base",
        "GPT-2 small",
        "Reptile"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-planning Code Generation with Large Language Models": {
    "filename": "Self-planning Code Generation with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MBPP-sanitized",
        "HumanEval",
        "HumanEval-X",
        "MBPP-ET",
        "HumanEval-ET"
      ],
      "models": [
        "self-planning",
        "direct",
        "Code CoT",
        "Ground-truth Planning",
        "AlphaCode",
        "Incoder",
        "CodeGeeX",
        "CodeGen-Mono",
        "PaLM Coder",
        "text-davinci-003",
        "code-davinci-002",
        "text-davinci-002",
        "code-cushman-001",
        "text-curie-001",
        "text-babbage-001",
        "text-ada-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards a Theoretical Understanding of the Reversal Curse via Training Dynamics": {
    "filename": "Towards a Theoretical Understanding of the Reversal Curse via Training Dynamics.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "bilinear model",
        "one-layer transformers",
        "multi-layer transformers",
        "GPT-2 architecture"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Boosting of Thoughts Trial-and-Error Problem Solving with Large Language Models": {
    "filename": "Boosting of Thoughts Trial-and-Error Problem Solving with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "AQuA",
        "MMLU",
        "SVAMP",
        "MATH",
        "Game of 24"
      ],
      "models": [
        "Boosting of Thoughts (BoT)",
        "GPT-4",
        "Llama2",
        "Chain-of-thought (CoT)",
        "CoT-SC",
        "Complex CoT",
        "Tree of Thoughts (ToT)",
        "Progressive-Hint Prompting (PHP)",
        "CSV"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Toolink Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model": {
    "filename": "Toolink Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-bench",
        "AQUA-RAT",
        "GSM8K",
        "TabMWP",
        "FinQA",
        "MATH",
        "Dynamic Counting",
        "Unit Interpretation"
      ],
      "models": [
        "Toolink",
        "ChatGPT",
        "LLaMA-7B",
        "LLaMA-CoS",
        "Alpaca",
        "LLaMA-CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Talk like a Graph Encoding Graphs for Large Language Models": {
    "filename": "Talk like a Graph Encoding Graphs for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GraphQA"
      ],
      "models": [
        "PaLM 62B",
        "PaLM 2-XXS",
        "PaLM 2-XS",
        "PaLM 2-S",
        "PaLM 2-L"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Life Cycle of Knowledge in Big Language Models A Survey": {
    "filename": "The Life Cycle of Knowledge in Big Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "LAMA",
        "oLMpics",
        "LM diagnostics",
        "BIG-bench",
        "BLiMP",
        "X-FACTR",
        "Multilingual LAMA",
        "Bio LAMA",
        "CAT",
        "NumerSense",
        "Open Sesame",
        "LKT",
        "NPI probe",
        "Edge probe",
        "MDL probe",
        "Structural probe",
        "Physical Commonsense"
      ],
      "models": [
        "ALBERT",
        "RoBERTa",
        "BERT",
        "ChatGPT",
        "FTM",
        "SERAC",
        "MEM-PROMPT",
        "CALINET",
        "KNOWEDITOR",
        "MEMD",
        "Knowledge Neuron",
        "ROME"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers": {
    "filename": "Towards Truly Zero-shot Compositional Visual Reasoning with LLMs as Programmers.pdf",
    "analysis": {
      "benchmarks": [
        "RefCOCO",
        "RefCOCO+",
        "GQA",
        "NExT-QA"
      ],
      "models": [
        "ViperGPT",
        "VisProg",
        "CodeVQA",
        "OWLv2",
        "SigLiT",
        "MiDaS",
        "PaLI-3",
        "code-bison",
        "GPT-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatScratch An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12": {
    "filename": "ChatScratch An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12.pdf",
    "analysis": {
      "benchmarks": [
        "Dr. Scratch"
      ],
      "models": [
        "ChatScratch",
        "Scratch",
        "Scratch-specialized Large Language Model",
        "Stable Diffusion with ControlNet"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Stochastic Parrots or ICU Experts Large Language Models in Critical Care Medicine A Scoping Review": {
    "filename": "Stochastic Parrots or ICU Experts Large Language Models in Critical Care Medicine A Scoping Review.pdf",
    "analysis": {
      "benchmarks": [
        "Spanish Medical Residency Entrance Examination",
        "Japanese Emergency Medicine Board Certification Examinations",
        "American Board of Surgery In-Training Examination",
        "Medical Information Mart for Intensive Care (MIMIC) III"
      ],
      "models": [
        "ChatGPT-3.5",
        "GPT-4",
        "BioMed-RoBERTa",
        "Claude-2",
        "Bard",
        "Gemini",
        "Bing",
        "ELMo",
        "BERT",
        "BioGPT",
        "MedAlpaca"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Complex Reading Comprehension Through Question Decomposition": {
    "filename": "Complex Reading Comprehension Through Question Decomposition.pdf",
    "analysis": {
      "benchmarks": [
        "DROP",
        "BREAK"
      ],
      "models": [
        "t5-base",
        "bart-base",
        "GPT-3",
        "NAQANet",
        "NumNet",
        "QDGAT",
        "Nerd",
        "separate t5-base variant",
        "unified t5-base variant",
        "separate bart-base variant",
        "unified bart-base variant"
      ]
    }
  },
  "SpeechGen Unlocking the Generative Power of Speech Language Models with Prompts": {
    "filename": "SpeechGen Unlocking the Generative Power of Speech Language Models with Prompts.pdf",
    "analysis": {
      "benchmarks": [
        "CoVOST2",
        "LibriSpeech",
        "LJSpeech"
      ],
      "models": [
        "SpeechGen",
        "Unit mBART",
        "AudioLM",
        "TWIST",
        "SPECTRON",
        "GSLM",
        "pGSLM",
        "SpeechPrompt",
        "SpeechPrompt v2",
        "WAVPROMPT",
        "Whisper"
      ]
    }
  },
  "Wearable intelligent throat enables natural speech in stroke patients with dysarthria": {
    "filename": "Wearable intelligent throat enables natural speech in stroke patients with dysarthria.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "AI-driven intelligent throat (IT) system",
        "token decoding network",
        "token synthesis agent (TSA)",
        "sentence expansion agent (SEA)",
        "1D-CNN",
        "1D ResNet-101",
        "1D ResNet-18",
        "GPT-4o-mini API"
      ]
    }
  },
  "MM-Narrator Narrating Long-form Videos with Multimodal In-Context Learning": {
    "filename": "MM-Narrator Narrating Long-form Videos with Multimodal In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "MAD-eval",
        "MAD-v2-Named",
        "MAD-eval-Named"
      ],
      "models": [
        "MM-Narrator",
        "ClipCap",
        "ClipDec",
        "AutoAD-I",
        "AutoAD-II",
        "VLog",
        "MM-Vid"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation": {
    "filename": "Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation.pdf",
    "analysis": {
      "benchmarks": [
        "COCO Caption",
        "Visual Genome Caption",
        "VQA v2",
        "OK-VQA",
        "A-OKVQA",
        "OVEN",
        "Encyclopedic-VQA"
      ],
      "models": [
        "LLaVA",
        "BLIP-2",
        "InstructBLIP",
        "BLIVA",
        "MiniGPT v1",
        "MiniGPT v2",
        "LLaVA v1",
        "LLaVA v1.5",
        "KOSMOS-2",
        "Shikra",
        "GPT4RoI",
        "GPT-4",
        "vicuna-7b-1.5",
        "CLIP-ViT-Large",
        "CoR w/o question",
        "CoR w/ uncertainty",
        "CoR w/ uncertainty, w/o knowledge",
        "Ours CoR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SimpleLLM4AD An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving": {
    "filename": "SimpleLLM4AD An End-to-End Vision-Language Model with Graph Visual Question Answering for Autonomous Driving.pdf",
    "analysis": {
      "benchmarks": [
        "DriveLM-nuScenes"
      ],
      "models": [
        "SimpleLLM4AD",
        "DriveLM baseline",
        "LLaVA-1.5",
        "Cube-LLM",
        "InternViT-6B",
        "Vicuna-13B",
        "LLaMA-Adapter-V2"
      ]
    }
  },
  "Beyond LLMs Advancing the Landscape of Complex Reasoning": {
    "filename": "Beyond LLMs Advancing the Landscape of Complex Reasoning.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "EC AI platform",
        "GPT-4",
        "Projecto",
        "RTW",
        "Classpath"
      ]
    }
  },
  "Learning Reward for Robot Skills Using Large Language Models via Self-Alignment": {
    "filename": "Learning Reward for Robot Skills Using Large Language Models via Self-Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "ManiSkill2",
        "Isaac Gym"
      ],
      "models": [
        "Proposed Self-Alignment Model",
        "Text2Reward",
        "Eureka"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Bayesian Approach to Data Point Selection": {
    "filename": "A Bayesian Approach to Data Point Selection.pdf",
    "analysis": {
      "benchmarks": [
        "MNIST",
        "CIFAR-10",
        "WebNLG",
        "MMLU",
        "ARC-challenge",
        "ARC-easy",
        "HellaSwag"
      ],
      "models": [
        "LeNet5",
        "ResNet32",
        "T5-small",
        "OpenLLaMA 3B",
        "BADS",
        "BLO",
        "CDS",
        "ClassAct",
        "AskLLM-O",
        "Mixing",
        "Meta_Only",
        "Random_Select",
        "Duplicate_Meta"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training": {
    "filename": "Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training.pdf",
    "analysis": {
      "benchmarks": [
        "WikiText2",
        "Colossal Clean Common Crawl (C4)",
        "Penn Treebank (PTB)",
        "Recognizing Textual Entailment (RTE)",
        "WinoGrande",
        "BoolQ",
        "HellaSwag",
        "ARC-e",
        "ARC-c",
        "OBQA"
      ],
      "models": [
        "NEURON AL",
        "OWL",
        "DsNoT",
        "Magnitude",
        "MULTIFLOW",
        "Wanda",
        "SparseGPT",
        "Phi-2",
        "LLama-1 7B",
        "LLama-2 7B",
        "Mistral 7B",
        "OPT 6.7B",
        "LLama-1 13B",
        "LLama-2 13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LayoutLLM-T2I Eliciting Layout Guidance from LLM for Text-to-Image Generation": {
    "filename": "LayoutLLM-T2I Eliciting Layout Guidance from LLM for Text-to-Image Generation.pdf",
    "analysis": {
      "benchmarks": [
        "COCO2014"
      ],
      "models": [
        "LayoutLLM-T2I",
        "Stable Diffusion",
        "ControlNet",
        "LayoutTrans",
        "MaskGIT",
        "BLT",
        "VQDiffusion",
        "LayoutDM",
        "GLIGEN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking": {
    "filename": "Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking.pdf",
    "analysis": {
      "benchmarks": [
        "MultiWOZ 2.1",
        "MultiWOZ 2.4"
      ],
      "models": [
        "ParsingDST",
        "IC-DST",
        "SimpleTOD++",
        "T5DST + description",
        "TransferQA",
        "IC-DST Codex",
        "IC-DST Text-davinci-003",
        "IC-DST Gpt-3.5-turbo-0301",
        "ParsingDST Text-davinci-003",
        "ParsingDST Gpt-3.5-turbo-0301",
        "ParsingDST (w/o framework)"
      ]
    }
  },
  "SilVar Speech Driven Multimodal Model for Reasoning Visual Question Answering and Object Localization": {
    "filename": "SilVar Speech Driven Multimodal Model for Reasoning Visual Question Answering and Object Localization.pdf",
    "analysis": {
      "benchmarks": [
        "MMMU",
        "ScienceQA",
        "LISA",
        "SilVar"
      ],
      "models": [
        "SilVar",
        "CLIP",
        "Whisper",
        "LLaMA 3.1-8B",
        "Flamingo",
        "BLIP-2",
        "Llava",
        "LocVLM",
        "LISA",
        "GPT-4o",
        "Qwen2-Audio",
        "SALMONN",
        "Llama-Omni",
        "SpeechGPT",
        "HuggingGPT",
        "Adept Fuyu-8B",
        "OpenFlamingo2-9B",
        "MiniGPT4-Vicuna-13B",
        "LLaMA-Adapter2-7B",
        "LLaV A-1.5-13B",
        "Qwen-VL-7B-Chat",
        "Chat-UniVi (7B)",
        "LaVIN-13B",
        "MiniGPT-4"
      ]
    }
  },
  "Large Language Model-Powered Smart Contract Vulnerability Detection New Perspectives": {
    "filename": "Large Language Model-Powered Smart Contract Vulnerability Detection New Perspectives.pdf",
    "analysis": {
      "benchmarks": [
        "Common Vulnerabilities and Exposures (CVEs) database"
      ],
      "models": [
        "GPTLens",
        "AUDITOR",
        "CRITIC",
        "GPT-4",
        "GPT-3.5",
        "Claude"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automatic Behavior Tree Expansion with LLMs for Robotic Manipulation": {
    "filename": "Automatic Behavior Tree Expansion with LLMs for Robotic Manipulation.pdf",
    "analysis": {
      "benchmarks": [
        "LLM-OBTEA dataset"
      ],
      "models": [
        "BETR-XP-LLM",
        "LLM-BT",
        "LLM-OBTEA",
        "HOBTEA",
        "MOSAIC",
        "SayCan",
        "LLM+P",
        "Text2Reaction",
        "GPT-4-1106",
        "GPT-3.5"
      ]
    }
  },
  "KNIFE Distilling Reasoning Knowledge From Free-Text Rationales": {
    "filename": "KNIFE Distilling Reasoning Knowledge From Free-Text Rationales.pdf",
    "analysis": {
      "benchmarks": [
        "OpenBookQA",
        "StrategyQA",
        "ECQA",
        "QuaRTz"
      ],
      "models": [
        "KNIFE",
        "T5-Base",
        "T5-Large",
        "FT (I!O)",
        "FT (I!OR)",
        "FT (I!RO)",
        "FT (I!R!O)",
        "FT (IR!O)",
        "FT Dropout (IR!O)",
        "FT Teacher Init.",
        "CoT (I!RO)",
        "GPT-NeoX",
        "GPT-3 (text-davinci-003)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoFeedback An LLM-based Framework for Efficient and Accurate API Request Generation": {
    "filename": "AutoFeedback An LLM-based Framework for Efficient and Accurate API Request Generation.pdf",
    "analysis": {
      "benchmarks": [
        "API-Bank",
        "MP-API",
        "ToolAlpaca-single",
        "ToolAlpaca-mix"
      ],
      "models": [
        "AutoFeedback",
        "GPT-3.5 Turbo",
        "GPT-4 Turbo",
        "LLaMA-2-7B",
        "Mistral-V0.2-7B",
        "ToolAlpaca-7B",
        "LLaMA-3-8B-chinese",
        "Mistral-V0.3-7B-chinese"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BlockFound Customized blockchain foundation model for anomaly detection": {
    "filename": "BlockFound Customized blockchain foundation model for anomaly detection.pdf",
    "analysis": {
      "benchmarks": [
        "Ethereum",
        "Solana"
      ],
      "models": [
        "BlockFound",
        "BlockGPT",
        "Doc2Vec",
        "GPT-4o",
        "Heuristic",
        "BERT-base",
        "BERT-large"
      ]
    }
  },
  "A Survey on Text-guided 3D Visual Grounding Elements Recent Advances and Future Directions": {
    "filename": "A Survey on Text-guided 3D Visual Grounding Elements Recent Advances and Future Directions.pdf",
    "analysis": {
      "benchmarks": [
        "ScanNet",
        "ReferIt3D",
        "ARKitSceneRefer",
        "3DVG-Transformer",
        "3DRefTransformer",
        "3D-SPS",
        "3D-STMN",
        "3D-VLA",
        "3DVP",
        "3D-SPS",
        "3DRefTR",
        "3DOGSFormer",
        "3D-VisTA",
        "3D-VLP",
        "3DVG-Transformer",
        "3DRefTransformer",
        "3D-SPS",
        "3D-STMN",
        "3D-VLA",
        "3DVP",
        "3D-SPS",
        "3DRefTR",
        "3DOGSFormer",
        "3D-VisTA",
        "3D-VLP"
      ],
      "models": [
        "ScanRefer",
        "ReferIt3D",
        "3DVG-Transformer",
        "3DRefTransformer",
        "3D-SPS",
        "3D-STMN",
        "3D-VLA",
        "3DVP",
        "3D-SPS",
        "3DRefTR",
        "3DOGSFormer",
        "3D-VisTA",
        "3D-VLP",
        "3DVG-Transformer",
        "3DRefTransformer",
        "3D-SPS",
        "3D-STMN",
        "3D-VLA",
        "3DVP",
        "3D-SPS",
        "3DRefTR",
        "3DOGSFormer",
        "3D-VisTA",
        "3D-VLP",
        "Uni3DL",
        "RoMa",
        "3DVLP",
        "PATRON",
        "3D-SPS",
        "EDA",
        "3DRefTR",
        "3DOGSFormer",
        "3D-VisTA",
        "3D-VLP",
        "3DVG-Transformer",
        "3DRefTransformer",
        "3D-SPS",
        "3D-STMN",
        "3D-VLA",
        "3DVP",
        "3D-SPS",
        "3DRefTR",
        "3DOGSFormer",
        "3D-VisTA",
        "3D-VLP",
        "Uni3DL",
        "RoMa",
        "3DVLP",
        "PATRON",
        "3D-SPS",
        "EDA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SAGE Bridging Semantic and Actionable Parts for GEneralizable Manipulation of Articulated Objects": {
    "filename": "SAGE Bridging Semantic and Actionable Parts for GEneralizable Manipulation of Articulated Objects.pdf",
    "analysis": {
      "benchmarks": [
        "ManiSkill",
        "GAPartNet",
        "SAPIEN"
      ],
      "models": [
        "SAGE",
        "GAPartNet",
        "VoxPoser",
        "GPT-4V",
        "GroundedSAM",
        "DINOv2",
        "PointGroup",
        "SoftGroup",
        "AutoGPart",
        "PartGroundedSAM"
      ]
    }
  },
  "ConvFinQA Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering": {
    "filename": "ConvFinQA Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "CONV FINQA",
        "FinQA",
        "SQuAD",
        "SQA",
        "CSQA",
        "CoQA",
        "QuAC",
        "DROP",
        "MathQA",
        "TAT-QA"
      ],
      "models": [
        "CONV FINQA",
        "FinQANet",
        "GPT-2",
        "T5",
        "BERT-base",
        "BERT-large",
        "RoBERTa-base",
        "RoBERTa-large",
        "GPT-3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain of Preference Optimization Improving Chain-of-Thought Reasoning in LLMs": {
    "filename": "Chain of Preference Optimization Improving Chain-of-Thought Reasoning in LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Bamboogle",
        "WikiMultiHopQA",
        "HotpotQA",
        "Fever",
        "Feverous",
        "Vitaminc",
        "SVAMP"
      ],
      "models": [
        "LLaMA",
        "Mistral",
        "Chain of Thought (CoT)",
        "Tree of Thought (ToT)",
        "Chain of Preference Optimization (CPO)",
        "TS-SFT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-Assisted Code Cleaning For Training Accurate Code Generators": {
    "filename": "LLM-Assisted Code Cleaning For Training Accurate Code Generators.pdf",
    "analysis": {
      "benchmarks": [
        "APPS",
        "CODE-CONTESTS"
      ],
      "models": [
        "CODELLAMA-7B",
        "ALPHA CODE",
        "CODE-DAVINCI-002",
        "GPT-3.5-TURBO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GPT as Psychologist Preliminary Evaluations for GPT-4V on Visual Affective Computing": {
    "filename": "GPT as Psychologist Preliminary Evaluations for GPT-4V on Visual Affective Computing.pdf",
    "analysis": {
      "benchmarks": [
        "DISFA",
        "RAF-DB",
        "CASME2",
        "iMiGUE",
        "Real-Life Trial"
      ],
      "models": [
        "GPT-4V",
        "DRML",
        "DSIN",
        "LP",
        "SRERL",
        "EAC",
        "JAA",
        "ARL",
        "FAUDT",
        "PIAP",
        "ME-GraphAU",
        "BG-AU",
        "MPSCL"
      ]
    }
  },
  "Harnessing Business and Media Insights with Large Language Models": {
    "filename": "Harnessing Business and Media Insights with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Global 500",
        "Fortune 1000"
      ],
      "models": [
        "Fortune Analytics Language Model (FALM)",
        "state-of-the-art open-source LLM with prompt engineering"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Instance-adaptive Zero-shot Chain-of-Thought Prompting": {
    "filename": "Instance-adaptive Zero-shot Chain-of-Thought Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MMLU",
        "Causal Judgement",
        "SVAMP",
        "CommonsenseQA",
        "Tracking Shuffled Objects"
      ],
      "models": [
        "LLaMA-2-13B-Chat",
        "LLaMA-3-8B-Instruct",
        "LLaMA-3-70B-Instruct",
        "Qwen-14B-Chat",
        "OPPR",
        "Self-discover",
        "IAP-ss",
        "IAP-mv"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On the Expressive Power of a Variant of the Looped Transformer": {
    "filename": "On the Expressive Power of a Variant of the Looped Transformer.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "AlgoFormer",
        "standard transformer",
        "vanilla looped transformer",
        "GPT-2 model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning to Route Among Specialized Experts for Zero-Shot Generalization": {
    "filename": "Learning to Route Among Specialized Experts for Zero-Shot Generalization.pdf",
    "analysis": {
      "benchmarks": [
        "T0 Held-Out (T0HO)",
        "BIG-bench Hard (BBH)",
        "BIG-bench Lite (BBL)"
      ],
      "models": [
        "PHATGOOSE",
        "T0-3B",
        "FLAN-T5 XL",
        "Retrieval",
        "Arrow",
        "Merged Experts",
        "Average Activation",
        "Oracle",
        "Best Individual"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Advancing LLM Reasoning Generalists with Preference Trees": {
    "filename": "Advancing LLM Reasoning Generalists with Preference Trees.pdf",
    "analysis": {
      "benchmarks": [
        "LeetCode",
        "TheoremQA",
        "HumanEval",
        "MBPP",
        "GSM-Plus",
        "MATH",
        "SVAMP",
        "ASDiv",
        "BBH-Hard",
        "IFEval",
        "MINT",
        "RewardBench",
        "AutoJ",
        "MT-Bench"
      ],
      "models": [
        "EURUS-7B",
        "EURUS-70B",
        "EURUS-7B-SFT",
        "EURUS-70B-SFT",
        "EURUS-RM-7B",
        "Mistral-7B-Instruct-v0.2",
        "Zephyr-7B-\u03b2",
        "OpenChat-3.5-1210",
        "Starling-LM-7B-\u03b1",
        "Magicoder-S-DS-6.7B",
        "OpenCI-DS-6.7B",
        "MAmmoTH-7B-Mistral",
        "WizardMath-7B-v1.1",
        "OpenMath-Mistral-7B",
        "Mixtral-8x7B-Instruct",
        "DeepSeek-Coder-33B-Instruct",
        "CodeLLaMA-70B-Instruct",
        "DeepSeek-LM-67B-Chat",
        "QWen1.5-72B-Chat",
        "OpenCI-CL-70B",
        "OpenMath-CL-70B",
        "GPT-3.5 Turbo",
        "GPT-4",
        "PairRM",
        "Starling-RM-7B",
        "Starling-RM-34B",
        "UltraRM-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GPT-4 as an Agronomist Assistant Answering Agriculture Exams Using Large Language Models": {
    "filename": "GPT-4 as an Agronomist Assistant Answering Agriculture Exams Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Certified Crop Adviser (CCA) Exam",
        "EMBRAPA Dataset",
        "AgriExams Questions"
      ],
      "models": [
        "Llama2-13B",
        "Llama2-70B",
        "GPT-3.5",
        "GPT-4",
        "RAG (Retrieval-Augmented Generation)",
        "ER (Ensemble Refinement)"
      ]
    }
  },
  "Evaluating the World Model Implicit in a Generative Model": {
    "filename": "Evaluating the World Model Implicit in a Generative Model.pdf",
    "analysis": {
      "benchmarks": [
        "taxi rides in New York City",
        "Othello",
        "logic puzzles"
      ],
      "models": [
        "transformer trained on shortest paths",
        "transformer trained on noisy shortest paths",
        "transformer trained on random walks",
        "untrained transformer",
        "Llama-2 (70B)",
        "Llama-3 (8B)",
        "Llama-3 (70B)",
        "Mixtral-8x22B",
        "Qwen 1.5 (72B)",
        "Qwen 1.5 (110B)",
        "GPT-3.5 (turbo)",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PerceptionCLIP Visual Classification by Inferring and Conditioning on Contexts": {
    "filename": "PerceptionCLIP Visual Classification by Inferring and Conditioning on Contexts.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "ImageNetV2",
        "ImageNet-R",
        "ImageNet-A",
        "ImageNet-Sketch",
        "CUB200",
        "EuroSAT",
        "Places365",
        "Flowers102",
        "Food101",
        "Oxford Pets",
        "Waterbirds",
        "CelebA"
      ],
      "models": [
        "CLIP",
        "PerceptionCLIP",
        "ViT-B/16",
        "ViT-B/32",
        "ViT-L/14",
        "RN50"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "JustiLM Few-shot Justification Generation for Explainable Fact-Checking of Real-world Claims": {
    "filename": "JustiLM Few-shot Justification Generation for Explainable Fact-Checking of Real-world Claims.pdf",
    "analysis": {
      "benchmarks": [
        "ExClaim",
        "WatClaimCheck"
      ],
      "models": [
        "JustiLM",
        "Atlas",
        "Flan-T5",
        "Llama2",
        "GPT-4",
        "ExplainerFC",
        "ExplainMT",
        "Contriever",
        "BM25",
        "Lead-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Thinking Before Looking Improving Multimodal LLM Reasoning via Mitigating Visual Hallucination": {
    "filename": "Thinking Before Looking Improving Multimodal LLM Reasoning via Mitigating Visual Hallucination.pdf",
    "analysis": {
      "benchmarks": [
        "MMVP",
        "HallusionBench",
        "POPE",
        "MME",
        "MathVista",
        "SEED-Bench"
      ],
      "models": [
        "VIC",
        "GPT-4o mini",
        "Gemini 1.5 Flash",
        "GPT-4o",
        "Gemini 1.5 Pro",
        "zero-shot CoT",
        "Qwen-VL Plus"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Thinking LLMs General Instruction Following with Thought Generation": {
    "filename": "Thinking LLMs General Instruction Following with Thought Generation.pdf",
    "analysis": {
      "benchmarks": [
        "AlpacaEval",
        "Arena-Hard",
        "GSM8K"
      ],
      "models": [
        "Llama-3-8B-Instruct",
        "TPO",
        "GPT-4",
        "Mistral Large",
        "Qwen2 72B Instruct",
        "Self-Taught Evaluator (STE)",
        "ArmoRM",
        "Direct response baseline"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation": {
    "filename": "Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation.pdf",
    "analysis": {
      "benchmarks": [
        "MultiDoc2Dial"
      ],
      "models": [
        "U-EIDG",
        "RAG-BART large",
        "DIALKI-BART large",
        "FiD-T5 base",
        "EviGui-G-T5 base",
        "U-EIDG-T5 base",
        "U-EIDG ub-T5 base"
      ]
    }
  },
  "How Secure Are Large Language Models LLMs for Navigation in Urban Environments": {
    "filename": "How Secure Are Large Language Models LLMs for Navigation in Urban Environments.pdf",
    "analysis": {
      "benchmarks": [
        "Touchdown",
        "Map2Seq"
      ],
      "models": [
        "VELMA-GPT3",
        "VELMA-GPT4",
        "VELMA-LLaMa",
        "VELMA-LLaMa2",
        "VELMA-FT",
        "VELMA-RBL",
        "LM-Nav"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Compositional Semantic Parsing with Large Language Models": {
    "filename": "Compositional Semantic Parsing with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CFQ",
        "COGS",
        "SCAN"
      ],
      "models": [
        "Dynamic Least-to-Most Prompting",
        "Chain-of-Thought Prompting",
        "Vanilla Few-Shot Prompting",
        "T5-base",
        "T5-large",
        "T5-3B",
        "HPD",
        "LeAR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Limitations of Language Models in Arithmetic and Symbolic Induction": {
    "filename": "Limitations of Language Models in Arithmetic and Symbolic Induction.pdf",
    "analysis": {
      "benchmarks": [
        "MultiArith",
        "GSM8k"
      ],
      "models": [
        "GPT3",
        "T5",
        "LMs with tutor",
        "DeBERTa",
        "Pathways Language Model (PaLM)",
        "Scratchpad",
        "Chain-of-Thought Prompting",
        "LM with callable programs"
      ]
    }
  },
  "MMLU-Pro Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs": {
    "filename": "MMLU-Pro Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU-Pro+",
        "MMLU-Pro",
        "IFEval",
        "BBH (Big-Bench Hard)",
        "MATH",
        "GPQA",
        "MUSR",
        "GLUE",
        "SuperGLUE",
        "SQuAD"
      ],
      "models": [
        "GPT-4o",
        "Gemini-1.5-Pro",
        "Llama-405B-Ins",
        "O1-preview",
        "Qwen2-72B-Ins",
        "Sonnet-3.5",
        "Claude-3.5 Sonnet",
        "LLaMA-3.1-405B-Instruct",
        "Qwen-2-72B-Instruct"
      ]
    }
  },
  "LLM for Test Script Generation and Migration Challenges Capabilities and Opportunities": {
    "filename": "LLM for Test Script Generation and Migration Challenges Capabilities and Opportunities.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM for SoC Security A Paradigm Shift": {
    "filename": "LLM for SoC Security A Paradigm Shift.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MetaMath Integrating Natural Language and Code for Enhanced Mathematical Reasoning in Large Language Models": {
    "filename": "MetaMath Integrating Natural Language and Code for Enhanced Mathematical Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "Algebra",
        "AIME",
        "MATH"
      ],
      "models": [
        "GPT-4o-mini",
        "Llama-3.1-8b-Turbo",
        "INC-Math",
        "Chain-of-Thought prompting (CoT)",
        "Program-aided Language Models (PAL)",
        "CodeNL",
        "NLCode"
      ]
    }
  },
  "Iteration of Thought Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning": {
    "filename": "Iteration of Thought Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GPQA",
        "Game of 24",
        "Mini Crosswords",
        "HotpotQA-Hard"
      ],
      "models": [
        "Iteration of Thought (IoT)",
        "Autonomous Iteration of Thought (AIoT)",
        "Guided Iteration of Thought (GIoT)",
        "Chain of Thought (CoT)",
        "Tree of Thoughts (ToT)",
        "Self-Refine",
        "Self-Verification",
        "AgentLite"
      ]
    }
  },
  "Recursive Visual Programming": {
    "filename": "Recursive Visual Programming.pdf",
    "analysis": {
      "benchmarks": [
        "VSR",
        "COVR",
        "GQA",
        "NextQA",
        "Dyck Language",
        "Games of 24"
      ],
      "models": [
        "Recursive Visual Programming (RVP)",
        "ViperGPT",
        "CLIP",
        "BLIPv2",
        "CodeVQA",
        "ViLT",
        "HiTeA",
        "VinVL-Base",
        "VisualBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GPTScore Evaluate as You Desire": {
    "filename": "GPTScore Evaluate as You Desire.pdf",
    "analysis": {
      "benchmarks": [
        "text summarization",
        "data-to-text",
        "machine translation",
        "dialogue response generation"
      ],
      "models": [
        "GPTScore",
        "GPT2",
        "OPT",
        "FLAN",
        "GPT3",
        "GPT3-text-davinci-003",
        "GPT3-text-davinci-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Insights into Alignment Evaluating DPO and its Variants Across Multiple Tasks": {
    "filename": "Insights into Alignment Evaluating DPO and its Variants Across Multiple Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "MT-Bench",
        "Big Bench",
        "Open LLM Leaderboard",
        "ARC",
        "HellaSwag",
        "Winogrande",
        "Big Bench Sports Understanding (BB-sports)",
        "Big Bench Causal Judgment (BB-casual)",
        "Big Bench Formal Fallacies (BB-formal)",
        "PIQA",
        "GSM8K",
        "TruthfulQA",
        "MMLU",
        "OpenBookQA",
        "BoolQ"
      ],
      "models": [
        "DPO",
        "IPO",
        "KTO",
        "CPO",
        "Mistral",
        "Mistral+SFT",
        "Mistral+IPO",
        "Mistral+DPO",
        "Mistral+KTO",
        "Mistral+CPO",
        "zephyr-sft-full",
        "Mistral-7B-v0.1",
        "Mistral-instruct-7B-v0.2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Stop Reasoning When Multimodal LLM with Chain-of-Thought Reasoning Meets Adversarial Image": {
    "filename": "Stop Reasoning When Multimodal LLM with Chain-of-Thought Reasoning Meets Adversarial Image.pdf",
    "analysis": {
      "benchmarks": [
        "A-OKVQA",
        "ScienceQA",
        "ImageNet"
      ],
      "models": [
        "MiniGPT4",
        "OpenFlamingo",
        "LLaVA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Generating API Parameter Security Rules with LLM for API Misuse Detection": {
    "filename": "Generating API Parameter Security Rules with LLM for API Misuse Detection.pdf",
    "analysis": {
      "benchmarks": [
        "APIMU4C"
      ],
      "models": [
        "GPTAid",
        "Advance",
        "Goshawk",
        "IPPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RNR Teaching Large Language Models to Follow Roles and Rules": {
    "filename": "RNR Teaching Large Language Models to Follow Roles and Rules.pdf",
    "analysis": {
      "benchmarks": [
        "Alpaca",
        "Ultrachat",
        "RNR-Expert",
        "RNR-Awesome",
        "RNR-AlpacaFarm",
        "IFEval",
        "RoleBench",
        "Alpacafarm",
        "MMLU",
        "BBH",
        "DROP"
      ],
      "models": [
        "RoleNRules",
        "Llama-2",
        "IFT: fixed-system",
        "IFT: no-system",
        "Claude-2",
        "Claude-2.1",
        "Zephyr-7b-beta",
        "Vicuna-7b-v1.5",
        "Mistral-7B-Instruct-v0.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Aligning Large Language Models to a Domain-specific Graph Database": {
    "filename": "Aligning Large Language Models to a Domain-specific Graph Database.pdf",
    "analysis": {
      "benchmarks": [
        "FinGQL",
        "MediGQL"
      ],
      "models": [
        "ChatGPT",
        "mbart-large",
        "mt5-large",
        "Baichuan2-13B-chat",
        "Chatglm3-6B",
        "Qwen-14B-Chat",
        "HuatuoGPT2-7B",
        "BianQue-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Correctness Comparison of ChatGPT4 Gemini Claude3 and Copilot for Spatial Tasks": {
    "filename": "Correctness Comparison of ChatGPT4 Gemini Claude3 and Copilot for Spatial Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "GeoQuestions201",
        "GeoAnQu",
        "GeoQuestions1089",
        "MathVista"
      ],
      "models": [
        "ChatGPT-4",
        "Gemini",
        "Claude-3",
        "Copilot",
        "Claude 3 Opus",
        "Gemini 1.0 Ultra",
        "GPT-4V(ision)",
        "BLIP2-FLAN-T5-XXL",
        "Multimodal Bard"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond Bare Queries Open-Vocabulary Object Grounding with 3D Scene Graph": {
    "filename": "Beyond Bare Queries Open-Vocabulary Object Grounding with 3D Scene Graph.pdf",
    "analysis": {
      "benchmarks": [
        "Replica",
        "ScanNet",
        "Sr3D+",
        "Nr3D",
        "ScanRefer"
      ],
      "models": [
        "BBQ",
        "ConceptGraphs",
        "LLM-Grounder",
        "OpenFusion",
        "ConceptFusion",
        "OpenMask3D",
        "BBQ-CLIP",
        "LERF",
        "OpenScene"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "D-RMGPT Robot-assisted collaborative tasks driven by large multimodal models": {
    "filename": "D-RMGPT Robot-assisted collaborative tasks driven by large multimodal models.pdf",
    "analysis": {
      "benchmarks": [
        "Yale-CMU-Berkeley object and model dataset"
      ],
      "models": [
        "D-RMGPT",
        "DetGPT-V",
        "R-ManGPT",
        "ViLD",
        "OWL-ViT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatGPT Alternative Solutions Large Language Models Survey": {
    "filename": "ChatGPT Alternative Solutions Large Language Models Survey.pdf",
    "analysis": {
      "benchmarks": [
        "MultiArith",
        "Common Sense Reasoning",
        "Closed-book Question Answering",
        "Reading Comprehension",
        "Mathematical Reasoning",
        "Code Generation",
        "Massive Multitask Language Understanding (MMLU)",
        "WinoGrande",
        "DROP",
        "ARC-C",
        "ARC-E",
        "HellaSwag"
      ],
      "models": [
        "ChatGPT",
        "Bard",
        "PaLM",
        "T5",
        "LLaMA",
        "OpenAssistance",
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "GPT-NeoX-20B",
        "BLOOM",
        "Alpaca",
        "GPT-J",
        "GPTNeo",
        "Chinchilla",
        "Gopher",
        "OPT",
        "LLaMA-65B",
        "LLaMA-13B",
        "Minerva-62B",
        "LaMDA",
        "PaLM-540B",
        "PaLM 2",
        "Stanford Alpaca"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Explore then Determine A GNN-LLM Synergy Framework for Reasoning over Knowledge Graph": {
    "filename": "Explore then Determine A GNN-LLM Synergy Framework for Reasoning over Knowledge Graph.pdf",
    "analysis": {
      "benchmarks": [
        "WebQSP",
        "CWQ",
        "MetaQA-1",
        "MetaQA-2",
        "MetaQA-3"
      ],
      "models": [
        "EtD",
        "NSM",
        "UniKGQA",
        "KV-Mem",
        "GraftNet",
        "EmbedKGQA",
        "SR+NSM",
        "KB-Binder",
        "KAPING",
        "RoG-Llama2-7B",
        "ToG-Llama2-70B",
        "EtD-Llama2-13B",
        "RoG-ChatGPT",
        "KD-CoT",
        "StructGPT",
        "ToG-ChatGPT",
        "EtD-ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-driven Imitation of Subrational Behavior  Illusion or Reality": {
    "filename": "LLM-driven Imitation of Subrational Behavior  Illusion or Reality.pdf",
    "analysis": {
      "benchmarks": [
        "Ultimatum Game",
        "Stanford Marshmallow Experiment",
        "Double or Nothing Gamble",
        "Procrastination Experiment"
      ],
      "models": [
        "LLM-driven Imitation Learning Framework",
        "GPT-4",
        "3-layer Neural Network for Q-value Function",
        "Multi-Armed Bandit",
        "RL Policy Network",
        "Prospect Theory Model",
        "Quasi-Hyperbolic Discounting Model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multi-step planning with learned effects of partial action executions": {
    "filename": "Multi-step planning with learned effects of partial action executions.pdf",
    "analysis": {
      "benchmarks": [
        "lever-up dataset",
        "CoppeliaSim simulation dataset"
      ],
      "models": [
        "proposed affordance model",
        "recurrent neural network-based model",
        "LSTM model",
        "Conditional Neural Processes (CNPs) model"
      ]
    }
  },
  "Seq-VCR Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning": {
    "filename": "Seq-VCR Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "5x5 integer multiplication task",
        "arithmetic expression",
        "longest increasing subsequence (LIS)",
        "BIG-bench benchmark",
        "Arithmetic Expressions Feng et al. (2024)",
        "Dynamic Programming (DP)",
        "Longest Increasing Sub-sequence (LIS)"
      ],
      "models": [
        "Seq-VCR",
        "GPT-4",
        "GPT-3.5",
        "GPT-2 Small",
        "minGPT",
        "Vanilla",
        "With CoT",
        "Pause",
        "Seq-VCR + Pause"
      ]
    }
  },
  "Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow": {
    "filename": "Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow.pdf",
    "analysis": {
      "benchmarks": [
        "North American (NA) market dataset",
        "European (EU) market dataset",
        "Emerging (EM) market dataset"
      ],
      "models": [
        "DeBERTa",
        "Mistral",
        "Llama",
        "FinBERT",
        "FinVader"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Large Language Models to Improve REST API Testing": {
    "filename": "Leveraging Large Language Models to Improve REST API Testing.pdf",
    "analysis": {
      "benchmarks": [
        "FDIC Bank Data",
        "Genome Nexus",
        "LanguageTool",
        "OCVN",
        "OhSome",
        "OMDb",
        "REST Countries",
        "Spotify",
        "YouTube"
      ],
      "models": [
        "RESTGPT",
        "NLP2REST",
        "ARTE"
      ]
    }
  },
  "Professional Agents - Evolving Large Language Models into Autonomous Experts with Human-Level Competencies": {
    "filename": "Professional Agents - Evolving Large Language Models into Autonomous Experts with Human-Level Competencies.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "AutoGen",
        "AppAgent",
        "MetaGPT",
        "ModelScope-Agent",
        "AutoAgents",
        "OpenAgents",
        "ChatDev",
        "AGENTVERSE",
        "PAgents"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HAMMR HierArchical MultiModal React agents for generic VQA": {
    "filename": "HAMMR HierArchical MultiModal React agents for generic VQA.pdf",
    "analysis": {
      "benchmarks": [
        "PointQA",
        "EncyclopedicVQA",
        "NLVR2",
        "GQA",
        "TallyQA",
        "TextVQA"
      ],
      "models": [
        "HAMMR",
        "PaLI-X",
        "BLIP-2",
        "Gemini Pro 1.0",
        "Naive Generic ReAct",
        "Specialist ReAct Agents"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Bot or Human Detecting ChatGPT Imposters with A Single Question": {
    "filename": "Bot or Human Detecting ChatGPT Imposters with A Single Question.pdf",
    "analysis": {
      "benchmarks": [
        "Counting",
        "Substitution",
        "Random Editing",
        "Searching",
        "ASCII Art Reasoning",
        "Memorization",
        "Computation"
      ],
      "models": [
        "FLAIR",
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "Vicuna-13b",
        "LLaMA-2-13b",
        "LLaMA-2-70b",
        "GPT-4-CoT",
        "GPT-4-py"
      ]
    }
  },
  "Tool Learning with Foundation Models": {
    "filename": "Tool Learning with Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld"
      ],
      "models": [
        "ChatGPT",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Bootstrapping Multilingual Semantic Parsers using Large Language Models": {
    "filename": "Bootstrapping Multilingual Semantic Parsers using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MTOP",
        "MASSIVE"
      ],
      "models": [
        "LLM-T",
        "TAF",
        "Zero-Shot",
        "Few-Shot",
        "Gold",
        "mT5-Large",
        "LLM-T-8B",
        "LLM-T-62B",
        "LLM-T-540B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SelfEvolve A Code Evolution Framework via Large Language Models": {
    "filename": "SelfEvolve A Code Evolution Framework via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "DS-1000",
        "HumanEval",
        "TransCoder"
      ],
      "models": [
        "SELFEVOLVE",
        "ChatGPT",
        "DocPrompting",
        "Self-Debugging",
        "GPT-4",
        "Codex",
        "PaLM",
        "PaLM-Coder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Recover A Neuro-Symbolic Framework for Failure Detection and Recovery": {
    "filename": "Recover A Neuro-Symbolic Framework for Failure Detection and Recovery.pdf",
    "analysis": {
      "benchmarks": [
        "AI2Thor"
      ],
      "models": [
        "Recover",
        "LLM-based subgoal verifier (LM-SGV)",
        "LLM-based re-planner (LM-RePl)",
        "GPT-4",
        "REFLECT"
      ]
    }
  },
  "How Far Are We to GPT-4V Closing the Gap to Commercial Multimodal Models with Open-Source Suites": {
    "filename": "How Far Are We to GPT-4V Closing the Gap to Commercial Multimodal Models with Open-Source Suites.pdf",
    "analysis": {
      "benchmarks": [
        "DocVQA",
        "ChartQA",
        "InfoVQA",
        "TextVQA",
        "OCRBench",
        "RealWorldQA",
        "AI2D",
        "MMMU",
        "MMBench-EN",
        "MMBench-CN",
        "CCBench",
        "MMVet",
        "SEED",
        "HallusionBench",
        "MathVista",
        "ConvBench",
        "MMT-Bench"
      ],
      "models": [
        "InternVL 1.5",
        "GPT-4V",
        "Claude-3 Opus",
        "Gemini Pro 1.0",
        "Gemini Pro 1.5",
        "Qwen-VL-Max",
        "Qwen-VL-Plus",
        "Grok-1.5V",
        "Text-Monkey",
        "DocOwl-1.5",
        "Mini-Gemini",
        "LLaVA-NeXT",
        "InternVL 1.2",
        "ShareGPT4V-13B",
        "LLaVA-1.5-13B",
        "XComposer2",
        "mPLUG-Owl2",
        "Qwen-VL-Chat",
        "MiniGPT-4",
        "LLaMA-A-V2",
        "Reka Flash",
        "BLIP-2-XXL",
        "Yi-VL-34B",
        "Monkey-Chat",
        "DeepSeek-VL",
        "CogVLM-Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ArguGPT evaluating understanding and identifying argumentative essays generated by GPT models": {
    "filename": "ArguGPT evaluating understanding and identifying argumentative essays generated by GPT models.pdf",
    "analysis": {
      "benchmarks": [
        "ArguGPT",
        "TOEFL11",
        "WECCL",
        "GRE",
        "CLEC"
      ],
      "models": [
        "GPT2-XL",
        "text-babbage-001",
        "text-curie-001",
        "text-davinci-001",
        "text-davinci-002",
        "text-davinci-003",
        "gpt-3.5-turbo",
        "RoBERTa",
        "SVM",
        "GPTZero",
        "claude-instant",
        "bloomz-7b",
        "flan-t5-11b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Words to Wheels Vision-Based Autonomous Driving Understanding Human Language Instructions Using Foundation Models": {
    "filename": "Words to Wheels Vision-Based Autonomous Driving Understanding Human Language Instructions Using Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "RUGD",
        "RELLIS-3D"
      ],
      "models": [
        "Words to Wheels",
        "GANav",
        "Model Predictive Path Integral (MPPI) planner",
        "YOLO-World",
        "EfficientViT-SAM",
        "GPT-4",
        "CLIP-ViT-B-32",
        "motion primitives planner"
      ]
    }
  },
  "Large Language Models are In-context Teachers for Knowledge Reasoning": {
    "filename": "Large Language Models are In-context Teachers for Knowledge Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA",
        "MedMCQA",
        "MedQA"
      ],
      "models": [
        "Self-Explain",
        "Teach-Back",
        "GPT-3.5",
        "Llama2-7B",
        "Llama2-13B",
        "Mistral-7B",
        "Phi3-mini",
        "Zero-shot CoT",
        "Auto-CoT",
        "Human CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Persona to Personalization A Survey on Role-Playing Language Agents": {
    "filename": "From Persona to Personalization A Survey on Role-Playing Language Agents.pdf",
    "analysis": {
      "benchmarks": [
        "MPI",
        "PsychoBench",
        "OpinionQA",
        "CharacterEval",
        "PersonaGym",
        "TimeChara",
        "SocialBench",
        "LiveChat",
        "FoCus",
        "Poly-encoders",
        "MPCHAT",
        "PRM",
        "TaskBench",
        "Assistgui",
        "Planbench"
      ],
      "models": [
        "MetaGPT",
        "OKR-AGENT",
        "Cicero",
        "The Avalon",
        "The Werewolf",
        "Humanoid Agent",
        "ChatHaruhi",
        "CharacterGLM",
        "Character-LLM",
        "RoleLLM",
        "HPD",
        "DITTO",
        "NarrativePlay",
        "MORTISE",
        "MMRole",
        "InCharacter",
        "LifeChoice",
        "PersonaAware-D2S",
        "GIRL",
        "personalized-RLHF",
        "VaRMI",
        "ControlLM",
        "TeachMe",
        "CoPS",
        "PEARL",
        "PersonaDB",
        "ExploreLLM",
        "GeneInput",
        "LFM",
        "PALR",
        "IGL",
        "ONCE",
        "G4C",
        "MMToM-QA",
        "OpenToM",
        "Toolllm",
        "Api-bank",
        "Toolqa",
        "UltraTool",
        "AutoDroid",
        "PDP",
        "PROMPTINJECT",
        "K-Anonymity",
        "ProPILE",
        "COSPLAY",
        "FANToM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Images in Language Space Exploring the Suitability of Large Language Models for Vision  Language Tasks": {
    "filename": "Images in Language Space Exploring the Suitability of Large Language Models for Vision  Language Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "MAMI",
        "HF",
        "MVSA",
        "OK-VQA",
        "NLVR2"
      ],
      "models": [
        "GPT-3",
        "Flan-T5",
        "T0pp",
        "OPT",
        "Cheema et al. (2021)",
        "Wu et al. (2022)",
        "Chen et al. (2020)",
        "Kiela et al. (2020)",
        "Zhang and Wang (2022)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM as Dataset Analyst Subpopulation Structure Discovery with Large Language Model": {
    "filename": "LLM as Dataset Analyst Subpopulation Structure Discovery with Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "Waterbirds",
        "Metashift",
        "Nico++",
        "ImageNet"
      ],
      "models": [
        "SSD-LLM",
        "ERM",
        "GroupDRO",
        "JTT",
        "LfF",
        "LISA",
        "Resample",
        "Reweight",
        "Focal",
        "CBLoss",
        "BSoftmax",
        "Mixup",
        "RandAug",
        "Class Prompt",
        "Class-Attribute Prompt",
        "CiP",
        "Domino",
        "B2T"
      ]
    }
  },
  "Interlinking User Stories and GUI Prototyping A Semi-Automatic LLM-Based Approach": {
    "filename": "Interlinking User Stories and GUI Prototyping A Semi-Automatic LLM-Based Approach.pdf",
    "analysis": {
      "benchmarks": [
        "Rico"
      ],
      "models": [
        "Zero-Shot",
        "Few-Shot 5",
        "Few-Shot 10",
        "CoT t=0",
        "CoT t=0.5",
        "CoT t=1",
        "CoT t=1.3"
      ]
    }
  },
  "Social Learning Towards Collaborative Learning with Large Language Models": {
    "filename": "Social Learning Towards Collaborative Learning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SMS Spam",
        "Lambada",
        "BoolQ",
        "GSM8K",
        "Random Insertion"
      ],
      "models": [
        "PaLM 2-S",
        "OpenAI GPT3.5-Turbo",
        "Zero-shot",
        "Manual Prompt",
        "8-shot Original Examples",
        "8-shot PaLM 2-S Generated Examples",
        "GPT3.5 Generated Instruction",
        "PaLM 2-S Generated Instruction"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ThreatModeling-LLM Automating Threat Modeling using Large Language Models for Banking System": {
    "filename": "ThreatModeling-LLM Automating Threat Modeling using Large Language Models for Banking System.pdf",
    "analysis": {
      "benchmarks": [
        "Microsoft Threat Modeling Tool (TMT) dataset"
      ],
      "models": [
        "ThreatModeling-LLM",
        "Llama-3.1-8B",
        "GPT-3.5-turbo",
        "Cyber Sentinel",
        "STRIDEGPT",
        "Raw LLM (ChatGPT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Zero-shot Sequential Neuro-symbolic Reasoning for Automatically Generating Architecture Schematic Designs": {
    "filename": "Zero-shot Sequential Neuro-symbolic Reasoning for Automatically Generating Architecture Schematic Designs.pdf",
    "analysis": {
      "benchmarks": [
        "Hypothetical lots in New York City",
        "Actual apartment buildings across the US"
      ],
      "models": [
        "Sequential neuro-symbolic reasoning approach",
        "GPT-4",
        "Gurobi",
        "Baseline approach without sequential breakdown",
        "Baseline approach without symbolic reasoning",
        "Baseline approach without neural feedback loop",
        "Baseline approach without symbolic feedback loop"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Detecting Phishing Sites Using ChatGPT": {
    "filename": "Detecting Phishing Sites Using ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "OpenPhish",
        "PhishTank",
        "CrowdCanary"
      ],
      "models": [
        "ChatPhishDetector",
        "GPT-4V",
        "GPT-4",
        "GPT-3.5",
        "Llama-2-70B",
        "Gemini Pro",
        "Gemini Pro Vision",
        "dnstwist",
        "Phishpedia"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Meet NL2Code A Survey": {
    "filename": "Large Language Models Meet NL2Code A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "APPS",
        "CodeContests",
        "DS-1000",
        "DSP",
        "MBXP",
        "MBXP-HumanEval",
        "HumanEval-X",
        "MultiPL-HumanEval",
        "MultiPL-MBPP",
        "PandasEval",
        "NumpyEval",
        "TorchDataEval",
        "MTPB",
        "ODEX",
        "BIG-Bench"
      ],
      "models": [
        "Codex",
        "AlphaCode",
        "InCoder",
        "CodeGen",
        "PaLM-Coder",
        "PanGu-Coder",
        "CodeGeeX",
        "SantaCoder",
        "GPT-C",
        "CodeGPT",
        "GPT-Neo",
        "GPT-J",
        "GPT-CC",
        "CodeParrot",
        "LaMDA",
        "PolyCoder",
        "GPT-NeoX",
        "FIM",
        "PyCodeGPT",
        "BLOOM",
        "PyMT5",
        "PLBART",
        "CodeT5",
        "JuPyT5",
        "CodeRL",
        "CodeT5Mix",
        "ERNIE-Code"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reasoning in Transformers - Mitigating Spurious Correlations and Reasoning Shortcuts": {
    "filename": "Reasoning in Transformers - Mitigating Spurious Correlations and Reasoning Shortcuts.pdf",
    "analysis": {
      "benchmarks": [
        "SimpleLogic",
        "SimpleLogicPS"
      ],
      "models": [
        "WP-BART",
        "SIP-BART",
        "BERT"
      ]
    }
  },
  "Real-World Robot Applications of Foundation Models A Review": {
    "filename": "Real-World Robot Applications of Foundation Models A Review.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "Ego4D",
        "EPIC-KITCHENS",
        "D4RL",
        "RoboNet",
        "Bridge Data",
        "Open X-Embodiement (OXE)"
      ],
      "models": [
        "CLIPort",
        "REFLECT",
        "VoxPoser",
        "CLIP-Fields",
        "TidyBot",
        "Code as Policies",
        "SayTap",
        "General Pattern Machines",
        "GenAug",
        "DIAL",
        "R3M",
        "MVP",
        "VC-1",
        "PaLM-E",
        "RoboVQA",
        "MT-Opt",
        "BC-Z",
        "Gato",
        "RT-1",
        "RT-2",
        "Q-Transformer",
        "RoboCat",
        "TDMs",
        "LM-Nav",
        "CLIP on Wheels",
        "ConceptFusion",
        "ConceptGraphs",
        "VL-Maps",
        "AVL-Maps",
        "GNM",
        "ViNT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning to Reason via Program Generation Emulation and Search": {
    "filename": "Learning to Reason via Program Generation Emulation and Search.pdf",
    "analysis": {
      "benchmarks": [
        "CoLA",
        "Emotion",
        "SST2",
        "Word Sorting",
        "SVAMP",
        "Coin Flip Tracking",
        "Number Summing",
        "CommonsenseQA",
        "Social IQa"
      ],
      "models": [
        "COGEX",
        "Llama-2",
        "Alpaca",
        "Code Llama",
        "COTACS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PathOCl Path-Based Prompt Augmentation for OCL Generation with GPT-4": {
    "filename": "PathOCl Path-Based Prompt Augmentation for OCL Generation with GPT-4.pdf",
    "analysis": {
      "benchmarks": [
        "Royal & Loyal domain model",
        "airport domain model"
      ],
      "models": [
        "PathOCL",
        "UML-Augmentation",
        "GPT-4",
        "Codex",
        "ChatGPT"
      ]
    }
  },
  "ManiTweet A New Benchmark for Identifying Manipulation of News on Social Media": {
    "filename": "ManiTweet A New Benchmark for Identifying Manipulation of News on Social Media.pdf",
    "analysis": {
      "benchmarks": [
        "MANITWEET",
        "FakeNewsNet"
      ],
      "models": [
        "LLM",
        "fine-tuned sequence-to-sequence model",
        "LED-FT",
        "LLM + LED-FT",
        "Vicuna",
        "ChatGPT",
        "CONCRETE",
        "DocNLI",
        "QAFactEval"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Large Language Model for Automatic Evolving of Industrial Data-Centric RD Cycle": {
    "filename": "Leveraging Large Language Model for Automatic Evolving of Industrial Data-Centric RD Cycle.pdf",
    "analysis": {
      "benchmarks": [
        "Qlib"
      ],
      "models": [
        "Arda",
        "Arda wo KM",
        "Standard few-shot prompting",
        "CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "When Qualitative Research Meets Large Language Model Exploring the Potential of QualiGPT as a Tool for Qualitative Coding": {
    "filename": "When Qualitative Research Meets Large Language Model Exploring the Potential of QualiGPT as a Tool for Qualitative Coding.pdf",
    "analysis": {
      "benchmarks": [
        "simulated focus group dataset",
        "real social media dataset"
      ],
      "models": [
        "QualiGPT",
        "ChatGPT",
        "GPT-4",
        "GPT-4o",
        "Claude 3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MindStar Enhancing Math Reasoning in Pre-trained LLMs at Inference Time": {
    "filename": "MindStar Enhancing Math Reasoning in Pre-trained LLMs at Inference Time.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH"
      ],
      "models": [
        "MindStar (M*)",
        "Llama-2-13B",
        "Mistral-7B",
        "GPT-3.5",
        "Grok-1",
        "GPT-4",
        "Claude-3",
        "Gemini Ultra",
        "Llama-3-8B",
        "Llama-3-70B",
        "Grok-1.5",
        "MetaMath-Mistral",
        "MetaMath-Llama-2",
        "Mistral (CoT)",
        "Mistral (CoT-SC@16)",
        "Llama-2 (CoT)",
        "Llama-2 (CoT-SC@16)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Baldur Whole-Proof Generation and Repair with Large Language Models": {
    "filename": "Baldur Whole-Proof Generation and Repair with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "PISA dataset",
        "Isabelle/HOL theorems"
      ],
      "models": [
        "Baldur",
        "Thor",
        "Minerva 8b",
        "Minerva 62b",
        "Sledgehammer",
        "DeepHOL",
        "GPT-f",
        "TacticZero",
        "Lisa",
        "Evariste",
        "Diva",
        "TacTok",
        "ASTactic"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evolving AI Collectives to Enhance Human Diversity and Enable Self-Regulation": {
    "filename": "Evolving AI Collectives to Enhance Human Diversity and Enable Self-Regulation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Claude-2.1",
        "Claude-3-Opus",
        "Gemini Pro",
        "GPT-4-Turbo",
        "text-embedding-3-large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Making Network Configuration Human Friendly": {
    "filename": "Making Network Configuration Human Friendly.pdf",
    "analysis": {
      "benchmarks": [
        "Kathar\u00e1 network emulator"
      ],
      "models": [
        "NETBUDDY",
        "GPT-4"
      ]
    }
  },
  "ChipGPT How far are we from natural language hardware design": {
    "filename": "ChipGPT How far are we from natural language hardware design.pdf",
    "analysis": {
      "benchmarks": [
        "matrix multiplication",
        "4x1 multiplexer",
        "3-to-8 decoder",
        "button count",
        "vector matrix multiplication",
        "add multiply tree",
        "accumulator",
        "simple CPU"
      ],
      "models": [
        "ChipGPT",
        "ChatGPT",
        "HLS-CPP",
        "Chisel",
        "SuSy",
        "Spatial",
        "ScaleHLS",
        "TVM-VTA",
        "CIRCT",
        "XLS",
        "Bosy"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Words to Wheels Automated Style-Customized Policy Generation for Autonomous Driving": {
    "filename": "From Words to Wheels Automated Style-Customized Policy Generation for Autonomous Driving.pdf",
    "analysis": {
      "benchmarks": [
        "HighD dataset"
      ],
      "models": [
        "Words2Wheels",
        "Intelligent Driver Model (IDM)",
        "Proximal Policy Optimization",
        "FollowNet"
      ]
    }
  },
  "EMMA End-to-End Multimodal Model for Autonomous Driving": {
    "filename": "EMMA End-to-End Multimodal Model for Autonomous Driving.pdf",
    "analysis": {
      "benchmarks": [
        "nuScenes",
        "Waymo Open Motion Dataset (WOMD)",
        "Waymo Open Dataset (WOD)"
      ],
      "models": [
        "EMMA",
        "MotionLM",
        "Wayformer",
        "BEV-Planner",
        "DriveVLM-Dual",
        "Ego-MLP",
        "BEVFormer",
        "MV-FCOS3D++"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Large Language Model-based Room-Object Relationships Knowledge for Enhancing Multimodal-Input Object Goal Navigation": {
    "filename": "Leveraging Large Language Model-based Room-Object Relationships Knowledge for Enhancing Multimodal-Input Object Goal Navigation.pdf",
    "analysis": {
      "benchmarks": [
        "Gibson",
        "Matterport3D",
        "Habitat simulator"
      ],
      "models": [
        "LROGNav",
        "PONI",
        "SemExp",
        "FSE-VN",
        "PEANUT",
        "RIM",
        "CER",
        "GTV",
        "L3MVN",
        "LFG",
        "ESC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "UL2 Unifying Language Learning Paradigms": {
    "filename": "UL2 Unifying Language Learning Paradigms.pdf",
    "analysis": {
      "benchmarks": [
        "SuperGLUE",
        "GEM",
        "XSUM",
        "ToTTo",
        "Schema Guided Dialog",
        "C4"
      ],
      "models": [
        "UL2",
        "T5",
        "GPT-like",
        "Causal Language Model (CLM)",
        "Prefix LM (PLM)",
        "Span Corruption (SC)",
        "Span Corruption + LM (SCLM)",
        "UniLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Know Your Contextual Search Intent A Prompting Framework for Conversational Search": {
    "filename": "Large Language Models Know Your Contextual Search Intent A Prompting Framework for Conversational Search.pdf",
    "analysis": {
      "benchmarks": [
        "CAsT-19",
        "CAsT-20",
        "CAsT-21"
      ],
      "models": [
        "LLM4CS",
        "T5QR",
        "ConvDR",
        "COTED",
        "ZeCo",
        "CRDR",
        "ConvGQR"
      ]
    }
  },
  "Deepfake definitions performance metrics and standards datasets and a meta-review": {
    "filename": "Deepfake definitions performance metrics and standards datasets and a meta-review.pdf",
    "analysis": {
      "benchmarks": [
        "SwapMe and FaceSwap dataset",
        "Fake Faces in the Wild (FFW) dataset",
        "generated.photos datasets",
        "MesoNet Deepfake Dataset",
        "100K-Generated-Images",
        "Ding et al.'s swapped face dataset",
        "iFakeFaceDB",
        "Faces-HQ",
        "CelebA-Spoof",
        "Diverse Fake Face Dataset (DFFD)",
        "DeepfakeTIMIT",
        "FaceForensics (FF)",
        "UADFV dataset",
        "DFDC (Deepfake Detection Challenge) preview dataset",
        "FaceForensics++ (FF++)",
        "Deep Fakes Dataset",
        "Celeb-DF v1",
        "Celeb-DF v2",
        "DeepFake Detection (DFD) dataset",
        "DeeperForensics-1.0",
        "DFDC (Deepfake Detection Challenge) full dataset",
        "FFIW 10K(Face Forensics in the Wild) dataset",
        "Korean DeepFake Detection Dataset (KoDF)",
        "VideoForensicsHQ",
        "WildDeepfake",
        "Voice Conversion Challenge 2016 dataset",
        "Voice Conversion Challenge 2018 dataset",
        "ASVspoof 2019 dataset (Logical Access task)",
        "Voice Conversion Challenge 2020 dataset",
        "Baidu Research dataset",
        "ASVspoof 2021 Challenge - Logical Access Database",
        "ASVspoof 2021 Challenge - Speech Deepfake Database",
        "NIST Open Media Forensics Challenge Datasets",
        "ForgeryNet dataset"
      ],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Compact Language Models via Pruning and Knowledge Distillation": {
    "filename": "Compact Language Models via Pruning and Knowledge Distillation.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "HumanEval",
        "Arc-C",
        "HellaSwag",
        "TruthfulQA",
        "WinoGrande",
        "XL-Sum",
        "MT-Bench",
        "Instruction-Following Eval (IFEval)",
        "ChatRAG-Bench",
        "Berkeley Function Calling Leaderboard (BFCL)"
      ],
      "models": [
        "Nemotron-4 15B",
        "Nemotron-3 8B",
        "MINITRON 8B",
        "MINITRON 4B",
        "Mistral 7B",
        "Gemma 7B",
        "Llama-3 8B",
        "Llama-2 7B",
        "Phi-2",
        "Gemma2",
        "Qwen2",
        "MiniCPM",
        "LLM-Pruner",
        "SliceGPT",
        "LaCo",
        "ShortGPT",
        "Sheared LLaMa",
        "MINITRON 4B-instruct",
        "Gemma-2B-IT",
        "Qwen2-1.5B-Instruct",
        "TinyLlama v1.0 Chat",
        "StableLM 2 Chat",
        "Llama-3-8B-instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CLAIM Your Data Enhancing Imputation Accuracy with Contextual Large Language Models": {
    "filename": "CLAIM Your Data Enhancing Imputation Accuracy with Contextual Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "UCI Wine dataset",
        "Glass Identification",
        "Seeds",
        "Wine Quality"
      ],
      "models": [
        "CLAIM",
        "k-Nearest Neighbors (k-NN)",
        "MissForest",
        "GAIN (Generative Adversarial Imputation Nets)",
        "MICE (Multiple Imputation by Chained Equations)",
        "LLaMA 2"
      ]
    }
  },
  "ROSE Revolutionizing Open-Set Dense Segmentation with Patch-Wise Perceptual Large Multimodal Model": {
    "filename": "ROSE Revolutionizing Open-Set Dense Segmentation with Patch-Wise Perceptual Large Multimodal Model.pdf",
    "analysis": {
      "benchmarks": [
        "ADE-20k",
        "COCO",
        "RefCOCO",
        "RefCOCO+",
        "RefCOCOg",
        "COCO-Stuff",
        "Mapillary"
      ],
      "models": [
        "ROSE",
        "Mask2former",
        "OpenSeg",
        "FC-CLIP",
        "CascadePSP",
        "SegRefiner",
        "LLaVA",
        "Shikra",
        "Kosmos-2",
        "LISA",
        "GLaMM",
        "AnyRef",
        "PixelLM",
        "GSVA",
        "VisionLLM",
        "PSALM",
        "Painter",
        "SegGPT",
        "Pix2Seq v2",
        "Osprey-7B",
        "LISA-7B",
        "GLaMM-7B",
        "GSVA-7B",
        "GSVA-13B",
        "Ferret-7B",
        "Ferret-13B",
        "VisionLLM-7B",
        "ROSE-7B",
        "ROSE-7B + CSR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Investigation of Large Language Models for Real-World Hate Speech Detection": {
    "filename": "An Investigation of Large Language Models for Real-World Hate Speech Detection.pdf",
    "analysis": {
      "benchmarks": [
        "HateXplain",
        "COVID-HATE",
        "CallMeSexist",
        "USElectionHate",
        "SWSR"
      ],
      "models": [
        "BERT",
        "RoBERTa",
        "ChatGPT",
        "GPT-3.5-turbo"
      ]
    }
  },
  "Blocks as Probes Dissecting Categorization Ability of Large Multimodal Models": {
    "filename": "Blocks as Probes Dissecting Categorization Ability of Large Multimodal Models.pdf",
    "analysis": {
      "benchmarks": [
        "ComBo"
      ],
      "models": [
        "CLIP",
        "GPT-4V",
        "Gemini-1.5-Pro",
        "LLaVA-v1.5-13B",
        "Qwen-VL-Chat",
        "ResNet-50",
        "ViT-B/16"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "When Scaling Meets LLM Finetuning The Effect of Data Model and Finetuning Method": {
    "filename": "When Scaling Meets LLM Finetuning The Effect of Data Model and Finetuning Method.pdf",
    "analysis": {
      "benchmarks": [
        "WMT14 English-German",
        "WMT19 English-Chinese",
        "MLSum",
        "Flores200"
      ],
      "models": [
        "Full-Model Tuning (FMT)",
        "Prompt Tuning",
        "Low-Rank Adaptation (LoRA)",
        "bilingual LLMs (English&German, English&Chinese)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MathVC An LLM-Simulated Multi-Character Virtual Classroom for Mathematics Education": {
    "filename": "MathVC An LLM-Simulated Multi-Character Virtual Classroom for Mathematics Education.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "MAP"
      ],
      "models": [
        "MATHVC",
        "vanilla simulation",
        "domain-specified simulation",
        "w/ only character schema",
        "w/ only meta planner"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can LLM Find the Green Circle Investigation and Human-Guided Tool Manipulation for Compositional Generalization": {
    "filename": "Can LLM Find the Green Circle Investigation and Human-Guided Tool Manipulation for Compositional Generalization.pdf",
    "analysis": {
      "benchmarks": [
        "ReaSCAN",
        "GSRR"
      ],
      "models": [
        "MM-LSTM",
        "GCN-LSTM",
        "MM-TRF",
        "Gro-CoT",
        "Zero-Shot ICL",
        "Standard Few-Shot ICL",
        "Chain-of-Thought (CoT)",
        "Program-of-Thought (PoT)",
        "Human-guided Tool Manipulation (HTM)"
      ]
    }
  },
  "AI Robustness a Human-Centered Perspective on Technological Challenges and Opportunities": {
    "filename": "AI Robustness a Human-Centered Perspective on Technological Challenges and Opportunities.pdf",
    "analysis": {
      "benchmarks": [
        "Control Flow Graphs",
        "MNIST",
        "CIFAR-10",
        "ImageNet",
        "SQuAD",
        "Common Corruptions",
        "Adversarial Robustness Evaluation",
        "Robustness against Noise",
        "Graph Neural Networks Benchmark",
        "Natural Language Processing Benchmark"
      ],
      "models": [
        "Compositional Neural Networks",
        "Rationale Models",
        "Spiking Neural Networks",
        "Bayesian Neural Networks",
        "Generative Adversarial Networks (GAN)",
        "Adversarially Robust GAN (ARGAN)",
        "Boundary Conditional GAN",
        "Projected Gradient Descent (PGD)",
        "Robust Adversarial Training",
        "Graph Neural Networks (GNN)",
        "Neural Architecture Search (NAS)",
        "Decision Trees with Max-Min Saddle Point",
        "Support Vector Machines with Correntropy",
        "Error Correcting Output Code",
        "Certified Robustness Models",
        "Deterministic Smoothing",
        "Random Smoothing"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Synergize with Automated Machine Learning": {
    "filename": "Large Language Models Synergize with Automated Machine Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Boston",
        "Iris",
        "Age",
        "Default",
        "CIFAR-10",
        "CIFAR-100",
        "Whale",
        "Strip",
        "IMDb Reviews",
        "AG News",
        "Exam",
        "Learning"
      ],
      "models": [
        "Text-to-ML",
        "Contextual Modular Generation",
        "CoT",
        "Zero-shot",
        "Reflexion",
        "Self-Revision",
        "GPT-4",
        "GPT-3.5",
        "PaLM 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Empathy-Based Sandbox Approach to Bridge the Privacy Gap among Attitudes Goals Knowledge and Behaviors": {
    "filename": "An Empathy-Based Sandbox Approach to Bridge the Privacy Gap among Attitudes Goals Knowledge and Behaviors.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "Privacy Sandbox"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LARP Language-Agent Role Play for Open-World Games": {
    "filename": "LARP Language-Agent Role Play for Open-World Games.pdf",
    "analysis": {
      "benchmarks": [
        "Minecraft"
      ],
      "models": [
        "LARP",
        "Voyager",
        "Octopus"
      ]
    }
  },
  "UDA A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis": {
    "filename": "UDA A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "UDA",
        "HybridQA",
        "WiKiTableQuestion",
        "TriviaQA",
        "VisualMRC",
        "FinQA",
        "TAT-DQA",
        "Qasper",
        "PDF-VQA",
        "DocVQA",
        "NarrativeQA",
        "Natural-Questions"
      ],
      "models": [
        "GPT-4",
        "Llama-3-8B",
        "Llama-3-70B",
        "Qwen-1.5-32B",
        "Qwen-1.5-7B",
        "Mixtral-8x7B",
        "Mistral-7B",
        "CodeLlama-7B",
        "CodeLlama-13B",
        "BM-25",
        "all-MiniLM-L6",
        "all-mpnet-base",
        "OpenAI text-embedding-3-large",
        "ColBERT",
        "GPT-4-Omni"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Quantitative and Qualitative Evaluation of LLM-Based Explainable Fault Localization": {
    "filename": "A Quantitative and Qualitative Evaluation of LLM-Based Explainable Fault Localization.pdf",
    "analysis": {
      "benchmarks": [
        "Defects4J",
        "BugsInPy"
      ],
      "models": [
        "AutoFL",
        "Ochiai",
        "DStar",
        "Metallaxis",
        "SmartFL",
        "Test-GPT3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4": {
    "filename": "A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4.pdf",
    "analysis": {
      "benchmarks": [
        "WebText",
        "ImageNet",
        "Books corpus",
        "Wikipedia",
        "ACL",
        "EMNLP",
        "COLING",
        "AAAI",
        "ICML",
        "ICLR",
        "NeurIPS"
      ],
      "models": [
        "GPT-3",
        "GPT-3.5",
        "ChatGPT",
        "GPT-4",
        "InstructGPT",
        "Codex",
        "BERT",
        "RoBERTa",
        "XLNet",
        "ELECTRA",
        "ALBERT",
        "DeBERTa",
        "T5",
        "BART",
        "PaLM",
        "Chinchilla",
        "GLaM",
        "LaMDA",
        "Gopher",
        "Megatron\u2013Turing NLG",
        "BLOOM",
        "Galactica",
        "OPT",
        "LLaMA",
        "LLaMA2",
        "Falcon",
        "BLOOMZ",
        "JAIS",
        "GLM",
        "FLM-101B",
        "FinGPT",
        "BloombergGPT",
        "MedPaLM",
        "MedPaLM2",
        "StarCoder",
        "CodeLlaMa",
        "CodeGen",
        "CodeGen2",
        "VGGNet",
        "AlexNet",
        "GoogleNet",
        "Word2Vec",
        "FastText",
        "Sent2Vec",
        "ELMo",
        "mBERT",
        "mT5",
        "mBART",
        "IndicBERT",
        "XLM",
        "XLM-R",
        "mDeBERTa",
        "DistilBERT",
        "TinyBERT",
        "MobileBERT",
        "MiniLM",
        "LongFormer",
        "BigBird",
        "SapBERT",
        "UmlsBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LiP-LLM Integrating Linear Programming and dependency graph with Large Language Models for multi-robot task planning": {
    "filename": "LiP-LLM Integrating Linear Programming and dependency graph with Large Language Models for multi-robot task planning.pdf",
    "analysis": {
      "benchmarks": [
        "AWS RoboMaker Small House World ROS package"
      ],
      "models": [
        "LiP-LLM",
        "RoCo",
        "SMART-LLM"
      ]
    }
  },
  "MedFuzz Exploring the Robustness of Large Language Models in Medical Question Answering": {
    "filename": "MedFuzz Exploring the Robustness of Large Language Models in Medical Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "MedQA-USMLE"
      ],
      "models": [
        "MedFuzz",
        "GPT-4",
        "GPT-3.5",
        "Claude",
        "OpenBioLLM-70B",
        "Meditron-70B",
        "BioMistral-7B",
        "Medllama3-v20"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Healthcare Copilot Eliciting the Power of General LLMs for Medical Consultation": {
    "filename": "Healthcare Copilot Eliciting the Power of General LLMs for Medical Consultation.pdf",
    "analysis": {
      "benchmarks": [
        "USMLE",
        "MedMCQA",
        "PubMedQA",
        "MedDialog"
      ],
      "models": [
        "Healthcare Copilot",
        "ChatGLM3",
        "ChatGLM3 Copilot",
        "LLaMA2",
        "LLaMA2 Copilot",
        "GPT-3.5",
        "GPT-3.5 Copilot",
        "GPT-4",
        "GPT-4 Copilot",
        "MedAlpaca"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors": {
    "filename": "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors.pdf",
    "analysis": {
      "benchmarks": [
        "FewRel",
        "Wiki-ZSL",
        "ADE",
        "CoNLL2004",
        "GIDS",
        "KBP37",
        "NYT24",
        "NYT11",
        "SciERC",
        "SemEval",
        "TACRED",
        "ACE2004",
        "ACE2005",
        "WebNLG"
      ],
      "models": [
        "MICRE",
        "GPT-2",
        "GPT-2-large",
        "GPT-2-XL",
        "T5-base",
        "T5-large",
        "T5-3B",
        "LLaMA",
        "ESIM",
        "ZS-BERT",
        "PromptMatch",
        "RelationPrompt",
        "RE-Matching",
        "Vanilla w/ GPT-3.5",
        "SumAsk w/ GPT-3.5",
        "TableSequence",
        "ZETT",
        "ProtoNet",
        "MAML",
        "CP",
        "HCRP",
        "LPD",
        "HDN",
        "DeepStruct",
        "CoT-ER w/ GPT-3",
        "FT-BERT",
        "FastRE",
        "CasRel",
        "MPE",
        "StructShot",
        "PA-CRF",
        "RelATE",
        "MG-FTE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MetaGPT Meta Programming for A Multi-Agent Collaborative Framework": {
    "filename": "MetaGPT Meta Programming for A Multi-Agent Collaborative Framework.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "SoftwareDev"
      ],
      "models": [
        "MetaGPT",
        "AutoGPT",
        "LangChain",
        "AgentVerse",
        "ChatDev",
        "AlphaCode",
        "Incoder",
        "CodeGeeX",
        "CodeGen",
        "CodeX",
        "CodeT",
        "PaLM",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MUSTARD Mastering Uniform Synthesis of Theorem and Proof Data": {
    "filename": "MUSTARD Mastering Uniform Synthesis of Theorem and Proof Data.pdf",
    "analysis": {
      "benchmarks": [
        "MUSTARD SAUCE",
        "GSM8K",
        "MATH",
        "Mathlib",
        "miniF2F"
      ],
      "models": [
        "MUSTARD",
        "Llama 2-7B",
        "GPT2-large",
        "Llama 2-70B",
        "GPT-4",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLaMA Rider Spurring Large Language Models to Explore the Open World": {
    "filename": "LLaMA Rider Spurring Large Language Models to Explore the Open World.pdf",
    "analysis": {
      "benchmarks": [
        "Minecraft",
        "MineDojo"
      ],
      "models": [
        "LLaMA-Rider",
        "LLaMA-2-70B-chat",
        "ChatGPT planner",
        "RL",
        "Plan4MC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OlaGPT Empowering LLMs With Human-like Problem-Solving Abilities": {
    "filename": "OlaGPT Empowering LLMs With Human-like Problem-Solving Abilities.pdf",
    "analysis": {
      "benchmarks": [
        "AQuA",
        "E-KAR"
      ],
      "models": [
        "OlaGPT",
        "GPT-3.5-turbo",
        "Auto-CoT",
        "SC",
        "Analogy Thinking (AT)",
        "Decomposition Thinking 1 (DT)",
        "Decomposition Thinking 2 (DST)",
        "Plan Thinking (PT)",
        "Sequential Thinking (ST)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RAGBench Explainable Benchmark for Retrieval-Augmented Generation Systems": {
    "filename": "RAGBench Explainable Benchmark for Retrieval-Augmented Generation Systems.pdf",
    "analysis": {
      "benchmarks": [
        "RAGBench",
        "RGB",
        "AttributionBench",
        "RAGTruth",
        "ChatbotArena",
        "CHATRAGBENCH",
        "CovidQA",
        "PubmedQA",
        "HotpotQA",
        "MS Marco",
        "CUAD",
        "EManual",
        "TechQA",
        "FinQA",
        "TAT-QA",
        "ExpertQA",
        "HAGRID",
        "DelucionQA"
      ],
      "models": [
        "RoBERTa",
        "DeBERTa-large",
        "GPT-3.5",
        "Claude 3 Haiku",
        "RAGAS",
        "TruLens",
        "ARES",
        "DeBERTa-v3-Large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Generating Explanations in Medical Question-Answering by Expectation Maximization Inference over Evidence": {
    "filename": "Generating Explanations in Medical Question-Answering by Expectation Maximization Inference over Evidence.pdf",
    "analysis": {
      "benchmarks": [
        "MQAE-diag",
        "MQAE"
      ],
      "models": [
        "EMIN",
        "T5 (q+a)",
        "BART (q+a)",
        "SIMI (q+a+e)",
        "MHOP (q+a+e)",
        "MEAN (q+a+e)"
      ]
    }
  },
  "BayesPrompt Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction": {
    "filename": "BayesPrompt Prompting Large-Scale Pre-Trained Language Models on Few-shot Inference via Debiased Domain Abstraction.pdf",
    "analysis": {
      "benchmarks": [
        "SemEval 2010 Task 8",
        "TACRED",
        "TACREV",
        "ReTACRED"
      ],
      "models": [
        "BayesPrompt",
        "FINE-TUNING",
        "SPANBERT",
        "KNOWBERT",
        "LUKE",
        "MTB",
        "GDPNET",
        "PTR",
        "KnowPrompt",
        "RetrievalRE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatABL Abductive Learning via Natural Language Interaction with ChatGPT": {
    "filename": "ChatABL Abductive Learning via Natural Language Interaction with ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "variable-length handwritten equation deciphering task"
      ],
      "models": [
        "ChatABL",
        "CNN-based machine model",
        "Vision Transformer (ViT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SPARQL Generation an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph": {
    "filename": "SPARQL Generation an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph.pdf",
    "analysis": {
      "benchmarks": [
        "Bgee gene expression knowledge graph",
        "KQA Pro",
        "Wikidata"
      ],
      "models": [
        "OpenLLaMA",
        "OpenLLaMA_7b_v2",
        "OpenLLaMA+KQA_Pro"
      ]
    }
  },
  "Language-Conditioned Robotic Manipulation with Fast and Slow Thinking": {
    "filename": "Language-Conditioned Robotic Manipulation with Fast and Slow Thinking.pdf",
    "analysis": {
      "benchmarks": [
        "VIMA-Bench"
      ],
      "models": [
        "RFST",
        "Gato",
        "Flamingo",
        "VIMA",
        "Distil-RoBERTa",
        "Vision-Language Model (VLM)",
        "LLaMA-2-7B",
        "CLIP",
        "BLIP-2",
        "RT-2",
        "PaLI-X",
        "PaLM-E"
      ]
    }
  },
  "ComposerX Multi-Agent Symbolic Music Composition with LLMs": {
    "filename": "ComposerX Multi-Agent Symbolic Music Composition with LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Irishman",
        "KernScores"
      ],
      "models": [
        "ComposerX",
        "GPT-4-Turbo",
        "GPT-4-0314",
        "GPT-3.5-Turbo",
        "MuseCoco",
        "text2music",
        "Original GPT with Simple Role-play",
        "Role-Play with Additional Instruction",
        "Chain-of-Thought",
        "In Context Learning"
      ]
    }
  },
  "Verify-and-Edit A Knowledge-Enhanced Chain-of-Thought Framework": {
    "filename": "Verify-and-Edit A Knowledge-Enhanced Chain-of-Thought Framework.pdf",
    "analysis": {
      "benchmarks": [
        "Adversarial HotpotQA",
        "2WikiMultihop",
        "Fever"
      ],
      "models": [
        "Verify-and-Edit",
        "GPT-3",
        "CoT",
        "CoT-SC",
        "Calibrator",
        "ReAct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain-of-Thought Prompt Distillation for Multimodal Named Entity Recognition and Multimodal Relation Extraction": {
    "filename": "Chain-of-Thought Prompt Distillation for Multimodal Named Entity Recognition and Multimodal Relation Extraction.pdf",
    "analysis": {
      "benchmarks": [
        "Twitter2015",
        "Twitter2017",
        "SNAP",
        "WikiDiverse",
        "MNRE"
      ],
      "models": [
        "BERTCAT-MNER",
        "R-GCN",
        "FMIT",
        "XMLRITA",
        "promptMNER",
        "CAT-MNER",
        "MoRe",
        "ChatGPT",
        "GPT4",
        "our(ChatGPT-BERT)",
        "our(GPT4-BERT)",
        "our(ChatGPT-XMLR)",
        "our(GPT4-XMLR)"
      ]
    }
  },
  "Enhancing Text Annotation through Rationale-Driven Collaborative Few-Shot Prompting": {
    "filename": "Enhancing Text Annotation through Rationale-Driven Collaborative Few-Shot Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "SST-2",
        "SST-5",
        "AG News",
        "DBPedia"
      ],
      "models": [
        "Qwen-72B",
        "Qwen-14B",
        "Qwen-7B",
        "LLaMA3-70B",
        "LLaMA3-8B",
        "RDC (Ours)"
      ]
    }
  },
  "UVLLM An Automated Universal RTL Verification Framework using LLMs": {
    "filename": "UVLLM An Automated Universal RTL Verification Framework using LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "RTLLM dataset",
        "proposed benchmark"
      ],
      "models": [
        "UVLLM",
        "GPT-4-turbo",
        "MEIC",
        "Cirfix",
        "Strider",
        "RTLrepair"
      ]
    }
  },
  "Learning and Forgetting Unsafe Examples in Large Language Models": {
    "filename": "Learning and Forgetting Unsafe Examples in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BBQ",
        "Pile",
        "HarmfulQA",
        "SQuAD",
        "Alpaca"
      ],
      "models": [
        "ForgetFilter",
        "LLaMA-7B",
        "GPT2-XL",
        "GPT2-L",
        "GPT2-M",
        "BaseFT",
        "SafetyFT",
        "Replay",
        "Self-Correction"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Deciphering Human Mobility Inferring Semantics of Trajectories with Large Language Models": {
    "filename": "Deciphering Human Mobility Inferring Semantics of Trajectories with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Shenzhen individual trajectory dataset"
      ],
      "models": [
        "TSI-LLM",
        "multinomial logit regression model",
        "Bayesian rule-based approach",
        "enhanced hidden Markov network (HMN) model",
        "versatile white box approach",
        "LLM-Mob",
        "UrbanGPT",
        "MobiGeaR"
      ]
    }
  },
  "BRIGHT A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval": {
    "filename": "BRIGHT A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval.pdf",
    "analysis": {
      "benchmarks": [
        "BRIGHT",
        "BEIR",
        "MTEB",
        "MS MARCO",
        "Natural Questions",
        "TheoremQA",
        "AoPS",
        "GSM8K",
        "MATH",
        "HumanEval",
        "MBPP",
        "LiveCodeBench"
      ],
      "models": [
        "SFR-Embedding-Mistral",
        "Qwen",
        "BM25",
        "BGE",
        "Inst-L",
        "SBERT",
        "E5",
        "Inst-XL",
        "GritLM",
        "Cohere",
        "OpenAI",
        "Voyage",
        "Google",
        "MiniLM",
        "Gemini",
        "GPT-4",
        "Llama-3-70B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment": {
    "filename": "Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "WoW",
        "CMU_DoG"
      ],
      "models": [
        "K-D IAL",
        "RLFC",
        "GPT2-M",
        "GPT2-L",
        "GPT2-XL",
        "K-Adapter",
        "K-Former",
        "Neural Knowledge Bank (NKB)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models can Achieve Social Balance": {
    "filename": "Large Language Models can Achieve Social Balance.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "llama-3-70B-instruct",
        "llama-3-8B-instruct",
        "mistral-7B-Instruct-v0.2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Step-Controlled DPO Leveraging Stepwise Error for Enhanced Mathematical Reasoning": {
    "filename": "Step-Controlled DPO Leveraging Stepwise Error for Enhanced Mathematical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "APE210K",
        "CMATH",
        "MGSM-zh"
      ],
      "models": [
        "Step-Controlled DPO (SCDPO)",
        "Direct Preference Optimization (DPO)",
        "InternLM2-20B",
        "Mistral-7B-Ours",
        "MetaMath-Mistral-7B",
        "MathCoder-Mistral-7B",
        "GPT-3.5",
        "GPT-4",
        "GPT-4 Code Interpreter",
        "GLM-4",
        "Baichuan-3",
        "Math-Shepherd",
        "SeaLLM-v2",
        "DeepSeekMath-RL",
        "Skywork-13B-Math",
        "InternLM2-Math",
        "MathGenie",
        "ChatGLM3-32B-RFT-DPO",
        "Yi-Chat",
        "ToRA",
        "MAmmoTH",
        "MathCoder",
        "WizardMath-v1.0",
        "Qwen"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Can Recommender Systems Benefit from Large Language Models A Survey": {
    "filename": "How Can Recommender Systems Benefit from Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Joint Estimation and Prediction of City-wide Delivery Demand A Large Language Model Empowered Graph-based Learning Approach": {
    "filename": "Joint Estimation and Prediction of City-wide Delivery Demand A Large Language Model Empowered Graph-based Learning Approach.pdf",
    "analysis": {
      "benchmarks": [
        "real-world delivery datasets in China and the US"
      ],
      "models": [
        "individual-collective message-passing neural network",
        "LLM-enhanced spatiotemporal graph forecasting architecture",
        "Inductive Message-Passing Neural Network with Encoding from LLMs (IMPEL)",
        "spatiotemporal graph neural network (STGNN)",
        "spatiotemporal message passing neural network (STMPNN)",
        "collective-individual hybrid model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing In-context Learning via Linear Probe Calibration": {
    "filename": "Enhancing In-context Learning via Linear Probe Calibration.pdf",
    "analysis": {
      "benchmarks": [
        "SST-2",
        "SST-5",
        "AGNews",
        "TREC",
        "DBPedia",
        "RTE",
        "Subj",
        "Hamster",
        "Customers",
        "Breast",
        "Spambase",
        "TAE",
        "Vehicle",
        "LED"
      ],
      "models": [
        "GPT-2-XL",
        "GPT-J",
        "Llama-2",
        "LinC",
        "NoC",
        "ConC",
        "SPT",
        "LoRA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding LLMs Requires More Than Statistical Generalization": {
    "filename": "Understanding LLMs Requires More Than Statistical Generalization.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Transformer",
        "decoder-only Transformer",
        "AR probabilistic models",
        "LLMs",
        "autoregressive language models",
        "AR language model",
        "AR LLMs"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course": {
    "filename": "Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course.pdf",
    "analysis": {
      "benchmarks": [
        "BLEU-4",
        "ROUGE",
        "BERTScore",
        "METEOR"
      ],
      "models": [
        "GPT-3.5",
        "LLaMA-2",
        "LLaMA-2-ft",
        "GPT-3.5 (System Message)",
        "GPT-3.5 (RAG + System Message)",
        "LLaMA-2 (RAG + System Message)",
        "LLaMA-2-ft (Filter)",
        "LLaMA-2-ft (RAG + System Message)",
        "LLaMA-2-ft (RAG + System Message + Filter)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Successive Prompting for Decomposing Complex Questions": {
    "filename": "Successive Prompting for Decomposing Complex Questions.pdf",
    "analysis": {
      "benchmarks": [
        "DROP",
        "HotpotQA"
      ],
      "models": [
        "Successive Prompting",
        "Chain-of-Thought (CoT)",
        "TASE",
        "UnifiedQA",
        "PReasM",
        "GPT-J",
        "T5",
        "Text Modular Networks (TMNs)",
        "MRKL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey of NL2SQL with Large Language Models Where are we and where are we going": {
    "filename": "A Survey of NL2SQL with Large Language Models Where are we and where are we going.pdf",
    "analysis": {
      "benchmarks": [
        "Spider",
        "BIRD",
        "BULL"
      ],
      "models": [
        "GPT-4",
        "StarCoder",
        "DAIL-SQL",
        "CodeS",
        "CHESS",
        "FinSQL",
        "DTS-SQL",
        "TA-SQL",
        "SuperSQL",
        "ZeroNL2SQL",
        "PET-SQL",
        "CoE-SQL",
        "PURPLE",
        "MetaSQL",
        "DEA-SQL",
        "DIN-SQL",
        "C3-SQL",
        "RESDSQL",
        "T5-3B+NatSQL+Token Preprocessing",
        "ACT-SQL",
        "ODIS",
        "MAC-SQL",
        "SC-Prompt",
        "CatSQL",
        "SQLFormer",
        "G\u00b3R",
        "Graphix-T5",
        "SHiP",
        "N-best List Rerankers",
        "RASAT",
        "PICARD",
        "TKK",
        "S\u00b2SQL",
        "RAT-SQL",
        "SmBoP",
        "RaSaP",
        "BRIDGE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey of Large Language Models in Cybersecurity": {
    "filename": "A Survey of Large Language Models in Cybersecurity.pdf",
    "analysis": {
      "benchmarks": [
        "Capture-The-Flag Challenges",
        "Cisco certifications",
        "CTF challenges"
      ],
      "models": [
        "GPT-3.5",
        "PaLM 2",
        "Prometheus",
        "ChatGPT-3.5-turbo",
        "LaMDA",
        "GPT-4",
        "code-cushman-001",
        "code-davinci-001",
        "code-davinci-002",
        "j1-jumbo",
        "j1-large",
        "polycoder",
        "gpt2-csrc",
        "RoBERTa",
        "SecureBERT",
        "FalconLLM",
        "BERT",
        "DistilBERT",
        "CodeBERT",
        "MegatronBERT",
        "MegatronGPT-2",
        "GPT-J",
        "CodeT5",
        "PentestGPT",
        "PentestGPT-GPT4"
      ]
    }
  },
  "Suspicion-Agent Playing Imperfect Information Games with Theory of Mind Aware GPT-4": {
    "filename": "Suspicion-Agent Playing Imperfect Information Games with Theory of Mind Aware GPT-4.pdf",
    "analysis": {
      "benchmarks": [
        "Leduc Hold'em",
        "Coup",
        "Texas Hold'em Limit"
      ],
      "models": [
        "Suspicion-Agent",
        "CFR+",
        "NFSP",
        "DMC",
        "DQN",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMs as Potential Brainstorming Partners for Math and Science Problems": {
    "filename": "LLMs as Potential Brainstorming Partners for Math and Science Problems.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Combining Ontological Knowledge and Large Language Model for User-Friendly Service Robots": {
    "filename": "Combining Ontological Knowledge and Large Language Model for User-Friendly Service Robots.pdf",
    "analysis": {
      "benchmarks": [
        "Gazebo simulator",
        "YCB object set"
      ],
      "models": [
        "Llama2-13b-chat",
        "YOLOv7",
        "OKB",
        "OKB+LLM",
        "OKB+LLM+MEM"
      ]
    }
  },
  "Dynamic Universal Approximation Theory The Basic Theory for Transformer-based Large Language Models": {
    "filename": "Dynamic Universal Approximation Theory The Basic Theory for Transformer-based Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "Llama",
        "PaLM",
        "GPT-3",
        "DUAT",
        "LoRA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CursorCore Assist Programming through Aligning Anything": {
    "filename": "CursorCore Assist Programming through Aligning Anything.pdf",
    "analysis": {
      "benchmarks": [
        "APEval"
      ],
      "models": [
        "CursorCore",
        "CursorCore-DS",
        "CursorCore-Yi",
        "CursorCore-QW2.5",
        "Deepseek-Coder",
        "Yi-Coder",
        "Qwen2.5-Coder",
        "GPT-4o",
        "GPT-4o-Mini",
        "Codestral-V0.1-22B",
        "DS-Coder-33B-Base",
        "DS-Coder-33B-Inst",
        "Qwen2.5-72B",
        "Qwen2.5-72B-Inst",
        "Mistral-Large-123B-Inst",
        "DS-Coder-V2-236B-Base",
        "DS-Coder-V2-236B-Inst",
        "Llama-3.1-8B",
        "Llama-3.1-8B-Inst",
        "Gemma-2-9B",
        "Gemma-2-9B-It",
        "Codegeex4-All-9B",
        "DS-Coder-6.7B-Base",
        "DS-Coder-6.7B-Inst",
        "Yi-Coder-9B",
        "Yi-Coder-9B-Chat",
        "Qwen2.5-Coder-7B",
        "Qwen2.5-Coder-7B-Inst",
        "CursorCore-DS-6.7B",
        "CursorCore-Yi-9B",
        "CursorCore-QW2.5-7B",
        "Llama-3.2-1B",
        "Llama-3.2-1B-Instruct",
        "Llama-3.2-3B",
        "Llama-3.2-3B-Instruct",
        "Gemma-2-2B",
        "Gemma-2-2B-It",
        "Phi-3.5-3.8B-Inst",
        "DS-Coder-1.3B-Base",
        "DS-Coder-1.3B-Inst",
        "Yi-Coder-1.5B",
        "Yi-Coder-1.5B-Chat",
        "Qwen2.5-Coder-1.5B",
        "Qwen2.5-Coder-1.5B-Inst",
        "CursorCore-DS-1.3B",
        "CursorCore-Yi-1.5B",
        "CursorCore-QW2.5-1.5B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Engineer Too Many Simple Features For Tabular Data": {
    "filename": "Large Language Models Engineer Too Many Simple Features For Tabular Data.pdf",
    "analysis": {
      "benchmarks": [
        "ada",
        "adult",
        "amazon_employee_access",
        "australian",
        "bank-marketing",
        "blood-transfusion-service-center",
        "car",
        "churn",
        "click_prediction_small",
        "cmc",
        "connect-4",
        "credit-g",
        "eucalyptus",
        "first-order-theorem-proving",
        "gesturephasesegmentationprocessed",
        "jannis",
        "jungle_chess_2pcs_raw_endgame_complete",
        "kc1",
        "kick",
        "kr-vs-kp",
        "numerai28.6",
        "okcupid-stem",
        "ozone-level.8hr",
        "pc4",
        "phishingwebsites",
        "phoneme",
        "qsar-biodeg"
      ],
      "models": [
        "GPT-4o-mini",
        "Gemini-1.5-flash",
        "Llama3.1-8B",
        "Mistral7B-v0.3",
        "OpenFE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Marco-o1 Towards Open Reasoning Models for Open-Ended Solutions": {
    "filename": "Marco-o1 Towards Open Reasoning Models for Open-Ended Solutions.pdf",
    "analysis": {
      "benchmarks": [
        "MGSM (English)",
        "MGSM (Chinese)"
      ],
      "models": [
        "Marco-o1",
        "Qwen2-7B-Instruct",
        "Marco-o1-CoT",
        "Marco-o1-MCTS (step)",
        "Marco-o1-MCTS (mini-step of 64 tokens)",
        "Marco-o1-MCTS (mini-step of 32 tokens)"
      ]
    }
  },
  "Benchmarking Large Language Model Capabilities for Conditional Generation": {
    "filename": "Benchmarking Large Language Model Capabilities for Conditional Generation.pdf",
    "analysis": {
      "benchmarks": [
        "E2E",
        "WebNLG",
        "ToTTo",
        "Czech Restaurant",
        "XSum",
        "WikiLingua",
        "MLSum",
        "XL-Sum"
      ],
      "models": [
        "T5",
        "BART",
        "mT5",
        "GPT-3",
        "GLaM",
        "Gopher",
        "LaMDA",
        "PaLM",
        "GPT-3.5",
        "ST-MoE",
        "LongT5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Foundation Model Sherpas Guiding Foundation Models through Knowledge and Reasoning": {
    "filename": "Foundation Model Sherpas Guiding Foundation Models through Knowledge and Reasoning.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "flan-T5",
        "ChatGPT",
        "RLHF",
        "RLAIF",
        "K-ADAPTER",
        "MixDA",
        "RAG",
        "IRCoT",
        "ReAct",
        "LLM Augmenter",
        "ChemCrow",
        "BINDER",
        "ToT",
        "GoT",
        "ADaPT",
        "RAP",
        "Reflexion",
        "LM Cascade",
        "CONCORD",
        "PLoT",
        "LARK",
        "CoK"
      ]
    }
  },
  "InfeRE Step-by-Step Regex Generation via Chain of Inference": {
    "filename": "InfeRE Step-by-Step Regex Generation via Chain of Inference.pdf",
    "analysis": {
      "benchmarks": [
        "NL-RX-Turk",
        "KB13"
      ],
      "models": [
        "InfeRE",
        "TRANX",
        "Deep-Regex",
        "SemRegex",
        "SoftRegex",
        "S2RE",
        "S2RE-T5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations": {
    "filename": "Structured Chain-of-Thought Prompting for Few-Shot Generation of Content-Grounded QA Conversations.pdf",
    "analysis": {
      "benchmarks": [
        "DoQA",
        "QuAC"
      ],
      "models": [
        "SCoT",
        "FALCON-40B",
        "FLAN-UL2-20B",
        "MIXTRAL-8X7B-INSTRUCT-V0.1",
        "LLAMA-2-13B-CHAT",
        "FALCON-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DrICL Demonstration-Retrieved In-context Learning": {
    "filename": "DrICL Demonstration-Retrieved In-context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "NQ",
        "ANLI-r3",
        "GSM8k",
        "AQuA",
        "StrategyQA"
      ],
      "models": [
        "PaLM",
        "Flan-PaLM",
        "BM25",
        "GTR",
        "Demo-GTR"
      ]
    }
  },
  "Fine-tune Language Models to Approximate Unbiased In-context Learning": {
    "filename": "Fine-tune Language Models to Approximate Unbiased In-context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "numerical dataset"
      ],
      "models": [
        "RICL",
        "LARICL",
        "GPT-2",
        "ICL",
        "fine-tuning method",
        "prefix-tuning method"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Human-Computer Collaborative Tool for Training a Single Large Language Model Agent into a Network through Few Examples": {
    "filename": "A Human-Computer Collaborative Tool for Training a Single Large Language Model Agent into a Network through Few Examples.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "EasyLAN",
        "LLM agent network",
        "Literal Translator",
        "Rhyming Polisher",
        "Structure Refiner",
        "Spoken Text Translator",
        "Literary Text Translator"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ModelGPT Unleashing LLMs Capabilities for Tailored Model Generation": {
    "filename": "ModelGPT Unleashing LLMs Capabilities for Tailored Model Generation.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE Benchmark",
        "Iris",
        "Heart Disease",
        "Wine",
        "Adult",
        "Breast Cancer",
        "Car Evaluation",
        "Wine Quality",
        "Dry Bean",
        "Rice",
        "Bank Marketing",
        "Office-31"
      ],
      "models": [
        "ModelGPT",
        "Distil-BERT",
        "MLP",
        "ResNet-50",
        "LoRA",
        "Finetune",
        "ModelGPT-F"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMs Killed the Script Kiddie How Agents Supported by Large Language Models Change the Landscape of Network Threat Testing": {
    "filename": "LLMs Killed the Script Kiddie How Agents Supported by Large Language Models Change the Landscape of Network Threat Testing.pdf",
    "analysis": {
      "benchmarks": [
        "Metasploitable 2"
      ],
      "models": [
        "ChatGPT",
        "GPT-3.5-Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Let Models Speak Ciphers Multiagent Debate through Embeddings": {
    "filename": "Let Models Speak Ciphers Multiagent Debate through Embeddings.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "Arithmetic",
        "MMLU Formal Logic",
        "MMLU High School Math",
        "MMLU Professional Psychology"
      ],
      "models": [
        "CIPHER",
        "LLaMA2-70B",
        "LLaMA-65B",
        "Falcon-40B-Instruct",
        "MPT-30B",
        "WizardMath-70B-V1.0",
        "Single Answer",
        "Self-Consistency",
        "Natural Language Debate (NLD)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "T2I-CompBench A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation": {
    "filename": "T2I-CompBench A Comprehensive Benchmark for Open-world Compositional Text-to-image Generation.pdf",
    "analysis": {
      "benchmarks": [
        "T2I-CompBench",
        "CC-500",
        "ABC-6K",
        "Attn-Exct",
        "HRS-comp",
        "CUB birds",
        "Oxford flowers",
        "COCO",
        "DrawBench",
        "DALL-EVAL",
        "HE-T2I",
        "HRS-Bench"
      ],
      "models": [
        "Stable Diffusion v1-4",
        "Stable Diffusion v2",
        "Composable Diffusion",
        "Structured Diffusion",
        "Attend-and-Excite",
        "GORS",
        "GORS-unbiased"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Public Large Language Models to Synthesize Data for Private On-device Applications": {
    "filename": "Prompt Public Large Language Models to Synthesize Data for Private On-device Applications.pdf",
    "analysis": {
      "benchmarks": [
        "Gboard",
        "C4"
      ],
      "models": [
        "baseline model",
        "LLM",
        "on-device LM",
        "LLM-filter-C4-136G",
        "LLM-syn-chat-29G",
        "LLM-mix-166G",
        "LLM-prox-32G"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RAFT Reward rAnked FineTuning for Generative Foundation Model Alignment": {
    "filename": "RAFT Reward rAnked FineTuning for Generative Foundation Model Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "HH-RLHF",
        "CIFAR-10",
        "CIFAR-100"
      ],
      "models": [
        "RAFT",
        "LLaMA-7B",
        "LLaMA-7B-SFT",
        "PPO",
        "GPT-Neo-2.7B",
        "Stable-diffusion v1.5",
        "DDPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-Assisted Visual Analytics Opportunities and Challenges": {
    "filename": "LLM-Assisted Visual Analytics Opportunities and Challenges.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "NL2Rigel",
        "Data-Copilot",
        "Chat2Vis",
        "ChartGPT",
        "LIDA",
        "InkSight",
        "DATATALES",
        "ChatGPT",
        "Codex"
      ]
    }
  },
  "ChatSchema A pipeline of extracting structured information with Large Multimodal Models based on schema": {
    "filename": "ChatSchema A pipeline of extracting structured information with Large Multimodal Models based on schema.pdf",
    "analysis": {
      "benchmarks": [
        "Peking University First Hospital medical reports"
      ],
      "models": [
        "ChatSchema",
        "GPT-4o",
        "Gemini 1.5 Pro",
        "Baseline"
      ]
    }
  },
  "SDS - See it Do it Sorted Quadruped Skill Synthesis from Single Video Demonstration": {
    "filename": "SDS - See it Do it Sorted Quadruped Skill Synthesis from Single Video Demonstration.pdf",
    "analysis": {
      "benchmarks": [
        "Unitree Go1 robot"
      ],
      "models": [
        "SDS",
        "PPO",
        "GPT-4V(ision)",
        "Eureka",
        "RoboCLIP",
        "SLoMo"
      ]
    }
  },
  "MaxMind A Memory Loop Network to Enhance Software Productivity based on Large Language Models": {
    "filename": "MaxMind A Memory Loop Network to Enhance Software Productivity based on Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SheetCopilot test suite (221 tasks)"
      ],
      "models": [
        "MaxMind",
        "MaxMind4Sheet",
        "SheetCopilot",
        "llama3.1-70B",
        "llama3-70B",
        "llama3-405B",
        "GPT4o"
      ]
    }
  },
  "MedG-KRP Medical Graph Knowledge Representation Probing": {
    "filename": "MedG-KRP Medical Graph Knowledge Representation Probing.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "MultiMedQA",
        "BIOS"
      ],
      "models": [
        "GPT-4",
        "Llama3-70b",
        "PalmyraMed-70b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Three-Phases SFT Hybrid Model Integrated Strong Prior Module and Data Overlap Estimation in the Eduation Context": {
    "filename": "A Three-Phases SFT Hybrid Model Integrated Strong Prior Module and Data Overlap Estimation in the Eduation Context.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MMLU",
        "C-Eval",
        "AGIEval"
      ],
      "models": [
        "Three-Phases SFT Hybrid Model",
        "LLAMA2-34B",
        "StarCoder-15B",
        "OctoCoder",
        "GPT-3.5",
        "CodeLlama-34B",
        "PanGu-Coder2-15B",
        "GPT-4",
        "WizardCoder-Python-34B",
        "CodeFuse-CodeLlama-34B",
        "C-Alpaca-13B",
        "ChatGLM2-6B",
        "Vicuna-13B",
        "LLaMA2-13B",
        "Claude-2",
        "GPT-3.5 Turbo",
        "Educhat-13B",
        "IBL-Tutoring-7B",
        "SparkDesk-3.0",
        "ERNIE-4.0 Bot",
        "LaMDA",
        "Gopher",
        "OPT-IML"
      ]
    }
  },
  "The Capacity for Moral Self-Correction in Large Language Models": {
    "filename": "The Capacity for Moral Self-Correction in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BBQ",
        "Winogender",
        "Discrimination in Law Student Course Admission"
      ],
      "models": [
        "22B parameter model",
        "175B parameter model",
        "Q",
        "Q+IF",
        "Q+IF+CoT",
        "Q+Match Stats"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LiveBench A Challenging Contamination-Free LLM Benchmark": {
    "filename": "LiveBench A Challenging Contamination-Free LLM Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "LiveBench",
        "Big-Bench Hard",
        "AMPS",
        "IFEval",
        "AMC12",
        "AIME",
        "USAMO",
        "IMO",
        "SMC",
        "Leetcode",
        "AtCoder",
        "LiveCodeBench",
        "Kaggle",
        "Socrata"
      ],
      "models": [
        "zephyr-7b-alpha",
        "phi-3-mini-4k-instruct",
        "mistral-7b-instruct-v0.2",
        "mixtral-8x7b-instruct-v0.1",
        "openhermes-2.5-mistral-7b",
        "phi-3-small-8k-instruct",
        "qwen2-7b-instruct",
        "meta-llama-3-8b-instruct",
        "phi-3-small-128k-instruct",
        "command-r",
        "qwen1.5-72b-chat",
        "qwen1.5-110b-chat",
        "deepseek-coder-v2-lite-instruct",
        "phi-3-medium-128k-instruct",
        "phi-3-medium-4k-instruct",
        "mistral-small-2402",
        "command-r-plus",
        "gpt-3.5-turbo-1106",
        "gpt-3.5-turbo-0125",
        "mixtral-8x22b-instruct-v0.1",
        "claude-3-haiku-20240307",
        "meta-llama-3-70b-instruct",
        "claude-3-sonnet-20240229",
        "deepseek-chat-v2",
        "mistral-large-2402",
        "qwen2-72b-instruct",
        "gemini-1.5-flash-api-0514",
        "gemini-1.5-pro-api-0514",
        "deepseek-coder-v2",
        "gpt-4-0125-preview",
        "claude-3-opus-20240229",
        "gpt-4-1106-preview",
        "gpt-4-turbo-2024-04-09",
        "gpt-4o-2024-05-13",
        "claude-3-5-sonnet-20240620",
        "command-r-plus",
        "qwen1.5-72b-chat",
        "command-r",
        "meta-llama-3-8b-instruct",
        "mistral-7b-instruct-v0.2",
        "starling-lm-7b-beta",
        "gpt-4-turbo-2024-04-09",
        "claude-3-opus-20240229",
        "gpt-4-0125-preview",
        "mistral-large-2402",
        "claude-3-sonnet-20240229",
        "meta-llama-3-70b-instruct",
        "claude-3-haiku-20240307",
        "mixtral-8x22b-instruct-v0.1",
        "gpt-3.5-turbo-0125",
        "gpt-3.5-turbo-1106",
        "command-r-plus",
        "qwen1.5-72b-chat",
        "command-r",
        "meta-llama-3-8b-instruct",
        "mistral-7b-instruct-v0.2",
        "starling-lm-7b-beta"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GraphAgent Agentic Graph Language Assistant": {
    "filename": "GraphAgent Agentic Graph Language Assistant.pdf",
    "analysis": {
      "benchmarks": [
        "IMDB",
        "ACM",
        "Arxiv-Papers",
        "ICLR-Peer Reviews",
        "GovReport"
      ],
      "models": [
        "GraphAgent",
        "GraphGPT",
        "LLaGA",
        "HiGPT",
        "SAGE",
        "GAT",
        "HAN",
        "HGT",
        "HetGNN",
        "Llama3-8b",
        "Mistral-Nemo",
        "Llama3-70b",
        "Qwen2-72b",
        "Deepseek-Chat-V2",
        "GPT4o-mini",
        "Gemini-1.5-Flash",
        "GraphRAG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Bias to Balance Detecting Facial Expression Recognition Biases in Large Multimodal Foundation Models": {
    "filename": "From Bias to Balance Detecting Facial Expression Recognition Biases in Large Multimodal Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "RADIATE",
        "Tarr",
        "Chicago Face"
      ],
      "models": [
        "GPT-4o",
        "PaliGemma",
        "Gemini",
        "CLIP",
        "Linear Classifier on CLIP Embeddings",
        "Gemini 1.5 Flash",
        "Gemini 1.5 Pro",
        "PaliGemma pt-224",
        "PaliGemma mix-224",
        "PaliGemma pt-448"
      ]
    }
  },
  "Diffusion-ES Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following": {
    "filename": "Diffusion-ES Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following.pdf",
    "analysis": {
      "benchmarks": [
        "nuPlan"
      ],
      "models": [
        "Diffusion-ES",
        "PDM-Closed",
        "UrbanDriverOL",
        "PlanCNN",
        "IDM",
        "Diffusion Policy",
        "Conditional Diffusion-ES",
        "CEM",
        "MPPI",
        "Reward-gradient guidance"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Crystal Introspective Reasoners Reinforced with Self-Feedback": {
    "filename": "Crystal Introspective Reasoners Reinforced with Self-Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "OpenBookQA",
        "ARC_easy",
        "ARC_hard",
        "AI2Science_elementary",
        "AI2Science_middle",
        "CommonsenseQA",
        "QASC",
        "PhysicalIQA",
        "SocialIQA",
        "Winogrande",
        "Com2Sense",
        "SciQ",
        "QuaRel",
        "QuaRTz",
        "CycIC",
        "ComVE",
        "Winograd Schema Challenge",
        "COPA",
        "NumerSense",
        "PROST",
        "SWAG",
        "HellaSwag",
        "CODAH",
        "Story Cloze Test",
        "\u03b1NLI"
      ],
      "models": [
        "CRYSTAL",
        "Direct QA",
        "Rainier",
        "UnifiedQA",
        "Fine-tune-CoT",
        "SCoTD",
        "SCOTT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering": {
    "filename": "Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "WebQuestionsSP",
        "Mintaka"
      ],
      "models": [
        "KAPING",
        "T5 (0.8B)",
        "T5 (3B)",
        "T5 (11B)",
        "T0 (3B)",
        "T0 (11B)",
        "OPT (2.7B)",
        "OPT (6.7B)",
        "GPT-3 (6.7B)",
        "GPT-3 (175B)",
        "AlexaTM (20B)",
        "No Knowledge",
        "Random Knowledge",
        "Popular Knowledge",
        "Generated Knowledge"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Images to Textual Prompts Zero-shot Visual Question Answering with Frozen Large Language Models": {
    "filename": "From Images to Textual Prompts Zero-shot Visual Question Answering with Frozen Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "VQAv2",
        "OK-VQA",
        "A-OKVQA"
      ],
      "models": [
        "Img2LLM",
        "Flamingo",
        "PICa",
        "OPT",
        "BLIP",
        "Frozen",
        "VL-T5",
        "FewVLM",
        "VLKD",
        "WeaQA",
        "VQ2A",
        "ClipCap",
        "GPT-Neo",
        "BLOOM",
        "GPT-J"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Personalized Autonomous Driving with Large Language Models Field Experiments": {
    "filename": "Personalized Autonomous Driving with Large Language Models Field Experiments.pdf",
    "analysis": {
      "benchmarks": [
        "LaMPilot"
      ],
      "models": [
        "Talk2Drive",
        "GPT-Driver",
        "DiLu",
        "GPT-4"
      ]
    }
  },
  "Extracting Heuristics from Large Language Models for Reward Shaping in Reinforcement Learning": {
    "filename": "Extracting Heuristics from Large Language Models for Reward Shaping in Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "BabyAI environment suite",
        "Household",
        "Mario",
        "Minecraft"
      ],
      "models": [
        "PPO",
        "A2C",
        "Q-learning",
        "LLM",
        "LLM+verifier"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference": {
    "filename": "Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference.pdf",
    "analysis": {
      "benchmarks": [
        "aNLI",
        "HellaSwag",
        "PIQA",
        "SocialIQA"
      ],
      "models": [
        "RoBERTa-large Ensemble",
        "ChatGPT",
        "DwD",
        "ConfStd",
        "Calibrator"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Verbalized Machine Learning Revisiting Machine Learning with Language Models": {
    "filename": "Verbalized Machine Learning Revisiting Machine Learning with Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "VML",
        "LLM-parameterized learner",
        "LLM-parameterized optimizer",
        "Llama-3",
        "ChatGPT",
        "GPT-4o",
        "neural network"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Intern VL Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks": {
    "filename": "Intern VL Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "ADE20K",
        "Kinetics-400",
        "Kinetics-600",
        "Kinetics-700",
        "Flickr30K",
        "COCO",
        "MSR-VTT",
        "NoCaps",
        "MME",
        "POPE",
        "Tiny LVLM",
        "ImageNet-1K",
        "ImageNet-ReaL",
        "ImageNet-V2",
        "ImageNet-A",
        "ImageNet-R",
        "ImageNet-Sketch",
        "ObjectNet",
        "Flickr30K-CN",
        "COCO-CN",
        "XTD"
      ],
      "models": [
        "InternVL",
        "InternViT-6B",
        "QLLaMA",
        "Vicuna",
        "InternLM",
        "ViT-22B",
        "OpenCLIP-H",
        "OpenCLIP-G",
        "DINOv2-g",
        "EVA-01-CLIP-g",
        "MAWS-ViT-6.5B",
        "ViT-6.5B",
        "ViT-G",
        "ViT-e",
        "EVA-02-ViT-E",
        "EVA-02-CLIP-E+",
        "CoCa",
        "LiT-22B",
        "M-CLIP",
        "CLIP-Italian",
        "Japanese-CLIP-ViT-B",
        "Taiyi-CLIP-ViT-H",
        "WuKong-ViT-L-G",
        "CN-CLIP-ViT-H",
        "AltCLIP-ViT-L",
        "OpenCLIP-XLM-R-B",
        "OpenCLIP-XLM-R-H",
        "Florence",
        "ONE-PEACE",
        "BLIP-2",
        "ViCLIP",
        "InstructBLIP",
        "Shikra",
        "IDEFICS-80B",
        "Qwen-VL",
        "Qwen-VL-Chat",
        "LLaVA-1.5",
        "Emu",
        "Emu-I",
        "DreamLLM",
        "Flamingo-9B",
        "Flamingo-80B",
        "KOSMOS-2",
        "PaLI-X-55B",
        "ASM",
        "InternVL-C",
        "InternVL-G",
        "InternVL-Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Minimalist Dataset for Systematic Generalization of Perception Syntax and Semantics": {
    "filename": "A Minimalist Dataset for Systematic Generalization of Perception Syntax and Semantics.pdf",
    "analysis": {
      "benchmarks": [
        "HINT",
        "SCAN"
      ],
      "models": [
        "RNN",
        "LSTM",
        "GRU",
        "Transformer",
        "Universal Transformer",
        "GPT-3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Secrets of RLHF in Large Language Models Part I PPO": {
    "filename": "Secrets of RLHF in Large Language Models Part I PPO.pdf",
    "analysis": {
      "benchmarks": [
        "HH-RLHF dataset"
      ],
      "models": [
        "PPO",
        "PPO-max",
        "SFT models",
        "ChatGPT",
        "LLaMA-7B",
        "OpenChineseLLaMA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models": {
    "filename": "Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HuggingFace Open LLM Leaderboard",
        "MT-Bench",
        "Big-Bench",
        "GSM8k",
        "TruthfulQA",
        "Arc",
        "HellaSwag",
        "Winogrande",
        "MMLU"
      ],
      "models": [
        "SPIN",
        "zephyr-7b-sft-full",
        "Mistral-7B",
        "zephyr-7b-beta"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoGuide Automated Generation and Selection of Context-Aware Guidelines for Large Language Model Agents": {
    "filename": "AutoGuide Automated Generation and Selection of Context-Aware Guidelines for Large Language Model Agents.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld",
        "WebShop",
        "WebArena",
        "GitHub",
        "Google Flights",
        "Coursera"
      ],
      "models": [
        "AUTOGUIDE",
        "ReAct",
        "ExpeL",
        "Reflexion",
        "SoM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Give us the Facts Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling": {
    "filename": "Give us the Facts Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling.pdf",
    "analysis": {
      "benchmarks": [
        "entity typing",
        "relation classification",
        "question answering",
        "NER datasets"
      ],
      "models": [
        "ChatGPT",
        "BERT",
        "GPT-3.5",
        "K-BERT",
        "CoLAKE",
        "LUKE",
        "KEPLER",
        "ERNIE",
        "CokeBERT",
        "K-Adapter",
        "ERICA",
        "KP-PLM",
        "ERNIE 3.0",
        "BERT-MK",
        "JointLK",
        "KET",
        "QA-GNN",
        "GreaseLM",
        "KLMo",
        "KnowBERT",
        "JAKET",
        "KGBART",
        "OM-ADAPT",
        "DAKI-ALBERT",
        "CKGA",
        "SenseBERT",
        "SentiLARE",
        "DRAGON",
        "LRLM",
        "KALA",
        "KeBioSum",
        "KagNet",
        "BioKGLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Thinking Like an Expert Multimodal Hypergraph-of-Thought HoT Reasoning to boost Foundation Modals": {
    "filename": "Thinking Like an Expert Multimodal Hypergraph-of-Thought HoT Reasoning to boost Foundation Modals.pdf",
    "analysis": {
      "benchmarks": [
        "ScienceQA"
      ],
      "models": [
        "HoT-based T5",
        "CoT-based GPT3.5",
        "ChatGPT",
        "GPT4",
        "UnifiedQA Base",
        "GPT-3.5",
        "MCAN",
        "Top-Down",
        "BAN",
        "DFAF",
        "ViLT",
        "Patch-TRM",
        "VisualBERT",
        "HoT-T5 Base",
        "HoT-T5 Large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BLINK Multimodal Large Language Models Can See but Not Perceive": {
    "filename": "BLINK Multimodal Large Language Models Can See but Not Perceive.pdf",
    "analysis": {
      "benchmarks": [
        "Blink",
        "MMBench",
        "MMMU"
      ],
      "models": [
        "GPT-4V",
        "Gemini",
        "LLaVA",
        "MiniGPT-4-v2",
        "OpenFlamingo-v2",
        "InstructBLIP-7B",
        "InstructBLIP-13B",
        "LLaVA-internLM2-7B",
        "Yi-VL-6B2",
        "Yi-VL-34B2",
        "LLaVA-v1.5-7B-xtuner",
        "LLaVA-v1.5-13B-xtuner",
        "CogVLM",
        "LLaVA-v1.5-7B",
        "LLaVA-v1.5-13B",
        "LLaVA-v1.6-34B",
        "Qwen-VL-Max",
        "Gemini Pro",
        "Claude 3 OPUS",
        "GPT-4 Turbo",
        "GPT-4o",
        "DIFT",
        "DepthAnything",
        "LoFTR",
        "DIRE",
        "Ordinal Shading"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Negative Object Presence Evaluation NOPE to Measure Object Hallucination in Vision-Language Models": {
    "filename": "Negative Object Presence Evaluation NOPE to Measure Object Hallucination in Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "NOPE",
        "VQAv2.0",
        "VQAv1.0",
        "Visual Genome",
        "Visual7W",
        "AdVQA",
        "Vizwiz",
        "TextVQA",
        "R-VQA",
        "VQA-Rephrasings",
        "TDIUC"
      ],
      "models": [
        "OFA",
        "BLIP",
        "BLIP CapFilt-L",
        "ALBEF",
        "GITLARGE",
        "InstructBLIP",
        "PromptCap BASE",
        "PromptCap",
        "BLIP-2",
        "OpenFlamingo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ADAM An Embodied Causal Agent in Open-World Environments": {
    "filename": "ADAM An Embodied Causal Agent in Open-World Environments.pdf",
    "analysis": {
      "benchmarks": [
        "Minecraft"
      ],
      "models": [
        "Adam",
        "CDHRL",
        "ReAct",
        "Re\ufb02exion",
        "AutoGPT",
        "VOYAGER",
        "VOYAGER-Guided",
        "EmptyGraph"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Methods to Estimate Large Language Model Confidence": {
    "filename": "Methods to Estimate Large Language Model Confidence.pdf",
    "analysis": {
      "benchmarks": [
        "New England Journal of Medicine (NEJM) Case Records series"
      ],
      "models": [
        "GPT-4"
      ]
    }
  },
  "Solving and Generating NPR Sunday Puzzles with Large Language Models": {
    "filename": "Solving and Generating NPR Sunday Puzzles with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "PUZZLEQA"
      ],
      "models": [
        "GPT-3",
        "GPT-3.5",
        "GPT-J",
        "LLaMA"
      ]
    }
  },
  "An X-Ray Is Worth 15 Features Sparse Autoencoders for Interpretable Radiology Report Generation": {
    "filename": "An X-Ray Is Worth 15 Features Sparse Autoencoders for Interpretable Radiology Report Generation.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-CXR"
      ],
      "models": [
        "SAE-Rad",
        "CheXagent",
        "MAIRA-1",
        "MAIRA-2",
        "Rad-DINO",
        "Claude 3.5 Sonnet",
        "Llama3-70B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TART A plug-and-play Transformer module for task-agnostic reasoning": {
    "filename": "TART A plug-and-play Transformer module for task-agnostic reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "RAFT Benchmark",
        "SST",
        "Rotten Tomatoes",
        "SMS Spam",
        "IMDB",
        "Civil Comments",
        "AGNews",
        "DBPedia",
        "Youtube",
        "CIFAR-10",
        "MNIST",
        "Speech Commands"
      ],
      "models": [
        "Tart",
        "GPT-Neo",
        "Pythia",
        "Bloom",
        "GPT-J",
        "OPT",
        "GPT-3",
        "Vision Transformer (ViT)",
        "Whisper"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Large Language Models Replace Data Scientists in Clinical Research": {
    "filename": "Can Large Language Models Replace Data Scientists in Clinical Research.pdf",
    "analysis": {
      "benchmarks": [
        "CliniDSBench",
        "cBioPortal"
      ],
      "models": [
        "GPT-4o",
        "GPT-4o-mini",
        "Sonnet",
        "Opus",
        "Gemini-pro",
        "Gemini-flash"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Making Language Models Better Reasoners with Step-Aware Verifier": {
    "filename": "Making Language Models Better Reasoners with Step-Aware Verifier.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "AsDiv",
        "MultiArith",
        "SVAMP",
        "SingleEq",
        "CLUTRR",
        "CommonsenseQA",
        "StrategyQA"
      ],
      "models": [
        "DIVERSE",
        "code-davinci-002",
        "davinci",
        "text-davinci-002",
        "GPT-3",
        "PaLM",
        "deberta-v3-large",
        "roberta-large-mnli"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Lean-STaR Learning to Interleave Thinking and Proving": {
    "filename": "Lean-STaR Learning to Interleave Thinking and Proving.pdf",
    "analysis": {
      "benchmarks": [
        "miniF2F-test"
      ],
      "models": [
        "Lean-STaR",
        "InternLM2-7b",
        "InternLM2-7b-plus",
        "GPT-4",
        "SFT (InternLM2-7b)",
        "Lean-CoT (InternLM2-7b)",
        "Lean-STaR (Iter-1) (InternLM2-7b)",
        "Lean-STaR (Iter-2) (InternLM2-7b)",
        "SFT (InternLM2-plus-7b)",
        "Lean-CoT (InternLM2-plus-7b)",
        "Lean-STaR (Iter-1) (InternLM2-plus-7b)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Empowering biomedical discovery with AI agents": {
    "filename": "Empowering biomedical discovery with AI agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "BioGPT",
        "NYUTron",
        "Med-PaLM",
        "Coscientist",
        "ChemCrow",
        "AutoBa",
        "GENTRL",
        "AlphaFold",
        "AlphaFold-Multimer",
        "FoldSeek",
        "HuggingGPT",
        "Toolformer",
        "Inner Monologue",
        "AutoGPT",
        "AutoGen",
        "MetaGPT",
        "MedAgent",
        "RoCo",
        "SayCan",
        "LLaVA",
        "MemoryBank",
        "ChatDB",
        "Reconcile"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Statler State-Maintaining Language Models for Embodied Reasoning": {
    "filename": "Statler State-Maintaining Language Models for Embodied Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "three-cups-and-a-ball",
        "Pick-and-Place",
        "Block Disinfection",
        "Relative Weight Reasoning"
      ],
      "models": [
        "Statler",
        "Code-as-Policies",
        "CaP+CoT",
        "LLM+State",
        "LLM+CoT",
        "LLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Emergency Department Decision Support using Clinical Pseudo-notes": {
    "filename": "Emergency Department Decision Support using Clinical Pseudo-notes.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-IV",
        "Institutional Database"
      ],
      "models": [
        "Multiple Embedding Model for EHR (MEME)",
        "Logistic Regression",
        "Random Forest",
        "MLP",
        "GenHPF",
        "EHR-Shot",
        "MC-BEC",
        "GPT3.5-turbo",
        "MSEM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cant make an Omelette without Breaking some Eggs Plausible Action Anticipation using Large Video-Language Models": {
    "filename": "Cant make an Omelette without Breaking some Eggs Plausible Action Anticipation using Large Video-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Ego4D",
        "EPIC-Kitchens-100"
      ],
      "models": [
        "PlausiVL",
        "Video-LLaMA",
        "Video-LLM",
        "AntGPT",
        "RU-LSTM",
        "Temporal Aggregation",
        "AFFT",
        "A VT",
        "MeMViT",
        "RAFTformer",
        "InA ViT",
        "RepLAI",
        "SlowFast",
        "ICV AE",
        "HierVL",
        "Video+CLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Distributed Rule Vectors is A Key Mechanism in Large Language Models In-Context Learning": {
    "filename": "Distributed Rule Vectors is A Key Mechanism in Large Language Models In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "categorization task",
        "knowledge task",
        "2-D data"
      ],
      "models": [
        "LLaMA-7B",
        "task vector",
        "distributed rule vectors"
      ]
    }
  },
  "Visual ChatGPT Talking Drawing and Editing with Visual Foundation Models": {
    "filename": "Visual ChatGPT Talking Drawing and Editing with Visual Foundation Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Visual ChatGPT",
        "ChatGPT",
        "BLIP",
        "Stable Diffusion",
        "ControlNet",
        "Pix2Pix",
        "InstructGPT",
        "T5",
        "BLOOM",
        "GPT-3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Causal Language Modeling Can Elicit Search and Reasoning Capabilities on Logic Puzzles": {
    "filename": "Causal Language Modeling Can Elicit Search and Reasoning Capabilities on Logic Puzzles.pdf",
    "analysis": {
      "benchmarks": [
        "Sudoku puzzles",
        "Zebra puzzles",
        "MATH",
        "HumanEval"
      ],
      "models": [
        "Transformer",
        "GPT-4o",
        "Gemini-1.5 Pro",
        "Recurrent Relational Network (RRN)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Powered Context-aware Motion Prediction in Autonomous Driving": {
    "filename": "Large Language Models Powered Context-aware Motion Prediction in Autonomous Driving.pdf",
    "analysis": {
      "benchmarks": [
        "Waymo Open Motion Dataset (WOMD)"
      ],
      "models": [
        "MTR",
        "MTR++",
        "MGTR",
        "Motion Transformer (MTR)",
        "GPT4-V",
        "LLM-augmented model"
      ]
    }
  },
  "Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine Knowledge": {
    "filename": "Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine Knowledge.pdf",
    "analysis": {
      "benchmarks": [
        "TCM-QA"
      ],
      "models": [
        "ChatGPT",
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "MathViz-E A Case-study in Domain-Specialized Tool-Using Agents": {
    "filename": "MathViz-E A Case-study in Domain-Specialized Tool-Using Agents.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "utterance-focused dataset",
        "textbook-focused dataset",
        "multi-turn dataset"
      ],
      "models": [
        "MathViz-E",
        "LLM-only system",
        "LLM+Solver system"
      ]
    }
  },
  "WESE Weak Exploration to Strong Exploitation for LLM Agents": {
    "filename": "WESE Weak Exploration to Strong Exploitation for LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld",
        "ScienceWorld",
        "HotPotQA",
        "FEVER"
      ],
      "models": [
        "WESE",
        "Act",
        "ReAct",
        "CoT",
        "Llama-2-7B",
        "text-davinci-003",
        "SESE"
      ]
    }
  },
  "Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models A Study on Prompt Design Strategies": {
    "filename": "Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models A Study on Prompt Design Strategies.pdf",
    "analysis": {
      "benchmarks": [
        "Spider",
        "Spider-Syn",
        "Spider-DK",
        "Spider-Realistic"
      ],
      "models": [
        "Codex",
        "ChatGPT (gpt-3.5-turbo)",
        "Random sampling",
        "Similarity sampling",
        "Diversity sampling",
        "Similarity-Diversity sampling",
        "SD + schema augmentation",
        "SD + SA + Voting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MinT Boosting Generalization in Mathematical Reasoning via Multi-view Fine-tuning": {
    "filename": "MinT Boosting Generalization in Mathematical Reasoning via Multi-view Fine-tuning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MathQA",
        "Ape210K",
        "CM17K",
        "ASDiv-CoT",
        "ExamQA",
        "MAWPS"
      ],
      "models": [
        "LLaMA-7B",
        "GPT-6B",
        "FlanT5-11B",
        "T5-11B",
        "BLOOMz-7B"
      ]
    }
  },
  "Practically implementing an LLM-supported collaborative vulnerability remediation process A team-based approach": {
    "filename": "Practically implementing an LLM-supported collaborative vulnerability remediation process A team-based approach.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLM-supported collaborative vulnerability remediation process",
        "User Engagement Enhancement",
        "LLM-supported Technician Enhancement"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Lemur Integrating Large Language Models in Automated Program Verification": {
    "filename": "Lemur Integrating Large Language Models in Automated Program Verification.pdf",
    "analysis": {
      "benchmarks": [
        "Code2Inv",
        "SV-COMP"
      ],
      "models": [
        "LEMUR",
        "GPT-3.5 turbo",
        "GPT-4",
        "ESBMC",
        "UAUTOMIZER",
        "Code2Inv"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PromptCrafter Crafting Text-to-Image Prompt through Mixed-Initiative Dialogue with LLM": {
    "filename": "PromptCrafter Crafting Text-to-Image Prompt through Mixed-Initiative Dialogue with LLM.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "PromptCrafter",
        "DALL-E",
        "GPT-3"
      ]
    }
  },
  "DANA Domain-Aware Neurosymbolic Agents for Consistency and Accuracy": {
    "filename": "DANA Domain-Aware Neurosymbolic Agents for Consistency and Accuracy.pdf",
    "analysis": {
      "benchmarks": [
        "FinanceBench"
      ],
      "models": [
        "DANA",
        "AutoGPT",
        "LangChain ReAct",
        "OpenAI ChatGPT",
        "LlamaIndex RAG",
        "OpenAI Assistant",
        "OpenSSA DANA-NK-NP"
      ]
    }
  },
  "A Review on Language Models as Knowledge Bases": {
    "filename": "A Review on Language Models as Knowledge Bases.pdf",
    "analysis": {
      "benchmarks": [
        "Wikidata",
        "ATOMIC",
        "LeapOfThought"
      ],
      "models": [
        "BERT",
        "GPT-3",
        "BART",
        "T5",
        "XGLM",
        "KNOWLEDGE EDITOR",
        "MEND",
        "SLAG",
        "ROME"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Ability of Large Language Models to Evaluate Constraint-satisfaction in Agent Responses to Open-ended Requests": {
    "filename": "The Ability of Large Language Models to Evaluate Constraint-satisfaction in Agent Responses to Open-ended Requests.pdf",
    "analysis": {
      "benchmarks": [
        "Arithmetic Constraint-Satisfaction (ACS) dataset"
      ],
      "models": [
        "Gemini 1.5 Pro",
        "Gemini 1.5 Flash",
        "Gemini 1.0 Pro",
        "GPT-4o",
        "Llama-3-70b-chat",
        "Llama-3-8b-chat",
        "Mixtral-8x7b-instruct-v0.1",
        "Mistral-7b-instruct-v0.2"
      ]
    }
  },
  "LIFT Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks": {
    "filename": "LIFT Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "MNIST",
        "Fashion-MNIST",
        "Iris",
        "OpenML",
        "Medical Insurance",
        "Combined Cycle Power Plant",
        "Servo",
        "Student Performance",
        "Spambase",
        "Hill-Valley",
        "Wine",
        "Vehicle",
        "LED",
        "OPT",
        "Mfeat",
        "Margin",
        "Texture"
      ],
      "models": [
        "LIFT",
        "GPT-J",
        "GPT-3",
        "Logistic Regression",
        "Decision Tree",
        "k-Nearest Neighbor",
        "Support Vector Machine",
        "MLP",
        "Random Forest",
        "XGBoost",
        "Polynomial Regression",
        "Kernel Ridge Regression",
        "Gradient Boosting Trees",
        "Gaussian Process",
        "LeNet-5",
        "LoRA",
        "Rand-GPT-J",
        "CodeGen",
        "CodeParrot",
        "Gibberish"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RouterBench A Benchmark for Multi-LLM Routing System": {
    "filename": "RouterBench A Benchmark for Multi-LLM Routing System.pdf",
    "analysis": {
      "benchmarks": [
        "Hellaswag",
        "Winogrande",
        "ARC Challenge",
        "MMLU",
        "MT-Bench",
        "GSM8K",
        "MBPP",
        "RAG Dataset"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5-turbo",
        "Claude-instant-v1",
        "Claude-v1",
        "Claude-v2",
        "Llama-70B-chat",
        "Mixtral-8x7B-chat",
        "Yi-34B-chat",
        "Code Llama-34B",
        "Mistral-7B-chat",
        "WizardLM-13B",
        "You.com API",
        "sonar-small-online",
        "sonar-medium-online",
        "Zero router",
        "KNN router",
        "MLP router",
        "Cascading router",
        "Oracle router"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Trust in LLM-Generated Code Summaries with Calibrated Confidence Scores": {
    "filename": "Enhancing Trust in LLM-Generated Code Summaries with Calibrated Confidence Scores.pdf",
    "analysis": {
      "benchmarks": [
        "CodeXGLUE"
      ],
      "models": [
        "CodeLlama-70b",
        "DeepSeek-Coder-33b Instruct",
        "GPT-3.5-Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Graph-of-Thought Utilizing Large Language Models to Solve Complex and Dynamic Business Problems": {
    "filename": "Graph-of-Thought Utilizing Large Language Models to Solve Complex and Dynamic Business Problems.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Graph-of-Thought (GoT)",
        "Chain-of-Thought (CoT)",
        "Tree-of-Thought (ToT)",
        "GoTFlow"
      ]
    }
  },
  "An Intelligent Agentic System for Complex Image Restoration Problems": {
    "filename": "An Intelligent Agentic System for Complex Image Restoration Problems.pdf",
    "analysis": {
      "benchmarks": [
        "MiO100"
      ],
      "models": [
        "AgenticIR",
        "DepictQA",
        "Restormer",
        "DehazeFormer",
        "AirNet",
        "PromptIR",
        "MiOIR",
        "DA-CLIP",
        "InstructIR",
        "AutoDIR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Models as Zero-Shot Trajectory Generators": {
    "filename": "Language Models as Zero-Shot Trajectory Generators.pdf",
    "analysis": {
      "benchmarks": [
        "30 real-world language-based tasks",
        "tasks from recent robotics papers"
      ],
      "models": [
        "GPT-4",
        "VoxPoser",
        "Code as Policies",
        "SayCan",
        "RT-2",
        "ChatGPT for Robotics",
        "Language to Rewards",
        "Claude 3",
        "Gemini Pro",
        "Claude 2",
        "Llama 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Measuring and Narrowing the Compositionality Gap in Language Models": {
    "filename": "Measuring and Narrowing the Compositionality Gap in Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Compositional Celebrities",
        "2WikiMultiHopQA",
        "Musique",
        "Bamboogle"
      ],
      "models": [
        "GPT-3",
        "InstructGPT",
        "self-ask",
        "chain of thought",
        "self-ask + Search Engine",
        "direct prompting",
        "Least-to-Most"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs": {
    "filename": "What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "CSN-Java",
        "TLC",
        "B2Fsmall",
        "B2Fmedium",
        "CoNaLa"
      ],
      "models": [
        "CodeBERT",
        "PLBART",
        "CodeT5",
        "GPT-3",
        "PALM-E",
        "AlphaCode",
        "Codex",
        "ChatGPT",
        "GPT-4",
        "BM-25",
        "SBERT",
        "UniXcoder",
        "CoCoSoDa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InfiMM-WebMath-40B Advancing Multimodal Pre-Training for Enhanced Mathematical Reasoning": {
    "filename": "InfiMM-WebMath-40B Advancing Multimodal Pre-Training for Enhanced Mathematical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "MathVerse",
        "We-Math",
        "GSM8K",
        "MATH",
        "MMLU",
        "SAT",
        "OCW",
        "MalAlgoQA",
        "MathCheck-GSM",
        "GeoEval",
        "Geometry3K",
        "GeomVerse",
        "ChartX",
        "ChartQA",
        "ChartBench",
        "MathVista"
      ],
      "models": [
        "InfiMM-Math",
        "DeepSeekMath-1.3B",
        "DeepSeekMath-7B",
        "InternLM-Math",
        "Alpha-Proof",
        "DeepSeek-Prover",
        "G-LLaVA",
        "Math-LLaVA",
        "LLaVA-Next",
        "MA VIS",
        "GPT-4V",
        "Gemini-Pro",
        "Qwen-VL-Max",
        "SPHINX-Plus",
        "InternLM-XC2",
        "ShareGPT4V",
        "LLaVA-NeXT",
        "MA VIS Mammoth2-7B",
        "InfiMM-Math DS-Coder-1.3B",
        "InfiMM-Math DS-Coder-1.5-7B",
        "Deepseek-coder-1.3b-base",
        "Deepseek-coder-7b-v1.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Maintaining Informative Coherence Migrating Hallucinations in Large Language Models via Absorbing Markov Chains": {
    "filename": "Maintaining Informative Coherence Migrating Hallucinations in Large Language Models via Absorbing Markov Chains.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA",
        "FACTOR",
        "HaluEval",
        "WIKI-FACTOR",
        "NEWS-FACTOR"
      ],
      "models": [
        "LLaMa2-7B-chat",
        "LLaMa2-13B-chat",
        "LLaMa3-8B",
        "Qwen2-7B",
        "Dola",
        "Activation Decoding (AD)",
        "Ours"
      ]
    }
  },
  "SimSAM Zero-Shot Medical Image Segmentation via Simulated Interaction": {
    "filename": "SimSAM Zero-Shot Medical Image Segmentation via Simulated Interaction.pdf",
    "analysis": {
      "benchmarks": [
        "Breast Ultrasound Scan Images (BUSI)",
        "CVC-ClinicDB",
        "ISIC-2016"
      ],
      "models": [
        "Segment Anything Model (SAM)",
        "SIMSAM",
        "SAM-FT"
      ]
    }
  },
  "Efficient Human-AI Coordination via Preparatory Language-based Convention": {
    "filename": "Efficient Human-AI Coordination via Preparatory Language-based Convention.pdf",
    "analysis": {
      "benchmarks": [
        "Overcooked-AI",
        "Symbolic Manipulation",
        "Compositional Generalization",
        "Math Reasoning"
      ],
      "models": [
        "HAPLAN",
        "Fictitious Co-Play (FCP)",
        "Maximum Entropy Population-based training (MEP)",
        "Hidden-utility Self-Play (HSP)",
        "Integrate-LLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Native vs Non-Native Language Prompting A Comparative Analysis": {
    "filename": "Native vs Non-Native Language Prompting A Comparative Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "OSACT 2020",
        "ASAD",
        "CLEF CheckThat!",
        "WANLP22",
        "ANS",
        "OffensEval2020",
        "ThatiAR"
      ],
      "models": [
        "GPT-4o",
        "Llama-3.1-8b-Instruct",
        "Jais-13b-chat"
      ]
    }
  },
  "Large Language Model Enhanced Multi-Agent Systems for 6G Communications": {
    "filename": "Large Language Model Enhanced Multi-Agent Systems for 6G Communications.pdf",
    "analysis": {
      "benchmarks": [
        "Cornell Movie-Dialogs Corpus"
      ],
      "models": [
        "Multi-agent Data Retrieval (MDR)",
        "Multi-agent Collaborative Planning (MCP)",
        "Multi-agent Evaluation and Reflexion (MER)",
        "GPT-3.5",
        "Semantic Communication (SC) model",
        "Long Short-Term Memory (LSTM)",
        "Multilayer Perceptron (MLP)"
      ]
    }
  },
  "AI-assisted Automated Short Answer Grading of Handwritten University Level Mathematics Exams": {
    "filename": "AI-assisted Automated Short Answer Grading of Handwritten University Level Mathematics Exams.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "GPT-4V",
        "Mathpix",
        "Watch, Attend and Parse (WAP)",
        "Track, Attend and Parse (TAP)",
        "Random Forest",
        "XGBoost",
        "LSTM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding": {
    "filename": "Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "ScienceQA",
        "HotpotQA"
      ],
      "models": [
        "Hidden Chain-of-Thought (HCoT)",
        "auxiliary CoT model",
        "LLaMa2-7B",
        "LLaMa2-13B",
        "Zero/Few-shot CoT",
        "Train without COT",
        "Train with COT",
        "Train with HCoT base",
        "Train with HCoT Contrast"
      ]
    }
  },
  "AutoAttacker A Large Language Model Guided System to Implement Automatic Cyber-attacks": {
    "filename": "AutoAttacker A Large Language Model Guided System to Implement Automatic Cyber-attacks.pdf",
    "analysis": {
      "benchmarks": [
        "new benchmark with 14 different attacks"
      ],
      "models": [
        "AUTOATTACKER",
        "GPT-3.5",
        "GPT-4",
        "Llama2-7B-chat",
        "Llama2-70B-chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models": {
    "filename": "Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "CSQA",
        "Letter",
        "AQuA",
        "AddSub",
        "SingleEq",
        "SVAMP",
        "ASDiv",
        "StrategyQA",
        "Date Understanding",
        "Letter Concatenation"
      ],
      "models": [
        "Iter-CoT",
        "Zero-Shot-CoT",
        "Manual-CoT",
        "Random-CoT",
        "Complex-CoT",
        "Auto-CoT",
        "Self-Consistency",
        "UL2-20B",
        "LaMDA-137B",
        "PaLM-540B",
        "GPT-3.5-turbo",
        "GPT-4",
        "Llama-2-70B-Chat",
        "Llama-2-70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Uni-NLX Unifying Textual Explanations for Vision and Vision-Language Tasks": {
    "filename": "Uni-NLX Unifying Textual Explanations for Vision and Vision-Language Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "VQA-X",
        "A-OKVQA",
        "VQA-ParaX",
        "ImageNetX",
        "ACT-X",
        "e-SNLI-VE",
        "VCR"
      ],
      "models": [
        "Uni-NLX",
        "NLX-GPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Construction contract risk identification based on knowledge-augmented language model": {
    "filename": "Construction contract risk identification based on knowledge-augmented language model.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Saika Wong",
        "DeBERTa",
        "BART",
        "bi-LSTM",
        "BERT",
        "GPT-4",
        "sentence-transformers",
        "text-embedding-ada-002"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Face4RAG Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese": {
    "filename": "Face4RAG Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese.pdf",
    "analysis": {
      "benchmarks": [
        "Face4RAG",
        "WebCPM",
        "RAG",
        "summarization",
        "dialogue",
        "fact verification",
        "FRANK",
        "SummEval",
        "Q2",
        "DialFact",
        "VitaminC"
      ],
      "models": [
        "L-Face4RAG",
        "FACTSCORE",
        "FELM",
        "Ragas",
        "RefChecker",
        "GPT-4",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation": {
    "filename": "Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "TriviaQA",
        "SciQ",
        "AmbigQA",
        "DateUnd",
        "Biz-Ethics"
      ],
      "models": [
        "Collaborative Calibration",
        "Ask4Conf",
        "Verbalized+Consistency",
        "Top-K+Self-Random+Avg-Conf",
        "Mistral-7B",
        "GPT-3.5-turbo",
        "Cohere-Commend"
      ]
    }
  },
  "Knowledge Graph Large Language Model KG-LLM for Link Prediction": {
    "filename": "Knowledge Graph Large Language Model KG-LLM for Link Prediction.pdf",
    "analysis": {
      "benchmarks": [
        "WN18RR",
        "NELL-995",
        "FB15k-237",
        "YAGO3-10"
      ],
      "models": [
        "KG-LLM",
        "Flan-T5",
        "Llama2",
        "Gemma",
        "TransE",
        "Analogy",
        "CompleX",
        "DistMult",
        "RESCAL",
        "wsGAT",
        "ConGLR",
        "ConvRot"
      ]
    }
  },
  "MiLoRA Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning": {
    "filename": "MiLoRA Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning.pdf",
    "analysis": {
      "benchmarks": [
        "Commonsense170K",
        "BoolQ",
        "PIQA",
        "SIQA",
        "HellaSwag",
        "WinoGrande",
        "ARC-e",
        "ARC-c",
        "OBQA",
        "GSM8K",
        "MATH",
        "MetaMathQA",
        "Alpaca-Eval v1.0",
        "VQA-v2",
        "GQA",
        "VizWiz",
        "SQA",
        "VQAT",
        "POPE",
        "MMBench"
      ],
      "models": [
        "MiLoRA",
        "LoRA",
        "PiSSA",
        "LLaMA2-7B",
        "LLaMA3-8B",
        "LLaV A1.5-7B",
        "ChatGPT",
        "GPT-4-0613",
        "GPT-3.5-turbo-0613",
        "LLaMA2-Chat-7B",
        "rsLoRA",
        "LoRA+",
        "DoRA",
        "AdaLoRA",
        "LoRA-GA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ProgPrompt Generating Situated Robot Task Plans using Large Language Models": {
    "filename": "ProgPrompt Generating Situated Robot Task Plans using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "VirtualHome"
      ],
      "models": [
        "PROGPROMPT",
        "GPT-3",
        "CODEX",
        "DAVINCI",
        "LANG PROMPT",
        "Baseline from Huang et al."
      ]
    }
  },
  "Stress-Testing Capability Elicitation With Password-Locked Models": {
    "filename": "Stress-Testing Capability Elicitation With Password-Locked Models.pdf",
    "analysis": {
      "benchmarks": [
        "APPS",
        "MBPP",
        "MATH",
        "MMLU"
      ],
      "models": [
        "Deepseek-7B",
        "Pythia-1B",
        "Mistral-7B",
        "GPT-4",
        "Llama7B",
        "Deepseek-7B-Coder",
        "Deepseek-7B-Math",
        "Pythia-7B",
        "Pythia-400M",
        "fixedrdm"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Minimal Self in Humanoid Robot Alter3 Driven by Large Language Model": {
    "filename": "Minimal Self in Humanoid Robot Alter3 Driven by Large Language Model.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Alter3",
        "GPT-4",
        "Alter3+GPT-4"
      ]
    }
  },
  "CodeHelp Using Large Language Models with Guardrails for Scalable Support in Programming Classes": {
    "filename": "CodeHelp Using Large Language Models with Guardrails for Scalable Support in Programming Classes.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "CodeHelp",
        "GPT-4",
        "Codex",
        "ChatGPT",
        "GitHub Copilot",
        "Python-Bot",
        "RevBot",
        "Duckbot"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhance Reasoning for Large Language Models in the Game Werewolf": {
    "filename": "Enhance Reasoning for Large Language Models in the Game Werewolf.pdf",
    "analysis": {
      "benchmarks": [
        "FanLang-9"
      ],
      "models": [
        "GPT3.5",
        "GPT4",
        "Thinker",
        "ChatGLM-6B",
        "Finetune-T",
        "GPT3.5-LtM",
        "GPT3.5-T",
        "GPT4-LtM",
        "GPT4-T"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Fabrication of Reality and Fantasy Scene Generation with LLM-Assisted Prompt Interpretation": {
    "filename": "The Fabrication of Reality and Fantasy Scene Generation with LLM-Assisted Prompt Interpretation.pdf",
    "analysis": {
      "benchmarks": [
        "Realistic-Fantasy Benchmark (RFBench)",
        "DrawBench"
      ],
      "models": [
        "Realistic-Fantasy Network (RFNet)",
        "Stable Diffusion",
        "GLIDE",
        "DALLE2",
        "Imagen",
        "Attend and Excite",
        "LMD",
        "BoxDiff",
        "MultiDiffusion",
        "SDXL"
      ]
    }
  },
  "CHATATC Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management": {
    "filename": "CHATATC Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "CHATATC",
        "U-M GPT",
        "Maizey",
        "GPT-3.5",
        "GPT-4 Turbo",
        "Llama 2"
      ]
    }
  },
  "Solving Math Word Problems via Cooperative Reasoning induced Language Models": {
    "filename": "Solving Math Word Problems via Cooperative Reasoning induced Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "ASDiv-A",
        "SingleOp",
        "SingleEq",
        "MultiArith"
      ],
      "models": [
        "Cooperative Reasoning (CoRe)",
        "Instruct GPT-3",
        "PaLM",
        "GPT-J",
        "DeBERTa-large",
        "LaMDA",
        "GPT-3",
        "Self-Consistency",
        "Chain-of-Thought (CoT)",
        "Zero-shot-CoT",
        "UNITDEP",
        "LogicForm",
        "Relevance and LCA operation classifier"
      ]
    }
  },
  "Chaining Simultaneous Thoughts for Numerical Reasoning": {
    "filename": "Chaining Simultaneous Thoughts for Numerical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "MathQA",
        "SVAMP",
        "DROP num",
        "DROP",
        "GSM8K"
      ],
      "models": [
        "CANTOR",
        "mBERT2Seq",
        "Graph2Tree",
        "BERT2Tree",
        "DEDUCT REASONER",
        "GPT-2",
        "RoBERTaGen",
        "TASE",
        "TASE arith",
        "Vanilla NAR",
        "Vanilla CANTOR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LeTI Learning to Generate from Textual Interactions": {
    "filename": "LeTI Learning to Generate from Textual Interactions.pdf",
    "analysis": {
      "benchmarks": [
        "MBPP",
        "HumanEval",
        "GSM8K",
        "Big-Bench-Hard"
      ],
      "models": [
        "LETI",
        "CodeGen-mono",
        "2B LM",
        "350M LM",
        "pre-trained LM",
        "fine-tuned baseline"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning": {
    "filename": "Explanation-aware Soft Ensemble Empowers Large Language Model In-context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "E-SNLI",
        "ANLI-R1",
        "ANLI-R2",
        "ANLI-R3",
        "ECQA",
        "OpenbookQA",
        "StrategyQA"
      ],
      "models": [
        "EASE",
        "PaLM 2-S",
        "PaLM 2-L",
        "FLAN-UL2",
        "Llama-2",
        "Standard In-context Learning (ICL)",
        "Predict-then-Explain (PE)",
        "Explain-then-Predict (EP)",
        "Self-consistency",
        "FLamE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatGPT or Grammarly Evaluating ChatGPT on Grammatical Error Correction Benchmark": {
    "filename": "ChatGPT or Grammarly Evaluating ChatGPT on Grammatical Error Correction Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "CoNLL2014",
        "BEA-2019",
        "JFLEG"
      ],
      "models": [
        "ChatGPT",
        "Grammarly",
        "GECToR"
      ]
    }
  },
  "NaVid Video-based VLM Plans the Next Step for Vision-and-Language Navigation": {
    "filename": "NaVid Video-based VLM Plans the Next Step for Vision-and-Language Navigation.pdf",
    "analysis": {
      "benchmarks": [
        "VLN-CE R2R",
        "VLN-CE RxR",
        "R2R",
        "RxR"
      ],
      "models": [
        "NaVid",
        "Seq2Seq",
        "CMA",
        "WS-MGMap",
        "RGB-Seq2Seq",
        "RGB-CMA",
        "A2Nav",
        "GPT-4V",
        "Emu",
        "LLaVA",
        "LLaMA-VID",
        "LLaVA-Nav",
        "LLaMA-VID-Nav",
        "LM-Nav",
        "LM-Nav (GPT 3.5, CLIP)",
        "LM-Nav (GPT 4, EVA-CLIP)",
        "LM-Nav (Vicuna-7B, EVA-CLIP)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reason out Your Layout Evoking the Layout Master from Large Language Models for Text-to-Image Synthesis": {
    "filename": "Reason out Your Layout Evoking the Layout Master from Large Language Models for Text-to-Image Synthesis.pdf",
    "analysis": {
      "benchmarks": [
        "Flickr30K",
        "COCO2017"
      ],
      "models": [
        "Stable Diffusion",
        "GLIGEN",
        "LACA",
        "LLM-based Layout Generator"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "What Formal Languages Can Transformers Express A Survey": {
    "filename": "What Formal Languages Can Transformers Express A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "MAJORITY",
        "SHUFFLE-DYCK-k",
        "DYCK-k",
        "PARITY",
        "DYCK-1",
        "DYCK-2",
        "DYCK-(1,D)",
        "DYCK-(k,D)"
      ],
      "models": [
        "transformer encoder-decoder with average-hard attention",
        "transformer encoder-decoder with softmax attention",
        "transformer encoder with leftmost-hard attention",
        "transformer encoder with rightmost-hard attention",
        "transformer encoder with average-hard attention",
        "transformer encoder with softmax attention",
        "transformer decoder with intermediate steps",
        "transformer encoder-decoder with intermediate steps"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Program of Thoughts Prompting Disentangling Computation from Reasoning for Numerical Reasoning Tasks": {
    "filename": "Program of Thoughts Prompting Disentangling Computation from Reasoning for Numerical Reasoning Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "AQuA",
        "SVAMP",
        "TabMWP",
        "MultiArith",
        "FinQA",
        "ConvFinQA",
        "TATQA"
      ],
      "models": [
        "Program of Thoughts (PoT)",
        "Chain of Thoughts (CoT)",
        "Codex",
        "GPT-3",
        "PaLM",
        "LaMDA",
        "GPT-4",
        "code-davinci-002",
        "text-davinci-002",
        "gpt-3.5-turbo",
        "codegen-16B-multi",
        "codegen-16B-mono",
        "CodeT5+",
        "Xgen"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Diffusion Model-Based Image Editing A Survey": {
    "filename": "Diffusion Model-Based Image Editing A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "EditEval"
      ],
      "models": [
        "DiffusionCLIP",
        "Asyrp",
        "EffDiff",
        "DiffStyler",
        "StyleDiffusion",
        "UNIT-DDPM",
        "CycleNet",
        "Diffusion Autoencoders",
        "HDAE",
        "EGSDE",
        "Pixel-Guided Diffusion",
        "PbE",
        "RIC",
        "ObjectStitch",
        "PhD",
        "DreamInpainter",
        "Anydoor",
        "FADING",
        "PAIR Diffusion",
        "SmartBrush",
        "IIR-Net",
        "PowerPaint",
        "Imagen Editor",
        "SmartMask",
        "Uni-paint",
        "InstructPix2Pix",
        "MoEController",
        "FoI",
        "LOFIE",
        "InstructDiffusion",
        "Emu Edit",
        "DialogPaint",
        "Inst-Inpaint",
        "HIVE",
        "ImageBrush",
        "InstructAny2Pix",
        "MGIE",
        "SmartEdit",
        "iEdit",
        "TDIELR",
        "ChatFace",
        "UniTune",
        "Custom-Edit",
        "KV-Inversion",
        "Null-Text Inversion",
        "DPL",
        "DiffusionDisentanglement",
        "Prompt Tuning Inversion",
        "StyleDiffusion",
        "InST",
        "DragonDiffusion",
        "DragDiffusion",
        "DDS",
        "DiffuseIT",
        "CDS",
        "MagicRemover",
        "Imagic",
        "LayerDiffusion",
        "Forgedit",
        "SINE",
        "PRedItOR",
        "ReDiffuser",
        "Captioning and Injection",
        "InstructEdit",
        "Direct Inversion",
        "DDPM Inversion",
        "SDE-Drag",
        "LEDITS++",
        "FEC",
        "EMILIE",
        "Negative Inversion",
        "ProxEdit",
        "Null-Text Guidance",
        "EDICT",
        "AIDI",
        "CycleDiffusion",
        "InjectFusion",
        "Fixed-point inversion",
        "TIC",
        "Diffusion Brush",
        "Self-guidance",
        "P2P",
        "Pix2Pix-Zero",
        "MasaCtrl",
        "PnP",
        "TF-ICON",
        "Object-Shape Variations",
        "Conditional Score Guidance",
        "EBMs",
        "Shape-Guided Diffusion",
        "HD-Painter",
        "FISEdit",
        "Blended Latent Diffusion",
        "PFB-Diff",
        "DiffEdit",
        "RDM",
        "MFL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompting Is Programming A Query Language for Large Language Models": {
    "filename": "Prompting Is Programming A Query Language for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LMQL",
        "gpt2-medium",
        "EleutherAI/gpt-j-6B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Meta-prompting Optimized Retrieval-augmented Generation": {
    "filename": "Meta-prompting Optimized Retrieval-augmented Generation.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA"
      ],
      "models": [
        "Llama-2-70b",
        "Llama-2-70b-chat"
      ]
    }
  },
  "Universal Self-adaptive Prompting": {
    "filename": "Universal Self-adaptive Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "winogrande",
        "piqa",
        "storycloze",
        "anlir1",
        "anlir2",
        "anlir3",
        "boolq",
        "copa",
        "rte",
        "wic",
        "wsc",
        "arc_e",
        "arc_c",
        "raceh",
        "racem",
        "lambada",
        "web_questions",
        "natural_questions",
        "triviaqa_wiki",
        "squad",
        "xsum",
        "wikilingua (en)",
        "BIG-bench Hard (BBH)"
      ],
      "models": [
        "PaLM",
        "PaLM 2",
        "PaLM-62B",
        "PaLM-540B",
        "PaLM 2-M",
        "USP",
        "AutoCoT",
        "Random demo",
        "0-shot",
        "3-shot",
        "5-shot"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Orca Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models": {
    "filename": "Orca Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Gulf of Mexico",
        "National Data Buoy Center dataset (NDBC)",
        "Global Wave Database (GWD)"
      ],
      "models": [
        "Orca",
        "GWD",
        "PatchTST",
        "GPT-2",
        "GPT4TS"
      ]
    }
  },
  "Rationale-Enhanced Language Models are Better Continual Relation Learners": {
    "filename": "Rationale-Enhanced Language Models are Better Continual Relation Learners.pdf",
    "analysis": {
      "benchmarks": [
        "FewRel",
        "TACRED"
      ],
      "models": [
        "RationaleCL",
        "RPCRE",
        "EMAR",
        "CRECL",
        "CRL",
        "ACA",
        "CEAR"
      ]
    }
  },
  "Human-AI Safety A Descendant of Generative AI and Control Systems Safety": {
    "filename": "Human-AI Safety A Descendant of Generative AI and Control Systems Safety.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How to Train Data-Efficient LLMs": {
    "filename": "How to Train Data-Efficient LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "Super-GLUE",
        "CNN/DM",
        "SQuAD",
        "MMLU",
        "BBH",
        "Reasoning QA"
      ],
      "models": [
        "ASK-LLM",
        "DENSITY",
        "T5-Large",
        "T5-Small",
        "Flan-T5-XL",
        "Flan-T5-Small",
        "Flan-T5-Base",
        "Flan-T5-Large",
        "Flan-T5-XXL",
        "Perplexity (XL)",
        "Perplexity (Small)",
        "SemDeDup",
        "Prototypes"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FiDeLiS Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering": {
    "filename": "FiDeLiS Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "WebQSP",
        "CWQ",
        "CR-LT"
      ],
      "models": [
        "FiDeLiS",
        "gpt-3.5-turbo",
        "gpt-4-turbo",
        "NSM",
        "CBR-KBQA",
        "DeCAF",
        "KD-CoT",
        "RoG",
        "ToG",
        "Few-shot",
        "CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SAIL Search-Augmented Instruction Learning": {
    "filename": "SAIL Search-Augmented Instruction Learning.pdf",
    "analysis": {
      "benchmarks": [
        "CommonsenseQA",
        "OpenbookQA",
        "ARC-Challenge",
        "UniLC",
        "Climate-Fever",
        "PubHealth",
        "Hate Speech Detection",
        "Social Bias Frame"
      ],
      "models": [
        "SAIL-7B",
        "LLaMA-7B",
        "Vicuna-7B",
        "Vicuna-13B",
        "GPT-3.5-Turbo",
        "GPT-4",
        "ChatGPT"
      ]
    }
  },
  "Recommender Systems in the Era of Large Language Models LLMs": {
    "filename": "Recommender Systems in the Era of Large Language Models LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "IMDB",
        "Netflix"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "T5",
        "LLaMA",
        "Chat-Rec",
        "BERT4Rec",
        "UniMIND",
        "GPT4Rec",
        "P5",
        "PALR",
        "TALLRec",
        "M6-Rec",
        "RecLLM",
        "GIRL",
        "LMRec",
        "TransRec",
        "SBERT",
        "UniTRec",
        "TallRec",
        "GLRec",
        "LLaRA",
        "PTUM",
        "M6",
        "P5",
        "RecAgent",
        "Agent4Rec",
        "InteRecAgent"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Organizing Unstructured Image Collections using Natural Language": {
    "filename": "Organizing Unstructured Image Collections using Natural Language.pdf",
    "analysis": {
      "benchmarks": [
        "COCO-4c",
        "Food-4c",
        "Clevr-4c",
        "Fruit-2c",
        "Card-2c",
        "Action-3c"
      ],
      "models": [
        "TeDeSC",
        "IC|TC",
        "MMaP",
        "CLIP ViT-L/14",
        "DINOv1-B/16",
        "DINOv2-G/14",
        "BLIP-2 Flan-T5 XXL",
        "LLaVA-NeXT-7B",
        "Llama-3.1-8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reason-before-Retrieve One-Stage Reflective Chain-of-Thoughts for Training-Free Zero-Shot Composed Image Retrieval": {
    "filename": "Reason-before-Retrieve One-Stage Reflective Chain-of-Thoughts for Training-Free Zero-Shot Composed Image Retrieval.pdf",
    "analysis": {
      "benchmarks": [
        "CIRCO",
        "CIRR",
        "FashionIQ",
        "GeneCIS"
      ],
      "models": [
        "OSrCIR",
        "CIReVL",
        "CIReVL*",
        "Pic2Word",
        "SEARLE",
        "LinCIR",
        "Context-I2W"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Adapting a Foundation Model for Space-based Tasks": {
    "filename": "Adapting a Foundation Model for Space-based Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "AI4Mars"
      ],
      "models": [
        "LLaVA",
        "Space-LLaVA",
        "GPT-4o"
      ]
    }
  },
  "What does a platypus look like Generating customized prompts for zero-shot image classification": {
    "filename": "What does a platypus look like Generating customized prompts for zero-shot image classification.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "Describable Textures Dataset",
        "Stanford Cars",
        "SUN397",
        "Food101",
        "FGVC Aircraft",
        "Oxford Pets",
        "Caltech101",
        "Flowers 102",
        "UCF101",
        "Kinetics-700",
        "RESISC45",
        "CIFAR-10",
        "CIFAR-100",
        "Birdsnap"
      ],
      "models": [
        "CuPL",
        "CLIP",
        "GPT-3",
        "CuPL (base)",
        "CuPL (full)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompting Is All You Need Automated Android Bug Replay with Large Language Models": {
    "filename": "Prompting Is All You Need Automated Android Bug Replay with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "AdbGPT",
        "ReCDroid",
        "MaCa",
        "AdbGPT w/o Few",
        "AdbGPT w/o CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Grounding LLMs For Robot Task Planning Using Closed-loop State Feedback": {
    "filename": "Grounding LLMs For Robot Task Planning Using Closed-loop State Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "VirtualHome",
        "Franka Research 3"
      ],
      "models": [
        "BrainBody-LLM",
        "GPT-4",
        "GPT-3.5",
        "PaLM 2 text-bison-001",
        "ProgPrompt",
        "Baseline-LLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning": {
    "filename": "Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning.pdf",
    "analysis": {
      "benchmarks": [
        "IWSLT",
        "WMT",
        "Flores-200",
        "AlpacaEval"
      ],
      "models": [
        "LLaMA",
        "LLaMA-MT",
        "Post-Ins",
        "PTL",
        "1-shot",
        "5-shot",
        "Clang",
        "Ours"
      ]
    }
  },
  "AllHands Ask Me Anything on Large-scale Verbatim Feedback via Large Language Models": {
    "filename": "AllHands Ask Me Anything on Large-scale Verbatim Feedback via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GoogleStoreApp",
        "ForumPost",
        "MSearch"
      ],
      "models": [
        "AllHands",
        "BERT",
        "DistilBERT",
        "ALBERT",
        "RoBERTa",
        "XLM-RoBERTa",
        "GPT-3.5",
        "GPT-4",
        "LDA",
        "HDP",
        "NMF",
        "ProdLDA",
        "CTM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Long-Horizon Vision-Language Navigation Platform Benchmark and Method": {
    "filename": "Towards Long-Horizon Vision-Language Navigation Platform Benchmark and Method.pdf",
    "analysis": {
      "benchmarks": [
        "LHPR-VLN",
        "Room-to-Room (R2R)",
        "Room-for-Room (R4R)",
        "VLN-CE",
        "CVDN",
        "REVERIE",
        "SOON",
        "OVMM",
        "Behavior-1K"
      ],
      "models": [
        "Navigate with CoT and Memory",
        "MGDM",
        "ETPNav",
        "GLM-4v prompt",
        "NaviLLM",
        "GPT-4 + NaviLLM",
        "InstructNav"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Software Testing With Large Language Models Survey Landscape and Vision": {
    "filename": "Software Testing With Large Language Models Survey Landscape and Vision.pdf",
    "analysis": {
      "benchmarks": [
        "Defects4J",
        "CodeSearchNet",
        "HumanEval",
        "SF110"
      ],
      "models": [
        "T5",
        "GPT-3",
        "ChatGPT",
        "LLaMA",
        "Codex",
        "BART",
        "CodeT5",
        "CodeGen",
        "PaLM",
        "InstructGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TART An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning": {
    "filename": "TART An Open-Source Tool-Augmented Framework for Explainable Table-based Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "TOOLTAB",
        "WikiTableQuestion (WTQ)",
        "HiTab (HIT)",
        "TabMWP (TMP)",
        "FinQA (FQA)",
        "TAT-QA (TAT)",
        "HybridQA (HYQ)",
        "TabFact (TAF)",
        "SCITAB (SCT)",
        "PubHealthTab (PHT)"
      ],
      "models": [
        "TART",
        "Chain-of-Thought (CoT)",
        "GPT-3.5-turbo",
        "GPT-4",
        "TableLlama",
        "Llama2-7b",
        "Llama3-8b",
        "CodeLlama-7b",
        "DeepSeek-Coder-7b-Instruct-V1.5",
        "DeepSeek-7b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Recent Advances in Multi-Choice Machine Reading Comprehension A Survey on Methods and Datasets": {
    "filename": "Recent Advances in Multi-Choice Machine Reading Comprehension A Survey on Methods and Datasets.pdf",
    "analysis": {
      "benchmarks": [
        "CBT",
        "MovieQA",
        "WDW",
        "BookTest",
        "Quasar-S",
        "WikiHop",
        "RACE",
        "SciQ",
        "RecipeQA-text",
        "CliCR",
        "CLOTH",
        "ReCoRD",
        "BioRead",
        "MultiRC",
        "ARC",
        "MedQA",
        "MCScript",
        "MCScript2.0",
        "RACE-C",
        "DREAM",
        "CosmosQA",
        "Shmoop",
        "BioMRC",
        "ReClor",
        "QuAIL",
        "QASC",
        "LogiQA",
        "ExpMRC-RACE+",
        "LogiQA2.0",
        "RULE"
      ],
      "models": [
        "RoBERTa",
        "ERNIE",
        "T5",
        "DeBERTa",
        "PaLM",
        "BERT",
        "GPT",
        "XLNET",
        "ALBERT",
        "Sparse Transformer",
        "Longformer",
        "ETC",
        "Big-Bird",
        "Realformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language as Reality A Co-Creative Storytelling Game Experience in 1001 Nights using Generative AI": {
    "filename": "Language as Reality A Co-Creative Storytelling Game Experience in 1001 Nights using Generative AI.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "Stable Diffusion",
        "Pixelization model",
        "ChatGPT",
        "dreamily.ai",
        "ControlNet"
      ]
    }
  },
  "Multi-Agent Consensus Seeking via Large Language Models": {
    "filename": "Multi-Agent Consensus Seeking via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5-turbo-0613",
        "LLM-driven agents"
      ]
    }
  },
  "Language Models as Knowledge Bases for Visual Word Sense Disambiguation": {
    "filename": "Language Models as Knowledge Bases for Visual Word Sense Disambiguation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "CLIP-L",
        "CLIP LAION",
        "ALIGN",
        "BLIP C",
        "BLIP-L C",
        "BLIP F",
        "BLIP-L F",
        "GPT2-XL",
        "BLOOMZ-1.7B",
        "BLOOMZ-3B",
        "OPT-2.7B",
        "OPT-6.7B",
        "Galactica 6.7B",
        "LLAMA-7B",
        "Vicuna 7B",
        "Vicuna 13B",
        "GPT-3",
        "GPT-3.5-turbo",
        "GiT-L",
        "BLIP-L",
        "ViT-GPT2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ContextGPT Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models": {
    "filename": "ContextGPT Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models.pdf",
    "analysis": {
      "benchmarks": [
        "DOMINO",
        "ExtraSensory"
      ],
      "models": [
        "ContextGPT",
        "No knowledge",
        "Ontology",
        "NIMBUS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "N-Critics Self-Refinement of Large Language Models with Ensemble of Critics": {
    "filename": "N-Critics Self-Refinement of Large Language Models with Ensemble of Critics.pdf",
    "analysis": {
      "benchmarks": [
        "REALTOXICITYPROMPTS",
        "AmbigNQ",
        "TriviaQA",
        "HotpotQA"
      ],
      "models": [
        "N-CRITICS",
        "LLaMA-70b",
        "WizardLM-70b",
        "WizardLM-13b",
        "Koala-13b",
        "Vicuna-13b",
        "ChatGPT",
        "CRITIC",
        "Vanilla Llama-70b"
      ]
    }
  },
  "Question Suggestion for Conversational Shopping Assistants Using Product Metadata": {
    "filename": "Question Suggestion for Conversational Shopping Assistants Using Product Metadata.pdf",
    "analysis": {
      "benchmarks": [
        "Amazon Reviews Dataset"
      ],
      "models": [
        "Claude-2 LLM",
        "Flan-T5-xxl",
        "GPT-4"
      ]
    }
  },
  "Retrieval-Augmented Chain-of-Thought in Semi-structured Domains": {
    "filename": "Retrieval-Augmented Chain-of-Thought in Semi-structured Domains.pdf",
    "analysis": {
      "benchmarks": [
        "FinQA",
        "SARA"
      ],
      "models": [
        "GPT-3",
        "LLaMA2-7B",
        "LLaMA2-7B_chat",
        "LLaMA2-13B",
        "LLaMA2-13B_chat",
        "LLaMA2-70B",
        "Majority baseline",
        "Feed-forward",
        "Legal-BERT",
        "BERT",
        "Longformer",
        "ELASTIC",
        "DyRRen",
        "TabT5",
        "APOLLO",
        "FinQANet-BERT",
        "GPT-3-BERT",
        "LLaMA2-7B-BERT",
        "LLaMA2-7B_chat-BERT",
        "LLaMA2-13B-BERT",
        "LLaMA2-13B_chat-BERT",
        "LLaMA2-70B-BERT",
        "FinQANet-Gold",
        "GPT-3-Gold",
        "LLaMA2-70B-Gold"
      ]
    }
  },
  "PharmacyGPT The AI Pharmacist": {
    "filename": "PharmacyGPT The AI Pharmacist.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-CXR",
        "OpenI"
      ],
      "models": [
        "PharmacyGPT",
        "ChatGPT",
        "GPT-4",
        "LLAMA2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MINTQA A Multi-Hop Question Answering Benchmark for Evaluating LLMs on New and Tail Knowledge": {
    "filename": "MINTQA A Multi-Hop Question Answering Benchmark for Evaluating LLMs on New and Tail Knowledge.pdf",
    "analysis": {
      "benchmarks": [
        "MINTQA",
        "MINTQA-POP",
        "MINTQA-TI",
        "MultiHop-RAG",
        "FanoutQA",
        "HotpotQA",
        "WiTQA",
        "Head-to-Tail"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4o",
        "GPT-4o mini",
        "LLaMA-3.1",
        "LLaMA-3.2",
        "Gemma-2",
        "Mistral",
        "Phi-3",
        "Qwen2.5",
        "LLaMA-3.1-70B",
        "LLaMA-3.1-8B",
        "LLaMA-3.2-1B",
        "LLaMA-3.2-3B",
        "Qwen2.5-1.5B",
        "Qwen2.5-3B",
        "Qwen2.5-7B",
        "Qwen2.5-14B",
        "Qwen2.5-32B",
        "Qwen2.5-72B",
        "Gemma-2-2B",
        "Gemma-2-9B",
        "Gemma-2-27B",
        "Phi-3-mini",
        "Phi-3-small",
        "Phi-3-medium",
        "Mistral-7B-v0.3",
        "Mixtral-8x7B-v0.1",
        "Ministral-8B-2410"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Critical-Questions-of-Thought Steering LLM reasoning with Argumentative Querying": {
    "filename": "Critical-Questions-of-Thought Steering LLM reasoning with Argumentative Querying.pdf",
    "analysis": {
      "benchmarks": [
        "MT-Bench Reasoning",
        "MT-Bench Math"
      ],
      "models": [
        "Critical-Questions-of-Thought (CQoT)",
        "Chain-of-Thought (CoT)",
        "Claude Sonnet 3.5",
        "GPT-4o",
        "Gemini 1.5-pro-001",
        "Llama 3.1-70b-Instruct",
        "Nemotron-51b-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Retrieval  Fine-Tuning for In-Context Tabular Models": {
    "filename": "Retrieval  Fine-Tuning for In-Context Tabular Models.pdf",
    "analysis": {
      "benchmarks": [
        "TabZilla",
        "OpenML",
        "adult-census",
        "electricity",
        "eeg-eye-state",
        "GesturePhaseSegmentationProcessed",
        "JapaneseVowels",
        "MagicTelescope",
        "MiniBooNE",
        "PhishingWebsites",
        "Satellite",
        "adult",
        "artificial-characters",
        "bank-marketing",
        "cardiotocography",
        "churn",
        "connect-4",
        "elevators",
        "first-order-theorem-proving",
        "jannis",
        "kc1",
        "kr-vs-kp",
        "magic",
        "mfeat-fourier",
        "mfeat-karhunen",
        "mfeat-morphological"
      ],
      "models": [
        "TabPFN",
        "LoCalPFN",
        "XGBoost",
        "CatBoost",
        "LightGBM",
        "RandomForest",
        "kNN",
        "TabPFN-kNN",
        "TabPFN-3k",
        "TabPFN-32ens",
        "TabPFN-3k-32ens",
        "TabPFN-3k-32ens-int",
        "TabPFN-ICD",
        "SAINT",
        "RIM",
        "TabR",
        "VIME"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluation is all you need Prompting Generative Large Language Models for Annotation Tasks in the Social Sciences A Primer using Open Models": {
    "filename": "Evaluation is all you need Prompting Generative Large Language Models for Annotation Tasks in the Social Sciences A Primer using Open Models.pdf",
    "analysis": {
      "benchmarks": [
        "SemEval-2017 Task 4 - Subtask A",
        "National Child Development Study"
      ],
      "models": [
        "neural-chat-7b-v3-2",
        "Starling-LM-7B-alpha",
        "openchat_3.5",
        "zephyr-7b-alpha",
        "zephyr-7b-beta"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Explanation Regeneration via Information Bottleneck": {
    "filename": "Explanation Regeneration via Information Bottleneck.pdf",
    "analysis": {
      "benchmarks": [
        "ECQA",
        "e-SNLI",
        "MIXEXPL",
        "ScienceQA",
        "Sen-Making",
        "LIAR-PLUS",
        "PubHealth",
        "E-\u03b4-NLI"
      ],
      "models": [
        "EIB",
        "SUPERVISED",
        "BOTTLE SUM",
        "PROMPTING",
        "PROMPTING-Filter",
        "PROMPTING-EIB",
        "PROMPTING-Filter-EIB"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Devil Is in the Errors Leveraging Large Language Models for Fine-grained Machine Translation Evaluation": {
    "filename": "The Devil Is in the Errors Leveraging Large Language Models for Fine-grained Machine Translation Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "WMT'22 Metrics Shared Task",
        "WMT'19 Metrics Shared Task",
        "WMT'21 Metrics Shared Task"
      ],
      "models": [
        "AUTO MQM",
        "PaLM",
        "PaLM-2",
        "PaLM-2 BISON",
        "PaLM-2 UNICORN",
        "FLAN-PaLM-2 UNICORN",
        "MetricX-XXL",
        "COMET-22",
        "COMET-QE",
        "MATES E",
        "MATES E-QE",
        "COMET-WL",
        "GEMBA",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AgentsCoDriver Large Language Model Empowered Collaborative Driving with Lifelong Learning": {
    "filename": "AgentsCoDriver Large Language Model Empowered Collaborative Driving with Lifelong Learning.pdf",
    "analysis": {
      "benchmarks": [
        "HighwayEnv",
        "V2X-SIM",
        "OPV2V",
        "DAIR-V2X"
      ],
      "models": [
        "AGENTS CODRIVER",
        "DiLu",
        "GPT-Driver",
        "Agent-Driver",
        "LanguageMPC",
        "F-Cooper",
        "V2VNet",
        "DiscoNet",
        "Where2comm"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Redefining Qualitative Analysis in the AI Era Utilizing ChatGPT for Efficient Thematic Analysis": {
    "filename": "Redefining Qualitative Analysis in the AI Era Utilizing ChatGPT for Efficient Thematic Analysis.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unlocking Large Language Models Planning Capabilities with Maximum Diversity Fine-tuning": {
    "filename": "Unlocking Large Language Models Planning Capabilities with Maximum Diversity Fine-tuning.pdf",
    "analysis": {
      "benchmarks": [
        "Blocksworld",
        "Logistics"
      ],
      "models": [
        "GPT-3.5-turbo",
        "Llama-3-8b",
        "Llama-2-7b",
        "MDFT-g",
        "MDFT-l",
        "Random"
      ]
    }
  },
  "Towards General Industrial Intelligence A Survey on IIoT-Enhanced Continual Large Models": {
    "filename": "Towards General Industrial Intelligence A Survey on IIoT-Enhanced Continual Large Models.pdf",
    "analysis": {
      "benchmarks": [
        "CWRU",
        "XJTU-SY",
        "MVTec-AD",
        "VisA",
        "HAD",
        "nuScenes",
        "NuPrompt",
        "NuScenes-QA"
      ],
      "models": [
        "GPT",
        "LLaMA",
        "LLaVA",
        "CLIP",
        "GPT4TS",
        "Time-LLM",
        "ViT",
        "ResNet",
        "SAM",
        "BLIP",
        "BLIP-2",
        "MiniGPT-4",
        "LLaMA-Adapter",
        "DriveLM",
        "SignalGPT",
        "DDPM",
        "FABRICATOR",
        "DYNOSAUR",
        "DEFT",
        "MeZO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Graph Foundation Models A Survey and Beyond": {
    "filename": "Towards Graph Foundation Models A Survey and Beyond.pdf",
    "analysis": {
      "benchmarks": [
        "node classification",
        "link prediction",
        "graph classification",
        "graph clustering",
        "molecular property prediction",
        "graph regression",
        "graph generation",
        "graph condensation",
        "average clustering coefficient prediction"
      ],
      "models": [
        "Graph Foundation Models (GFMs)",
        "GNN-based Models",
        "LLM-based Models",
        "GNN+LLM-based Models",
        "Graph Neural Networks (GNNs)",
        "Graph Convolutional Network (GCN)",
        "Graph Attention Network (GAT)",
        "GraphSAGE",
        "Heterogeneous Graph Transformer (HGT)",
        "Graph Isomorphism Network (GIN)",
        "Graph Transformer",
        "Graph-BERT",
        "GROVER",
        "Graphormer",
        "SimpleDyG",
        "CoBFormer",
        "Graph Control",
        "AdapterGNN",
        "G-Adapter",
        "G-TUNING",
        "GraphPrompt",
        "GraphPrompt+",
        "GCC",
        "GraphCL",
        "GraphMAE",
        "GraphMAE2",
        "GPT-GNN",
        "PT-HGNN",
        "CPT-HG",
        "FOTOM",
        "GraphControl",
        "All In One",
        "PRODIGY",
        "DGI",
        "GRACE",
        "VGAE",
        "MA-GCL",
        "MultiGPrompt",
        "IGAP",
        "HGPROMPT",
        "GPPT",
        "VPGNN",
        "GraphMAE",
        "GraphMAE2",
        "Graph-BERT",
        "GROVER",
        "G-Adapter"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations": {
    "filename": "Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations.pdf",
    "analysis": {
      "benchmarks": [
        "HaluSum2130",
        "HaluQA4170",
        "FactCC503",
        "SummEval",
        "QAGS-CNNDM",
        "QAGS-XSUM"
      ],
      "models": [
        "CoNLI-GPT3.5",
        "CoNLI-GPT4",
        "FactCC",
        "AlignScore-L",
        "HaluEval-GPT3.5",
        "HaluEval-GPT4",
        "CoNLI-3.5 (sent)",
        "CoNLI-3.5 (ent)",
        "CoNLI-3.5 (sent+ent)",
        "CoNLI-4 (sent)",
        "CoNLI-4 (ent)",
        "CoNLI-4 (sent+ent)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How to Determine the Preferred Image Distribution of a Black-Box Vision-Language Model": {
    "filename": "How to Determine the Preferred Image Distribution of a Black-Box Vision-Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "CAD-VQA"
      ],
      "models": [
        "GPT-4o",
        "Claude-3.5-Sonnet",
        "Gemini-1.5-Pro",
        "O1-preview"
      ]
    }
  },
  "LiveMind Low-latency Large Language Models with Simultaneous Inference": {
    "filename": "LiveMind Low-latency Large Language Models with Simultaneous Inference.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "MMLU-Pro"
      ],
      "models": [
        "LiveMind",
        "Llama-3-70B-Instruct",
        "Llama-3-8B-Instruct",
        "GPT-4o"
      ]
    }
  },
  "Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health": {
    "filename": "Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health.pdf",
    "analysis": {
      "benchmarks": [
        "CLPsych15",
        "Depression_Reddit",
        "Dreaddit",
        "SAD",
        "T-SID",
        "UMD",
        "SWMH",
        "CAMS"
      ],
      "models": [
        "MentalXLNet",
        "MentalLongformer",
        "BERT",
        "RoBERTa",
        "XLNet",
        "Longformer",
        "MentalBERT",
        "MentalRoBERTa",
        "ChatGPT ZS",
        "ChatGPT V",
        "ChatGPT N_sen",
        "ChatGPT N_emo",
        "ChatGPT CoT",
        "ChatGPT CoT_emo"
      ]
    }
  },
  "An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing": {
    "filename": "An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing.pdf",
    "analysis": {
      "benchmarks": [
        "Clinical Abbreviation Sense Inventories (CASI)",
        "EBM-NLP"
      ],
      "models": [
        "GPT-3.5",
        "BARD",
        "LLAMA2"
      ]
    }
  },
  "Adapting Large Multimodal Models to Distribution Shifts The Role of In-Context Learning": {
    "filename": "Adapting Large Multimodal Models to Distribution Shifts The Role of In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Camelyon17",
        "HAM10000",
        "NIH Chest",
        "COVID"
      ],
      "models": [
        "InvariantSelectPR",
        "TopKNearestPR",
        "RandomPR",
        "Gemini",
        "GPT-4V",
        "Claude 3 Opus"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Models Hallucinate but May Excel at Fact Verification": {
    "filename": "Language Models Hallucinate but May Excel at Fact Verification.pdf",
    "analysis": {
      "benchmarks": [
        "Wikipedia",
        "FEVER",
        "BoolQ-FV",
        "FM2",
        "PubMedQA",
        "XsumFaith",
        "SummEval",
        "SciFact",
        "FaVIQ"
      ],
      "models": [
        "GPT-3.5",
        "ChatGPT",
        "FLAN-T5 11B",
        "LLama 30B",
        "LLama 65B",
        "FiD",
        "NLI 11B",
        "FACTSCORE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Large Language Models to Detect npm Malicious Packages": {
    "filename": "Leveraging Large Language Models to Detect npm Malicious Packages.pdf",
    "analysis": {
      "benchmarks": [
        "MalwareBench"
      ],
      "models": [
        "SocketAI",
        "GPT-3",
        "GPT-4",
        "CodeQL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can GPT-3 Perform Statutory Reasoning": {
    "filename": "Can GPT-3 Perform Statutory Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "SARA"
      ],
      "models": [
        "GPT-3",
        "text-davinci-003",
        "BERT-based models"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "QualiGPT GPT as an easy-to-use tool for qualitative coding": {
    "filename": "QualiGPT GPT as an easy-to-use tool for qualitative coding.pdf",
    "analysis": {
      "benchmarks": [
        "simulated dataset",
        "real-world social media dataset"
      ],
      "models": [
        "QualiGPT",
        "ChatGPT (web version)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Stealing Attacks Against Large Language Models": {
    "filename": "Prompt Stealing Attacks Against Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "RetrievalQA",
        "Alpaca-GPT4"
      ],
      "models": [
        "ChatGPT",
        "LLaMA",
        "parameter extractor",
        "prompt reconstructor",
        "primary classifier",
        "sub-classifier for role-based prompts",
        "sub-classifier for in-context prompts"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Bridging Today and the Future of Humanity AI Safety in 2024 and Beyond": {
    "filename": "Bridging Today and the Future of Humanity AI Safety in 2024 and Beyond.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "ChatGPT",
        "LLMs",
        "DeepMind Weight Averaged Reward Models",
        "OpenAI Rule-based rewards",
        "PromptArmor",
        "Purple Llama",
        "DeepMind",
        "Anthropic",
        "Protect AI",
        "Giskard",
        "Virtue AI",
        "Dynamo AI",
        "Mindgard",
        "OpenAI Moderation API",
        "Perspective API",
        "Detoxify",
        "Llama Guard",
        "Emergence AI",
        "Calypso AI",
        "Lakera AI",
        "BreezeML",
        "Guardrails AI",
        "Nvidia Nemo Guardrails",
        "Private AI",
        "DataGrail",
        "Dastra",
        "OneTrust",
        "Relyance AI",
        "Zendata",
        "Transcend",
        "Saidot",
        "Arize",
        "Credo AI",
        "Google",
        "DeepMind SynthID watermark"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Review of Generative AI Methods in Cybersecurity": {
    "filename": "Review of Generative AI Methods in Cybersecurity.pdf",
    "analysis": {
      "benchmarks": [
        "CyberMetric",
        "QuixBugs",
        "HumanEval",
        "FormAI"
      ],
      "models": [
        "ChatGPT",
        "Google's Gemini",
        "YandexGPT",
        "MIT's Norman",
        "FunSearch",
        "PentestGPT",
        "SecurityLLM",
        "FalconLLM",
        "SecurityBERT",
        "Codex",
        "GPT-3",
        "GPT-4",
        "Llama2",
        "Wintermute",
        "WolfGPT",
        "XXXGPT",
        "WormGPT",
        "01.ai"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dissecting Dissonance Benchmarking Large Multimodal Models Against Self-Contradictory Instructions": {
    "filename": "Dissecting Dissonance Benchmarking Large Multimodal Models Against Self-Contradictory Instructions.pdf",
    "analysis": {
      "benchmarks": [
        "Self-Contradictory Instructions (SCI)",
        "ImageNet"
      ],
      "models": [
        "Claude 3",
        "Gemini 1.5 Pro",
        "ChatGLM",
        "ChatGPT",
        "GPT-4",
        "Llama 2",
        "GLM-4",
        "GPT-4V",
        "LLaVA-1.5",
        "LLaMA-Adapter V2",
        "BLIP-2",
        "SPHINX-v2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MobileSafetyBench Evaluating Safety of Autonomous Agents in Mobile Device Control": {
    "filename": "MobileSafetyBench Evaluating Safety of Autonomous Agents in Mobile Device Control.pdf",
    "analysis": {
      "benchmarks": [
        "MobileSafetyBench"
      ],
      "models": [
        "GPT-4o",
        "Gemini-1.5-Pro",
        "Claude-3.5-Sonnet",
        "Safety-guided Chain-of-Thought (SCoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Human-in-the-Loop through Chain-of-Thought": {
    "filename": "Human-in-the-Loop through Chain-of-Thought.pdf",
    "analysis": {
      "benchmarks": [
        "AddSub",
        "MultiArith",
        "SingleEq",
        "SingleOp",
        "ASDiv",
        "AQUA-RAT",
        "GSM8K",
        "CommonsensQA",
        "StrategyQA",
        "Last Letter Concatenation",
        "Coinflip"
      ],
      "models": [
        "Manual Correction System (MCS)",
        "Cost-utility Analysis Model for Human-in-the-Loop systems (CAMLOP)",
        "CoT-prompting",
        "Self-consistency",
        "MCS + Self-consistency"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them": {
    "filename": "Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-Bench",
        "BIG-Bench Hard (BBH)"
      ],
      "models": [
        "PaLM",
        "Codex (code-davinci-002)",
        "InstructGPT (text-davinci-002)",
        "GPT-3",
        "Gopher",
        "text-curie-002",
        "text-babbage-001",
        "text-ada-001",
        "code-cushman-001",
        "PaLM 8B",
        "PaLM 62B",
        "PaLM 540B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LyricWhiz Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT": {
    "filename": "LyricWhiz Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "Jamendo",
        "Hansen",
        "MUSDB18",
        "DSing",
        "MulJam",
        "MTG-Jamendo"
      ],
      "models": [
        "LyricWhiz",
        "Whisper",
        "GPT-4",
        "TDNN-F",
        "CTDNN-SA",
        "Genre-informed AM",
        "MSTRE-Net",
        "DE2-segmented",
        "W2V2-ALT"
      ]
    }
  },
  "The importance of visual modelling languages in generative software engineering": {
    "filename": "The importance of visual modelling languages in generative software engineering.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "Copilot",
        "ChatGPT",
        "gemini-1.5-flash"
      ]
    }
  },
  "Understanding the planning of LLM agents A survey": {
    "filename": "Understanding the planning of LLM agents A survey.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld",
        "ScienceWorld",
        "HotPotQA",
        "FEVER",
        "Minecraft",
        "WebShop",
        "Mind2Web",
        "WebArena",
        "Agent Bench",
        "MiniWoB++"
      ],
      "models": [
        "CoT",
        "ReAct",
        "HuggingGPT",
        "Plan-and-Solve",
        "ProgPrompt",
        "ZeroShot-CoT",
        "Fewshot-CoT",
        "CoT-SC",
        "SayCan",
        "Reflexion",
        "CRITIC",
        "InteRecAgent",
        "LEMA",
        "REMEMBER",
        "Generative Agents",
        "MemoryBank",
        "TiM",
        "RecMind",
        "MemGPT",
        "LLM+P",
        "LLM-DP",
        "LLM+PDDL",
        "LLM+ASP",
        "DRRN",
        "Decision Transformer",
        "CALM",
        "SwiftSage",
        "Tree-of-Thought",
        "Graph-of-Thought",
        "LLM-MCTS",
        "RAP",
        "LLM A*",
        "Self-refine",
        "AgentTuning"
      ]
    }
  },
  "From Models to Microtheories Distilling a Models Topical Knowledge for Grounded Question Answering": {
    "filename": "From Models to Microtheories Distilling a Models Topical Knowledge for Grounded Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "ARC",
        "MedQA"
      ],
      "models": [
        "microtheory",
        "GPT-4",
        "Mixtral-8x22B-Instruct-v0.1",
        "TREEWISE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Text2Reward Reward Shaping with Language Models for Reinforcement Learning": {
    "filename": "Text2Reward Reward Shaping with Language Models for Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "MANISKILL 2",
        "METAWORLD",
        "MUJOCO",
        "Gym MUJOCO"
      ],
      "models": [
        "TEXT2REWARD",
        "PPO",
        "SAC",
        "L2R"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Compresso Structured Pruning with Collaborative Prompting Learns Compact Large Language Models": {
    "filename": "Compresso Structured Pruning with Collaborative Prompting Learns Compact Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "commonsense reasoning",
        "reading comprehension",
        "MMLU",
        "BBH",
        "StoryCloze",
        "PIQA",
        "HellaSwag",
        "WinoGrande",
        "ARC easy",
        "ARC challenge",
        "OpenBookQA",
        "BoolQ",
        "RACE-High"
      ],
      "models": [
        "Compresso",
        "LLaMA-7B",
        "LLM-Pruner",
        "SparseGPT",
        "Wanda"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Are Emergent Abilities in Large Language Models just In-Context Learning": {
    "filename": "Are Emergent Abilities in Large Language Models just In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Social IQA",
        "BIG-bench",
        "GSM8K"
      ],
      "models": [
        "GPT-2",
        "GPT-2-XL",
        "GPT-J",
        "davinci",
        "T5-small",
        "T5-large",
        "Falcon-7B",
        "Falcon-40B",
        "LLaMA-7B",
        "LLaMA-13B",
        "LLaMA-30B",
        "Flan-T5-small",
        "Flan-T5-large",
        "GPT-2-IT",
        "GPT-2-XL-IT",
        "GPT-JT",
        "text-davinci-001",
        "text-davinci-003",
        "Falcon-7B-Instruct",
        "Falcon-40B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding the Interplay between Parametric and Contextual Knowledge for Large Language Models": {
    "filename": "Understanding the Interplay between Parametric and Contextual Knowledge for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ECHOQA",
        "ALCUNA",
        "ConflictQA",
        "MuSiQue",
        "OpenBookQA"
      ],
      "models": [
        "OpenAI o1",
        "GPT-4o",
        "GPT-4o-mini",
        "Llama 3.1-70B",
        "Llama 3.1-8B",
        "Qwen 2-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Factor-Conditioned Speaking-Style Captioning": {
    "filename": "Factor-Conditioned Speaking-Style Captioning.pdf",
    "analysis": {
      "benchmarks": [
        "PromptTTS",
        "LibriTTS"
      ],
      "models": [
        "Factor-Conditioned Captioning (FCC)",
        "Greedy-then-Sampling (GtS)",
        "StyleCap",
        "Whisper large-v3",
        "TLTR-utt",
        "LLaMA-2 7B-chat-LoRA",
        "WavLM-base-plus",
        "WavLM-large",
        "HuBERT-large",
        "7B-chat",
        "7B-chat-LoRA"
      ]
    }
  },
  "Video as the New Language for Real-World Decision Making": {
    "filename": "Video as the New Language for Real-World Decision Making.pdf",
    "analysis": {
      "benchmarks": [
        "Arcade Learning Environment",
        "MineDojo",
        "Open X-Embodiment"
      ],
      "models": [
        "autoregressive model",
        "diffusion model",
        "masked transformer model",
        "transformer-based architecture",
        "video pretraining (VPT)",
        "latent actions/skills model",
        "Dyna",
        "Dreamer",
        "MuZero",
        "Genie",
        "STEM data model",
        "video generation model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Words2Contact Identifying Support Contacts from Verbal Instructions Using Foundation Models": {
    "filename": "Words2Contact Identifying Support Contacts from Verbal Instructions Using Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "Words2Contact dataset"
      ],
      "models": [
        "Words2Contact",
        "Calme-7b-Instruct",
        "mixtao-7bx2-moe",
        "GPT-3.5-turbo",
        "CLIPSeg",
        "CLIP Surgery",
        "GroundingDINO",
        "Florence-2",
        "SEIKO"
      ]
    }
  },
  "From Artificial Needles to Real Haystacks Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data": {
    "filename": "From Artificial Needles to Real Haystacks Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data.pdf",
    "analysis": {
      "benchmarks": [
        "20 documents MDQA",
        "FLenQA",
        "MMLU",
        "HellaSwag",
        "GSM8K",
        "TriviaQA",
        "NQ-Open",
        "MultidocQA",
        "IN2",
        "Needle-in-a-haystack"
      ],
      "models": [
        "GPT-3.5 Turbo",
        "Mistral 7B",
        "Mistral-7B-Instruct-v0.1",
        "Mistral-7b-Instruct-v0.2",
        "ft on key-value retrieval (w/ template)",
        "ft on key-value retrieval (w/o template)",
        "ft on MDQA"
      ]
    }
  },
  "Can Separators Improve Chain-of-Thought Prompting": {
    "filename": "Can Separators Improve Chain-of-Thought Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "AQuA",
        "CSQA"
      ],
      "models": [
        "GPT-3.5-Turbo",
        "GPT-4",
        "LLaMA-2 7B",
        "Vanilla CoT",
        "COT-SEP",
        "Heterogeneous COT-SEP"
      ]
    }
  },
  "Understanding LLMs A Comprehensive Overview from Training to Inference": {
    "filename": "Understanding LLMs A Comprehensive Overview from Training to Inference.pdf",
    "analysis": {
      "benchmarks": [
        "CommonCrawl",
        "C4",
        "CC-Stories",
        "CC-News",
        "RealNews",
        "WebText",
        "OpenWebText",
        "PushShift.io",
        "Wikipedia",
        "BigQuery",
        "CodeParrot",
        "the Pile",
        "ROOTS",
        "BookCorpus",
        "Gutenberg",
        "Books1",
        "Books2",
        "RefinedWeb",
        "Social Media",
        "Webpages",
        "News",
        "Arxiv",
        "StackExchange",
        "Github",
        "Books",
        "Natural instructions",
        "P3",
        "Promptsource",
        "WebGPT",
        "Flan",
        "MVPCorpus"
      ],
      "models": [
        "GPT-3",
        "LLaMA",
        "PaLM",
        "T5",
        "CodeGen",
        "CodeGeeX",
        "GLM",
        "BLOOM",
        "OPT",
        "flan-T5",
        "BART",
        "Gopher"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Guiding Enumerative Program Synthesis with Large Language Models": {
    "filename": "Guiding Enumerative Program Synthesis with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Syntax-Guided Synthesis (SyGuS) competition"
      ],
      "models": [
        "GPT-3.5",
        "enumerative synthesizer",
        "cvc5",
        "pCFG-synth",
        "A*-pCFG-synth",
        "iLLM-synth",
        "e-pCFG-synth",
        "A*-iLLM-synth"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Generate Train PGT Few-shot Domain Adaption of Retrieval Augmented Generation Models for Open Book Question-Answering": {
    "filename": "Prompt Generate Train PGT Few-shot Domain Adaption of Retrieval Augmented Generation Models for Open Book Question-Answering.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Prompt Generate Train (PGT)",
        "Retriever Augmented Generation (RAG)",
        "ColBERTv2",
        "Flan-T5",
        "Flan-TF XXL",
        "GPT-4",
        "BERT",
        "Reward model"
      ]
    }
  },
  "Agent Skill Acquisition for Large Language Models via CycleQD": {
    "filename": "Agent Skill Acquisition for Large Language Models via CycleQD.pdf",
    "analysis": {
      "benchmarks": [
        "AgentBench"
      ],
      "models": [
        "CycleQD",
        "LLaMA 3-8B-INSTRUCT",
        "GPT-3.5-TURBO",
        "Segment Anything Model (SAM)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Decoding ChatGPT A Taxonomy of Existing Research Current Challenges and Possible Future Directions": {
    "filename": "Decoding ChatGPT A Taxonomy of Existing Research Current Challenges and Possible Future Directions.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-1",
        "GPT-2",
        "GPT-3",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CoD Towards an Interpretable Medical Agent using Chain of Diagnosis": {
    "filename": "CoD Towards an Interpretable Medical Agent using Chain of Diagnosis.pdf",
    "analysis": {
      "benchmarks": [
        "Muzhi Dataset",
        "Dxy Dataset",
        "DxBench"
      ],
      "models": [
        "DiagnosisGPT",
        "Basic DQN",
        "HRL",
        "Diaformer",
        "MTDiag",
        "Yi-34B-Chat",
        "GPT-3.5",
        "Mixtral-8x7B-Instruct-v0.1",
        "ERNIE Bot",
        "Gemini-Pro",
        "GPT-4",
        "Claude-3-Opus"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Best Defense is a Good Offense Countering LLM-Powered Cyberattacks": {
    "filename": "The Best Defense is a Good Offense Countering LLM-Powered Cyberattacks.pdf",
    "analysis": {
      "benchmarks": [
        "PurpleLlama"
      ],
      "models": [
        "PentestGPT",
        "HackingBuddyGPT",
        "AutoAttacker",
        "PenHeal",
        "GPT-4o",
        "Claude Sonnet 3.5",
        "Gemini Pro 1.5",
        "LLaMA 3.1 70B Instruct2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Does Reasoning Emerge Examining the Probabilities of Causation in Large Language Models": {
    "filename": "Does Reasoning Emerge Examining the Probabilities of Causation in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Div6",
        "EvenSum",
        "CandyParty"
      ],
      "models": [
        "GPT-2",
        "GPT-3.5-turbo",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Distilling Script Knowledge from Large Language Models for Constrained Language Planning": {
    "filename": "Distilling Script Knowledge from Large Language Models for Constrained Language Planning.pdf",
    "analysis": {
      "benchmarks": [
        "CoScript",
        "wikiHow",
        "proScript"
      ],
      "models": [
        "InstructGPT",
        "GPT-3",
        "PaLM",
        "T5",
        "Codex",
        "Flan-T5",
        "T0",
        "GPT-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Summarization Programs Interpretable Abstractive Summarization with Neural Modular Trees": {
    "filename": "Summarization Programs Interpretable Abstractive Summarization with Neural Modular Trees.pdf",
    "analysis": {
      "benchmarks": [
        "CNN/DailyMail",
        "XSum"
      ],
      "models": [
        "Summarization Program (SP)",
        "SP-SEARCH",
        "Extract-and-Build SP generation model",
        "Joint SP generation model",
        "BART",
        "PEGASUS",
        "MatchSum",
        "Random SP",
        "SP-SEARCH Top-1",
        "SP-SEARCH Leaves",
        "BART-Oracle"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AnalogCoder Analog Circuit Design via Training-Free Code Generation": {
    "filename": "AnalogCoder Analog Circuit Design via Training-Free Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "AnalogCoder benchmark",
        "ChipChat benchmark",
        "VeriGen benchmark"
      ],
      "models": [
        "AnalogCoder",
        "GPT-4o",
        "Llama 3-70B",
        "DeepSeek-V2",
        "GPT 3.5 (w/o flow)",
        "GPT 3.5 (SPICE)",
        "GPT 3.5",
        "WizardCoder-33B",
        "CodeQwen-7B",
        "Llama 2-70B",
        "GPT 4",
        "Mixtral-8\u00d77B",
        "CodeLlama-70B",
        "CodeLlama-70B-Instruct",
        "Wizardcoder-33B-V1.1",
        "Llama3-70B",
        "DeepSeek-V2",
        "GPT-3.5-turbo",
        "GPT-4-turbo",
        "GPT-4o",
        "GPT3.5 (SPICE)",
        "GPT3.5 (w/o context)",
        "GPT3.5 (w/o CoT)",
        "GPT3.5 (w/o flow)",
        "GPT3.5 (fine-tune)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "UGIF UI Grounded Instruction Following": {
    "filename": "UGIF UI Grounded Instruction Following.pdf",
    "analysis": {
      "benchmarks": [
        "UGIF-DataSet",
        "PixelHelp"
      ],
      "models": [
        "PaLM",
        "GPT-3",
        "T5",
        "UL2",
        "LaBSE",
        "UiBERT"
      ]
    }
  },
  "Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation": {
    "filename": "Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation.pdf",
    "analysis": {
      "benchmarks": [
        "LogicNLI",
        "FOLIO"
      ],
      "models": [
        "LOGIC LLAMA",
        "GPT-3.5",
        "GPT-4",
        "LLaMA-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Resolving Crash Bugs via Large Language Models An Empirical Study": {
    "filename": "Resolving Crash Bugs via Large Language Models An Empirical Study.pdf",
    "analysis": {
      "benchmarks": [
        "QuixBugs",
        "Defects4j",
        "ManySStuBs4J",
        "UnifiedBugDataset",
        "Stack Overflow (SO) threads"
      ],
      "models": [
        "ChatGPT",
        "IntDiagSolver",
        "Claude",
        "CodeLlama",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Lets reward step by step Step-Level reward model as the Navigators for Reasoning": {
    "filename": "Lets reward step by step Step-Level reward model as the Navigators for Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "MBPP",
        "HumanEval"
      ],
      "models": [
        "Process-Supervised Reward Model (PRM)",
        "Chain of Thought (CoT)",
        "WizardMath-13B",
        "LLaMA-7B",
        "LLaMA-13B",
        "Code-LLaMA-Python-7B",
        "Code-LLaMA-Python-13B",
        "Star-Coder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From News to Forecast Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection": {
    "filename": "From News to Forecast Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection.pdf",
    "analysis": {
      "benchmarks": [
        "Traffic",
        "Exchange",
        "Bitcoin",
        "Electricity"
      ],
      "models": [
        "LLM-based agents",
        "GPT-4 Turbo",
        "TEMPO",
        "TIME-LLM",
        "FPT",
        "Lag-LLaMa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SpatialVLM Endowing Vision-Language Models with Spatial Reasoning Capabilities": {
    "filename": "SpatialVLM Endowing Vision-Language Models with Spatial Reasoning Capabilities.pdf",
    "analysis": {
      "benchmarks": [
        "VQAv2",
        "OK-VQA",
        "COCO",
        "Visual Genome"
      ],
      "models": [
        "SpatialVLM",
        "GPT-4V",
        "PaLI",
        "PaLM-E",
        "PaLM2-E",
        "LLaVA-1.5",
        "InstructBLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction": {
    "filename": "Controlled Generation with Prompt Insertion for Natural Language Explanations in Grammatical Error Correction.pdf",
    "analysis": {
      "benchmarks": [
        "NUCLE",
        "CoNLL2013",
        "CoNLL2014",
        "W&I",
        "JFLEG",
        "XGEC"
      ],
      "models": [
        "GPT-3",
        "ChatGPT",
        "GPT-3.5",
        "ChatGPTPost w/ PI",
        "Post w/o PI",
        "Pre w/o PI",
        "GPT-3.5Post w/ IP",
        "Post w/o IP",
        "Pre w/o IP"
      ]
    }
  },
  "MSCoTDet Language-driven Multi-modal Fusion for Improved Multispectral Pedestrian Detection": {
    "filename": "MSCoTDet Language-driven Multi-modal Fusion for Improved Multispectral Pedestrian Detection.pdf",
    "analysis": {
      "benchmarks": [
        "FLIR",
        "CVC-14",
        "ROTX-MP"
      ],
      "models": [
        "MSCoTDet",
        "Halfway Fusion",
        "CFT",
        "Kim et al.",
        "ProbEn",
        "CMM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Validation of the Scientific Literature via Chemputation Augmented by Large Language Models": {
    "filename": "Validation of the Scientific Literature via Chemputation Augmented by Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Reaxys database",
        "Open Reaction Database (ORD)",
        "10 scientific publications",
        "organic chemistry PhD thesis",
        "German undergraduate practical transcript"
      ],
      "models": [
        "Autonomous Chemputer Reaction Agents (ACRA)",
        "GPT-4",
        "GPT-4-mini",
        "XDL-agent",
        "scraping-agent",
        "procedure-agent",
        "critique-agent"
      ]
    }
  },
  "Fix the Tests Augmenting LLMs to Repair Test Cases with Static Collector and Neural Reranker": {
    "filename": "Fix the Tests Augmenting LLMs to Repair Test Cases with Static Collector and Neural Reranker.pdf",
    "analysis": {
      "benchmarks": [
        "benchmark dataset",
        "C EPROT dataset"
      ],
      "models": [
        "SYNTER",
        "CEPROT",
        "NAIVELLM",
        "GPT-4",
        "CodeT5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoPRM Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition": {
    "filename": "AutoPRM Automating Procedural Supervision for Multi-Step Reasoning via Controllable Question Decomposition.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "StrategyQA"
      ],
      "models": [
        "AutoPRM",
        "WizardMath",
        "MetaMath",
        "Distilling-LM",
        "ORM-RL",
        "PRM-RL",
        "LLaMA-2-70B",
        "LLaMA-2-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MotionLLaMA A Unified Framework for Motion Synthesis and Comprehension": {
    "filename": "MotionLLaMA A Unified Framework for Motion Synthesis and Comprehension.pdf",
    "analysis": {
      "benchmarks": [
        "MotionHub",
        "AIST++",
        "FineDance",
        "BEAT2"
      ],
      "models": [
        "MotionLLaMA",
        "MotionGPT",
        "LMM",
        "UDE2",
        "UniMuMo",
        "M3GPT",
        "MotionAgent",
        "TM2T",
        "MDM",
        "MotionDiffuse",
        "MCM",
        "MoMask",
        "ComMDM",
        "InterGen",
        "FACT",
        "Bailando",
        "EDGE",
        "Foley",
        "CMT",
        "D2MGAN",
        "CDCD",
        "LORIS",
        "CaMN",
        "DiffStyleGesture"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Is ChatGPT a Good Sentiment Analyzer A Preliminary Study": {
    "filename": "Is ChatGPT a Good Sentiment Analyzer A Preliminary Study.pdf",
    "analysis": {
      "benchmarks": [
        "SST-2",
        "SemEval 2014-ABSA Challenge Datasets",
        "Camera dataset",
        "Emotion Cause Dataset",
        "14-Restaurant",
        "14-Laptop",
        "14-Res-Negation",
        "14-Lap-Negation",
        "14-Res-Speculation",
        "14-Lap-Speculation",
        "Restaurant",
        "Laptop",
        "Device",
        "Service",
        "Books",
        "Clothing",
        "Hotel",
        "Twitter",
        "Financial News Headlines",
        "METS-CoV"
      ],
      "models": [
        "ChatGPT",
        "BERT",
        "T5-11B",
        "DPL",
        "RILGNet",
        "SyMux",
        "Multi-Stage BERT",
        "GAS-Extraction-style",
        "PAE-DGL",
        "ECPE-2D"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TAROT Targeted Data Selection via Optimal Transport": {
    "filename": "TAROT Targeted Data Selection via Optimal Transport.pdf",
    "analysis": {
      "benchmarks": [
        "nuScenes",
        "Waymo",
        "Cityscapes",
        "GTA5",
        "CIFAR-10",
        "MMLU",
        "BBH",
        "Argoverse 2",
        "nuPlan"
      ],
      "models": [
        "TAROT",
        "DeepLabV3",
        "ResNet-9",
        "AutoBots",
        "Wayformer",
        "LLAMA-3.1-8B",
        "QWEN-2.5-7B",
        "LESS",
        "DsDm",
        "TRAK"
      ]
    }
  },
  "Exploring Question Decomposition for Zero-Shot VQA": {
    "filename": "Exploring Question Decomposition for Zero-Shot VQA.pdf",
    "analysis": {
      "benchmarks": [
        "VQA-Introspect",
        "A-OKVQA",
        "ArtVQA",
        "OK-VQA",
        "SLAKE",
        "Winoground",
        "PathVQA",
        "VQA Rad"
      ],
      "models": [
        "BLIP-2",
        "FLAN-T5",
        "FLAN-T5-small",
        "FLAN-T5-base",
        "FLAN-T5-large",
        "FLAN-T5-xl",
        "FLAN-T5-xxl",
        "Galactica",
        "BLIP2_flant5xl",
        "BLIP2_flant5xxl"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Redefining crowdsourced test report prioritization An innovative approach with large language model": {
    "filename": "Redefining crowdsourced test report prioritization An innovative approach with large language model.pdf",
    "analysis": {
      "benchmarks": [
        "MoocTest"
      ],
      "models": [
        "LLMPrior",
        "DeepPrior",
        "BERT",
        "XLNet",
        "DirectLLMPrior",
        "SimpleLLMPrior"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Consistent Language Models Using Declarative Constraints": {
    "filename": "Towards Consistent Language Models Using Declarative Constraints.pdf",
    "analysis": {
      "benchmarks": [
        "CommonGen"
      ],
      "models": [
        "Llama-2",
        "NeuroLogic",
        "Sequential Monte Carlo (SMC)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "V-RECS a Low-Cost LLM4VIS Recommender with Explanations Captioning and Suggestions": {
    "filename": "V-RECS a Low-Cost LLM4VIS Recommender with Explanations Captioning and Suggestions.pdf",
    "analysis": {
      "benchmarks": [
        "NvBench"
      ],
      "models": [
        "V-RECS",
        "GPT-4",
        "Llama-2-7B",
        "NcNet",
        "Codex",
        "ChatGPT",
        "FLAN-T5-XL",
        "TableGPT",
        "SheetCopilot",
        "VL2NL",
        "Datatales"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Retrieval Meets Reasoning Even High-school Textbook Knowledge Benefits Multimodal Reasoning": {
    "filename": "Retrieval Meets Reasoning Even High-school Textbook Knowledge Benefits Multimodal Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "ScienceQA",
        "A-OKVQA",
        "MMBench",
        "SEED-Bench"
      ],
      "models": [
        "RMR",
        "LLaVA",
        "Qwen-VL",
        "InternLM-XComposer2-VL",
        "Gemini",
        "MCAN",
        "Top-Down",
        "BAN",
        "DFAF",
        "ViLT",
        "Patch-TRM",
        "VisualBERT",
        "UnifiedQA Base",
        "UnifiedQA Base w/ CoT",
        "GPT-3.5",
        "GPT-3.5 w/ CoT",
        "ChatGPT w/ CoT",
        "GPT-4 w/ CoT",
        "Chameleon + ChatGPT",
        "Chameleon + GPT-4",
        "Pythia",
        "ViLBERT",
        "LXMERT",
        "KRISP",
        "GPV-2",
        "BLIP-2",
        "PaLM-CoT",
        "PICa",
        "IPVR",
        "PromptCap",
        "Prophet",
        "PaLI-3-VPD",
        "PaLI-X-VPD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Bias and Fairness in Large Language Models A Survey": {
    "filename": "Bias and Fairness in Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TAIA Large Language Models are Out-of-Distribution Data Learners": {
    "filename": "TAIA Large Language Models are Out-of-Distribution Data Learners.pdf",
    "analysis": {
      "benchmarks": [
        "MMedBench",
        "CMExam",
        "CoT-Collection",
        "MATH",
        "BBH",
        "CommonsenseQA",
        "LogiQA",
        "SVAMP",
        "MMedBench",
        "MMLU",
        "C-Eval",
        "Advbench",
        "AlpacaEval"
      ],
      "models": [
        "Qwen1.5-1.8B",
        "Qwen1.5-1.8B Vanilla",
        "Qwen1.5-1.8B TAIA",
        "Qwen1.5-7B",
        "Qwen1.5-7B Vanilla",
        "Qwen1.5-7B TAIA",
        "LLaMA2-7B",
        "LLaMA3-8B",
        "TAIA",
        "TOA",
        "LoRA",
        "MoLoRA",
        "TAIF",
        "TOF"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Theory of Emergent In-Context Learning as Implicit Structure Induction": {
    "filename": "A Theory of Emergent In-Context Learning as Implicit Structure Induction.pdf",
    "analysis": {
      "benchmarks": [
        "FUNCTION EVALUATION",
        "PROPOSITIONAL",
        "INVERSE",
        "COMPOSITION",
        "RELATION CLASSIFICATION",
        "CHAIN-OF-THOUGHT"
      ],
      "models": [
        "HMM5",
        "FVPROMPT",
        "HMMPERDOC",
        "COMPOSITIONAL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Querying Large Language Models with SQL": {
    "filename": "Querying Large Language Models with SQL.pdf",
    "analysis": {
      "benchmarks": [
        "Spider"
      ],
      "models": [
        "Galois",
        "Flan-T5-large",
        "TK-instruct-large",
        "InstructGPT-3",
        "GPT-3.5-turbo",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reasoning with Language Model is Planning with World Model": {
    "filename": "Reasoning with Language Model is Planning with World Model.pdf",
    "analysis": {
      "benchmarks": [
        "Blocksworld",
        "GSM8K",
        "PrOntoQA"
      ],
      "models": [
        "Reasoning via Planning (RAP)",
        "Chain-of-Thought (CoT)",
        "Least-to-Most prompting",
        "GPT-4",
        "LLaMA-33B",
        "Llama-2 70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt-Enhanced Software Vulnerability Detection Using ChatGPT": {
    "filename": "Prompt-Enhanced Software Vulnerability Detection Using ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "Software Assurance Reference Dataset (SARD)",
        "National Vulnerability Database (NVD)"
      ],
      "models": [
        "ChatGPT",
        "CFGNN",
        "Bugram"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Distill or Annotate Cost-Efficient Fine-Tuning of Compact Models": {
    "filename": "Distill or Annotate Cost-Efficient Fine-Tuning of Compact Models.pdf",
    "analysis": {
      "benchmarks": [
        "WLP",
        "STANCEOSAURUS",
        "FEVER",
        "MULTI PIT Id",
        "MULTI PIT Gen",
        "NATURAL QUESTIONS"
      ],
      "models": [
        "T5-XXL",
        "T5-Small",
        "GPT-3.5",
        "T5-Small (Ann.)",
        "T5-XXL [performance]\u21d2T5-Small (Dist.)",
        "T5-Small \u21d2T5-Small (Self-Dist.)",
        "T5-XXL \u21d2T5-Small (Dist.)",
        "T5-Base",
        "T5-Large",
        "T5-XL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TAGCOS Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data": {
    "filename": "TAGCOS Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data.pdf",
    "analysis": {
      "benchmarks": [
        "TydiQA",
        "MMLU",
        "BBH"
      ],
      "models": [
        "TAGCOS",
        "Llama-2-7B",
        "Mistral-7B",
        "Uniform",
        "Hardest Sampling",
        "Perplexity Sampling",
        "K-Center BERT",
        "K-Center Llama",
        "K-Center Grad",
        "OMP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Paralinguistics-Aware Speech-Empowered Large Language Models for Natural Conversation": {
    "filename": "Paralinguistics-Aware Speech-Empowered Large Language Models for Natural Conversation.pdf",
    "analysis": {
      "benchmarks": [
        "DailyTalk",
        "CREMA-D",
        "LibriSpeech"
      ],
      "models": [
        "Unified Spoken Dialog Model (USDM)",
        "From Scratch",
        "Cascaded",
        "SpeechGPT",
        "Mistral-7B",
        "whisper-large-v3",
        "unit-Voicebox",
        "BigVGAN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Specializing Smaller Language Models towards Multi-Step Reasoning": {
    "filename": "Specializing Smaller Language Models towards Multi-Step Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MultiArith",
        "ASDiv",
        "SVAMP",
        "BigBench Hard"
      ],
      "models": [
        "GPT-3.5",
        "T5",
        "FlanT5",
        "UL2",
        "code-davinci-002",
        "LaMDA",
        "PaLM",
        "UL2",
        "FlanT5-XXL",
        "FlanT5-XL",
        "FlanT5-Large",
        "FlanT5-Base",
        "Magister22",
        "Shridhar22",
        "Ho22"
      ]
    }
  },
  "Robust Planning with LLM-Modulo Framework Case Study in Travel Planning": {
    "filename": "Robust Planning with LLM-Modulo Framework Case Study in Travel Planning.pdf",
    "analysis": {
      "benchmarks": [
        "Travel Planning Benchmark"
      ],
      "models": [
        "GPT-3.5-Turbo",
        "GPT-4-Turbo",
        "Chain of Thought",
        "ReAct",
        "Reflexion",
        "LLM Modulo [All] GPT-3.5-Turbo",
        "LLM Modulo [Common] GPT-3.5-Turbo",
        "LLM Modulo [Hard] GPT-3.5-Turbo",
        "LLM Modulo [Json] GPT-3.5-Turbo",
        "LLM Modulo [All] GPT-4-Turbo"
      ]
    }
  },
  "BadRobot Manipulating Embodied LLMs in the Physical World": {
    "filename": "BadRobot Manipulating Embodied LLMs in the Physical World.pdf",
    "analysis": {
      "benchmarks": [
        "malicious physical action queries benchmark"
      ],
      "models": [
        "BADROBOT",
        "Voxposer",
        "Code as Policies",
        "ProgPrompt",
        "Visual Programming",
        "GPT-4-turbo",
        "GPT-3.5-turbo",
        "GPT4o",
        "Yi-vision",
        "Llava-1.5-7b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks": {
    "filename": "Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA-USMLE",
        "StrategyQA",
        "OpenbookQA"
      ],
      "models": [
        "KARD",
        "small T5",
        "small GPT",
        "Flan-T5",
        "OPT",
        "OPT-IML",
        "Reasoning Distillation",
        "Few-shot In-context Learning",
        "Few-shot In-context Learning + Chain-of-Thought",
        "Knowledge-Augmented Few-shot + CoT",
        "Fine-tuning",
        "Knowledge-Augmented Fine-tuning",
        "RAG + RD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Looped Transformers as Programmable Computers": {
    "filename": "Looped Transformers as Programmable Computers.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Looped Transformer",
        "SUBLEQ Transformer",
        "FLEQ Transformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Combining Cognitive and Generative AI for Self-Explanation in Interactive AI Agents": {
    "filename": "Combining Cognitive and Generative AI for Self-Explanation in Interactive AI Agents.pdf",
    "analysis": {
      "benchmarks": [
        "bank of 66 questions"
      ],
      "models": [
        "Virtual Experimental Research Assistant (VERA)",
        "ChatGPT",
        "LangChain",
        "Chain-of-Thought",
        "Ask-TMK"
      ]
    }
  },
  "The Sound of Healthcare Improving Medical Transcription ASR Accuracy with Large Language Models": {
    "filename": "The Sound of Healthcare Improving Medical Transcription ASR Accuracy with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "PriMock57"
      ],
      "models": [
        "Google Cloud's Medical Conversation model (GCMC)",
        "Google Cloud's Chirp",
        "OpenAI's Whisper 1",
        "Amazon Transcribe Medical",
        "Soniox en v2",
        "Deepgram's Nova 2",
        "Google Cloud's Gemini Pro",
        "Google Cloud's Gemini Ultra",
        "Google Cloud's Text Bison 32k",
        "Anthropic's Claude V2",
        "OpenAI's GPT-4",
        "Meta's LLaMA 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards the Scalable Evaluation of Cooperativeness in Language Models": {
    "filename": "Towards the Scalable Evaluation of Cooperativeness in Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Winogenerated dataset"
      ],
      "models": [
        "UnifiedQA",
        "GPT-3",
        "text-davinci-002",
        "text-davinci-003"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "forallutoexistsval Autonomous Assessment of LLMs in Formal Synthesis and Interpretation Tasks": {
    "filename": "forallutoexistsval Autonomous Assessment of LLMs in Formal Synthesis and Interpretation Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "3-SAT",
        "Propositional Logic",
        "First-order Logic (Synthetic)",
        "First-order Logic (English)",
        "Regular Expression"
      ],
      "models": [
        "GPT-4o",
        "GPT-3.5-turbo",
        "Claude Sonnet",
        "LLama-3-8B-Instruct",
        "Mistral-v0.2-7B-Instruct",
        "Phi-3-medium-4k-instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A criterion for Artificial General Intelligence hypothetic-deductive reasoning tested on ChatGPT": {
    "filename": "A criterion for Artificial General Intelligence hypothetic-deductive reasoning tested on ChatGPT.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT(3)",
        "ChatGPT(4)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Is In-Context Learning in Large Language Models Bayesian A Martingale Perspective": {
    "filename": "Is In-Context Learning in Large Language Models Bayesian A Martingale Perspective.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Llama2",
        "Mistral",
        "GPT-3.5",
        "GPT-4",
        "GPT-3-170B",
        "GPT-3-2.7B",
        "llama-2-7B",
        "mistral-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RAT Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation": {
    "filename": "RAT Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "HumanEval+",
        "MBPP",
        "MBPP+",
        "GSM8K",
        "GSMHard",
        "MC-TextWorld"
      ],
      "models": [
        "RAT",
        "GPT-3.5",
        "GPT-4",
        "CodeLLaMA-7b",
        "DIRECT",
        "RAG_1 shot",
        "RAG_5 shot",
        "CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Soft Contrastive Learning-Based Prompt Model for Few-Shot Sentiment Analysis": {
    "filename": "A Soft Contrastive Learning-Based Prompt Model for Few-Shot Sentiment Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "GoEmotions"
      ],
      "models": [
        "SCP",
        "Supervised",
        "iPet",
        "P-tuning(mlp)",
        "P-tuning(lstm)",
        "Basic Prompt",
        "Mixed Template",
        "Soft Template",
        "Soft Verbalizers",
        "ChatGPT",
        "SCP w/o SCoT",
        "SCP w/o SoftCL",
        "SCP w/o CL"
      ]
    }
  },
  "Large Language Models Are Also Good Prototypical Commonsense Reasoners": {
    "filename": "Large Language Models Are Also Good Prototypical Commonsense Reasoners.pdf",
    "analysis": {
      "benchmarks": [
        "ProtoQA",
        "StrategyQA",
        "CommonsenseQA2.0"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Claude",
        "Bard",
        "GPT-2-KEPR",
        "BART-KEPR",
        "T5-3B-KEPR",
        "T5-3B-finetune",
        "GPT-3-davinci-5-Shot",
        "GPT-3.5-few-shot",
        "Claude-few-shot",
        "Bard-few-shot",
        "GPT4-few-shot",
        "GPT-3.5-Task-relevant prompt",
        "GPT-3.5-Support evidence thinking prompt",
        "GPT-3.5-diverse path decoding prompt"
      ]
    }
  },
  "Is ChatGPT a Good Causal Reasoner A Comprehensive Evaluation": {
    "filename": "Is ChatGPT a Good Causal Reasoner A Comprehensive Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "EventStoryLine v0.9 (ESC)",
        "Causal-TimeBank (CTB)",
        "MA VEN-ERE",
        "COPA",
        "e-CARE"
      ],
      "models": [
        "ChatGPT",
        "text-davinci-002",
        "text-davinci-003",
        "gpt-3.5-turbo",
        "gpt-4",
        "BERT-Base",
        "RoBERTa-Base",
        "KEPT",
        "DPJL",
        "GRU-Seq2Seq",
        "GPT2",
        "LLaMA 7B",
        "FLAN-T5 11B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Shaky Foundations of Clinical Foundation Models A Survey of Large Language Models and Foundation Models for EMRs": {
    "filename": "The Shaky Foundations of Clinical Foundation Models A Survey of Large Language Models and Foundation Models for EMRs.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-III",
        "PubMed",
        "eICU",
        "CPRD",
        "Truven Health MarketScan",
        "Partners For Kids"
      ],
      "models": [
        "ChatGPT",
        "AlphaFold",
        "ehrBERT",
        "UCSF-Bert",
        "GatorTron",
        "DescEmb",
        "Clinical Decision Transformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain-of-Table Evolving Tables in the Reasoning Chain for Table Understanding": {
    "filename": "Chain-of-Table Evolving Tables in the Reasoning Chain for Table Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "WikiTQ",
        "FeTaQA",
        "TabFact"
      ],
      "models": [
        "CHAIN-OF-TABLE",
        "PaLM 2",
        "GPT-3.5",
        "LLaMA 2",
        "End-to-End QA",
        "Few-Shot QA",
        "Chain-of-Thought",
        "Text-to-SQL",
        "Binder",
        "Dater"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Biomolecule and Natural Language through Multi-Modal Learning A Survey": {
    "filename": "Leveraging Biomolecule and Natural Language through Multi-Modal Learning A Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChemBERTa",
        "ProtTrans",
        "ESM",
        "MolCLR",
        "Graphormer",
        "AlphaFold",
        "ProteinMPNN",
        "Uni-Mol",
        "PaLM",
        "BLIP2",
        "LLaVA",
        "GPT-4",
        "LLaMA",
        "Alpaca",
        "MolT5",
        "BioT5",
        "KEDD",
        "KV-PLM",
        "BERT",
        "BioBERT",
        "SciBERT",
        "ClinicalBERT",
        "BlueBERT",
        "BioM-BERT",
        "PubMedBERT",
        "BioMegatron",
        "ScholarBERT",
        "BioLinkBERT",
        "Gatortron",
        "BioGPT",
        "BioMedLM",
        "PMC-LLaMA",
        "BioMedGPT-LM",
        "GatorTronGPT",
        "MEDITRON",
        "BioinspiredLLM",
        "Med-PaLM",
        "SciGLM",
        "Clinical Camel",
        "MedAlpaca",
        "ClinicalGPT",
        "BioBART",
        "Scifive",
        "DRAGON",
        "KV-PLM",
        "CaR",
        "GPT-MolBERTa",
        "MolXPT",
        "MolReGPT",
        "ChemCrow",
        "ReLM",
        "ChemDFM",
        "DrugAssist",
        "LlaSMol",
        "ChemLLMBench",
        "ChemLLM",
        "MolT5",
        "Text+Chem T5",
        "Ada/Aug-T5",
        "ChatMol",
        "nach0",
        "PolyNC",
        "HI-Mol",
        "TextReact",
        "Drug-to-indication",
        "MolTailor",
        "MoleculeSTM",
        "CLAMP",
        "MolCA",
        "3D-MoLM",
        "GIT-Mol",
        "MolTC",
        "DrugChat",
        "T-Rex",
        "GIMLET",
        "AMAN",
        "MoMu",
        "MolLM",
        "MolFM",
        "InstructMol",
        "TEDMol",
        "TGM-DLM",
        "Text2Mol",
        "OntoProtein",
        "ProTranslator",
        "ProtST",
        "ProteinDT",
        "Prot2Text",
        "ProtChatGPT",
        "ProtAgents",
        "ProteinChat",
        "BioBridge",
        "Galactica",
        "BioTranslator",
        "DARWIN",
        "BioT5+",
        "ChatCell"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unnatural Instructions Tuning Language Models with Almost No Human Labor": {
    "filename": "Unnatural Instructions Tuning Language Models with Almost No Human Labor.pdf",
    "analysis": {
      "benchmarks": [
        "Super-Natural Instructions",
        "BIG-bench Hard",
        "LMentry",
        "T0: Zero-Shot"
      ],
      "models": [
        "T5-LM",
        "T0++",
        "Tk-Instruct",
        "FLAN-T5",
        "T5-LM on Super-Natural Instructions",
        "T5-LM on Unnatural Instructions"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Instructed Reinforcement Learning for Human-AI Coordination": {
    "filename": "Language Instructed Reinforcement Learning for Human-AI Coordination.pdf",
    "analysis": {
      "benchmarks": [
        "Hanabi",
        "Say-Select"
      ],
      "models": [
        "instructRL",
        "instructQ",
        "instructPPO",
        "Q-learning",
        "PPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Few-Shot Identification of Morality Frames using In-Context Learning": {
    "filename": "Towards Few-Shot Identification of Morality Frames using In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Roy et al. (2021) dataset"
      ],
      "models": [
        "few-shot RoBERTa",
        "GPT-J-6B",
        "one-pass prompting",
        "one-vs-all prompting",
        "two-steps prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Embodied LLM Agents Learn to Cooperate in Organized Teams": {
    "filename": "Embodied LLM Agents Learn to Cooperate in Organized Teams.pdf",
    "analysis": {
      "benchmarks": [
        "VirtualHome-Social"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5-turbo",
        "Llama2-70B",
        "Criticize-Reflect framework",
        "embodied LLM-agent architecture"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ICLEF In-Context Learning with Expert Feedback for Explainable Style Transfer": {
    "filename": "ICLEF In-Context Learning with Expert Feedback for Explainable Style Transfer.pdf",
    "analysis": {
      "benchmarks": [
        "E-GYAFC",
        "E-WNC",
        "GYAFC",
        "WNC",
        "PAN 2022"
      ],
      "models": [
        "ICLEF",
        "ChatGPT-3.5",
        "ChatGPT-4",
        "LLaMA-7B",
        "Alpaca-7B",
        "Vicuna-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Legislative Models Towards Efficient AI Policymaking in Economic Simulations": {
    "filename": "Large Legislative Models Towards Efficient AI Policymaking in Economic Simulations.pdf",
    "analysis": {
      "benchmarks": [
        "Commons Harvest Open",
        "Gather-Trade-Build (GTB)",
        "Escape Room",
        "Harvest",
        "Clean Up",
        "Contextual Escape Room (CER)"
      ],
      "models": [
        "AI Economist",
        "MetaGrad",
        "\u03f5-greedy bandit algorithm",
        "UCB",
        "Thompson sampling",
        "Large Language Models (LLMs)",
        "GPT-4o mini",
        "Gemini-1.5 flash",
        "Gemini-1.0 pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automating Dataset Updates Towards Reliable and Timely Evaluation of Large Language Models": {
    "filename": "Automating Dataset Updates Towards Reliable and Timely Evaluation of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "BIG-Bench",
        "GLUE",
        "SQuAD",
        "CoQA",
        "Sports Understanding",
        "Periodic Elements",
        "CS Algorithms",
        "Physical Intuition",
        "Math Word Problems with Hints",
        "Abstract Algebra",
        "International Law",
        "Econometrics",
        "College Medicine",
        "Computer Security"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "Claude",
        "Llama-2-7b-chat",
        "Llama-2-13b-chat",
        "Llama-3-8b-Instruction",
        "Mistral-7B-Instruct-v0.2",
        "Mixtral-8x7B-Instruct-v0.1",
        "Yi-6b-chat",
        "Yi-34b-chat",
        "Gemini-pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How far is Language Model from 100 Few-shot Named Entity Recognition in Medical Domain": {
    "filename": "How far is Language Model from 100 Few-shot Named Entity Recognition in Medical Domain.pdf",
    "analysis": {
      "benchmarks": [
        "BC5CDR",
        "NCBI"
      ],
      "models": [
        "RT (Retrieving and Thinking)",
        "Small LMs (SLMs)",
        "Large LMs (LLMs)",
        "T5",
        "GPT-4",
        "BERT",
        "ClinicalBERT",
        "BioBERT",
        "GatorTron",
        "NNshot",
        "Structshot",
        "ContaiNER",
        "COPNER",
        "EP-NET",
        "MetaNER",
        "ProtoBERT",
        "BINDER",
        "LM-tagger",
        "Vanilla ICL",
        "PromptNER",
        "GPT-NER*",
        "GPT-NER* (self-verification)"
      ]
    }
  },
  "AI Safety in Generative AI Large Language Models A Survey": {
    "filename": "AI Safety in Generative AI Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "Measuring Massive Multitask Evaluation (MMLU)",
        "Bias Benchmark for Question Answering (BBQ)",
        "Holistic Evaluation of Language Models (HELM)",
        "BigBench",
        "TruthfulQA"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "BLOOM",
        "Bard",
        "BERT",
        "RoBERTa",
        "ALBERT",
        "DistillBERT",
        "ELECTRA",
        "DeBERTa",
        "GPT-1",
        "GPT-2",
        "GPT-3",
        "InstructGPT",
        "GLaM",
        "Gopher",
        "LaMDA",
        "PaLM",
        "U-PaLM",
        "Flan-PaLM",
        "OPT",
        "OPT-IML",
        "BLOOMZ",
        "LLaMA",
        "Claude"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Breaking Language Barriers with a LEAP Learning Strategies for Polyglot LLMs": {
    "filename": "Breaking Language Barriers with a LEAP Learning Strategies for Polyglot LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "IndicQA",
        "TyDiQA"
      ],
      "models": [
        "GPT-3",
        "GPT3.5 Turbo",
        "Muril",
        "XLMR",
        "IndicBert",
        "TuLR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AlphaIntegrator Transformer Action Search for Symbolic Integration Proofs": {
    "filename": "AlphaIntegrator Transformer Action Search for Symbolic Integration Proofs.pdf",
    "analysis": {
      "benchmarks": [
        "SymPy",
        "GPT-4o-mini"
      ],
      "models": [
        "AlphaIntegrator",
        "SymPy",
        "GPT-4o-mini",
        "seq2seq model by Lample and Charton"
      ]
    }
  },
  "VaQuitA Enhancing Alignment in LLM-Assisted Video Understanding": {
    "filename": "VaQuitA Enhancing Alignment in LLM-Assisted Video Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "MSVD-QA",
        "MSRVTT-QA",
        "Activity Net-QA"
      ],
      "models": [
        "VaQuitA",
        "FrozenBiLM",
        "VideoLLaMA",
        "LLaMA-Adapter",
        "Video Chat",
        "Video-ChatGPT",
        "BT-Adapter"
      ]
    }
  },
  "Conformer LLMs - Convolution Augmented Large Language Models": {
    "filename": "Conformer LLMs - Convolution Augmented Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "YouTubeMix",
        "text8"
      ],
      "models": [
        "Transformer based decoder language model",
        "Conformer language model",
        "Text-Baseline LLM",
        "Text-Conformer LLM",
        "Piano-Baseline LLM"
      ]
    }
  },
  "APPL A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts": {
    "filename": "APPL A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts.pdf",
    "analysis": {
      "benchmarks": [
        "CoT-SC",
        "SoT",
        "MemWalker",
        "QuALITY"
      ],
      "models": [
        "APPL",
        "LMQL",
        "SGLang",
        "Guidance",
        "GPT-3.5",
        "LLAMA-7b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Justice or Prejudice Quantifying Biases in LLM-as-a-Judge": {
    "filename": "Justice or Prejudice Quantifying Biases in LLM-as-a-Judge.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "ScienceQA",
        "OpenOrca",
        "emerton_dpo",
        "Common-senseQA",
        "TruthfulQA",
        "Truthy-DPO-v0.1",
        "Emerton-DPO-Pairs-Judge",
        "Orca-DPO-Pairs",
        "Py-DPO-v0.1",
        "Roleplay-NSFW",
        "Quora-QuAD"
      ],
      "models": [
        "CALM",
        "ChatGPT",
        "GPT-4-Turbo",
        "GPT-4o",
        "Claude-3.5-Sonnet",
        "GLM-4",
        "Qwen-72b",
        "Mixtral-8x22B",
        "Llama3-70B",
        "Llama3-8B",
        "Mistral-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatGPT Beginning of an End of Manual Linguistic Data Annotation Use Case of Automatic Genre Identification": {
    "filename": "ChatGPT Beginning of an End of Manual Linguistic Data Annotation Use Case of Automatic Genre Identification.pdf",
    "analysis": {
      "benchmarks": [
        "EN-GINCO",
        "GINCO",
        "CORE",
        "FTD",
        "WMT22",
        "GLUE"
      ],
      "models": [
        "ChatGPT",
        "X-GENRE",
        "XLM-RoBERTa",
        "BERT",
        "RoBERTa"
      ]
    }
  },
  "Benchmarking Agentic Workflow Generation": {
    "filename": "Benchmarking Agentic Workflow Generation.pdf",
    "analysis": {
      "benchmarks": [
        "WORFBENCH",
        "ToolBench",
        "ToolAlpaca",
        "Seal-Tools",
        "ALFWorld",
        "WebShop",
        "InterCodeSQL",
        "LUMOS",
        "WikiHow",
        "StableToolBench"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Claude-3.5",
        "O1",
        "GLM-4-9B",
        "Phi-3-small",
        "Llama-3.1-8B",
        "Mistral-7B",
        "Qwen-2-7B",
        "InternLM-2.5-7B",
        "Llama-2-13B",
        "WizardLM-13B",
        "Vicuna-13B",
        "Qwen-1.5-14B",
        "Phi-3-medium",
        "WizardLM-70B",
        "Mixtral-8x7B",
        "Llama-3.1-70B",
        "Qwen-2-72B",
        "Qwen-2-7B +FT",
        "InternLM-2.5-7B +FT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PET-SQL A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency": {
    "filename": "PET-SQL A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency.pdf",
    "analysis": {
      "benchmarks": [
        "Spider",
        "Bird-SQL"
      ],
      "models": [
        "PET-SQL",
        "DIN-SQL",
        "DAIL-SQL",
        "CodeLlama-34B",
        "SQLCoder-34B",
        "InternLM-70B",
        "SenseChat-70B",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Verbalized Graph Representation Learning A Fully Interpretable Graph Model Based on Large Language Models Throughout the Entire Process": {
    "filename": "Verbalized Graph Representation Learning A Fully Interpretable Graph Model Based on Large Language Models Throughout the Entire Process.pdf",
    "analysis": {
      "benchmarks": [
        "Cora",
        "CITESEER",
        "OGBN-ARXIV"
      ],
      "models": [
        "VGRL",
        "Graph Convolutional Network (GCN)",
        "Graph Attention Network (GAT)",
        "GNNExplainer",
        "XGNN",
        "SE-SGformer",
        "LLM-as-predictor",
        "Node only",
        "Summary",
        "Llama3.1 8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DEAL Disentangle and Localize Concept-level Explanations for VLMs": {
    "filename": "DEAL Disentangle and Localize Concept-level Explanations for VLMs.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "CUB",
        "Food101",
        "OxfordPets",
        "EuroSAT",
        "CUB-Part",
        "PartImageNet"
      ],
      "models": [
        "DEAL",
        "CLIP",
        "FLAVA",
        "DeCLIP",
        "PyramidCLIP",
        "CLIPpy",
        "X-VLM",
        "ViT-B/32",
        "ResNet-50"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Coin3D Controllable and Interactive 3D Assets Generation with Proxy-Guided Conditioning": {
    "filename": "Coin3D Controllable and Interactive 3D Assets Generation with Proxy-Guided Conditioning.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Coin3D",
        "Wonder3D",
        "SyncDreamer",
        "Fantasia3D",
        "Latent-NeRF"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InputSnatch Stealing Input in LLM Services via Timing Side-Channel Attacks": {
    "filename": "InputSnatch Stealing Input in LLM Services via Timing Side-Channel Attacks.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "InputSnatch",
        "GPT-3",
        "PaLM",
        "vLLM",
        "GPTCache",
        "LLaMa-2 70B",
        "LLaMa-3 8B",
        "ChatGPT-4o",
        "Gaussian Naive Bayes",
        "Gradient Boosting",
        "Random Forest",
        "XGBoost"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EcomGPT Instruction-tuning Large Language Models with Chain-of-Task Tasks for E-commerce": {
    "filename": "EcomGPT Instruction-tuning Large Language Models with Chain-of-Task Tasks for E-commerce.pdf",
    "analysis": {
      "benchmarks": [
        "Lenove",
        "Reddit",
        "ABSA",
        "MEPA VE",
        "Multi-CPR",
        "OpenBG3",
        "SGD",
        "JDDC"
      ],
      "models": [
        "EcomGPT",
        "ChatGPT",
        "BLOOMZ",
        "BLOOM",
        "E-BERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Code Pretraining Improves Entity Tracking Abilities of Language Models": {
    "filename": "Code Pretraining Improves Entity Tracking Abilities of Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ProPara",
        "bAbI tasks",
        "boxes task"
      ],
      "models": [
        "GPT-3.5",
        "GPT-3",
        "Llama 2",
        "Code Llama",
        "DeepSeek",
        "DeepSeek-Coder",
        "Gemma",
        "CodeGemma",
        "FLoat",
        "Mistral",
        "OpenMathMistral",
        "DeepSeek-Math",
        "Llemma",
        "Llama 2-Chat",
        "Code Llama-Instruct",
        "Gemma-Instruct",
        "CodeGemma-Instruct",
        "DeepSeek-Chat",
        "DeepSeek-Coder-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Distributed agency in second language learning and teaching through generative AI": {
    "filename": "Distributed agency in second language learning and teaching through generative AI.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "LaMDA",
        "Pi",
        "ElliQ",
        "GPT 4o",
        "Criterion",
        "MY Access!",
        "Grammarly",
        "Midjourney",
        "Stable Diffusion",
        "Speechify",
        "ElevenLabs",
        "Invideo AI",
        "synthesia",
        "Langotalk",
        "Polyglot AI",
        "LangAI",
        "Speaking Club AI",
        "Talkpal",
        "Andy English Bot",
        "Replika"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Promptor A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques": {
    "filename": "Promptor A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques.pdf",
    "analysis": {
      "benchmarks": [
        "KWickChat",
        "MultiArith",
        "ConvAI",
        "movie-ticket booking",
        "restaurant reservation",
        "taxi booking"
      ],
      "models": [
        "Promptor",
        "Prompted GPT-3.5",
        "Fine-tuned GPT-2",
        "Fine-tuned GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "V-STaR Training Verifiers for Self-Taught Reasoners": {
    "filename": "V-STaR Training Verifiers for Self-Taught Reasoners.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "MBPP",
        "HumanEval"
      ],
      "models": [
        "V-STaR",
        "LLaMA2",
        "CodeLLaMA",
        "STaR",
        "RFT",
        "ReSTEM",
        "ORM",
        "RFT + Verifier",
        "Self-consistency",
        "V-STaR [1 Iter]"
      ]
    }
  },
  "Anchoring Bias in Large Language Models An Experimental Study": {
    "filename": "Anchoring Bias in Large Language Models An Experimental Study.pdf",
    "analysis": {
      "benchmarks": [
        "BiasMedQA",
        "experimental dataset designed by Taha Yasseri"
      ],
      "models": [
        "GPT-4",
        "GPT-4o",
        "GPT 3.5 Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Harmful Fine-tuning Attacks and Defenses for Large Language Models A Survey": {
    "filename": "Harmful Fine-tuning Attacks and Defenses for Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "SST2",
        "BeaverTails",
        "Decoding Trust",
        "PureBad",
        "HEx-PHI",
        "HH-RLHF",
        "DirectHarm4",
        "GSM-Danger",
        "AdvBench"
      ],
      "models": [
        "Llama2-7B",
        "SFT",
        "Non-Aligned",
        "Vaccine",
        "RepNoise",
        "CTRL",
        "TAR",
        "Booster",
        "RSN-Tune",
        "T-Vaccine",
        "LDIFS",
        "SafeInstr",
        "VLGuard",
        "Freeze",
        "BEA",
        "PTST",
        "Lisa",
        "Constrain-SFT",
        "Paraphrase",
        "SPPFT",
        "ML-LR",
        "Freeze+",
        "Seal",
        "SaLoRA",
        "SAFT",
        "LAT",
        "SOMF",
        "Safe Lora",
        "Antidote",
        "SafetyLock"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Human IO Towards a Unified Approach to Detecting Situational Impairments": {
    "filename": "Human IO Towards a Unified Approach to Detecting Situational Impairments.pdf",
    "analysis": {
      "benchmarks": [
        "Ego4D v1"
      ],
      "models": [
        "Human I/O",
        "BLIP-2",
        "GPT-3 text-curie-001",
        "MediaPipe Hands",
        "efficientdet_lite0",
        "BLIP-2 VQA",
        "YAMNet",
        "GPT-4",
        "GPT-3.5-turbo",
        "Human I/O Lite"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MindLLM Pre-training Lightweight Large Language Model from Scratch Evaluations and Domain Applications": {
    "filename": "MindLLM Pre-training Lightweight Large Language Model from Scratch Evaluations and Domain Applications.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "AGIEval",
        "C-Eval",
        "CMMLU",
        "Arithmetic",
        "GSM8K",
        "MATH",
        "HellaSwag",
        "WinoGrande",
        "LogiQA",
        "PubMedQA",
        "PIQA",
        "MathQA",
        "BBH",
        "Flores-101",
        "TruthfulQA",
        "ToxiGen",
        "Ethics"
      ],
      "models": [
        "MindLLM-1.3B",
        "MindLLM-3B",
        "MPT-7B",
        "MOSS-Base-16B",
        "Bloom-7B",
        "Falcon-7B",
        "Baichuan2-7B",
        "LLaMA-2-7B",
        "LLaMA-7B",
        "Open-LLaMA-7B",
        "Bloom-3B",
        "Open-LLaMA-3B",
        "GPT-Neo-1.3B",
        "GPT-Neo-2.7B",
        "GPT-J-6B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VividDreamer Towards High-Fidelity and Efficient Text-to-3D Generation": {
    "filename": "VividDreamer Towards High-Fidelity and Efficient Text-to-3D Generation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "VividDreamer",
        "Pose-dependent Consistency Distillation Sampling (PCDS)",
        "Score Distillation Sampling (SDS)",
        "Interval Score Matching (ISM)",
        "DreamFusion",
        "DreamGaussian",
        "GaussianDreamer",
        "LucidDreamer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Test-Time Fairness and Robustness in Large Language Models": {
    "filename": "Test-Time Fairness and Robustness in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "civilcomments",
        "Bios",
        "Amazon fashion reviews",
        "Discrimination",
        "MIMIC-III"
      ],
      "models": [
        "gpt-3.5-turbo",
        "gpt-4-turbo",
        "LLAMA-3-70B",
        "OOC prompting",
        "zero-shot CoT",
        "safety prompts (Unbiased, Precog, Really4x, Illegal, Ignore, Illegal+Ignore)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tree Search for Language Model Agents": {
    "filename": "Tree Search for Language Model Agents.pdf",
    "analysis": {
      "benchmarks": [
        "VisualWebArena",
        "WebArena",
        "Mind2Web",
        "VisualWebBench",
        "MiniWoB",
        "WebShop",
        "WebLINX",
        "MMInA",
        "OSWorld",
        "WorkArena"
      ],
      "models": [
        "GPT-4o",
        "Llama-3-70B-Instruct",
        "ICAL",
        "AutoWebGLM",
        "AutoEval",
        "BrowserGym",
        "SteP",
        "WebGUM",
        "SeeAct",
        "ICAL",
        "AutoGuide",
        "Reflexion",
        "LLaVA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI An Exploratory Analysis": {
    "filename": "Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI An Exploratory Analysis.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-4",
        "PaLM 2",
        "augmented LLMs",
        "Common Model of Cognition",
        "LIDA cognitive architecture",
        "CLARION cognitive architecture",
        "ReAct",
        "Auto-CoT",
        "Program-Aided Language model (PAL)",
        "Toolformer",
        "Generative Agents",
        "OlaGPT",
        "Auto-GPT",
        "BabyAGI",
        "Voyager"
      ]
    }
  },
  "Forward-Backward Reasoning in Large Language Models for Mathematical Verification": {
    "filename": "Forward-Backward Reasoning in Large Language Models for Mathematical Verification.pdf",
    "analysis": {
      "benchmarks": [
        "AddSub",
        "MultiArith",
        "SingleEQ",
        "SVAMP",
        "GSM8K",
        "AQuA"
      ],
      "models": [
        "FOBAR",
        "Self-Consistency",
        "Self-Verification",
        "CoT",
        "ComplexCoT",
        "PHP",
        "RE2",
        "RCoT",
        "RCI",
        "ICL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Automated Startup Evaluation Pipeline Startup Success Forecasting Framework SSFF": {
    "filename": "An Automated Startup Evaluation Pipeline Startup Success Forecasting Framework SSFF.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Startup Success Forecasting Framework (SSFF)",
        "Random Forest",
        "Neural Network",
        "LLM-Based Fuzzy Random Forest Model",
        "Founder-Idea Fit Network",
        "Founder-Idea Fit Model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AgentDojo A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents": {
    "filename": "AgentDojo A Dynamic Environment to Evaluate Attacks and Defenses for LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "AgentDojo",
        "Berkeley Tool Calling Leaderboard",
        "ToolEmu",
        "InjecAgent"
      ],
      "models": [
        "Command-R+",
        "Llama 3 70b",
        "GPT-3.5 Turbo",
        "GPT-4 Turbo",
        "GPT-4o",
        "Claude 3 Opus",
        "Claude 3 Sonnet",
        "Claude 3.5 Sonnet",
        "Gemini 1.5 Flash",
        "Gemini 1.5 Pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Building Cooperative Embodied Agents Modularly with Large Language Models": {
    "filename": "Building Cooperative Embodied Agents Modularly with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ThreeDWorld Multi-Agent Transport (TDW-MAT)",
        "Communicative Watch-And-Help (C-WAH)"
      ],
      "models": [
        "CoELA",
        "GPT-4",
        "LLAMA-2",
        "CoLLAMA",
        "MCTS-based Hierarchical Planner (MHP)",
        "Rule-based Hierarchical Planner (RHP)",
        "Multi-Agent Transformer (MAT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models": {
    "filename": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SCAN",
        "GSM8K",
        "DROP"
      ],
      "models": [
        "GPT-3 code-davinci-002",
        "GPT-3 text-davinci-002",
        "GPT-3 code-davinci-001",
        "least-to-most prompting",
        "chain-of-thought prompting",
        "standard few-shot prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "In-Context Learning Enables Robot Action Prediction in LLMs": {
    "filename": "In-Context Learning Enables Robot Action Prediction in LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "RL-Bench"
      ],
      "models": [
        "RoboPrompt",
        "GPT-4 Turbo",
        "VoxPoser",
        "KAT",
        "RVT-2",
        "Act3D",
        "Octo",
        "LLARVA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MAmmoTH2 Scaling Instructions from the Web": {
    "filename": "MAmmoTH2 Scaling Instructions from the Web.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "TheoremQA",
        "ARC-C",
        "MMLU-STEM",
        "GPQA",
        "BBH",
        "HumanEval",
        "MBPP",
        "MMLU",
        "MMLU-Pro",
        "MT-Bench",
        "AlpacaEval 2.0",
        "Arena Hard"
      ],
      "models": [
        "MAmmoTH2-7B",
        "MAmmoTH2-8x7B",
        "MAmmoTH2-7B-Plus",
        "MAmmoTH2-8B-Plus",
        "MAmmoTH2-34B",
        "Mistral-7B",
        "Mixtral-8x7B",
        "Yi-34B",
        "Llama-3-8B",
        "Qwen-1.5-110B",
        "Deepseek-LM-67B",
        "Llemma-34B",
        "Mixtral-8x7B-Instruct",
        "Intern-Math-20B",
        "Deepseek-7B",
        "Qwen-1.5-7B",
        "Gemma-7B",
        "Llemma-7B",
        "WizardMath-7B-1.1",
        "Abel-7B-002",
        "Intern-Math-7B",
        "Rho-1-Math-7B",
        "Deepseek-Math-7B",
        "Deepseek-Math-Instruct",
        "Llama-3-8B-Instruct",
        "MAmmoTH2-8B",
        "MAmmoTH2-8x7B-Plus"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "End-to-End Ontology Learning with Large Language Models": {
    "filename": "End-to-End Ontology Learning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Wikipedia categories",
        "arXiv taxonomy"
      ],
      "models": [
        "OLLM",
        "Finetune",
        "Finetune (transfer)",
        "Memorisation",
        "Hearst",
        "REBEL",
        "Zero-shot",
        "One-shot",
        "Three-shot"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Fine-grained Sentiment Analysis of App Reviews using Large Language Models An Evaluation Study": {
    "filename": "A Fine-grained Sentiment Analysis of App Reviews using Large Language Models An Evaluation Study.pdf",
    "analysis": {
      "benchmarks": [
        "Evernote",
        "Facebook",
        "eBay",
        "Netflix",
        "Spotify",
        "Photo editor",
        "Twitter",
        "WhatsApp"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "LLama-2-7B Chat",
        "LLama-2-13B Chat",
        "LLama-2-70B Chat",
        "GuMA",
        "SAFE",
        "ReUS",
        "RE-BERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Robust Prompt Optimization for Large Language Models Against Distribution Shifts": {
    "filename": "Robust Prompt Optimization for Large Language Models Against Distribution Shifts.pdf",
    "analysis": {
      "benchmarks": [
        "Yelp",
        "Flipkart",
        "IMDB",
        "Amazon",
        "MNLI",
        "ANLI",
        "RTE",
        "HANS",
        "SocialIQA",
        "PIQA",
        "OpenbookQA",
        "DSTC7",
        "Ubuntu Dialog",
        "MuTual",
        "DROP"
      ],
      "models": [
        "gpt-3.5-turbo-0301",
        "APE",
        "Generalized Prompt Optimization (GPO)",
        "APO",
        "Vicuna-7B",
        "Vicuna-13B",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Simultaneous Computation and Memory Efficient Zeroth-Order Optimizer for Fine-Tuning Large Language Models": {
    "filename": "Simultaneous Computation and Memory Efficient Zeroth-Order Optimizer for Fine-Tuning Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SuperGLUE",
        "SQuAD",
        "DROP",
        "SST-2",
        "BoolQ",
        "Copa",
        "RTE",
        "CB",
        "WSC",
        "WIC",
        "MultiRC",
        "ReCoRD"
      ],
      "models": [
        "OPT-13b",
        "OPT-1.3b",
        "OPT-30b",
        "MeZO",
        "LeZO",
        "Sparse-MeZO",
        "FT with Adamw",
        "LeZO (LoRA)",
        "LeZO (prefix)",
        "MeZO (LoRA)",
        "MeZO (prefix)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PINTO Faithful Language Reasoning Using Prompt-Generated Rationales": {
    "filename": "PINTO Faithful Language Reasoning Using Prompt-Generated Rationales.pdf",
    "analysis": {
      "benchmarks": [
        "CommonsenseQA",
        "StrategyQA",
        "OpenBookQA",
        "QASC"
      ],
      "models": [
        "PINTO",
        "Prompted Self-Rationalization",
        "Distilled Self-Rationalization",
        "NILE",
        "Standard Training",
        "Dropout Context",
        "Token Masking Only",
        "Token Replacement Only"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AVI-Talking Learning Audio-Visual Instructions for Expressive 3D Talking Face Generation": {
    "filename": "AVI-Talking Learning Audio-Visual Instructions for Expressive 3D Talking Face Generation.pdf",
    "analysis": {
      "benchmarks": [
        "MeadText",
        "RAVDESS"
      ],
      "models": [
        "AVI-Talking",
        "MeshTalk",
        "EmoTalk",
        "CodeTalker",
        "FaceFormer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Refining Decompiled C Code with Large Language Models": {
    "filename": "Refining Decompiled C Code with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Code Contest dataset"
      ],
      "models": [
        "DecGPT",
        "DecRule",
        "LLM-baseline"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Classification-Based Automatic HDL Code Generation Using LLMs": {
    "filename": "Classification-Based Automatic HDL Code Generation Using LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "VerilogEval-human",
        "VerilogEval-machine"
      ],
      "models": [
        "GPT4",
        "AutoChip",
        "ChipNeMo",
        "RTLcoder",
        "VeriGen",
        "BetterV",
        "GPT4AIGChip",
        "HDLdebugger"
      ]
    }
  },
  "Analyzing and Mitigating Object Hallucination in Large Vision-Language Models": {
    "filename": "Analyzing and Mitigating Object Hallucination in Large Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MSCOCO",
        "LLaVA-150k"
      ],
      "models": [
        "MiniGPT-4",
        "LLaVa",
        "MMGPT",
        "LLaMA-Adapter",
        "mPLUG-Owl",
        "InstructBLIP",
        "LVLM Hallucination Revisor (LURE)",
        "Teacher",
        "Chain-of-Thought (CoT)",
        "Greedy-Decoding",
        "GPT-Ensemble",
        "GPT-Teacher"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Binary Code Summarization Benchmarking ChatGPTGPT-4 and Other Large Language Models": {
    "filename": "Binary Code Summarization Benchmarking ChatGPTGPT-4 and Other Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BinSum"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "Llama 2",
        "Code Llama",
        "BinT5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Iterative Motion Editing with Natural Language": {
    "filename": "Iterative Motion Editing with Natural Language.pdf",
    "analysis": {
      "benchmarks": [
        "AMASS",
        "HumanML3D",
        "fairmotion"
      ],
      "models": [
        "MDM",
        "MoMask",
        "ENG",
        "ENG-SS",
        "ENG-Interp"
      ]
    }
  },
  "TidyBot Personalized Robot Assistance with Large Language Models": {
    "filename": "TidyBot Personalized Robot Assistance with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "TidyBot benchmark dataset"
      ],
      "models": [
        "TidyBot",
        "LLM summarization",
        "CLIP embeddings",
        "ViLD",
        "OWL-ViT",
        "text-davinci-003",
        "text-davinci-002",
        "code-davinci-002",
        "PaLM 540B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoWebGLM A Large Language Model-based Web Navigating Agent": {
    "filename": "AutoWebGLM A Large Language Model-based Web Navigating Agent.pdf",
    "analysis": {
      "benchmarks": [
        "AutoWebBench",
        "Mind2Web",
        "MiniWob++",
        "WebArena"
      ],
      "models": [
        "AutoWebGLM",
        "GPT-4",
        "GPT-3.5-Turbo",
        "Claude2",
        "LLaMA2-70B",
        "LLaMA2-7B",
        "Qwen",
        "Flan-T5-XL",
        "Html-T5-XL",
        "WebN-T5-XL",
        "SeeClick",
        "Text-Bison-001",
        "Lemur"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Solution toward Transparent and Practical AI Regulation Privacy Nutrition Labels for Open-source Generative AI-based Applications": {
    "filename": "A Solution toward Transparent and Practical AI Regulation Privacy Nutrition Labels for Open-source Generative AI-based Applications.pdf",
    "analysis": {
      "benchmarks": [
        "gpt3demo",
        "gpt4demo"
      ],
      "models": [
        "Repo2Label",
        "GPT-4o",
        "GPT-4 Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Submodular Minimax Optimization Finding Effective Sets": {
    "filename": "Submodular Minimax Optimization Finding Effective Sets.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD",
        "custom datasets for prompt engineering",
        "custom datasets for dialog state tracking",
        "custom datasets for ride-sharing optimization",
        "custom datasets for adversarial image summarization"
      ],
      "models": [
        "proposed submodular minimax optimization algorithms",
        "baseline models for prompt engineering",
        "baseline models for dialog state tracking",
        "baseline models for ride-sharing optimization",
        "baseline models for adversarial image summarization"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models are Better Reasoners with Self-Verification": {
    "filename": "Large Language Models are Better Reasoners with Self-Verification.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SingleEq",
        "AddSub",
        "MultiArith",
        "AQUA-RAT",
        "SVAMP",
        "CommonsenseQA",
        "Date Understanding"
      ],
      "models": [
        "GPT-3",
        "Instruct-GPT",
        "Self-Verification",
        "Self-Consistency Decoding",
        "PAL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tackling Vision Language Tasks Through Learning Inner Monologues": {
    "filename": "Tackling Vision Language Tasks Through Learning Inner Monologues.pdf",
    "analysis": {
      "benchmarks": [
        "ScienceQA",
        "SNLI-VE"
      ],
      "models": [
        "IMMO",
        "PICa",
        "Vicuna-16-shots",
        "Vicuna-SL",
        "MiniGPT4",
        "LLaVA",
        "OFA",
        "IdealGPT",
        "Chameleon",
        "UnifiedQA"
      ]
    }
  },
  "From Words to Molecules A Survey of Large Language Models in Chemistry": {
    "filename": "From Words to Molecules A Survey of Large Language Models in Chemistry.pdf",
    "analysis": {
      "benchmarks": [
        "PubChem",
        "C4",
        "ChEBI-20",
        "PCDes",
        "PubChemSTM",
        "PubChem324k",
        "MoMu",
        "Mol-Instructions",
        "USPTO 50k",
        "GEOM-Drugs"
      ],
      "models": [
        "SMILES-BERT",
        "Molecular Transformer",
        "ChemBERTa",
        "ChemBERTa-2",
        "MG-BERT",
        "X-Mol",
        "ChemFormer",
        "BARTSmiles",
        "SPT",
        "T5 Chem",
        "MM-Deacon",
        "Regression Transformer",
        "ChemGPT",
        "MolFormer",
        "Selformer",
        "KV-PLM",
        "MolT5",
        "PrefixMol",
        "BioT5",
        "MolGen",
        "MolXPT",
        "Text+Chem T5",
        "nach0",
        "DrugGPT",
        "Text2Mol",
        "DMP",
        "MoMu",
        "MolCA",
        "MolSTM",
        "GIT-Mol",
        "GIMLET",
        "UniMap",
        "Memo"
      ]
    }
  },
  "Learning Interpretable Concepts Unifying Causal Representation Learning and Foundation Models": {
    "filename": "Learning Interpretable Concepts Unifying Causal Representation Learning and Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA"
      ],
      "models": [
        "LLaMA",
        "Inference-Time Intervention",
        "contrastive learning algorithm"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Structured Chain-of-Thought Prompting for Code Generation": {
    "filename": "Structured Chain-of-Thought Prompting for Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "MBCPP"
      ],
      "models": [
        "ChatGPT",
        "Codex",
        "CodeGen",
        "CodeParrot",
        "CodeGeeX",
        "InCoder",
        "StarCoder",
        "CodeT5+",
        "Alpaca",
        "Code Alpaca",
        "WizardCoder",
        "InstructCodeT5+",
        "Zero-shot prompting",
        "Few-shot prompting",
        "Chain-of-Thought prompting",
        "SCoT prompting",
        "SCoT-P prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Solving Math Word Problems with Reexamination": {
    "filename": "Solving Math Word Problems with Reexamination.pdf",
    "analysis": {
      "benchmarks": [
        "Math23k",
        "MathQA",
        "MAWPS",
        "SVAMP"
      ],
      "models": [
        "PseDual",
        "DNS",
        "DNS+PseDual (GRU)",
        "DNS+PseDual (GCN)",
        "GTS",
        "GTS+PseDual (GRU)",
        "GTS+PseDual (GCN)",
        "Graph2Tree",
        "Graph2Tree+PseDual (GRU)",
        "Graph2Tree+PseDual (GCN)",
        "BERT-Tree",
        "BERT-Tree+PseDual (GRU)",
        "BERT-Tree+PseDual (GCN)",
        "RE-Deduction",
        "RE-Deduction+PseDual (GRU)",
        "RE-Deduction+PseDual (GCN)",
        "Zero-Shot CoT",
        "ChatGPT",
        "ChatGPT+PseDual"
      ]
    }
  },
  "LLAssist Simple Tools for Automating Literature Review Using Large Language Models": {
    "filename": "LLAssist Simple Tools for Automating Literature Review Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "IEEE Xplore Database",
        "Scopus Database"
      ],
      "models": [
        "LLAssist",
        "Llama 3:8B",
        "Gemma 2:9B",
        "GPT-3.5-turbo-0125",
        "GPT-4o-2024-05-13"
      ]
    }
  },
  "Aligning Medical LLMs for Counterfactual Fairness": {
    "filename": "Aligning Medical LLMs for Counterfactual Fairness.pdf",
    "analysis": {
      "benchmarks": [
        "Q-Pain",
        "Treatment Recommendation",
        "Triage",
        "EquityMedQA",
        "PubMedQA"
      ],
      "models": [
        "Llama 3.1 (8B)",
        "Gemma 2 (9B)",
        "Meditron (7B)",
        "Llama 3-OpenBioLLM (8B)",
        "Gemini",
        "Gecko"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ImposterAI Adversarial Attacks with Hidden Intentions towards Aligned Large Language Models": {
    "filename": "ImposterAI Adversarial Attacks with Hidden Intentions towards Aligned Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HarmfulQ"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4",
        "Llama2",
        "Imposter.AI",
        "AIM",
        "GCG",
        "combination3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Grounded Decoding Guiding Text Generation with Grounded Models for Embodied Agents": {
    "filename": "Grounded Decoding Guiding Text Generation with Grounded Models for Embodied Agents.pdf",
    "analysis": {
      "benchmarks": [
        "RAVENS",
        "MiniGrid"
      ],
      "models": [
        "Grounded Decoding",
        "CLIPort",
        "SayCan",
        "PPO",
        "Hierarchical RL",
        "Large Language Model (LLM)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Faithful Chain-of-Thought Reasoning": {
    "filename": "Faithful Chain-of-Thought Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "MultiArith",
        "ASDiv",
        "AQuA",
        "StrategyQA",
        "Date Understanding",
        "Sports Understanding",
        "SayCan",
        "CLUTRR"
      ],
      "models": [
        "Faithful CoT",
        "Chain-of-Thought (CoT)",
        "Least-to-Most (LtM)",
        "Standard Prompting",
        "GPT-4",
        "Codex"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BoardgameQA A Dataset for Natural Language Reasoning with Contradictory Information": {
    "filename": "BoardgameQA A Dataset for Natural Language Reasoning with Contradictory Information.pdf",
    "analysis": {
      "benchmarks": [
        "BoardgameQA",
        "ConditionalQA",
        "bAbI 15",
        "CLUTRR",
        "FOLIO",
        "ProofWriter",
        "PrOntoQA-OOD",
        "AR-LSAT",
        "ENWN",
        "Leap of Thought"
      ],
      "models": [
        "BERT Large",
        "T5 XXL",
        "PaLM 62B",
        "PaLM 540B",
        "FLAN PaLM 540B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automate Knowledge Concept Tagging on Math Questions with LLMs": {
    "filename": "Automate Knowledge Concept Tagging on Math Questions with LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "MathKnowCT"
      ],
      "models": [
        "GPT-3.5-Turbo",
        "GPT-4",
        "LLAMA2-70B-Chat",
        "Mixtral-8*7B-Instruct",
        "Qwen1.5-72B-Chat",
        "InternLM2-20B-Chat",
        "InternLM2-20B-Math"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Whats the Magic Word A Control Theory of LLM Prompting": {
    "filename": "Whats the Magic Word A Control Theory of LLM Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "Wikitext"
      ],
      "models": [
        "Falcon-7b",
        "Llama-7b",
        "Falcon-40b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FELM Benchmarking Factuality Evaluation of Large Language Models": {
    "filename": "FELM Benchmarking Factuality Evaluation of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "FELM",
        "FEVER",
        "FactCC",
        "QAGS",
        "WICE",
        "HaluEval",
        "MMLU",
        "TruthfulQA",
        "GSM8K",
        "MATH"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "Vicuna-33B",
        "BART"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models are few1-shot Table Reasoners": {
    "filename": "Large Language Models are few1-shot Table Reasoners.pdf",
    "analysis": {
      "benchmarks": [
        "WikiTableQuestions",
        "FetaQA",
        "TabFact",
        "FEVEROUS"
      ],
      "models": [
        "GPT-3",
        "Codex",
        "T5-large",
        "T5-small",
        "T5-base",
        "BART",
        "TAPAS",
        "TABERT",
        "TAPEX",
        "LogicFactChecker",
        "Neural-Symbolic Machine",
        "Uni\ufb01edSKG-base",
        "Uni\ufb01edSKG-large",
        "Uni\ufb01edSKG-3B"
      ]
    }
  },
  "Generating Executable Action Plans with Environmentally-Aware Language Models": {
    "filename": "Generating Executable Action Plans with Environmentally-Aware Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "VirtualHome",
        "ActivityPrograms"
      ],
      "models": [
        "environmentally-aware language model",
        "Huang et al., 2022",
        "GPT2-large",
        "all-roberta-large-v1",
        "GPT2",
        "GPT2-xl",
        "OPT-125M",
        "OPT-350M",
        "OPT-1.3B",
        "stsb-bert-base",
        "stsb-bert-large",
        "stsb-roberta-base",
        "stsb-roberta-large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters": {
    "filename": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters.pdf",
    "analysis": {
      "benchmarks": [
        "MATH"
      ],
      "models": [
        "PaLM 2-S*",
        "PRM",
        "ORM",
        "Compute Optimal Revisions",
        "Compute Optimal Search",
        "Best-of-N Weighted",
        "Beam Search",
        "Lookahead Search",
        "Sequential Revisions",
        "Parallel Best-of-N"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Your Context Is Not an Array Unveiling Random Access Limitations in Transformers": {
    "filename": "Your Context Is Not an Array Unveiling Random Access Limitations in Transformers.pdf",
    "analysis": {
      "benchmarks": [
        "binary parity task",
        "multi-digit addition task"
      ],
      "models": [
        "BLOOMZ-560M",
        "Pythia-410M",
        "OPT-350M",
        "Llama2-7B",
        "BLOOMZ-7.1B"
      ]
    }
  },
  "V-IRL Grounding Virtual Intelligence in Real Life": {
    "filename": "V-IRL Grounding Virtual Intelligence in Real Life.pdf",
    "analysis": {
      "benchmarks": [
        "V-IRL Place Detection",
        "V-IRL Place Recognition",
        "V-IRL Place VQA",
        "V-IRL Vision-Language Navigation"
      ],
      "models": [
        "V-IRL agents",
        "Route Optimizer",
        "Place Recommender",
        "Urban Assistance Robot",
        "Intentional Explorer",
        "Tourist",
        "Interactive Concierge",
        "GroundingDINO",
        "GLIP",
        "Owl-ViT",
        "OpenSeeD",
        "Owl-ViT v2",
        "CLIP",
        "OpenCLIP",
        "Eva-02-CLIP",
        "SigLIP",
        "MiniGPT-4",
        "mPLUG-Owl",
        "Shikra",
        "BLIP-2",
        "InstructBLIP",
        "LLaVA",
        "LLaVA-1.5",
        "LLaVA-NeXT",
        "Mini-Gemini",
        "Intern-VL-1.5",
        "GPT-4V",
        "Qwen-VL-max",
        "PP-OCR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on Model Compression for Large Language Models": {
    "filename": "A Survey on Model Compression for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "WikiText-2",
        "C4",
        "PTB",
        "LAMBADA",
        "PIQA",
        "OpenBookQA",
        "GSM8K",
        "CommonsenseQA",
        "StrategyQA",
        "BIG-Bench",
        "Vicuna-Instructions",
        "User-Oriented-Instructions",
        "EleutherAI LM Harness"
      ],
      "models": [
        "LLM-QAT",
        "BitDistiller",
        "OneBit",
        "LUT-GEMM",
        "GPTQ",
        "QuIP",
        "AWQ",
        "OWQ",
        "SpQR",
        "SqueezeLLM",
        "ZeroQuant",
        "LLM.int8()",
        "SmoothQuant",
        "RPTQ",
        "OliVe",
        "OS+",
        "LLM-FP4",
        "OmniQuant",
        "KVQuant",
        "KIVI",
        "WKVQuant",
        "SparseGPT",
        "Wanda",
        "SAMSP",
        "DSnoT",
        "Flash-LLM",
        "LLM-Pruner",
        "Shortened LLaMA",
        "FLAP",
        "SliceGPT",
        "Sheared LLaMA",
        "E-Sparse",
        "MT-COT",
        "CoT Prompting",
        "Fine-tune-CoT",
        "SSLM",
        "SCOTT",
        "Distilling Step-by-Step",
        "SOCRATIC CoT",
        "PaD",
        "DRA",
        "TDIG",
        "In-context Learning Distillation",
        "AICD",
        "Lion",
        "LaMini-LM",
        "SELF-INSTRUCT",
        "Selective Reflection-Tuning",
        "MINILLM",
        "GKD",
        "TED",
        "LPLR",
        "ASVD",
        "LSAER"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On Improving Summarization Factual Consistency from Natural Language Feedback": {
    "filename": "On Improving Summarization Factual Consistency from Natural Language Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "DeFacto",
        "XSum",
        "CNN/DailyMail"
      ],
      "models": [
        "Editing model",
        "Critic model",
        "Editor model",
        "T5-3B",
        "T0-3B",
        "T0pp",
        "GPT-3.5",
        "GPT-4",
        "Pegasus",
        "CCGS",
        "CLIFF",
        "ReDRESS",
        "FactPegasus",
        "CompEdit"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Conversational Disease Diagnosis via External Planner-Controlled Large Language Models": {
    "filename": "Conversational Disease Diagnosis via External Planner-Controlled Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-IV"
      ],
      "models": [
        "GPT-4 Turbo",
        "Llama3-70B-Instruct",
        "GPT-4o",
        "AMIE",
        "Med-Palm 2",
        "Gemini",
        "Meditron-70b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automated Knowledge Concept Annotation and Question Representation Learning for Knowledge Tracing": {
    "filename": "Automated Knowledge Concept Annotation and Question Representation Learning for Knowledge Tracing.pdf",
    "analysis": {
      "benchmarks": [
        "XES3G5M",
        "Eedi"
      ],
      "models": [
        "KCQRL",
        "DKT",
        "DKT+",
        "KQN",
        "qDKT",
        "IEKT",
        "AT-DKT",
        "QIKT",
        "DKVMN",
        "DeepIRT",
        "ATKT",
        "SAKT",
        "SAINT",
        "AKT",
        "simpleKT",
        "sparseKT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Neuron Patching Semantic-based Neuron-level Language Model Repair for Code Generation": {
    "filename": "Neuron Patching Semantic-based Neuron-level Language Model Repair for Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CoNaLa",
        "IA32",
        "TLDR"
      ],
      "models": [
        "MINT",
        "KN",
        "CODEGEN-2B",
        "STARCODER 2-3B",
        "CODELLAMA-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Meta-Evaluation of Faithfulness Metrics for Long-Form Hospital-Course Summarization": {
    "filename": "A Meta-Evaluation of Faithfulness Metrics for Long-Form Hospital-Course Summarization.pdf",
    "analysis": {
      "benchmarks": [
        "CNN/DailyMail",
        "Xsum",
        "MIMIC-III",
        "MedNLI",
        "MT-Samples"
      ],
      "models": [
        "Longformer Encoder-Decoder (LED)",
        "BARTScore",
        "BERTScore",
        "Entailment-based CTC",
        "SummaC",
        "ReDRESS",
        "FactScore",
        "SciFIVE",
        "RoBERTA-Large",
        "BART-Large",
        "BART-Base",
        "RoBERTA-Large-PM-M3-Voc-large",
        "ReDRESS-clinical-hallucination-generator"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VLM See Robot Do Human Demo Video to Robot Action Plan via Vision Language Model": {
    "filename": "VLM See Robot Do Human Demo Video to Robot Action Plan via Vision Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "vegetable organization",
        "garments organization",
        "wooden block stacking"
      ],
      "models": [
        "SeeDo",
        "state-of-the-art video VLMs",
        "LLaVA",
        "VILA",
        "Gemini 1.5 Pro",
        "GPT-4o",
        "GPT-4o Init+Final",
        "SeeDo Unif.",
        "SeeDo w/o V.P."
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Bridging Low-level Geometry to High-level Concepts in Visual Servoing of Robot Manipulation Task Using Event Knowledge Graphs and Vision-Language Models": {
    "filename": "Bridging Low-level Geometry to High-level Concepts in Visual Servoing of Robot Manipulation Task Using Event Knowledge Graphs and Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "uncalibrated visual servoing controller",
        "event knowledge graphs (EKGs)",
        "large-scale pretrained vision-language models (VLMs)",
        "CLIPSeg",
        "MTF-LK",
        "MTF-lmes"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "THaLLE Text Hyperlocally Augmented Large Language Extension - Technical Report": {
    "filename": "THaLLE Text Hyperlocally Augmented Large Language Extension - Technical Report.pdf",
    "analysis": {
      "benchmarks": [
        "Chartered Financial Analyst (CFA) exam",
        "Flare CFA",
        "Internal Mock CFA Exam"
      ],
      "models": [
        "THaLLE",
        "Llama2-7B-chat",
        "Gemma-7B-instruct",
        "Llama3-8B-instruct",
        "Qwen2-7B-instruct",
        "THaLLE-SFT (Llama3-8B-instruct)",
        "THaLLE-DPO (Llama3-8B-instruct)",
        "THaLLE-SFT (Qwen2-7B-instruct)",
        "THaLLE-DPO (Qwen2-7B-instruct)",
        "FinGPT Multi-Task Llama2-7B",
        "GPT-3.5-turbo",
        "GPT-4o",
        "Gemini-1.5-Flash",
        "Gemini-1.5-Pro"
      ]
    }
  },
  "Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation": {
    "filename": "Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Devign",
        "BigCloneBench",
        "ATLAS",
        "CodeSearchNet"
      ],
      "models": [
        "ChatGLM-6B",
        "Vicuna-7B",
        "Alpaca-7B",
        "Dolly-7B",
        "StableLM-7B",
        "CodeAlpaca-7B",
        "Dolly-12B",
        "Vicuna-13B",
        "WizardCoder-15B",
        "Instruct-CodeGen-16B",
        "CodeGPT-adapted",
        "CoText",
        "PLBART",
        "CodeT5",
        "CodeGen-6B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mixture of Parrots Experts improve memorization more than reasoning": {
    "filename": "Mixture of Parrots Experts improve memorization more than reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "TriviaQA",
        "Natural Questions",
        "HellaSwag",
        "WinoGrande",
        "Hendrycks-MATH",
        "SVAMP",
        "GSM8k",
        "GSM-Hard",
        "Minerva-MATH",
        "HotpotQA",
        "WebQuestions",
        "ComplexWebQuestions",
        "ARC-C",
        "ARC-E",
        "CommonsenseQA",
        "OpenbookQA",
        "PIQA",
        "SciQ",
        "SIQA"
      ],
      "models": [
        "Dense transformer",
        "MoE (18M active parameters)",
        "MoE (58M active parameters)",
        "MoE (200M active parameters)",
        "Mistral",
        "Mixtral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DAWN Designing Distributed Agents in a Worldwide Network": {
    "filename": "DAWN Designing Distributed Agents in a Worldwide Network.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "DAWN",
        "LangGraph",
        "AutoGen",
        "ReAct",
        "ReWOO",
        "HuggingGPT",
        "Tree-of-Thoughts",
        "Language Agent Tree Search (LATS)",
        "ToolLLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FactBench A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation": {
    "filename": "FactBench A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "FACTBENCH",
        "TruthfulQA",
        "HaluEval",
        "FELM",
        "FactScore",
        "LongFact",
        "FactCheck-Bench",
        "ExpertQA"
      ],
      "models": [
        "VERIFY",
        "GPT4-o",
        "Gemini1.5-Pro",
        "Llama3.1-70B-Instruct",
        "Llama3.1-405B-Instruct",
        "Llama3-70B-Instruct",
        "GPT-4",
        "Claude-2",
        "FactScore",
        "SAFE",
        "Factcheck-GPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can ChatGPT Understand Too A Comparative Study on ChatGPT and Fine-tuned BERT": {
    "filename": "Can ChatGPT Understand Too A Comparative Study on ChatGPT and Fine-tuned BERT.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "CoLA",
        "SST-2",
        "MRPC",
        "STS-B",
        "QQP",
        "MNLI",
        "QNLI",
        "RTE"
      ],
      "models": [
        "ChatGPT",
        "BERT-base",
        "BERT-large",
        "RoBERTa-base",
        "RoBERTa-large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "REEF A Framework for Collecting Real-World Vulnerabilities and Fixes": {
    "filename": "REEF A Framework for Collecting Real-World Vulnerabilities and Fixes.pdf",
    "analysis": {
      "benchmarks": [
        "Juliet-C++",
        "Defects4J",
        "LinuxFlaw",
        "FUNDED"
      ],
      "models": [
        "SequenceR",
        "DLFix",
        "CoCoNuT",
        "CURE",
        "Recoder",
        "RewardRepair",
        "DEAR",
        "AlphaRepair",
        "KNOD",
        "TypeFix"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automated Design of Agentic Systems": {
    "filename": "Automated Design of Agentic Systems.pdf",
    "analysis": {
      "benchmarks": [
        "ARC logic puzzle task",
        "DROP",
        "MGSM",
        "GSM8K",
        "GSM-Hard",
        "SVAMP",
        "ASDiv",
        "MMLU",
        "GPQA"
      ],
      "models": [
        "Meta Agent Search",
        "Chain-of-Thought",
        "COT-SC",
        "Self-Refine",
        "LLM Debate",
        "Quality-Diversity",
        "Role Assignment",
        "Step-back Abstraction",
        "Structured Feedback and Ensemble Agent",
        "Hierarchical Committee Reinforcement Agent",
        "Dynamic Memory and Refinement Agent",
        "Dynamic Role-Playing Architecture",
        "Structured Multimodal Feedback Loop",
        "Interactive Multimodal Feedback Loop"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM4Vis Explainable Visualization Recommendation using ChatGPT": {
    "filename": "LLM4Vis Explainable Visualization Recommendation using ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "VizML"
      ],
      "models": [
        "LLM4Vis",
        "Random Forest",
        "Decision Tree",
        "MLP",
        "KG4Vis",
        "LLM-SP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GraphText Graph Reasoning in Text Space": {
    "filename": "GraphText Graph Reasoning in Text Space.pdf",
    "analysis": {
      "benchmarks": [
        "Cora",
        "Citeseer",
        "Texas",
        "Wisconsin",
        "Cornell"
      ],
      "models": [
        "GRAPH TEXT",
        "GCN",
        "GAT",
        "GCNII",
        "GATv2",
        "ChatGPT",
        "GPT-4",
        "Llama-2-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Distributed Speculative Inference of Large Language Models": {
    "filename": "Distributed Speculative Inference of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CNN-DM",
        "Alpaca",
        "HumanEval",
        "MBPP"
      ],
      "models": [
        "Distributed Speculative Inference (DSI)",
        "Speculative Inference (SI)",
        "non-SI",
        "Vicuna-13B",
        "Vicuna-68M",
        "Vicuna-7B",
        "Starcoder-15B",
        "Starcoder-168M",
        "Phi3-14B",
        "Phi3-4B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cocoon Semantic Table Profiling Using Large Language Models": {
    "filename": "Cocoon Semantic Table Profiling Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Synthea"
      ],
      "models": [
        "Cocoon",
        "Statistical Profile",
        "Semantic Profile",
        "Semantic Review"
      ]
    }
  },
  "Leveraging Large Language Models for Automated Web-Form-Test Generation An Empirical Study": {
    "filename": "Leveraging Large Language Models for Automated Web-Form-Test Generation An Empirical Study.pdf",
    "analysis": {
      "benchmarks": [
        "146 web forms from 30 open-source Java web applications"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "GLM-3",
        "GLM-4",
        "GLM-4V",
        "Baichuan2",
        "LLaMa2(7B)",
        "LLaMa2(13B)",
        "LLaMa2(70B)",
        "Spark-3",
        "Spark-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Concept Induction Analyzing Unstructured Text with High-Level Concepts Using LLooM": {
    "filename": "Concept Induction Analyzing Unstructured Text with High-Level Concepts Using LLooM.pdf",
    "analysis": {
      "benchmarks": [
        "toxic online comments",
        "political social media dataset",
        "HCI paper abstracts",
        "NeurIPS 2020 broader impact statements"
      ],
      "models": [
        "LLooM",
        "BERTopic",
        "GPT-3.5",
        "GPT-4",
        "zero-shot GPT-4 variants"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models": {
    "filename": "A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "TravelPlanner"
      ],
      "models": [
        "GPT-3.5-Turbo",
        "GPT-4-Turbo",
        "Mistral-7B-32K",
        "Mixtral-8\u00d77B-MoE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CourseGPT-zh an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization": {
    "filename": "CourseGPT-zh an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "QA dataset",
        "200 QA pairs derived from examination papers and web pages in the field of communication principles"
      ],
      "models": [
        "CourseGPT-zh",
        "ChatGPT",
        "GPT-3.5-turbo",
        "ChatGLM3-6B",
        "Qianfan-llama2-7b-chinese",
        "Qianfan-llama2-13b-chinese",
        "ERNIE-Bot-turbo",
        "ChatGPT-prompt"
      ]
    }
  },
  "Multimodal Grounding for Embodied AI via Augmented Reality Headsets for Natural Language Driven Task Planning": {
    "filename": "Multimodal Grounding for Embodied AI via Augmented Reality Headsets for Natural Language Driven Task Planning.pdf",
    "analysis": {
      "benchmarks": [
        "VirtualHome",
        "ALFRED",
        "BEHAVIOR",
        "REVERIE",
        "R2R"
      ],
      "models": [
        "GPT-3",
        "PaLM",
        "InstructGPT",
        "ViLD",
        "ViLBERT with LSTM and MLP Head",
        "InnerMonologue",
        "ProgPrompt",
        "SocraticModels",
        "ProbES"
      ]
    }
  },
  "Revisiting Large Language Models as Zero-shot Relation Extractors": {
    "filename": "Revisiting Large Language Models as Zero-shot Relation Extractors.pdf",
    "analysis": {
      "benchmarks": [
        "FewRel",
        "Wiki-ZSL",
        "TACRED",
        "TACREV",
        "Re-TACRED",
        "NYT"
      ],
      "models": [
        "ChatGPT",
        "SUMASK",
        "VANILLA",
        "R-BERT",
        "ESIM",
        "CIM",
        "ZS-BERT",
        "GPT-J",
        "BLOOM",
        "T0",
        "PA-LSTM",
        "C-GCN",
        "SpanBERT",
        "LUKE",
        "NLI-DeBERTa",
        "SuRE-PEGASUS",
        "DeepStruct",
        "QA4RE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Compressed Chain of Thought Efficient Reasoning Through Dense Representations": {
    "filename": "Compressed Chain of Thought Efficient Reasoning Through Dense Representations.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K"
      ],
      "models": [
        "Compressed Chain-of-Thought (CCoT)",
        "GPT-4o",
        "LLAMA 2-7B-CHAT",
        "PAUSE",
        "Chain of Thought (CoT)"
      ]
    }
  },
  "Enabling Large Language Models to Perform Power System Simulations with Previously Unseen Tools A Case of Daline": {
    "filename": "Enabling Large Language Models to Perform Power System Simulations with Previously Unseen Tools A Case of Daline.pdf",
    "analysis": {
      "benchmarks": [
        "DALINE"
      ],
      "models": [
        "GPT-4o",
        "ChatGPT-4o",
        "GPT-3.5-Turbo",
        "GPT-4o-Full",
        "GPT-3.5-Full",
        "GPT-3.5-NRPL",
        "GPT-3.5-NRM",
        "GPT-3.5-NG",
        "GPT-3.5-NK",
        "GPT-3.5-NC",
        "GPT-3.5-NRE",
        "GPT-3.5-NRP",
        "GPT-3.5-NS",
        "GPT-3.5-Prompt",
        "GPT-3.5-NCS",
        "GPT-3.5-NGS",
        "GPT-3.5-NKS",
        "ChatGPT-4o-R",
        "GPT-4o-R",
        "GPT-4o-Sole",
        "GPT-3.5-Sole"
      ]
    }
  },
  "Situated Natural Language Explanations": {
    "filename": "Situated Natural Language Explanations.pdf",
    "analysis": {
      "benchmarks": [
        "CoS-E"
      ],
      "models": [
        "ChatGPT",
        "Cohere Command",
        "Llama2-7B",
        "Pythia-2.8B",
        "GPT2-base",
        "GPT2-medium",
        "GPT2-large"
      ]
    }
  },
  "Deception abilities emerged in large language models": {
    "filename": "Deception abilities emerged in large language models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "ChatGPT",
        "Claude",
        "Bard",
        "BLOOM",
        "FLAN-T5",
        "text-curie-001",
        "text-davinci-003",
        "GPT-2 XL",
        "GPT-3 text-davinci-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Jailbreaking Black Box Large Language Models in Twenty Queries": {
    "filename": "Jailbreaking Black Box Large Language Models in Twenty Queries.pdf",
    "analysis": {
      "benchmarks": [
        "JailbreakBench",
        "AdvBench"
      ],
      "models": [
        "PAIR",
        "GCG",
        "Vicuna",
        "Llama-2",
        "GPT-3.5",
        "GPT-4",
        "Claude-1",
        "Claude-2",
        "Gemini",
        "Mixtral",
        "JBC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Establishing Trustworthiness Rethinking Tasks and Model Evaluation": {
    "filename": "Establishing Trustworthiness Rethinking Tasks and Model Evaluation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-4",
        "instruction-tuned models",
        "prompt-based generative models",
        "LLMs",
        "white-box models",
        "black-box models"
      ]
    }
  },
  "Inference-Time Intervention Eliciting Truthful Answers from a Language Model": {
    "filename": "Inference-Time Intervention Eliciting Truthful Answers from a Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA",
        "Natural Questions",
        "TriviaQA",
        "MMLU"
      ],
      "models": [
        "LLaMA",
        "Alpaca",
        "Vicuna",
        "GPT-judge"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cooperation Competition and Maliciousness LLM-Stakeholders Interactive Negotiation": {
    "filename": "Cooperation Competition and Maliciousness LLM-Stakeholders Interactive Negotiation.pdf",
    "analysis": {
      "benchmarks": [
        "scorable negotiation games",
        "base game",
        "new game 1",
        "new game 2",
        "new game 3"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Gemini Pro",
        "Llama2 13b",
        "Llama2 70b",
        "Llama3 70b",
        "Mixtral 8x7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4": {
    "filename": "Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4.pdf",
    "analysis": {
      "benchmarks": [
        "Aliyun",
        "Catak",
        "GraphMal",
        "VirusSample",
        "VirusShare"
      ],
      "models": [
        "GPT-4",
        "BERT",
        "CNN-based detection model",
        "TextCNN",
        "BiLSTM",
        "BiGRU",
        "CatakNet",
        "ZhangNet",
        "Kolosnjaji",
        "LiNet",
        "Mal-ASSF",
        "Transformer",
        "MalBert",
        "Embed3D+CNN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Android in the Wild A Large-Scale Dataset for Android Device Control": {
    "filename": "Android in the Wild A Large-Scale Dataset for Android Device Control.pdf",
    "analysis": {
      "benchmarks": [
        "AITW",
        "RicoSCA",
        "UIBert",
        "MiniWoB++",
        "PixelHelp",
        "UGIF",
        "Mind2Web",
        "MoTIF"
      ],
      "models": [
        "BC-single",
        "BC-history",
        "LLM-0",
        "LLM-hist-5-CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing LLMs for Power System Simulations A Feedback-driven Multi-agent Framework": {
    "filename": "Enhancing LLMs for Power System Simulations A Feedback-driven Multi-agent Framework.pdf",
    "analysis": {
      "benchmarks": [
        "DALINE",
        "MATPOWER"
      ],
      "models": [
        "GPT4o-Full",
        "GPT4o-PR",
        "GPT4o-RSR",
        "GPT4o-NP",
        "GPT4o-NCS",
        "GPT4o-RSRNW",
        "GPT4o-SR",
        "CGPT4o-R",
        "GPT4o-Sole",
        "o1p-Sole"
      ]
    }
  },
  "Grace Language Models Meet Code Edits": {
    "filename": "Grace Language Models Meet Code Edits.pdf",
    "analysis": {
      "benchmarks": [
        "c3po",
        "overwatch"
      ],
      "models": [
        "codex-davinci",
        "CodeT5",
        "c3po",
        "overwatch",
        "codeT5-u",
        "codeT5-uf",
        "codeT5-uo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Elephants Never Forget Memorization and Learning of Tabular Data in Large Language Models": {
    "filename": "Elephants Never Forget Memorization and Learning of Tabular Data in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Iris",
        "Wine",
        "Adult",
        "Housing",
        "OpenML Diabetes",
        "Titanic",
        "ACS Income",
        "ACS Travel",
        "Spaceship Titanic",
        "FICO",
        "ICU"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "OLMo 7B",
        "Gemma2 27B",
        "Llama3 70B",
        "Qwen1.5 72B",
        "Llama3.1 405B",
        "Logistic Regression",
        "Gradient-Boosted Tree",
        "1-Nearest Neighbor",
        "TabLLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring generative AI assisted feedback writing for students written responses to a physics conceptual question with prompt engineering and few-shot learning": {
    "filename": "Exploring generative AI assisted feedback writing for students written responses to a physics conceptual question with prompt engineering and few-shot learning.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5",
        "GPT-3.5-turbo"
      ]
    }
  },
  "Seek and Solve Reasoning for Table Question Answering": {
    "filename": "Seek and Solve Reasoning for Table Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "HiTab",
        "WikiTableQuestions"
      ],
      "models": [
        "Seek-and-Solve pipeline",
        "TQA-solving prompt",
        "Mistral-7B-Instruct-v0.2",
        "Mixtral-8x7B-Instruct-v0.1",
        "Llama-3.1-8B-Instruct",
        "Llama-3.1-70B-Instruct",
        "TAPAS",
        "MAPO",
        "GPT-3.5 (text-davinci-003)",
        "GPT-4",
        "E5",
        "CABINET",
        "Binder",
        "LEVER",
        "DATER",
        "ReAct"
      ]
    }
  },
  "Towards an Understanding of Stepwise Inference in Transformers A Synthetic Graph Navigation Model": {
    "filename": "Towards an Understanding of Stepwise Inference in Transformers A Synthetic Graph Navigation Model.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "autoregressive Transformer",
        "zero-shot chain-of-thought (CoT)",
        "scratchpads",
        "few-shot CoT",
        "2-layer Transformer",
        "single-head, self-attention layer Transformer",
        "full trained model",
        "simplified algorithm"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Rethinking VLMs and LLMs for Image Classification": {
    "filename": "Rethinking VLMs and LLMs for Image Classification.pdf",
    "analysis": {
      "benchmarks": [
        "CIFAR-100",
        "OOD-CV",
        "Weather",
        "Skin Cancer",
        "Hateful Memes",
        "ScienceQA",
        "Visual Genome Attribution",
        "Visual Genome Relation",
        "Abstract Scenes VQA",
        "Binary Abstract Scenes"
      ],
      "models": [
        "BLIP",
        "PNP-VQA",
        "CLIP",
        "Flamingo-3B",
        "Flamingo-9B",
        "LiT-B/16",
        "LiT-L/16",
        "GPT-2 Router",
        "HuggingGPT",
        "GPT-4V"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CodeMMLU A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs": {
    "filename": "CodeMMLU A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs.pdf",
    "analysis": {
      "benchmarks": [
        "CodeMMLU",
        "HumanEval",
        "MBPP",
        "CodeContests",
        "LiveCodeBench",
        "CodeXGLUE",
        "XLCoST",
        "XCodeEval",
        "TruthfulQA",
        "APPS",
        "CRUXEval",
        "CodeApex"
      ],
      "models": [
        "GPT-4o",
        "Meta-Llama-3-70B-Instruct",
        "Claude-3-sonnet@20240229",
        "Mixtral-8x7B-Instruct-v0.1",
        "DeepSeek-moe-16b-chat",
        "GPT-3.5-turbo",
        "Llama3 70B",
        "Llama3.1 70B",
        "Mistral7B Instruct",
        "Codestral 22B",
        "Phi3 Medium Instruct",
        "Qwen2 57B-A14B Instruct",
        "Yi-1.5-34B-Chat",
        "DeepSeekCoder 7B Instruct",
        "DeepSeekCoder 33B Instruct",
        "InternLM2.5 20B Chat",
        "StarCoder2 15B Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Vision Language Model-Empowered Contract Theory for AIGC Task Allocation in Teleoperation": {
    "filename": "Vision Language Model-Empowered Contract Theory for AIGC Task Allocation in Teleoperation.pdf",
    "analysis": {
      "benchmarks": [
        "LPIPS",
        "SSIM"
      ],
      "models": [
        "diffusion-based AIGC model",
        "VLM-empowered contract theory",
        "Human Contract",
        "Oracle Contract",
        "VLM Contract"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond Words A Mathematical Framework for Interpreting Large Language Models": {
    "filename": "Beyond Words A Mathematical Framework for Interpreting Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Hex framework",
        "PaLM",
        "GPT-4",
        "LLaMA"
      ]
    }
  },
  "ChatGPT Dont Tell Me What to Do Designing AI for Context Analysis in Humanitarian Frontline Negotiations": {
    "filename": "ChatGPT Dont Tell Me What to Do Designing AI for Context Analysis in Humanitarian Frontline Negotiations.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "custom interface",
        "probe interface",
        "OpenAI's GPT-4o API"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey of Graph Meets Large Language Model Progress and Future Directions": {
    "filename": "A Survey of Graph Meets Large Language Model Progress and Future Directions.pdf",
    "analysis": {
      "benchmarks": [
        "Cora",
        "Ogbn-Arxiv",
        "PeMS03",
        "PascalVOC-SP",
        "PubChem"
      ],
      "models": [
        "TAPE",
        "InstructGLM",
        "MoleculeSTM",
        "GIANT",
        "SimTeG",
        "TouchUp-G",
        "G-Prompt",
        "WalkLM",
        "METERN",
        "LEADING",
        "OFA",
        "LLMRec",
        "GIMLET",
        "GraphLLM",
        "GraphGPT",
        "DGTL",
        "InstructMol",
        "SAFER",
        "Text2Mol",
        "MoMu",
        "GLEM",
        "G2P2",
        "GRENADE",
        "GraphFormers",
        "Patton",
        "GRAD",
        "THLM",
        "RLMRec",
        "LLM-GNN",
        "GPT4GNAS",
        "ENG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InternGPT Solving Vision-Centric Tasks by Interacting with Chatbots Beyond Language": {
    "filename": "InternGPT Solving Vision-Centric Tasks by Interacting with Chatbots Beyond Language.pdf",
    "analysis": {
      "benchmarks": [
        "COCO"
      ],
      "models": [
        "InternGPT",
        "Husky",
        "ChatGPT",
        "GPT-4",
        "LLaMA",
        "Visual ChatGPT",
        "MM-REACT",
        "HuggingGPT",
        "MiniGPT-4",
        "LLaVA",
        "BLIP",
        "BLIP-2",
        "SAM",
        "OCR",
        "Stable Diffusion",
        "ControlNet",
        "InternImage",
        "InternVideo",
        "DINOv2",
        "DragGAN",
        "ImageBind",
        "Grounding DINO",
        "GLIP",
        "VideoChat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Proactive Agent Shifting LLM Agents from Reactive Responses to Active Assistance": {
    "filename": "Proactive Agent Shifting LLM Agents from Reactive Responses to Active Assistance.pdf",
    "analysis": {
      "benchmarks": [
        "ProactiveBench"
      ],
      "models": [
        "LLaMA-3.1-8B-Instruct",
        "Qwen2-7B-Instruct",
        "GPT-4o",
        "GPT-4o-mini",
        "Claude-3-Sonnet",
        "Claude-3.5-Sonnet",
        "LLaMA-3.1-8B",
        "Qwen2-7B",
        "LLaMA-3.1-8B-Proactive",
        "Qwen2-7B-Proactive"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Few-shot In-context Learning on Knowledge Base Question Answering": {
    "filename": "Few-shot In-context Learning on Knowledge Base Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "WebQSP",
        "GrailQA",
        "GraphQA",
        "MetaQA"
      ],
      "models": [
        "KB-BINDER",
        "KB-BINDER-R",
        "GloVe + Transduction",
        "QGG",
        "BERT + Transduction",
        "GloVe + Ranking",
        "BERT + Ranking",
        "ReTraCk",
        "S2QL",
        "ArcaneQA",
        "RnG-KBQA",
        "DecAF",
        "TIARA",
        "AUDEPLAMBDA",
        "SPARQA",
        "KV-Mem",
        "VRN",
        "GraftNet",
        "PullNet",
        "Emb",
        "NSM"
      ]
    }
  },
  "Husky A Unified Open-Source Language Agent for Multi-Step Reasoning": {
    "filename": "Husky A Unified Open-Source Language Agent for Multi-Step Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "DROP",
        "IIRC",
        "HUSKY QA",
        "GSM-8K",
        "MATH",
        "Google DeepMind Mathematics",
        "MathQA",
        "TabMWP",
        "FinQA",
        "TAT-QA",
        "MultimodalQA",
        "HotpotQA",
        "CWQ",
        "Musique",
        "Bamboogle",
        "StrategyQA"
      ],
      "models": [
        "HUSKY",
        "FIREACT",
        "LUMOS",
        "REACT",
        "REWOO",
        "CHAMELEON",
        "CoT Tulu2-7B",
        "gpt-3.5-turbo",
        "gpt-4-turbo",
        "gpt-4o",
        "DeepSeekCoder-7B-Instruct-v1.5",
        "DeepSeekMath-7B-Instruct",
        "CodeTulu-7B",
        "Llama-3-8B",
        "Tulu-2-7B",
        "LLAMA-2-7B",
        "LLAMA-2-13B",
        "LLAMA-3-8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SPINE Online Semantic Planning for Missions with Incomplete Natural Language Specifications in Unstructured Environments": {
    "filename": "SPINE Online Semantic Planning for Missions with Incomplete Natural Language Specifications in Unstructured Environments.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "SPINE",
        "Explicit Tasking",
        "Mapping then LLM-as-Planner",
        "Two Stage"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RepairAgent An Autonomous LLM-Based Agent for Program Repair": {
    "filename": "RepairAgent An Autonomous LLM-Based Agent for Program Repair.pdf",
    "analysis": {
      "benchmarks": [
        "Defects4J",
        "GitBug-Java"
      ],
      "models": [
        "RepairAgent",
        "ChatRepair",
        "ITER",
        "SelfAPR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Long Is More for Alignment A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning": {
    "filename": "Long Is More for Alignment A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning.pdf",
    "analysis": {
      "benchmarks": [
        "Open LLM",
        "AlpacaEval 2.0",
        "MT-Bench",
        "ARC",
        "MMLU",
        "TruthfulQA",
        "Winogrande"
      ],
      "models": [
        "Llama-2-7B",
        "Llama-2-13B",
        "Mistral-7B-v0.1",
        "Alpaca-1k-longest",
        "Refined-Alpaca-1k-longest",
        "Evol-Instruct-1k-longest",
        "Refined-Evol-Instruct-1k-longest",
        "AlpaGasus-1k",
        "LIMA-1k",
        "Alpaca-52k",
        "Evol-Instruct-70k",
        "Evol-Instruct-AlpaGasus-1k",
        "Llama-2-Chat-7B",
        "Tulu-2-DPO-7B",
        "Llama-2-7B-Evol-Instruct-NEFTune"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Zero-Shot Language Agent for Computer Control with Structured Reflection": {
    "filename": "A Zero-Shot Language Agent for Computer Control with Structured Reflection.pdf",
    "analysis": {
      "benchmarks": [
        "MINIWOB++"
      ],
      "models": [
        "Zero-Shot Agent",
        "PaLM2",
        "SAYCAN",
        "REACT",
        "TOOLFORMER",
        "SWIFT SAGE",
        "REFLEXION",
        "SELF-REFINE",
        "CC-Net",
        "WebGUM",
        "RCI",
        "SYNAPSE",
        "ADAPLANNER",
        "PIX2ACT",
        "WEBNT5"
      ]
    }
  },
  "Capabilities of GPT-4 on Medical Challenge Problems": {
    "filename": "Capabilities of GPT-4 on Medical Challenge Problems.pdf",
    "analysis": {
      "benchmarks": [
        "USMLE Sample Exam",
        "USMLE Self Assessment",
        "MedQA",
        "PubMedQA",
        "MedMCQA",
        "MMLU",
        "MultiMedQA"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Med-PaLM",
        "Flan-PaLM 540B",
        "ChatGPT",
        "InstructGPT",
        "Codex"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An In-depth Look at Geminis Language Abilities": {
    "filename": "An In-depth Look at Geminis Language Abilities.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "BIG-Bench-Hard",
        "GSM8K",
        "SVAMP",
        "ASDIV",
        "MAWPS",
        "HumanEval",
        "ODEX",
        "FLORES",
        "WebArena"
      ],
      "models": [
        "Gemini Pro",
        "GPT 3.5 Turbo",
        "GPT 4 Turbo",
        "Mixtral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Infant Agent A Tool-Integrated Logic-Driven Agent with Cost-Effective API Usage": {
    "filename": "Infant Agent A Tool-Integrated Logic-Driven Agent with Cost-Effective API Usage.pdf",
    "analysis": {
      "benchmarks": [
        "SWE-bench-lite",
        "AIME2024",
        "GPQA-diamond",
        "Codeforce contests"
      ],
      "models": [
        "INFANT AGENT",
        "GPT-4o",
        "Qwen2.5-72B-Instruct",
        "OpenHands",
        "CodeActAgent",
        "o1-preview",
        "Claude 3.5 Sonnet",
        "SWE-Agent",
        "AutoCodeRover",
        "AgentMarsCode Agent",
        "Honeycomb",
        "Gru",
        "Isoform",
        "SuperCoder2.0",
        "Lingma Agent",
        "Q Developer Agent",
        "Agentless + RepoGraph",
        "CodeR",
        "MASAI",
        "SIMA",
        "Agentless",
        "Moatless Tools",
        "OpenDevin",
        "Agent-101",
        "Aider",
        "HyperAgent",
        "IBM SWE-1.0",
        "GenAgent",
        "Navie Agent",
        "AutoSE",
        "RAG",
        "o1-mini",
        "MACM",
        "DeepSeek-Coder-V2-236B",
        "Llama-3.1-70B-Instruct"
      ]
    }
  },
  "Can Pretrained Language Models Yet Reason Deductively": {
    "filename": "Can Pretrained Language Models Yet Reason Deductively.pdf",
    "analysis": {
      "benchmarks": [
        "Leap of Thought (LoT)",
        "WikiData (WD)"
      ],
      "models": [
        "BERT",
        "RoBERTa",
        "R-BERT",
        "CLS-BERT",
        "MLM-BERT",
        "Cloze-BERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM as a Mastermind A Survey of Strategic Reasoning with Large Language Models": {
    "filename": "LLM as a Mastermind A Survey of Strategic Reasoning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BigToM",
        "SOTOPIA",
        "UGI",
        "OpenToM",
        "TRIP",
        "WarAgent",
        "TradingGPT",
        "CompeteAI",
        "AucArena",
        "MAgIC",
        "Alympics",
        "Avalonbench",
        "ReCon",
        "Welfare diplomacy",
        "ChessGPT",
        "TextStarCraft II",
        "Pok\u00e9LLMon",
        "CivRealm",
        "GTBench",
        "LLMArena"
      ],
      "models": [
        "LLMs",
        "Suspicion-Agent",
        "PokerGPT",
        "Agent-Pro",
        "ChessGPT",
        "Thinker",
        "SwarmBrain",
        "OG-Narrator",
        "Cicero",
        "Retroformer",
        "LLaMAC",
        "INA",
        "TRIP",
        "K-Level Reasoning"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Power of Question Translation Training in Multilingual Reasoning Broadened Scope and Deepened Insights": {
    "filename": "The Power of Question Translation Training in Multilingual Reasoning Broadened Scope and Deepened Insights.pdf",
    "analysis": {
      "benchmarks": [
        "MGSM",
        "MSVAMP",
        "XCSQA",
        "XNLI"
      ],
      "models": [
        "LLaMA2",
        "LLaMA2-7B",
        "LLaMA2-13B",
        "LLaMA2-70B",
        "LLaMA3-8B",
        "CodeLLaMA-7B",
        "Mixtral-8x7B",
        "Mixtral-8x22B",
        "RAlign",
        "QAlign"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Data Augmentation for Sparse Multidimensional Learning Performance Data Using Generative AI": {
    "filename": "Data Augmentation for Sparse Multidimensional Learning Performance Data Using Generative AI.pdf",
    "analysis": {
      "benchmarks": [
        "AutoTutor Adult Reading Comprehension (ARC) lessons"
      ],
      "models": [
        "Generative Adversarial Networks (GANs)",
        "Generative Pre-Trained Transformers (GPT)",
        "Tensor Factorization",
        "Bayesian Knowledge Tracing (BKT)",
        "Performance Factor Analysis (PFA)",
        "Sparse Factor Analysis Lite (SPARFA-Lite)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "14 examples of how LLMs can transform materials science and chemistry a reflection on a large language model hackathon": {
    "filename": "14 examples of how LLMs can transform materials science and chemistry a reflection on a large language model hackathon.pdf",
    "analysis": {
      "benchmarks": [
        "QM9-G4MP2",
        "Open Reaction Database (ORD)"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "GPT-2",
        "GPTChem",
        "GPT-2-LoRA",
        "ScholarBERT-XL",
        "Text-to-Text Transfer Transformer (T5)",
        "GPT-2-medium",
        "Alpaca model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GLM-130B An Open Bilingual Pre-trained Model": {
    "filename": "GLM-130B An Open Bilingual Pre-trained Model.pdf",
    "analysis": {
      "benchmarks": [
        "LAMBADA",
        "Big-bench-lite",
        "MMLU",
        "CLUE",
        "FewCLUE",
        "Pile"
      ],
      "models": [
        "GLM-130B",
        "GPT-3 175B",
        "OPT-175B",
        "BLOOM-176B",
        "ERNIE TITAN 3.0 260B",
        "PaLM 540B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding and Predicting Human Label Variation in Natural Language Inference through Explanation": {
    "filename": "Understanding and Predicting Human Label Variation in Natural Language Inference through Explanation.pdf",
    "analysis": {
      "benchmarks": [
        "MNLI",
        "ChaosNLI"
      ],
      "models": [
        "GPT-3",
        "BERT-based fine-tuned models",
        "Explain-then-Predict",
        "Predict-then-Explain",
        "Predict-only",
        "Predict-only-extra-train"
      ]
    }
  },
  "Large Language Models and Knowledge Graphs Opportunities and Challenges": {
    "filename": "Large Language Models and Knowledge Graphs Opportunities and Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "PopQA",
        "Wikidata",
        "LAMA",
        "KAMEL",
        "KMIR",
        "SNOMED CT",
        "FoodOn"
      ],
      "models": [
        "BERT",
        "RoBERTa",
        "GPT-3",
        "GPT-4",
        "LLaMA",
        "ChatGPT",
        "PaLM",
        "SBERT",
        "Pretrain-KGE",
        "MADLINK",
        "KEPLER",
        "KG-BERT",
        "KG-GPT2",
        "MTL-KGC",
        "MEMKGC",
        "StAR",
        "SimKGC",
        "LP-BERT",
        "BERTSubs",
        "SciBERT",
        "BERTMap",
        "LogMap",
        "LogMap-ML",
        "KnowPrompt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Risk Taxonomy Mitigation and Assessment Benchmarks of Large Language Model Systems": {
    "filename": "Risk Taxonomy Mitigation and Assessment Benchmarks of Large Language Model Systems.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "LLaMA",
        "Flan-T5",
        "BLOOM",
        "GPT-Neo",
        "Alpaca",
        "Vicuna"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond Autoregression Discrete Diffusion for Complex Reasoning and Planning": {
    "filename": "Beyond Autoregression Discrete Diffusion for Complex Reasoning and Planning.pdf",
    "analysis": {
      "benchmarks": [
        "Countdown",
        "Sudoku",
        "Boolean Satisfiability Problem"
      ],
      "models": [
        "Multi-granularity Diffusion Modeling (MDM)",
        "autoregressive models",
        "GPT-2 Scratch",
        "LLaMA",
        "Stream-of-Search",
        "VDM",
        "D3PM",
        "RDM",
        "GPT-4",
        "Diffusion model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan A Multi-Player Cooperative Game under Imperfect Information": {
    "filename": "Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan A Multi-Player Cooperative Game under Imperfect Information.pdf",
    "analysis": {
      "benchmarks": [
        "Guandan"
      ],
      "models": [
        "LLM-Agent",
        "Danzero+",
        "GPT-4-Turbo",
        "GPT-3.5-Turbo",
        "Baichuan2-7B-Chat",
        "Baichuan2-13B-Chat",
        "chatglm3-6b-32k",
        "Qwen1.5-7B-Chat",
        "Qwen1.5-14B-Chat",
        "Rule-based Agent",
        "Vanilla Planning",
        "First-Order ToM Planning",
        "Second-Order ToM Planning"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Process-Driven Autoformalization in Lean 4": {
    "filename": "Process-Driven Autoformalization in Lean 4.pdf",
    "analysis": {
      "benchmarks": [
        "FORM L4",
        "Mathlib 4",
        "GSM8K",
        "MATH"
      ],
      "models": [
        "Process-Driven Autoformalization (PDA)",
        "Baseline Autoformalizer",
        "Rejective Sampling Fine-tuned (RFT) Autoformalizer",
        "Verifier-Enhanced Autoformalizer (VEA)",
        "Combined RFT and Verifier-Enhanced Autoformalizer (RFT+VEA)",
        "Process-Supervised Verifier (PSV)",
        "Outcome-Supervised Verifier (OSV)",
        "GPT-3.5-Turbo",
        "GPT-4-Turbo",
        "GPT-4o",
        "DeepSeek-Math-Base-7B",
        "DeepSeek-Math-Instruct-7B",
        "LLEMMA-7B",
        "LLEMMA-34B",
        "InternLM-Math-7B",
        "InternLM-Math-20B",
        "Mistral-Instruct-v0.3-7B",
        "Mistral-v0.3-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Is GPT Powerful Enough to Analyze the Emotions of Memes": {
    "filename": "Is GPT Powerful Enough to Analyze the Emotions of Memes.pdf",
    "analysis": {
      "benchmarks": [
        "SemEval-2020 Task 8",
        "Facebook Hateful Memes",
        "Multimodal Memotion Analysis"
      ],
      "models": [
        "GPT-3.5",
        "VisualGPT",
        "GPT-3.5-Turbo"
      ]
    }
  },
  "ZeFaV Boosting Large Language Models for Zero-Shot Fact Verification": {
    "filename": "ZeFaV Boosting Large Language Models for Zero-Shot Fact Verification.pdf",
    "analysis": {
      "benchmarks": [
        "HoVer",
        "FEVEROUS-S"
      ],
      "models": [
        "ZeFaV",
        "ProgramFC",
        "QACheck",
        "InfoRE",
        "Meta-Llama-3-70B-Instruct"
      ]
    }
  },
  "RSL-SQL Robust Schema Linking in Text-to-SQL Generation": {
    "filename": "RSL-SQL Robust Schema Linking in Text-to-SQL Generation.pdf",
    "analysis": {
      "benchmarks": [
        "BIRD",
        "Spider"
      ],
      "models": [
        "RSL-SQL",
        "GPT-4o",
        "DeepSeek",
        "DIN-SQL",
        "DAIL-SQL",
        "DTS-SQL",
        "Codes",
        "SQL-Palm",
        "MCS-SQL",
        "TA-SQL",
        "CHESS",
        "SuperSQL",
        "MAG-SQL",
        "MAC-SQL",
        "E-SQL",
        "MSc-SQL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "System 2 Attention is something you might need too": {
    "filename": "System 2 Attention is something you might need too.pdf",
    "analysis": {
      "benchmarks": [
        "modified TriviaQA",
        "SycophancyEval",
        "GSM-IC",
        "GSM8K"
      ],
      "models": [
        "System 2 Attention (S2A)",
        "LLaMA-2-70B-chat",
        "text-davinci-003",
        "GPT-3.5-turbo",
        "GPT-4",
        "Oracle Prompt",
        "Baseline",
        "Instructed Prompting",
        "Chain-of-Thought (CoT)"
      ]
    }
  },
  "RLPrompt Optimizing Discrete Text Prompts with Reinforcement Learning": {
    "filename": "RLPrompt Optimizing Discrete Text Prompts with Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "SST-2",
        "Yelp Polarity",
        "MR",
        "CR",
        "SST-5",
        "Yelp",
        "AG's News",
        "Subj",
        "TREC",
        "Yahoo",
        "DBPedia",
        "Yelp sentiment transfer",
        "Shakespeare authorship transfer"
      ],
      "models": [
        "RLPROMPT",
        "Fine-Tuning",
        "Manual Prompt",
        "Instructions",
        "In-Context Demonstration",
        "Prompt Tuning",
        "BB Tuning",
        "GrIPS",
        "AutoPrompt",
        "Style Transformer",
        "DiRR",
        "Null Prompt",
        "Random Prompt",
        "distilGPT-2",
        "GPT-2-small",
        "GPT-2-medium",
        "GPT-2-large",
        "GPT-2-xl"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LayoutLLM Layout Instruction Tuning with Large Language Models for Document Understanding": {
    "filename": "LayoutLLM Layout Instruction Tuning with Large Language Models for Document Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "DocVQA",
        "VisualMRC",
        "FUNSD",
        "CORD",
        "SROIE"
      ],
      "models": [
        "LayoutLLM",
        "ChatGPT",
        "LLaMA",
        "GPT-4V",
        "LayoutLMv3",
        "Vicuna-7B",
        "Llama2-7B",
        "Llama2-7B-chat",
        "Vicuna-1.5-7B",
        "LLaV AR-7B",
        "LLaV A-1.5-7B",
        "mPLUG-DocOWL-7B",
        "Qwen-VL-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The effect of source disclosure on evaluation of AI-generated messages A two-part study": {
    "filename": "The effect of source disclosure on evaluation of AI-generated messages A two-part study.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "Bloom",
        "GPT3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Dataset and Benchmark for Hospital Course Summarization with Adapted Large Language Models": {
    "filename": "A Dataset and Benchmark for Hospital Course Summarization with Adapted Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-IV-BHC"
      ],
      "models": [
        "Clinical-T5-Large",
        "Llama2-13B",
        "FLAN-UL2",
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "Hypothesis Generation with Large Language Models": {
    "filename": "Hypothesis Generation with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SHOE SALES",
        "DECEPTIVE REVIEWS",
        "HEADLINE POPULARITY",
        "TWEET POPULARITY"
      ],
      "models": [
        "HypoGeniC",
        "RoBERTa",
        "Llama-2-7B",
        "GPT-3.5-turbo",
        "Mixtral",
        "Claude-2.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ARN Analogical Reasoning on Narratives": {
    "filename": "ARN Analogical Reasoning on Narratives.pdf",
    "analysis": {
      "benchmarks": [
        "ARN",
        "ePiC",
        "StoryAnalogy"
      ],
      "models": [
        "GPT3.5",
        "GPT4.0",
        "UnifiedQA",
        "Llama-2",
        "FlanT5",
        "Macaw",
        "SBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AiBAT Artificial IntelligenceInstructions for Build Assembly and Test": {
    "filename": "AiBAT Artificial IntelligenceInstructions for Build Assembly and Test.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "AiBAT",
        "DocVQA models",
        "custom rule-based approach",
        "Mistral 7B"
      ]
    }
  },
  "Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning": {
    "filename": "Semantically Aligned Task Decomposition in Multi-Agent Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Overcooked",
        "MiniRTS"
      ],
      "models": [
        "SAMA",
        "selfplay",
        "PBT",
        "FCP",
        "COLE",
        "MASER",
        "LDSA",
        "ROMA",
        "RED"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Contextual Emotion Recognition using Large Vision Language Models": {
    "filename": "Contextual Emotion Recognition using Large Vision Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "EMOTIC"
      ],
      "models": [
        "CLIP",
        "GPT-4",
        "GPT-4 Vision",
        "LLaVA",
        "Mistral",
        "NarraCap",
        "ExpansionNet",
        "EMOTIC baseline",
        "Emoticon"
      ]
    }
  },
  "The Good the Bad and the Hulk-like GPT Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games": {
    "filename": "The Good the Bad and the Hulk-like GPT Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games.pdf",
    "analysis": {
      "benchmarks": [
        "Ultimatum Game",
        "Dictator Game",
        "Prisoner's Dilemma",
        "Battle of the Sexes"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Labyrinth of Links Navigating the Associative Maze of Multi-modal LLMs": {
    "filename": "The Labyrinth of Links Navigating the Associative Maze of Multi-modal LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "OCL",
        "Pangea"
      ],
      "models": [
        "GPT-4V",
        "Gemini-1.5-Flash",
        "LLaV A-OneVision",
        "Qwen2-VL",
        "mPLUG-Owl3",
        "MoE",
        "Qwen-VL",
        "LLaV A-NeXT-7B",
        "LLaV A-NeXT-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chinese Metaphor Recognition Using a Multi-stage Prompting Large Language Model": {
    "filename": "Chinese Metaphor Recognition Using a Multi-stage Prompting Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "NLPCC-2024 Shared Task 9"
      ],
      "models": [
        "BiLSTM",
        "BERT",
        "RoBERTa",
        "DeBERTa",
        "T5",
        "BART",
        "Qwen2-plus",
        "CT-LLM",
        "MAP-NEO",
        "Yi-1.5-34B",
        "Qwen2-72B",
        "GPT-4-Turbo"
      ]
    }
  },
  "Maieutic Prompting Logically Consistent Reasoning with Recursive Explanations": {
    "filename": "Maieutic Prompting Logically Consistent Reasoning with Recursive Explanations.pdf",
    "analysis": {
      "benchmarks": [
        "Com2Sense",
        "CSQA 2.0",
        "CREAK",
        "StrategyQA"
      ],
      "models": [
        "MAIEUTIC PROMPTING",
        "Chain of Thought",
        "Self Consistency",
        "Generated Knowledge Prompting (GKP)",
        "Standard Prompting",
        "RoBERTa-large",
        "T5-large",
        "T5-3B",
        "UnifiedQA-3B",
        "T5-11B",
        "Unicorn-11B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "S3HQA A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering": {
    "filename": "S3HQA A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "HybridQA"
      ],
      "models": [
        "S3HQA",
        "HYBRIDER",
        "DocHopper",
        "MuGER2",
        "POINTR",
        "DEHG",
        "MITQA",
        "MAFiD",
        "GPT3.5 direct",
        "GPT3.5 CoT",
        "S3HQA-RetrieverDB",
        "S3HQA-RetrieverBE",
        "BERT-large reader"
      ]
    }
  },
  "Auto MC-Reward Automated Dense Reward Design with Large Language Models for Minecraft": {
    "filename": "Auto MC-Reward Automated Dense Reward Design with Large Language Models for Minecraft.pdf",
    "analysis": {
      "benchmarks": [
        "Exploring diamond ore on the 11-th floor underground",
        "Approaching tree in plains biome",
        "Approaching specific animal in plains biome",
        "Obtaining diamond",
        "Approaching animals in plains biome",
        "Attacking cow in plains biome",
        "LavaCrossingS9N1",
        "LavaCrossingS9N3"
      ],
      "models": [
        "Auto MC-Reward",
        "Naive Handcraft",
        "Imitation Learning",
        "RL with Sparse Reward",
        "RL with Curiosity Dense Reward",
        "RL with Self-Imitation Dense Reward",
        "RL with MineCLIP Dense Reward"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The gene function prediction challenge Large language models and knowledge graphs to the rescue": {
    "filename": "The gene function prediction challenge Large language models and knowledge graphs to the rescue.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Random Forest (RF)",
        "Support Vector Machine (SVM)",
        "Convolutional Neural Networks (CNNs)",
        "Graph Convolutional Networks (GCNs)",
        "scGPT",
        "AgroNT",
        "interpretable DeepLearning models",
        "BioGPT",
        "BioBERT",
        "SciBERT",
        "PlantConnectome"
      ]
    }
  },
  "PentestGPT An LLM-empowered Automatic Penetration Testing Tool": {
    "filename": "PentestGPT An LLM-empowered Automatic Penetration Testing Tool.pdf",
    "analysis": {
      "benchmarks": [
        "HackTheBox",
        "VulnHub",
        "picoMini CTF competition",
        "OWASP Top 10",
        "Common Weakness Enumeration (CWE)"
      ],
      "models": [
        "PENTEST GPT",
        "GPT-3.5",
        "GPT-4",
        "Bard"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "D-Bot Database Diagnosis System using Large Language Models": {
    "filename": "D-Bot Database Diagnosis System using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Internet of Things",
        "E-Commerce",
        "Financial",
        "Business Intelligence",
        "File Sharing",
        "Social Media"
      ],
      "models": [
        "D-Bot (GPT-4)",
        "D-Bot (GPT-3.5)",
        "HumanDBA",
        "DNN",
        "DecisionTree",
        "GPT-4",
        "GPT-3.5",
        "NoKnowledge",
        "NoTreeSearch",
        "SingleLLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RoboScript Code Generation for Free-Form Manipulation Tasks across Real and Simulation": {
    "filename": "RoboScript Code Generation for Free-Form Manipulation Tasks across Real and Simulation.pdf",
    "analysis": {
      "benchmarks": [
        "RobotScript Benchmark",
        "Ravens",
        "RoboCodeGen",
        "RoboGen",
        "MoveIt"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Gemini",
        "AnyGrasp",
        "GIGA",
        "GAMMA",
        "GLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MMAU A Holistic Benchmark of Agent Capabilities Across Diverse Domains": {
    "filename": "MMAU A Holistic Benchmark of Agent Capabilities Across Diverse Domains.pdf",
    "analysis": {
      "benchmarks": [
        "MMAU",
        "CodeContest",
        "Kaggle",
        "DeepMind-Math"
      ],
      "models": [
        "GPT-4o",
        "GPT-4-Turbo",
        "GPT-3.5-Turbo",
        "Gemini-1.5-pro",
        "Gemini-1.0-pro",
        "Claude3 Opus",
        "Claude3 Sonnet",
        "Claude3 Haiku",
        "Mixtral-8x22B-v0.1",
        "Mixtral-8x7B-v0.1",
        "Mistral-7B-v0.2",
        "Phi-3-mini4K-instruct",
        "Openfunctions-v2",
        "Hermes-2-Pro-Mistral-7B",
        "Command R",
        "LLama2-70B",
        "Llama2-13B",
        "Llama2-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Principled Instructions Are All You Need for Questioning LLaMA-12 GPT-354": {
    "filename": "Principled Instructions Are All You Need for Questioning LLaMA-12 GPT-354.pdf",
    "analysis": {
      "benchmarks": [
        "ATLAS"
      ],
      "models": [
        "LLaMA-1-7B",
        "LLaMA-1-13B",
        "LLaMA-2-7B",
        "LLaMA-2-13B",
        "LLaMA-2-70B-chat",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "R2-Bench Benchmarking the Robustness of Referring Perception Models under Perturbations": {
    "filename": "R2-Bench Benchmarking the Robustness of Referring Perception Models under Perturbations.pdf",
    "analysis": {
      "benchmarks": [
        "RefCOCO",
        "RefCOCO+",
        "RefCOCOg",
        "DAVIS",
        "YTVOS",
        "Ref-DAVIS",
        "Ref-YTVOS",
        "AVS-s4",
        "AVS-ms3",
        "ScanNet",
        "ICL"
      ],
      "models": [
        "R2-Agent",
        "LAVT",
        "PolyFormer",
        "X-Decoder",
        "ETRIS",
        "SEEM",
        "AOT",
        "DeAOT",
        "XMem",
        "DEVA",
        "Cutie",
        "MTTR",
        "SgMg",
        "ReferFormer",
        "OnlineRefer",
        "R2-VOS",
        "AVS",
        "CATR",
        "AVSegFormer",
        "QSD",
        "ConceptFusion"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Location is Key Leveraging Large Language Model for Functional Bug Localization in Verilog": {
    "filename": "Location is Key Leveraging Large Language Model for Functional Bug Localization in Verilog.pdf",
    "analysis": {
      "benchmarks": [
        "RTLLM-based testset",
        "Devign"
      ],
      "models": [
        "Location isKey (LiK)",
        "GPT-3.5",
        "GPT-4",
        "Claude-3.5-Sonnet",
        "Deepseek-coder-V2-Lite-16B",
        "Strider"
      ]
    }
  },
  "Benchmarking and Explaining Large Language Model-based Code Generation A Causality-Centric Approach": {
    "filename": "Benchmarking and Explaining Large Language Model-based Code Generation A Causality-Centric Approach.pdf",
    "analysis": {
      "benchmarks": [
        "CodeSearchNet",
        "HumanEval",
        "APPS"
      ],
      "models": [
        "GPT-Neo",
        "GPT-3.5-Turbo (ChatGPT)",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Comparing Foundation Models using Data Kernels": {
    "filename": "Comparing Foundation Models using Data Kernels.pdf",
    "analysis": {
      "benchmarks": [
        "DBPedia14"
      ],
      "models": [
        "BERT",
        "plant-ablated BERT",
        "baseline BERT",
        "partially ablated BERT models"
      ]
    }
  },
  "Towards the Effect of Examples on In-Context Learning A Theoretical Case Study": {
    "filename": "Towards the Effect of Examples on In-Context Learning A Theoretical Case Study.pdf",
    "analysis": {
      "benchmarks": [
        "SST2"
      ],
      "models": [
        "Pythia-6.9B",
        "Llama2-7B",
        "GPT-2",
        "decoder-only Transformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MALMM Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation": {
    "filename": "MALMM Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation.pdf",
    "analysis": {
      "benchmarks": [
        "RLBench"
      ],
      "models": [
        "MALMM",
        "Single Agent (SA)",
        "Multi-Agent (MA)",
        "Code as Policies (CAP)",
        "VoxPoser"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Meta-Reasoning Semantics-Symbol Deconstruction For Large Language Models": {
    "filename": "Meta-Reasoning Semantics-Symbol Deconstruction For Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MultiArith",
        "GSM8K",
        "AddSub",
        "Last Letter Concatenation",
        "Coin Flip",
        "Web of Lies",
        "Tracking Shuffled Objects",
        "Hi-ToM"
      ],
      "models": [
        "Meta-Reasoning",
        "Chain-of-Thought",
        "GPT-3",
        "ChatGPT",
        "Codex",
        "PaLM",
        "Zero-Shot",
        "Few-Shot",
        "Zero-Shot-CoT",
        "Few-Shot-CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Models with Rationality": {
    "filename": "Language Models with Rationality.pdf",
    "analysis": {
      "benchmarks": [
        "EntailmentBank",
        "OBQA",
        "QuaRTz"
      ],
      "models": [
        "REFLEX",
        "T5-11B Entailer"
      ]
    }
  },
  "Evaluation of ChatGPTs Smart Contract Auditing Capabilities Based on Chain of Thought": {
    "filename": "Evaluation of ChatGPTs Smart Contract Auditing Capabilities Based on Chain of Thought.pdf",
    "analysis": {
      "benchmarks": [
        "SolidiFI-benchmark"
      ],
      "models": [
        "GPT-4"
      ]
    }
  },
  "Knowledge-aware Alert Aggregation in Large-scale Cloud Systems a Hybrid Approach": {
    "filename": "Knowledge-aware Alert Aggregation in Large-scale Cloud Systems a Hybrid Approach.pdf",
    "analysis": {
      "benchmarks": [
        "Dataset A",
        "Dataset B",
        "Dataset C"
      ],
      "models": [
        "COLA",
        "COLA w/o SFT",
        "FP-Growth",
        "DBSCAN",
        "AlertStorm",
        "LiDAR",
        "OAS",
        "iPACK"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Hints-In-Browser Benchmarking Language Models for Programming Feedback Generation": {
    "filename": "Hints-In-Browser Benchmarking Language Models for Programming Feedback Generation.pdf",
    "analysis": {
      "benchmarks": [
        "BASIC ALGO",
        "INTRO PYNUS",
        "KAREL ALGO"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Llama-3-8B",
        "Llama-3-8B-dom",
        "Llama-3-8B-web",
        "Llama-3-8B-dom-web",
        "Phi-3-3.8B",
        "Phi-3-3.8B-dom",
        "Phi-3-3.8B-web",
        "Phi-3-3.8B-dom-web"
      ]
    }
  },
  "GraphRouter A Graph-based Router for LLM Selections": {
    "filename": "GraphRouter A Graph-based Router for LLM Selections.pdf",
    "analysis": {
      "benchmarks": [
        "Alpaca",
        "GSM8K",
        "SQUAD",
        "Multi-News"
      ],
      "models": [
        "GraphRouter",
        "Hybrid LLM",
        "FrugalGPT",
        "C2MAB-V",
        "Largest LLM",
        "Smallest LLM",
        "Prompt LLM",
        "Oracle",
        "LLaMA-3 (7b)",
        "Mixtral-8x7B",
        "NousResearch",
        "LLaMA-2 (7b)",
        "Mistral-7b",
        "LLaMA-3 (70b)",
        "LLaMA-3-Turbo (8b)",
        "LLaMA-3-Turbo (70b)",
        "Llama-3.1-Turbo (70b)",
        "Qwen-1.5 (72b)"
      ]
    }
  },
  "Programming Every Example Lifting Pre-training Data Quality like Experts at Scale": {
    "filename": "Programming Every Example Lifting Pre-training Data Quality like Experts at Scale.pdf",
    "analysis": {
      "benchmarks": [
        "ARC-C",
        "ARC-E",
        "CSQA",
        "HellaSwag",
        "MMLU",
        "OBQA",
        "PIQA",
        "SIQA",
        "WinoGrande",
        "SciQA",
        "GSM8K",
        "MATH",
        "SVAMP",
        "ASDiv",
        "MAWPS",
        "TAB",
        "MQA",
        "MMLU STEM",
        "SAT MATH"
      ],
      "models": [
        "PROX",
        "MISTRAL-7B",
        "LLAMA-2-7B",
        "CODELLAMA-7B",
        "LLEMMA-7B",
        "TinyLLaMA-1.1B",
        "OLMo-1B",
        "Pythia-1.4B",
        "InternLM-MATH",
        "TLM-S",
        "TLM-XS",
        "TLM-M",
        "RHO-1",
        "INTERNLM2-MATH",
        "DEEPSEEK-LLM",
        "LLEMMA",
        "INTERNLM2-BASE",
        "TINYLLAMA-1.1B",
        "LLAMA-2",
        "CODELLAMA",
        "MISTRAL",
        "DSIR",
        "DsDm",
        "MATES",
        "QuRating",
        "INSTRUCTION LM-1.3B",
        "COSMO-1.8B",
        "SHEAD LLAMA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large Language Models Reasoning": {
    "filename": "Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large Language Models Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "ASDiv",
        "MAWPS",
        "Cluttr",
        "List Functions",
        "Babi-Induction",
        "Babi-Deduction",
        "First Letter Concatenation",
        "Last Letter Concatenation",
        "Reverse List",
        "Coin Flip"
      ],
      "models": [
        "Llama-1",
        "Llama-2",
        "Llama-3",
        "Mistral",
        "Qwen-1.5",
        "Gemma"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "G\u00f6del Agent A Self-Referential Agent Framework for Recursive Self-Improvement": {
    "filename": "G\u00f6del Agent A Self-Referential Agent Framework for Recursive Self-Improvement.pdf",
    "analysis": {
      "benchmarks": [
        "DROP",
        "MGSM",
        "MMLU",
        "GPQA"
      ],
      "models": [
        "Godel Agent",
        "Chain-of-Thought (CoT)",
        "Self-Consistency with Chain-of-Thought (CoT-SC)",
        "Self-Refine",
        "LLM-Debate",
        "Step-back Abstraction",
        "Quality-Diversity",
        "Role Assignment",
        "Meta Agent Search"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PROMPT-SAW Leveraging Relation-Aware Graphs for Textual Prompt Compression": {
    "filename": "PROMPT-SAW Leveraging Relation-Aware Graphs for Textual Prompt Compression.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K-aug",
        "NaturalQuestions",
        "ShareGPT"
      ],
      "models": [
        "Prompt-SAW",
        "Selective-Context",
        "LLMLingua",
        "LongLLMLingua",
        "GPT4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond Labels Aligning Large Language Models with Human-like Reasoning": {
    "filename": "Beyond Labels Aligning Large Language Models with Human-like Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "DFAR",
        "ETHOS"
      ],
      "models": [
        "Llama-2 (7B)",
        "Mistral (7B)",
        "SVM",
        "Random Forests",
        "Gradient Boosting",
        "Logistic Regression",
        "BERT",
        "DistilBERT"
      ]
    }
  },
  "A Personalised Learning Tool for Physics Undergraduate Students Built On a Large Language Model for Symbolic Regression": {
    "filename": "A Personalised Learning Tool for Physics Undergraduate Students Built On a Large Language Model for Symbolic Regression.pdf",
    "analysis": {
      "benchmarks": [
        "Feynman Lectures on Physics"
      ],
      "models": [
        "GPT-4",
        "AI Feynman",
        "Single-stage General Dimensional Analysis Method",
        "Two-stage General Dimensional Analysis Method",
        "Single-stage Rayleigh\u2019s Method Analysis Method",
        "Two-stage Rayleigh\u2019s Method Analysis Method"
      ]
    }
  },
  "AutoGPTP Affordance-based Task Planning with Large Language Models": {
    "filename": "AutoGPTP Affordance-based Task Planning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SayCan instruction set",
        "newly created dataset with 150 scenarios"
      ],
      "models": [
        "AutoGPT+P",
        "LLM+P",
        "SayCan"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Exploratory Learning through Exploratory Search with the Emergence of Large Language Models": {
    "filename": "Enhancing Exploratory Learning through Exploratory Search with the Emergence of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "LLMs",
        "neural network language model",
        "Transformer",
        "large model search systems",
        "large model agent systems",
        "end-to-end large model search systems",
        "large search model"
      ]
    }
  },
  "Do LLMs Exhibit Human-like Response Biases A Case Study in Survey Design": {
    "filename": "Do LLMs Exhibit Human-like Response Biases A Case Study in Survey Design.pdf",
    "analysis": {
      "benchmarks": [
        "Pew Research's American Trends Panel (ATP)"
      ],
      "models": [
        "Llama2 7b",
        "Llama2 13b",
        "Llama2 70b",
        "Solar",
        "Llama2 7b-chat",
        "Llama2 13b-chat",
        "Llama2 70b-chat",
        "GPT 3.5 turbo",
        "GPT 3.5 turbo instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Empowering Autonomous Driving with Large Language Models A Safety Perspective": {
    "filename": "Empowering Autonomous Driving with Large Language Models A Safety Perspective.pdf",
    "analysis": {
      "benchmarks": [
        "HighwayEnv"
      ],
      "models": [
        "adaptive LLM-conditioned Model Predictive Control (MPC)",
        "LLM-enabled interactive behavior planning scheme with a state machine",
        "DriveLikeAHuman",
        "LanguageMPC"
      ]
    }
  },
  "Can Language Models Learn to Skip Steps": {
    "filename": "Can Language Models Learn to Skip Steps.pdf",
    "analysis": {
      "benchmarks": [
        "Analog of Algebra",
        "Multi-digit Addition",
        "Directional Reasoning"
      ],
      "models": [
        "Llama2-7B",
        "phi-3-mini",
        "M0",
        "Mk",
        "Mstandard_k"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Model Self-improvement by Reinforcement Learning Contemplation": {
    "filename": "Language Model Self-improvement by Reinforcement Learning Contemplation.pdf",
    "analysis": {
      "benchmarks": [
        "CommonGen",
        "CNN/Daily Mail",
        "IWSLT 2017",
        "Bigbench-hard",
        "BBC"
      ],
      "models": [
        "SIRLC",
        "FLAN-T5",
        "FLAN-T5-Large",
        "FLAN-T5-XL",
        "FLAN-T5-XXL",
        "FLAN-T5-Small",
        "FLAN-T5-Base",
        "Self-consistency (SC)",
        "LMSI",
        "Reinforcement Learning Fine-Tuning (RLFT)",
        "DG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tool-Augmented Reward Modeling": {
    "filename": "Tool-Augmented Reward Modeling.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA",
        "Retarded-bar",
        "HH-RLHF*",
        "TARA"
      ],
      "models": [
        "Themis",
        "Gopher 280B",
        "Vicuna-7B",
        "Bert-Large",
        "GPT-3",
        "OPT",
        "Galactica",
        "Vicuna-33B",
        "Vicuna-13B",
        "Vicuna-7B + LoRA",
        "Vicuna-13B + LoRA",
        "Vicuna-33B + LoRA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EnvGen Generating and Adapting Environments via LLMs for Training Embodied Agents": {
    "filename": "EnvGen Generating and Adapting Environments via LLMs for Training Embodied Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Crafter",
        "Heist"
      ],
      "models": [
        "EnvGen",
        "PPO",
        "Achievement Distillation (AD)",
        "SPRING",
        "ELLM",
        "LSTM-SPCNN",
        "DreamerV3",
        "MuZero + SPR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evidence from counterfactual tasks supports emergent analogical reasoning in large language models": {
    "filename": "Evidence from counterfactual tasks supports emergent analogical reasoning in large language models.pdf",
    "analysis": {
      "benchmarks": [
        "Digit Matrices",
        "letter-string analogy variants",
        "counterfactual letter-string analogies"
      ],
      "models": [
        "GPT-3",
        "GPT-4",
        "GPT-4 + code execution"
      ]
    }
  },
  "2AFC Prompting of Large Multimodal Models for Image Quality Assessment": {
    "filename": "2AFC Prompting of Large Multimodal Models for Image Quality Assessment.pdf",
    "analysis": {
      "benchmarks": [
        "CSIQ",
        "KADID-10k",
        "MM21",
        "CLIVE",
        "KonIQ-10k",
        "SPAQ",
        "KADIS-700k",
        "SQAD"
      ],
      "models": [
        "IDEFICS-Instruct",
        "mPLUG-Owl",
        "XComposer-VL",
        "Q-Instruct",
        "GPT-4V",
        "NIQE",
        "DBCNN"
      ]
    }
  },
  "TrojanRobot Backdoor Attacks Against LLM-based Embodied Robots in the Physical World": {
    "filename": "TrojanRobot Backdoor Attacks Against LLM-based Embodied Robots in the Physical World.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "TrojanRobot",
        "plug-and-play vision-language backdoor model",
        "Yi-large",
        "Yi-vision language model",
        "moondream2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning to Decompose Hypothetical Question Decomposition Based on Comparable Texts": {
    "filename": "Learning to Decompose Hypothetical Question Decomposition Based on Comparable Texts.pdf",
    "analysis": {
      "benchmarks": [
        "Overnight",
        "TORQUE",
        "HotpotQA",
        "StrategyQA"
      ],
      "models": [
        "DECOMP T5",
        "DECOMP ENTAIL",
        "GPT-3",
        "T5-large",
        "RoBERTa*-IR"
      ]
    }
  },
  "Why think step-by-step Reasoning emerges from the locality of experience": {
    "filename": "Why think step-by-step Reasoning emerges from the locality of experience.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "autoregressive language model",
        "transformer",
        "GPT-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs": {
    "filename": "Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Letter Concatenation",
        "Date Understanding",
        "Math401",
        "AddSub",
        "Math10k"
      ],
      "models": [
        "Deconfounded Causal Adaptation (DCA)",
        "LLaMA-Adapter",
        "Alpaca-7B",
        "Vicuna-7B",
        "Koala-7B",
        "Baize-7B",
        "LLaMA2-7B",
        "Mistral-7B-ins",
        "S-Adapterh",
        "S-Adapterp",
        "P-Adapter",
        "LoRA",
        "AdaLoRA",
        "Prefix-Tune",
        "Prompt-Tune",
        "KronA",
        "LoftQ"
      ]
    }
  },
  "How Good Or Bad Are LLMs at Detecting Misleading Visualizations": {
    "filename": "How Good Or Bad Are LLMs at Detecting Misleading Visualizations.pdf",
    "analysis": {
      "benchmarks": [
        "FigureQA",
        "Competition on Harvesting Raw Tables from Infographics"
      ],
      "models": [
        "ChatGPT",
        "Copilot",
        "Gemini",
        "LLaVA-NeXT",
        "LLaVA-NeXT-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mitigating Copy Bias in In-Context Learning through Neuron Pruning": {
    "filename": "Mitigating Copy Bias in In-Context Learning through Neuron Pruning.pdf",
    "analysis": {
      "benchmarks": [
        "SST2",
        "SST5",
        "BBH Object Counting",
        "To Lowercase",
        "To Uppercase",
        "List First",
        "List Last",
        "List Max",
        "List Min",
        "Next Letter",
        "Present to Past",
        "Present to Gerund",
        "Singular to Plural",
        "Antonyms",
        "Past to Perfect",
        "Landmark",
        "Currency",
        "Country to Capital",
        "Person to Language",
        "Religion",
        "Continent"
      ],
      "models": [
        "GPT2-Small",
        "GPT2-Medium",
        "Bloom-560M",
        "Bloom-1.1B",
        "OPT-1.3B",
        "OPT-2.7B",
        "LLaMA",
        "Mamba-130M",
        "Mamba-370M",
        "Llama-2",
        "Llama-3-8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PAL Program-aided Language Models": {
    "filename": "PAL Program-aided Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-Bench Hard",
        "GSM 8K",
        "SVAMP",
        "ASDIV",
        "MAWPS",
        "SINGLEEQ",
        "SINGLEOP",
        "ADDSUB",
        "MULTIARITH",
        "GSM-HARD",
        "COLORED OBJECTS",
        "PENGUINS",
        "DATE",
        "OBJECT COUNTING",
        "REPEAT COPY"
      ],
      "models": [
        "PAL",
        "CODEX",
        "PaLM-540 B",
        "COT",
        "COTUL2-20B",
        "COTLaMDA-137B",
        "COTMinerva 540B",
        "DIRECT",
        "COTCodex",
        "COTPaLM-540 B",
        "COTMinerva 540B",
        "PALCodex",
        "code-cushman-001",
        "code-davinci-001",
        "code-davinci-002",
        "text-davinci-001",
        "text-davinci-002",
        "text-davinci-003"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Raising the Bar Investigating the Values of Large Language Models via Generative Evolving Testing": {
    "filename": "Raising the Bar Investigating the Values of Large Language Models via Generative Evolving Testing.pdf",
    "analysis": {
      "benchmarks": [
        "REALTOXICITY PROMPTS",
        "HARM BENCH",
        "ETHICS",
        "\u03b4-ROT",
        "MMLU",
        "AGIEval",
        "BIG-bench",
        "HELM",
        "BBQ",
        "REDDIT BIAS",
        "HARMFUL QA"
      ],
      "models": [
        "GETA",
        "GPT-4",
        "GPT-3.5-Turbo",
        "Gemini-1.0-Pro",
        "Mistral-Medium",
        "Mistral-7B-Instruct",
        "LLaMA-2-70B-Chat",
        "LLaMA-2-7B-Chat",
        "Orca-2-13B",
        "Static Evaluation (SE)",
        "CAT",
        "NCAT",
        "GPTFuzzer",
        "SAP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring Response Uncertainty in MLLMs An Empirical Evaluation under Misleading Scenarios": {
    "filename": "Exploring Response Uncertainty in MLLMs An Empirical Evaluation under Misleading Scenarios.pdf",
    "analysis": {
      "benchmarks": [
        "Multimodal Uncertainty Benchmark (MUB)",
        "MME",
        "MMB",
        "MMMU",
        "MathVista",
        "ScienceQA",
        "ConBench",
        "SEED",
        "MMStar",
        "AI2D",
        "SEED-Bench"
      ],
      "models": [
        "Llava",
        "Deepseek",
        "Phi-3-vision",
        "MinicpmII",
        "GPT-4o",
        "GLM-4v",
        "Gemini",
        "Qwen-VL",
        "Claude3",
        "MiniCPM-v-v2",
        "Yi-VL-6b",
        "Qwen-VL-Chat",
        "Deepseek-VL-7b-Chat",
        "LLaVA-NeXT-7b-vicuna",
        "MiniCPM-Llama3-v2.5",
        "GLM4V-9B-chat",
        "CogVLM-chat",
        "InternVL-Chat-V1-5",
        "LLaVA-Next-34b",
        "Yi-VL-34b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Toward Interactive Dictation": {
    "filename": "Toward Interactive Dictation.pdf",
    "analysis": {
      "benchmarks": [
        "TERTiUS"
      ],
      "models": [
        "T5",
        "GPT3",
        "segmentation model",
        "normalization model",
        "interpretation model",
        "MSEG",
        "MNOR",
        "MINT(state)",
        "MINT(program)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Harnessing the power of LLMs for normative reasoning in MASs": {
    "filename": "Harnessing the power of LLMs for normative reasoning in MASs.pdf",
    "analysis": {
      "benchmarks": [
        "Social-Chem-101",
        "Moral Stories",
        "Scruples",
        "Moral Integrity Corpus",
        "NormBank",
        "NormDial"
      ],
      "models": [
        "LLM agents",
        "Delphi",
        "ClarifyDelphi",
        "ChatGPT",
        "Theory of Mind (ToM) for LLM agents",
        "Retrieval Augmented Generation (RAG)"
      ]
    }
  },
  "Skill Learning Using Process Mining for Large Language Model Plan Generation": {
    "filename": "Skill Learning Using Process Mining for Large Language Model Plan Generation.pdf",
    "analysis": {
      "benchmarks": [
        "TaskBench",
        "ProcessTBench"
      ],
      "models": [
        "GPT-4-0613",
        "Universal Sentence Encoder (USE)",
        "OpenAI's ada-002",
        "Conformance Checking",
        "Hybrid (ada-002 + Conformance Checking)"
      ]
    }
  },
  "CoA Chain-of-Action for Generative Semantic Labels": {
    "filename": "CoA Chain-of-Action for Generative Semantic Labels.pdf",
    "analysis": {
      "benchmarks": [
        "VOC",
        "COCO",
        "NUS"
      ],
      "models": [
        "CoA",
        "BLIP-2",
        "InstructBLIP",
        "LLaVA",
        "MiniGPT-4",
        "LLaVA-1.5-7B",
        "LLaVA-1.5-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can AI Understand Human Personality - Comparing Human Experts and AI Systems at Predicting Personality Correlations": {
    "filename": "Can AI Understand Human Personality - Comparing Human Experts and AI Systems at Predicting Personality Correlations.pdf",
    "analysis": {
      "benchmarks": [
        "SAPA Personality Inventory"
      ],
      "models": [
        "PersonalityMap",
        "GPT-4o",
        "Claude 3 Opus"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AviationGPT A Large Language Model for the Aviation Domain": {
    "filename": "AviationGPT A Large Language Model for the Aviation Domain.pdf",
    "analysis": {
      "benchmarks": [
        "Digital Automatic Terminal Information Service (DATIS)",
        "National Traffic Management Log (NTML)"
      ],
      "models": [
        "AviationGPT",
        "Aviation-LLaMA2-chat-hf-70B",
        "Aviation-Mistral-7B-v0.1"
      ]
    }
  },
  "GPT-4 Is Too Smart To Be Safe Stealthy Chat with LLMs via Cipher": {
    "filename": "GPT-4 Is Too Smart To Be Safe Stealthy Chat with LLMs via Cipher.pdf",
    "analysis": {
      "benchmarks": [
        "Chinese safety assessment benchmark"
      ],
      "models": [
        "GPT-3.5-turbo-0613",
        "GPT-4-0613",
        "ALBERT",
        "Roberta",
        "Claude2",
        "Bard",
        "Llama2",
        "text-davinci-003",
        "Falcon-Chat",
        "Llama2-Chat",
        "SelfCipher"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Model LLM for Telecommunications A Comprehensive Survey on Principles Key Techniques and Opportunities": {
    "filename": "Large Language Model LLM for Telecommunications A Comprehensive Survey on Principles Key Techniques and Opportunities.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How to Protect Copyright Data in Optimization of Large Language Models": {
    "filename": "How to Protect Copyright Data in Optimization of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-4",
        "Llama",
        "BERT",
        "BARD",
        "PaLM",
        "OPT",
        "Copyright Regression"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant A Review": {
    "filename": "Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant A Review.pdf",
    "analysis": {
      "benchmarks": [
        "USMLE",
        "VQA-RAD",
        "SLAKE",
        "MultiMedQA",
        "MultiMedBench",
        "RadBench"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "Claude",
        "Med-PaLM",
        "Med-PaLM 2",
        "LLaMA",
        "ChatDoctor",
        "Radiology-GPT",
        "NYUTron",
        "BiomedGPT",
        "Med-PaLM Multimodal",
        "RadFM",
        "ELIXR",
        "Geneformer",
        "HeLM",
        "PathAsst",
        "AD-AutoGPT",
        "CHA",
        "ImpressionGPT",
        "PharmacyGPT",
        "ChatCAD+"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Plum Prompt Learning using Metaheuristic": {
    "filename": "Plum Prompt Learning using Metaheuristic.pdf",
    "analysis": {
      "benchmarks": [
        "Natural-Instructions datasets v2.6",
        "Commonsense Question Answering",
        "AQuA"
      ],
      "models": [
        "Plum-HC",
        "Plum-SA",
        "Plum-GA-M",
        "Plum-GA-C",
        "Plum-TS",
        "Plum-HS",
        "BDPL",
        "BBT",
        "GrIPS",
        "APO",
        "GPT2-large",
        "GPT3-babbage"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Empirical Study of Retrieval Augmented Generation with Chain-of-Thought": {
    "filename": "An Empirical Study of Retrieval Augmented Generation with Chain-of-Thought.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "PubMedQA",
        "DuReader robust"
      ],
      "models": [
        "RAFT",
        "LLaMA2-7B-chat",
        "Qwen-1.5-7B-chat",
        "DSF (Domain Specific Finetuning) + zero-shot prompting",
        "DSF + RAG",
        "RAFT w.o. CoT"
      ]
    }
  },
  "A Neural Rewriting System to Solve Algorithmic Problems": {
    "filename": "A Neural Rewriting System to Solve Algorithmic Problems.pdf",
    "analysis": {
      "benchmarks": [
        "ListOps",
        "Arithmetic",
        "Algebra"
      ],
      "models": [
        "Neural Rewriting System",
        "Neural Data Router",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Building blocks for complex tasks Robust generative event extraction for radiology reports under domain shifts": {
    "filename": "Building blocks for complex tasks Robust generative event extraction for radiology reports under domain shifts.pdf",
    "analysis": {
      "benchmarks": [
        "MRI",
        "PET",
        "CT"
      ],
      "models": [
        "multi-pass T5-based text-to-text generative models",
        "BERT-based task-specific classification layers",
        "mSpERT",
        "T5-base 3-step (vanilla)",
        "T5-base 2-step (vanilla)",
        "T5-base 1-step (vanilla)",
        "T5-base 1-step (blocks)",
        "T5-large"
      ]
    }
  },
  "Llama Guard LLM-based Input-Output Safeguard for Human-AI Conversations": {
    "filename": "Llama Guard LLM-based Input-Output Safeguard for Human-AI Conversations.pdf",
    "analysis": {
      "benchmarks": [
        "OpenAI Moderation Evaluation dataset",
        "ToxicChat"
      ],
      "models": [
        "Llama Guard",
        "OpenAI Moderation API",
        "Perspective API",
        "Azure AI Content Safety API",
        "GPT-4",
        "Llama2-7b"
      ]
    }
  },
  "LLM-Enhanced Data Management": {
    "filename": "LLM-Enhanced Data Management.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLMDB",
        "Marcoroni-7B",
        "vit-gpt2",
        "Diag-v1",
        "GPT-3.5"
      ]
    }
  },
  "Semantic Parsing for Complex Data Retrieval Targeting Query Plans vs SQL for No-Code Access to Relational Databases": {
    "filename": "Semantic Parsing for Complex Data Retrieval Targeting Query Plans vs SQL for No-Code Access to Relational Databases.pdf",
    "analysis": {
      "benchmarks": [
        "Spider",
        "MIMICSQL",
        "SEDE",
        "WIKISQL"
      ],
      "models": [
        "T5",
        "OpenAPI CodeX",
        "GPT variants",
        "BERT-based models",
        "RAT-SQL",
        "NatSQL",
        "DIN-SQL",
        "GPT-3.5-turbo",
        "GPT-4",
        "RESDSQL-3B",
        "CodeT5 Large",
        "PICARD",
        "SyntaxSQLNet",
        "IRNet",
        "SemQL",
        "SyntaxNet",
        "NatSQL",
        "QMDR"
      ]
    }
  },
  "dZiner Rational Inverse Design of Materials with AI Agents": {
    "filename": "dZiner Rational Inverse Design of Materials with AI Agents.pdf",
    "analysis": {
      "benchmarks": [
        "surfactant design and critical micelle concentration inference",
        "drug design and targeted docking inference",
        "MOF organic linker design and CO2 adsorption capacity inference"
      ],
      "models": [
        "dZiner",
        "Claude 3.5 Sonnet",
        "GPT-4o",
        "Graph Convolutional Neural Network (GCN)",
        "AutoDock Vina",
        "MOFormer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Brainstorming Brings Power to Large Language Models of Knowledge Reasoning": {
    "filename": "Brainstorming Brings Power to Large Language Models of Knowledge Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "GSM",
        "ARC-easy",
        "ARC-challenge"
      ],
      "models": [
        "ChatGPT",
        "Gemini Pro",
        "Qianwen1.5-7B",
        "Baichuan2-7B",
        "Mistral-7B",
        "Qwen-7B",
        "GPT-3.5",
        "Qwen-14B",
        "Baichuan-13B",
        "Mixtral 7x8B"
      ]
    }
  },
  "Designing for Human-Agent Alignment Understanding what humans want from their agents": {
    "filename": "Designing for Human-Agent Alignment Understanding what humans want from their agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "AutoGPT",
        "sales agents",
        "buyer agents"
      ]
    }
  },
  "Why Does ChatGPT Fall Short in Providing Truthful Answers": {
    "filename": "Why Does ChatGPT Fall Short in Providing Truthful Answers.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "BoolQ"
      ],
      "models": [
        "ChatGPT",
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "Mixture of insighTful Experts MoTE The Synergy of Thought Chains and Expert Mixtures in Self-Alignment": {
    "filename": "Mixture of insighTful Experts MoTE The Synergy of Thought Chains and Expert Mixtures in Self-Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "PKU-SafeRLHF",
        "HH-RLHF",
        "AlpacaFarm"
      ],
      "models": [
        "Mixture of insighTful Experts (MoTE)",
        "AlignCoT",
        "Alpaca-7B",
        "Wizard-Vicuna-Uncensored 7B",
        "Zero-shot CoT",
        "Critique-Revise",
        "Mistake Analysis",
        "RLCD",
        "MATRIX"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HRoT Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering": {
    "filename": "HRoT Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "MultiHiertt"
      ],
      "models": [
        "HRoT",
        "CoT",
        "TAGOP",
        "FinQANet",
        "MT2Net",
        "NAPG",
        "DeBERTa",
        "BERT",
        "RoBERTa"
      ]
    }
  },
  "Question-focused Summarization by Decomposing Articles into Facts and Opinions and Retrieving Entities": {
    "filename": "Question-focused Summarization by Decomposing Articles into Facts and Opinions and Retrieving Entities.pdf",
    "analysis": {
      "benchmarks": [
        "Economist dataset",
        "Wikipedia",
        "10K SEC filing data"
      ],
      "models": [
        "GPT 3.5 turbo",
        "Dense Passage Retrieval (DPR)",
        "Hugging Face sentence transformer",
        "NLTK and Spacy rule-based model",
        "Pyserini retrieval model"
      ]
    }
  },
  "Moral Alignment for LLM Agents": {
    "filename": "Moral Alignment for LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Iterated Prisoner's Dilemma",
        "Iterated Stag Hunt",
        "Iterated Chicken",
        "Iterated Bach or Stravinsky",
        "Iterated Defective Coordination"
      ],
      "models": [
        "Gemma2-2b-it",
        "Game reward model",
        "Deontological reward model",
        "Utilitarian reward model",
        "Game+Deontological reward model",
        "Game, then Deontological reward model",
        "Game, then Utilitarian reward model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring Autonomous Agents through the Lens of Large Language Models A Review": {
    "filename": "Exploring Autonomous Agents through the Lens of Large Language Models A Review.pdf",
    "analysis": {
      "benchmarks": [
        "AgentBench",
        "WebArena",
        "ToolBench",
        "APIBench"
      ],
      "models": [
        "ToolLLaMA",
        "GPT-4",
        "GPT-3.5",
        "LLaMA",
        "LLaMA 2",
        "T5",
        "BART",
        "RoBERTa",
        "BERT",
        "DistilBERT",
        "Auto-GPT",
        "LangChain",
        "LiteLLM",
        "HuggingGPT",
        "Chain of Thought",
        "Self Consistent Chain of Thought",
        "Tree of Thoughts",
        "Graph of Thoughts",
        "ReAct",
        "Reflexion",
        "RLHF",
        "Direct Preference Optimization",
        "Retrieval Augmented Generation",
        "MedFuseNet",
        "AlphaCode"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SemioLLM Assessing Large Language Models for Semiological Analysis in Epilepsy Research": {
    "filename": "SemioLLM Assessing Large Language Models for Semiological Analysis in Epilepsy Research.pdf",
    "analysis": {
      "benchmarks": [
        "Semio2Brain"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Mixtral 8x7B",
        "Qwen-72chat"
      ]
    }
  },
  "Prompt-In-Prompt Learning for Universal Image Restoration": {
    "filename": "Prompt-In-Prompt Learning for Universal Image Restoration.pdf",
    "analysis": {
      "benchmarks": [
        "BSD68",
        "SOTS",
        "Rain100L",
        "GoPro",
        "LOL",
        "Urban100",
        "Rain100H"
      ],
      "models": [
        "PIP Restormer",
        "PIP NAFNet",
        "BRDNet",
        "LPNet",
        "FDGAN",
        "MPRNet",
        "DL",
        "AirNet",
        "PromptIR",
        "Restormer",
        "NAFNet",
        "SwinIR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Multimodal In-Context Learning for Vision  Language Models": {
    "filename": "Towards Multimodal In-Context Learning for Vision  Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SEED-Bench-2",
        "VL-checklist",
        "Stanford Dogs",
        "CUB",
        "Flowers",
        "Food-101",
        "Stanford Cars",
        "MME"
      ],
      "models": [
        "IDEFICS 9B",
        "OpenFlamingo",
        "EMU2",
        "LLaVA-1.5 13B",
        "Otter",
        "LLaVA-next (1.6) 13B",
        "Ours 13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Gradient Boosting Trees and Large Language Models for Tabular Data Few-Shot Learning": {
    "filename": "Gradient Boosting Trees and Large Language Models for Tabular Data Few-Shot Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Kaggle Titanic",
        "OpenML Diabetes",
        "Adult Income",
        "FICO",
        "Spaceship Titanic",
        "Pneumonia",
        "Bank",
        "Blood",
        "Credit-g",
        "Diabetes",
        "Heart",
        "Income",
        "FedCSIS 2024 Data Science Challenge"
      ],
      "models": [
        "TabLLM",
        "LightGBM",
        "ExtraTrees",
        "Xgboost",
        "Logistic Regression",
        "TabPFN",
        "TabNet",
        "Wide&Deep",
        "DeepFM",
        "SDTR",
        "DeepGBM",
        "TabNN",
        "BGNN",
        "TransTab",
        "TabTransformer",
        "SAINT",
        "NPT",
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "Large Language Models can be Guided to Evade AI-Generated Text Detection": {
    "filename": "Large Language Models can be Guided to Evade AI-Generated Text Detection.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD",
        "Eli5",
        "Yelp"
      ],
      "models": [
        "SICO",
        "GPT-3.5",
        "GPT-3.5 Detector",
        "GPT2 Detector",
        "DetectGPT",
        "Log-Rank",
        "GPTzero",
        "OpenAI Detector",
        "Parrot",
        "DIPPER",
        "GPT-Para",
        "Human Prompt",
        "SICO-Para",
        "SICO-Gen",
        "Vicuna-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CompCodeVet A Compiler-guided Validation and Enhancement Approach for Code Dataset": {
    "filename": "CompCodeVet A Compiler-guided Validation and Enhancement Approach for Code Dataset.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP"
      ],
      "models": [
        "CompCodeVet",
        "Llama2-7b",
        "CodeLlama2-instruct-7b",
        "CodeLlama",
        "StarChat",
        "WizardCoder",
        "GPT3.5-turbo",
        "GPT-4",
        "StarCoder",
        "Code Llama",
        "WizardCoder",
        "FLAN-T5"
      ]
    }
  },
  "Empowering Large Language Model Agents through Action Learning": {
    "filename": "Empowering Large Language Model Agents through Action Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Robotic Planning",
        "AlfWorld"
      ],
      "models": [
        "LearnAct",
        "ReAct",
        "ReAct+Reflexion",
        "Act",
        "Act+Reflexion",
        "CodeAsPolicy",
        "Voyager"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Rephrase and Respond Let Large Language Models Ask Better Questions for Themselves": {
    "filename": "Rephrase and Respond Let Large Language Models Ask Better Questions for Themselves.pdf",
    "analysis": {
      "benchmarks": [
        "MultiNLI",
        "CSQA",
        "Date Understanding",
        "Last Letter Concatenation",
        "Coin Flip",
        "Sports",
        "StereoSet",
        "Chinese Idiom"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5-turbo-0613",
        "Vicuna-13b-v1.5",
        "Rephrase and Respond (RaR)",
        "Two-step RaR",
        "Chain-of-Thought (CoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Annotation-Efficient Preference Optimization for Language Model Alignment": {
    "filename": "Annotation-Efficient Preference Optimization for Language Model Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "AlpacaFarm",
        "Anthropic's Helpfulness",
        "Anthropic's Harmlessness",
        "ARC",
        "HellaSwag",
        "TruthfulQA",
        "WinoGrande"
      ],
      "models": [
        "Direct Preference Optimization (DPO)",
        "Annotation-Efficient Preference Optimization (AEPO)",
        "Mistral-7b-sft-beta",
        "Dolly-v2-3b",
        "SFT (Mistral)",
        "Random sampling",
        "West-of-N (WoN)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Human-Language Model Interaction": {
    "filename": "Evaluating Human-Language Model Interaction.pdf",
    "analysis": {
      "benchmarks": [
        "EmpatheticDialogues",
        "CommonsenseDialogues",
        "Measuring Massive Multitask Language Understanding (MMLU)"
      ],
      "models": [
        "TextDavinci",
        "TextBabbage",
        "Davinci",
        "Jumbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RLingua Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models": {
    "filename": "RLingua Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "panda_gym",
        "RLBench"
      ],
      "models": [
        "RLingua",
        "TD3",
        "GPT-4 generated controller"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VISCO Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning": {
    "filename": "VISCO Benchmarking Fine-Grained Critique and Correction Towards Self-Improvement in Visual Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "VISCO",
        "CriticBench",
        "MetaCritique",
        "CriticEval",
        "MLLM-as-a-Judge",
        "Perception Collection"
      ],
      "models": [
        "LLaVA",
        "Molmo",
        "GPT-4o",
        "Claude-3.5",
        "DeepSeek-VL",
        "Qwen2-VL",
        "InternVL2",
        "Llama-3.2",
        "NVLM",
        "Prometheus-Vision",
        "LLaVA-Critic",
        "Gemini-1.5-Pro",
        "LOOK BACK"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cooperative Resilience in Artificial Intelligence Multiagent Systems": {
    "filename": "Cooperative Resilience in Artificial Intelligence Multiagent Systems.pdf",
    "analysis": {
      "benchmarks": [
        "Melting Pot 2.0",
        "Common Harvest Open"
      ],
      "models": [
        "Reinforcement Learning (RL)",
        "Large Language Models (LLM)",
        "Proximal Policy Optimization (PPO)",
        "LLM-augmented agents"
      ]
    }
  },
  "Exploring and Characterizing Large Language Models for Embedded System Development and Debugging": {
    "filename": "Exploring and Characterizing Large Language Models for Embedded System Development and Debugging.pdf",
    "analysis": {
      "benchmarks": [
        "I2C interfaces",
        "LoRa communication",
        "nRF52 power optimization",
        "Photoresistor reading",
        "Ultrasonic Rangefinder",
        "6-axis IMU (LSM6DSO)"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "PaLM 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How and Why LLMs Use Deprecated APIs in Code Completion An Empirical Study": {
    "filename": "How and Why LLMs Use Deprecated APIs in Code Completion An Empirical Study.pdf",
    "analysis": {
      "benchmarks": [
        "Numpy",
        "Pandas",
        "scikit-learn",
        "SciPy",
        "seaborn",
        "TensorFlow",
        "PyTorch",
        "Transformers"
      ],
      "models": [
        "CodeGen-350m",
        "CodeGen-2b",
        "CodeGen-6b",
        "DeepSeek-1.3b",
        "StarCoder2-3b",
        "CodeLlama-7b",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Workbench for Autograding RetrieveGenerate Systems": {
    "filename": "A Workbench for Autograding RetrieveGenerate Systems.pdf",
    "analysis": {
      "benchmarks": [
        "TREC DL 2020"
      ],
      "models": [
        "ChatGPT",
        "Llama2",
        "Mistral",
        "FLAN-T5",
        "GPT-4",
        "GPT-3.5",
        "pash_f3",
        "bigIR-T5xp-T5-F",
        "TUW-TK-2Layer",
        "terrier-InL2",
        "terrier-BM25",
        "DoRA_Large"
      ]
    }
  },
  "Exploring Effective Factors for Improving Visual In-Context Learning": {
    "filename": "Exploring Effective Factors for Improving Visual In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "pascal-5i",
        "PASCAL VOC 2012",
        "MSCOCO"
      ],
      "models": [
        "prompt-SelF",
        "OSLSM",
        "co-FCN",
        "VP-Random",
        "VPR-UsupPR",
        "VPR-SupPR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AgentClinic a multimodal agent benchmark to evaluate AI in simulated clinical environments": {
    "filename": "AgentClinic a multimodal agent benchmark to evaluate AI in simulated clinical environments.pdf",
    "analysis": {
      "benchmarks": [
        "AgentClinic",
        "MedQA",
        "AgentClinic-MedQA",
        "AgentClinic-MIMIC-IV",
        "AgentClinic-NEJM",
        "MIMIC-IV",
        "NEJM case challenges",
        "MedMCQA",
        "AgentClinic-Spec",
        "AgentClinic-Lang"
      ],
      "models": [
        "Claude-3.5",
        "GPT-4",
        "GPT-4o",
        "Mixtral-8x7B",
        "GPT-3.5",
        "Llama 3 70B-Instruct",
        "Llama 2 70B-chat",
        "Claude-3.5-Sonnet",
        "GPT-4o-mini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Extractive Summarization via ChatGPT for Faithful Summary Generation": {
    "filename": "Extractive Summarization via ChatGPT for Faithful Summary Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CNN/DM",
        "XSum",
        "PubMed",
        "Reddit"
      ],
      "models": [
        "ChatGPT-Ext",
        "ChatGPT-Abs",
        "SOTA-Ext",
        "SOTA-Abs",
        "MatchSum",
        "BRIO",
        "SummaReranker",
        "GSum"
      ]
    }
  },
  "LTLBench Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models": {
    "filename": "LTLBench Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "LTLBench"
      ],
      "models": [
        "GPT-3.5 Turbo",
        "Llama 3",
        "Qwen",
        "Gemma",
        "Mistral"
      ]
    }
  },
  "A Survey on ChatGPT AIGenerated Contents Challenges and Solutions": {
    "filename": "A Survey on ChatGPT AIGenerated Contents Challenges and Solutions.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-4",
        "GPT-3",
        "DALL-E 2",
        "PaLM 2",
        "Imagen",
        "T-NLG",
        "MT-NLG",
        "LLaMa",
        "BERT",
        "VAE",
        "VAE-GAN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Visual Sketchpad Sketching as a Visual Chain of Thought for Multimodal Language Models": {
    "filename": "Visual Sketchpad Sketching as a Visual Chain of Thought for Multimodal Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "V*Bench",
        "BLINK",
        "visual correspondence",
        "Geometry3K",
        "IsoBench",
        "MMVP"
      ],
      "models": [
        "SKETCHPAD",
        "GPT-4o",
        "GPT-4 Turbo",
        "Claude 3",
        "Gemini-Pro",
        "Mixtral 8x7B",
        "LLaMA-2-70B",
        "LLaV A-1.5-7B",
        "LLaV A-1.5-13B",
        "LLaV A-NeXT-34B",
        "GPT-4V-preview",
        "SEAL",
        "LLaV A-NeXT-13B",
        "LLaV A-NeXT-34B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VLM Agents Generate Their Own Memories Distilling Experience into Embodied Programs of Thought": {
    "filename": "VLM Agents Generate Their Own Memories Distilling Experience into Embodied Programs of Thought.pdf",
    "analysis": {
      "benchmarks": [
        "TEACh",
        "VisualWebArena",
        "Ego4D"
      ],
      "models": [
        "ICAL",
        "HELPER",
        "GPT4V",
        "GPT4o",
        "Zero-shot CoT",
        "Raw Visual Demos",
        "Raw Kinesthetic Demos",
        "Supervised Baseline"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Answering Complex Questions over Text by Hybrid Question Parsing and Execution": {
    "filename": "Answering Complex Questions over Text by Hybrid Question Parsing and Execution.pdf",
    "analysis": {
      "benchmarks": [
        "MuSiQue",
        "2WikiMultiHopQA",
        "HotpotQA",
        "NQ"
      ],
      "models": [
        "HPE",
        "FiD",
        "FiD+PT",
        "FiDLF\u2212>Ans",
        "FiDCQ\u2212>LF+Ans",
        "Self-ask + Search",
        "IRCoT",
        "SA",
        "EX(SA)",
        "NA-Reviewer",
        "SupportFiD",
        "SelectFiD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DeepSeekMath Pushing the Limits of Mathematical Reasoning in Open Language Models": {
    "filename": "DeepSeekMath Pushing the Limits of Mathematical Reasoning in Open Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "MMLU",
        "BBH",
        "CMATH",
        "MGSM-zh",
        "Gaokao-MathCloze",
        "Gaokao-MathQA",
        "miniF2F",
        "HumanEval",
        "MBPP",
        "SAT",
        "OCW Courses"
      ],
      "models": [
        "DeepSeekMath 7B",
        "DeepSeekMath-Base 7B",
        "DeepSeekMath-Instruct 7B",
        "DeepSeekMath-RL 7B",
        "DeepSeek-Coder-Base-v1.5 7B",
        "Minerva 540B",
        "Mistral 7B",
        "Llemma 34B",
        "CodeLlama 34B",
        "InternLM2-Math 20B",
        "Qwen 72B",
        "Math-Shepherd-Mistral 7B",
        "WizardMath-v1.1 7B",
        "MetaMath 70B",
        "SeaLLM-v2 7B",
        "ChatGLM3 6B",
        "WizardMath-v1.0 70B",
        "ToRA 34B",
        "MAmmoTH 70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Response Tuning Aligning Large Language Models without Instruction": {
    "filename": "Response Tuning Aligning Large Language Models without Instruction.pdf",
    "analysis": {
      "benchmarks": [
        "AlpacaEval",
        "JustEval",
        "MMLU",
        "OpenbookQA",
        "HellaSwag",
        "ARC",
        "GSM8K",
        "PIQA",
        "AdvBench",
        "HarmBench",
        "MaliciousInstruct",
        "XSTest"
      ],
      "models": [
        "Response Tuning (RT)",
        "Llama-3.1-8B",
        "Gemma-2-2B",
        "Gemma-2-9B",
        "Mistral-7B-v0.3",
        "Alpaca",
        "Dolly",
        "LIMA",
        "Llama-3.1-70B-Instruct",
        "URIAL",
        "URIAL-R"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Faithful Model Explanation in NLP A Survey": {
    "filename": "Towards Faithful Model Explanation in NLP A Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning Semantic Role Labeling from Compatible Label Sequences": {
    "filename": "Learning Semantic Role Labeling from Compatible Label Sequences.pdf",
    "analysis": {
      "benchmarks": [
        "CoNLL05",
        "SEMLINK"
      ],
      "models": [
        "Joint CRF",
        "Multitask",
        "Joint",
        "Joint+CRF PB",
        "Marginal",
        "Marginal SEML",
        "IWCS2021"
      ]
    }
  },
  "SCHEMA State CHangEs MAtter for Procedure Planning in Instructional Videos": {
    "filename": "SCHEMA State CHangEs MAtter for Procedure Planning in Instructional Videos.pdf",
    "analysis": {
      "benchmarks": [
        "CrossTask",
        "COIN",
        "NIV"
      ],
      "models": [
        "SCHEMA",
        "PlaTe",
        "Ext-GAIL",
        "P3IV",
        "PDPP",
        "EGPP",
        "DDN",
        "Retrieval-Based",
        "WLTDO",
        "UAAA",
        "UPN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FastSwitch Optimizing Context Switching Efficiency in Fairness-aware Large Language Model Serving": {
    "filename": "FastSwitch Optimizing Context Switching Efficiency in Fairness-aware Large Language Model Serving.pdf",
    "analysis": {
      "benchmarks": [
        "ShareGPT"
      ],
      "models": [
        "FastSwitch",
        "vLLM",
        "LLaMA-8B",
        "Qwen-32B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RadAdapt Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models": {
    "filename": "RadAdapt Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-III",
        "MIMIC-CXR",
        "Stanford Hospital ultrasound dataset"
      ],
      "models": [
        "RadAdapt",
        "T5",
        "FLAN-T5",
        "SCIFIVE",
        "CLIN-T5-SCI",
        "CLIN-T5",
        "LoRA",
        "prefix tuning"
      ]
    }
  },
  "Glider Global and Local Instruction-Driven Expert Router": {
    "filename": "Glider Global and Local Instruction-Driven Expert Router.pdf",
    "analysis": {
      "benchmarks": [
        "T0 held-in",
        "T0 held-out",
        "FLAN",
        "big-bench lite",
        "hard tasks",
        "CommonGen",
        "PAWS",
        "COPA",
        "StoryCloze",
        "SuperGLUE",
        "Super Natural Instructions",
        "dialogue datasets",
        "Chain-of-Thought datasets"
      ],
      "models": [
        "GLIDER",
        "T5-based expert models",
        "Phatgoose",
        "LoRA",
        "T0-3B",
        "FLAN-T5 XL",
        "Expert Merging",
        "Arrow",
        "LoRA Hub",
        "Oracle Expert"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DiPT Enhancing LLM reasoning through diversified perspective-taking": {
    "filename": "DiPT Enhancing LLM reasoning through diversified perspective-taking.pdf",
    "analysis": {
      "benchmarks": [
        "AG News",
        "CosmosQA",
        "RTE",
        "SST-5",
        "SVAMP",
        "TREC",
        "TruthfulQA",
        "OpenbookQA",
        "GSM8K",
        "CoQA",
        "XWinograd",
        "MMLU",
        "PIQA",
        "Hellaswag",
        "Lambada",
        "MultiArith",
        "AddSub",
        "WSC",
        "Winogrande",
        "ARC-challenge",
        "WMT16",
        "Lambada-multilingual"
      ],
      "models": [
        "DiPT",
        "Chain-of-Thought (CoT)",
        "Rephrase and Respond (RaR)",
        "Analogical Reasoners (ANL)",
        "GPT-4-Turbo",
        "Mistral7B-Instruct-v0.1",
        "Mistral7B-v0.1",
        "Mistral7B-Instruct-v0.2",
        "Llama3-8B",
        "Llama3-8B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cobblestone Iterative Automation for Formal Verification": {
    "filename": "Cobblestone Iterative Automation for Formal Verification.pdf",
    "analysis": {
      "benchmarks": [
        "CoqGym",
        "coq-wigderson"
      ],
      "models": [
        "COBBLESTONE",
        "Proverbot9001",
        "CoqHammer",
        "ChainOfThought",
        "TacticByTactic",
        "COBBLESTONE-NoHammer",
        "TacticByTactic-NoHammer",
        "COBBLESTONE-PerfPrems",
        "COBBLESTONE-PerfDecomp"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large language models can accurately predict searcher preferences": {
    "filename": "Large language models can accurately predict searcher preferences.pdf",
    "analysis": {
      "benchmarks": [
        "TREC-Robust 2004"
      ],
      "models": [
        "GPT-4",
        "LLM labellers",
        "human labellers",
        "crowd workers"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Categorical Framework for Quantifying Emergent Effects in Network Topology": {
    "filename": "A Categorical Framework for Quantifying Emergent Effects in Network Topology.pdf",
    "analysis": {
      "benchmarks": [
        "random Boolean network"
      ],
      "models": [
        "proposed framework for emergence",
        "information-theoretic measure of emergence"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Chain of AI-based Solutions for Resolving FQNs and Fixing Syntax Errors in Partial Code": {
    "filename": "A Chain of AI-based Solutions for Resolving FQNs and Fixing Syntax Errors in Partial Code.pdf",
    "analysis": {
      "benchmarks": [
        "Python dataset",
        "Java dataset"
      ],
      "models": [
        "PCR-Chain",
        "RING",
        "BIFI",
        "CURE",
        "PCR-D",
        "PCR-CoT",
        "PCR-Chain w/oEME"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Natural Language Deduction through Search over Statement Compositions": {
    "filename": "Natural Language Deduction through Search over Statement Compositions.pdf",
    "analysis": {
      "benchmarks": [
        "EntailmentBank",
        "WANLI",
        "EBEntail"
      ],
      "models": [
        "proposed system",
        "end-to-end T5 model",
        "step model S",
        "EntailmentWriter",
        "DeBERTa model",
        "SCSearch",
        "Learned heuristic model",
        "Overlap heuristic",
        "Repetition heuristic",
        "Breadth-first heuristic"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Very Large-Scale Multi-Agent Simulation in AgentScope": {
    "filename": "Very Large-Scale Multi-Agent Simulation in AgentScope.pdf",
    "analysis": {
      "benchmarks": [
        "guess 2/3 of the average game"
      ],
      "models": [
        "AgentScope",
        "Llama3-8B",
        "Llama3-70B",
        "Qwen2-7B",
        "Qwen2-72B",
        "MistralAI-8x7B",
        "MistralAI-8x22B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions": {
    "filename": "Towards Generating Functionally Correct Code Edits from Natural Language Issue Descriptions.pdf",
    "analysis": {
      "benchmarks": [
        "Defects4J-Nl2fix",
        "Defects4J"
      ],
      "models": [
        "code-davinci-002",
        "code-davinci-edit-001",
        "gpt-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dialectical Alignment Resolving the Tension of 3H and Security Threats of LLMs": {
    "filename": "Dialectical Alignment Resolving the Tension of 3H and Security Threats of LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Needle In A Haystack",
        "HotpotQA",
        "MS-MARCO",
        "Natural Questions"
      ],
      "models": [
        "Dialectical Alignment (DA)",
        "RLHF",
        "RLAIF",
        "Direct Preference Optimization (DPO)",
        "TinyDolphin-2.8-1.1B",
        "Mistral-7B-Instruct-v0.2",
        "GLM-4",
        "gpt-3.5-turbo-16k"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Need Holistically Thought in Medical Conversational QA": {
    "filename": "Large Language Models Need Holistically Thought in Medical Conversational QA.pdf",
    "analysis": {
      "benchmarks": [
        "MedDialog",
        "COVID",
        "CMDD"
      ],
      "models": [
        "Holistically Thought (HoT)",
        "GPT-3",
        "Instruct-GPT",
        "GLM",
        "Chain of Thought (CoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DialogGen Multi-modal Interactive Dialogue System for Multi-turn Text-to-Image Generation": {
    "filename": "DialogGen Multi-modal Interactive Dialogue System for Multi-turn Text-to-Image Generation.pdf",
    "analysis": {
      "benchmarks": [
        "DialogBen"
      ],
      "models": [
        "DialogGen",
        "Qwen-VL",
        "NExT-GPT",
        "SEED-LLaMA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Log Parsing How Far Can ChatGPT Go": {
    "filename": "Log Parsing How Far Can ChatGPT Go.pdf",
    "analysis": {
      "benchmarks": [
        "HDFS",
        "Hadoop",
        "Spark",
        "Zookeeper",
        "BGL",
        "HPC",
        "Thunderbird",
        "Windows",
        "Linux",
        "Android",
        "HealthApp",
        "Apache",
        "Proxifier",
        "OpenSSH",
        "OpenStack",
        "Mac"
      ],
      "models": [
        "ChatGPT",
        "AEL",
        "Spell",
        "Drain",
        "Logram",
        "SPINE",
        "UniParser",
        "LogPPT"
      ]
    }
  },
  "Implicit Chain of Thought Reasoning via Knowledge Distillation": {
    "filename": "Implicit Chain of Thought Reasoning via Knowledge Distillation.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-bench",
        "GSM8K"
      ],
      "models": [
        "GPT-2 Small",
        "GPT-2 Medium",
        "GPT-2 Large",
        "ChatGPT",
        "GPT-4",
        "Implicit CoT",
        "Explicit CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoAD-Zero A Training-Free Framework for Zero-Shot Audio Description": {
    "filename": "AutoAD-Zero A Training-Free Framework for Zero-Shot Audio Description.pdf",
    "analysis": {
      "benchmarks": [
        "MAD-Eval",
        "CMD-AD",
        "TV-AD",
        "MovieNet"
      ],
      "models": [
        "AutoAD-Zero",
        "AutoAD-I",
        "AutoAD-II",
        "AutoAD-III",
        "Uni-AD",
        "MM-Narrator (GPT-4)",
        "MM-Narrator (GPT-4v)",
        "LLM-AD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Skill Set Optimization Reinforcing Language Model Behavior via Transferable Skills": {
    "filename": "Skill Set Optimization Reinforcing Language Model Behavior via Transferable Skills.pdf",
    "analysis": {
      "benchmarks": [
        "ScienceWorld",
        "NetHack"
      ],
      "models": [
        "Skill Set Optimization (SSO)",
        "CLIN",
        "ReAct",
        "Reflexion"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Speech-Copilot Leveraging Large Language Models for Speech Processing via Task Decomposition Modularization and Program Generation": {
    "filename": "Speech-Copilot Leveraging Large Language Models for Speech Processing via Task Decomposition Modularization and Program Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Dynamic-SUPERB"
      ],
      "models": [
        "Speech-Copilot",
        "Qwen-Audio-Chat",
        "SALMONN",
        "LTU-AS",
        "WavLLM",
        "ASR+LLM",
        "ASR+AAC+LLM",
        "All Attributes + LLM",
        "Whisper-large-v3",
        "emotion2vec",
        "Brouhaha",
        "CommonAccent",
        "autochord",
        "NVIDIA TitaNet-Large",
        "pyannote speaker-diarization-3.1",
        "GPT-3.5",
        "GPT-4o"
      ]
    }
  },
  "Recursive Introspection Teaching Language Model Agents How to Self-Improve": {
    "filename": "Recursive Introspection Teaching Language Model Agents How to Self-Improve.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "SVAMP"
      ],
      "models": [
        "RISE",
        "Llama2",
        "Llama3",
        "Mistral",
        "GPT-3.5",
        "Eurus-7B-SFT",
        "Self-Refine",
        "GloRE",
        "V-STaR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cost-effective Instruction Learning for Pathology Vision and Language Analysis": {
    "filename": "Cost-effective Instruction Learning for Pathology Vision and Language Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "PathVQA",
        "QUILT-VQA",
        "Clinical dataset"
      ],
      "models": [
        "CLOVER",
        "LLaVA",
        "LLaVA-Med",
        "BLIP-2",
        "VL Encoder-Decoder",
        "Q2ATransformer",
        "M2I2",
        "FlanT5XL",
        "Vicuna 7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning": {
    "filename": "Natural Language Embedded Programs for Hybrid Language Symbolic Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Tracking Shuffled Objects",
        "Dyck Language",
        "Word Sorting",
        "Chinese Remainder Theorem",
        "Scheduling Meeting",
        "GSM-Hard",
        "Game of 24",
        "StrategyQA",
        "TruthfulQA",
        "VicunaQA",
        "SST2",
        "Cola",
        "Emotion-Classification",
        "Amazon Review",
        "Hate-Speech",
        "Social Bias Frame"
      ],
      "models": [
        "NLEP",
        "CoT",
        "PoT",
        "LATM",
        "GPT-4",
        "GPT-3.5-Turbo",
        "CodeLlama7b",
        "CodeLlama13b",
        "Claude2",
        "RoBERTa",
        "DeBERTa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DePlot One-shot visual language reasoning by plot-to-table translation": {
    "filename": "DePlot One-shot visual language reasoning by plot-to-table translation.pdf",
    "analysis": {
      "benchmarks": [
        "ChartQA",
        "PlotQA"
      ],
      "models": [
        "DEPLOT",
        "MATCHA",
        "VisionTapas",
        "Pix2Struct",
        "FlanPaLM",
        "Codex",
        "GPT-3",
        "PaLM",
        "ChartOCR",
        "PaLI-17B",
        "T5",
        "VL-T5",
        "CRCT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large language models leverage external knowledge to extend clinical insight beyond language boundaries": {
    "filename": "Large language models leverage external knowledge to extend clinical insight beyond language boundaries.pdf",
    "analysis": {
      "benchmarks": [
        "CNMLE-2022"
      ],
      "models": [
        "ChatGPT (GPT3.5)",
        "GPT4",
        "Baichuan2-7B",
        "Baichuan2-13B",
        "SeaReader",
        "Med3R",
        "KFE (Knowledge and Few-shot Enhancement In-context Learning)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Guiding Large Language Models via Directional Stimulus Prompting": {
    "filename": "Guiding Large Language Models via Directional Stimulus Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "CNN/Daily Mail",
        "MultiWOZ",
        "MultiArith",
        "AQuA"
      ],
      "models": [
        "Directional Stimulus Prompting (DSP)",
        "ChatGPT",
        "Codex",
        "InstructGPT",
        "T5",
        "Flan-T5-Large",
        "T5-Base",
        "DAMD",
        "MinTL",
        "Soloist",
        "SimpleTOD",
        "DoTS",
        "PP-TOD",
        "UBAR",
        "GALAXY"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Optimizing with Large Language Models": {
    "filename": "Towards Optimizing with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "synthetic datasets"
      ],
      "models": [
        "GPT-turbo-3.5",
        "GPT-4"
      ]
    }
  },
  "A Theory for Length Generalization in Learning to Reason": {
    "filename": "A Theory for Length Generalization in Learning to Reason.pdf",
    "analysis": {
      "benchmarks": [
        "arithmetic in F7",
        "parity-[2-line]",
        "addition-[1-line]",
        "addition-[2-line]",
        "addition-[3-line]",
        "multiplication-[1-line]",
        "multiplication-[8-line]"
      ],
      "models": [
        "vanilla Transformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Energy-Efficient Code Emerging Results and Future Directions": {
    "filename": "Large Language Models for Energy-Efficient Code Emerging Results and Future Directions.pdf",
    "analysis": {
      "benchmarks": [
        "Energy-Language",
        "C++ benchmark",
        "DCPerf",
        "Green500"
      ],
      "models": [
        "GPT-4o",
        "Generator LLM",
        "Evaluator LLM",
        "GPT-o1"
      ]
    }
  },
  "Lets Verify Step by Step": {
    "filename": "Lets Verify Step by Step.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "AP Calculus",
        "AP Chemistry",
        "AP Physics",
        "AMC10/12"
      ],
      "models": [
        "GPT-4",
        "Outcome-supervised Reward Model (ORM)",
        "Process-supervised Reward Model (PRM)",
        "PRM800K",
        "PRMlarge",
        "PRMselector"
      ]
    }
  },
  "ChatLLM Network More brains More intelligence": {
    "filename": "ChatLLM Network More brains More intelligence.pdf",
    "analysis": {
      "benchmarks": [
        "digital mode classification",
        "sentiment reversal"
      ],
      "models": [
        "ChatLLM network",
        "ChatGPT",
        "ChatGPT-w/o FB",
        "ChatGPT-refine",
        "ChatGPT-ensemble",
        "ChatGPT-mem",
        "ChatGPT Network (leader)"
      ]
    }
  },
  "Making Large Vision Language Models to be Good Few-shot Learners": {
    "filename": "Making Large Vision Language Models to be Good Few-shot Learners.pdf",
    "analysis": {
      "benchmarks": [
        "MiniImageNet",
        "CIFAR-FS",
        "TieredImageNet",
        "CUB",
        "Stanford Dogs",
        "FGVC-Aircraft",
        "Oxford 102 Flower",
        "Stanford Cars"
      ],
      "models": [
        "GPT-4V",
        "Qwen-VL",
        "Qwen-VL-Chat",
        "Qwen-VL-Chat-Int4",
        "EASY 3 \u00d7ResNet12",
        "PEMnE-BMS",
        "PTMAP-SF-SOT",
        "P>M>F",
        "CAML",
        "FRN",
        "TDM",
        "MCL-Katz",
        "DeepBDC",
        "LCCRN",
        "SRM"
      ]
    }
  },
  "Language Model Cascades": {
    "filename": "Language Model Cascades.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-bench"
      ],
      "models": [
        "Language Model Cascades",
        "GPT-3",
        "PaLM",
        "LaMDA",
        "Scratchpads",
        "Chain of Thought",
        "Self Consistency",
        "PromptChainer",
        "Socratic models",
        "Self-Taught Reasoner (STaR)",
        "Selection-Inference",
        "Verifiers",
        "Self-critiquing models"
      ]
    }
  },
  "T-cell receptor binding prediction A machine learning revolution": {
    "filename": "T-cell receptor binding prediction A machine learning revolution.pdf",
    "analysis": {
      "benchmarks": [
        "VDJdb",
        "McPas-TCR",
        "MIRA dataset",
        "IMMREP22 benchmark",
        "IMMREP23 benchmark"
      ],
      "models": [
        "TCRdist",
        "GLIPH",
        "DeNeuter",
        "NetTCR",
        "Xu et al",
        "TCRex",
        "SETE",
        "TcellMatch",
        "ImRex",
        "iSMART",
        "ERGO",
        "TCRdist3",
        "TCRGP",
        "ERGO-II",
        "TCRMatch",
        "pMTnet",
        "TITAN",
        "NetTCR-2.0",
        "TCRAI",
        "DeepTCR",
        "TCR-BERT",
        "GIANA",
        "ELATE",
        "DLpTCR",
        "SwarmTCR",
        "ClusTCR",
        "SONIA",
        "ATM-TCR",
        "TCRconv",
        "PiTE",
        "Bi et al",
        "diffRBM",
        "PanPep",
        "catELMo",
        "STAPLER",
        "NetTCR-2.2",
        "TCR-H",
        "epiTCR",
        "GGNpTCR",
        "Rehman Khan",
        "TAPIR",
        "BERTrand",
        "MITNet",
        "SC-AIR-BERT",
        "MixTCRpred",
        "TSPred",
        "Koyama et al",
        "TCRen",
        "TEINet",
        "MIX-TPI",
        "A VIB",
        "EPIC-TRACE",
        "Deutschmann et al"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Library Learning Doesnt The Curious Case of the Single-Use Library": {
    "filename": "Library Learning Doesnt The Curious Case of the Single-Use Library.pdf",
    "analysis": {
      "benchmarks": [
        "miniF2F",
        "MATH"
      ],
      "models": [
        "LEGO-Prover",
        "TroVE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-Eval Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models": {
    "filename": "LLM-Eval Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "DSTC10 Hidden Set",
        "TopicalChat-USR",
        "PersonaChat-USR",
        "ConvAI2-GRADE",
        "DailyDialog-GRADE",
        "EmpatheticDialogue-GRADE",
        "DSTC6",
        "DailyDialog-PredictiveEngagement",
        "FED",
        "DSTC9"
      ],
      "models": [
        "LLM-E VAL",
        "Deep-AM-FM",
        "DSTC10 Team 1",
        "MME-CRS",
        "BERTScore",
        "DEB",
        "GRADE",
        "USR",
        "USL-H",
        "DynaEval",
        "FlowScore",
        "GPTScore"
      ]
    }
  },
  "PyGen A Collaborative Human-AI Approach to Python Package Creation": {
    "filename": "PyGen A Collaborative Human-AI Approach to Python Package Creation.pdf",
    "analysis": {
      "benchmarks": [
        "Human Evaluation",
        "LLM-based evaluation",
        "CodeBLEU"
      ],
      "models": [
        "Pygen",
        "Google DeepMind's Gemini",
        "Llama",
        "Meta's Llama",
        "Mistral model",
        "Ollama",
        "AutoML",
        "AutoVision",
        "AutoSpeech",
        "Quantum Error Correction",
        "Gemini 1.5 Pro 002",
        "Gemini 1.5 flash 002",
        "llama3-70b-8192",
        "llama3-8b-8192",
        "gemma2-9b-it",
        "Llama-3.1-70b-versatile"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph": {
    "filename": "Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph.pdf",
    "analysis": {
      "benchmarks": [
        "Open Research Knowledge Graph (ORKG)"
      ],
      "models": [
        "GPT-3.5",
        "Llama 2",
        "Mistral",
        "GPT-3.5-turbo",
        "SciNCL"
      ]
    }
  },
  "Towards Proactive Interactions for In-Vehicle Conversational Assistants Utilizing Large Language Models": {
    "filename": "Towards Proactive Interactions for In-Vehicle Conversational Assistants Utilizing Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "In-Car dataset"
      ],
      "models": [
        "gpt-3.5-turbo",
        "TSCP",
        "LABES",
        "Galaxy"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models PhenoBCBERT and PhenoGPT": {
    "filename": "Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models PhenoBCBERT and PhenoGPT.pdf",
    "analysis": {
      "benchmarks": [
        "BiolarkGSC+",
        "ID-68",
        "American Journal of Human Genetics (AJHG)"
      ],
      "models": [
        "PhenoBCBERT",
        "PhenoGPT",
        "PhenoTagger",
        "Bio+Clinical BERT",
        "GPT-J",
        "Falcon",
        "LLaMA",
        "GPT-3",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain-Of-Thought Prompting Under Streaming Batch A Case Study": {
    "filename": "Chain-Of-Thought Prompting Under Streaming Batch A Case Study.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MultiArith",
        "StrategyQA",
        "Letter"
      ],
      "models": [
        "text-davinci-002",
        "Zero-Shot-CoT",
        "Bootstraping Auto-CoT",
        "Correct-CoT",
        "Wrong-CoT",
        "Deep-CoT",
        "Shallow-CoT"
      ]
    }
  },
  "Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM": {
    "filename": "Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM.pdf",
    "analysis": {
      "benchmarks": [
        "Libri-Light",
        "LibriSpeech",
        "WebQuestions",
        "LLaMA-Questions"
      ],
      "models": [
        "Spectron",
        "GSLM",
        "AudioLM (3-RVQ)",
        "AudioLM (12-RVQ)",
        "TWIST (1.3B)",
        "TWIST (7B)",
        "SpeechGPT",
        "Spectron (350M)",
        "Spectron (1B)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting": {
    "filename": "Can Instruction Fine-Tuned Language Models Identify Social Bias through Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "BBQ"
      ],
      "models": [
        "LLaMA",
        "Alpaca 7B",
        "Alpaca 13B",
        "Koala 7B",
        "Koala 13B"
      ]
    }
  },
  "BBox-Adapter Lightweight Adapting for Black-Box Large Language Models": {
    "filename": "BBox-Adapter Lightweight Adapting for Black-Box Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "StrategyQA",
        "TruthfulQA",
        "ScienceQA"
      ],
      "models": [
        "BBOX-ADAPTER",
        "gpt-3.5-turbo",
        "Mixtral-8x7B",
        "Azure-SFT",
        "LoRA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Pyramid Coder Hierarchical Code Generator for Compositional Visual Question Answering": {
    "filename": "Pyramid Coder Hierarchical Code Generator for Compositional Visual Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "GQA",
        "VQAv2",
        "NLVR2"
      ],
      "models": [
        "PyramidCoder",
        "CodeVQA",
        "GLIP",
        "PNP-VQA",
        "StarCoder-Base",
        "CodeLlama-7b-Python",
        "gpt-3.5-turbo"
      ]
    }
  },
  "Unveiling the Safety of GPT-4o An Empirical Study using Jailbreak Attacks": {
    "filename": "Unveiling the Safety of GPT-4o An Empirical Study using Jailbreak Attacks.pdf",
    "analysis": {
      "benchmarks": [
        "AdvBench",
        "RedTeam-2K",
        "BeaverTails",
        "SafeBench",
        "MM-SafetyBench"
      ],
      "models": [
        "GPT-4o",
        "GPT-4V",
        "Llama2",
        "Llama Guard"
      ]
    }
  },
  "Towards Unified Alignment Between Agents Humans and Environment": {
    "filename": "Towards Unified Alignment Between Agents Humans and Environment.pdf",
    "analysis": {
      "benchmarks": [
        "WebShop",
        "Androidenv",
        "Mind2Web",
        "ToolBench",
        "WebArena",
        "VirtualHome",
        "BabyAI",
        "ALFWorld",
        "MineDojo",
        "ScienceWorld",
        "Interactive Gibson",
        "AGENT",
        "RFUniverse",
        "BEHAVIOR-1K",
        "HAZARD",
        "MINT",
        "SmartPlay",
        "AgentBench",
        "AgentBoard"
      ],
      "models": [
        "ReAct",
        "ReAct-SC",
        "Reflexion",
        "LATS",
        "SwiftSage",
        "RetroFormer",
        "DyLAN",
        "CAMEL",
        "ExpeL",
        "HLA",
        "MemPrompt",
        "MemGPT",
        "MetaGPT",
        "CLIN",
        "LATS",
        "RAP",
        "TRAN",
        "AgentVerse",
        "FireAct",
        "CodeAct",
        "AutoAct",
        "ToT",
        "BOLAA",
        "Chameleon",
        "HuggingGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-Polish Enhance Reasoning in Large Language Models via Problem Refinement": {
    "filename": "Self-Polish Enhance Reasoning in Large Language Models via Problem Refinement.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "AQuA",
        "SVAMP",
        "MultiArith",
        "MathQA",
        "GSM-IC"
      ],
      "models": [
        "Self-Polish",
        "Chain-of-Thought",
        "Least-to-Most",
        "Text-davinci-002",
        "Text-davinci-003",
        "GPT-3.5-Turbo",
        "Auto-CoT",
        "Complex-CoT",
        "Self-Consistency"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain-of-Interaction Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts": {
    "filename": "Chain-of-Interaction Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts.pdf",
    "analysis": {
      "benchmarks": [
        "Motivational Interviewing Skills Code (MISC)"
      ],
      "models": [
        "Chain-of-Interaction (CoI)",
        "Llama2-13B-Chat",
        "Falcon-7B-Instruct",
        "Mistral-7B-Instruct",
        "ChatGPT",
        "Zero-Shot prompting",
        "Few-Shot prompting",
        "Zero-Shot Chain of Thought (ZeroCoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Well Can Transformers Emulate In-context Newtons Method": {
    "filename": "How Well Can Transformers Emulate In-context Newtons Method.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Transformer",
        "linear attention Transformer",
        "Newton's iteration",
        "Newton's method",
        "gradient descent",
        "damped Newton's method",
        "LSA (linear self-attention)",
        "LSA with LayerNorm"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ROMAS A Role-Based Multi-Agent System for Database monitoring and Planning": {
    "filename": "ROMAS A Role-Based Multi-Agent System for Database monitoring and Planning.pdf",
    "analysis": {
      "benchmarks": [
        "FAMMA",
        "HotpotQA"
      ],
      "models": [
        "ROMAS",
        "Generative Agent",
        "AutoAgents",
        "CoT (GPT-4)",
        "ToT (GPT-4)",
        "ReAct (GPT-4)",
        "LLAMA2-70B",
        "QWEN2-72B",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DeepTagger Knowledge Enhanced Named Entity Recognition for Web-Based Ads Queries": {
    "filename": "DeepTagger Knowledge Enhanced Named Entity Recognition for Web-Based Ads Queries.pdf",
    "analysis": {
      "benchmarks": [
        "CoNLL2003",
        "self-collected dataset"
      ],
      "models": [
        "DeepTagger",
        "BERT",
        "Self-Training",
        "DRIFT",
        "VAT",
        "COSINE",
        "NEEDLE"
      ]
    }
  },
  "RecMind Large Language Model Powered Agent For Recommendation": {
    "filename": "RecMind Large Language Model Powered Agent For Recommendation.pdf",
    "analysis": {
      "benchmarks": [
        "Amazon Reviews",
        "Yelp"
      ],
      "models": [
        "RecMind",
        "RecMind-SI",
        "RecMind-ToT",
        "RecMind-CoT",
        "P5",
        "ChatGPT",
        "MF",
        "MLP",
        "AFM",
        "BPR-MLP",
        "ENMF",
        "S3-Rec",
        "SASRec"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Integration of large language models and federated learning": {
    "filename": "Integration of large language models and federated learning.pdf",
    "analysis": {
      "benchmarks": [
        "FATE-LLM",
        "Shepherd",
        "FederatedScope-LLMs",
        "OpenFedLLMs"
      ],
      "models": [
        "FedLLMs",
        "FedYolo",
        "pFedPG",
        "pFedPT",
        "DiPrompT",
        "Fed-DPT",
        "FedLogic"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Empirical Study on the Robustness of the Segment Anything Model SAM": {
    "filename": "An Empirical Study on the Robustness of the Segment Anything Model SAM.pdf",
    "analysis": {
      "benchmarks": [
        "Forest Aerial",
        "Water Bodies",
        "Road Extraction",
        "Breast Ultrasound",
        "Chest X-Ray",
        "Fish",
        "Fire",
        "Crack",
        "TikTok Dancing"
      ],
      "models": [
        "Segment Anything Model (SAM)",
        "U-Net",
        "Mask R-CNN",
        "DeepLab",
        "Pyramid Scene Parsing Network"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LogParser-LLM Advancing Efficient Log Parsing with Large Language Models": {
    "filename": "LogParser-LLM Advancing Efficient Log Parsing with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Loghub-2k",
        "LogPub"
      ],
      "models": [
        "LogParser-LLM",
        "Drain",
        "Uniparser",
        "LogPPT",
        "Brain",
        "LogParser-LLM-C"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Extracting user needs with Chat-GPT for dialogue recommendation": {
    "filename": "Extracting user needs with Chat-GPT for dialogue recommendation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Chat-GPT",
        "GPT-4"
      ]
    }
  },
  "A call for embodied AI": {
    "filename": "A call for embodied AI.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "rLLM Relational Table Learning with LLMs": {
    "filename": "rLLM Relational Table Learning with LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "TML1M",
        "TLF2K",
        "TACM12K"
      ],
      "models": [
        "BRIDGE",
        "TabTransformer",
        "TabNet",
        "FT-Transformer",
        "GCN",
        "GAT",
        "RECT",
        "TAPE",
        "OGC",
        "HAN",
        "HGT"
      ]
    }
  },
  "Making Large Language Models Better Reasoners with Alignment": {
    "filename": "Making Large Language Models Better Reasoners with Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "AQUA-RAT",
        "ECQA",
        "GSM8K-RANK"
      ],
      "models": [
        "LLama-7B",
        "LLama2-7B",
        "LLama-13B",
        "LLama2-13B",
        "AFT (LDC_A)",
        "AFT (LBC_A)",
        "VFT",
        "RFT",
        "RRHF",
        "PRO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-critiquing models for assisting human evaluators": {
    "filename": "Self-critiquing models for assisting human evaluators.pdf",
    "analysis": {
      "benchmarks": [
        "RACE"
      ],
      "models": [
        "InstructGPT",
        "GPT-3",
        "foundation models",
        "transformer decoders",
        "self-critiquing models",
        "baseline models",
        "proposed critique model",
        "InstructGPT baselines",
        "InstructGPT few-shot",
        "InstructGPT zero-shot"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Neuro-Symbolic Execution of Generic Source Code": {
    "filename": "Neuro-Symbolic Execution of Generic Source Code.pdf",
    "analysis": {
      "benchmarks": [
        "ETH Py150 Open",
        "CuBERT"
      ],
      "models": [
        "Neural Interpretation (NI)",
        "CodeBERT",
        "CodeGPT",
        "LSTM",
        "CuBERT baseline"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NapSS Paragraph-level Medical Text Simplification via Narrative Prompting and Sentence-matching Summarization": {
    "filename": "NapSS Paragraph-level Medical Text Simplification via Narrative Prompting and Sentence-matching Summarization.pdf",
    "analysis": {
      "benchmarks": [
        "Cochrane dataset",
        "TICO-19"
      ],
      "models": [
        "NapSS",
        "Vanilla BART",
        "UL-BART",
        "NapSS BioBART",
        "NapSS (+UL)",
        "NapSS (-Prompt)",
        "NapSS (-Summary)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InsightSee Advancing Multi-agent Vision-Language Models for Enhanced Visual Understanding": {
    "filename": "InsightSee Advancing Multi-agent Vision-Language Models for Enhanced Visual Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "SEED-Bench"
      ],
      "models": [
        "InsightSee",
        "InstructBLIP-Vicuna",
        "InstructBLIP",
        "Qwen-VL",
        "LLaVA-1.5",
        "ShareGPT4V-13B",
        "InternVL-Chat-V1.2-Plus",
        "GPT-4V"
      ]
    }
  },
  "X-InstructBLIP A Framework for aligning X-Modal instruction-aware representations to LLMs and Emergent Cross-modal Reasoning": {
    "filename": "X-InstructBLIP A Framework for aligning X-Modal instruction-aware representations to LLMs and Emergent Cross-modal Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "DisCRn",
        "ModelNet40",
        "ESC50",
        "ClothoAQA",
        "Clotho",
        "Flickr30k",
        "NoCaps",
        "VizWiz",
        "GQA",
        "MME",
        "MMVET",
        "MSVD",
        "VATEX",
        "MSVDQA",
        "MusicAVQA",
        "AudioCaps",
        "Cap3D"
      ],
      "models": [
        "X-InstructBLIP",
        "Q-Former",
        "Linear Projections",
        "InstructBLIP",
        "PointLLM",
        "PointBindLLM",
        "ImageBindLLM",
        "MiniGPT4",
        "LLaVA",
        "LLaMA-adapter",
        "PandaGPT",
        "VideoLLaMA",
        "FrozenBiLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatCAD Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models": {
    "filename": "ChatCAD Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-CXR",
        "CheXpert"
      ],
      "models": [
        "ChatCAD",
        "DiseaseClassifier",
        "LesionSegmentor",
        "ReportGenerator",
        "R2GenCMN",
        "CvT2DistilGPT2",
        "PCAM",
        "text-davinci-003",
        "ChatGPT",
        "text-babbage-001",
        "text-curie-001"
      ]
    }
  },
  "No Train Still Gain Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function": {
    "filename": "No Train Still Gain Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "AQUA-RAT"
      ],
      "models": [
        "Residual-EBM",
        "RFT",
        "WizardMath",
        "Llama2",
        "Qwen",
        "AFT",
        "SFT"
      ]
    }
  },
  "CABINET Content Relevance based Noise Reduction for Table Question Answering": {
    "filename": "CABINET Content Relevance based Noise Reduction for Table Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "WikiTQ",
        "FeTaQA",
        "WikiSQL"
      ],
      "models": [
        "CABINET",
        "GPT-3",
        "DATER",
        "OmniTab",
        "TAPEX",
        "ReasTAP",
        "T5-3b",
        "Flan T5-xl",
        "StructGPT",
        "LEVER",
        "BINDER",
        "TAPAS",
        "TaBERT",
        "MATE",
        "GraPPa",
        "DoT",
        "TableFormer",
        "TaCube",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Autonomous Evaluation and Refinement of Digital Agents": {
    "filename": "Autonomous Evaluation and Refinement of Digital Agents.pdf",
    "analysis": {
      "benchmarks": [
        "WebArena",
        "Android-in-the-Wild",
        "iOS device control"
      ],
      "models": [
        "GPT-4V",
        "QWen-VL-chat",
        "Captioner + Mixtral",
        "Captioner + GPT-4",
        "GPT-4-based WebArena agent",
        "CogAgent",
        "Auto-UI large",
        "Auto-UI base"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AskIt Unified Programming Interface for Programming with Large Language Models": {
    "filename": "AskIt Unified Programming Interface for Programming with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "OpenAI Evals",
        "HumanEval"
      ],
      "models": [
        "AskIt",
        "GPT-4",
        "GPT-3.5-turbo-16k"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Patterns of Creativity How User Input Shapes AI-Generated Visual Diversity": {
    "filename": "Patterns of Creativity How User Input Shapes AI-Generated Visual Diversity.pdf",
    "analysis": {
      "benchmarks": [
        "DiffusionDB",
        "Civiverse"
      ],
      "models": [
        "Linear Regression"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LangNav Language as a Perceptual Representation for Navigation": {
    "filename": "LangNav Language as a Perceptual Representation for Navigation.pdf",
    "analysis": {
      "benchmarks": [
        "R2R",
        "ALFRED"
      ],
      "models": [
        "LangNav",
        "GPT-4",
        "LLaMA",
        "LLaMA2",
        "RecBert",
        "DuET",
        "NavGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-Knowledge Guided Retrieval Augmentation for Large Language Models": {
    "filename": "Self-Knowledge Guided Retrieval Augmentation for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "TemporalQA",
        "CommonsenseQA",
        "TabularQA",
        "StrategyQA",
        "TruthfulQA"
      ],
      "models": [
        "InstructGPT",
        "ChatGPT",
        "Zero-Shot",
        "Zero-Shot-CoT",
        "Few-Shot",
        "Manual-CoT",
        "Auto-CoT (Similarity)",
        "Auto-CoT (Diversity)",
        "Manual-CoT-IR",
        "IRCoT",
        "SKR prompt",
        "SKR icl",
        "SKR cls",
        "SKR knn",
        "CoT-RR"
      ]
    }
  },
  "Empowering Language Models with Active Inquiry for Deeper Understanding": {
    "filename": "Empowering Language Models with Active Inquiry for Deeper Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "StrategyQA",
        "2WikiMultiHopQA",
        "MuSiQue",
        "IIRC",
        "QMSum"
      ],
      "models": [
        "LaMAI",
        "Direct Generation (DG)",
        "Chain of Thought (CoT)",
        "Self-ask",
        "RAG (Web)",
        "Oracle",
        "LaMAI+CoT",
        "Vicuna-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond ChatBots ExploreLLM for Structured Thoughts and Personalized Model Responses": {
    "filename": "Beyond ChatBots ExploreLLM for Structured Thoughts and Personalized Model Responses.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ExploreLLM",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LgTS Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents": {
    "filename": "LgTS Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Gridworld based DoorKey domain",
        "Search-and-rescue inspired domain"
      ],
      "models": [
        "LgTS",
        "Teacher-Student learning algorithm",
        "Learning from scratch (LFS)",
        "Teacher-student curriculum learning (TSCL)",
        "Automaton-guided Teacher-Student learning (AgTS)",
        "Automaton-guided Reward Shaping (AGRS)",
        "LLM-guided Reward Shaping (LgRS)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Matching to Generation A Survey on Generative Information Retrieval": {
    "filename": "From Matching to Generation A Survey on Generative Information Retrieval.pdf",
    "analysis": {
      "benchmarks": [
        "MS MARCO",
        "NQ",
        "TriviaQA",
        "KILT",
        "TREC DL 19",
        "TREC DL 20",
        "DynamicIR",
        "MMLU",
        "BIG-bench",
        "LLM-Eval",
        "API-Bank",
        "ToolBench",
        "TruthfulQA",
        "ALCE",
        "HaluEval",
        "RealTime QA",
        "FreshQA",
        "SafetyBench",
        "TrustGPT",
        "TrustLLM"
      ],
      "models": [
        "DSI",
        "DynamicRetriever",
        "NCI",
        "DSI-QG",
        "Chen et al.",
        "LTRGR",
        "GenRRL",
        "DGR",
        "ListGR",
        "TOME",
        "NP Decoding",
        "MEVI",
        "DiffusionRet",
        "GDR",
        "Self-Retrieval",
        "PAG",
        "GENRE",
        "SEAL",
        "Ultron",
        "GenRet",
        "Tied-Atomic",
        "LMIndexer",
        "ASI",
        "RIPOR",
        "GLEN",
        "AutoTSG",
        "SE-DSI",
        "LLM-URL",
        "MINDER",
        "NOVO",
        "DSI++",
        "IncDSI",
        "CLEVER",
        "CorpusBrain++",
        "GERE",
        "CorpusBrain",
        "GMR",
        "DearDR",
        "CodeDSI",
        "GCoQA",
        "UniGen",
        "CorpusLM",
        "IRGen",
        "GeMKR",
        "GRACE",
        "P5",
        "TIGER",
        "SEATER",
        "IDGenRec",
        "LC-Rec",
        "ColaRec"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multi-agent Planning using Visual Language Models": {
    "filename": "Multi-agent Planning using Visual Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ALFRED"
      ],
      "models": [
        "G-PlanET",
        "PG2S",
        "multi-agent architecture",
        "single-agent architecture",
        "GPT-4V",
        "GPT-4"
      ]
    }
  },
  "GenAINet Enabling Wireless Collective Intelligence via Knowledge Transfer and Reasoning": {
    "filename": "GenAINet Enabling Wireless Collective Intelligence via Knowledge Transfer and Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "TeleQnA"
      ],
      "models": [
        "GenAINet",
        "T5-770M",
        "PaLM-540B",
        "vLLM",
        "QLoRA",
        "BabyAGI",
        "Auto-GPT",
        "CAMEL",
        "GPT-3.5-turbo",
        "Llama-7B"
      ]
    }
  },
  "Tool Learning with Large Language Models A Survey": {
    "filename": "Tool Learning with Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "API-Bank",
        "APIBench",
        "ToolBench1",
        "ToolAlpaca",
        "RestBench",
        "ToolBench2",
        "MetaTool",
        "TaskBench",
        "T-Eval",
        "ToolEyes"
      ],
      "models": [
        "ReACT",
        "Toolformer",
        "TALM",
        "HuggingGPT",
        "ToolkenGPT",
        "LATMGPT4Tools",
        "ToolQA",
        "MetaTool",
        "CRITIC",
        "CLOVA",
        "ToolLLaMA",
        "ViperGPT",
        "AnyTool",
        "MINT",
        "ToolChain*",
        "API-Bank",
        "Gorilla",
        "ToolSword",
        "T-Eval",
        "TroVE",
        "ToolRerank",
        "WebGPT",
        "WebShop",
        "TRICE",
        "ToRA",
        "CREATOR",
        "Confucius",
        "Themis",
        "CRAFT",
        "PLUTO",
        "AppWorld",
        "STE",
        "ToolRec",
        "COLT",
        "FinAgent",
        "ATC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On the Diagram of Thought": {
    "filename": "On the Diagram of Thought.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Diagram of Thought (DoT)",
        "Chain-of-Thought (CoT)",
        "Tree-of-Thought (ToT)",
        "Graph-of-Thought (GoT)",
        "Cumulative Reasoning (CR)"
      ]
    }
  },
  "EvalYaks Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts": {
    "filename": "EvalYaks Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts.pdf",
    "analysis": {
      "benchmarks": [
        "CEFR B2 English speaking assessment",
        "English Vocabulary Profile",
        "CEFR-SP WikiAuto"
      ],
      "models": [
        "EvalYaks",
        "Mistral Instruct 7B v0.2",
        "Gemini Pro 1.0",
        "Vicuna 33B",
        "Claude Haiku (Mar '24)",
        "Llama2 70B Chat",
        "Llama2 7B Chat",
        "Mixtral Instruct v0.1",
        "Mistral Medium",
        "Qwen 72B Chat",
        "GPT 3.5 (Jan '24)",
        "Gemma 7B",
        "Mistral Instruct v0.2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V": {
    "filename": "Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V.pdf",
    "analysis": {
      "benchmarks": [
        "RefCOCOg",
        "COCO",
        "ADE20K",
        "Flickr30K",
        "DAVIS2017"
      ],
      "models": [
        "GPT-4V",
        "Set-of-Mark Prompting",
        "MaskDINO",
        "OpenSeeD",
        "GLIPv2",
        "Grounding DINO",
        "PolyFormer",
        "SegGPT",
        "SEEM",
        "RedCircle",
        "FGVP",
        "Shikra",
        "LLaVa-1.5",
        "MiniGPT-v2",
        "Ferret"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Measurement in the Age of LLMs An Application to Ideological Scaling": {
    "filename": "Measurement in the Age of LLMs An Application to Ideological Scaling.pdf",
    "analysis": {
      "benchmarks": [
        "DW-NOMINATE",
        "CFScores",
        "Text-based ideal points (TBIP)",
        "Tweets of U.S. legislators from 2009\u20132017"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4",
        "GPT-4-turbo",
        "Wu et al.'s LLM-based approach for ideological scaling",
        "Bradley-Terry model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Jointly Extracting Interventions Outcomes and Findings from RCT Reports with LLMs": {
    "filename": "Jointly Extracting Interventions Outcomes and Findings from RCT Reports with LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Evidence Inference dataset",
        "Trialstreamer database"
      ],
      "models": [
        "Flan-T5-base",
        "Flan-T5-large",
        "BART",
        "T5-base",
        "BRAN",
        "DyGIE++",
        "ELI"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Steering LLMs Towards Unbiased Responses A Causality-Guided Debiasing Framework": {
    "filename": "Steering LLMs Towards Unbiased Responses A Causality-Guided Debiasing Framework.pdf",
    "analysis": {
      "benchmarks": [
        "WinoBias",
        "Discrim-Eval"
      ],
      "models": [
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "Claude 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond the Black Box A Statistical Model for LLM Reasoning and Inference": {
    "filename": "Beyond the Black Box A Statistical Model for LLM Reasoning and Inference.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Bayesian learning model",
        "Llama model",
        "llama-3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on Medical Large Language Models Technology Application Trustworthiness and Future Directions": {
    "filename": "A Survey on Medical Large Language Models Technology Application Trustworthiness and Future Directions.pdf",
    "analysis": {
      "benchmarks": [
        "USMLE",
        "PubMedQA",
        "MedMCQA",
        "MultiMedQA",
        "HealthSearchQA",
        "MIMIC-III",
        "BC5CDR",
        "NCBI",
        "ChemProt",
        "BioASQ-7b-factoid",
        "BLURB",
        "CovidDialog",
        "iCliniq",
        "MeQSum",
        "UMLS",
        "HOC",
        "CNER",
        "MRE",
        "MQA",
        "i2b2/UTHealth de-identification task",
        "Medical Meadow",
        "MedDialog-CN",
        "MedDG",
        "CHIPMDCFNPC",
        "IMCS-V2",
        "Long-form QA",
        "DDI",
        "KD-DTI",
        "CmedQA",
        "webmedQA",
        "Huatuo26M",
        "MEDQA-MCMLE",
        "MD-EHR",
        "SkinGPT-4",
        "XrayChat",
        "PathologyChat",
        "VQA-RAD",
        "SLAKE",
        "PathVQA",
        "NEJM",
        "USMLE-MM",
        "MMMU-HM",
        "ECG-QA",
        "CMtMedQA",
        "huatuo-26M"
      ],
      "models": [
        "ChiMed-GPT",
        "MedicalGPT",
        "HuatuoGPT-II",
        "ChatMed",
        "MedPrompt",
        "BERT",
        "RoBERTa",
        "BioBERT",
        "ClinicalBERT",
        "BioMegatron",
        "PubMedBERT",
        "KeBioLM",
        "BioBART",
        "ClinicalT5",
        "GatorTron",
        "Codex-Med",
        "Galactica",
        "Med-PaLM",
        "GPT-4-Med",
        "DeID-GPT",
        "ChatDoctor",
        "DoctorGLM",
        "MedAlpaca",
        "BenTsao",
        "PMC-LLaMA",
        "Visual Med-Alpaca",
        "BianQue",
        "Med-PaLM 2",
        "GatorTronGPT",
        "HuatuoGPT",
        "ClinicalGPT",
        "MedAGI",
        "LLaV A-Med",
        "OphGLM",
        "SoulChat",
        "Med-Flamingo",
        "BioGPT",
        "DISC-MedLLM",
        "IvyGPT",
        "CareGPT",
        "ShenNong-TCM-LLM",
        "WiNGPT",
        "Taiyi-LLM",
        "Zhongjing",
        "Med-Gemini",
        "Health-LLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ToRA A Tool-Integrated Reasoning Agent for Mathematical Problem Solving": {
    "filename": "ToRA A Tool-Integrated Reasoning Agent for Mathematical Problem Solving.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8k",
        "GSM-Hard",
        "SVAMP",
        "ASDIV",
        "TabMWP",
        "SingleEQ",
        "SingleOP",
        "AddSub",
        "MultiArith"
      ],
      "models": [
        "TORA",
        "TORA-7B",
        "TORA-CODE-34B",
        "WizardMath-70B",
        "GPT-4",
        "GPT-4-Code",
        "ChatGPT",
        "ChatGPT-Code",
        "LLaMA-2",
        "CodeLLaMA",
        "Toolformer",
        "Platypus-2",
        "Claude-2",
        "PaLM-2",
        "LLaMA-2 SFT",
        "LLaMA-2 RFT",
        "WizardMath",
        "CodeLLaMA (PAL)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Visual Programming Compositional visual reasoning without training": {
    "filename": "Visual Programming Compositional visual reasoning without training.pdf",
    "analysis": {
      "benchmarks": [
        "GQA",
        "NLVR V2"
      ],
      "models": [
        "VISPROG",
        "VILT-VQA",
        "VILT-NLVR",
        "CLIP",
        "Stable Diffusion",
        "OWL-ViT",
        "DSFD",
        "MaskFormer",
        "ViLT"
      ]
    }
  },
  "Learning diverse attacks on large language models for robust red-teaming and safety tuning": {
    "filename": "Learning diverse attacks on large language models for robust red-teaming and safety tuning.pdf",
    "analysis": {
      "benchmarks": [
        "GPT-2",
        "dolly-v2-7b",
        "Gemma-2b-it",
        "Llama-2-7b-chat",
        "Llama-2-13b-chat",
        "Llama-2-70b-chat",
        "Llama-3-8b-instruct",
        "Llama-3-70b-instruct",
        "Starling-7b-beta",
        "Mistral-7b-instruct-v0.2"
      ],
      "models": [
        "GFlowNet + MLE",
        "GFlowNet",
        "PPO + Novelty",
        "REINFORCE",
        "Supervised Fine-tuning (SFT)",
        "In-Context Learning (ICL)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Novel Preprocessing Technique for Data Embedding in Engineering Code Generation Using Large Language Model": {
    "filename": "Novel Preprocessing Technique for Data Embedding in Engineering Code Generation Using Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "RedHawk-SC"
      ],
      "models": [
        "Retrieval-Augmented Generation (RAG)",
        "Chain of Density for Renovation Credibility (CoDRC)",
        "Adaptive Text Renovation (ATR)",
        "Implicit Knowledge Expansion and Contemplation (IKEC)",
        "ChatEDA",
        "GPT-4",
        "Vicuna",
        "Llama2",
        "Mistral",
        "CodeGen",
        "AgentCoder",
        "Active Retrieval Augmented Generation",
        "TestPilot",
        "VeriGen"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Genshin General Shield for Natural Language Processing with Large Language Models": {
    "filename": "Genshin General Shield for Natural Language Processing with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "stanfordnlp/sst2",
        "dair-ai/emotion",
        "Deysi/spam-detection-dataset"
      ],
      "models": [
        "Genshin",
        "bert-base-*",
        "roberta-base-*",
        "GPT-3.5"
      ]
    }
  },
  "Exploring the Potential of Llama Models in Automated Code Refinement A Replication Study": {
    "filename": "Exploring the Potential of Llama Models in Automated Code Refinement A Replication Study.pdf",
    "analysis": {
      "benchmarks": [
        "Code Review dataset (CR)",
        "Code Review New dataset (CRN)"
      ],
      "models": [
        "ChatGPT",
        "CodeReviewer",
        "Llama 2",
        "CodeLlama",
        "Llama 3.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EcoAct Economic Agent Determines When to Register What Action": {
    "filename": "EcoAct Economic Agent Determines When to Register What Action.pdf",
    "analysis": {
      "benchmarks": [
        "ToolBench"
      ],
      "models": [
        "EcoAct",
        "ReAct",
        "DFSDT",
        "GPT-4-turbo",
        "GPT-4o"
      ]
    }
  },
  "HalluciDoctor Mitigating Hallucinatory Toxicity in Visual Instruction Data": {
    "filename": "HalluciDoctor Mitigating Hallucinatory Toxicity in Visual Instruction Data.pdf",
    "analysis": {
      "benchmarks": [
        "LLaVA-Instruction-158K",
        "MSCOCO",
        "Visual Genome",
        "MME",
        "OwlEval"
      ],
      "models": [
        "HalluciDoctor",
        "LLaVA",
        "MiniGPT-4",
        "LLaVA+",
        "LLaVA++",
        "mPLUG-Owl",
        "LRV-Instruction",
        "Faithful Prompt",
        "LURC",
        "VIGC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Explicitly Encoding Structural Symmetry is Key to Length Generalization in Arithmetic Tasks": {
    "filename": "Explicitly Encoding Structural Symmetry is Key to Length Generalization in Arithmetic Tasks.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Transformer",
        "BERT-based encoder-only attention model",
        "Linear Transformer",
        "one-layer transformer model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RAFT Adapting Language Model to Domain Specific RAG": {
    "filename": "RAFT Adapting Language Model to Domain Specific RAG.pdf",
    "analysis": {
      "benchmarks": [
        "PubMed",
        "HotpotQA",
        "Gorilla",
        "HuggingFace Hub",
        "Torch Hub",
        "Tensorflow Hub",
        "Natural Questions (NQ)",
        "Trivia QA"
      ],
      "models": [
        "RAFT",
        "LLaMA2-7B",
        "LLaMA2-7B + RAG",
        "DSF",
        "DSF + RAG",
        "GPT-3.5 + RAG"
      ]
    }
  },
  "GIT-Mol A Multi-modal Large Language Model for Molecular Science with Graph Image and Text": {
    "filename": "GIT-Mol A Multi-modal Large Language Model for Molecular Science with Graph Image and Text.pdf",
    "analysis": {
      "benchmarks": [
        "ChEBI-20",
        "MoleculeNet",
        "Tox21",
        "ToxCast",
        "Sider",
        "ClinTox",
        "BBBP",
        "Bace"
      ],
      "models": [
        "GIT-Mol",
        "GIT-Former",
        "MolT5",
        "SciBERT",
        "SwinOCSR",
        "MoMu",
        "MoleculeSTM",
        "MolReGPT",
        "KV-PLM",
        "GraphCL",
        "GraphMVP",
        "Mole-BERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models": {
    "filename": "A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "PaLM 2",
        "Llama 2",
        "PaLM 2 XXS",
        "PaLM 2 XS",
        "PaLM 2 S",
        "PaLM 2 L",
        "Llama 2 7B",
        "Llama 2 13B",
        "Llama 2 70B",
        "mReasoner"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Investigating Recurrent Transformers with Dynamic Halt": {
    "filename": "Investigating Recurrent Transformers with Dynamic Halt.pdf",
    "analysis": {
      "benchmarks": [
        "Long Range Arena (LRA)",
        "flip-flop language modeling",
        "ListOps",
        "Logical Inference"
      ],
      "models": [
        "Universal Transformer (UT)",
        "Temporal Latent Bottleneck (TLB)",
        "Gated Universal Transformer (GUT)",
        "Gated Universal Transformer Latent Bottleneck (GUTLB)",
        "Transformer",
        "Sparse Universal Transformer (SUT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DynaMath A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models": {
    "filename": "DynaMath A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "DYNAMATH",
        "MATHVISTA",
        "MATH-V",
        "MATHVERSE"
      ],
      "models": [
        "GPT-4o",
        "Claude-3.5 Sonnet",
        "Gemini Pro",
        "LLaVA-OneVision",
        "InternVL2 series",
        "LLaVA-v1.6 series",
        "Qwen2-VL",
        "DeepSeek-VL",
        "Llama 3.2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Grounding Large Language Models In Embodied Environment With Imperfect World Models": {
    "filename": "Grounding Large Language Models In Embodied Environment With Imperfect World Models.pdf",
    "analysis": {
      "benchmarks": [
        "Agent World",
        "Urban Driving",
        "Agent-QA",
        "Driving-QA",
        "Driving-QA (OOD)"
      ],
      "models": [
        "GLIMO",
        "LLaMA-3-8B",
        "LLaMA-3-70B",
        "LLaMA-2-13B",
        "OPT-13B",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SBI-RAG Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation": {
    "filename": "SBI-RAG Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K"
      ],
      "models": [
        "SBI-RAG",
        "GPT-4",
        "GPT-3.5 Turbo",
        "DistilBERT",
        "Ollama Llama 3.1"
      ]
    }
  },
  "GPT-ology Computational Models Silicon Sampling How should we think about LLMs in Cognitive Science": {
    "filename": "GPT-ology Computational Models Silicon Sampling How should we think about LLMs in Cognitive Science.pdf",
    "analysis": {
      "benchmarks": [
        "World Values Survey",
        "Kahneman and Tversky tasks",
        "Sally-Anne False-Belief task",
        "Winograd Schema tasks"
      ],
      "models": [
        "GPT-3",
        "GPT-4",
        "chatGPT",
        "LLaMA",
        "Alpaca",
        "Vicuna",
        "LLaMA-7B",
        "LLaMA-13B"
      ]
    }
  },
  "DORIS-MAE Scientific Document Retrieval using Multi-level Aspect-based Queries": {
    "filename": "DORIS-MAE Scientific Document Retrieval using Multi-level Aspect-based Queries.pdf",
    "analysis": {
      "benchmarks": [
        "DORIS-MAE",
        "MS MARCO",
        "LoTTE",
        "NQ",
        "Wiki-QA",
        "CSFCube",
        "TRECCOVID",
        "RELISH"
      ],
      "models": [
        "TF-IDF",
        "BM25",
        "RocketQA-v2",
        "ColBERT-v2",
        "SimLM",
        "SPLADE-v2",
        "SPECTER",
        "ASPIRE",
        "ada-002",
        "E5-large-v2",
        "Sentence-BERT",
        "ChatGPT",
        "Anno-GPT",
        "LLAMA",
        "SimCSE",
        "ERNIE",
        "SciBERT",
        "ANCE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OpenFedLLM Training Large Language Models on Decentralized Private Data via Federated Learning": {
    "filename": "OpenFedLLM Training Large Language Models on Decentralized Private Data via Federated Learning.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "BBH",
        "DROP",
        "HumanEval",
        "CRASS",
        "Vicuna-Bench",
        "MT-Bench",
        "FPB",
        "FIQA-SA",
        "TFNS",
        "NWGI",
        "MedQA",
        "PubMedQA",
        "MedMCQA",
        "MBPP",
        "DS-1000",
        "HumanEvalFix",
        "HumanEvalSyn",
        "CoNaLa",
        "ConCode",
        "GSM8K",
        "HHH",
        "AdvBench"
      ],
      "models": [
        "OpenFedLLM",
        "Llama2-7B",
        "GPT-4",
        "GPT-3.5",
        "FedAvg",
        "FedProx",
        "SCAFFOLD",
        "FedAvgM",
        "FedAdagrad",
        "FedYogi",
        "FedAdam",
        "FedDPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Alfred A System for Prompted Weak Supervision": {
    "filename": "Alfred A System for Prompted Weak Supervision.pdf",
    "analysis": {
      "benchmarks": [
        "YouTube spam detection dataset",
        "Oxford-IIIT Pet dataset"
      ],
      "models": [
        "Alfred",
        "T0++",
        "CLIP-ViT/L-14",
        "NaiveBayes label model",
        "NPLM label model",
        "MajorityVote model",
        "FlyingSquid model"
      ]
    }
  },
  "On the Modeling Capabilities of Large Language Models for Sequential Decision Making": {
    "filename": "On the Modeling Capabilities of Large Language Models for Sequential Decision Making.pdf",
    "analysis": {
      "benchmarks": [
        "MiniWob",
        "NetHack",
        "Wordle",
        "MetaWorld",
        "POPE",
        "GQA",
        "AI2D",
        "MMMU"
      ],
      "models": [
        "Large Language Models (LLMs)",
        "LLM Policy",
        "Bradley-Terry model",
        "AI Feedback",
        "Direct Scalar",
        "Reward as Code",
        "Embedding-based",
        "GPT-4o",
        "Llama 3",
        "PaliGemma"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks": {
    "filename": "Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks.pdf",
    "analysis": {
      "benchmarks": [
        "AdvBench Subset",
        "OpenAI and Anthropic Red Teaming Dataset",
        "MasterKey dataset"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Claude 2",
        "Llama-2-7b",
        "Vicuna-7b",
        "Mixtral 8 \u00d77b",
        "Llama-3",
        "Wizardlm-70b",
        "PAIR",
        "GCG",
        "TAP",
        "ICA",
        "CIA",
        "SmoothLLM",
        "Self-reminder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-grounded Diffusion Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models": {
    "filename": "LLM-grounded Diffusion Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "COCO",
        "T2I-CompBench"
      ],
      "models": [
        "Stable Diffusion",
        "SDXL",
        "LMD",
        "GLIGEN",
        "VisualChatGPT",
        "GILL",
        "MultiDiffusion",
        "Backward Guidance",
        "BoxDiff"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Creative Agents Empowering Agents with Imagination for Creative Tasks": {
    "filename": "Creative Agents Empowering Agents with Imagination for Creative Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "Minecraft Building Creation"
      ],
      "models": [
        "Creative Agents",
        "Vanilla GPT-4",
        "CoT+GPT-4",
        "Diffusion+GPT-4V",
        "Diffusion+BC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Contrastive Decoding Improves Reasoning in Large Language Models": {
    "filename": "Contrastive Decoding Improves Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HellaSwag",
        "GSM8K",
        "AQuA",
        "ASDiv",
        "SVAMP",
        "MATH",
        "CommonsenseQA",
        "StrategyQA",
        "AI2 Reasoning Challenge",
        "BoolQ",
        "MMLU",
        "PIQA",
        "SIQA",
        "WinoGrande",
        "OpenBookQA",
        "TriviaQA"
      ],
      "models": [
        "LLaMA-65B",
        "LLaMA 2",
        "GPT-3.5",
        "PaLM 2-L",
        "PaLM-540B",
        "FLAN-T5",
        "FLAN-T5-XXL",
        "FLAN-T5-Small",
        "LLaMA-1.5B",
        "LLaMA-7B",
        "LLaMA-13B",
        "LLaMA-30B"
      ]
    }
  },
  "Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs": {
    "filename": "Mutation-based Consistency Testing for Evaluating the Code Understanding Capability of LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval-X"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multimodal Chain-of-Thought Reasoning in Language Models": {
    "filename": "Multimodal Chain-of-Thought Reasoning in Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ScienceQA",
        "A-OKVQA"
      ],
      "models": [
        "Multimodal-CoT",
        "Zero-Shot-CoT",
        "Few-Shot-CoT",
        "Self-Consistency-CoT",
        "Least-to-Most Prompting",
        "Retrieval-CoT",
        "PromptPG-CoT",
        "Auto-CoT",
        "Complexity-CoT",
        "Few-Shot-PoT",
        "UnifiedQA",
        "Fine-Tuned T5 XXL",
        "Fine-Tune-CoT",
        "GPT-3.5",
        "PaLM",
        "Codex",
        "T5",
        "FLAN-Alpaca",
        "ViT",
        "MCAN",
        "Top-Down",
        "BAN",
        "DFAF",
        "ViLT",
        "Patch-TRM",
        "VisualBERT",
        "ChatGPT",
        "GPT-4",
        "Chameleon",
        "LLaMA-Adapter",
        "LLaVA",
        "InstructBLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CPSeg Finer-grained Image Semantic Segmentation via Chain-of-Thought Language Prompting": {
    "filename": "CPSeg Finer-grained Image Semantic Segmentation via Chain-of-Thought Language Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "FloodPrompt",
        "FloodNet",
        "LoveDA"
      ],
      "models": [
        "CPSeg",
        "DeepLab V3+",
        "DenseCLIP",
        "PSPNet",
        "ENet",
        "SegFormer-B0"
      ]
    }
  },
  "Large Language Models as Commonsense Knowledge for Large-Scale Task Planning": {
    "filename": "Large Language Models as Commonsense Knowledge for Large-Scale Task Planning.pdf",
    "analysis": {
      "benchmarks": [
        "VirtualHome",
        "Novel Apartment"
      ],
      "models": [
        "LLM-MCTS",
        "L-Model",
        "L-Policy",
        "GPT2",
        "GPT3.5",
        "GPT4",
        "GPT3.5-MCTS",
        "UCT",
        "finetuned GPT2 policy",
        "GPT3.5 Policy"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Latent Logic Tree Extraction for Event Sequence Explanation from LLMs": {
    "filename": "Latent Logic Tree Extraction for Event Sequence Explanation from LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-3",
        "EPIC-100",
        "StackOverflow"
      ],
      "models": [
        "GPT-4 w/ semantic",
        "GPT-4 w/o semantic",
        "GPT-3.5-Turbo w semantic",
        "GPT-3.5-Turbo w/o semantic",
        "LaTee",
        "AttNHP",
        "Pt-AttNHP",
        "k-shot CoT",
        "ToT",
        "SFT Fine-Tuning",
        "PPO Fine-Tuning",
        "GFN Fine-Tuning"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Calibration and Correctness of Language Models for Code": {
    "filename": "Calibration and Correctness of Language Models for Code.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "DyPyBench",
        "Defects4J",
        "ManySStubs4J"
      ],
      "models": [
        "GPT-3.5",
        "Codex",
        "CodeGen2-16B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Watermarked LLMs be Identified by Users via Crafted Prompts": {
    "filename": "Can Watermarked LLMs be Identified by Users via Crafted Prompts.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Water-Probe",
        "Water-Bag",
        "KGW",
        "Aar",
        "KGW-Min",
        "KGW-Skip",
        "DiPMark",
        "\u03b3-reweighting",
        "EXP-Edit",
        "ITS-Edit",
        "Qwen2.5-1.5B",
        "OPT-2.7B",
        "Llama-3.2-3B",
        "Qwen2.5-3B",
        "Llama2-7B",
        "Mixtral-7B",
        "Qwen2.5-7B",
        "Llama-3.1-8B",
        "Llama2-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SaySelf Teaching LLMs to Express Confidence with Self-Reflective Rationales": {
    "filename": "SaySelf Teaching LLMs to Express Confidence with Self-Reflective Rationales.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "TruthfulQA",
        "StrategyQA",
        "FEVER",
        "HaluEval",
        "ParaRel",
        "SQUADRUN"
      ],
      "models": [
        "SaySelf",
        "Direct Prompting (DP)",
        "Self-Consistency (SC)",
        "Prompting for Correctness (PC)",
        "R-Tuning",
        "Aligning with Self-Consistency-based Confidence (AS)",
        "Grouping-based Confidence Estimates for Calibration Training (GCE)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "mABC multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture": {
    "filename": "mABC multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture.pdf",
    "analysis": {
      "benchmarks": [
        "AIOps challenge dataset",
        "Train-Ticket dataset"
      ],
      "models": [
        "MABC",
        "TraceAnomaly",
        "MEPFL",
        "RCA-Copilot",
        "RCAgent",
        "D-Bot",
        "Decision Tree",
        "ReAct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Planning-Driven Programming A Large Language Model Programming Workflow": {
    "filename": "Planning-Driven Programming A Large Language Model Programming Workflow.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "APPS",
        "CodeContests",
        "HumanEval-ET",
        "MBPP-ET"
      ],
      "models": [
        "LPW",
        "SLPW",
        "GPT-3.5",
        "Llama-3",
        "Phi-3",
        "GPT-4o",
        "Baseline",
        "Self-Planning (SP)",
        "Self-Debugging (+Expl) (SD)",
        "LDB"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Aladdin Zero-Shot Hallucination of Stylized 3D Assets from Abstract Scene Descriptions": {
    "filename": "Aladdin Zero-Shot Hallucination of Stylized 3D Assets from Abstract Scene Descriptions.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Aladdin",
        "baseline method",
        "GPT-3",
        "CLIP",
        "image diffusion models",
        "Future3D",
        "Objaverse"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can LLMs Understand Time Series Anomalies": {
    "filename": "Can LLMs Understand Time Series Anomalies.pdf",
    "analysis": {
      "benchmarks": [
        "Time-MMD"
      ],
      "models": [
        "GPT-3",
        "LLaMA-2",
        "AnomalyLLM",
        "Qwen-VL-Chat",
        "InternVL2-Llama3-76B",
        "GPT-4o-mini",
        "Gemini-1.5-Flash"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GameEval Evaluating LLMs on Conversational Games": {
    "filename": "GameEval Evaluating LLMs on Conversational Games.pdf",
    "analysis": {
      "benchmarks": [
        "Cifar-100"
      ],
      "models": [
        "GameEval",
        "ChatGPT",
        "GPT-4",
        "Text-Davinci-003",
        "TD003"
      ]
    }
  },
  "UrbanKGent A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction": {
    "filename": "UrbanKGent A Unified Large Language Model Agent Framework for Urban Knowledge Graph Construction.pdf",
    "analysis": {
      "benchmarks": [
        "NYC-Instruct",
        "NYC",
        "NYC-Large",
        "CHI-Instruct",
        "CHI",
        "CHI-Large",
        "NYC-UUKG",
        "CHI-UUKG"
      ],
      "models": [
        "UrbanKGent-7B",
        "UrbanKGent-8B",
        "UrbanKGent-13B",
        "GPT-4",
        "GPT-3.5",
        "Llama-2-7B",
        "Llama-2-13B",
        "Llama-2-70B",
        "Llama-3-8B",
        "Llama-3-70B",
        "Vicuna-7B",
        "Alpaca-7B",
        "Mistral-7B",
        "RelationPrompt",
        "PRGC",
        "KG-BERT",
        "KG-T5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Models are Bounded Pragmatic Speakers Understanding RLHF from a Bayesian Cognitive Modeling Perspective": {
    "filename": "Language Models are Bounded Pragmatic Speakers Understanding RLHF from a Bayesian Cognitive Modeling Perspective.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "bounded pragmatic speaker",
        "large language models",
        "pragmatic inference",
        "reinforcement learning from human feedback",
        "RLHF-tuned LLMs",
        "base speaker",
        "theory-of-mind listener",
        "ToM listener",
        "variational inference",
        "Monte-Carlo inference"
      ]
    }
  },
  "Long-Horizon Planning for Multi-Agent Robots in Partially Observable Environments": {
    "filename": "Long-Horizon Planning for Multi-Agent Robots in Partially Observable Environments.pdf",
    "analysis": {
      "benchmarks": [
        "MAP-THOR",
        "AI2-THOR"
      ],
      "models": [
        "LLaMAR",
        "SmartLLM",
        "CoELA",
        "Act",
        "ReAct",
        "Chain-of-Thought"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can LLM be a Good Path Planner based on Prompt Engineering Mitigating the Hallucination for Path Planning": {
    "filename": "Can LLM be a Good Path Planner based on Prompt Engineering Mitigating the Hallucination for Path Planning.pdf",
    "analysis": {
      "benchmarks": [
        "5\u00d75 mazes",
        "7\u00d77 mazes",
        "10\u00d710 mazes"
      ],
      "models": [
        "S2RCQL",
        "ERNIE-Bot 4.0",
        "CoT",
        "ToT",
        "ReAct",
        "Rememberer",
        "naive prompt"
      ]
    }
  },
  "MedThink Explaining Medical Visual Question Answering via Multimodal Decision-Making Rationale": {
    "filename": "MedThink Explaining Medical Visual Question Answering via Multimodal Decision-Making Rationale.pdf",
    "analysis": {
      "benchmarks": [
        "R-RAD",
        "R-SLAKE",
        "R-Path",
        "VQA-RAD",
        "SLAKE",
        "PathVQA"
      ],
      "models": [
        "MedThink",
        "Med-MoE",
        "LLaVA-Med",
        "Gemini Pro",
        "MFB",
        "SAN",
        "BAN",
        "MEVF+SAN",
        "MEVF+BAN",
        "MMBERT",
        "PubMedCLIP",
        "Prefix T. Medical LM",
        "LLaVA",
        "Med-Flamingo",
        "Med-Gemini"
      ]
    }
  },
  "Distilling LLMs Decomposition Abilities into Compact Language Models": {
    "filename": "Distilling LLMs Decomposition Abilities into Compact Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "GSM8K-AI-SubQ"
      ],
      "models": [
        "GPT-4",
        "Claude 22",
        "Gemini",
        "ChatGPT",
        "GPT-2",
        "DistilGPT",
        "Mistral 7B",
        "LLaMA 7B",
        "LLaMA 13B"
      ]
    }
  },
  "State of What Art A Call for Multi-Prompt LLM Evaluation": {
    "filename": "State of What Art A Call for Multi-Prompt LLM Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "LM ENTRY",
        "BIG-bench Lite",
        "BIG-bench Hard"
      ],
      "models": [
        "GPT-3.5-Turbo",
        "LLaMA",
        "T5",
        "Flan-T5",
        "T0",
        "Alpaca",
        "Vicuna",
        "Airoboros",
        "UltraLM",
        "Nous-Hermes",
        "Falcon-Instruct",
        "MPT",
        "Minotaur",
        "davinci",
        "text-davinci-002",
        "text-davinci-003"
      ]
    }
  },
  "Despite super-human performance current LLMs are unsuited for decisions about ethics and safety": {
    "filename": "Despite super-human performance current LLMs are unsuited for decisions about ethics and safety.pdf",
    "analysis": {
      "benchmarks": [
        "ETHICS",
        "ETHICS-C-S"
      ],
      "models": [
        "GPT-3 (smallest model, 2019)",
        "GPT-3 with random labels",
        "GPT-3 (largest model, 2019)",
        "GPT-3 (largest model, current)",
        "SimPrompter"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Medprompt to o1 Exploration of Run-Time Strategies for Medical Challenge Problems and Beyond": {
    "filename": "From Medprompt to o1 Exploration of Run-Time Strategies for Medical Challenge Problems and Beyond.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "MedMCQA Dev",
        "MMLU Clinical Knowledge",
        "MMLU Anatomy",
        "MMLU Medical Genetics",
        "MMLU Professional Medicine",
        "MMLU College Biology",
        "MMLU College Medicine",
        "NCLEX",
        "JMLE-2024",
        "USMLE Sample Exam",
        "USMLE Self Assessment"
      ],
      "models": [
        "o1-preview",
        "GPT-4",
        "GPT-4o",
        "GPT-4 Turbo",
        "Medprompt",
        "PubMedBERT",
        "BioLinkBERT",
        "DRAGON",
        "BioMedLM",
        "Med-PaLM",
        "Med-PaLM 2",
        "Med-Gemini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A survey on multimodal large language models": {
    "filename": "A survey on multimodal large language models.pdf",
    "analysis": {
      "benchmarks": [
        "ScienceQA",
        "NoCaps",
        "Flickr30K",
        "biomedical VQA",
        "MME",
        "MMBench",
        "Video-ChatGPT",
        "Video-Bench",
        "POPE",
        "COCO"
      ],
      "models": [
        "GPT-4V",
        "CLIP",
        "OFA",
        "Flamingo",
        "VIMA",
        "PaLM-E",
        "LLaMA-Adapter",
        "BLIP-2",
        "HuggingGPT",
        "MM-REACT",
        "InstructBLIP",
        "MultiModal-GPT",
        "VisionLLM",
        "DetGPT",
        "LLaVA",
        "MiniGPT-4",
        "mPLUG-Owl",
        "VideoChat",
        "Pengi",
        "LLaVA-Med",
        "Otter",
        "MotionGPT",
        "Shikra",
        "3D-LLM",
        "GPT4RoI",
        "Lynx",
        "AnyMAL",
        "LISA",
        "ASM",
        "VisCPM",
        "Qwen-VL",
        "PointLLM",
        "ImageBind-LLM",
        "NExT-GPT",
        "DreamLLM",
        "Xcomposer",
        "LanguageBIND",
        "LLaVA-1.5",
        "CogVLM",
        "Ferret",
        "GLaMM",
        "Fuyu-8B",
        "Monkey",
        "SPHINX",
        "Video-LLaVA",
        "MobileVLM",
        "MM1",
        "MoE-LLaVA",
        "Mobile-Agent",
        "Video-LLaMA",
        "Chameleon",
        "Woodpecker",
        "LLaMA-VID",
        "LaVIN",
        "Gemini",
        "Vary",
        "Kosmos-1",
        "Qwen-VL-Max",
        "Kosmos-2",
        "GPT4Tools",
        "ViperGPT",
        "V*",
        "Emu",
        "MMICL",
        "LTU",
        "EmbodiedGPT",
        "TextMonkey",
        "OpenCLIP-ConvNext-L",
        "CLIP-ViT-L/14",
        "EVA-CLIP-ViT-G/14",
        "OpenCLIP-ViT-G/14",
        "OpenCLIP-ViT-bigG/14",
        "Flan-T5-XL/XXL",
        "LLaMA",
        "Vicuna",
        "LLaMA-2",
        "Qwen",
        "LLaVA-RLHF",
        "RLHF-V",
        "VLFeedback",
        "LLaVA-Instruct",
        "LVIS-Instruct",
        "ALLaVA",
        "Video-ChatGPT",
        "VideoChat",
        "Clotho-Detail",
        "LLaVA-Med",
        "mPLUG-DocOwl",
        "CogAgent",
        "AppAgent",
        "MobileVLM",
        "Mobile-Agent",
        "LLaVA-Med",
        "LLaVA-RLHF",
        "LRV-Instruction"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring Equation as a Better Intermediate Meaning Representation for Numerical Reasoning": {
    "filename": "Exploring Equation as a Better Intermediate Meaning Representation for Numerical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "Algebra"
      ],
      "models": [
        "BRIDGE",
        "CoT",
        "Tab-CoT",
        "Declarative",
        "PoT",
        "PAL",
        "Codex",
        "GPT3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMs left right and center Assessing GPTs capabilities to label political bias from web domains": {
    "filename": "LLMs left right and center Assessing GPTs capabilities to label political bias from web domains.pdf",
    "analysis": {
      "benchmarks": [
        "Ad Fontes Media",
        "AllSides",
        "Media Bias/Fact Check (MBFC)",
        "Open PageRank"
      ],
      "models": [
        "GPT-4",
        "gpt-4-1106-preview"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Plan of Thoughts Heuristic-Guided Problem Solving with Large Language Models": {
    "filename": "Plan of Thoughts Heuristic-Guided Problem Solving with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Game of 24"
      ],
      "models": [
        "Plan of Thoughts (PoT)",
        "Tree of Thoughts (ToT)",
        "Chain of Thoughts (CoT)",
        "GPT-4",
        "GPT-3.5-Turbo-Instruct"
      ]
    }
  },
  "How Aligned are Human Chart Takeaways and LLM Predictions A Case Study on Bar Charts with Varying Layouts": {
    "filename": "How Aligned are Human Chart Takeaways and LLM Predictions A Case Study on Bar Charts with Varying Layouts.pdf",
    "analysis": {
      "benchmarks": [
        "Xiong et al. datasets"
      ],
      "models": [
        "GPT-4",
        "GPT-4V",
        "GPT-3.5",
        "Gemini 1.0 Pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cognitive Modeling with Scaffolded LLMs A Case Study of Referential Expression Generation": {
    "filename": "Cognitive Modeling with Scaffolded LLMs A Case Study of Referential Expression Generation.pdf",
    "analysis": {
      "benchmarks": [
        "A3DS"
      ],
      "models": [
        "Iterative Model (IM)",
        "Ablated Single-Pass Model (SP)",
        "LLM Baseline",
        "gpt-3.5-turbo"
      ]
    }
  },
  "Ever-Evolving Memory by Blending and Refining the Past": {
    "filename": "Ever-Evolving Memory by Blending and Refining the Past.pdf",
    "analysis": {
      "benchmarks": [
        "Multi-Session Chat (MSC)",
        "Conversation Chronicles (CC)"
      ],
      "models": [
        "CREEM",
        "SumMem MSC",
        "REBOTCC",
        "GPT CareCall"
      ]
    }
  },
  "Seeing the Big through the Small Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations": {
    "filename": "Seeing the Big through the Small Can LLMs Approximate Human Judgment Distributions on NLI from a Few Explanations.pdf",
    "analysis": {
      "benchmarks": [
        "Chaos NLI",
        "VariErr NLI",
        "MNLI"
      ],
      "models": [
        "Mixtral",
        "Llama3",
        "BERT",
        "RoBERTa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MARVEL Multidimensional Abstraction and Reasoning through Visual Evaluation and Learning": {
    "filename": "MARVEL Multidimensional Abstraction and Reasoning through Visual Evaluation and Learning.pdf",
    "analysis": {
      "benchmarks": [
        "MARVEL",
        "RAVEN",
        "Bongard-LOGO",
        "SVRT",
        "ARC",
        "DOPT"
      ],
      "models": [
        "GPT-4V",
        "Gemini",
        "Claude3",
        "InstructBLIP",
        "BLIP-2",
        "Fuyu",
        "Qwen-VL",
        "LLaVA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Are Hard Examples also Harder to Explain A Study with Human and Model-Generated Explanations": {
    "filename": "Are Hard Examples also Harder to Explain A Study with Human and Model-Generated Explanations.pdf",
    "analysis": {
      "benchmarks": [
        "Winogrande"
      ],
      "models": [
        "GPT-3",
        "RoBERTa-large"
      ]
    }
  },
  "OpenR An Open Source Framework for Advanced Reasoning with Large Language Models": {
    "filename": "OpenR An Open Source Framework for Advanced Reasoning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "MATH500"
      ],
      "models": [
        "OpenR",
        "o1",
        "Qwen2.5-Math-7B-Instruct",
        "Qwen2.5-1.5B-Math-Instruct",
        "Math-psa",
        "Math-Shepherd"
      ]
    }
  },
  "TextMonkey An OCR-Free Large Multimodal Model for Understanding Document": {
    "filename": "TextMonkey An OCR-Free Large Multimodal Model for Understanding Document.pdf",
    "analysis": {
      "benchmarks": [
        "STVQA",
        "TextVQA",
        "OCRVQA",
        "DocVQA",
        "InfoVQA",
        "ChartVQA",
        "DeepForm",
        "Kleister Charity",
        "WikiTableQuestions",
        "FUNSD",
        "SROIE",
        "POIE",
        "OCRBench",
        "Total-Text",
        "CTW1500",
        "ICDAR 2015",
        "COCOText",
        "TextOCR",
        "HierText",
        "MLT",
        "IIT-CDIP"
      ],
      "models": [
        "TextMonkey",
        "LLaVAR",
        "UniDoc",
        "TGDoc",
        "mPLUG-DocOwl",
        "UReader",
        "Monkey",
        "DocPedia",
        "BLIP2-OPT-6.7B",
        "mPLUG-Owl",
        "InstructBLIP",
        "BLIVA",
        "mPLUG-Owl2",
        "LLaVA1.5-7B",
        "InternVL",
        "InternLM-XComposer2",
        "Donut",
        "Pix2Struct",
        "Qwen-VL",
        "SPTS v2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FinEval A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models": {
    "filename": "FinEval A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "FinEval",
        "MMLU",
        "BIG-bench",
        "GAOKAO-Bench",
        "FinQA",
        "FinanceIQ",
        "CFLUE",
        "SecEval"
      ],
      "models": [
        "Claude 3.5-Sonnet",
        "GPT-4o",
        "Qwen2.5-72B-Instruct",
        "XuanYuan3-70B-Chat",
        "Gemini1.5-Pro",
        "GPT-4o-mini",
        "Gemini1.5-Flash",
        "Qwen2.5-7B-Instruct",
        "Yi1.5-34B-Chat",
        "InternLM2.5-20B-Chat",
        "GLM-4-9B-Chat",
        "InternLM2-20B-Chat",
        "Yi1.5-9B-Chat",
        "XuanYuan2-70B-Chat",
        "CFGPT2-7B",
        "Baichuan2-13B-Chat",
        "ChatGLM3-6B",
        "DISC-FinLLM",
        "FinGPTv3.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TR2MTL LLM based framework for Metric Temporal Logic Formalization of Traffic Rules": {
    "filename": "TR2MTL LLM based framework for Metric Temporal Logic Formalization of Traffic Rules.pdf",
    "analysis": {
      "benchmarks": [
        "StVO",
        "VCoRT",
        "CommonRoad",
        "drone planning dataset"
      ],
      "models": [
        "TR2MTL",
        "GPT-4",
        "GPT-3.5-turbo",
        "StarCoder",
        "Falcon-7b",
        "Bloomz",
        "nl2ltl"
      ]
    }
  },
  "LLM-based Robot Task Planning with Exceptional Handling for General Purpose Service Robots": {
    "filename": "LLM-based Robot Task Planning with Exceptional Handling for General Purpose Service Robots.pdf",
    "analysis": {
      "benchmarks": [
        "RoboCup@Home Command Generator"
      ],
      "models": [
        "Constrained LLM prompt scheme",
        "Baidu ERNIE-Bot 4.0",
        "YOLOv7",
        "MediaPipe",
        "Deepface",
        "Baidu Short Speech-to-Text",
        "SMACH state machine"
      ]
    }
  },
  "Explanation-based Finetuning Makes Models More Robust to Spurious Cues": {
    "filename": "Explanation-based Finetuning Makes Models More Robust to Spurious Cues.pdf",
    "analysis": {
      "benchmarks": [
        "ComVE",
        "CREAK",
        "e-SNLI",
        "SBIC"
      ],
      "models": [
        "GPT-3 (Davinci)",
        "GPT-3 (Curie)",
        "GPT-3 (Babbage)",
        "GPT-3 (Ada)",
        "T5",
        "BART",
        "OPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Incremental Learning in Large Language Models A Critical Review": {
    "filename": "Towards Incremental Learning in Large Language Models A Critical Review.pdf",
    "analysis": {
      "benchmarks": [
        "CIFAR100",
        "ImageNet100",
        "Split CIFAR-100",
        "Split ImageNet-R",
        "CIFAR-10",
        "ImageNet1K",
        "MovieLens",
        "Amazon-Book",
        "Super-Natural Instructions",
        "MTIL",
        "VQA"
      ],
      "models": [
        "BERT",
        "DeBERTa",
        "ALBERT",
        "GPT4",
        "ChatGPT",
        "Gemini",
        "LLaMA",
        "Falcon",
        "Bard",
        "GLM",
        "T5",
        "BART",
        "LLaMA2",
        "LoRA",
        "ViT-B/16-IN21K",
        "ViT-B/16-1K",
        "MiniGPT-4",
        "Vicuna",
        "BLIP",
        "LLaVA",
        "Otter",
        "InstructBLIP",
        "LENS",
        "CLIP",
        "CoLeCLIP",
        "PROOF",
        "T0",
        "Progressive Prompts",
        "X-ICL",
        "BLOOM-7B",
        "XGLM-7.5B",
        "LLaVA-1.5",
        "SelfExtend",
        "SSR",
        "Alpaca-7B",
        "SLM",
        "GPT-NeoX",
        "MEND",
        "DynaMind",
        "LEAGUE++",
        "AutoGPT+P",
        "COPR",
        "LLaMA Pro-8.3B",
        "LLaMA Pro-Instruct",
        "Self-Synthesized Rehearsal",
        "Online Training using External Interactions"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TPO Aligning Large Language Models with Multi-branch  Multi-step Preference Trees": {
    "filename": "TPO Aligning Large Language Models with Multi-branch  Multi-step Preference Trees.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "SVAMP",
        "ASDiv",
        "GSM-Plus",
        "HumanEval",
        "MBPP"
      ],
      "models": [
        "TPO",
        "DPO",
        "Qwen2-1.5B-Instruct",
        "Qwen2-7B-Instruct",
        "DeepSeekMath-7B-Instruct",
        "DeepSeekMath-7B-RL",
        "GPT-3.5 Turbo",
        "GPT-4"
      ]
    }
  },
  "Scaling Laws for Predicting Downstream Performance in LLMs": {
    "filename": "Scaling Laws for Predicting Downstream Performance in LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "RACE",
        "TriviaQA",
        "BigBench-Challenge (BBH)",
        "ARC-Challenge (ARC)",
        "Hellaswag",
        "HumanEval",
        "MMLU"
      ],
      "models": [
        "FLP",
        "FLP-M",
        "3B LLM",
        "7B LLM",
        "13B LLM",
        "sampling LMs up to 3B",
        "sampling LMs with sizes of {0.12B, 0.2B, 0.32B, 0.5B, 0.72B, 1B}"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "X-IQE eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models": {
    "filename": "X-IQE eXplainable Image Quality Evaluation for Text-to-Image Generation with Visual Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "COCO Captions",
        "DrawBench"
      ],
      "models": [
        "X-IQE",
        "MiniGPT-4",
        "Stable Diffusion 1.4",
        "Stable Diffusion 2.1",
        "Openjourney",
        "DeepFloyd-IF",
        "CLIPScore",
        "Aesthetic Predictor",
        "ImageReward",
        "HPS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-supervised Interpretable Concept-based Models for Text Classification": {
    "filename": "Self-supervised Interpretable Concept-based Models for Text Classification.pdf",
    "analysis": {
      "benchmarks": [
        "CEBaB",
        "MultiEmotions-IT",
        "Drug review",
        "Depression"
      ],
      "models": [
        "ICEM",
        "Self-ICEM",
        "R-ICEM",
        "L-ICEM",
        "CBM+LL",
        "CBM+MLP",
        "CBM+DT",
        "CBM+XG",
        "CEM",
        "E2E"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FoMo Rewards Can we cast foundation models as reward functions": {
    "filename": "FoMo Rewards Can we cast foundation models as reward functions.pdf",
    "analysis": {
      "benchmarks": [
        "VIMABench",
        "VIMA(Uni)"
      ],
      "models": [
        "FoMo Rewards",
        "CLIP",
        "Flamingo",
        "ViT",
        "Mosaic pretrained transformers (MPT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards LogiGLUE A Brief Survey and A Benchmark for Analyzing Logical Reasoning Capabilities of Language Models": {
    "filename": "Towards LogiGLUE A Brief Survey and A Benchmark for Analyzing Logical Reasoning Capabilities of Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "LOGIGLUE",
        "RuleTaker",
        "PrOntoQA",
        "WN18RR",
        "Rulebert",
        "\u03b1ARCT",
        "\u03b1NLI",
        "AbductionRule-Animal",
        "LogicNLI",
        "ProofWriter",
        "Rulebert-Union",
        "FOLIO",
        "ANLI",
        "CLUTTR-Robust",
        "LogiQA",
        "AbductionRule-person",
        "bAbi",
        "Bird-Electricity",
        "NatlLang",
        "Winologic",
        "WaNLI",
        "PrOntoQA",
        "BigBench",
        "CLUTTR-Systematic",
        "ReClor",
        "LogiQA 2.0"
      ],
      "models": [
        "LogiT5",
        "Flan-T5",
        "GPT-4",
        "GPT-3.5-turbo",
        "LLaMA-2-chat",
        "BERT",
        "GPT2",
        "RoBERTa",
        "XLNet",
        "APOLLO",
        "MERIt",
        "MERIt+",
        "NL-ProofS",
        "ProofWriter",
        "Fine-tune-CoT",
        "LMLP",
        "Logic-LM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Generative Type Inference for Python": {
    "filename": "Generative Type Inference for Python.pdf",
    "analysis": {
      "benchmarks": [
        "ManyTypes4Py"
      ],
      "models": [
        "TYPEGEN",
        "Type4Py",
        "TypeBERT",
        "TypeWriter",
        "HiTyper",
        "InCoder-1.3B",
        "InCoder-6.7B",
        "UniXcoder",
        "CodeT5-base",
        "CodeT5-large",
        "GPT-Neo-1.3B",
        "GPT-Neo-2.7B",
        "GPT-J",
        "CodeGen",
        "GPT-3.5",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Words into Action Learning Diverse Humanoid Robot Behaviors using Language Guided Iterative Motion Refinement": {
    "filename": "Words into Action Learning Diverse Humanoid Robot Behaviors using Language Guided Iterative Motion Refinement.pdf",
    "analysis": {
      "benchmarks": [
        "HumanML3D"
      ],
      "models": [
        "Digit humanoid robot",
        "T2M-GPT",
        "Adversarial Motion Priors (AMP)",
        "Proximal Policy Optimization (PPO)",
        "ChatGPT-4"
      ]
    }
  },
  "Is Your Model Really A Good Math Reasoner Evaluating Mathematical Reasoning with Checklist": {
    "filename": "Is Your Model Really A Good Math Reasoner Evaluating Mathematical Reasoning with Checklist.pdf",
    "analysis": {
      "benchmarks": [
        "MATHCHECK-GSM",
        "MATHCHECK-GEO",
        "GSM8k",
        "GeoQA",
        "UniGeo",
        "Geometry3K",
        "GSM1k",
        "MATH",
        "TheromQA"
      ],
      "models": [
        "GPT-4o",
        "GPT-4-Turbo-20240409",
        "GPT-3.5-Turbo",
        "O1-preview",
        "O1-mini",
        "Gemini-1.5-Pro",
        "Claude-3.5-sonnet-20240620",
        "Claude-3-opus-20240229",
        "Claude-3-sonnet-20240229",
        "Claude-3-haiku-20240229",
        "Llama-3.1-70B-Instruct",
        "Llama-3-70B-Instruct",
        "DeepSeek V2",
        "Mixtral 8 x 7B-Instruct",
        "Mixtral 8 x 7B-Base",
        "Qwen1.5-72B-Chat",
        "Phi-3-Medium-4K-Instruct",
        "Phi-3-Mini-4K-Instruct",
        "Llama-3.1-8B-Instruct",
        "Llama-3-8B-Instruct",
        "ChatGLM3-6B",
        "DeepSeek-Math-7B-RL",
        "DeepSeek-Math-7B-Instruct",
        "DeepSeek-Math-7B-Base",
        "MetaMath-LLama2-70B",
        "GPT-4-Vision-Preview",
        "QWen2-VL-72B-Instruct",
        "QWen2-VL-7B-Instruct",
        "InternVL-1.5-Chat",
        "MiniCPM-Llama3-V-2.5",
        "LLaVA-1.6-Mistral-7B-Instruct",
        "Phi-3-Vision-128k-Instruct",
        "CogVLM2-Llama3-Chat-19B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Capabilities of Large Language Models in Control Engineering A Benchmark Study on GPT-4 Claude 3 Opus and Gemini 10 Ultra": {
    "filename": "Capabilities of Large Language Models in Control Engineering A Benchmark Study on GPT-4 Claude 3 Opus and Gemini 10 Ultra.pdf",
    "analysis": {
      "benchmarks": [
        "ControlBench",
        "ControlBench-C"
      ],
      "models": [
        "GPT-4",
        "Claude 3 Opus",
        "Gemini 1.0 Ultra"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PointCLIP V2 Prompting CLIP and GPT for Powerful 3D Open-world Learning": {
    "filename": "PointCLIP V2 Prompting CLIP and GPT for Powerful 3D Open-world Learning.pdf",
    "analysis": {
      "benchmarks": [
        "ModelNet40",
        "ModelNet10",
        "ScanObjectNN",
        "ShapeNetPart",
        "ScanNet V2"
      ],
      "models": [
        "PointCLIP V2",
        "PointCLIP",
        "CLIP2Point",
        "Cheraghian",
        "PointNet",
        "PointNet++",
        "SimpleView",
        "CurveNet",
        "3DETR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "In-context Autoencoder for Context Compression in a Large Language Model": {
    "filename": "In-context Autoencoder for Context Compression in a Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "PWC dataset",
        "Pile"
      ],
      "models": [
        "In-context Autoencoder (ICAE)",
        "Llama",
        "Llama-7b",
        "Llama-2-7b",
        "Llama-2-13b",
        "Alpaca",
        "StableLM-tuned-alpha-7b",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Natural Language Understanding and Inference with MLLM in Visual Question Answering A Survey": {
    "filename": "Natural Language Understanding and Inference with MLLM in Visual Question Answering A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "VQA v1",
        "VQA v2",
        "MS COCO",
        "CLEVER",
        "MovieQA",
        "Visual7W",
        "A-OKVQA",
        "GQA",
        "VizWiz",
        "KRVQA"
      ],
      "models": [
        "VGG-Net",
        "Faster-RCNN",
        "LSTM",
        "GRU",
        "Transformer",
        "BLIP",
        "Flamingo",
        "BLIP-2",
        "InternVL",
        "ViLBERT",
        "LXMERT",
        "Oscar",
        "ConceptBert",
        "MuKEA",
        "ViLT",
        "ALBEF",
        "Visual ChatGPT",
        "MM-REACT",
        "PICA",
        "Img2LLM",
        "Prophet",
        "PaLM-E",
        "LLaVA",
        "Shikra",
        "mPLUG-OWL",
        "InternVL-2",
        "LLaVA-1.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In": {
    "filename": "Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "PopQA"
      ],
      "models": [
        "Augmentation-Adapted Retriever (AAR)",
        "Flan-T5 Base",
        "Flan-T5 Large",
        "Flan-T5 XL",
        "InstructGPT",
        "Contriever",
        "ANCE",
        "Atlas",
        "OPT",
        "GPT-neo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Table-GPT Table-tuned GPT for Diverse Table Tasks": {
    "filename": "Table-GPT Table-tuned GPT for Diverse Table Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "Table-QA",
        "Column type annotation",
        "Entity matching",
        "Schema matching",
        "Data imputation",
        "Error detection",
        "Natural-language to SQL"
      ],
      "models": [
        "Table-GPT",
        "GPT-3.5",
        "ChatGPT",
        "Text-Davinci-002"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MME A Comprehensive Evaluation Benchmark for Multimodal Large Language Models": {
    "filename": "MME A Comprehensive Evaluation Benchmark for Multimodal Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MME",
        "COCO",
        "ScienceQA"
      ],
      "models": [
        "Flamingo",
        "PaLM-E",
        "GPT-4V",
        "MiniGPT-4",
        "BLIP-2",
        "InstructBLIP",
        "PandaGPT",
        "Multimodal-GPT",
        "VisualGLM-6B",
        "ImageBind-LLM",
        "VPGTrans",
        "LaVIN",
        "mPLUG-Owl",
        "Octopus",
        "Muffin",
        "Otter",
        "LRV-Instruction",
        "Cheetor",
        "LLaMA-Adapter-v2",
        "GIT2",
        "BLIVA",
        "Lynx",
        "MMICL",
        "Skywork-MM",
        "mPLUG-Owl2",
        "Qwen-VL-Chat",
        "XComposer-VL",
        "LLaVA",
        "Lion",
        "SPHINX",
        "InfMLLM",
        "WeMM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Susceptibility to Influence of Large Language Models": {
    "filename": "Susceptibility to Influence of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3",
        "text-davinci-003"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Autoregressive Search Engines Generating Substrings as Document Identifiers": {
    "filename": "Autoregressive Search Engines Generating Substrings as Document Identifiers.pdf",
    "analysis": {
      "benchmarks": [
        "KILT",
        "Natural Questions",
        "NQ320k"
      ],
      "models": [
        "SEAL",
        "BART",
        "DPR",
        "BM25",
        "GAR",
        "DSI-BART",
        "GENRE",
        "FiD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large-scale text analysis using generative language models A case study in discovering public value expressions in AI patents": {
    "filename": "Large-scale text analysis using generative language models A case study in discovering public value expressions in AI patents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "BERT-based classifiers",
        "BERT-base-uncased",
        "BERT-large-uncased",
        "DistilBERT",
        "RoBERTa-large",
        "ALBERT-xxl-v2",
        "DeBERTa-xxl-v2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Make a Donut Hierarchical EMD-Space Planning for Zero-Shot Deformable Manipulation with Tools": {
    "filename": "Make a Donut Hierarchical EMD-Space Planning for Zero-Shot Deformable Manipulation with Tools.pdf",
    "analysis": {
      "benchmarks": [
        "Donut",
        "Baguette",
        "TwoPancakes",
        "Spread",
        "Cut",
        "Arrange"
      ],
      "models": [
        "Diff. Physics",
        "PASTA",
        "BC",
        "SAC-N",
        "Ours"
      ]
    }
  },
  "Collaborative Human-AI Risk Annotation Co-Annotating Online Incivility with CHAIRA": {
    "filename": "Collaborative Human-AI Risk Annotation Co-Annotating Online Incivility with CHAIRA.pdf",
    "analysis": {
      "benchmarks": [
        "457 user comments dataset"
      ],
      "models": [
        "CHAIRA",
        "Two-stage Few-shot Chain of Thought",
        "GPT 3.5 Turbo"
      ]
    }
  },
  "Accelerating Clinical Evidence Synthesis with Large Language Models": {
    "filename": "Accelerating Clinical Evidence Synthesis with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "TrialReviewBench"
      ],
      "models": [
        "TrialMind",
        "GPT-4",
        "MPNet",
        "MedCPT",
        "Sonnet"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation": {
    "filename": "A Probabilistic Framework for LLM Hallucination Detection via Belief Tree Propagation.pdf",
    "analysis": {
      "benchmarks": [
        "Wikibio-GPT3",
        "FELM-Science",
        "FactCheckGPT"
      ],
      "models": [
        "BTPROP",
        "Prior Confidence",
        "Chain-of-thought",
        "SelfCheckGPT",
        "Maieutic-Prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatGPT as a Factual Inconsistency Evaluator for Text Summarization": {
    "filename": "ChatGPT as a Factual Inconsistency Evaluator for Text Summarization.pdf",
    "analysis": {
      "benchmarks": [
        "SUMMAC",
        "FactCC",
        "CoGenSumm",
        "XSumFaith",
        "SummEval",
        "FRANK",
        "Polytope",
        "GLUE"
      ],
      "models": [
        "ChatGPT",
        "FactCC",
        "FEQA",
        "QuestEval",
        "SummaC",
        "SummaC ZS",
        "SummaC Conv",
        "NER Overlap",
        "MNLI-doc",
        "DAE",
        "BARTScore",
        "T5Score",
        "GPT-3",
        "InstructGPT",
        "PaLM",
        "BLOOM",
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet": {
    "filename": "Why Solving Multi-agent Path Finding with Large Language Model has not Succeeded Yet.pdf",
    "analysis": {
      "benchmarks": [
        "empty map",
        "room map",
        "maze map",
        "EMPTY map",
        "ROOM -32-32-4 map",
        "MAZE -32-32-2 map"
      ],
      "models": [
        "GPT-4-1106-preview model",
        "GPT-4-turbo model",
        "one-shot (OS) generation",
        "step-by-step (SBS) generation",
        "GPT-4-8K model",
        "GPT-4-128K model",
        "multimodal-based method (MM)",
        "text-only method (TOO)",
        "text-only method (TOM)"
      ]
    }
  },
  "Analyzing the Generalization and Reliability of Steering Vectors": {
    "filename": "Analyzing the Generalization and Reliability of Steering Vectors.pdf",
    "analysis": {
      "benchmarks": [
        "Model-Written Evaluations (MWE)",
        "TruthfulQA",
        "sycophancy dataset"
      ],
      "models": [
        "Steering Vectors (SVs)",
        "Contrastive Activation Addition (CAA)",
        "Llama-2-7b-Chat",
        "Qwen-1.5-14b-Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models as Tool Makers": {
    "filename": "Large Language Models as Tool Makers.pdf",
    "analysis": {
      "benchmarks": [
        "Big-Bench",
        "Logical Deduction",
        "Tracking Shuffled Objects",
        "Dyck Language",
        "Word Sorting",
        "Chinese Remainder Theorem",
        "Scheduling Meeting"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5 Turbo",
        "LATM",
        "Chain-of-Thought",
        "text-davinci-002",
        "davinci",
        "curie",
        "babbage",
        "ada"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Characterizing Manipulation from AI Systems": {
    "filename": "Characterizing Manipulation from AI Systems.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "recommender systems",
        "language models"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On the Discussion of Large Language Models Symmetry of Agents and Interplay with Prompts": {
    "filename": "On the Discussion of Large Language Models Symmetry of Agents and Interplay with Prompts.pdf",
    "analysis": {
      "benchmarks": [
        "FOLIO",
        "FOLIO wiki curated"
      ],
      "models": [
        "ChatGPT",
        "GPT-3.5-Turbo-0613",
        "CMD",
        "MAD",
        "Debate (3 agents)",
        "Debate (6 agents)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Attention Prompting on Image for Large Vision-Language Models": {
    "filename": "Attention Prompting on Image for Large Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MM-Vet",
        "LLaVA-Wild",
        "LLaVA-Bench",
        "VisWiz",
        "TextVQA",
        "MMMU",
        "MME",
        "POPE"
      ],
      "models": [
        "Attention Prompting on Image (API)",
        "LLaVA-1.5",
        "CLIP",
        "LLaVA",
        "GPT-4V",
        "CogVLM",
        "Gemini",
        "FGVP (Mask)",
        "FGVP (RBM)",
        "SoM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing text-based knowledge graph completion with zero-shot large language models A focus on semantic enhancement": {
    "filename": "Enhancing text-based knowledge graph completion with zero-shot large language models A focus on semantic enhancement.pdf",
    "analysis": {
      "benchmarks": [
        "FB15k-237",
        "WN18RR",
        "UMLS",
        "FB15k-237N"
      ],
      "models": [
        "CP-KGC",
        "Qwen-7B-Chat-int4",
        "Qwen-7B-Chat",
        "LLaMA2-7B-Chat",
        "Qwen-turbo",
        "GPT-3.5-turbo",
        "GPT-4",
        "SimKGC",
        "KG-S2S",
        "KG-BERT",
        "StAR",
        "CSProm-KG",
        "TransE",
        "DistMult",
        "ConvE",
        "RotatE"
      ]
    }
  },
  "Follow the Rules Reasoning for Video Anomaly Detection with Large Language Models": {
    "filename": "Follow the Rules Reasoning for Video Anomaly Detection with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "UCSD Ped2",
        "CUHK Avenue",
        "ShanghaiTech",
        "UBnormal"
      ],
      "models": [
        "AnomalyRuler",
        "MNAD",
        "rGAN",
        "CDAE",
        "MPN",
        "NGOF",
        "HF2",
        "BAF",
        "GCL",
        "S3R",
        "SSL",
        "zxVAD",
        "HSC",
        "FPDM",
        "SLM",
        "STG-NF"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ROSCOE A Suite of Metrics for Scoring Step-by-Step Reasoning": {
    "filename": "ROSCOE A Suite of Metrics for Scoring Step-by-Step Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Entailment-Bank",
        "ProofWriter",
        "MATH",
        "ASDIV",
        "AQUA",
        "EQASC",
        "StrategyQA",
        "GSM8K",
        "DROP",
        "ESNLI",
        "COSMOS-QA",
        "SemEV AL"
      ],
      "models": [
        "ROSCOE",
        "GPT-3",
        "text-davinci-002",
        "175b_verification",
        "SimCSE",
        "sup-simcse-roberta-base",
        "all-mpnet-base-v2",
        "BARTScore",
        "BARTScore+CNN+Para",
        "BARTScore-P",
        "BERTScore",
        "BLEURT",
        "PRISM",
        "CTC",
        "CTC-Relevancy",
        "CTC-Consistency"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ToolChain Efficient Action Space Navigation in Large Language Models with A Search": {
    "filename": "ToolChain Efficient Action Space Navigation in Large Language Models with A Search.pdf",
    "analysis": {
      "benchmarks": [
        "ToolBench",
        "GSM8K",
        "ToolQA"
      ],
      "models": [
        "ToolChain*",
        "GPT-3.5-turbo",
        "GPT-4",
        "ReAct",
        "AdaPlanner",
        "ToT-DFS",
        "ToT-BFS",
        "MCTS",
        "Chain-of-Thought",
        "Self-Consistency"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Code Soliloquies for Accurate Calculations in Large Language Models": {
    "filename": "Code Soliloquies for Accurate Calculations in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "PHY300"
      ],
      "models": [
        "Higgs",
        "GPT-4",
        "LLaMA-2-70b-chat"
      ]
    }
  },
  "Case-Based Reasoning with Language Models for Classification of Logical Fallacies": {
    "filename": "Case-Based Reasoning with Language Models for Classification of Logical Fallacies.pdf",
    "analysis": {
      "benchmarks": [
        "LOGIC",
        "LOGIC Climate"
      ],
      "models": [
        "Case-Based Reasoning (CBR)",
        "ELECTRA",
        "RoBERTa",
        "BERT",
        "Codex"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Explainable artificial intelligence A survey of needs techniques applications and future direction": {
    "filename": "Explainable artificial intelligence A survey of needs techniques applications and future direction.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Token-Efficient Leverage Learning in Large Language Models": {
    "filename": "Token-Efficient Leverage Learning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HaluEval",
        "WMT-21",
        "AGIEval",
        "OpenBookQA"
      ],
      "models": [
        "Token-Efficient Leverage Learning (TELL)",
        "LLaMA2-7B-Chat",
        "QWen-7B-Chat",
        "Gemma-7b-it",
        "Instruction Supervised Fine-tuning (SFT)",
        "LoRA"
      ]
    }
  },
  "3D-GPT Procedural 3D Modeling with Large Language Models": {
    "filename": "3D-GPT Procedural 3D Modeling with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "3D-GPT",
        "DreamFields",
        "CLIP-Mesh",
        "Dreamfusion",
        "Magic3D",
        "Dream3D",
        "Latent-NeRF",
        "DreamBooth3D",
        "One-2-3-45"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Where does In-context Translation Happen in Large Language Models": {
    "filename": "Where does In-context Translation Happen in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "FLORES"
      ],
      "models": [
        "GPTN EO2.7B",
        "BLOOM 3B",
        "LLAMA 7B",
        "LLAMA 7B-CHAT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learnings from Data Integration for Augmented Language Models": {
    "filename": "Learnings from Data Integration for Augmented Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Toolformer"
      ]
    }
  },
  "Chain of Thought Imitation with Procedure Cloning": {
    "filename": "Chain of Thought Imitation with Procedure Cloning.pdf",
    "analysis": {
      "benchmarks": [
        "AntMaze",
        "MinAtar",
        "bimanual sweeping task"
      ],
      "models": [
        "procedure cloning",
        "behavioral cloning (BC)",
        "auxiliary BC",
        "Aug BC",
        "VIN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DataEnvGym Data Generation Agents in Teacher Environments with Student Feedback": {
    "filename": "DataEnvGym Data Generation Agents in Teacher Environments with Student Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "GQA",
        "MATH",
        "LiveCodeBench",
        "NaturalBench",
        "MnMs"
      ],
      "models": [
        "PaliGemma-3b-pt-224",
        "GPT-4o",
        "Gemma-2-2B-Instruct",
        "Llama-3-8B-Instruct",
        "GPT-4o-mini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Predicting the Quality of Revisions in Argumentative Writing": {
    "filename": "Predicting the Quality of Revisions in Argumentative Writing.pdf",
    "analysis": {
      "benchmarks": [
        "elementary essays",
        "college essays"
      ],
      "models": [
        "Chain-of-Thought prompts",
        "ChatGPT",
        "DistilRoBERTa",
        "Base-Short",
        "Base-Long",
        "AC-Claim",
        "AC-Reasoning",
        "AC-Evidence"
      ]
    }
  },
  "Conditional and Modal Reasoning in Large Language Models": {
    "filename": "Conditional and Modal Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "GSM8K"
      ],
      "models": [
        "Llama 3.1 Instruct 405B",
        "GPT-4 Turbo (2024-04-09)",
        "Claude 3.5 Sonnet",
        "GPT-4 Turbo (1106)",
        "GPT-4 (0613)",
        "Llama 3.1 Instruct 70B",
        "Gemini 1.5 Pro",
        "GPT-4 (0314)",
        "GPT-4o (2024-05-13)",
        "GPT-4o mini",
        "Claude 3 Opus",
        "Gemini 1.5 Flash",
        "Mistral Large 2",
        "Mixtral 8x7B",
        "Llama 3 Instruct 70B",
        "Claude 3 Sonnet",
        "Claude 3 Haiku",
        "Mixtral 8x22B",
        "Gemma 2 27B",
        "Llama 3 Instruct 8B",
        "Code Llama 34B",
        "GPT-3.5 Turbo (0125)",
        "Llama 2 Chat 7B",
        "GPT-3.5 Turbo (1106)",
        "Llama 3.1 Instruct 8B",
        "Code Llama 7B",
        "Llama 2 Chat 13B",
        "Mistral 7B",
        "Code Llama 13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data": {
    "filename": "Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data.pdf",
    "analysis": {
      "benchmarks": [
        "Dynamic-SUPERB",
        "AIR-Bench-Chat"
      ],
      "models": [
        "DeSTA2",
        "ASR + Llama3",
        "Specialized Models + Llama3",
        "LTU-AS",
        "Salmonn",
        "BLSP-emo",
        "WavLLM",
        "Qwen-Audio",
        "BLSP",
        "Qwen2-Audio",
        "Whisper-LLM",
        "DeSTA",
        "FT-only"
      ]
    }
  },
  "TinyLlama An Open-Source Small Language Model": {
    "filename": "TinyLlama An Open-Source Small Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "Hellaswag",
        "OpenBookQA",
        "WinoGrande",
        "ARC-Easy",
        "ARC-Challenge",
        "BoolQ",
        "PIQA",
        "MMLU",
        "BIG-Bench Hard",
        "DROP",
        "HumanEval",
        "xwinograd_zh",
        "xstorycloze_zh",
        "xnli_zh",
        "xcopa_zh"
      ],
      "models": [
        "TinyLlama",
        "TinyLlama v1.0",
        "TinyLlama v1.1",
        "TinyLlama v1.1 Math&Code",
        "TinyLlama v1.1 Chinese",
        "OPT-1.3B",
        "Pythia-1.0B",
        "Pythia-1.4B"
      ]
    }
  },
  "Data-Centric Human Preference Optimization with Rationales": {
    "filename": "Data-Centric Human Preference Optimization with Rationales.pdf",
    "analysis": {
      "benchmarks": [
        "Orca DPO Pairs",
        "UltraFeedback",
        "TriviaQA",
        "AlpacaEval 2.0"
      ],
      "models": [
        "DPO",
        "RDPO",
        "ORPO",
        "RORPO",
        "Mistral-7B-v0.1",
        "Mistral-7B-Instruct-v0.2",
        "Zephyr-7B-Beta",
        "Llama3-8B-Instruct",
        "GPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "H3Fusion Helpful Harmless Honest Fusion of Aligned LLMs": {
    "filename": "H3Fusion Helpful Harmless Honest Fusion of Aligned LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Alpaca-Eval",
        "BeaverTails",
        "TruthfulQA"
      ],
      "models": [
        "H3Fusion",
        "LLaMA-2 7B",
        "H3Fusion-Summary",
        "H3Fusion-Instruct",
        "H3Fusion-MoE",
        "GPT4o",
        "text-davinci-003",
        "beaver-dam-7b",
        "GPT-Judge"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Two Timin Repairing Smart Contracts With A Two-Layered Approach": {
    "filename": "Two Timin Repairing Smart Contracts With A Two-Layered Approach.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "RandomForestClassifier",
        "GPT-3.5-Turbo",
        "Llama-2-7B",
        "Slither",
        "DLV A",
        "MRN-GCN",
        "ContractFix",
        "Elysium"
      ]
    }
  },
  "Strong and weak alignment of large language models with human values": {
    "filename": "Strong and weak alignment of large language models with human values.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "Gemini",
        "Copilot"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Transformers Provably Solve Parity Efficiently with Chain of Thought": {
    "filename": "Transformers Provably Solve Parity Efficiently with Chain of Thought.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "one-layer transformer",
        "RNNs",
        "autoregressive transformers",
        "transformer with teacher forcing",
        "transformer without teacher forcing",
        "CoT transformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GeomVerse A Systematic Evaluation of Large Models for Geometric Reasoning": {
    "filename": "GeomVerse A Systematic Evaluation of Large Models for Geometric Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GeomVerse",
        "Geometry3k"
      ],
      "models": [
        "PaLI",
        "GPT4V",
        "PaLM 2 Large",
        "PaLI 55B",
        "PaLI 5B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How is ChatGPTs behavior changing over time": {
    "filename": "How is ChatGPTs behavior changing over time.pdf",
    "analysis": {
      "benchmarks": [
        "US Medical License tests",
        "LangChain HotpotQA",
        "OpinionQA",
        "Math I: Prime vs Composite",
        "Math II: Happy Numbers"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Navigating the Landscape of Large Language Models A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies": {
    "filename": "Navigating the Landscape of Large Language Models A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies.pdf",
    "analysis": {
      "benchmarks": [
        "six text classification datasets",
        "16 classification datasets"
      ],
      "models": [
        "BERT",
        "RoBERTa",
        "ALBERT",
        "GPT",
        "GPT-2",
        "GPT-3",
        "LLaMA",
        "OPT",
        "BioBERT",
        "ClinicalBERT",
        "TinyBERT",
        "ULMFiT",
        "MAML",
        "LoRA",
        "T5",
        "BART",
        "ChatGPT",
        "InstructGPT",
        "LLaMA2",
        "Codex",
        "WebGPT",
        "GLaM",
        "BLOOM",
        "GLM",
        "GPT-NeoX-20B",
        "mT5",
        "GShard",
        "FLAN",
        "Flan-PaLM",
        "Flan-T5",
        "Yuan",
        "LaMDA",
        "PaLM",
        "PaLM2",
        "Sparrow",
        "NLLB",
        "CPM-2",
        "Ernie 3.0",
        "Vicuna",
        "CodeGen2",
        "Falcon",
        "ViT",
        "BEiT",
        "DALLE2",
        "Imagen",
        "Midjourney",
        "StableDiffusion",
        "Kandinsky",
        "LCM-LoRA",
        "Cogview",
        "Cogview2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "When do you need Chain-of-Thought Prompting for ChatGPT": {
    "filename": "When do you need Chain-of-Thought Prompting for ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "MultiArith",
        "AddSub",
        "AQUA",
        "SVAMP",
        "GSM8K",
        "SingleOp",
        "CSQA",
        "StrategyQA",
        "Last Letter",
        "Coin-flip",
        "Date",
        "Object"
      ],
      "models": [
        "ChatGPT",
        "GPT-3",
        "Text-Davinci-002",
        "Text-Davinci-003"
      ]
    }
  },
  "GuReT Distinguishing Guilt and Regret related Text": {
    "filename": "GuReT Distinguishing Guilt and Regret related Text.pdf",
    "analysis": {
      "benchmarks": [
        "ReDDIT",
        "VIC"
      ],
      "models": [
        "Random Forest",
        "AdaBoost",
        "XGBoost",
        "BERT",
        "RoBERTa",
        "AlBERT",
        "XLNet",
        "DistilBERT",
        "ELECTRA",
        "GPT-3.5-Turbo"
      ]
    }
  },
  "Mastering the ABCDs of Complex Questions Answer-Based Claim Decomposition for Fine-grained Self-Evaluation": {
    "filename": "Mastering the ABCDs of Complex Questions Answer-Based Claim Decomposition for Fine-grained Self-Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "TRIVIA QA",
        "HOTPOT QA",
        "OBSCURE QA"
      ],
      "models": [
        "GPT-3.5",
        "ABCD"
      ]
    }
  },
  "CHASE-SQL Multi-Path Reasoning and Preference Optimized Candidate Selection in Text-to-SQL": {
    "filename": "CHASE-SQL Multi-Path Reasoning and Preference Optimized Candidate Selection in Text-to-SQL.pdf",
    "analysis": {
      "benchmarks": [
        "BIRD",
        "Spider"
      ],
      "models": [
        "CHASE-SQL",
        "Gemini 1.5 Pro",
        "Claude-3.5-sonnet",
        "Distillery + GPT-4o",
        "CHESS",
        "MCS-SQL + GPT-4",
        "SuperSQL",
        "Insights AI",
        "AskData + GPT-4o",
        "OpenSearch-v2 + GPT-4o",
        "PURPLE-RED + GPT-4o",
        "Arcwise + GPT-4o",
        "ExSL + granite-34b-code",
        "DAIL-SQL + GPT-4",
        "DIN-SQL + GPT-4",
        "C3 + ChatGPT",
        "RESDSQL 3B",
        "DIN-SQL + CodeX",
        "T5-3B+NatSQL",
        "Graphix-3B+PICARD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Are Human Rules Necessary Generating Reusable APIs with CoT Reasoning and In-Context Learning": {
    "filename": "Are Human Rules Necessary Generating Reusable APIs with CoT Reasoning and In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Terragni et al. evaluation set"
      ],
      "models": [
        "APIzator",
        "Code2API"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Spatio-Temporal Side Tuning Pre-trained Foundation Models for Video-based Pedestrian Attribute Recognition": {
    "filename": "Spatio-Temporal Side Tuning Pre-trained Foundation Models for Video-based Pedestrian Attribute Recognition.pdf",
    "analysis": {
      "benchmarks": [
        "MARS-Attribute",
        "DukeMTMC-VID-Attribute"
      ],
      "models": [
        "CLIP-guided Visual-Text Fusion Transformer",
        "VTFPAR++",
        "3DCNN",
        "CNN-RNN",
        "ALM",
        "SSC soft",
        "TA(Image)",
        "TA(Video)",
        "Lee et al.",
        "TRA",
        "VTB",
        "VTF"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning": {
    "filename": "Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "MathQA"
      ],
      "models": [
        "LaMDA",
        "PaLM",
        "GPT-3 CoT",
        "Codex CoT",
        "Complex CoT",
        "PAL",
        "Our Dynamic Program Prompting",
        "GPT-3",
        "CoT Fine-tune",
        "CoT Fine-tune (CodeGen)",
        "Our Program Distillation"
      ]
    }
  },
  "Advancements in Scientific Controllable Text Generation Methods": {
    "filename": "Advancements in Scientific Controllable Text Generation Methods.pdf",
    "analysis": {
      "benchmarks": [
        "Sci-Cite",
        "SciCCG",
        "Wiki-QA"
      ],
      "models": [
        "ReWoS",
        "GCSumm",
        "SCSumm",
        "GPT2",
        "SCI BERT",
        "BIOBERT",
        "Transformer",
        "OpenNMT-py",
        "Pointer-Generator Network",
        "Galactica",
        "XLNet",
        "GPT",
        "GPT-2",
        "GPT-3",
        "BART",
        "T5",
        "Plug and Play Language Model",
        "PaLM",
        "LLAMA",
        "Alpaca"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RAGent Retrieval-based Access Control Policy Generation": {
    "filename": "RAGent Retrieval-based Access Control Policy Generation.pdf",
    "analysis": {
      "benchmarks": [
        "iTrust",
        "IBM course registration",
        "CyberChair conference management",
        "CACP",
        "CC"
      ],
      "models": [
        "RAGent",
        "Text2Policy",
        "ACRE",
        "Narouei et al.",
        "Xia et al.",
        "BERT",
        "LLaMa 3 8B",
        "BART"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CRITIC Large Language Models Can Self-Correct with Tool-Interactive Critiquing": {
    "filename": "CRITIC Large Language Models Can Self-Correct with Tool-Interactive Critiquing.pdf",
    "analysis": {
      "benchmarks": [
        "AmbigNQ",
        "TriviaQA",
        "HotpotQA",
        "GSM8k",
        "SVAMP",
        "TabMWP",
        "REALTOXICITY PROMPTS"
      ],
      "models": [
        "CRITIC",
        "ChatGPT",
        "Text-Davinci-003",
        "LLaMA-2-7B",
        "LLaMA-2-13B",
        "LLaMA-2-70B",
        "Vanilla",
        "CoT",
        "Self-Consistency",
        "ReAct",
        "ReAct \u2192 CRITIC",
        "CRITIC w/o Tool",
        "CRITIC*",
        "Rejection Sampling",
        "PoT",
        "PAL",
        "Self-Refine",
        "PPLM",
        "GeDi",
        "DEXPERT",
        "DAPT",
        "PPO",
        "Quark",
        "Self-Correct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Diversity-Rewarded CFG Distillation": {
    "filename": "Diversity-Rewarded CFG Distillation.pdf",
    "analysis": {
      "benchmarks": [
        "MusicCaps"
      ],
      "models": [
        "MusicLM",
        "CFG-augmented base model",
        "CFG-distilled model",
        "LERP(0, 15) merged model",
        "MusicRL-R checkpoint"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tokenization counts the impact of tokenization on arithmetic in frontier LLMs": {
    "filename": "Tokenization counts the impact of tokenization on arithmetic in frontier LLMs.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "LLaMa",
        "PaLM",
        "Claude v2.1",
        "Gopher",
        "Chinchilla",
        "GPT-J",
        "Mistral",
        "OLMo",
        "gpt-3.5-turbo-0301",
        "gpt-3.5-turbo-0613",
        "gpt-4-0314",
        "gpt-4-0613",
        "gpt-4-1106-preview"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LMC Large Model Collaboration with Cross-assessment for Training-Free Open-Set Object Recognition": {
    "filename": "LMC Large Model Collaboration with Cross-assessment for Training-Free Open-Set Object Recognition.pdf",
    "analysis": {
      "benchmarks": [
        "CIFAR10",
        "CIFAR+10",
        "CIFAR+50",
        "TinyImageNet"
      ],
      "models": [
        "LMC",
        "OSRCI",
        "C2AE",
        "RPL",
        "OpenHybrid",
        "CV AECapOSR",
        "ARPL",
        "ARPL+CS",
        "PMAL",
        "ZOC",
        "MLS",
        "DIAS",
        "Class-inclusion",
        "ODL",
        "ODL+",
        "CSSR",
        "RCSSR",
        "Softmax",
        "GCPL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatVis Automating Scientific Visualization with a Large Language Model": {
    "filename": "ChatVis Automating Scientific Visualization with a Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "Marschner-Lobb benchmark dataset"
      ],
      "models": [
        "ChatVis",
        "GPT-4",
        "GPT-3.5-turbo",
        "LLaMA-3.8B",
        "Code LLaMA",
        "Codegemma"
      ]
    }
  },
  "Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning": {
    "filename": "Diffusion Language Models Can Perform Many Tasks with Scaling and Instruction-Finetuning.pdf",
    "analysis": {
      "benchmarks": [
        "IWSLT14 DE\u2192EN",
        "WMT14 EN\u2192DE",
        "Gigaword-10K",
        "MMLU",
        "BBH-NLP",
        "TyDiQA",
        "GSM8K",
        "MGSM"
      ],
      "models": [
        "Diffusion Language Models",
        "Autoregressive Language Models",
        "Transformer-BASE-IWSLT",
        "Transformer-BASE",
        "XLM-R-BASE",
        "XLM-R-XXL",
        "Flan-XLM-R",
        "Flan-T5",
        "Flan-PaLM",
        "LLaMA-13B",
        "DiffusionBERT",
        "Reparameterized Discrete Diffusion Models (RDM)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Large Language Models for Solving Rare MIP Challenges": {
    "filename": "Leveraging Large Language Models for Solving Rare MIP Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "DiDi operational dataset"
      ],
      "models": [
        "LLaMA 3.1 (8B)",
        "Gurobi",
        "CPLEX",
        "COPT"
      ]
    }
  },
  "FormulaReasoning A Dataset for Formula-Based Numerical Reasoning": {
    "filename": "FormulaReasoning A Dataset for Formula-Based Numerical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "FormulaReasoning",
        "GSM8K",
        "Math23K-F",
        "MAWPS-F",
        "MATH"
      ],
      "models": [
        "LLMs (7B to >100B parameters)",
        "Qwen-1.8B",
        "ChatGLM3-6B",
        "GPT-4o",
        "GPT-4-turbo",
        "GPT-3.5-turbo",
        "GLM-4-plus",
        "GLM-4-flash",
        "Qwen-max",
        "Qwen2.5-14B",
        "Qwen2.5-7B",
        "Llama3.1-8B",
        "Chain-of-Thought supervised fine-tuned method",
        "retrieval-augmented generative models",
        "formula retriever"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Demystifying Faulty Code with LLM Step-by-Step Reasoning for Explainable Fault Localization": {
    "filename": "Demystifying Faulty Code with LLM Step-by-Step Reasoning for Explainable Fault Localization.pdf",
    "analysis": {
      "benchmarks": [
        "Refactory dataset",
        "Defects4J"
      ],
      "models": [
        "FuseFL",
        "Tarantula",
        "Ochiai",
        "OP2",
        "Barinel",
        "DStar",
        "XAI4FL",
        "LLM-based approach by Wu et al."
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Operationalizing the Blueprint for an AI Bill of Rights Recommendations for Practitioners Researchers and Policy Makers": {
    "filename": "Operationalizing the Blueprint for an AI Bill of Rights Recommendations for Practitioners Researchers and Policy Makers.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RSPrompter Learning to Prompt for Remote Sensing Instance Segmentation Based on Visual Foundation Model": {
    "filename": "RSPrompter Learning to Prompt for Remote Sensing Instance Segmentation Based on Visual Foundation Model.pdf",
    "analysis": {
      "benchmarks": [
        "WHU building",
        "NWPU VHR-10",
        "SSDD"
      ],
      "models": [
        "RSPrompter",
        "Segment Anything Model (SAM)",
        "Mask R-CNN",
        "Cascade Mask R-CNN",
        "Mask Scoring R-CNN",
        "HTC",
        "HQ-ISNet",
        "YOLACT",
        "BlendMask",
        "EmbedMask",
        "Condinst",
        "SOLO",
        "Mask2Former",
        "RSPrompter-anchor",
        "RSPrompter-query",
        "SAM-seg (Mask R-CNN)",
        "SAM-seg (Mask2Former)",
        "SAM-cls",
        "SAM-det",
        "MS R-CNN",
        "SCNet",
        "CATNet",
        "SOLOv2",
        "BoxInst"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Constrained-Based Causal Discovery": {
    "filename": "Large Language Models for Constrained-Based Causal Discovery.pdf",
    "analysis": {
      "benchmarks": [
        "BNLearn repository",
        "spurious correlation website",
        "protein-signaling networks",
        "climatic teleconnections",
        "cancer",
        "burglary",
        "asia",
        "sachs",
        "spurious",
        "bk-spv",
        "nao-dk-med"
      ],
      "models": [
        "PC algorithm",
        "GES",
        "LPCMCI",
        "FCI",
        "SVAR-FCI",
        "GPS",
        "chatPC",
        "GPT-3.5-turbo",
        "GPT-4"
      ]
    }
  },
  "LLM-Coordination Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models": {
    "filename": "LLM-Coordination Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "LLM-Coordination Benchmark",
        "Hanabi Challenge",
        "Overcooked-AI",
        "Collab Capture",
        "Collab Escape",
        "CoordinationQA Suite"
      ],
      "models": [
        "Cognitive Architecture for Coordination (CAC)",
        "GPT-4-turbo",
        "GPT-3.5-turbo",
        "Mixtral8x7B",
        "Proximal Policy Optimization (PPO)",
        "Population-Based Training (PBT)",
        "Bayesian Action Decoder (BAD)",
        "Simplified Action Decoder (SAD)",
        "Off-Belief Learning (OBL)",
        "Behavior Cloning",
        "Self-verification LLM",
        "Theory of Mind Reasoning LLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models From Notes to Musical Form": {
    "filename": "Large Language Models From Notes to Musical Form.pdf",
    "analysis": {
      "benchmarks": [
        "Pond5"
      ],
      "models": [
        "MusicGen",
        "Vanilla MusicGen",
        "Jukebox",
        "Music Transformer",
        "EnCodec",
        "GPT-4",
        "ChatGPT 4",
        "T5",
        "Hierarchical VQ-VAEs",
        "WaveNet",
        "AutoEncoders",
        "LoRA"
      ]
    }
  },
  "SleepCoT A Lightweight Personalized Sleep Health Model via Chain-of-Thought Distillation": {
    "filename": "SleepCoT A Lightweight Personalized Sleep Health Model via Chain-of-Thought Distillation.pdf",
    "analysis": {
      "benchmarks": [
        "SleepQA"
      ],
      "models": [
        "SleepCoT",
        "Qwen-max",
        "Qwen2.5-1.5B",
        "Qwen2.5-0.5B",
        "GPT-4o",
        "Claude-Sonnet 3.5",
        "Baichuan4",
        "GLM-4",
        "Gemini 1.5 Pro",
        "Qwen2.5-7B"
      ]
    }
  },
  "Metacognitive Prompting Improves Understanding in Large Language Models": {
    "filename": "Metacognitive Prompting Improves Understanding in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "SuperGLUE",
        "BLUE",
        "LexGLUE"
      ],
      "models": [
        "Llama2",
        "PaLM2",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Generate rather than Retrieve Large Language Models are Strong Context Generators": {
    "filename": "Generate rather than Retrieve Large Language Models are Strong Context Generators.pdf",
    "analysis": {
      "benchmarks": [
        "TriviaQA",
        "WebQ",
        "NQ",
        "FEVER",
        "FM2",
        "WoW"
      ],
      "models": [
        "GENREAD",
        "DPR-FiD",
        "InstructGPT",
        "DPR",
        "BM25",
        "Contriever",
        "Google + InstructGPT",
        "FiD",
        "RAG",
        "FiD-l",
        "FiD-xl"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Surprising Effectiveness of Test-Time Training for Abstract Reasoning": {
    "filename": "The Surprising Effectiveness of Test-Time Training for Abstract Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Abstraction and Reasoning Corpus (ARC)"
      ],
      "models": [
        "8B-parameter language model",
        "1B model",
        "3B model",
        "Llama-3 models",
        "Llama-3.2 models",
        "BARC",
        "Claude - Few-shot prompting",
        "GPT-4.0 - Few-shot prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Military to Healthcare Adopting and Expanding Ethical Principles for Generative Artificial Intelligence": {
    "filename": "From Military to Healthcare Adopting and Expanding Ethical Principles for Generative Artificial Intelligence.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-3.5",
        "GPT-4",
        "GPT",
        "GPT-2",
        "GPT-3",
        "Stable Diffusion",
        "DALL-E 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Perturbed examples reveal invariances shared by language models": {
    "filename": "Perturbed examples reveal invariances shared by language models.pdf",
    "analysis": {
      "benchmarks": [
        "Stanford Sentiment Treebank (SST2)",
        "AG's News"
      ],
      "models": [
        "BERT",
        "DistilBERT",
        "BERT-Tiny",
        "BERT-Mini",
        "BERT-Small",
        "BERT-Medium",
        "BERT-Base",
        "GPT-2",
        "InstructGPT (text-ada-001)",
        "InstructGPT (text-babbage-001)",
        "InstructGPT (text-curie-001)",
        "InstructGPT (text-davinci-001)",
        "InstructGPT (text-davinci-002)",
        "InstructGPT (text-davinci-003)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Synthetic continued pretraining": {
    "filename": "Synthetic continued pretraining.pdf",
    "analysis": {
      "benchmarks": [
        "QuALITY"
      ],
      "models": [
        "EntiGraph",
        "Llama 3 8B",
        "gpt-4-turbo",
        "Raw CPT",
        "Rephrase CPT",
        "EntiGraph CPT",
        "EntiGraph Instruct",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Task Arithmetic for Language Expansion in Speech Translation": {
    "filename": "Task Arithmetic for Language Expansion in Speech Translation.pdf",
    "analysis": {
      "benchmarks": [
        "MuST-C",
        "CoVoST-2"
      ],
      "models": [
        "SpeechGPT-7B-cm",
        "Task vector addition",
        "Task vector addition with Language Control",
        "TIES-Merging",
        "Joint fine-tuning",
        "Monolingual fine-tuning",
        "Synthesized ST model"
      ]
    }
  },
  "Sparse MoE as the New Dropout Scaling Dense and Self-Slimmable Transformers": {
    "filename": "Sparse MoE as the New Dropout Scaling Dense and Self-Slimmable Transformers.pdf",
    "analysis": {
      "benchmarks": [
        "enwik8",
        "BookCorpus",
        "SST-2",
        "CSQA",
        "ASDiv-A",
        "MAWPS",
        "SVAMP"
      ],
      "models": [
        "SMoE-Dropout",
        "BERT",
        "Transformer-XL",
        "RoBERTa",
        "Dense w. Dropout",
        "Dense w. Concrete Dropout",
        "Dense w. DropBlock",
        "THOR",
        "Learnable SMoE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NPHardEval Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes": {
    "filename": "NPHardEval Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes.pdf",
    "analysis": {
      "benchmarks": [
        "NPHardEval"
      ],
      "models": [
        "GPT 4 Turbo",
        "Claude 2",
        "GPT 3.5 Turbo",
        "Claude Instant",
        "PaLM 2",
        "Yi-34b",
        "Qwen-14b",
        "Mistral-7b",
        "Phi-2",
        "MPT-30b",
        "Vicuna-13b",
        "Phi-1.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HippoRAG Neurobiologically Inspired Long-Term Memory for Large Language Models": {
    "filename": "HippoRAG Neurobiologically Inspired Long-Term Memory for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MuSiQue",
        "2WikiMultiHopQA",
        "HotpotQA"
      ],
      "models": [
        "HippoRAG",
        "IRCoT",
        "BM25",
        "Contriever",
        "GTR",
        "ColBERTv2",
        "RAPTOR",
        "Propositionizer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An overview of domain-specific foundation model key technologies applications and challenges": {
    "filename": "An overview of domain-specific foundation model key technologies applications and challenges.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "VGG",
        "ResNet",
        "GPT-1",
        "GPT-2",
        "GPT-3",
        "GPT-3.5 turbo",
        "BERT",
        "GLM",
        "LLaMA",
        "LLaMA-2",
        "iGPT",
        "LVM",
        "SAM",
        "BART",
        "T5",
        "Time-LLM",
        "UniTS",
        "ST-LLM",
        "CoDi",
        "CoDi-2",
        "Claude-3",
        "GPT-4",
        "LLaVA",
        "BriVL",
        "ImageBind",
        "NExT-GPT",
        "VL-BERT",
        "DiT",
        "Longformer",
        "BigBird",
        "XLNet",
        "Transformer-XL",
        "LongRoPE",
        "VQGAN",
        "PET",
        "Prefix Tuning",
        "P-tuning",
        "RAG",
        "GraphRAG",
        "RankRAG",
        "Adapter",
        "AdapterFusion",
        "IA3",
        "Model Reprogramming",
        "LoRA",
        "LoHa",
        "LoKr",
        "PEFT",
        "AdaLoRA",
        "LISA",
        "MoE",
        "VAR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning Performance-Improving Code Edits": {
    "filename": "Learning Performance-Improving Code Edits.pdf",
    "analysis": {
      "benchmarks": [
        "PIE",
        "CodeNet"
      ],
      "models": [
        "CODELLAMA 7B",
        "CODELLAMA 13B",
        "CODELLAMA 34B",
        "GPT-3.5",
        "GPT-4",
        "GPT-3.5 augmented with synthetic data",
        "CODELLAMA 13B with performance-conditioned generation"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding In-Context Learning from Repetitions": {
    "filename": "Understanding In-Context Learning from Repetitions.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "GSM8K",
        "Wikitext-103",
        "BookCorpus"
      ],
      "models": [
        "LLaMA",
        "OPT",
        "LLaMA-7B",
        "LLaMA-13B",
        "LLaMA-30B",
        "LLaMA-65B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A social path to human-like artificial intelligence": {
    "filename": "A social path to human-like artificial intelligence.pdf",
    "analysis": {
      "benchmarks": [
        "StarCraft II",
        "Diplomacy"
      ],
      "models": [
        "AlphaStar",
        "GPT-3",
        "PaLM",
        "Malthusian reinforcement learning",
        "multi-agent reinforcement learning",
        "hierarchical reinforcement learning",
        "generative adversarial imitation learning",
        "imitation learning",
        "behavioral cloning from observation",
        "intrinsic motivation models",
        "autotelic agents with intrinsically motivated goal-conditioned reinforcement learning"
      ]
    }
  },
  "AI-Assisted Causal Pathway Diagram for Human-Centered Design": {
    "filename": "AI-Assisted Causal Pathway Diagram for Human-Centered Design.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Jailbreaking Text-to-Image Models with LLM-Based Agents": {
    "filename": "Jailbreaking Text-to-Image Models with LLM-Based Agents.pdf",
    "analysis": {
      "benchmarks": [
        "NSFW-200",
        "Dog/Cat-100"
      ],
      "models": [
        "Atlas",
        "LLaV A",
        "ShareGPT4V",
        "Vicuna",
        "SneakyPrompt",
        "DACA",
        "Ring-A-Bell",
        "Stable Diffusion v1.4",
        "Stable Diffusion XL Refiner",
        "Stable Diffusion 3 Medium",
        "DALL\u00b7E 3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving Large Language Model Fine-tuning for Solving Math Problems": {
    "filename": "Improving Large Language Model Fine-tuning for Solving Math Problems.pdf",
    "analysis": {
      "benchmarks": [
        "MATH"
      ],
      "models": [
        "PaLM 2-S*",
        "PaLM 2-L",
        "GPT-4",
        "Supervised step-by-step solution fine-tuning (SSFT)",
        "Solution-cluster Re-ranking (SCR)",
        "Multi-task Sequential Fine-tuning"
      ]
    }
  },
  "Dont Trust Verify - Grounding LLM Quantitative Reasoning with Autoformalization": {
    "filename": "Dont Trust Verify - Grounding LLM Quantitative Reasoning with Autoformalization.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "MultiArith"
      ],
      "models": [
        "Minerva",
        "GPT3.5",
        "GPT4",
        "PaLM",
        "DTV (Don't Trust: Verify)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PD-Serve Serving Disaggregated Large Language Model at Scale": {
    "filename": "PD-Serve Serving Disaggregated Large Language Model at Scale.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "P/D-Serve",
        "vLLM",
        "Bert",
        "Llama",
        "GPT-3",
        "Pangu"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RTLRewriter Methodologies for Large Models aided RTL Code Optimization": {
    "filename": "RTLRewriter Methodologies for Large Models aided RTL Code Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "Large Rewriter Benchmark",
        "Small Rewriter Benchmark"
      ],
      "models": [
        "RTLRewriter",
        "Yosys",
        "E-graph",
        "GPT4",
        "Claude3-Opus",
        "VeriGen",
        "RTLCoder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Similarity-based Neighbor Selection for Graph LLMs": {
    "filename": "Similarity-based Neighbor Selection for Graph LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Cora",
        "PubMed",
        "CiteSeer",
        "Ogbn-arxiv",
        "Ogbn-products"
      ],
      "models": [
        "Similarity-based Neighbor Selection (SNS)",
        "GCN",
        "GAT",
        "GraphSAGE",
        "GPT-3.5",
        "GPT-4",
        "1-hop attention",
        "\u03b3-hop random neighbor selection"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "V Guided Visual Search as a Core Mechanism in Multimodal LLMs": {
    "filename": "V Guided Visual Search as a Core Mechanism in Multimodal LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "V*Bench",
        "COCO2017",
        "GQA",
        "VAW",
        "SA-1B",
        "COCO-Search18",
        "MME",
        "POPE",
        "MMBench",
        "SEED-Bench",
        "MM-Vet",
        "LLaVA-BenchW"
      ],
      "models": [
        "V*",
        "SEAL",
        "LLaVA",
        "GPT-4V",
        "Gemini Pro",
        "Bard",
        "BLIP2",
        "MiniGPT-4",
        "InstructBLIP",
        "Otter",
        "LLaVA-1.5",
        "MM-React",
        "VisualChatGPT",
        "Visprog",
        "GroundingDINO",
        "OWL-ViT",
        "Vicuna-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Know Your Needs Better Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs": {
    "filename": "Know Your Needs Better Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ARALLM",
        "GPT-3.5",
        "ChatGLM2-6B-32K",
        "Baichuan2-13B-Chat",
        "BGE-large-zh"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Semantic Mechanical Search with Large Vision and Language Models": {
    "filename": "Semantic Mechanical Search with Large Vision and Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "pharmacy domain",
        "kitchen domain",
        "office domain",
        "real-life scenes dataset"
      ],
      "models": [
        "Semantic Mechanical Search (SMS)",
        "CLIP",
        "SMS-LLM",
        "SMS-E",
        "LAX-RAY",
        "OWL-ViT",
        "ViLD",
        "BLIP-2",
        "Segment-Anything (SAM)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Code Prompting a Neural Symbolic Method for Complex Reasoning in Large Language Models": {
    "filename": "Code Prompting a Neural Symbolic Method for Complex Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "last letter concatenation",
        "coin flip",
        "SingleEq",
        "AddSub",
        "MultiArith",
        "SVAMP",
        "GSM8K"
      ],
      "models": [
        "zero-shot standard prompting",
        "zero-shot chain-of-thought prompting",
        "few-shot chain-of-thought prompting",
        "zero-shot code prompting + LLM self-contained",
        "zero-shot code prompting + Python interpreter",
        "Program-aided Language Models (PAL)",
        "few-shot code prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving Language Model Prompting in Support of Semi-autonomous Task Learning": {
    "filename": "Improving Language Model Prompting in Support of Semi-autonomous Task Learning.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3",
        "text-davinci-001",
        "text-davinci-002"
      ]
    }
  },
  "Do Language Models Enjoy Their Own Stories Prompting Large Language Models for Automatic Story Evaluation": {
    "filename": "Do Language Models Enjoy Their Own Stories Prompting Large Language Models for Automatic Story Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "HANNA",
        "WritingPrompts",
        "BooksMIA"
      ],
      "models": [
        "GPT-3",
        "LaMDA",
        "PaLM",
        "LLaMA",
        "Llama-2-7b-chat-hf",
        "Platypus2-70B-instruct",
        "Llama-30b-instruct-2048",
        "StableBeluga-13B",
        "Mistral-7B-OpenOrca",
        "Llama-7B",
        "GPT-2",
        "HINT",
        "BERTGeneration",
        "CTRL",
        "GPT",
        "RoBERTa",
        "XLNet",
        "Fusion",
        "TD-VAE",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Message Brokers for Generative AI Survey Challenges and Opportunities": {
    "filename": "Towards Message Brokers for Generative AI Survey Challenges and Opportunities.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Evaluation of Estimative Uncertainty in Large Language Models": {
    "filename": "An Evaluation of Estimative Uncertainty in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "ERNIE-4",
        "Llama-2-7B",
        "Llama-2-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reasoning in Token Economies Budget-Aware Evaluation of LLM Reasoning Strategies": {
    "filename": "Reasoning in Token Economies Budget-Aware Evaluation of LLM Reasoning Strategies.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "TheoremQA",
        "CSQA",
        "HotpotQA",
        "Game of 24"
      ],
      "models": [
        "Chain-of-Thought Self-Consistency (CoT SC)",
        "Multi-Agent Debate (MAD)",
        "Reflexion",
        "Plan and Solve",
        "Least to Most Prompting",
        "Progressive Hint Prompting",
        "Tree-of-Thoughts (ToT)",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Understanding the Working Mechanism of Text-to-Image Diffusion Model": {
    "filename": "Towards Understanding the Working Mechanism of Text-to-Image Diffusion Model.pdf",
    "analysis": {
      "benchmarks": [
        "MS-COCO"
      ],
      "models": [
        "Stable Diffusion v1.5-Base",
        "Stable Diffusion v2.1-Base",
        "Pixart-Alpha",
        "DPM-Solver",
        "DDIM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "KnowPhish Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection": {
    "filename": "KnowPhish Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection.pdf",
    "analysis": {
      "benchmarks": [
        "TR-OP",
        "SG-SCAN"
      ],
      "models": [
        "KnowPhish Detector (KPD)",
        "Phishpedia",
        "PhishIntention",
        "DynaPhish"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models": {
    "filename": "Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "AddSub",
        "MultiArith",
        "SingleEq",
        "AQUA-RAT",
        "SVAMP",
        "GSM8K",
        "CommonsenseQA",
        "StrategyQA",
        "Last Letter Concatenation",
        "Coin Flip"
      ],
      "models": [
        "Prompt Space",
        "Few-shot",
        "Manual-CoT",
        "Zero-shot",
        "Zero-shot-CoT",
        "Auto-CoT",
        "Prompt-Space-CoT-Zero",
        "Prompt-Space-CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Multilingual Alignment Prism Aligning Global and Local Preferences to Reduce Harm": {
    "filename": "The Multilingual Alignment Prism Aligning Global and Local Preferences to Reduce Harm.pdf",
    "analysis": {
      "benchmarks": [
        "Multilingual Dolly-200",
        "FLORES-200",
        "Aya Red-teaming",
        "XSafety"
      ],
      "models": [
        "Base model",
        "SFT-Preferred",
        "SFT-Random",
        "DPO(IFT)",
        "DPO(SFT)",
        "Command R+",
        "Aya 23 8B",
        "Aya-101",
        "Gemma",
        "Mistral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Synergy-of-Thoughts Eliciting Efficient Reasoning in Hybrid Language Models": {
    "filename": "Synergy-of-Thoughts Eliciting Efficient Reasoning in Hybrid Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Game of 24",
        "Logic Grid Puzzle",
        "GSM8K",
        "Trivia Creative Writing",
        "Open-ended QA",
        "Constrained Generation"
      ],
      "models": [
        "Synergy of Thoughts (SoT)",
        "Chain-of-thought (CoT)",
        "Self-refine",
        "Tree-of-thoughts (ToT)",
        "LLM-cascade",
        "SPP",
        "MAD+judge",
        "SoTO",
        "SoTC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs": {
    "filename": "Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "ADOS-2"
      ],
      "models": [
        "ADOS-Copilot",
        "GPT-4-turbo",
        "Gemini1.5-Pro",
        "Claude3",
        "Llama3-8b",
        "Mixtral",
        "Qwen1.5",
        "Glm",
        "Yi-34b",
        "Kimi",
        "Qwen1.5-32b",
        "Qwen1.5-72b",
        "Qwen1.5-14b",
        "glm4",
        "glm-3-turbo",
        "mistral-7b",
        "llama-3-8b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ClassActionPrediction A Challenging Benchmark for Legal Judgment Prediction of Class Action Cases in the US": {
    "filename": "ClassActionPrediction A Challenging Benchmark for Legal Judgment Prediction of Class Action Cases in the US.pdf",
    "analysis": {
      "benchmarks": [
        "USClassActions",
        "USClassActionOutcomes_ExpertsAnnotations"
      ],
      "models": [
        "Longformer",
        "BigBird",
        "BERT",
        "LegalBERT",
        "CaseLawBERT",
        "LegalRoBERTa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An In-Context Learning Agent for Formal Theorem-Proving": {
    "filename": "An In-Context Learning Agent for Formal Theorem-Proving.pdf",
    "analysis": {
      "benchmarks": [
        "miniF2F",
        "CompCert"
      ],
      "models": [
        "COPRA",
        "GPT-4",
        "REPROVER",
        "PROVERBOT 9001",
        "LLEMMA-7b",
        "LLEMMA-34b",
        "CodeLlama",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SheetCopilot Bringing Software Productivity to the Next Level through Large Language Models": {
    "filename": "SheetCopilot Bringing Software Productivity to the Next Level through Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "superuser.com dataset",
        "221 spreadsheet tasks dataset"
      ],
      "models": [
        "SheetCopilot",
        "GPT-3.5-Turbo",
        "GPT-4",
        "Claude",
        "VBA-based method"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Defining a New NLP Playground": {
    "filename": "Defining a New NLP Playground.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "SuperGLUE",
        "MMLU",
        "Super-NaturalInstructions",
        "HELM",
        "AGIEval"
      ],
      "models": [
        "LLMs",
        "GPT variants"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Search Model Redefining Search Stack in the Era of LLMs": {
    "filename": "Large Search Model Redefining Search Stack in the Era of LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "MS MARCO",
        "TREC DL 19",
        "TREC DL 20"
      ],
      "models": [
        "Large Search Model",
        "LLaMA",
        "GPT-4",
        "BERT",
        "T5",
        "BM25",
        "ANCE",
        "E5 large-v2",
        "gpt-35-turbo"
      ]
    }
  },
  "Better to Ask in English Cross-Lingual Evaluation of Large Language Models for Healthcare Queries": {
    "filename": "Better to Ask in English Cross-Lingual Evaluation of Large Language Models for Healthcare Queries.pdf",
    "analysis": {
      "benchmarks": [
        "XLingHealth",
        "HealthQA",
        "LiveQA",
        "MedicationQA"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Bard",
        "MedAlpaca",
        "XLingEval"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "What Makes Large Language Models Reason in Multi-Turn Code Generation": {
    "filename": "What Makes Large Language Models Reason in Multi-Turn Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CodeContests",
        "TACO"
      ],
      "models": [
        "Llama 3.0 8B",
        "Llama 3.0 70B",
        "Llama 3.1 8B",
        "Llama 3.1 70B",
        "Llama 3.1 405B",
        "GPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training": {
    "filename": "Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "Game24",
        "PrOntoQA",
        "RLHF Alignment",
        "Chess Endgame"
      ],
      "models": [
        "TS-LLM",
        "Tree-of-Thought (ToT)",
        "Reasoning via Planning (RAP)",
        "AlphaZero",
        "MCTS-\u03b1",
        "MCTS-Rollout",
        "BFS-V",
        "DFS-V",
        "CoT-Greedy",
        "CoT-SC",
        "CoT-SC-Tree",
        "LLaMA2-7B",
        "GPT-2-small",
        "GPT-3.5",
        "LLaMA-V",
        "LLaMA-SFT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Autoformulation of Mathematical Optimization Models Using LLMs": {
    "filename": "Autoformulation of Mathematical Optimization Models Using LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "NL4OPT",
        "IndustryOR"
      ],
      "models": [
        "MCTS LLM",
        "ORLM- LLaMA-3-8B",
        "Reflexion",
        "Chain-of-Experts",
        "OptiMUS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MOSS Enabling Code-Driven Evolution and Context Management for AI Agents": {
    "filename": "MOSS Enabling Code-Driven Evolution and Context Management for AI Agents.pdf",
    "analysis": {
      "benchmarks": [
        "SWEBench-lite"
      ],
      "models": [
        "MOSS",
        "Program-aided Language Models (PAL)",
        "CodeAct",
        "OpenDevin",
        "MindSearch",
        "Automated Design of Agentic Systems (ADAS)",
        "Diversity Empowered Intelligence (DEI)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks": {
    "filename": "Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA"
      ],
      "models": [
        "BERT",
        "T5",
        "GPT-3",
        "Gopher",
        "SATNet",
        "sequence-to-sequence LM",
        "Elman RNN",
        "Transformer",
        "BERT-base sized Transformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "E2LLM Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning": {
    "filename": "E2LLM Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "QMSum",
        "GovReport",
        "Quality",
        "NarrativeQA",
        "TriviaQA"
      ],
      "models": [
        "E2LLM",
        "Llama2-7B",
        "LongLoRA",
        "YaRN",
        "RAG",
        "LLoCO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Neuro-Symbolic Procedural Planning with Commonsense Prompting": {
    "filename": "Neuro-Symbolic Procedural Planning with Commonsense Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "WikiHow",
        "RobotHow"
      ],
      "models": [
        "PLAN",
        "BART",
        "GPT2",
        "GPT3",
        "LLMaP",
        "Chain"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NutriBench A Dataset for Evaluating Large Language Models on Nutrition Estimation from Meal Descriptions": {
    "filename": "NutriBench A Dataset for Evaluating Large Language Models on Nutrition Estimation from Meal Descriptions.pdf",
    "analysis": {
      "benchmarks": [
        "NUTRI BENCH"
      ],
      "models": [
        "GPT-4o",
        "Llama3.1",
        "Qwen2",
        "Gemma2",
        "OpenBioLLM",
        "GPT-4o-mini",
        "Llama3.1-8B",
        "Llama3.1-70B",
        "Llama3.1-405B-FP8",
        "Llama3-8B",
        "Llama3-70B",
        "Qwen2-7B",
        "Qwen2-72B",
        "Gemma2-9B",
        "Gemma2-27B",
        "OpenBioLLM-70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Training Nonlinear Transformers for Chain-of-Thought Inference A Theoretical Generalization Analysis": {
    "filename": "Training Nonlinear Transformers for Chain-of-Thought Inference A Theoretical Generalization Analysis.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3",
        "GPT-4",
        "LLaMa",
        "Sora",
        "nonlinear Transformers",
        "one-layer single-head attention-only Transformer",
        "multi-head attention networks"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Tyranny of Possibilities in the Design of Task-Oriented LLM Systems A Scoping Survey": {
    "filename": "The Tyranny of Possibilities in the Design of Task-Oriented LLM Systems A Scoping Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "GPT-6",
        "Superintelligent LLM",
        "Autonomous GPT-4 Agent",
        "Autonomous GPT-6 based Agent",
        "Multiple GPT-4 based Agents",
        "Multiple GPT-6 based Agents"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Circuit Complexity Bounds for RoPE-based Transformer Architecture": {
    "filename": "Circuit Complexity Bounds for RoPE-based Transformer Architecture.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "RoPE-based Transformer",
        "GPT-4",
        "Claude",
        "Llama",
        "OpenAI's o1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SQA3D Situated Question Answering in 3D Scenes": {
    "filename": "SQA3D Situated Question Answering in 3D Scenes.pdf",
    "analysis": {
      "benchmarks": [
        "SQA3D",
        "ScanNet",
        "ScanRefer",
        "ReferIt3D"
      ],
      "models": [
        "ScanQA",
        "ClipBERT",
        "MCAN",
        "Unified QA",
        "GPT-3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "APOLLO An Optimized Training Approach for Long-form Numerical Reasoning": {
    "filename": "APOLLO An Optimized Training Approach for Long-form Numerical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "FinQA",
        "ConvFinQA"
      ],
      "models": [
        "APOLLO",
        "FinQANet",
        "ELASTIC",
        "DyRRen",
        "TabT5",
        "CellRetriever+UniLM",
        "GPT-2",
        "T-5",
        "Retriever+NeRd",
        "Longformer",
        "BloombergGPT",
        "GPT-3.5-turbo",
        "GPT-4",
        "Program-of-Thought"
      ]
    }
  },
  "Generative Relevance Feedback with Large Language Models": {
    "filename": "Generative Relevance Feedback with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "TREC Robust04",
        "CODEC",
        "TREC Deep Learning 19",
        "TREC Deep Learning 20"
      ],
      "models": [
        "Generative Relevance Feedback (GRF)",
        "BM25",
        "BM25+RM3",
        "CEQE-MaxPool",
        "SPLADE+RM3",
        "TCT+PRF",
        "ColBERT-PRF"
      ]
    }
  },
  "Can I understand what I create Self-Knowledge Evaluation of Large Language Models": {
    "filename": "Can I understand what I create Self-Knowledge Evaluation of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM-8k",
        "MMLU"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Llama3-8B-Instruct",
        "Llama2-7B-Chat",
        "Mistral-7B-Instruct-v0.2",
        "Gemma-1.1-7B-Instruct",
        "Qwen1.5-7B-Chat",
        "Gill",
        "SEED-LLaMa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Solving Math Word Problem with Problem Type Classification": {
    "filename": "Solving Math Word Problem with Problem Type Classification.pdf",
    "analysis": {
      "benchmarks": [
        "Math23K",
        "NLPCC2023 Shared Task3"
      ],
      "models": [
        "Bert2Tree",
        "LLM solver",
        "Ensemble-MWP",
        "ChatGLM-6B",
        "MWP-Bert"
      ]
    }
  },
  "ChatQA Surpassing GPT-4 on Conversational QA and RAG": {
    "filename": "ChatQA Surpassing GPT-4 on Conversational QA and RAG.pdf",
    "analysis": {
      "benchmarks": [
        "CHATRAG BENCH",
        "Doc2Dial",
        "QuAC",
        "QReCC",
        "TopiOCQA",
        "INSCIT",
        "CoQA",
        "DoQA",
        "ConvFinQA",
        "SQA",
        "HybriDial",
        "NarrativeQA",
        "DROP",
        "Quoref",
        "ROPES",
        "SQuAD1.1",
        "SQuAD2.0",
        "NewsQA",
        "TAT-QA"
      ],
      "models": [
        "ChatQA-1.0-70B",
        "Llama2",
        "GPT-4-0613",
        "GPT-4-Turbo-2024-04-09",
        "Llama3-ChatQA-1.5-70B",
        "GPT-3.5-Turbo",
        "Dragon",
        "E5-unsupervised",
        "Command R+",
        "Llama2-Chat-7B",
        "Llama2-Chat-70B",
        "Llama3-Instruct-8B",
        "Llama3-Instruct-70B",
        "ChatQA-1.0-7B",
        "Llama3-ChatQA-1.5-8B",
        "ChatQA-1.0-70B - SyntheticConvQA",
        "ChatQA-1.0-70B - w/o stage-1",
        "ChatQA-1.0-70B - w/o stage-2",
        "ChatQA-1.0-70B - w/o single-turn",
        "ChatQA-1.0-70B - w/o ConvQAData"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FakeShield Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models": {
    "filename": "FakeShield Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CASIA1+",
        "IMD2020",
        "Columbia",
        "Coverage",
        "DSO",
        "Korus",
        "FFHQ",
        "FaceApp",
        "CASIAv2",
        "Fantastic Reality",
        "COCO"
      ],
      "models": [
        "FakeShield",
        "SPAN",
        "ManTraNet",
        "HiFi-Net",
        "PSCC-Net",
        "CAT-Net",
        "MVSS-Net",
        "OSN",
        "CADDM",
        "HiFi-DeepFake",
        "LLaVA-v1.6-34B",
        "InternVL2-26B",
        "Qwen2-VL-7B",
        "GPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Empowering Segmentation Ability to Multi-modal Large Language Models": {
    "filename": "Empowering Segmentation Ability to Multi-modal Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ReasonSeg",
        "ADE20k",
        "COCO-Stuff",
        "PACO-LVIS",
        "PASCAL-Part",
        "RefCOCO",
        "RefCOCO+",
        "RefCOCOg",
        "Refclef"
      ],
      "models": [
        "LLaVASeg",
        "LISA",
        "OVSeg",
        "GRES",
        "X-Decoder",
        "SEEM",
        "LLaVA",
        "ViT-H SAM",
        "MCN",
        "VLT",
        "CRIS",
        "LAVT",
        "ReLA"
      ]
    }
  },
  "Robustness of Demonstration-based Learning Under Limited Data Scenario": {
    "filename": "Robustness of Demonstration-based Learning Under Limited Data Scenario.pdf",
    "analysis": {
      "benchmarks": [
        "CoNLL03",
        "OntoNotes 5.0",
        "CoNLL00",
        "Name Regularity Bias (NRB)",
        "WTS",
        "SST-5",
        "MNLI"
      ],
      "models": [
        "bert-base-cased",
        "Roberta",
        "roberta-base",
        "roberta-large",
        "NO",
        "ST",
        "SW",
        "SN",
        "TR",
        "SR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoHint Automatic Prompt Optimization with Hint Generation": {
    "filename": "AutoHint Automatic Prompt Optimization with Hint Generation.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-Bench Instruction Induction",
        "Epistemic Reasoning",
        "Logical Fallacy Detection",
        "Implicatures",
        "Hyperbaton",
        "Causal Judgment",
        "Winowhy"
      ],
      "models": [
        "AutoHint",
        "GPT-4"
      ]
    }
  },
  "OWL A Large Language Model for IT Operations": {
    "filename": "OWL A Large Language Model for IT Operations.pdf",
    "analysis": {
      "benchmarks": [
        "Owl-Bench",
        "LogHub"
      ],
      "models": [
        "OWL",
        "LLaMA2-13b",
        "ChatGLM-6b",
        "ChatGLM2-6b",
        "Qwen-7b",
        "InternLM-7b",
        "ChatGPT",
        "DeepLog",
        "LogAnomaly",
        "LogRobust",
        "LogPrompt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LGR2 Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning": {
    "filename": "LGR2 Language Guided Reward Relabeling for Accelerating Hierarchical Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "maze navigation",
        "pick and place",
        "bin",
        "franka kitchen"
      ],
      "models": [
        "LGR2",
        "L2R",
        "HAC",
        "HIER",
        "DAC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FVEval Understanding Language Model Capabilities in Formal Verification of Digital Hardware": {
    "filename": "FVEval Understanding Language Model Capabilities in Formal Verification of Digital Hardware.pdf",
    "analysis": {
      "benchmarks": [
        "FVEval",
        "NL2SVA-Human",
        "NL2SVA-Machine",
        "Design2SVA"
      ],
      "models": [
        "GPT-4",
        "Gemini-1.5-pro",
        "Gemini-1.5-flash",
        "Mixtral-8x22b",
        "Llama-3.1-70b",
        "Llama-3-70b",
        "Llama-3.1-8b",
        "Llama-3-8b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From PDFs to Structured Data Utilizing LLM Analysis in Sports Database Management": {
    "filename": "From PDFs to Structured Data Utilizing LLM Analysis in Sports Database Management.pdf",
    "analysis": {
      "benchmarks": [
        "Finnish Sports Clubs Database"
      ],
      "models": [
        "OpenAI's GPT-4",
        "Anthropic's Claude 3 Opus"
      ]
    }
  },
  "Revisiting Prompt Engineering via Declarative Crowdsourcing": {
    "filename": "Revisiting Prompt Engineering via Declarative Crowdsourcing.pdf",
    "analysis": {
      "benchmarks": [
        "DBLP-Google Scholar dataset",
        "Restaurants",
        "Buy"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "Claude",
        "Bard",
        "gpt-3.5-turbo",
        "Anthropic's Claude 2",
        "OpenAI's gpt-3.5-turbo",
        "OpenAI text-embedding-ada-002"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Systematic Evaluation of Large Language Models for Natural": {
    "filename": "A Systematic Evaluation of Large Language Models for Natural.pdf",
    "analysis": {
      "benchmarks": [
        "DailyDialog",
        "PersonaChat",
        "EmpatheticDialogue",
        "LCCC",
        "CNN/DailyMail",
        "XSum",
        "THUCNews",
        "LCSTS",
        "ROCStories",
        "WritingPrompts",
        "LOT"
      ],
      "models": [
        "ChatGPT",
        "ChatGLM",
        "Flan-T5-XXL",
        "FastChat-T5",
        "Open-LLaMA",
        "Vicuna",
        "Alpaca-Lora",
        "Chinese-Alpaca",
        "GPT4ALL",
        "Dolly",
        "Oasst-Pythia",
        "T5-based models",
        "LLaMA-based models",
        "Pythia-based models",
        "EP-PG",
        "MoEL",
        "PLATO",
        "DialogWAE",
        "CTRLStruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Toward Self-Improvement of LLMs via Imagination Searching and Criticizing": {
    "filename": "Toward Self-Improvement of LLMs via Imagination Searching and Criticizing.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH"
      ],
      "models": [
        "ALPHA LLM",
        "Llama-2-70b",
        "WizardMath-70B-V1.0",
        "GPT-4",
        "GPT-3.5",
        "Claude-2",
        "PaLM-2",
        "Gemini 1.0 Pro",
        "Gemini 1.0 Ultra",
        "Gemini 1.5 Pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning": {
    "filename": "Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "TABMWP"
      ],
      "models": [
        "GPT-3",
        "PROMPT PG",
        "UnifiedQA",
        "TAPEX",
        "Zero-shot GPT-3",
        "Few-shot GPT-3",
        "Few-shot-CoT GPT-3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Rethinking Large Language Models in Mental Health Applications": {
    "filename": "Rethinking Large Language Models in Mental Health Applications.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "PsychBERT",
        "MentalBERT",
        "PHS-BERT",
        "MentalLongformer",
        "SmileChat",
        "Psy-LLM",
        "Mental-LLM",
        "MentalLLaMA",
        "ChatCounselor",
        "MindWatch",
        "ChatGPT",
        "GPT-3",
        "BERT",
        "GPT-2",
        "LLaMA",
        "BLOOM"
      ]
    }
  },
  "Chain of Thoughtlessness An Analysis of CoT in Planning": {
    "filename": "Chain of Thoughtlessness An Analysis of CoT in Planning.pdf",
    "analysis": {
      "benchmarks": [
        "Blocksworld",
        "Coin Flip",
        "Last Letter Concatenation",
        "multi-step arithmetic"
      ],
      "models": [
        "GPT-4",
        "Claude-3-Opus",
        "GPT-4-Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Large Language Models Learn Independent Causal Mechanisms": {
    "filename": "Can Large Language Models Learn Independent Causal Mechanisms.pdf",
    "analysis": {
      "benchmarks": [
        "ACRE",
        "RAVEN"
      ],
      "models": [
        "Independent Causal Language Models (ICLM)",
        "LLaMA2-7B",
        "ICLM-No-Inv",
        "ICLM-Invariant",
        "ICLM-Domain",
        "Finetuned-All",
        "Finetuned-Oracle-Router"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning": {
    "filename": "Improving Few-shot Generalization of Safety Classifiers via Data Augmented Parameter-Efficient Fine-Tuning.pdf",
    "analysis": {
      "benchmarks": [
        "Social Chemistry 101",
        "Toxicity"
      ],
      "models": [
        "DAPT",
        "base model",
        "fine-tuning (SFT)",
        "prompt-tuning (PT)",
        "in-context few-shot",
        "low-rank adapters (LoRA)",
        "chain-of-thought",
        "transfer learning",
        "automated prompt generation"
      ]
    }
  },
  "Mental-LLM": {
    "filename": "Mental-LLM.pdf",
    "analysis": {
      "benchmarks": [
        "Dreaddit",
        "DepSeverity",
        "SDCNL",
        "CSSRS-Suicide",
        "Red-Sam",
        "Twt-60Users",
        "SAD"
      ],
      "models": [
        "Alpaca",
        "Alpaca-LoRA",
        "FLAN-T5",
        "LLaMA2",
        "GPT-3.5",
        "GPT-4",
        "Mental-Alpaca",
        "Mental-FLAN-T5",
        "BERT",
        "Mental-RoBERTa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Avalons Game of Thoughts Battle Against Deception through Recursive Contemplation": {
    "filename": "Avalons Game of Thoughts Battle Against Deception through Recursive Contemplation.pdf",
    "analysis": {
      "benchmarks": [
        "Avalon game"
      ],
      "models": [
        "Recursive Contemplation (ReCon)",
        "Chain-of-Thoughts (CoT)",
        "ChatGPT",
        "Claude",
        "LLaMA-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automating Human Tutor-Style Programming Feedback Leveraging GPT-4 Tutor Model for Hint Generation and GPT-35 Student Model for Hint Validation": {
    "filename": "Automating Human Tutor-Style Programming Feedback Leveraging GPT-4 Tutor Model for Hint Generation and GPT-35 Student Model for Hint Validation.pdf",
    "analysis": {
      "benchmarks": [
        "BasicAlgo",
        "DataRegex",
        "DataAnalysis"
      ],
      "models": [
        "GPT4Hints-GPT3.5Val",
        "GPT4Hints-Base",
        "GPT4Hints-IO",
        "GPT4Hints-IOFix",
        "TutorHints"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Mamba Always Enjoy the Free Lunch": {
    "filename": "Can Mamba Always Enjoy the Free Lunch.pdf",
    "analysis": {
      "benchmarks": [
        "copy task",
        "phonebook task"
      ],
      "models": [
        "Mamba",
        "Transformers",
        "Mamba-small-L",
        "Mamba-small-D",
        "Mamba-small-LD",
        "Mamba(2.8B)++"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Transferring Procedural Knowledge across Commonsense Tasks": {
    "filename": "Transferring Procedural Knowledge across Commonsense Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "TRIP",
        "ROCStories",
        "PhysicalIQA",
        "aNLI",
        "CODAH"
      ],
      "models": [
        "LEAP",
        "CGLI",
        "RoBERTa-Large",
        "RoBERTa-L (CSKG)",
        "TRIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MathOdyssey Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data": {
    "filename": "MathOdyssey Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data.pdf",
    "analysis": {
      "benchmarks": [
        "MathOdyssey",
        "GSM8K",
        "MATH",
        "ProofNet",
        "OCWCourses",
        "MiniF2F",
        "AlphaGeometry",
        "SAT"
      ],
      "models": [
        "Llama-3",
        "DBRX-Instruct",
        "GPT-4 Turbo",
        "GPT-4",
        "GPT-3.5 Turbo",
        "Gemini 1.5 Pro",
        "Gemini Math-Specialized 1.5 Pro",
        "Claude 3 Opus",
        "Llama-3-70B"
      ]
    }
  },
  "Transformers and Large Language Models for Chemistry and Drug Discovery": {
    "filename": "Transformers and Large Language Models for Chemistry and Drug Discovery.pdf",
    "analysis": {
      "benchmarks": [
        "Therapeutics Data Commons",
        "Open Reaction Database",
        "MoleculeNet"
      ],
      "models": [
        "Molecular Transformer",
        "Chemformer",
        "RXNMapper",
        "AlphaFold2",
        "GPT-3",
        "ChatGPT",
        "GPT-4",
        "ChemCrow"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PromptCARE Prompt Copyright Protection by Watermark Injection and Verification": {
    "filename": "PromptCARE Prompt Copyright Protection by Watermark Injection and Verification.pdf",
    "analysis": {
      "benchmarks": [
        "SST2",
        "IMDb",
        "AG_News",
        "QQP",
        "QNLI",
        "MNLI"
      ],
      "models": [
        "PromptCARE",
        "BERT",
        "RoBERTa",
        "facebook OPT-1.3b",
        "LLaMA-3b",
        "LLaMA-7b",
        "LLaMA-13b",
        "AUTOPROMPT",
        "Prompt Tuning",
        "P-Tuning v2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Is Not All You Need Aligning Perception with Language Models": {
    "filename": "Language Is Not All You Need Aligning Perception with Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "StoryCloze",
        "HellaSwag",
        "Winograd",
        "Winogrande",
        "PIQA",
        "BoolQ",
        "CB",
        "COPA",
        "Rendered SST-2",
        "HatefulMemes",
        "RelativeSize",
        "MemoryColor",
        "ColorTerms",
        "Raven's Progressive Matrices",
        "COCO Caption",
        "Flickr30k",
        "VQAv2",
        "VizWiz",
        "WebSRC",
        "ImageNet",
        "CUB"
      ],
      "models": [
        "KOSMOS-1",
        "Flamingo-3B",
        "Flamingo-9B",
        "ZeroCap",
        "VLKD",
        "FewVLM",
        "METALM",
        "Frozen",
        "GIT",
        "CLIP ViT-B/32",
        "CLIP ViT-B/16",
        "CLIP ViT-L/14",
        "LLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer": {
    "filename": "Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer.pdf",
    "analysis": {
      "benchmarks": [
        "tiny Shakespeare"
      ],
      "models": [
        "minGPT"
      ]
    }
  },
  "InstructNav Zero-shot System for Generic Instruction Navigation in Unexplored Environment": {
    "filename": "InstructNav Zero-shot System for Generic Instruction Navigation in Unexplored Environment.pdf",
    "analysis": {
      "benchmarks": [
        "R2R-CE",
        "Habitat ObjNav",
        "DDN",
        "HM3D"
      ],
      "models": [
        "InstructNav",
        "SemExp",
        "PixelNav",
        "Habitat-Web",
        "OVRL",
        "ZSON",
        "ESC",
        "VoroNav",
        "L3MVN",
        "VLMF",
        "Sasra",
        "Seq2Seq",
        "CWP-CMA",
        "CWP-RecBERT",
        "Ego2Map-NaViT",
        "CMA",
        "NaVid",
        "ZSON-demand",
        "VTN-CLIP-demand",
        "DDN",
        "ChatGPT-Prompt",
        "MiniGPT-4"
      ]
    }
  },
  "Lost-in-Distance Impact of Contextual Proximity on LLM Performance in Graph Tasks": {
    "filename": "Lost-in-Distance Impact of Contextual Proximity on LLM Performance in Graph Tasks.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Llama-3-8B",
        "Llama-3-70B",
        "GPT-4",
        "Llama-3-8B-Instruct",
        "Llama-3-70B-Instruct",
        "GPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ECR-Chain Advancing Generative Language Models to Better Emotion-Cause Reasoners through Reasoning Chains": {
    "filename": "ECR-Chain Advancing Generative Language Models to Better Emotion-Cause Reasoners through Reasoning Chains.pdf",
    "analysis": {
      "benchmarks": [
        "RECCON-DD"
      ],
      "models": [
        "ECR-Chain",
        "ChatGPT",
        "Vicuna-7B",
        "RoBERTa-B",
        "RoBERTa-L",
        "KEC",
        "KBCIN",
        "TSAM"
      ]
    }
  },
  "Finding Visual Task Vectors": {
    "filename": "Finding Visual Task Vectors.pdf",
    "analysis": {
      "benchmarks": [
        "Pascal-5i",
        "Computer Vision Figures",
        "ImageNet"
      ],
      "models": [
        "MAE-VQGAN",
        "Visual Prompting",
        "REINFORCE",
        "Greedy Random Search",
        "Causal Mediation Analysis",
        "Llama2 7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Demonstration Notebook Finding the Most Suited In-Context Learning Example from Interactions": {
    "filename": "Demonstration Notebook Finding the Most Suited In-Context Learning Example from Interactions.pdf",
    "analysis": {
      "benchmarks": [
        "SingleEq",
        "MultiArith",
        "GSM8k",
        "SVAMP",
        "AQuA",
        "CSQA",
        "STQA",
        "Last Letter Concatenation",
        "Coin Flip",
        "Samsung Abstractive Messenger Summarization"
      ],
      "models": [
        "Zero-shot CoT",
        "Manual CoT",
        "AutoCoT",
        "PromptSO",
        "demonstration notebook"
      ]
    }
  },
  "SayPlan Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning": {
    "filename": "SayPlan Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning.pdf",
    "analysis": {
      "benchmarks": [
        "Office Environment",
        "Home Environment"
      ],
      "models": [
        "SayPlan",
        "LLM-As-Planner",
        "LLM+P",
        "SayPlan (GPT-3.5)",
        "SayPlan (GPT-4)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Supporting Human Raters with the Detection of Harmful Content using Large Language Models": {
    "filename": "Supporting Human Raters with the Detection of Harmful Content using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Google's dataset of 40,000 text comments",
        "Google's dataset of 10,000 non-violative comments"
      ],
      "models": [
        "PaLM 2 text-bison",
        "PaLM 2 text-unicorn",
        "LLM rater with dynamic few-shot examples",
        "LLM rater with hand-picked few-shot examples",
        "LLM rater with zero-shot prompt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do LLMs Really Adapt to Domains An Ontology Learning Perspective": {
    "filename": "Do LLMs Really Adapt to Domains An Ontology Learning Perspective.pdf",
    "analysis": {
      "benchmarks": [
        "Open English WordNet",
        "WN-sweets",
        "WN-football",
        "WN-music"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Falcon-40B",
        "LLaMa2-13B",
        "Zephyr-7B-\u03b2",
        "Falcon-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Information Re-Organization Improves Reasoning in Large Language Models": {
    "filename": "Information Re-Organization Improves Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HOVER",
        "FEVEROUS",
        "SCIFACT",
        "2WikiMultiHopQA",
        "StrategyQA",
        "MuSiQue",
        "HotpotQA",
        "WIKIHOP"
      ],
      "models": [
        "Llama2-70B",
        "GPT-3.5",
        "GPT-4",
        "Chain-of-Thought (CoT)",
        "Tree of Thoughts (ToT)",
        "Graph of Thoughts (GoT)",
        "InfoRE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Does Self-Rationalization Improve Robustness to Spurious Correlations": {
    "filename": "Does Self-Rationalization Improve Robustness to Spurious Correlations.pdf",
    "analysis": {
      "benchmarks": [
        "SNLI",
        "ESNLI",
        "CQA",
        "ECQA",
        "HANS",
        "CAD",
        "TEST-HARD",
        "TEST-EASY",
        "TEST-HYP"
      ],
      "models": [
        "self-rationalization models",
        "baseline task-only models",
        "BART-BASE",
        "BART-LARGE",
        "GPT2-MEDIUM",
        "GPT2-LARGE",
        "T5-BASE",
        "T5-LARGE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "QACHECK A Demonstration System for Question-Guided Multi-Hop Fact-Checking": {
    "filename": "QACHECK A Demonstration System for Question-Guided Multi-Hop Fact-Checking.pdf",
    "analysis": {
      "benchmarks": [
        "HOVER",
        "FEVEROUS"
      ],
      "models": [
        "QAC HECK",
        "InstructGPT",
        "Codex",
        "FLAN-T5",
        "ProgramFC",
        "Retriever\u2013Reader",
        "FLAN-T5",
        "GPT Reciter\u2013Reader"
      ]
    }
  },
  "Failure Modes of LLMs for Causal Reasoning on Narratives": {
    "filename": "Failure Modes of LLMs for Causal Reasoning on Narratives.pdf",
    "analysis": {
      "benchmarks": [
        "CauseNet"
      ],
      "models": [
        "GPT-4",
        "Claude 3.5 Sonnet"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unleashing the Creative Mind Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving": {
    "filename": "Unleashing the Creative Mind Language Model As Hierarchical Policy For Improved Exploration on Challenging Problem Solving.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K"
      ],
      "models": [
        "Large Language Models (LLMs)",
        "GPT-3.5",
        "GPT-4",
        "Chain-of-Thought (CoT) Sampling",
        "Tree-of-Thoughts (ToT)",
        "SentenceBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMs as Workers in Human-Computational Algorithms Replicating Crowdsourcing Pipelines with LLMs": {
    "filename": "LLMs as Workers in Human-Computational Algorithms Replicating Crowdsourcing Pipelines with LLMs.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLM Chain",
        "Baseline",
        "text-davinci-003",
        "text-ada-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FacTool Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios": {
    "filename": "FacTool Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios.pdf",
    "analysis": {
      "benchmarks": [
        "RoSE",
        "FactPrompts",
        "HumanEval",
        "GSM-Hard",
        "GSM8K"
      ],
      "models": [
        "FACTOOL",
        "GPT-4",
        "ChatGPT",
        "Claude-v1",
        "Bard",
        "Vicuna-13B",
        "Self-Check (0)",
        "Self-Check (3)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "When do Generative Query and Document Expansions Fail A Comprehensive Study Across Methods Retrievers and Datasets": {
    "filename": "When do Generative Query and Document Expansions Fail A Comprehensive Study Across Methods Retrievers and Datasets.pdf",
    "analysis": {
      "benchmarks": [
        "TREC DL 2019",
        "FiQA",
        "ArguAna",
        "GooAQ Technical",
        "NFCorpus",
        "SciFact Refute",
        "TREC-CT",
        "TREC-DL19",
        "TREC-DL20",
        "Tip of My Tongue",
        "Touch\u00e9",
        "WikiQA",
        "Quora",
        "TREC Clinical Trials '21"
      ],
      "models": [
        "DPR",
        "Contriever",
        "BM25",
        "Contriever FT",
        "E5 Base v2",
        "MPNet Base v2",
        "E5 Small v2",
        "GTE Large",
        "E5 Large v2",
        "MonoT5-Small",
        "MiniLM-2-v2",
        "SPLADEv2",
        "MonoBERT",
        "MiniLM-4-v2",
        "MonoT5-Base",
        "MonoT5-3B",
        "ColBERTv2",
        "MiniLM-12-v2",
        "MonoT5-Large",
        "LLAMA",
        "LLAMAv2",
        "LLAMAv2-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MALADE Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance": {
    "filename": "MALADE Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance.pdf",
    "analysis": {
      "benchmarks": [
        "OMOP Ground Truth table"
      ],
      "models": [
        "MALADE",
        "GPT-4 Turbo",
        "GPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Predicting Learning Performance with Large Language Models A Study in Adult Literacy": {
    "filename": "Predicting Learning Performance with Large Language Models A Study in Adult Literacy.pdf",
    "analysis": {
      "benchmarks": [
        "AutoTutor datasets",
        "CSAL AutoTutor lessons"
      ],
      "models": [
        "GPT-4",
        "Bayesian Knowledge Tracing",
        "Performance Factor Analysis",
        "Sparse Factor Analysis Lite",
        "tensor factorization",
        "eXtreme Gradient Boosting",
        "XGBoost (selected by GPT-4)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The debate over understanding in AIs large language models": {
    "filename": "The debate over understanding in AIs large language models.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "SuperGLUE",
        "Argument Reasoning Comprehension Task"
      ],
      "models": [
        "GPT-3",
        "ChatGPT",
        "PaLM",
        "LaMDA",
        "BERT"
      ]
    }
  },
  "EX-FEVER A Dataset for Multi-hop Explainable Fact Verification": {
    "filename": "EX-FEVER A Dataset for Multi-hop Explainable Fact Verification.pdf",
    "analysis": {
      "benchmarks": [
        "EX-FEVER",
        "FEVER",
        "HOVER",
        "e-FEVER",
        "LIAR-PLUS",
        "PUBHEALTH"
      ],
      "models": [
        "BERT-based",
        "MDR",
        "BART",
        "GEAR",
        "Aug-HOVER",
        "Large Language Models (LLMs)",
        "GPT-3.5-turbo"
      ]
    }
  },
  "Language-Guided Music Recommendation for Video via Prompt Analogies": {
    "filename": "Language-Guided Music Recommendation for Video via Prompt Analogies.pdf",
    "analysis": {
      "benchmarks": [
        "YT8M-MusicVideo",
        "YT8M-MusicTextClips"
      ],
      "models": [
        "ViML",
        "MVPt",
        "MVPt+",
        "Pretet et al.",
        "DeepSim",
        "CLIP",
        "BLOOM-176B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GeneGPT Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information": {
    "filename": "GeneGPT Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information.pdf",
    "analysis": {
      "benchmarks": [
        "GeneTuring",
        "GeneHop"
      ],
      "models": [
        "GeneGPT",
        "new Bing",
        "BioMedLM",
        "BioGPT",
        "GPT-3",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Generating Sequences by Learning to Self-Correct": {
    "filename": "Generating Sequences by Learning to Self-Correct.pdf",
    "analysis": {
      "benchmarks": [
        "Multiarith",
        "Multitask",
        "GSM",
        "COMMON GEN",
        "E2E",
        "REALTOXICITY PROMPTS"
      ],
      "models": [
        "SELF-CORRECT",
        "GPT-Neo 1.3B",
        "GPT-3",
        "GPT-2",
        "NeuroLogic",
        "NeuroLogic-A*",
        "PPLM",
        "GeDi",
        "DExpert",
        "DAPT",
        "PPO",
        "Quark"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Almanac Retrieval-Augmented Language Models for Clinical Medicine": {
    "filename": "Almanac Retrieval-Augmented Language Models for Clinical Medicine.pdf",
    "analysis": {
      "benchmarks": [
        "ClinicalQA",
        "MultiMedQA",
        "MedMCQA",
        "PubMedQA",
        "MedQA"
      ],
      "models": [
        "Almanac",
        "ChatGPT",
        "BioGPT",
        "SciBERT",
        "GatorTron",
        "Med-PaLM",
        "WebGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Human Participants in AI Research Ethics and Transparency in Practice": {
    "filename": "Human Participants in AI Research Ethics and Transparency in Practice.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do Efficient Transformers Really Save Computation": {
    "filename": "Do Efficient Transformers Really Save Computation.pdf",
    "analysis": {
      "benchmarks": [
        "Arithmetic",
        "Longest Increasing Subsequence (LIS)",
        "Edit Distance (ED)"
      ],
      "models": [
        "Standard Transformer",
        "Sparse Transformer",
        "Linear Transformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Can Automatically Engineer Features for Few-Shot Tabular Learning": {
    "filename": "Large Language Models Can Automatically Engineer Features for Few-Shot Tabular Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Adult",
        "Bank",
        "Blood",
        "Car",
        "Communities",
        "Credit-g",
        "Diabetes",
        "Heart",
        "Myocardial",
        "Cultivars",
        "NHANES",
        "Sequence-type",
        "Solution-mix"
      ],
      "models": [
        "FeatLLM",
        "TabLLM",
        "STUNT",
        "LogReg",
        "XGBoost",
        "RandomForest",
        "SCARF",
        "TabPFN",
        "In-context",
        "TABLET"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ComperDial Commonsense Persona-grounded Dialogue Dataset and Benchmark": {
    "filename": "ComperDial Commonsense Persona-grounded Dialogue Dataset and Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "ComperDial",
        "USR-TopicalChat",
        "USR-PersonaChat",
        "PersonaChat",
        "DailyDialog",
        "DSTC-ChitChat",
        "Empathetic Dialogue",
        "TopicalChat"
      ],
      "models": [
        "CPDS CORE",
        "BLEU",
        "ROUGE",
        "METEOR",
        "F1",
        "BERTScore",
        "BLEURT",
        "FED",
        "USR",
        "UniEval",
        "RADE",
        "GRADE",
        "USL-H"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Sparks of Large Audio Models A Survey and Outlook": {
    "filename": "Sparks of Large Audio Models A Survey and Outlook.pdf",
    "analysis": {
      "benchmarks": [
        "LibriSpeech",
        "CommonVoice",
        "VoxPopuli",
        "CVSS",
        "YouTube ASR",
        "Fleurs",
        "AudioCaps",
        "Clotho",
        "AudioSet",
        "EMIME",
        "MTG-Jamendo",
        "Jamendo",
        "Hansen",
        "MUSDB",
        "DSing",
        "LibriTTS",
        "VCTK",
        "CMU Arctic",
        "VoiceMOS",
        "LJ Speech",
        "FMA",
        "POP909",
        "Jamendo",
        "MusicCaps",
        "Symphony",
        "Vggsound",
        "DALI2",
        "MetaMIDI",
        "EMOPIA",
        "FSD50K",
        "Million MIDI",
        "MuST-C",
        "Wenetspeech",
        "Gigaspeech",
        "CoVoST",
        "Libri-Light"
      ],
      "models": [
        "SeamlessM4T",
        "AudioPaLM",
        "AudioLM",
        "SpeechGPT",
        "LTU",
        "VioLA",
        "MusicGen",
        "MusicLM",
        "WavJourney",
        "Whisper",
        "MMS",
        "GPT-2",
        "GPT-3",
        "GPT-4",
        "LLaMA",
        "HuBERT",
        "SoundStream",
        "w2v-BERT",
        "HiFi-GAN",
        "CLAP",
        "AudioMAE",
        "LoRA",
        "ChatGPT",
        "BERT",
        "TWIST",
        "SPEAR-TTS",
        "Mega-TTS",
        "PromptTTS",
        "FoundationTTS",
        "LM-VC",
        "VALL-E",
        "VALL-E X",
        "LyricWhiz",
        "AudioGen",
        "AudioLDM",
        "AudioLDM 2",
        "SoundStorm",
        "NExT-GPT",
        "Pengi",
        "AudioGPT",
        "Mu2SLAM",
        "SpeechX"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating and Inducing Personality in Pre-trained Language Models": {
    "filename": "Evaluating and Inducing Personality in Pre-trained Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Machine Personality Inventory (MPI)",
        "vignette tests"
      ],
      "models": [
        "BART",
        "GPT-Neo 2.7B",
        "GPT-NeoX 20B",
        "T0++ 11B",
        "Alpaca 7B",
        "GPT-3.5 175B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Stay on topic with Classifier-Free Guidance": {
    "filename": "Stay on topic with Classifier-Free Guidance.pdf",
    "analysis": {
      "benchmarks": [
        "LAMBADA",
        "ARC (challenge)",
        "Winogrande",
        "PIQA",
        "SCIQ",
        "TriviaQA",
        "HellaSwag",
        "BoolQ",
        "HumanEval",
        "GSM8K",
        "AQuA"
      ],
      "models": [
        "Pythia",
        "GPT-2",
        "LLaMA",
        "PaLM-540B",
        "GPT4All",
        "GPT-J",
        "CodeGen-350M-mono",
        "CodeGen-2B-mono",
        "CodeGen-6B-mono",
        "WizardLM-30B",
        "Guanaco-65B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AGILE A Novel Reinforcement Learning Framework of LLM Agents": {
    "filename": "AGILE A Novel Reinforcement Learning Framework of LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "ProductQA",
        "MedMCQA",
        "HotPotQA"
      ],
      "models": [
        "AGILE",
        "GPT-4",
        "GPT-3.5",
        "agile-vic13b-ppo",
        "agile-vic13b-sft",
        "agile-mek7b-ppo",
        "Meerkat-7b",
        "Vicuna-13b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Make LLMs better zero-shot reasoners Structure-orientated autonomous reasoning": {
    "filename": "Make LLMs better zero-shot reasoners Structure-orientated autonomous reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "Fever",
        "MMLU-BIO",
        "MMLU-PHY"
      ],
      "models": [
        "Structure-oriented Autonomous Reasoning Agents (SARA)",
        "Chain-of-Thought (CoT)",
        "ReAct",
        "Chain-of-Knowledge (CoK)",
        "Vanilla ICL",
        "GPT-4",
        "Qwen-max",
        "Llama3-70B",
        "Qwen2-57B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Empirical Investigation of Neural Symbolic Reasoning Strategies": {
    "filename": "Empirical Investigation of Neural Symbolic Reasoning Strategies.pdf",
    "analysis": {
      "benchmarks": [
        "purely symbolic numerical reasoning dataset"
      ],
      "models": [
        "T5-base",
        "T5-large",
        "BART-base"
      ]
    }
  },
  "Physics of Language Models Part 32 Knowledge Manipulation": {
    "filename": "Physics of Language Models Part 32 Knowledge Manipulation.pdf",
    "analysis": {
      "benchmarks": [
        "bioS",
        "bioR",
        "WikiBio",
        "StrategyQA"
      ],
      "models": [
        "GPT-4",
        "Llama-3",
        "GPT2",
        "Llama",
        "Mistral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Working Memory Capacity of ChatGPT An Empirical Study": {
    "filename": "Working Memory Capacity of ChatGPT An Empirical Study.pdf",
    "analysis": {
      "benchmarks": [
        "verbal n-back task",
        "spatial n-back task"
      ],
      "models": [
        "ChatGPT (gpt-3.5-turbo)",
        "Bloomz-7B",
        "Bloomz-7B1-mt",
        "ChatGLM-6B v1.0",
        "ChatGLM-6B v1.1",
        "GPT-4",
        "Vicuna-7B",
        "Vicuna-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An appraisal-based chain-of-emotion architecture for affective language model game agents": {
    "filename": "An appraisal-based chain-of-emotion architecture for affective language model game agents.pdf",
    "analysis": {
      "benchmarks": [
        "Situational Test of Emotional Understanding (STEU)"
      ],
      "models": [
        "gpt-3.5-turbo",
        "Chain-Of-Emotion architecture",
        "No Memory condition",
        "Memory condition",
        "Appraisal Prompts condition"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Egocentric Vision Language Planning": {
    "filename": "Egocentric Vision Language Planning.pdf",
    "analysis": {
      "benchmarks": [
        "Virtualhome",
        "Habitat2.0",
        "AI2-THOR",
        "VH-1.5M"
      ],
      "models": [
        "EgoPlan",
        "GPT-4V",
        "InstructP2P",
        "ControlNet",
        "LoRA",
        "VQ-GAN",
        "RAFT",
        "GPT4+React",
        "GPT4V+React",
        "GPT4V+Reflexion",
        "GPT4V+P2P",
        "GPT4V+PrevOF"
      ]
    }
  },
  "Preconditioned Visual Language Inference with Weak Supervision": {
    "filename": "Preconditioned Visual Language Inference with Weak Supervision.pdf",
    "analysis": {
      "benchmarks": [
        "PVLIR",
        "PNLI",
        "VSNLI",
        "SNLI"
      ],
      "models": [
        "FLAVA",
        "VisualBERT",
        "ViLBERT",
        "ViLT",
        "CLIP",
        "FLAVA-rationale-gen",
        "FLAVA-rationale-gold"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OpenBA An Open-sourced 15B Bilingual Asymmetric seq2seq Model Pre-trained from Scratch": {
    "filename": "OpenBA An Open-sourced 15B Bilingual Asymmetric seq2seq Model Pre-trained from Scratch.pdf",
    "analysis": {
      "benchmarks": [
        "BELEBELE",
        "MMLU",
        "C-Eval",
        "SuperGLUE",
        "CMMLU",
        "BBH",
        "Flores",
        "CLTS",
        "QQP",
        "WIKI AUTO",
        "ROC"
      ],
      "models": [
        "OpenBA",
        "OpenBA-X",
        "LLaMA-70B",
        "BLOOM-176B",
        "GLM-130B",
        "ChatGLM-6B",
        "Falcon",
        "LLaMA",
        "XLM-V",
        "InfoXLM",
        "ChatGPT",
        "Flan-T5-XL",
        "GPT-3",
        "BERT-Large",
        "BERT-Large++",
        "Alpaca",
        "PARROT",
        "BatGPT",
        "MOSS",
        "Baichuan",
        "OPT-13B",
        "GPT-J"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Model-Based Evolutionary Optimizer Reasoning with elitism": {
    "filename": "Large Language Model-Based Evolutionary Optimizer Reasoning with elitism.pdf",
    "analysis": {
      "benchmarks": [
        "Rosenbrock function",
        "Himmelblau function",
        "Beale function",
        "Goldstein-Price function",
        "Scaled Sphere function",
        "Sphere function",
        "ZDT1",
        "ZDT3"
      ],
      "models": [
        "Language-model-based Evolutionary Optimizer (LEO)",
        "Stochastic Gradient Descent (SGD)",
        "Adam",
        "L-BFGS-B",
        "Simulated Annealing",
        "CMA-ES",
        "COBYLA",
        "NSGA II",
        "LEO-modular",
        "LEO-Rnd"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Stop Uploading Test Data in Plain Text Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks": {
    "filename": "Stop Uploading Test Data in Plain Text Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-Bench"
      ],
      "models": [
        "GPT series",
        "MosaicML Inference",
        "Google's Bard",
        "PaLM API"
      ]
    }
  },
  "Post Hoc Explanations of Language Models Can Improve Language Models": {
    "filename": "Post Hoc Explanations of Language Models Can Improve Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Snarks",
        "Causal Judgment",
        "Ruin Names",
        "Formal Fallacies",
        "Salient Translation Error Detection",
        "CommonsenseQA",
        "Coin Flip",
        "GSM8k"
      ],
      "models": [
        "AMPLIFY",
        "GPT-3",
        "GPT-3.5",
        "GPT-2",
        "BERT",
        "Answer-Only (AO)",
        "Chain-of-Thought (CoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dynamic Open-Vocabulary 3D Scene Graphs for Long-term Language-Guided Mobile Manipulation": {
    "filename": "Dynamic Open-Vocabulary 3D Scene Graphs for Long-term Language-Guided Mobile Manipulation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "DovSG",
        "Ok-Robot",
        "GPT-4o"
      ]
    }
  },
  "On the Planning Abilities of Large Language Models A Critical Investigation with a Proposed Benchmark": {
    "filename": "On the Planning Abilities of Large Language Models A Critical Investigation with a Proposed Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "International Planning Competition",
        "Blocksworld"
      ],
      "models": [
        "GPT-3",
        "Instruct-GPT3",
        "BLOOM",
        "LPG",
        "Finetuned-GPT3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AstroMLab 2 AstroLLaMA-2-70B Model and Benchmarking Specialised LLMs for Astronomy": {
    "filename": "AstroMLab 2 AstroLLaMA-2-70B Model and Benchmarking Specialised LLMs for Astronomy.pdf",
    "analysis": {
      "benchmarks": [
        "Annual Review of Astronomy and Astrophysics MCQ dataset",
        "AstroMLab benchmarking dataset"
      ],
      "models": [
        "AstroLLaMA-2-7B",
        "AstroLLaMA-2-7B-Abstract",
        "AstroLLaMA-2-7B-AIC",
        "AstroLLaMA-3-8B",
        "AstroLLaMA-3-8B-AIC",
        "AstroLLaMA-3-8B-Summary",
        "AstroLLaMA-2-70B",
        "LLaMA-2-7B",
        "LLaMA-3-8B",
        "LLaMA-2-70B",
        "CosmoSage",
        "Qwen-2-8B",
        "LLaMA-3.1-8B",
        "Gemini-1.5-Pro-001",
        "GLM-4-0520",
        "Claude-3.0-Sonnet"
      ]
    }
  },
  "Holy Grail 20 From Natural Language to Constraint Models": {
    "filename": "Holy Grail 20 From Natural Language to Constraint Models.pdf",
    "analysis": {
      "benchmarks": [
        "NL4Opt competition dataset"
      ],
      "models": [
        "BART",
        "GPT-3.5",
        "LLAMA",
        "Ner4Opt"
      ]
    }
  },
  "Beyond Accuracy Investigating Error Types in GPT-4 Responses to USMLE Questions": {
    "filename": "Beyond Accuracy Investigating Error Types in GPT-4 Responses to USMLE Questions.pdf",
    "analysis": {
      "benchmarks": [
        "USMLE",
        "MedQA-USMLE"
      ],
      "models": [
        "GPT-4",
        "Med-PaLM 2",
        "GPT-3.5",
        "Galactica",
        "PMC-LLaMA",
        "GatorTronGPT",
        "DoctorGLM",
        "MedAlpaca",
        "Codex",
        "Med-PaLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies": {
    "filename": "Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies.pdf",
    "analysis": {
      "benchmarks": [
        "synthetic single-line system",
        "real-world multi-line system"
      ],
      "models": [
        "LLM-enhanced RL",
        "vanilla RL",
        "LLM-based controller",
        "feedback controller",
        "RL - local",
        "RL - global",
        "RL - local + global"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Navigating Prompt Complexity for Zero-Shot Classification A Study of Large Language Models in Computational Social Science": {
    "filename": "Navigating Prompt Complexity for Zero-Shot Classification A Study of Large Language Models in Computational Social Science.pdf",
    "analysis": {
      "benchmarks": [
        "Complaint",
        "Vaccine Stance",
        "Bragging",
        "Rumour Stance",
        "Sarcasm",
        "Hate Speech"
      ],
      "models": [
        "ChatGPT",
        "OpenAssistant",
        "GPT-3.5-turbo",
        "OpenAssistant-LLaMA",
        "BERT-large",
        "Logistic Regression"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Good Questions Help Zero-Shot Image Reasoning": {
    "filename": "Good Questions Help Zero-Shot Image Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "ScienceQA",
        "Flowers102",
        "Oxford-IIIT Pet",
        "FGVC Aircraft",
        "SNLI-VE"
      ],
      "models": [
        "QVix",
        "InstructBLIP",
        "MiniGPT",
        "LLaVA",
        "Cheetah",
        "GPT-4V"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LAMM Language-Assisted Multi-Modal Instruction-Tuning Dataset Framework and Benchmark": {
    "filename": "LAMM Language-Assisted Multi-Modal Instruction-Tuning Dataset Framework and Benchmark.pdf",
    "analysis": {
      "benchmarks": [
        "CIFAR10",
        "VOC2012",
        "SQAimage",
        "AI2D",
        "flickr30k",
        "UCMerced",
        "FSC147",
        "SVT",
        "CelebA",
        "LSP",
        "ScanNet",
        "ScanRefer",
        "ScanQA"
      ],
      "models": [
        "LAMM",
        "LLaVA",
        "MiniGPT4",
        "mPLUG-owl",
        "Vicuna-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Matching Patients to Clinical Trials with Large Language Models": {
    "filename": "Matching Patients to Clinical Trials with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SIGIR 2016 cohort",
        "TREC 2021 CT cohort",
        "TREC 2022 CT cohort"
      ],
      "models": [
        "TrialGPT",
        "TrialGPT-Retrieval",
        "TrialGPT-Matching",
        "TrialGPT-Ranking",
        "GPT-4",
        "GPT-3.5",
        "BioLinkBERT",
        "SciFive",
        "BioBERT",
        "PubMedBERT",
        "SapBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-contradictory Hallucinations of Large Language Models Evaluation Detection and Mitigation": {
    "filename": "Self-contradictory Hallucinations of Large Language Models Evaluation Detection and Mitigation.pdf",
    "analysis": {
      "benchmarks": [
        "PopQA"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "Llama2-70B-Chat",
        "Vicuna-13B",
        "SelfCheckGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations": {
    "filename": "Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations.pdf",
    "analysis": {
      "benchmarks": [
        "Japanese medical licensing examinations",
        "IGAKU QA"
      ],
      "models": [
        "GPT-3",
        "ChatGPT",
        "GPT-4",
        "ChatGPT-EN",
        "ChatGPT-Exp",
        "Student Majority"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChartAssisstant A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning": {
    "filename": "ChartAssisstant A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning.pdf",
    "analysis": {
      "benchmarks": [
        "ChartQA",
        "PlotQA",
        "OpenCQA",
        "ScigraphQA",
        "Vistext",
        "Chart-to-text",
        "ChartSumm",
        "RealCQA",
        "StructChart",
        "ChartLLM"
      ],
      "models": [
        "ChartAssistant",
        "UniChart",
        "Chartllama",
        "Donut",
        "SPHINX",
        "Matcha",
        "Pix2Struct",
        "T5",
        "Chart-T5",
        "Blip2-flant5-xl",
        "Qwen-VL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain of Agents Large Language Models Collaborating on Long-Context Tasks": {
    "filename": "Chain of Agents Large Language Models Collaborating on Long-Context Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "MuSiQue",
        "NarrativeQA",
        "Qasper",
        "QuALITY",
        "QMSum",
        "GovReport",
        "BookSum",
        "RepoBench-P"
      ],
      "models": [
        "Chain-of-Agents (CoA)",
        "RAG",
        "Full-Context (Vanilla)",
        "PaLM 2",
        "Gemini",
        "Claude 3",
        "text-bison",
        "text-unicorn",
        "gemini-ultra",
        "claude-3-haiku",
        "claude-3-sonnet",
        "claude-3-opus",
        "Multi-Agent Voting (Merge)",
        "Multi-Agent Hierarchical Structure (Hierarchical)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Scaling Diffusion Language Models via Adaptation from Autoregressive Models": {
    "filename": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models.pdf",
    "analysis": {
      "benchmarks": [
        "TriviaQA",
        "Lambada",
        "HellaSwag",
        "Winogrande",
        "SIQA",
        "PIQA",
        "GSM8K",
        "ROCStories",
        "Humaneval",
        "MAWPS",
        "SATMath"
      ],
      "models": [
        "DiffuGPT",
        "DiffuLLaMA",
        "GPT2",
        "LLaMA2",
        "SEDD",
        "Plaid1B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PDE Generalization of In-Context Operator Networks A Study on 1D Scalar Nonlinear Conservation Laws": {
    "filename": "PDE Generalization of In-Context Operator Networks A Study on 1D Scalar Nonlinear Conservation Laws.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "In-Context Operator Networks (ICON)",
        "ICON-LM",
        "Deep Galerkin Method (DGM)",
        "Deep Ritz Method (DRM)",
        "Physics-Informed Neural Networks (PINNs)",
        "Weak Adversarial Network (WAN)",
        "APAC-Net",
        "PDE-Net",
        "Fourier Neural Operator (FNO)",
        "Deep Operator Network (DeepONet)",
        "Physics-Informed Neural Operators (PINO)",
        "ICON-LM",
        "ICON"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Efficient Prompting Methods for Large Language Models A Survey": {
    "filename": "Efficient Prompting Methods for Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "Instruction Induction",
        "Big-Bench"
      ],
      "models": [
        "Self-instruct",
        "APE (Automatic Prompt Engineer)",
        "GPO framework",
        "OPRO",
        "PromptAgent",
        "Mixture-of-Prompt (MoP)",
        "GPS",
        "EvoPrompting",
        "EvoPrompt",
        "Promptbreeder",
        "AELP",
        "PhaseEvo",
        "RLPrompt",
        "DSP",
        "PACE",
        "PRewrite",
        "SCULPT",
        "ProTeGi",
        "PE2",
        "PREFER",
        "AutoHint",
        "UniPrompt",
        "GPO",
        "AMPO",
        "APOHF",
        "BPO",
        "APEER",
        "FIPO",
        "GrIPS",
        "Plum",
        "SPRIG",
        "TEMPERA",
        "Zero-Shot-CoT",
        "self-consistency",
        "LMSI",
        "Auto-CoT",
        "Boosted Prompting",
        "COSP",
        "USP",
        "Meta-CoT",
        "Reprompting",
        "Self-refine",
        "PromptPG",
        "Prompt-OIRL",
        "Reflexion",
        "PROMST",
        "DTG",
        "Reprompt",
        "ReAct",
        "Verify-and-Edit",
        "ART",
        "self-ask",
        "ToolLLM",
        "ATC",
        "Context Distillation",
        "PI (Prompt Injection)",
        "Distilling Context",
        "Instruction Distillation",
        "Distilling Step-by-Step",
        "xRAG",
        "Prompt Compression",
        "Gisting",
        "Gist-COCO",
        "UltraGist",
        "AutoCompressor",
        "LLoCO",
        "ICAE",
        "500xCompressor",
        "POD",
        "RDRec"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Offline Training of Language Model Agents with Functions as Learnable Weights": {
    "filename": "Offline Training of Language Model Agents with Functions as Learnable Weights.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "TabMWP",
        "GAIA"
      ],
      "models": [
        "GPT-4+ agent",
        "ReAct agent"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Retrieval-Augmented Generation for Large Language Models A Survey": {
    "filename": "Retrieval-Augmented Generation for Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Questions (NQ)",
        "TriviaQA (TQA)",
        "SQuAD",
        "Web Questions (WebQ)",
        "PopQA",
        "MS MARCO",
        "HotpotQA",
        "2WikiMultiHopQA",
        "MuSiQue",
        "ELI5",
        "NarrativeQA (NQA)",
        "ASQA",
        "QMSum (QM)",
        "Qasper",
        "COVID-QA",
        "CMB",
        "MMCU Medical",
        "QuALITY",
        "ARC",
        "CommonsenseQA",
        "GraphQA",
        "Wizard of Wikipedia (WoW)",
        "Personal Dialog KBP",
        "DuleMon",
        "CamRest",
        "Amazon (Toys, Sport, Beauty)",
        "WikiEvent",
        "RAMS",
        "T-REx",
        "ZsRE",
        "HellaSwag",
        "CoT Reasoning",
        "CSQA",
        "MMLU",
        "WikiText-103",
        "StrategyQA",
        "FEVER",
        "PubHealth",
        "Biography",
        "WikiASP",
        "XSum",
        "VioLens",
        "TREC",
        "SST-2",
        "CodeSearchNet",
        "NoMIRACL",
        "GSM8K",
        "JRC-Acquis"
      ],
      "models": [
        "Naive RAG",
        "Advanced RAG",
        "Modular RAG",
        "CoG",
        "DenseX",
        "EAR",
        "UPRISE",
        "RAST",
        "Self-Mem",
        "FLARE",
        "PGRA",
        "FILCO",
        "RADA",
        "Filter-rerank",
        "R-GQA",
        "LLM-R",
        "TIGER",
        "LM-Indexer",
        "BEQUE",
        "CT-RAG",
        "Atlas",
        "RAVEN",
        "RETRO++",
        "INSTRUCTRETRO",
        "RRR",
        "RA-e2e",
        "PROMPTAGATOR",
        "AAR",
        "RA-DIT",
        "RAG-Robust",
        "RA-Long-Form",
        "CoN",
        "Self-RAG",
        "BGM",
        "CoQ",
        "Token-Elimination",
        "PaperQA",
        "NoiseRAG",
        "IAG",
        "NoMIRACL",
        "ToC",
        "SKR",
        "ITRG",
        "RAG-LongContext",
        "ITER-RETGEN",
        "IRCoT",
        "LLM-Knowledge-Boundary",
        "RAPTOR",
        "RECITE",
        "ICRALM",
        "Retrieve-and-Sample",
        "Zemi",
        "CRAG",
        "1-PAGER",
        "PRCA",
        "QLM-Doc-ranking",
        "Recomp",
        "DSP",
        "RePLUG",
        "ARM-RAG",
        "GenRead",
        "UniMS-RAG",
        "CREA-ICL",
        "PKG",
        "SANTA",
        "SURGE",
        "MK-ToD",
        "Dual-Feedback-ToD",
        "KnowledGPT",
        "FABULA",
        "HyKGE",
        "KALMV",
        "RoG",
        "G-Retriever"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Memory GAPS Would LLMs pass the Tulving Test": {
    "filename": "Memory GAPS Would LLMs pass the Tulving Test.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "mistral-7b-instruct-v0",
        "orca-mini-3b"
      ]
    }
  },
  "Self-Supervised Open-Ended Classification with Small Visual Language Models": {
    "filename": "Self-Supervised Open-Ended Classification with Small Visual Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Real-Names miniImageNet",
        "Open-Ended miniImageNet",
        "Oxford-Pets",
        "Flowers102",
        "Food101",
        "CUBS-200",
        "SUN397"
      ],
      "models": [
        "SeCAt",
        "Frozen",
        "FROMAGe",
        "OpenFlamingo",
        "ClipCap",
        "GPT-Neo",
        "GPT2-small",
        "GPT2-medium"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "KS-LLM Knowledge Selection of Large Language Models with Evidence Document for Question Answering": {
    "filename": "KS-LLM Knowledge Selection of Large Language Models with Evidence Document for Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "TriviaQA-verified",
        "WebQ",
        "NQ"
      ],
      "models": [
        "KS-LLM",
        "Vicuna-13B",
        "Llama 2-13B",
        "Llama 2-7B",
        "Standard",
        "Standard+doc",
        "CoT+doc",
        "KS-Q",
        "KS-T",
        "KS-S"
      ]
    }
  },
  "Enhancing Robustness in Large Language Models Prompting for Mitigating the Impact of Irrelevant Information": {
    "filename": "Enhancing Robustness in Large Language Models Prompting for Mitigating the Impact of Irrelevant Information.pdf",
    "analysis": {
      "benchmarks": [
        "GSMIR",
        "GSM8K",
        "GSM8K-SLC",
        "GSMIC"
      ],
      "models": [
        "GPT-3.5-Turbo",
        "GPT-3.5-Turbo-16K",
        "ATF",
        "SP",
        "COT",
        "0-COT",
        "LTM",
        "IP"
      ]
    }
  },
  "Can only LLMs do Reasoning Potential of Small Language Models in Task Planning": {
    "filename": "Can only LLMs do Reasoning Potential of Small Language Models in Task Planning.pdf",
    "analysis": {
      "benchmarks": [
        "COmmand-STeps datasets (COST)",
        "RT-1",
        "RoboVQA",
        "BridgeData V1",
        "BridgeData V2",
        "Language Table dataset"
      ],
      "models": [
        "GPT3.5",
        "GPT4",
        "GPT2-medium",
        "GPT2-base",
        "Socratic models (SMs)"
      ]
    }
  },
  "A Survey of Large Language Models in Finance FinLLMs": {
    "filename": "A Survey of Large Language Models in Finance FinLLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Financial PhraseBank (FPB)",
        "FiQA-SA",
        "SemEval-2017 (Task 5)",
        "StockEmotions",
        "Headline",
        "FedNLP",
        "FOMC",
        "Banking77",
        "FIN",
        "FiNER-139",
        "FiQA-QA",
        "FinQA",
        "ConvFinQA",
        "StockNet",
        "CIKM18",
        "BigData22",
        "ECTSum",
        "MultiLing 2019",
        "FinRED",
        "Event-Driven Trading (EDT)",
        "FinCausal20",
        "FinTabNet",
        "MAEC",
        "MONOPOLY",
        "MINDS-14",
        "MultiFin"
      ],
      "models": [
        "GPT-1",
        "GPT-2",
        "GPT-3",
        "GPT-4",
        "ChatGPT",
        "BERT",
        "FinBERT-19",
        "FinBERT-20",
        "FinBERT-21",
        "FLANG",
        "BloombergGPT",
        "FinMA",
        "InvestLM",
        "FinGPT",
        "LLaMA",
        "BLOOM",
        "ELECTRA",
        "InstructGPT",
        "Codex"
      ]
    }
  },
  "How Good Are GPT Models at Machine Translation A Comprehensive Evaluation": {
    "filename": "How Good Are GPT Models at Machine Translation A Comprehensive Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "WMT22",
        "WMT21",
        "News Commentary"
      ],
      "models": [
        "ChatGPT",
        "GPT3.5 (text-davinci-003)",
        "text-davinci-002",
        "Microsoft Translator",
        "WMT-Best Systems",
        "Hybrid Max-Routing"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Language-driven Scientific AI": {
    "filename": "Towards Language-driven Scientific AI.pdf",
    "analysis": {
      "benchmarks": [
        "COCO",
        "Visual Genome",
        "AI2D",
        "SciFact"
      ],
      "models": [
        "GPT-3",
        "T5",
        "SciBERT",
        "BioBERT",
        "SpaceRoBERTa",
        "ISAAQ"
      ]
    }
  },
  "A Principled Framework for Knowledge-enhanced Large Language Model": {
    "filename": "A Principled Framework for Knowledge-enhanced Large Language Model.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Knowledge-driven LLM",
        "Reasoning Agent",
        "LLM Predominant (LLM-only)",
        "LLM\u2295KG",
        "LLM \u2297KG",
        "Reasoner(LLM/Rules/\u2026)",
        "Actor Critic World Model",
        "Memory Buffer",
        "KB Query Results",
        "Judge",
        "Structural (KG)",
        "Document (Wiki)",
        "Parametric (LLM)",
        "Rules",
        "Fuzzy rules",
        "Chain-of-Thought (CoT)"
      ]
    }
  },
  "CAVM Conditional Autoregressive Vision Model for Contrast-Enhanced Brain Tumor MRI Synthesis": {
    "filename": "CAVM Conditional Autoregressive Vision Model for Contrast-Enhanced Brain Tumor MRI Synthesis.pdf",
    "analysis": {
      "benchmarks": [
        "BraSyn-2023"
      ],
      "models": [
        "CAVM",
        "ResViT",
        "SynDiff",
        "TSF-Seq2Seq",
        "MT-Net"
      ]
    }
  },
  "Large Language Models A Survey": {
    "filename": "Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "Wikipedia QA",
        "XNLI",
        "Crosslingual QA",
        "Multi choice QA",
        "Boolean QA",
        "MedQA",
        "MedMCQA",
        "HealthSearchQA",
        "LiveQA",
        "MedicationQA",
        "MMLU",
        "MATH",
        "HumanEval",
        "Multi-Turn Programming Benchmark",
        "BIG-bench"
      ],
      "models": [
        "GPT",
        "LLaMA",
        "PaLM",
        "ChatGPT",
        "GPT-4",
        "BERT",
        "RoBERTa",
        "ALBERT",
        "DeBERTa",
        "XLNet",
        "T5",
        "mT5",
        "BART",
        "CODEX",
        "WebGPT",
        "InstructGPT",
        "LLaMA-2",
        "Alpaca",
        "Vicuna-13B",
        "Guanaco",
        "Koala",
        "Mistral-7B",
        "Code LLaMA",
        "Med-PaLM",
        "Med-PaLM 2",
        "FLAN",
        "Gopher",
        "T0",
        "ERNIE 3.0",
        "RETRO",
        "GLaM",
        "LaMDA",
        "OPT",
        "Chinchilla",
        "Galactica",
        "CodeGen",
        "AlexaTM",
        "Sparrow",
        "Minerva",
        "MoD",
        "BLOOM",
        "GLM",
        "Pythia",
        "Orca",
        "StarCoder",
        "KOSMOS",
        "Gemini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PaLM 2 Technical Report": {
    "filename": "PaLM 2 Technical Report.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-Bench",
        "BIG-Bench Hard",
        "HSK 7-9",
        "J-Test A-C",
        "PLIDA C2",
        "TCF",
        "DELE C2",
        "TriviaQA",
        "Natural Questions",
        "WebQuestions",
        "LAMBADA",
        "HellaSwag",
        "StoryCloze",
        "Winograd",
        "WinoGrande",
        "SQuAD v2",
        "RACE",
        "PIQA",
        "ARC",
        "OpenBookQA",
        "SuperGLUE",
        "Adversarial NLI",
        "TyDi QA",
        "Jigsaw",
        "DROP",
        "StrategyQA",
        "CommonsenseQA",
        "XCOPA",
        "MATH",
        "GSM8K",
        "MGSM",
        "HumanEval",
        "MBPP",
        "ARCADE",
        "BabelCode"
      ],
      "models": [
        "PaLM 2",
        "PaLM",
        "PaLM 2-S",
        "PaLM 2-M",
        "PaLM 2-L",
        "PaLM 2-S*",
        "GPT-4",
        "Minerva",
        "Flan-PaLM",
        "PaLM-Coder-540B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Event Causality Identification with Rationale and Structure-Aware Causal Question Answering": {
    "filename": "Enhancing Event Causality Identification with Rationale and Structure-Aware Causal Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "EventStoryLine",
        "Causal-TimeBank"
      ],
      "models": [
        "GenECI",
        "SEAG",
        "DS-GCN",
        "RichGCN",
        "ERGO",
        "CHEER",
        "SENDIR",
        "GPT-3.5",
        "BERT",
        "LR+",
        "LIP",
        "Ours"
      ]
    }
  },
  "ThinkBot Embodied Instruction Following with Thought Chain Reasoning": {
    "filename": "ThinkBot Embodied Instruction Following with Thought Chain Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "ALFRED"
      ],
      "models": [
        "ThinkBot",
        "Prompter",
        "Prompter+",
        "Seq2seq",
        "MOCA",
        "E.T.",
        "LWIT",
        "HITUT",
        "ABP",
        "LLM-Planner",
        "FILM",
        "LGS-RPA",
        "CPEM"
      ]
    }
  },
  "Complex Logical Reasoning over Knowledge Graphs using Large Language Models": {
    "filename": "Complex Logical Reasoning over Knowledge Graphs using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "FB15k",
        "FB15k-237",
        "NELL995"
      ],
      "models": [
        "LARK",
        "GQE",
        "Query2Box (Q2B)",
        "BetaE",
        "HQE",
        "HypE",
        "CQD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Universal Self-Consistency for Large Language Model Generation": {
    "filename": "Universal Self-Consistency for Large Language Model Generation.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "BIRD-SQL",
        "ARCADE",
        "GovReport",
        "SummScreen",
        "TruthfulQA"
      ],
      "models": [
        "Universal Self-Consistency (USC)",
        "Self-Consistency (SC)",
        "Greedy decoding",
        "Random",
        "SC-Exec",
        "SC-Exec (fuzzy match)"
      ]
    }
  },
  "Chain of Explanation New Prompting Method to Generate Quality Natural Language Explanation for Implicit Hate Speech": {
    "filename": "Chain of Explanation New Prompting Method to Generate Quality Natural Language Explanation for Implicit Hate Speech.pdf",
    "analysis": {
      "benchmarks": [
        "LatentHatred"
      ],
      "models": [
        "GPT-2",
        "GPT-NEO",
        "OPT",
        "T5",
        "BART",
        "GPT-2 (CoE)",
        "BART (CoE)"
      ]
    }
  },
  "Interpreting and Mitigating Hallucination in MLLMs through Multi-agent Debate": {
    "filename": "Interpreting and Mitigating Hallucination in MLLMs through Multi-agent Debate.pdf",
    "analysis": {
      "benchmarks": [
        "POPE",
        "POPE-R",
        "POPE-C",
        "MSCOCO",
        "A-OKVQA",
        "GQA"
      ],
      "models": [
        "Gemini-Pro-Vision",
        "GPT-4o",
        "LLaVA-1.5",
        "MiniGPT-4"
      ]
    }
  },
  "Are Large Language Models Really Good Logical Reasoners A Comprehensive Evaluation and Beyond": {
    "filename": "Are Large Language Models Really Good Logical Reasoners A Comprehensive Evaluation and Beyond.pdf",
    "analysis": {
      "benchmarks": [
        "bAbI-15",
        "EntailmentBank",
        "RuleTaker",
        "FOLIO",
        "Leap-Of-Thought",
        "bAbI-16",
        "CLUTRR",
        "\u03b1-NLI",
        "\u03b1-NLG",
        "AbductiveRules",
        "D*-Ab",
        "ReClor",
        "LogiQA",
        "LogiQA 2.0",
        "LogiQA2NLI",
        "NeuLR"
      ],
      "models": [
        "text-davinci-003",
        "ChatGPT",
        "BARD",
        "LLaMA3.1-Chat",
        "Mistral-Instruct-v0.3",
        "Claude-3",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Model Decoding as LikelihoodUtility Alignment": {
    "filename": "Language Model Decoding as LikelihoodUtility Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "REBEL",
        "WMT14",
        "RTP",
        "SwissProt",
        "Sports"
      ],
      "models": [
        "GenIE (BART)",
        "mBART50",
        "GPT2",
        "ProtoGPT2",
        "MT-NLG 530B",
        "Greedy Search",
        "Beam Search",
        "Stochastic Beams",
        "Constrained Beam Search",
        "Value-Guided Beam Search",
        "Monte-Carlo Tree Search",
        "Zero-Shot",
        "Few-Shot",
        "Chain-of-Thought"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Distilling Step-by-Step Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes": {
    "filename": "Distilling Step-by-Step Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes.pdf",
    "analysis": {
      "benchmarks": [
        "e-SNLI",
        "ANLI",
        "CQA",
        "SVAMP",
        "ASDiv"
      ],
      "models": [
        "Distilling step-by-step",
        "T5-Base",
        "T5-Large",
        "T5-XXL",
        "Few-shot CoT",
        "PINTO Tuning",
        "Standard finetuning",
        "Standard task distillation",
        "PaLM",
        "GPT-NeoX"
      ]
    }
  },
  "AI-native Memory A Pathway from LLMs Towards AGI": {
    "filename": "AI-native Memory A Pathway from LLMs Towards AGI.pdf",
    "analysis": {
      "benchmarks": [
        "Mebot",
        "reasoning-in-a-haystack",
        "needle-in-a-haystack"
      ],
      "models": [
        "GPT-4",
        "GPT-4-turbo",
        "GPT-4o",
        "GPT-3.5-turbo",
        "LLAMA-2-7B",
        "ChatGLM",
        "Gemini 1.5",
        "GraphRAG",
        "GraphRAG-local",
        "GraphRAG-global",
        "RAG++",
        "LPM (Lifelong Personal Model)",
        "Qwen-2-7B-instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TeacherLM Teaching to Fish Rather Than Giving the Fish Language Modeling Likewise": {
    "filename": "TeacherLM Teaching to Fish Rather Than Giving the Fish Language Modeling Likewise.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "StrategyQA",
        "CREAK",
        "ECQA",
        "P3-Sense-3K"
      ],
      "models": [
        "TeacherLM-7.1B",
        "OPT",
        "BLOOM",
        "BLOOMZ-7.1B",
        "text-davinci-003",
        "TeacherLM-Fundamental",
        "TeacherLM-COT",
        "TeacherLM-CommonMistake",
        "TeacherLM-560M",
        "TeacherLM-1.1B",
        "TeacherLM-3B",
        "TeacherLM-176B",
        "Flan-PaLM-8B",
        "GLM-130B",
        "BLOOM-176B",
        "Gopher-280B",
        "P3-Augmented-BLOOMZ-7.1B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Visual Reasoning and Multi-Agent Approach in Multimodal Large Language Models MLLMs Solving TSP and mTSP Combinatorial Challenges": {
    "filename": "Visual Reasoning and Multi-Agent Approach in Multimodal Large Language Models MLLMs Solving TSP and mTSP Combinatorial Challenges.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Multi-Agent 1",
        "Multi-Agent 2",
        "ChatGPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AgentCoder Multi-Agent-based Code Generation with Iterative Testing and Optimisation": {
    "filename": "AgentCoder Multi-Agent-based Code Generation with Iterative Testing and Optimisation.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "HumanEval-ET",
        "MBPP-ET"
      ],
      "models": [
        "AgentCoder",
        "GPT-4",
        "GPT-3.5-turbo",
        "PaLM Coder",
        "Claude-instant-1",
        "MetaGPT",
        "ChatDev",
        "AgentVerse",
        "CodeCoT",
        "Self-Collaboration",
        "INTERVENOR",
        "Self-Debugging",
        "Self-Planing",
        "Self-Edit",
        "RAP",
        "ToT",
        "Reflexion",
        "ReAct",
        "CoT",
        "Few-Shot",
        "AlphaCode",
        "Incoder",
        "CodeGeeX",
        "StarCoder",
        "CodeLlama",
        "Llama3",
        "CodeGen-Mono",
        "CodeX",
        "CodeX+CodeT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Addition is All You Need for Energy-efficient Language Models": {
    "filename": "Addition is All You Need for Energy-efficient Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Massive Multitask Language Understanding (MMLU)",
        "BigBench-Hard (BBH)",
        "ARC-Challenge",
        "CSQA",
        "OBQA",
        "PIQA",
        "SIQA",
        "Visual Question Answering (VQAv2)",
        "VizWiz",
        "TextVQA",
        "Llava-bench",
        "POPE",
        "GSM8k"
      ],
      "models": [
        "Llama-3.1-8b-Instruct",
        "mistral-7b-v0.3-Instruct",
        "Gemma2-2b-It",
        "Llava-v1.5-7b",
        "L-Mul"
      ]
    }
  },
  "Measuring Taiwanese Mandarin Language Understanding": {
    "filename": "Measuring Taiwanese Mandarin Language Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "TMLU",
        "TC-Eval",
        "TMMLU-plus",
        "C-Eval",
        "CMMLU",
        "MMLU",
        "BIG-bench"
      ],
      "models": [
        "Taiwan-LLM",
        "Breeze",
        "Yi",
        "Qwen",
        "GPT-4",
        "GPT-3.5",
        "Claude-3-Opus",
        "Claude-Instant-1.2",
        "Gemini-Pro",
        "Mixtral-8x7B-Instruct",
        "chatglm3-6b",
        "Mistral-7B-Instruct",
        "Baichuan2-13B-Chat",
        "falcon-40b-instruct",
        "OLMo-7B-Instruct",
        "Llama-2-13b-Chat",
        "Qwen-0.5B-Chat",
        "Llama-2-7b-chat",
        "Falcon-7b-instruct",
        "Gemma-7b-it"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM-Grounder Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent": {
    "filename": "LLM-Grounder Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent.pdf",
    "analysis": {
      "benchmarks": [
        "ScanRefer"
      ],
      "models": [
        "LLM-Grounder",
        "OpenScene",
        "LERF",
        "ScanRefer",
        "3DVG-Transformer"
      ]
    }
  },
  "Decoding In-Context Learning Neuroscience-inspired Analysis of Representations in Large Language Models": {
    "filename": "Decoding In-Context Learning Neuroscience-inspired Analysis of Representations in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "linear regression",
        "reading comprehension"
      ],
      "models": [
        "Llama-2 70B",
        "Vicuna 13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Label-free Node Classification on Graphs with Large Language Models LLMS": {
    "filename": "Label-free Node Classification on Graphs with Large Language Models LLMS.pdf",
    "analysis": {
      "benchmarks": [
        "OGBN-PRODUCTS",
        "OGBN-ARXIV",
        "CORA",
        "CITESEER",
        "PUBMED",
        "WIKICS"
      ],
      "models": [
        "LLM-GNN",
        "Graph Neural Networks (GNNs)",
        "LLMs-as-Predictors",
        "SES",
        "TAG-Z",
        "BART-large-MNLI",
        "GCN",
        "Random",
        "Density",
        "AGE",
        "RIM",
        "GraphPart",
        "FeatProp"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Large Language Models to Generate Answer Set Programs": {
    "filename": "Leveraging Large Language Models to Generate Answer Set Programs.pdf",
    "analysis": {
      "benchmarks": [
        "Mitra and Baral 2015 logic puzzles dataset"
      ],
      "models": [
        "GPT-3",
        "GPT-4",
        "LOGICIA",
        "GPT-3 Generated ASP Rules",
        "GPT-4 Generated ASP Rules"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Conceptual and Unbiased Reasoning in Language Models": {
    "filename": "Conceptual and Unbiased Reasoning in Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BoolQ",
        "CommonsenseQA",
        "HotpotQA",
        "StrategyQA"
      ],
      "models": [
        "GPT-3.5",
        "Llama-70B-instruct",
        "Mixtral-8x7B"
      ]
    }
  },
  "Schema-learning and rebinding as mechanisms of in-context learning and emergence": {
    "filename": "Schema-learning and rebinding as mechanisms of in-context learning and emergence.pdf",
    "analysis": {
      "benchmarks": [
        "GINC",
        "LIALT",
        "PreCo"
      ],
      "models": [
        "CSCG",
        "transformer",
        "LSTM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluation of ChatGPT Model for Vulnerability Detection": {
    "filename": "Evaluation of ChatGPT Model for Vulnerability Detection.pdf",
    "analysis": {
      "benchmarks": [
        "CWE vulnerabilities",
        "CWE-20",
        "CWE-200",
        "CWE-502",
        "CWE-611",
        "CWE-79"
      ],
      "models": [
        "ChatGPT",
        "GPT-3",
        "text-davinci-003",
        "gpt-3.5-turbo",
        "baseline"
      ]
    }
  },
  "Data Augmentation with In-Context Learning and Comparative Evaluation in Math Word Problem Solving": {
    "filename": "Data Augmentation with In-Context Learning and Comparative Evaluation in Math Word Problem Solving.pdf",
    "analysis": {
      "benchmarks": [
        "Draw1K",
        "HMWP",
        "ALG514",
        "MAWPS",
        "SVAMP",
        "MAWPS-Single",
        "ASDIV-A",
        "Math23K"
      ],
      "models": [
        "Llama-7b",
        "DNS",
        "MathEN",
        "Saligned",
        "RNNVAE",
        "MWPBert",
        "SAUSolver",
        "GTS",
        "Graph2Tree",
        "RobertaGen"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GPT Can Solve Mathematical Problems Without a Calculator": {
    "filename": "GPT Can Solve Mathematical Problems Without a Calculator.pdf",
    "analysis": {
      "benchmarks": [
        "Ape210K",
        "K6",
        "BIG-bench"
      ],
      "models": [
        "MathGLM",
        "MathGLM-10M",
        "MathGLM-100M",
        "MathGLM-500M",
        "MathGLM-2B",
        "GPT-4",
        "ChatGPT",
        "text-davinci-003",
        "code-davinci-002",
        "Galactica",
        "LLaMA",
        "OPT",
        "BLOOM",
        "GLM",
        "GLM-Large",
        "GLM-6B",
        "GLM2-6B",
        "GLM-10B",
        "ChatGLM-6B",
        "ChatGLM2-6B",
        "Chinese-Alpaca-13B",
        "MOSS-16B",
        "Ziya-LLaMA-13B",
        "Baichuan-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on In-context Learning": {
    "filename": "A Survey on In-context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "SST5",
        "SST2",
        "Commonsense QA",
        "SNLI",
        "AG News"
      ],
      "models": [
        "GPT2",
        "GPT-J",
        "Qwen2",
        "Llama3",
        "KATE",
        "MI",
        "EPR",
        "IDS",
        "AdaICL",
        "UDR",
        "SG-ICL",
        "AutoICL",
        "MSP",
        "ICV",
        "GlobalE & LocalE",
        "ICCL",
        "PICL",
        "MEND",
        "ICLM",
        "MetaICL",
        "OPT-IML",
        "Super-NaturalInstructions",
        "FLAN",
        "Scaling Instruction",
        "Self-supervised ICL",
        "Symbol Tuning",
        "RICL",
        "ICL Markup",
        "Instruction Induction",
        "Self-Instruct",
        "APE",
        "Grimoire",
        "Calibrate",
        "Channel Models",
        "kNN-Prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models as Biomedical Hypothesis Generators A Comprehensive Evaluation": {
    "filename": "Large Language Models as Biomedical Hypothesis Generators A Comprehensive Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "seen dataset",
        "unseen dataset"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "LLaMA",
        "Vicuna-33b-v1.3",
        "Llama-2-70b-chat",
        "WizardLM-13B-V1.2",
        "WizardLM-70B-V1.0",
        "Openchat-v3.2-super",
        "MedAlpaca-13B",
        "PMC-LLaMA-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Exploration to Mastery Enabling LLMs to Master Tools via Self-Driven Interactions": {
    "filename": "From Exploration to Mastery Enabling LLMs to Master Tools via Self-Driven Interactions.pdf",
    "analysis": {
      "benchmarks": [
        "ToolBench",
        "RestBench-TMDB",
        "RestBench-Spotify"
      ],
      "models": [
        "DRAFT",
        "ReAct",
        "DFSDT",
        "EasyTool",
        "GPT-4o-mini",
        "Llama-3-70B",
        "GPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ArthModel Enhance Arithmetic Skills to Large Language Model": {
    "filename": "ArthModel Enhance Arithmetic Skills to Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "Dot Place Datasets",
        "Arithmetic QA Datasets",
        "Alpace and Arithmetic QA Datasets"
      ],
      "models": [
        "LLaMA",
        "AuxLLM",
        "Arithmetic Small Model",
        "ArthModel",
        "LLM-Chat"
      ]
    }
  },
  "LightPAL Lightweight Passage Retrieval for Open Domain Multi-Document Summarization": {
    "filename": "LightPAL Lightweight Passage Retrieval for Open Domain Multi-Document Summarization.pdf",
    "analysis": {
      "benchmarks": [
        "ODSum",
        "LFRQA",
        "Story",
        "Meeting",
        "RAG-QA"
      ],
      "models": [
        "LightPAL",
        "PromptRank",
        "bge-large-en-v1.5",
        "BM25",
        "Qwen2.5-0.5B",
        "Qwen2.5-1.5B",
        "Qwen2.5-3B",
        "Meta-Llama-3.1-8B-Instruct",
        "MegaBeam-Mistral-7B-512k"
      ]
    }
  },
  "Generative Expressive Robot Behaviors using Large Language Models": {
    "filename": "Generative Expressive Robot Behaviors using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Generative Expressive Motion (GenEM)",
        "GenEM with iterative Feedback (GenEM++)",
        "oracle animator"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TelecomRAG Taming Telecom Standards with Retrieval Augmented Generation and LLMs": {
    "filename": "TelecomRAG Taming Telecom Standards with Retrieval Augmented Generation and LLMs.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "TelecomRAG",
        "ChatGPT-4",
        "Gemini Ultra",
        "TelecomGPT"
      ]
    }
  },
  "Do Large Language Models Know What They Dont Know": {
    "filename": "Do Large Language Models Know What They Dont Know.pdf",
    "analysis": {
      "benchmarks": [
        "SelfAware",
        "SQuAD2.0",
        "NewsQA",
        "SQuAD",
        "HotpotQA",
        "TriviaQA"
      ],
      "models": [
        "GPT-3",
        "InstructGPT",
        "LLaMA",
        "Alpaca",
        "Vicuna",
        "GPT-4",
        "text-ada-001",
        "text-babbage-001",
        "text-curie-001",
        "text-davinci-001",
        "text-davinci-002",
        "text-davinci-003",
        "gpt-3.5-turbo-0301",
        "gpt-4-0314",
        "LLaMA-7B",
        "Alpaca-7B",
        "Vicuna-7B",
        "LLaMA-13B",
        "Alpaca-13B",
        "Vicuna-13B",
        "LLaMA-30B",
        "LLaMA-65B"
      ]
    }
  },
  "Large Language Models Perform Diagnostic Reasoning": {
    "filename": "Large Language Models Perform Diagnostic Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "DDXPlus"
      ],
      "models": [
        "InstructGPT",
        "Few-Shot Bot",
        "DR-CoT",
        "Standard Prompting"
      ]
    }
  },
  "COMPS Conceptual Minimal Pair Sentences for testing Robust Property Knowledge and its Inheritance in Pre-trained Language Models": {
    "filename": "COMPS Conceptual Minimal Pair Sentences for testing Robust Property Knowledge and its Inheritance in Pre-trained Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "COMPS",
        "COMPS-BASE",
        "COMPS-WUGS",
        "COMPS-WUGS-DIST"
      ],
      "models": [
        "ALBERT",
        "BERT",
        "ELECTRA",
        "RoBERTa",
        "GPT2",
        "GPT-Neo",
        "GPT-J",
        "distilled BERT-base",
        "distilled RoBERTa-base",
        "distilled GPT2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Grokked Transformers are Implicit Reasoners A Mechanistic Journey to the Edge of Generalization": {
    "filename": "Grokked Transformers are Implicit Reasoners A Mechanistic Journey to the Edge of Generalization.pdf",
    "analysis": {
      "benchmarks": [
        "train_inferred ID",
        "test_inferred ID",
        "test_inferred OOD"
      ],
      "models": [
        "Grokked Transformer",
        "GPT-4-Turbo",
        "Gemini-1.5-Pro",
        "standard decoder-only transformer model as in GPT-2",
        "Universal Transformer variant"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Empirical Study of Instruction-tuning Large Language Models in Chinese": {
    "filename": "An Empirical Study of Instruction-tuning Large Language Models in Chinese.pdf",
    "analysis": {
      "benchmarks": [
        "Belle-eval",
        "MMCU"
      ],
      "models": [
        "LLaMA",
        "Bloom",
        "moss-base",
        "ChatGLM",
        "Vicuna",
        "Bloomz",
        "Bloomz-mt",
        "moss-sft",
        "Ours",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SocialGPT Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization": {
    "filename": "SocialGPT Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "PIPA",
        "PISC"
      ],
      "models": [
        "SocialGPT",
        "GRM",
        "GR2N",
        "TRGAT",
        "Dual-Glance",
        "Pair CNN",
        "MGR",
        "SRG-GN",
        "GPT-3.5",
        "Vicuna-13B",
        "Vicuna-7B",
        "Llama2-7B",
        "Llama2-13B",
        "BLIP-2",
        "SAM",
        "GPT-4V",
        "LLaVA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How AI Processing Delays Foster Creativity Exploring Research Question Co-Creation with an LLM-based Agent": {
    "filename": "How AI Processing Delays Foster Creativity Exploring Research Question Co-Creation with an LLM-based Agent.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "CoQuest"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tabular Transfer Learning via Prompting LLMs": {
    "filename": "Tabular Transfer Learning via Prompting LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Adult",
        "Credit-R",
        "Electricity",
        "Credit-g",
        "Credit-A",
        "Heart-c",
        "Diabetes",
        "Breast",
        "Haberman",
        "TAE",
        "Hamster",
        "Customers",
        "Pollution",
        "Car",
        "BTC",
        "Caesarian",
        "VC",
        "Salaries",
        "Laptops",
        "Choles.",
        "House"
      ],
      "models": [
        "P2T",
        "Conventional prompting",
        "LLM",
        "CatBoost",
        "Logistic Regression (LR)",
        "Nearest Neighbor Classifier (kNN)",
        "VIME",
        "STUNT",
        "LIFT-ICL",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination": {
    "filename": "Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "ChatGPT",
        "SPARK"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On the Consistency of Video Large Language Models in Temporal Comprehension": {
    "filename": "On the Consistency of Video Large Language Models in Temporal Comprehension.pdf",
    "analysis": {
      "benchmarks": [
        "Charades-STA",
        "ActivityNet-Captions",
        "Charades-CON",
        "ActivityNet-CON"
      ],
      "models": [
        "GPT-4o",
        "Gemini",
        "TimeChat",
        "VTimeLLM",
        "VTG-LLM",
        "Video-LLaVA",
        "Video-ChatGPT",
        "Video-LLaMA",
        "Video-LLaMA2",
        "VideoChat2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DiversiGATE A Comprehensive Framework for Reliable Large Language Models": {
    "filename": "DiversiGATE A Comprehensive Framework for Reliable Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "Synthetic Dataset"
      ],
      "models": [
        "SelfLearner",
        "Zero-shot learning",
        "One-shot learning",
        "One-shot Ensemble learning",
        "GPT-3 Davinci-text-003",
        "Self-Consistency",
        "MathPrompter",
        "WebGPT"
      ]
    }
  },
  "Who is leading in AI An analysis of industry AI research": {
    "filename": "Who is leading in AI An analysis of industry AI research.pdf",
    "analysis": {
      "benchmarks": [
        "OpenAlex",
        "Parameter, Compute and Data Trends in Machine Learning (PCD) database",
        "novel publicly available dataset of key algorithmic innovations underpinning large language models"
      ],
      "models": [
        "GPT-3",
        "LLaMA 2",
        "Claude 2",
        "SPPNet",
        "Seq2Seq",
        "LSTM",
        "AlphaGo Fan",
        "GNMT",
        "AlphaGo Master",
        "Megatron-Turing NLG 530B",
        "PaLM (540B)",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models Injecting Disguised Vulnerabilities against Strong Detection": {
    "filename": "An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models Injecting Disguised Vulnerabilities against Strong Detection.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval"
      ],
      "models": [
        "CODEBREAKER",
        "SIMPLE",
        "COVERT",
        "TROJAN PUZZLE",
        "CodeGen-Multi",
        "GPT-3.5-Turbo",
        "GPT-4",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CoMA Compositional Human Motion Generation with Multi-modal Agents": {
    "filename": "CoMA Compositional Human Motion Generation with Multi-modal Agents.pdf",
    "analysis": {
      "benchmarks": [
        "HumanML3D"
      ],
      "models": [
        "CoMA",
        "MoMask",
        "MMM",
        "FineMoGen",
        "CoMo",
        "MotionChain",
        "Motion-Agent",
        "MotionGPT",
        "MDM",
        "T2M-GPT",
        "SPAM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Neuroformer Multimodal and Multitask Generative Pretraining for Brain Data": {
    "filename": "Neuroformer Multimodal and Multitask Generative Pretraining for Brain Data.pdf",
    "analysis": {
      "benchmarks": [
        "Simulated Dataset",
        "Two-photon calcium imaging datasets",
        "Passive-Stim data",
        "Visnav data"
      ],
      "models": [
        "Neuroformer",
        "Generalized Linear Model (GLM)",
        "Lasso Regression",
        "MLP",
        "Bidirectional GRU"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards autonomous system flexible modular production system enhanced with large language model agents": {
    "filename": "Towards autonomous system flexible modular production system enhanced with large language model agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLM-enhanced automated modular production system",
        "LLM agents",
        "GPT-model",
        "text-davinci-003",
        "manager agent",
        "operator agent"
      ]
    }
  },
  "EPIC Effective Prompting for Imbalanced-Class Data Synthesis in Tabular Data Classification via Large Language Models": {
    "filename": "EPIC Effective Prompting for Imbalanced-Class Data Synthesis in Tabular Data Classification via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Travel",
        "Sick",
        "HELOC",
        "Income",
        "Diabetes",
        "Thyroid"
      ],
      "models": [
        "EPIC",
        "GReaT",
        "TabDDPM",
        "CTAB-GAN+",
        "CTGAN",
        "TVAE",
        "CopulaGAN",
        "SMOTE",
        "SMOTENC",
        "XGBoost",
        "CatBoost",
        "LightGBM",
        "Gradient boosting classifier",
        "GPT-3.5-turbo",
        "Mistral",
        "Llama2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Large Language Models Empower Molecular Property Prediction": {
    "filename": "Can Large Language Models Empower Molecular Property Prediction.pdf",
    "analysis": {
      "benchmarks": [
        "MUTAG",
        "PTC",
        "AIDS",
        "Sider",
        "ClinTox",
        "Bace",
        "BBBP",
        "Esol",
        "Lipophilicity"
      ],
      "models": [
        "ChatGPT",
        "CaR Roberta",
        "GCN",
        "GIN",
        "ChebyNet",
        "D-MPNN",
        "ECFP4-MLP",
        "SMILES-Transformer",
        "MolR",
        "GraphMVP",
        "InfoGraph",
        "G-Motif",
        "Mole-BERT",
        "ChemBERTa",
        "MolKD",
        "DeBERTa",
        "adaptive-lm-molecules"
      ]
    }
  },
  "Proof of Thought  Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning": {
    "filename": "Proof of Thought  Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA",
        "Reddit-OSHA Benchmark"
      ],
      "models": [
        "PROOF OF THOUGHT",
        "Chain of Thought (CoT)",
        "Chain of Thought with Self-Consistency (CoT-SC)",
        "Tree of Thought (ToT)",
        "Graph of Thought (GoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improve Mathematical Reasoning in Language Models by Automated Process Supervision": {
    "filename": "Improve Mathematical Reasoning in Language Models by Automated Process Supervision.pdf",
    "analysis": {
      "benchmarks": [
        "MATH500",
        "GSM8K"
      ],
      "models": [
        "Gemini Pro",
        "Gemma2 27B",
        "OmegaPRM",
        "PRM800K",
        "Math-Shepherd"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Language Models Employ the Socratic Method Experiments with Code Debugging": {
    "filename": "Can Language Models Employ the Socratic Method Experiments with Code Debugging.pdf",
    "analysis": {
      "benchmarks": [
        "Auckland dataset",
        "Refactory dataset",
        "FalconCode dataset",
        "Socratic debugging benchmark"
      ],
      "models": [
        "Flan-T5",
        "GPT-3.5",
        "GPT-4",
        "FLAN-T5 small",
        "FLAN-T5 base",
        "FLAN-T5 large"
      ]
    }
  },
  "Releasing the CRaQAn Coreference Resolution in Question-Answering An open-source dataset and dataset creation methodology using instruction-following models": {
    "filename": "Releasing the CRaQAn Coreference Resolution in Question-Answering An open-source dataset and dataset creation methodology using instruction-following models.pdf",
    "analysis": {
      "benchmarks": [
        "Quoref",
        "HotpotQA"
      ],
      "models": [
        "GPT-4",
        "Recursive Criticism and Improvement Loop (RCI)"
      ]
    }
  },
  "TextCoT Zoom In for Enhanced Multimodal Text-Rich Image Understanding": {
    "filename": "TextCoT Zoom In for Enhanced Multimodal Text-Rich Image Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "TextVQA",
        "STVQA",
        "DocVQA",
        "InfographicVQA",
        "ChartQA",
        "POIE",
        "SROIE",
        "FUNSD"
      ],
      "models": [
        "TextCoT",
        "LLaVA-1.5-7B",
        "LLaVA-1.5-13B",
        "SPHINX",
        "ShareGPT4V",
        "Qwen-VL-Chat",
        "ZS-CoT",
        "CoT-SC",
        "DDCoT",
        "CCoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Test of Time A Benchmark for Evaluating LLMs on Temporal Reasoning": {
    "filename": "Test of Time A Benchmark for Evaluating LLMs on Temporal Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "ToT-Semantic",
        "ToT-Arithmetic",
        "TGQA",
        "TempTabQA",
        "YAGO11k",
        "Anonymized Wikidata Extract (AWE)"
      ],
      "models": [
        "Claude-3-Sonnet",
        "GPT-4",
        "Gemini 1.5 Pro",
        "GPT4-Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Lets Think Outside the Box Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation": {
    "filename": "Lets Think Outside the Box Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Oogiri-GO",
        "Cloud Guessing Game",
        "Divergent Association Task"
      ],
      "models": [
        "Qwen-VL",
        "CLoT",
        "GPT-4",
        "GPT-3.5",
        "LLaVA-1.5",
        "MiniGPT-v2",
        "mPLUG-Owl Multilingual",
        "VisualGLM-6B",
        "CogVLM-17B",
        "InstructionBLIP",
        "mPLUG-Owl LLaMA2",
        "Otter",
        "LLAMA2",
        "Baichuan2",
        "ChatGLM3",
        "Vicuna-v1.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SynAsk unleashing the power of large language models in organic synthesis": {
    "filename": "SynAsk unleashing the power of large language models in organic synthesis.pdf",
    "analysis": {
      "benchmarks": [
        "Massive Multi-task Language Understanding (MMLU)",
        "Multi-level multi-discipline chinese evaluation (C-Eval)",
        "GSM8K",
        "BIG-Bench-Hard (BBH)",
        "Measuring massive multitask language understanding in Chinese (CMMLU)",
        "ChEMBL"
      ],
      "models": [
        "SynAsk",
        "ChatGPT",
        "GPT-4",
        "Qwen",
        "LLaMA",
        "DISC-LawLLM",
        "MultiMedQA",
        "ChemCrow",
        "ChemLLM",
        "AIZynthFinder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ExpeL LLM Agents Are Experiential Learners": {
    "filename": "ExpeL LLM Agents Are Experiential Learners.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "ALFWorld",
        "WebShop",
        "FEVER"
      ],
      "models": [
        "ExpeL",
        "ReAct",
        "Act",
        "Reflexion",
        "ExpeL Transfer",
        "ExpeL (retrieve-only)",
        "ExpeL (insights-only)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RethinkMCTS Refining Erroneous Thoughts in Monte Carlo Tree Search for Code Generation": {
    "filename": "RethinkMCTS Refining Erroneous Thoughts in Monte Carlo Tree Search for Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "APPS"
      ],
      "models": [
        "RethinkMCTS",
        "GPT-3.5-turbo",
        "GPT-4o-mini",
        "PG-TD",
        "ToT",
        "LATS",
        "RAP",
        "LDB",
        "Reflexion"
      ]
    }
  },
  "Can LLMs Perform Structured Graph Reasoning Tasks": {
    "filename": "Can LLMs Perform Structured Graph Reasoning Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "custom graph traversal tasks"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Claude-2",
        "Llama-2",
        "Palm-2",
        "PathCompare"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Autonomous Prompt Engineering in Large Language Models": {
    "filename": "Autonomous Prompt Engineering in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Checkmate in One",
        "Word-sorting",
        "Game of 24",
        "Geometric Shapes"
      ],
      "models": [
        "GPT-4",
        "Automatic Prompt Engineering Toolbox (APET)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Complex QA and language models hybrid architectures Survey": {
    "filename": "Complex QA and language models hybrid architectures Survey.pdf",
    "analysis": {
      "benchmarks": [
        "MS Marco",
        "SQuAD",
        "SQuAD v2",
        "TriviaQA",
        "MMLU",
        "NarrativeQA",
        "NaturalQuestions"
      ],
      "models": [
        "ChatGPT",
        "GALACTICA",
        "BLOOM",
        "HELM",
        "InstructGPT",
        "PaLM",
        "BIG-G",
        "GPT-3",
        "BERT",
        "RoBERTa",
        "T5",
        "BART",
        "BigBird"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Natural Language Commanding via Program Synthesis": {
    "filename": "Natural Language Commanding via Program Synthesis.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Semantic Interpreter",
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "text-davinci-003"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate": {
    "filename": "Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate.pdf",
    "analysis": {
      "benchmarks": [
        "Commonsense Machine Translation",
        "Counter-Intuitive Arithmetic Reasoning",
        "GSM",
        "AddSub",
        "Penguin Date",
        "Colored Objects"
      ],
      "models": [
        "Multi-Agent Debate (MAD)",
        "GPT-3.5-Turbo",
        "GPT-4",
        "Self-Reflect",
        "Rerank",
        "MAPS",
        "CoT",
        "Self-Consistency",
        "vicuna-7b-v1.5-16k",
        "vicuna-13b-v1.5-16k"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GenCHiP Generating Robot Policy Code for High-Precision and Contact-Rich Manipulation Tasks": {
    "filename": "GenCHiP Generating Robot Policy Code for High-Precision and Contact-Rich Manipulation Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "Functional Manipulation Benchmark (FMB)",
        "NIST Task Board Benchmarks",
        "IROS 2020 Robotic Grasping and Manipulation Competition (IROS RGMC)"
      ],
      "models": [
        "GenCHiP",
        "contact-unaware model",
        "Code-as-Policies (CaP)",
        "GenCHiP, Fixed Compliance (FC)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Conceptual Design Generation Using Large Language Models": {
    "filename": "Conceptual Design Generation Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "crowdsourced dataset",
        "design prompts"
      ],
      "models": [
        "GPT-3",
        "GPT-3 Base",
        "GPT-3 Zero-shot",
        "GPT-3 Few-shot",
        "SentenceBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can formal argumentative reasoning enhance LLMs performances": {
    "filename": "Can formal argumentative reasoning enhance LLMs performances.pdf",
    "analysis": {
      "benchmarks": [
        "MT-Bench"
      ],
      "models": [
        "MQArgEng",
        "Mistral 7B",
        "Mistral-7B-Instruct-v0.2",
        "MQInstruct"
      ]
    }
  },
  "GUARD Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models": {
    "filename": "GUARD Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HarmBench",
        "JailbreakBench"
      ],
      "models": [
        "Vicuna-13B",
        "LongChat-7B",
        "Llama2-7B",
        "ChatGPT",
        "MiniGPT-v2",
        "Gemini Vision Pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From LLMs to Actions Latent Codes as Bridges in Hierarchical Robot Control": {
    "filename": "From LLMs to Actions Latent Codes as Bridges in Hierarchical Robot Control.pdf",
    "analysis": {
      "benchmarks": [
        "Language Table",
        "Calvin"
      ],
      "models": [
        "Latent Codes as Bridges (LCB)",
        "GPT-4V",
        "LLaVA",
        "RoboFlamingo",
        "3D Diffusion Actor (3DDA)",
        "LangTable"
      ]
    }
  },
  "Deductive Beam Search Decoding Deducible Rationale for Chain-of-Thought Reasoning": {
    "filename": "Deductive Beam Search Decoding Deducible Rationale for Chain-of-Thought Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "AQuA",
        "SingleEq",
        "MultiArith",
        "CommonsenseQA",
        "StrategyQA",
        "Coin Flip"
      ],
      "models": [
        "Deductive Beam Search (DBS)",
        "Llama2-7b",
        "Llama2-13b",
        "Llama2-70b",
        "ChatGPT",
        "SelfEval",
        "Deductive Verification (DV)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FLEXTAF Enhancing Table Reasoning with Flexible Tabular Formats": {
    "filename": "FLEXTAF Enhancing Table Reasoning with Flexible Tabular Formats.pdf",
    "analysis": {
      "benchmarks": [
        "WikiTableQuestions",
        "TabFact"
      ],
      "models": [
        "FLEXTAF-Single",
        "FLEXTAF-Vote",
        "Llama3",
        "DeepSeek-Coder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RAP Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents": {
    "filename": "RAP Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld",
        "Webshop",
        "Franka Kitchen",
        "Meta World"
      ],
      "models": [
        "RAP",
        "ReAct",
        "Reflexion",
        "ADaPT",
        "GPT-3.5",
        "GPT-4",
        "Llama2-13b",
        "LLaVA",
        "CogVLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatRetriever Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval": {
    "filename": "ChatRetriever Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval.pdf",
    "analysis": {
      "benchmarks": [
        "QReCC",
        "TopiOCQA",
        "CAsT-19",
        "CAsT-20",
        "CAsT-21"
      ],
      "models": [
        "ChatRetriever",
        "T5QR",
        "ConvGQR",
        "LLM4CS",
        "LLM Embedder",
        "INSTRCUT OR",
        "RepLLaMA",
        "E5mistral-7b",
        "GRIT",
        "Conv-ANCE",
        "ConvDR",
        "DialogInpainter",
        "LeCoRE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Inner Monologue Embodied Reasoning through Planning with Language Models": {
    "filename": "Inner Monologue Embodied Reasoning through Planning with Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "simulated tabletop rearrangement",
        "real-world tabletop rearrangement",
        "real-world kitchen mobile manipulation"
      ],
      "models": [
        "Inner Monologue",
        "CLIPort",
        "SayCan",
        "InstructGPT",
        "PALM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MANGO A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models": {
    "filename": "MANGO A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MANGO"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4",
        "Claude-instant-1",
        "Claude-2",
        "Llama-2",
        "RWKV",
        "Llama-2-S",
        "RWKV-S"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Reliable Common-Sense Reasoning Socialbot Built Using LLMs and Goal-Directed ASP": {
    "filename": "A Reliable Common-Sense Reasoning Socialbot Built Using LLMs and Goal-Directed ASP.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "AutoCompanion",
        "GPT-4",
        "s(CASP)",
        "ChatGPT-3.5",
        "AutoConcierge",
        "STAR framework"
      ]
    }
  },
  "AnyTool Self-Reflective Hierarchical Agents for Large-Scale API Calls": {
    "filename": "AnyTool Self-Reflective Hierarchical Agents for Large-Scale API Calls.pdf",
    "analysis": {
      "benchmarks": [
        "ToolBench",
        "AnyToolBench"
      ],
      "models": [
        "AnyTool",
        "ToolLLM",
        "GPT-4 variant tailored for tool utilization",
        "ToolLLaMA",
        "GPT-4 w/ DFSDT",
        "GPT-4 w/ CoT",
        "GPT-3.5 w/ CoT",
        "GPT-3.5 w/ DFSDT",
        "GPT-4 Plain Agent",
        "GPT-4 AutoGen-RAG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Understanding the Capability of Large Language Models on Code Clone Detection A Survey": {
    "filename": "Towards Understanding the Capability of Large Language Models on Code Clone Detection A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "BigCloneBench",
        "CodeNet"
      ],
      "models": [
        "LLaMA",
        "Alpaca",
        "Vicuna",
        "StarChat-\u03b2",
        "Falcon",
        "MPT",
        "LLaMA2",
        "LLaMA2-Chat",
        "GPT-3.5-Turbo",
        "GPT-4",
        "CodeBERT-base",
        "CodeBERT-mlm",
        "Text-embedding-ada-002",
        "SourcererCC",
        "CCFinder",
        "NiCad",
        "Deckard",
        "CCAligner",
        "Oreo",
        "LVMapper",
        "NIL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on Compositional Learning of AI Models Theoretical and Experimetnal Practices": {
    "filename": "A Survey on Compositional Learning of AI Models Theoretical and Experimetnal Practices.pdf",
    "analysis": {
      "benchmarks": [
        "CREPE",
        "SCAN",
        "gSCAN",
        "PCFG SET",
        "COGS",
        "ReaSCAN",
        "SQOOP",
        "CLUTRR",
        "KiloGram",
        "CompMCTG",
        "MIT-States",
        "Skill-Mix",
        "CFQ"
      ],
      "models": [
        "LSTMS2S",
        "ConvS2S",
        "Transformer",
        "GroCoT",
        "VisProg",
        "RegularGPT",
        "Neural Modular Network",
        "LEFT",
        "HOUDINI"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Using Artificial Intelligence to Unlock Crowdfunding Success for Small Businesses": {
    "filename": "Using Artificial Intelligence to Unlock Crowdfunding Success for Small Businesses.pdf",
    "analysis": {
      "benchmarks": [
        "GoFundMe small-business-relief campaigns"
      ],
      "models": [
        "LightGBM",
        "ChatGPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models": {
    "filename": "Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "curated dataset tailored to precision-oriented LegalAI tasks",
        "real-world dataset of house prices"
      ],
      "models": [
        "Large Language Models (LLMs)",
        "OpenAI GPT-3.5",
        "OpenAI GPT-4",
        "Claude AI",
        "Google Bard with Gemini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification": {
    "filename": "Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "MATH",
        "MATH500",
        "MBPP",
        "MagiCoder-75k"
      ],
      "models": [
        "Math-Rev",
        "Code-Rev",
        "Qwen-72B-Instruct",
        "LLaMA2-7B-base",
        "Mistral-7B-v0.1",
        "Gemma-7B-it",
        "Phi-14B",
        "InternLM2-Math-7B",
        "LLaMA3-70B",
        "LLaMA3-8B-instruct",
        "Mistral-7B-v0.3",
        "CodeGemma-7B-it",
        "CodeQwen1.5",
        "DeepseekV2-chat-Lite",
        "Math-Shepard",
        "Math-Minos",
        "GPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Vision-Language Instruction Tuning A Review and Analysis": {
    "filename": "Vision-Language Instruction Tuning A Review and Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "LLaVA-Instruct-150K",
        "cc_sbu_align",
        "VideoChat",
        "X-LLM",
        "DetGPT",
        "MULTIS",
        "pandagpt_vid",
        "PMC-VQA",
        "GPT4Tools",
        "M3IT",
        "MIMIC-IT",
        "Video-ChatGPT",
        "MULTIINSTRUCT",
        "Video-LLaMA",
        "Valley-Instruct-73k",
        "MultiModal-GPT",
        "InstructBLIP",
        "MACAW-LLM",
        "LAMM",
        "OphGLM",
        "LLaVAR",
        "Shikra-RD",
        "PF-1M",
        "GPT4RoI",
        "SVIT",
        "GRIT-20M",
        "BuboGPT",
        "MGVLID",
        "Lynx",
        "Multimodal_id_v1",
        "AS-1B",
        "I4",
        "StableLLaVA",
        "M-HalDetect",
        "VIGC",
        "PointLLM",
        "CIEM",
        "GPTVQA",
        "T2M",
        "MosIT",
        "PVIT",
        "TextBind",
        "DreamLLM",
        "AnyMAL",
        "InternLM-XComposer",
        "SparklesDialogue-VG",
        "SparklesDialogue-CC",
        "Ferret",
        "MiniGPT-v2",
        "ComVint",
        "GranD",
        "LVIS-INSTRUCT4V"
      ],
      "models": [
        "LLaVA",
        "Mini-GPT4",
        "mPLUG-Owl",
        "VideoChat",
        "VisionLLM",
        "X-LLM",
        "DetGPT",
        "ChatBridge",
        "PandaGPT",
        "MedVInT-TE/TD",
        "GPT4Tools",
        "LLaVA-Med",
        "Ying-VLM",
        "Otter",
        "Video-ChatGPT",
        "OFAmultiinstruct",
        "Video-LLaMA",
        "VALLEY",
        "MultiModal-GPT",
        "InstructBLIP",
        "MACAW-LLM",
        "LAMM",
        "OphGLM",
        "LLaVAR",
        "Shikra",
        "Clever Flamingo",
        "GPT4RoI",
        "SVIT",
        "KOSMOS-2",
        "BuboGPT",
        "ChatSpot",
        "ImageBind-LLM",
        "Lynx",
        "LMEye(IPN)",
        "ASM",
        "Cheetor",
        "BLIVA",
        "StableLLAVA",
        "Qwen-VL",
        "VIGC",
        "PointLLM",
        "MLLM-DataEngine",
        "NExT-GPT",
        "PVIT",
        "TextBind",
        "DreamLLM",
        "AnyMAL",
        "InternLM-XComposer",
        "SparklesChat",
        "LLaVA 1.5",
        "CogVLM",
        "Ferret",
        "MiniGPT-v2",
        "GLaMM",
        "SEED-LLaMA",
        "OtterHD",
        "mPLUG-Owl2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do LLMs Have Political Correctness Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems": {
    "filename": "Do LLMs Have Political Correctness Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems.pdf",
    "analysis": {
      "benchmarks": [
        "JailBreakBench"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4",
        "GPT-4-o",
        "Llama2-7B",
        "Llama2-13B",
        "Llama3-7B",
        "Phi-mini-7B",
        "Qwen1.5",
        "Qwen2-7B"
      ]
    }
  },
  "Do Advanced Language Models Eliminate the Need for Prompt Engineering in Software Engineering": {
    "filename": "Do Advanced Language Models Eliminate the Need for Prompt Engineering in Software Engineering.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "CodeTrans",
        "CodeSearchNet"
      ],
      "models": [
        "GPT-4o",
        "o1",
        "o1-mini",
        "ChatGPT-3.5",
        "AgentCoder",
        "Self-collaboration",
        "LDB",
        "S&G",
        "Unitrans",
        "LostinTransl",
        "ASAP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models can Implement Policy Iteration": {
    "filename": "Large Language Models can Implement Policy Iteration.pdf",
    "analysis": {
      "benchmarks": [
        "chain",
        "distractor-chain",
        "maze",
        "mini-catch",
        "mini-invaders",
        "point-mass"
      ],
      "models": [
        "ICPI",
        "OPT-30B",
        "GPT-J",
        "Codex",
        "InCoder",
        "code-davinci-001",
        "No arg max",
        "Tabular Q",
        "Nearest Neighbor",
        "Matching Model"
      ]
    }
  },
  "Large Language Models and Simple Stupid Bugs": {
    "filename": "Large Language Models and Simple Stupid Bugs.pdf",
    "analysis": {
      "benchmarks": [
        "ManySStuBs4J"
      ],
      "models": [
        "Codex",
        "CodeGen",
        "PolyCoder",
        "CodeTrans"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Interactive Speculative Planning Enhance Agent Efficiency through Co-design of System and User Interface": {
    "filename": "Interactive Speculative Planning Enhance Agent Efficiency through Co-design of System and User Interface.pdf",
    "analysis": {
      "benchmarks": [
        "OpenAGI",
        "TravelPlanner"
      ],
      "models": [
        "Interactive Speculative Planning",
        "ReAct",
        "Chain-of-Thought (CoT)",
        "Multi-Agent Debate (MAD)",
        "Direct-Generation (DG)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can LLMs plan paths with extra hints from solvers": {
    "filename": "Can LLMs plan paths with extra hints from solvers.pdf",
    "analysis": {
      "benchmarks": [
        "Blocksworld",
        "Maze",
        "Scots",
        "Box Boundary",
        "Easy",
        "Wall",
        "Box",
        "Canyon",
        "Diagonal Wall",
        "Curve",
        "Spiral",
        "1 Obs",
        "2 Obs",
        "3 Obs",
        "4 Obs",
        "5 Obs"
      ],
      "models": [
        "GPT-4o",
        "Gemini Pro 1.5",
        "Claude 3.5 Sonnet"
      ]
    }
  },
  "Integrating Planning into Single-Turn Long-Form Text Generation": {
    "filename": "Integrating Planning into Single-Turn Long-Form Text Generation.pdf",
    "analysis": {
      "benchmarks": [
        "SciNews",
        "KILT-Wiki",
        "FreshWiki"
      ],
      "models": [
        "Gemini Pro",
        "Gemini Ultra",
        "Gemini 1.5 Flash"
      ]
    }
  },
  "Large Language Models can Share Images Too": {
    "filename": "Large Language Models can Share Images Too.pdf",
    "analysis": {
      "benchmarks": [
        "PHOTO CHAT++",
        "PHOTO CHAT",
        "MMDialog"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "VICUNA 13B",
        "FALCON INSTRUCT",
        "LLAMA2 CHAT 70B",
        "ALBERT-base",
        "BERT-base",
        "T5-base",
        "T5-3B",
        "ViLT",
        "PaCE",
        "CLIP",
        "BLIP",
        "ALIGN",
        "DialCLIP",
        "LLaVA v1.5 7B",
        "LLaVA v1.5 13B",
        "MiniGPT-4 Vicuna 7B",
        "MiniGPT-4 Vicuna 13B",
        "Qwen-VL-Chat 7B",
        "GPT4-V"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Parse-Execute to Parse-Execute-Refine Improving Semantic Parser for Complex Question Answering over Knowledge Base": {
    "filename": "From Parse-Execute to Parse-Execute-Refine Improving Semantic Parser for Complex Question Answering over Knowledge Base.pdf",
    "analysis": {
      "benchmarks": [
        "KQAPro",
        "MetaQA",
        "WebQSP",
        "LC-QuAD"
      ],
      "models": [
        "KoPL",
        "PER-KBQA",
        "BART-based KoPL",
        "KaFSP",
        "RnG-KBQA",
        "KVMemNet",
        "SRN",
        "EmbedKGQA",
        "RGCN",
        "GraphQ IR"
      ]
    }
  },
  "What Factors Affect Multi-Modal In-Context Learning An In-Depth Exploration": {
    "filename": "What Factors Affect Multi-Modal In-Context Learning An In-Depth Exploration.pdf",
    "analysis": {
      "benchmarks": [
        "M3IT",
        "M3CoT"
      ],
      "models": [
        "OpenFlamingo",
        "Otter",
        "Qwen-VL",
        "GPT4V",
        "IDEFICS2",
        "Gemini-Pro",
        "Multi-Modal Retriever",
        "Textual Retriever",
        "Visual Retriever"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Distractor generation for multiple-choice questions with predictive prompting and large language models": {
    "filename": "Distractor generation for multiple-choice questions with predictive prompting and large language models.pdf",
    "analysis": {
      "benchmarks": [
        "Wezooz test data"
      ],
      "models": [
        "Zero-ChatGPT",
        "Dynamic-Demo-ChatGPT",
        "Static-Demo-ChatGPT",
        "DQ-SIM",
        "mT5"
      ]
    }
  },
  "Constitutional AI Harmlessness from AI Feedback": {
    "filename": "Constitutional AI Harmlessness from AI Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "PALMS",
        "InstructGPT",
        "LaMDA"
      ],
      "models": [
        "Constitutional AI (CAI)",
        "RL-CAI",
        "SL-CAI",
        "Helpful RLHF",
        "HH RLHF",
        "RL-CAI w/ CoT",
        "Pretrained LM",
        "Feedback Model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond Numbers Creating Analogies to Enhance Data Comprehension and Communication with Generative AI": {
    "filename": "Beyond Numbers Creating Analogies to Enhance Data Comprehension and Communication with Generative AI.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "AnalogyMate",
        "GPT-3.5",
        "Stable Diffusion"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Knowledge Distillation Using Frontier Open-source LLMs Generalizability and the Role of Synthetic Data": {
    "filename": "Knowledge Distillation Using Frontier Open-source LLMs Generalizability and the Role of Synthetic Data.pdf",
    "analysis": {
      "benchmarks": [
        "Griffin CoD",
        "GovReport",
        "BBCNews",
        "Alpaca",
        "Quora",
        "AQUA-RAT",
        "GSM8K",
        "MultiArith",
        "SV AMP",
        "ANLI",
        "ConjNLI",
        "ConTRoL",
        "HELP",
        "AI2_ARC",
        "CommonSense QA",
        "QASC",
        "RiddleSense"
      ],
      "models": [
        "Llama-3.1-405B-Instruct",
        "Llama-3.1-8B-Instruct",
        "Llama-3.1-70B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt to GPT-3 Step-by-Step Thinking Instructions for Humor Generation": {
    "filename": "Prompt to GPT-3 Step-by-Step Thinking Instructions for Humor Generation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3",
        "GPT-2",
        "neural network model by Zhang et al.",
        "proposed method with step-by-step thinking instructions"
      ]
    }
  },
  "InferCept Efficient Intercept Support for Augmented Large Language Model Inference": {
    "filename": "InferCept Efficient Intercept Support for Augmented Large Language Model Inference.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K-XL",
        "Multihop QA Wikipedia",
        "ALFWorld",
        "ShareGPT"
      ],
      "models": [
        "INFER CEPT",
        "vLLM",
        "Preserve",
        "Swap",
        "GPT-J-6B",
        "Vicuna-13B",
        "Llama3-70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "In-Context Impersonation Reveals Large Language Models Strengths and Biases": {
    "filename": "In-Context Impersonation Reveals Large Language Models Strengths and Biases.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "Caltech UCSD Birds (CUB)",
        "Stanford Cars",
        "FGVC Aircraft",
        "Oxford Flowers"
      ],
      "models": [
        "Vicuna-13B",
        "ChatGPT (gpt-3.5-turbo)",
        "CLIP ViT-B/32",
        "CLIP ViT-B/16",
        "OpenCLIP ViT-B/32"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ProSLM A Prolog Synergized Language Model for explainable Domain Specific Knowledge Based Question Answering": {
    "filename": "ProSLM A Prolog Synergized Language Model for explainable Domain Specific Knowledge Based Question Answering.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ProSLM",
        "GPT 3.5",
        "ChatGPT",
        "Neuro-Symbolic Concept Learner",
        "Logic-LM"
      ]
    }
  },
  "Brain-to-Text Decoding with Context-Aware Neural Representations and Large Language Models": {
    "filename": "Brain-to-Text Decoding with Context-Aware Neural Representations and Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Brain-to-Text 2024"
      ],
      "models": [
        "DCoND",
        "DCoND-L",
        "DCoND-LI",
        "DCoND-LIFT",
        "NPTL",
        "LISA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Does the Most Sinfully Decadent Cake Ever Taste Good Answering YesNo Questions from Figurative Contexts": {
    "filename": "Does the Most Sinfully Decadent Cake Ever Taste Good Answering YesNo Questions from Figurative Contexts.pdf",
    "analysis": {
      "benchmarks": [
        "FigurativeQA",
        "Amazon product reviews",
        "Yelp restaurant reviews",
        "BoolQ"
      ],
      "models": [
        "BERT-based QA models",
        "GPT-3",
        "ChatGPT",
        "RoBERTa-based QA model",
        "RoBERTa-finetuned-on-BoolQ",
        "GPT-3-finetuned-FLUTE",
        "ChatGPT with chain-of-thought prompting"
      ]
    }
  },
  "Bugs in Large Language Models Generated Code An Empirical Study": {
    "filename": "Bugs in Large Language Models Generated Code An Empirical Study.pdf",
    "analysis": {
      "benchmarks": [
        "CoderEval"
      ],
      "models": [
        "CodeGen",
        "PanGu-Coder",
        "Codex"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards More Unified In-Context Visual Understanding": {
    "filename": "Towards More Unified In-Context Visual Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "MS-COCO",
        "Visual Genome",
        "LVIS"
      ],
      "models": [
        "SegGPT",
        "Flamingo",
        "OpenFlamingo",
        "FPTrans",
        "V AT",
        "DCAMA",
        "GRiT",
        "GPT-2",
        "Ours"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Motif Intrinsic Motivation from Artificial Intelligence Feedback": {
    "filename": "Motif Intrinsic Motivation from Artificial Intelligence Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "NetHack Learning Environment",
        "score task",
        "staircase",
        "staircase (level 3)",
        "staircase (level 4)",
        "oracle task"
      ],
      "models": [
        "Motif",
        "Extrinsic only",
        "RND (ext.+int.)",
        "CDGPT5 baseline",
        "E3B",
        "NovelD"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Concise and Organized Perception Facilitates Reasoning in Large Language Models": {
    "filename": "Concise and Organized Perception Facilitates Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ProofWriter",
        "PrOntoQA",
        "PrOntoQA-OOD",
        "FOLIO",
        "DI-GSM"
      ],
      "models": [
        "Concise and Organized Perception (COP)",
        "Chain-of-thought (CoT)",
        "Selection-Inference (SI)",
        "LOGIC-LM",
        "LAMBADA",
        "Standard Few-Shot"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMs Are In-Context Reinforcement Learners": {
    "filename": "LLMs Are In-Context Reinforcement Learners.pdf",
    "analysis": {
      "benchmarks": [
        "Banking-77",
        "Clinic-150",
        "NLU",
        "TREC",
        "TREC-fine"
      ],
      "models": [
        "Llama 3.1",
        "Phi-3.5-mini",
        "Naive ICRL",
        "Explorative ICRL",
        "Approximate ICRL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science": {
    "filename": "Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science.pdf",
    "analysis": {
      "benchmarks": [
        "Kaggle",
        "UCI Machine Learning Repository",
        "public tabular benchmarks"
      ],
      "models": [
        "Llama-2",
        "XGBoost",
        "NODE",
        "AutoInt",
        "Tapas",
        "TaBERT",
        "TabTransformer",
        "FT-Transformer",
        "TabNet",
        "TUTA",
        "TabPFN",
        "XTab",
        "GANDALF",
        "TabLLM",
        "GPT-4",
        "Llama-2 7B",
        "Llama-2 7B 80K"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Prompting-Based Representation Learning Method for Recommendation with Large Language Models": {
    "filename": "A Prompting-Based Representation Learning Method for Recommendation with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Yelp2018",
        "Amazon-VideoGames"
      ],
      "models": [
        "P4R",
        "NGCF",
        "LightGCN",
        "SGL",
        "P4R-WIP",
        "P4R-B32",
        "P4R-B128",
        "P4R-B256",
        "P4R-WT",
        "Random"
      ]
    }
  },
  "Ghost in the Minecraft Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory": {
    "filename": "Ghost in the Minecraft Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory.pdf",
    "analysis": {
      "benchmarks": [
        "ObtainDiamond task",
        "Minecraft Overworld Technology Tree"
      ],
      "models": [
        "Ghost in the Minecraft (GITM)",
        "VPT",
        "DreamerV3",
        "DEPS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PatternGPT A Pattern-Driven Framework for Large Language Model Text Generation": {
    "filename": "PatternGPT A Pattern-Driven Framework for Large Language Model Text Generation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "PatternGPT",
        "ChatGPT",
        "GPT-4"
      ]
    }
  },
  "Black-Box Access is Insufficient for Rigorous AI Audits": {
    "filename": "Black-Box Access is Insufficient for Rigorous AI Audits.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book": {
    "filename": "Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book.pdf",
    "analysis": {
      "benchmarks": [
        "FLORES",
        "Machine Translation from One Book (MTOB)",
        "Dictionaria"
      ],
      "models": [
        "Gemini",
        "Llama-3.1-8B",
        "Llama-Instruct",
        "Llama-ft",
        "NLLB-1.3B-Distilled",
        "Gemini-ft",
        "BYT5-FT",
        "GLOSSLM-FT",
        "SMP-BASE",
        "T\u00dcCL-MORPH",
        "TOP-CLASS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal Large Language Models": {
    "filename": "Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMBench",
        "MME",
        "MMVet"
      ],
      "models": [
        "IoT prompting",
        "GPT-4",
        "Gemini-Pro",
        "MiniGPT-4",
        "LLaVA-v1.5-13B",
        "InternLM-XComposer2-VL",
        "Qwen-VL-Plus",
        "Qwen-VL-Max"
      ]
    }
  },
  "A Multi-Source Retrieval Question Answering Framework Based on RAG": {
    "filename": "A Multi-Source Retrieval Question Answering Framework Based on RAG.pdf",
    "analysis": {
      "benchmarks": [
        "2WikiMultiHopQA",
        "HotpotQA",
        "StrategyQA"
      ],
      "models": [
        "MSRAG",
        "No-RAG",
        "SR-RAG",
        "FL-RAG",
        "FLARE",
        "FS-RAG",
        "GPT-Retrieval",
        "w/oGPT",
        "w/oWeb"
      ]
    }
  },
  "Interactive-Chain-Prompting Ambiguity Resolution for Crosslingual Conditional Generation with Interaction": {
    "filename": "Interactive-Chain-Prompting Ambiguity Resolution for Crosslingual Conditional Generation with Interaction.pdf",
    "analysis": {
      "benchmarks": [
        "AMBIG MT",
        "Opensubtitles"
      ],
      "models": [
        "INTER CPT",
        "PaLM",
        "PaLM-with-context",
        "PaLM-no-extras",
        "Google Cloud Translation v2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-consistent Reasoning For Solving Math Word Problems": {
    "filename": "Self-consistent Reasoning For Solving Math Word Problems.pdf",
    "analysis": {
      "benchmarks": [
        "Math23k",
        "Ape210k"
      ],
      "models": [
        "SCR",
        "roberta2tree",
        "NS-Solver",
        "NumS2T",
        "TSN-MD",
        "MATH-EN",
        "Graph2Tree",
        "Multi-E/D",
        "GTS",
        "Tree-Decoder",
        "Ape",
        "StackDecoder",
        "KAS2T",
        "GenerateRank",
        "DeductReasoner",
        "source network",
        "sub-network"
      ]
    }
  },
  "MP5 A Multi-modal Open-ended Embodied System in Minecraft via Active Perception": {
    "filename": "MP5 A Multi-modal Open-ended Embodied System in Minecraft via Active Perception.pdf",
    "analysis": {
      "benchmarks": [
        "MineDojo"
      ],
      "models": [
        "MP5",
        "MineLLM",
        "VPT",
        "Steve-1",
        "Voyager",
        "DEPS",
        "GITM",
        "DreamerV3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can LLMs Keep a Secret Testing Privacy Implications of Language Models via Contextual Integrity Theory": {
    "filename": "Can LLMs Keep a Secret Testing Privacy Implications of Language Models via Contextual Integrity Theory.pdf",
    "analysis": {
      "benchmarks": [
        "CONFAIDE"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "Davinci1",
        "Llama-2 Chat (70B)",
        "Llama 2 (70B)",
        "Mixtral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Groma Localized Visual Tokenization for Grounding Multimodal Large Language Models": {
    "filename": "Groma Localized Visual Tokenization for Grounding Multimodal Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "RefCOCO",
        "RefCOCO+",
        "RefCOCOg",
        "LVIS-Ground",
        "Visual Genome",
        "Flickr30k Entities",
        "LLaVA Bench (COCO)"
      ],
      "models": [
        "Groma",
        "MDETR",
        "G-DINO",
        "UNINEXT-L",
        "VisionLLM",
        "OFA",
        "Shikra",
        "Ferret",
        "MiniGPT-v2",
        "Qwen-VL",
        "Kosmos-2",
        "GPT4RoI",
        "GLaMM",
        "LLaVA",
        "LLaVA-G"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do Prompts Really Prompt Exploring the Prompt Understanding Capability of Whisper": {
    "filename": "Do Prompts Really Prompt Exploring the Prompt Understanding Capability of Whisper.pdf",
    "analysis": {
      "benchmarks": [
        "GigaSpeech",
        "ASCEND",
        "CSZS-correct-zh",
        "CSZS-correct-fr"
      ],
      "models": [
        "Whisper",
        "Whisper-large-v3"
      ]
    }
  },
  "Beyond Generating Code Evaluating GPT on a Data Visualization Course": {
    "filename": "Beyond Generating Code Evaluating GPT on a Data Visualization Course.pdf",
    "analysis": {
      "benchmarks": [
        "CS171 course assignments"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "Towards a Unified Multimodal Reasoning Framework": {
    "filename": "Towards a Unified Multimodal Reasoning Framework.pdf",
    "analysis": {
      "benchmarks": [
        "TextVQA",
        "ScienceQA"
      ],
      "models": [
        "GPT-4",
        "T5",
        "DistilBERT",
        "RoBERTa",
        "ViLT",
        "VisualBERT",
        "DETR",
        "ViT-GPT2",
        "Baseline pre-trained T5 model",
        "Model 1",
        "Model 2",
        "Model 3",
        "Model 4",
        "Model 5",
        "Model 6"
      ]
    }
  },
  "How do Large Language Models Navigate Conflicts between Honesty and Helpfulness": {
    "filename": "How do Large Language Models Navigate Conflicts between Honesty and Helpfulness.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5 Turbo",
        "GPT-4",
        "GPT-4 Turbo",
        "LLaMA 2 70B chat",
        "LLaMA 2 70B",
        "Mixtral 8x7B instruct v0.1",
        "Mixtral 8x7B v0.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Sycophancy to Subterfuge Investigating Reward-Tampering in Large Language Models": {
    "filename": "Sycophancy to Subterfuge Investigating Reward-Tampering in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "political sycophancy dataset",
        "tool-use flattery environment",
        "rubric modification environment",
        "reward-tampering environment"
      ],
      "models": [
        "Claude-2",
        "helpful-only model",
        "HHH expert iteration model",
        "exploit-only expert iteration model",
        "PPO model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Iteratively Prompt Pre-trained Language Models for Chain of Thought": {
    "filename": "Iteratively Prompt Pre-trained Language Models for Chain of Thought.pdf",
    "analysis": {
      "benchmarks": [
        "2WikiMultiHopQA",
        "R4C",
        "LoT"
      ],
      "models": [
        "Iterative Context-Aware Prompter (iCAP)",
        "Prompt Tuning (Prompt-T)",
        "Prefix Tuning (Prefix-T)",
        "PLM fine-tuning (PLM-FT)",
        "PLM-QA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CodeChain Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules": {
    "filename": "CodeChain Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules.pdf",
    "analysis": {
      "benchmarks": [
        "APPS",
        "CodeContests"
      ],
      "models": [
        "CodeChain",
        "OpenAI LLMs",
        "WizardCoder",
        "Codex",
        "CodeT5",
        "CodeRL+CodeT5",
        "text-davinci-002",
        "Self-edit+text-davinci-002",
        "code-davinci-002",
        "GPT3.5",
        "GPT4",
        "Self-repair+GPT4",
        "Self-repair+GPT4 Human",
        "Self-debug",
        "Reflexion"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PERSOMA PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting": {
    "filename": "PERSOMA PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "MovieLens"
      ],
      "models": [
        "PERSOMA",
        "PaLM 2",
        "UEM Base",
        "UEM Large",
        "Gemini 1.5 Pro",
        "PERSOMA MLP",
        "PERSOMA Perceiver",
        "PERSOMA Transformer"
      ]
    }
  },
  "Battle of the Large Language Models Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison": {
    "filename": "Battle of the Large Language Models Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison.pdf",
    "analysis": {
      "benchmarks": [
        "Academic",
        "ATIS",
        "GeoQuery",
        "Yelp",
        "IMDB",
        "Restaurants",
        "Scholar",
        "Advising",
        "Spider"
      ],
      "models": [
        "Dolly",
        "LLaMA",
        "Vicuna",
        "Guanaco",
        "Bard",
        "ChatGPT",
        "GPT-3.5",
        "Bard-L",
        "Bard-P2",
        "Dolly v2-3b",
        "Dolly v2-7b",
        "Dolly v2-12b",
        "Vicuna 7B",
        "Vicuna 13B",
        "Guanaco 33B",
        "LLaMA 7B",
        "LLaMA 13B",
        "LLaMA 30B",
        "LLaMA 65B",
        "GPT-3.5-turbo-0301"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Deep Tensor Network": {
    "filename": "Deep Tensor Network.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Tensor Attention",
        "Tensor Interaction",
        "Linear Tensor Attention",
        "TensorAttention MatrixExponential",
        "TensorInteraction MatrixExponential"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Language Models as Compilers Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models": {
    "filename": "Language Models as Compilers Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Dyck Languages",
        "Geometric Shapes",
        "Navigate",
        "Reasoning about Colored Objects",
        "Temporal Sequences",
        "Tracking Shuffled Objectives",
        "Web of Lies"
      ],
      "models": [
        "THINK-AND-EXECUTE",
        "Chain-of-Thought",
        "Program-of-Thought",
        "Zero-shot CoT",
        "Zero-shot PoT",
        "NL Planning",
        "Direct Prompting",
        "Plan-and-Solve",
        "Chain-of-Code",
        "Self-Discover"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Using Large Language Models for Commit Message Generation A Preliminary Study": {
    "filename": "Using Large Language Models for Commit Message Generation A Preliminary Study.pdf",
    "analysis": {
      "benchmarks": [
        "BLEU",
        "Rouge-L"
      ],
      "models": [
        "ChatGPT",
        "Llama 2",
        "CommitGen",
        "NMT",
        "CoDiSum",
        "PtrGNCMsg",
        "NNGen"
      ]
    }
  },
  "A Simple and Effective Pruning Approach for Large Language Models": {
    "filename": "A Simple and Effective Pruning Approach for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "EleutherAI LM Harness",
        "WikiText"
      ],
      "models": [
        "Wanda",
        "LLaMA",
        "LLaMA-2",
        "SparseGPT",
        "Magnitude Pruning"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SIaM Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models": {
    "filename": "SIaM Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "APE",
        "CM",
        "CMATH",
        "MathBench"
      ],
      "models": [
        "SIAM",
        "GPT-4",
        "Llama3-8B",
        "DeepSeek-Coder-7B",
        "Qwen2-7B",
        "CodeLlama-7B-Python",
        "QWEN2Math instruct",
        "DeepSeek code",
        "Llama3 instruct",
        "MathCoder",
        "ToRA",
        "MathGenieLM",
        "MinT",
        "ChatGLM-Math",
        "Skywork-Math",
        "Math-InternLM2",
        "MetaMath"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Element-aware Summarization with Large Language Models Expert-aligned Evaluation and Chain-of-Thought Method": {
    "filename": "Element-aware Summarization with Large Language Models Expert-aligned Evaluation and Chain-of-Thought Method.pdf",
    "analysis": {
      "benchmarks": [
        "CNN/DailyMail",
        "BBC XSum",
        "Element-aware test sets"
      ],
      "models": [
        "BART-BASE",
        "BART-LARGE",
        "T5-LARGE",
        "PEGASUS-LARGE",
        "175B GPT-3",
        "Summary Chain-of-Thought (SumCoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Hacking The Lazy Way LLM Augmented Pentesting": {
    "filename": "Hacking The Lazy Way LLM Augmented Pentesting.pdf",
    "analysis": {
      "benchmarks": [
        "boot2root box"
      ],
      "models": [
        "Pentest Copilot",
        "GPT-3.5-Turbo",
        "GPT-4",
        "GPT-4-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Rethinking harmless refusals when fine-tuning foundation models": {
    "filename": "Rethinking harmless refusals when fine-tuning foundation models.pdf",
    "analysis": {
      "benchmarks": [
        "car sales",
        "real estate",
        "stock trader"
      ],
      "models": [
        "gpt-4-0613",
        "gpt-4-1106-preview",
        "gpt-4-0125-preview",
        "gpt-4-vision-preview"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Foundation Models Wrangle Your Data": {
    "filename": "Can Foundation Models Wrangle Your Data.pdf",
    "analysis": {
      "benchmarks": [
        "Magellan",
        "Synthea",
        "TDE",
        "Restaurants",
        "Buy",
        "Hospital",
        "Adult"
      ],
      "models": [
        "GPT-3-175B",
        "Ditto",
        "IMP",
        "HoloClean",
        "SMAT",
        "HoloDetect"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Intelligent Go-Explore Standing on the Shoulders of Giant Foundation Models": {
    "filename": "Intelligent Go-Explore Standing on the Shoulders of Giant Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "Atari games",
        "BabyAI",
        "TextWorld",
        "Game of 24"
      ],
      "models": [
        "Intelligent Go-Explore (IGE)",
        "Classic Go-Explore",
        "Reflexion",
        "ReAct",
        "Naive LLM",
        "DFS",
        "BFS",
        "GLAM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Semantic-Enhanced Indirect Call Analysis with Large Language Models": {
    "filename": "Semantic-Enhanced Indirect Call Analysis with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "oss-fuzz",
        "bind9",
        "cairo",
        "dovecot",
        "gdbm",
        "hdf5",
        "krb5",
        "libjpeg-turbo",
        "libsndfile",
        "librabbitmq",
        "lua",
        "lxc",
        "mdbtools",
        "nginx",
        "opensips",
        "pjsip",
        "rtpproxy",
        "selinux",
        "sudo",
        "tmux",
        "vlc"
      ],
      "models": [
        "SEA",
        "FLTA",
        "MLTA",
        "Kelp",
        "Qwen1.5-72B-Chat",
        "LLaMA3-70B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SCREWS A Modular Framework for Reasoning with Revisions": {
    "filename": "SCREWS A Modular Framework for Reasoning with Revisions.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "StrategyQA",
        "Big-Bench AutoDebugging"
      ],
      "models": [
        "SCREWS",
        "ChatGPT",
        "GPT-4",
        "Chain of Thought (CoT)",
        "Subquestion Decomposition",
        "Answer Only",
        "Self-Ask",
        "Tool-Based LLM",
        "Self-Select",
        "Majority Voting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do Chase Your Tail Missing Key Aspects Augmentation in Textual Vulnerability Descriptions of Long-tail Software through Feature Inference": {
    "filename": "Do Chase Your Tail Missing Key Aspects Augmentation in Textual Vulnerability Descriptions of Long-tail Software through Feature Inference.pdf",
    "analysis": {
      "benchmarks": [
        "CVE",
        "NVD",
        "NVD*"
      ],
      "models": [
        "PMA",
        "BERT",
        "LLaMA",
        "GPT-3.5",
        "GPT-4",
        "T5",
        "RoBERTa",
        "LSTM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MemoChat Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain Conversation": {
    "filename": "MemoChat Tuning LLMs to Use Memos for Consistent Long-Range Open-Domain Conversation.pdf",
    "analysis": {
      "benchmarks": [
        "MT-Bench+"
      ],
      "models": [
        "MemoChat",
        "Fastchat-T5-3B",
        "Vicuna-7B",
        "Vicuna-13B",
        "Vicuna-33B",
        "ChatGPT-2k",
        "MPC-ChatGPT",
        "MemoryBank-ChatGPT",
        "MemoChat-ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning How To Ask Cycle-Consistency Refines Prompts in Multimodal Foundation Models": {
    "filename": "Learning How To Ask Cycle-Consistency Refines Prompts in Multimodal Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "VQAv2",
        "FigureQA"
      ],
      "models": [
        "CyclePrompt",
        "GPT4",
        "GPT4V",
        "PARSEL",
        "METAGPT",
        "ANPL",
        "OCTOPACK",
        "REFLEXION",
        "LATS"
      ]
    }
  },
  "Improving Interpersonal Communication by Simulating Audiences with Language Models": {
    "filename": "Improving Interpersonal Communication by Simulating Audiences with Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Stanford Human Preferences (SHP) dataset"
      ],
      "models": [
        "Explore-Generate-Simulate (EGS) framework",
        "GPT-4 zero-shot",
        "Chain-of-Thought (CoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Code Generation Tools Almost for Free A Study of Few-Shot Pre-Trained Language Models on Code": {
    "filename": "Code Generation Tools Almost for Free A Study of Few-Shot Pre-Trained Language Models on Code.pdf",
    "analysis": {
      "benchmarks": [
        "Colt",
        "ElasticSearch",
        "GWT",
        "GraphStream",
        "Guava",
        "Hibernate",
        "JDK",
        "Commons Math",
        "Weka"
      ],
      "models": [
        "Codex",
        "Major",
        "MeMo",
        "Randoop",
        "FSLM-based code mutation tool",
        "FSLM-based oracle generator",
        "FSLM-based test generator"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ForgerySleuth Empowering Multimodal Large Language Models for Image Manipulation Detection": {
    "filename": "ForgerySleuth Empowering Multimodal Large Language Models for Image Manipulation Detection.pdf",
    "analysis": {
      "benchmarks": [
        "ForgeryAnalysis-Eval",
        "Columbia",
        "Coverage",
        "CASIA1",
        "NIST16",
        "IMD20",
        "COCOGlide",
        "MIML",
        "CASIA2",
        "DEFACTO",
        "AutoSplice"
      ],
      "models": [
        "ForgerySleuth",
        "GPT-4o",
        "Qwen-VL",
        "Qwen2-VL-7B-instruct",
        "LISA-7B-v1-explanatory",
        "Mantra-Net",
        "SPAN",
        "MVSS-Net",
        "PSCC-Net",
        "CAT-Net2",
        "TruFor",
        "UnionFormer",
        "ObjectFormer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Assessing the Impact of Prompting Methods on ChatGPTs Mathematical Capabilities": {
    "filename": "Assessing the Impact of Prompting Methods on ChatGPTs Mathematical Capabilities.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "MMLU"
      ],
      "models": [
        "ChatGPT-3.5"
      ]
    }
  },
  "Automating Venture Capital Founder assessment using LLM-powered segmentation feature engineering and automated labeling techniques": {
    "filename": "Automating Venture Capital Founder assessment using LLM-powered segmentation feature engineering and automated labeling techniques.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "linear regression",
        "random forest",
        "XGBoost"
      ]
    }
  },
  "ChatGraph Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs": {
    "filename": "ChatGraph Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs.pdf",
    "analysis": {
      "benchmarks": [
        "20NG",
        "R8",
        "R52",
        "Ohsumed"
      ],
      "models": [
        "ChatGraph",
        "ChatGraph (with TF-IDF)",
        "TextGCN (1 layer)",
        "TextGCN (2 layers)",
        "TF-IDF+LR",
        "ChatGPT"
      ]
    }
  },
  "MIO A Foundation Model on Multimodal Tokens": {
    "filename": "MIO A Foundation Model on Multimodal Tokens.pdf",
    "analysis": {
      "benchmarks": [
        "MS-COCO",
        "VQAv2",
        "OK-VQA",
        "VizWiz",
        "SEED-Bench",
        "Flickr30K",
        "LibriSpeech",
        "VCTK",
        "MSVDQA",
        "MSRVTT-QA"
      ],
      "models": [
        "MIO",
        "Emu1",
        "Emu2",
        "SEED-LLaMA",
        "AnyGPT",
        "CM3Leon",
        "Chameleon",
        "Gemini",
        "Transfusion",
        "Flamingo",
        "Kosmos-1",
        "MetaLM",
        "IDEFICS",
        "InstructBLIP",
        "Wav2vec 2.0",
        "Whisper",
        "VALL-E",
        "USLM",
        "BLIP-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mastering Symbolic Operations Augmenting Language Models with Compiled Neural Networks": {
    "filename": "Mastering Symbolic Operations Augmenting Language Models with Compiled Neural Networks.pdf",
    "analysis": {
      "benchmarks": [
        "AddSub+"
      ],
      "models": [
        "Neural Comprehension",
        "T5",
        "GPT-3.5",
        "GPT-4",
        "vanilla fine-tuning",
        "few-shot learning",
        "Chain-of-Thought reasoning",
        "Tool-Based method",
        "T5-Small",
        "GLM-130B",
        "GPT-3.5",
        "Scratchpad",
        "Algorithmic",
        "CoT",
        "PAL",
        "llama-2-7b",
        "llama-2-70b",
        "GLM-130B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models": {
    "filename": "Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MovieLens-1M",
        "Amazon-Books"
      ],
      "models": [
        "KAR",
        "DIN",
        "DIEN",
        "DeepFM",
        "xDeepFM",
        "DCN",
        "DCNv2",
        "FiBiNet",
        "FiGNN",
        "AutoInt",
        "DLCM",
        "PRM",
        "SetRank",
        "MIR",
        "P5",
        "UniSRec",
        "VQ-Rec",
        "TALLRec",
        "LLM2DIN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "In Context Learning and Reasoning for Symbolic Regression with Large Language Models": {
    "filename": "In Context Learning and Reasoning for Symbolic Regression with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Langmuir adsorption isotherm",
        "Kepler's Law",
        "Bode's Law",
        "Hubble's Law",
        "Dual-site Langmuir adsorption isotherm",
        "Nikuradse dataset"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5-turbo",
        "Bayesian-based SR (BMS)",
        "genetic programming-based SR (PySR)",
        "mixed-integer non-linear programming-based SR",
        "Eureqa",
        "EFS (Evolutionary Feature Synthesis)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CultiVerse Towards Cross-Cultural Understanding for Paintings with Large Language Model": {
    "filename": "CultiVerse Towards Cross-Cultural Understanding for Paintings with Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "TCP Cultural Norm Dataset",
        "Cross-Cultural Understanding Benchmark (CCUB)"
      ],
      "models": [
        "CultiVerse",
        "GPT-4",
        "ChatGPT-4 Turbo",
        "GroundingDINO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MEDCO Medical Education Copilots Based on A Multi-Agent Framework": {
    "filename": "MEDCO Medical Education Copilots Based on A Multi-Agent Framework.pdf",
    "analysis": {
      "benchmarks": [
        "MVME dataset",
        "ICD-10"
      ],
      "models": [
        "MEDCO",
        "GPT-3.5",
        "GPT-4o-mini",
        "Claude3.5-Sonnet",
        "2 Agents"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TravelPlanner A Benchmark for Real-World Planning with Language Agents": {
    "filename": "TravelPlanner A Benchmark for Real-World Planning with Language Agents.pdf",
    "analysis": {
      "benchmarks": [
        "TravelPlanner"
      ],
      "models": [
        "GPT-4",
        "Gemini",
        "Mixtral",
        "ReAct",
        "Reflexion",
        "Mistral-7B-32K",
        "Mixtral-8x7B-MoE",
        "Gemini Pro",
        "GPT-3.5-Turbo",
        "GPT-4-Turbo",
        "Direct",
        "CoT",
        "ReAct GPT-3.5-Turbo",
        "Reflexion GPT-3.5-Turbo",
        "Direct Mixtral-8x7B-MoE",
        "Direct Gemini Pro",
        "Direct GPT-4-Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMD A Large Language Model for Interpreting Longitudinal Medical Records": {
    "filename": "LLMD A Large Language Model for Interpreting Longitudinal Medical Records.pdf",
    "analysis": {
      "benchmarks": [
        "PubMedQA"
      ],
      "models": [
        "LLMD",
        "LLMD-8B",
        "GPT-4o",
        "Llama3.1 8B Instruct",
        "JSL-MedLlama-3-8B",
        "BioMistral-7B",
        "Hermes-2-Pro-7B",
        "MedLM",
        "Llama-3-70B-Instr"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VIP5 Towards Multimodal Foundation Models for Recommendation": {
    "filename": "VIP5 Towards Multimodal Foundation Models for Recommendation.pdf",
    "analysis": {
      "benchmarks": [
        "Clothing",
        "Sports",
        "Beauty",
        "Toys"
      ],
      "models": [
        "VIP5",
        "P5",
        "HGN",
        "SASRec",
        "S3-Rec",
        "BPR-MF",
        "BPR-MLP",
        "VBPR",
        "Attn2Seq",
        "NRT",
        "PETER",
        "PETER+"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Complete Survey on LLM-based AI Chatbots": {
    "filename": "A Complete Survey on LLM-based AI Chatbots.pdf",
    "analysis": {
      "benchmarks": [
        "Vietnamese National High School Graduation Examination (VNHSGE)",
        "USMLE",
        "MIMIC-III clinical notes",
        "TREC CDS 2016 topics",
        "Mayo Clinic Brain Bank Clinico-Pathological Conferences"
      ],
      "models": [
        "ChatGPT",
        "GPT-3",
        "GPT-3.5",
        "GPT-4",
        "BARD",
        "Bing Chat",
        "Claude",
        "Claude 2",
        "Claude Instant",
        "Ernie Bot",
        "Med-PaLM 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "INCLUDE Evaluating Multilingual Language Understanding with Regional Knowledge": {
    "filename": "INCLUDE Evaluating Multilingual Language Understanding with Regional Knowledge.pdf",
    "analysis": {
      "benchmarks": [
        "INCLUDE",
        "ArabicMMLU",
        "ChineseMMLU",
        "TurkishMMLU",
        "PersianMMLU",
        "VNHSGE",
        "EXAMS"
      ],
      "models": [
        "GPT-4o",
        "Llama-3.1-70B-Instruct",
        "Aya-expanse-32B",
        "Qwen2.5-14B",
        "Llama-3.1-Instruct-8B",
        "Aya-expanse-8B",
        "Qwen2.5-7B",
        "Mistral-7B",
        "Gemma-7B",
        "Mistral-7B-Instruct",
        "Gemma-7B-Instruct",
        "Qwen2.5-7B-Instruct",
        "Llama-3.1-8B",
        "Llama-3.1-8B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation": {
    "filename": "Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation.pdf",
    "analysis": {
      "benchmarks": [
        "MT-Bench",
        "AlpacaEval",
        "AlpacaEval 2.0",
        "AdvBench",
        "GSM8K",
        "WMT'22"
      ],
      "models": [
        "LLaMA-2-7B-Chat",
        "Mistral-7B-Instruct-v0.2",
        "RaDis",
        "Vanilla-FT",
        "Seq-KD",
        "SDFT",
        "ParroT",
        "BigTrans",
        "BayLing-7B",
        "ALMA-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Preliminary Study of o1 in Medicine Are We Closer to an AI Doctor": {
    "filename": "A Preliminary Study of o1 in Medicine Are We Closer to an AI Doctor.pdf",
    "analysis": {
      "benchmarks": [
        "PICOMIMIC4ED",
        "MedNLI-Dis",
        "PUBHEALTH Ver.",
        "PubMedQA",
        "MedQA",
        "MedMCQA",
        "LancetQA",
        "NEJMQA",
        "Medbullets",
        "MedCalc-Bench",
        "XMedBench",
        "BC5-disease",
        "BC5Chem",
        "BC4Chem",
        "Species800",
        "HoC",
        "HumanDiseaseOntology",
        "BioLORD",
        "PMC-Patient",
        "PICO-Participant",
        "PICO-Intervention",
        "PICO-Outcome",
        "ADE Corpus",
        "MIMIC-IV-Ultrasound",
        "MIMIC-IV-CT",
        "RCT-Text",
        "MedQSum",
        "DDXPlus",
        "SEER",
        "MIMIC4ED-Hospitalization",
        "MIMIC4ED-72h ED Revisit",
        "MIMIC4ED-Critical Triage",
        "PUBHEALTH Exp.",
        "EBMS",
        "ChatDoctor",
        "MedNLI-Gen.",
        "AI Hospital",
        "AgentClinic"
      ],
      "models": [
        "o1",
        "GPT-4",
        "GPT-3.5",
        "MEDITRON-70B",
        "Llama3-8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GeoMeter Probing Depth and Height Perception of Large Visual-Language Models": {
    "filename": "GeoMeter Probing Depth and Height Perception of Large Visual-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CLEVR",
        "GeoMeter Synthetic 2D",
        "GeoMeter Synthetic 3D",
        "GeoMeter Real-World"
      ],
      "models": [
        "GeoMeter",
        "GPT-4V",
        "LLaVA 1.5 7B",
        "LLaVA 1.5 13B",
        "LLaVA 1.6 Mistral 7B",
        "LLaVA 1.6 Vicuna 7B",
        "LLaVA 1.6 Vicuna 13B",
        "Bunny-v1.0-3B",
        "Bunny-v1.0-4B",
        "Bunny-v1.1-4B",
        "Bunny-Llama-3-8B-V",
        "Fuyu-8B",
        "InstructBLIP-Vicuna-7B",
        "InstructBLIP-Flan-T5-XL",
        "LLaMA-Adapter-v2-Multimodal",
        "MiniGPT-4",
        "GPT-4o",
        "Claude 3 Opus"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Behavior Trees Enable Structured Programming of Language Model Agents": {
    "filename": "Behavior Trees Enable Structured Programming of Language Model Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Dendron",
        "OpenChat",
        "LLaVA",
        "ViP-LLaVA",
        "YOLO-World",
        "EfficientSAM",
        "GPT",
        "Anthropic's Claude"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Faith and Fate Limits of Transformers on Compositionality": {
    "filename": "Faith and Fate Limits of Transformers on Compositionality.pdf",
    "analysis": {
      "benchmarks": [
        "multi-digit multiplication",
        "logic grid puzzles",
        "dynamic programming problem",
        "Einstein's puzzle"
      ],
      "models": [
        "ChatGPT",
        "GPT4",
        "GPT3",
        "text-davinci-003",
        "GPT-3.5-turbo",
        "gpt-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RePrompt Planning by Automatic Prompt Engineering for Large Language Models Agents": {
    "filename": "RePrompt Planning by Automatic Prompt Engineering for Large Language Models Agents.pdf",
    "analysis": {
      "benchmarks": [
        "HotPotQA",
        "PDDL generation",
        "Travel Planner"
      ],
      "models": [
        "REPROMPT",
        "GPT-4",
        "LLAMA-2",
        "REACT",
        "REFLEXION"
      ]
    }
  },
  "Adversarial Preference Optimization": {
    "filename": "Adversarial Preference Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "Helpful&Harmless"
      ],
      "models": [
        "Alpaca",
        "LLaMA-2",
        "APO",
        "RJS",
        "RRHF",
        "DPO",
        "Alpaca-RJS",
        "Alpaca-APO RJS",
        "Alpaca-RRHF",
        "Alpaca-APO RRHF",
        "Alpaca-DPO",
        "Alpaca-APO DPO",
        "Alpaca2-RJS",
        "Alpaca2-APO RJS",
        "Alpaca2-RRHF",
        "Alpaca2-APO RRHF",
        "Alpaca2-DPO",
        "Alpaca2-APO DPO",
        "LLaMA2-Chat",
        "Alpaca-Golden",
        "Alpaca2-Golden"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models as Urban Residents An LLM Agent Framework for Personal Mobility Generation": {
    "filename": "Large Language Models as Urban Residents An LLM Agent Framework for Personal Mobility Generation.pdf",
    "analysis": {
      "benchmarks": [
        "personal activity trajectory dataset of Tokyo"
      ],
      "models": [
        "LLMob",
        "GPT-3.5",
        "attention-based methods",
        "adversarial learning methods",
        "diffusion model",
        "Markov-based mechanic model (MM)",
        "LSTM-based prediction model (LSTM)",
        "DeepMove",
        "STAN",
        "TrajGAIL",
        "ActSTD",
        "DiffTraj",
        "LLMob-E",
        "LLMob-E w/o P",
        "LLMob-E w/o SC",
        "LLMob-L",
        "LLMob-L w/o P",
        "LLMob-L w/o SC",
        "LLMob w/o M",
        "LLMob w/o P&M"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Unpacking DPO and PPO Disentangling Best Practices for Learning from Preference Feedback": {
    "filename": "Unpacking DPO and PPO Disentangling Best Practices for Learning from Preference Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "MMLU",
        "Big Bench Hard",
        "TruthfulQA",
        "HumanEval+",
        "MBPP+",
        "ToxiGen",
        "XSTest",
        "AlpacaEval 1",
        "AlpacaEval 2",
        "IFEval"
      ],
      "models": [
        "T\u00dcLU 2",
        "Llama 2",
        "Llama 2 Chat",
        "Nous Hermes",
        "Vicuna 1.5",
        "T\u00dcLU 2+DPO",
        "T\u00dcLU 2+PPO",
        "L3+T\u00dcLU 2",
        "L3+T\u00dcLU 2+DPO",
        "L3+T\u00dcLU 2+PPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HELP ME THINK A Simple Prompting Strategy for Non-experts to Create Customized Content with Models": {
    "filename": "HELP ME THINK A Simple Prompting Strategy for Non-experts to Create Customized Content with Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT3",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Logical Tasks for Measuring Extrapolation and Rule Comprehension": {
    "filename": "Logical Tasks for Measuring Extrapolation and Rule Comprehension.pdf",
    "analysis": {
      "benchmarks": [
        "Mathematics Dataset",
        "GSM8K",
        "MATH",
        "BIG-bench",
        "Visual Sudoku",
        "Abstract Reasoning Corpus (ARC)",
        "SCAN",
        "gSCAN",
        "GridWorld"
      ],
      "models": [
        "Neural Arithmetic Expression Calculator",
        "Scratchpad",
        "GPT-3",
        "PaLM",
        "Minerva",
        "T5",
        "GPT-NeoX",
        "MLP",
        "Seq2seq",
        "Transformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring Large Language Models for Human Mobility Prediction under Public Events": {
    "filename": "Exploring Large Language Models for Human Mobility Prediction under Public Events.pdf",
    "analysis": {
      "benchmarks": [
        "Barclays Center event data",
        "NYC Taxi Data"
      ],
      "models": [
        "LLM-MPE",
        "Linear Regression (LR)",
        "Gradient-Boosted Decision Trees (GBDT)",
        "Feed Forward Network (FNN)",
        "Recurrent Neural Network (RNN)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AIvril AI-Driven RTL Generation With Verification In-The-Loop": {
    "filename": "AIvril AI-Driven RTL Generation With Verification In-The-Loop.pdf",
    "analysis": {
      "benchmarks": [
        "VerilogEval-Human"
      ],
      "models": [
        "AIVRIL",
        "CodeV",
        "RTLFixer",
        "Claude 3.5 Sonnet",
        "GPT-4o",
        "Llama3 70B",
        "VerilogCoder"
      ]
    }
  },
  "Towards Modeling Learner Performance with Large Language Models": {
    "filename": "Towards Modeling Learner Performance with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
    }
  },
  "Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training TXIT Exam and Red Journal Gray Zone Cases Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology": {
    "filename": "Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training TXIT Exam and Red Journal Gray Zone Cases Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology.pdf",
    "analysis": {
      "benchmarks": [
        "ACR TXIT exam",
        "Red Journal Gray Zone cases"
      ],
      "models": [
        "ChatGPT-3.5",
        "ChatGPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Boosting Deductive Reasoning with Step Signals In RLHF": {
    "filename": "Boosting Deductive Reasoning with Step Signals In RLHF.pdf",
    "analysis": {
      "benchmarks": [
        "MuseD",
        "PrOntoQA",
        "ProofWriter",
        "LogicalDeduction",
        "FOLIO",
        "AR-LSAT",
        "hellaswag",
        "lambada openai",
        "mmlu",
        "gsm8k",
        "openbookqa",
        "triviaqa",
        "arc easy",
        "arc challenge",
        "truthfulqa"
      ],
      "models": [
        "MuseD",
        "Llama3 8B",
        "Llama3 8B Instruct",
        "PPO UF",
        "PPO Na-P",
        "PPO NaO-P",
        "PPO Na-P-All",
        "PPO Na-P-Replace",
        "PPO Na-P-Cur",
        "PPO Na-R",
        "PPO Na-PN",
        "PPO Fo-P",
        "PPO Mix-P",
        "GPT-4",
        "GPT-4o",
        "GPT-4o-mini",
        "GPT-4-o1-preview",
        "GPT-4-o1-mini",
        "Qwen2.5-72B-Instruct",
        "Qwen2-72B-Instruct",
        "Llama3.1-72B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection": {
    "filename": "Re-Scoring Using Image-Language Similarity for Few-Shot Object Detection.pdf",
    "analysis": {
      "benchmarks": [
        "MS-COCO",
        "PASCAL VOC"
      ],
      "models": [
        "RISF",
        "Faster R-CNN",
        "CM-CLIP",
        "BNRL",
        "DeFRCN",
        "TFA",
        "FRCN-ft",
        "MPSR",
        "FSDetView",
        "QA-FewDet",
        "FADI",
        "DCF",
        "MFDC",
        "FSRW",
        "Meta Det",
        "MM-FSOD",
        "KFSOD",
        "TENET",
        "FCT",
        "ICPE",
        "LVC",
        "CNPB-DeFRCN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating ChatGPTs Information Extraction Capabilities An Assessment of Performance Explainability Calibration and Faithfulness": {
    "filename": "Evaluating ChatGPTs Information Extraction Capabilities An Assessment of Performance Explainability Calibration and Faithfulness.pdf",
    "analysis": {
      "benchmarks": [
        "BBN",
        "OntoNotes 5.0",
        "CoNLL2003",
        "TACRED",
        "SemEval2010",
        "ACE05-R",
        "SciERC",
        "ACE05-E",
        "ACE05-E+"
      ],
      "models": [
        "ChatGPT",
        "BERT",
        "RoBERTa",
        "State-of-the-Art (SOTA)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Optimizing Prompts for Text-to-Image Generation": {
    "filename": "Optimizing Prompts for Text-to-Image Generation.pdf",
    "analysis": {
      "benchmarks": [
        "Stable Diffusion v1.4",
        "Stable Diffusion v1.5",
        "DiffusionDB",
        "COCO",
        "ImageNet-21k"
      ],
      "models": [
        "PROMPTIST",
        "GPT-2",
        "Supervised Fine-Tuning",
        "Reinforcement Learning",
        "Proximal Policy Optimization (PPO)"
      ]
    }
  },
  "Skywork-Math Data Scaling Laws for Mathematical Reasoning in Large Language Models - The Story Goes On": {
    "filename": "Skywork-Math Data Scaling Laws for Mathematical Reasoning in Large Language Models - The Story Goes On.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K"
      ],
      "models": [
        "Skywork-Math",
        "GPT-4",
        "MetaMath-7B",
        "MetaMath-13B",
        "WizardMath-70B",
        "InternLM2-Math-7B",
        "LEMA-LLaMA2-7B",
        "LEMA-LLaMA2-13B",
        "MetaMath-Mistral-7B",
        "MAmmoTH-7B",
        "MAmmoTH-13B",
        "MAmmoTH-70B",
        "WizardMath-7B",
        "WizardMath-13B",
        "MetaMath-70B",
        "LLaMA3-8B",
        "GPT-3.5-Turbo",
        "LEMA-LLaMA2-70B",
        "DeepSeekMath-Instruct-7B",
        "InternLM2-Math-20B",
        "Xwin-Math-13B",
        "Xwin-Math-Mistral-7B",
        "Skywork-Math-LLaMA2-7B",
        "Skywork-Math-DeepSeekMath-7B",
        "Skywork-Math-Mistral-7B",
        "ChatGLM3-Math-SFT-32B",
        "Xwin-Math-7B",
        "GPT-4-Turbo",
        "PaLM2",
        "Flan-PaLM2",
        "Minerva",
        "ChatGLM3-32B-SFT-2312",
        "Claude-3-Oppus",
        "Baichuan-2",
        "LEMA-LLaMA2",
        "MetaMath",
        "WizardMath-V1.1",
        "Xwin-Math-LLaMA",
        "Xwin-Math-Mistral",
        "Xwin-Math-Llemma",
        "MAmmoTH",
        "InternLM2-Math",
        "DeepSeekMath-Instruct",
        "Skywork-Math-LLaMA2",
        "Skywork-Math-Mistral",
        "Skywork-Math-DeepSeekMath",
        "LLaMA3-Instruct",
        "LLaMA2",
        "LLema",
        "WizardMath",
        "Mixtral-8x7B",
        "Llemma-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Digital Life Project Autonomous 3D Characters with Social Intelligence": {
    "filename": "Digital Life Project Autonomous 3D Characters with Social Intelligence.pdf",
    "analysis": {
      "benchmarks": [
        "DLP-MoCap",
        "InterHuman",
        "HumanML3D",
        "KIT-ML"
      ],
      "models": [
        "SocioMind",
        "MoMat-MoGen",
        "MotionDiffuse",
        "ReMoDiffuse",
        "InterGen",
        "TM2T",
        "MotionGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets Insights and Best Practices": {
    "filename": "What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets Insights and Best Practices.pdf",
    "analysis": {
      "benchmarks": [
        "NarrativeQA",
        "2WikiMQA",
        "DuReader",
        "HotpotQA",
        "MultifieldQA en",
        "MultifieldQA zh",
        "MuSiQue",
        "Qasper"
      ],
      "models": [
        "Multi-agent Interactive Multi-hop Generation (MIMG)",
        "InternLM2-1.8B",
        "LLaMA3-8B",
        "InternLM2-7B",
        "ChatQA2",
        "LongAlign",
        "LongAlpaca",
        "NQ",
        "LongMIT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Peering Through Preferences Unraveling Feedback Acquisition for Aligning Large Language Models": {
    "filename": "Peering Through Preferences Unraveling Feedback Acquisition for Aligning Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Dolly",
        "Self-Instruct (User Oriented)",
        "Super-NI",
        "Open Assistant (OASST)",
        "Anthropic helpful evaluation",
        "Vicuna",
        "Koala"
      ],
      "models": [
        "Alpaca-7B",
        "LLaMA-7B",
        "GPT-3.5-Turbo",
        "DaVinci-003",
        "Best-of-n policy",
        "Best-of-64 policy",
        "LoRA",
        "ChatGPT-3.5-Turbo-0613",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MuseGraph Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining": {
    "filename": "MuseGraph Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining.pdf",
    "analysis": {
      "benchmarks": [
        "Arxiv",
        "MIMIC-III",
        "Cora",
        "AGENDA",
        "WebNLG"
      ],
      "models": [
        "MuseGraph",
        "MLP",
        "GraphSAGE",
        "GCN",
        "GAT",
        "RevGNN",
        "DGI",
        "GKD",
        "GLNN",
        "NodeFormer",
        "DIFFormer",
        "BART",
        "T5",
        "LLaMA",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Complexity-Based Prompting for Multi-Step Reasoning": {
    "filename": "Complexity-Based Prompting for Multi-Step Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MultiArith",
        "MathQA",
        "Date Understanding",
        "Penguins",
        "StrategyQA"
      ],
      "models": [
        "GPT-3",
        "Codex",
        "LaMDA",
        "PaLM",
        "Minerva",
        "DiVeRSe",
        "text-davinci-002",
        "code-davinci-002",
        "text-curie-001",
        "Flan-T5"
      ]
    }
  },
  "Multimodal Auto Validation For Self-Refinement in Web Agents": {
    "filename": "Multimodal Auto Validation For Self-Refinement in Web Agents.pdf",
    "analysis": {
      "benchmarks": [
        "WebVoyager"
      ],
      "models": [
        "Agent-E",
        "GPT-4-Turbo",
        "GPT4-Omni",
        "GPT-4V"
      ]
    }
  },
  "Hypothesizing Missing Causal Variables with LLMs": {
    "filename": "Hypothesizing Missing Causal Variables with LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Cancer",
        "Survey",
        "Asia",
        "Child",
        "Insurance",
        "Alarm",
        "Alzheimer's Disease"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "LLama2-chat-7b",
        "Mistral-7B-Instruct-v0.2",
        "Mixtral-7B-Instruct-v0.1",
        "Zephyr-7b-Beta",
        "Neural-chat-7b-v3-1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ANALOGYKB Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base": {
    "filename": "ANALOGYKB Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base.pdf",
    "analysis": {
      "benchmarks": [
        "E-KAR",
        "BATS",
        "UNIT 2",
        "UNIT 4",
        "Google",
        "SAT",
        "SCAN"
      ],
      "models": [
        "ANALOGY KB",
        "RoBERTa-Large",
        "DeBERTa-v3",
        "T5-Large",
        "BERT-Large",
        "ERNIE",
        "LUKE",
        "InstructGPT 003",
        "ChatGPT",
        "GPT-2",
        "AnalogyT5",
        "SimCSE",
        "SentenceBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "QueryCAD Grounded Question Answering for CAD Models": {
    "filename": "QueryCAD Grounded Question Answering for CAD Models.pdf",
    "analysis": {
      "benchmarks": [
        "CAD-Q&A Benchmark"
      ],
      "models": [
        "QueryCAD",
        "SegCAD",
        "GroundedSAM",
        "GroundingDINO",
        "MetaWizard",
        "Llama 3.1 8B",
        "Llama 3.1 405B",
        "GPT4o"
      ]
    }
  },
  "ZeroCAP Zero-Shot Multi-Robot Context Aware Pattern Formation via Large Language Models": {
    "filename": "ZeroCAP Zero-Shot Multi-Robot Context Aware Pattern Formation via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "General pattern formation",
        "Infill pattern formation",
        "Caging formation",
        "Single Object setup",
        "Multi-Object setup",
        "Hidden Object setup"
      ],
      "models": [
        "ZeroCAP",
        "RL-based approach",
        "GPT-4 Vision",
        "Llava-v1.6",
        "GPT-4",
        "llama70b",
        "Claude",
        "CLIPSeg",
        "LangSAM"
      ]
    }
  },
  "Synergizing Knowledge Graphs with Large Language Models A Comprehensive Review and Future Prospects": {
    "filename": "Synergizing Knowledge Graphs with Large Language Models A Comprehensive Review and Future Prospects.pdf",
    "analysis": {
      "benchmarks": [
        "DBpedia",
        "Wikidata"
      ],
      "models": [
        "BERT",
        "GPT",
        "T5",
        "GLM",
        "ChatGPT4",
        "LLaMA3",
        "InstructGPT",
        "LPAQA",
        "KEPLER",
        "KnowPrompt",
        "LARK"
      ]
    }
  },
  "Team Trifecta at Factify5WQA Setting the Standard in Fact Verification with Fine-Tuning": {
    "filename": "Team Trifecta at Factify5WQA Setting the Standard in Fact Verification with Fine-Tuning.pdf",
    "analysis": {
      "benchmarks": [
        "FACTIFY5WQA",
        "SQuAD 2.0"
      ],
      "models": [
        "Pre-CoFactv3",
        "FakeNet",
        "roberta-large",
        "deberta-v3-large",
        "bert-large-uncased",
        "gpt2",
        "t5-large",
        "microsoft/deberta-large",
        "microsoft/deberta-xlarge",
        "microsoft/deberta-v3-base",
        "microsoft/deberta-v3-large"
      ]
    }
  },
  "Chain-of-Spot Interactive Reasoning Improves Large Vision-Language Models": {
    "filename": "Chain-of-Spot Interactive Reasoning Improves Large Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "VQAv2",
        "GQA",
        "VizWiz",
        "Science QA",
        "TextVQA",
        "OKVQA",
        "SEEDBench",
        "MME",
        "MMBench",
        "POPE",
        "MM-Vet"
      ],
      "models": [
        "LLaVA-1.5",
        "LLaVA-1.5-CoS",
        "BLIP-2",
        "InstructBLIP",
        "Shikra",
        "IDEFICS-80B",
        "Qwen-VL",
        "Qwen-VL-Chat",
        "mPLUG-Owl2",
        "Monkey",
        "LLaVA/7B",
        "LLaVA/13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Raidar geneRative AI Detection viA Rewriting": {
    "filename": "Raidar geneRative AI Detection viA Rewriting.pdf",
    "analysis": {
      "benchmarks": [
        "News Dataset",
        "Creative Writing Dataset",
        "Student Essay Dataset",
        "Code Dataset",
        "Yelp Review Dataset",
        "ArXiv Paper Abstract"
      ],
      "models": [
        "Raidar",
        "GPT Zero-shot",
        "GPTZero",
        "DetectGPT",
        "Ghostbuster",
        "Ada",
        "Text-Davinci-002",
        "Claude",
        "GPT-3.5-turbo",
        "GPT-4-turbo",
        "LLaMA 2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM2FEA Discover Novel Designs with Generative Evolutionary Multitasking": {
    "filename": "LLM2FEA Discover Novel Designs with Generative Evolutionary Multitasking.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLM2FEA",
        "Shape-E",
        "ChatGPT",
        "BLIP-2",
        "OpenFoam"
      ]
    }
  },
  "DiffusionGPT LLM-Driven Text-to-Image Generation System": {
    "filename": "DiffusionGPT LLM-Driven Text-to-Image Generation System.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "DiffusionGPT",
        "SD1.5",
        "SD1.5+Lora",
        "SDXL",
        "Stable Diffusion",
        "DALLE-2",
        "Imagen",
        "Controlnet",
        "FilmVelvia2",
        "CineStyle5"
      ]
    }
  },
  "Large Language Models Can Be Easily Distracted by Irrelevant Context": {
    "filename": "Large Language Models Can Be Easily Distracted by Irrelevant Context.pdf",
    "analysis": {
      "benchmarks": [
        "Grade-School Math with Irrelevant Context (GSM-IC)",
        "GSM8K",
        "SVAMP",
        "DROP"
      ],
      "models": [
        "Codex (code-davinci-002)",
        "GPT-3.5 (text-davinci-003)",
        "Chain-of-Thought prompting (COT)",
        "Zero-shot Chain-of-Thought prompting (0-COT)",
        "Least-to-Most prompting (LTM)",
        "Prompting with programs (PROGRAM)",
        "Self-consistency"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Do better language models have crisper vision": {
    "filename": "Do better language models have crisper vision.pdf",
    "analysis": {
      "benchmarks": [
        "Visual Text Representation Benchmark (ViTeRB)",
        "ImageNet",
        "AWA2",
        "CUB",
        "FGVCAircraft",
        "ImageNet+",
        "Winoground"
      ],
      "models": [
        "ShareLock",
        "CLIP",
        "LiT",
        "ASIF",
        "BERT Base",
        "T5-XL",
        "Flan UL2",
        "Llama 3",
        "Phi-3",
        "Qwen2",
        "BLOOM",
        "Falcon",
        "Gemma",
        "Vicuna v1.5",
        "NV-Embed",
        "SentenceT5-XXL",
        "Llama-3 8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On the Limitations of Large Language Models LLMs False Attribution": {
    "filename": "On the Limitations of Large Language Models LLMs False Attribution.pdf",
    "analysis": {
      "benchmarks": [
        "Pride and Prejudice",
        "Moby Dick",
        "Middlemarch",
        "The Adventures of Ferdinand Count Fathom",
        "The Expedition of Humphry Clinker",
        "The Adventures of Roderick Random",
        "History of Tom Jones",
        "A Doll\u2019s House",
        "Crime and Punishment",
        "Great Expectations"
      ],
      "models": [
        "LLaMA-2-13B",
        "Mixtral 8x7B",
        "Gemma-7B"
      ]
    }
  },
  "Reasoning Implicit Sentiment with Chain-of-Thought Prompting": {
    "filename": "Reasoning Implicit Sentiment with Chain-of-Thought Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "SemEval14 Laptop",
        "SemEval14 Restaurant"
      ],
      "models": [
        "BERT+SPC",
        "BERT+ADA",
        "BERT+RGAT",
        "BERT Asp+CEPT",
        "BERT+ISAIV",
        "BERT Asp+SCAPT",
        "BERT+Prompt",
        "Flan-T5+Prompt",
        "Flan-T5+THOR",
        "GPT3+THOR",
        "ChatGPT+THOR"
      ]
    }
  },
  "How FaR Are Large Language Models From Agents with Theory-of-Mind": {
    "filename": "How FaR Are Large Language Models From Agents with Theory-of-Mind.pdf",
    "analysis": {
      "benchmarks": [
        "ToMi",
        "False Belief Test",
        "ToM-bAbI",
        "T4D",
        "Faux Pas"
      ],
      "models": [
        "GPT-4",
        "PaLM 2",
        "ChatGPT (GPT-3.5)",
        "Foresee and Reflect (FaR)",
        "Chain-of-Thought",
        "Self-Ask",
        "Tree-of-Thought",
        "PaLM 2-S (Bison)",
        "PaLM 2-L (Unicorn)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DeLLMa Decision Making Under Uncertainty with Large Language Models": {
    "filename": "DeLLMa Decision Making Under Uncertainty with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Agriculture",
        "Stocks"
      ],
      "models": [
        "DeLLMa",
        "DeLLMa-Pairs",
        "DeLLMa-Top1",
        "DeLLMa-Naive",
        "Zero-Shot",
        "Self-Consistency",
        "Chain-of-Thought",
        "OpenAI o1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MathVista Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts": {
    "filename": "MathVista Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts.pdf",
    "analysis": {
      "benchmarks": [
        "MATHVISTA",
        "IQTest",
        "FunctionQA",
        "PaperQA",
        "ChartQA",
        "CLEVR-Math",
        "DVQA",
        "FigureQA",
        "IconQA",
        "GeoQA+",
        "Geometry3K",
        "UniGeo",
        "GEOS",
        "VQA2.0",
        "TabMWP",
        "SciBenchTQA",
        "Super-CLEVR",
        "AI2D",
        "PlotQA"
      ],
      "models": [
        "GPT-4V",
        "Bard",
        "ChatGPT",
        "GPT-4",
        "Claude-2",
        "IDEFICS-9B",
        "mPLUG-OWL-LLaMA-7B",
        "miniGPT-4-LLaMA-2-7B",
        "LLaMA-Adapter-V2-7B",
        "InstructBLIP-Vicuna-7B",
        "LLaVA-LLaMA-2-13B",
        "LLaVAR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RL2 Reinforce Large Language Model to Assist Safe Reinforcement Learning for Energy Management of Active Distribution Networks": {
    "filename": "RL2 Reinforce Large Language Model to Assist Safe Reinforcement Learning for Energy Management of Active Distribution Networks.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "RL2",
        "soft actor-critic (SAC)",
        "LLM agent",
        "RL agent"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Expressive Power of Low-Rank Adaptation": {
    "filename": "The Expressive Power of Low-Rank Adaptation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Low-Rank Adaptation (LoRA)",
        "Fully Connected Neural Networks (FNN)",
        "Transformer Networks (TFN)",
        "frozen FNN",
        "target FNN",
        "frozen TFN",
        "target TFN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Let GPT be a Math Tutor Teaching Math Word Problem Solvers with Customized Exercise Generation": {
    "filename": "Let GPT be a Math Tutor Teaching Math Word Problem Solvers with Customized Exercise Generation.pdf",
    "analysis": {
      "benchmarks": [
        "MAWPS",
        "ASDiv-a",
        "SVAMP"
      ],
      "models": [
        "GPT-3",
        "PaLM",
        "GTS",
        "Graph2Tree",
        "Bert2Tree",
        "GPT-3+CoT",
        "PaLM+CoT",
        "Our Method",
        "CEMAL",
        "LSTM",
        "RoBERTa-base",
        "RoBERTa-large"
      ]
    }
  },
  "Grammar Prompting for Domain-Specific Language Generation with Large Language Models": {
    "filename": "Grammar Prompting for Domain-Specific Language Generation with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SMCalFlow",
        "Overnight",
        "GeoQuery",
        "PDDL",
        "SMILES"
      ],
      "models": [
        "grammar prompting",
        "standard prompting",
        "linearized derivation tree prompting",
        "Codex",
        "GPT-3.5",
        "GPT-4",
        "PaLM 2-L"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TRANSAGENT An LLM-Based Multi-Agent System for Code Translation": {
    "filename": "TRANSAGENT An LLM-Based Multi-Agent System for Code Translation.pdf",
    "analysis": {
      "benchmarks": [
        "new code translation benchmark"
      ],
      "models": [
        "TRANS AGENT",
        "UniTrans",
        "TransCoder",
        "Deepseek-coder-6.7b-instruct",
        "Llama-3-8B-Instruct",
        "ChatGLM2-6b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Should we be going MAD A Look at Multi-Agent Debate Strategies for LLMs": {
    "filename": "Should we be going MAD A Look at Multi-Agent Debate Strategies for LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "PubMedQA",
        "MMLU",
        "CosmosQA",
        "CIAR",
        "GPQA",
        "Chess"
      ],
      "models": [
        "Multi-Agent Debate (MAD)",
        "Multi-Persona",
        "Society of Minds",
        "ChatEval",
        "Self-consistency",
        "Ensemble Refinement",
        "Medprompt",
        "Single Agent",
        "Solo Performance Prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Action Contextualization Adaptive Task Planning and Action Tuning Using Large Language Models": {
    "filename": "Action Contextualization Adaptive Task Planning and Action Tuning Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4-1106-preview",
        "open-mixtral-8x22b",
        "Meta-Llama-3-70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Sketch A Toolkit for Streamlining LLM Operations": {
    "filename": "Sketch A Toolkit for Streamlining LLM Operations.pdf",
    "analysis": {
      "benchmarks": [
        "CoNLL-2003",
        "SemEval-2010 Task 8",
        "20 Newsgroup",
        "SemEval-2015 Task 12",
        "DBPedia",
        "Medical NER"
      ],
      "models": [
        "Sketch-8B",
        "LLaMA3-8B-Instruct",
        "DeepSeek",
        "ChatGLM",
        "GPT-4o",
        "Sketch-8B-w.o.-ner"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Attention Sorting Combats Recency Bias In Long Context Language Models": {
    "filename": "Attention Sorting Combats Recency Bias In Long Context Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SynthWiki"
      ],
      "models": [
        "TogetherComputer's Llama-2-7B-32k",
        "Llama-2-7B-32k-Instruct",
        "YaRN Llama-2-7B-64k",
        "WizardLM-tuned Code-Llama-7B",
        "Claude-1-Instant",
        "Claude-2",
        "GPT-3.5-turbo-16k"
      ]
    }
  },
  "Attention Heads of Large Language Models A Survey": {
    "filename": "Attention Heads of Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "LRE",
        "ToyMovieReview",
        "ToyMoodStory",
        "FV-Caplitalize",
        "ICL-MC",
        "Succession",
        "Iteration-Synthetic",
        "Omniglot",
        "IOI",
        "Colored Object",
        "World-Capital",
        "MMLU",
        "TruthfulQA",
        "LogiQA",
        "MQuAKE",
        "SST",
        "SST2",
        "ETHOS",
        "Needle-in-a-Haystack",
        "AG News",
        "TriviaQA",
        "AGENDA"
      ],
      "models": [
        "BERT",
        "GPT",
        "LLaMA",
        "ChatGPT",
        "InternLM",
        "Yi",
        "Gemma",
        "Mistral",
        "Llama",
        "Qwen",
        "Pythia",
        "GPT-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Arithmetic with Language Models from Memorization to Computation": {
    "filename": "Arithmetic with Language Models from Memorization to Computation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "original encoder-decoder architecture by Vaswani et al. (2017)",
        "nanoGPT",
        "ChatGPT",
        "GPT-4",
        "Goat",
        "LLaMA",
        "T5-based pre-trained LM",
        "vanilla non-pretrained LM",
        "pre-trained GPT-2",
        "small LMs",
        "proposed light language model"
      ]
    }
  },
  "BOLAA Benchmarking and Orchestrating LLM-augmented Autonomous Agents": {
    "filename": "BOLAA Benchmarking and Orchestrating LLM-augmented Autonomous Agents.pdf",
    "analysis": {
      "benchmarks": [
        "WebShop",
        "HotPotQA"
      ],
      "models": [
        "BOLAA",
        "Zeroshot LAA (ZS-LAA)",
        "ZeroshotThink LAA (ZST-LAA)",
        "ReAct LAA",
        "PlanAct LAA",
        "PlanReAct LAA",
        "fastchat-t5-3b",
        "vicuna-7b",
        "vicuna-13b",
        "vicuna-33b",
        "llama-2-7b",
        "llama-2-13b",
        "llama-2-70b",
        "mpt-7b-instruct",
        "mpt-30b-instruct",
        "xgen-8k-7b-instruct",
        "longchat-7b-16k",
        "longchat-13b-16k",
        "text-davinci-003",
        "gpt-3.5-turbo",
        "gpt-3.5-turbo-16k"
      ]
    }
  },
  "Preference Optimization for Reasoning with Pseudo Feedback": {
    "filename": "Preference Optimization for Reasoning with Pseudo Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "College Math",
        "LiveCodeBench",
        "HumanEval",
        "MBPP",
        "APPs",
        "xCodeEval"
      ],
      "models": [
        "Mathstral-7B",
        "NuminaMath-72B",
        "GPT-4-Turbo-1106-preview",
        "Claude-3-Haiku",
        "Deepseek-coder-7B-v1.5",
        "Llama-3.1-8B-base",
        "Llama-3.1-8B-Instruct",
        "Llama-3.1-70B-Instruct",
        "Codestral-22B-V0.1",
        "CodeQwen1.5-7B-chat",
        "Qwen2.5-Coder-7B-Instruct",
        "Deepseek-coder-33B-Instruct",
        "Deepseek-coder-v1.5-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Using Large Language Models for Knowledge Engineering LLMKE A Case Study on Wikidata": {
    "filename": "Using Large Language Models for Knowledge Engineering LLMKE A Case Study on Wikidata.pdf",
    "analysis": {
      "benchmarks": [
        "ISWC 2023 LM-KBC Challenge"
      ],
      "models": [
        "LLMKE",
        "gpt-3.5-turbo",
        "GPT-4"
      ]
    }
  },
  "Sirius Contextual Sparsity with Correction for Efficient LLMs": {
    "filename": "Sirius Contextual Sparsity with Correction for Efficient LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "CNN/DailyMail",
        "GSM8K",
        "HumanEval",
        "MMLU",
        "AQuA-RAT",
        "CSQA",
        "StrategyQA",
        "Date",
        "Sports",
        "MBPP+"
      ],
      "models": [
        "Sirius",
        "Llama-3-8B-Instruct",
        "Llama-3-70B-Instruct",
        "Llama-2-7B-Chat",
        "Llama-2-7B",
        "Llama-2-13B-Chat",
        "Llama-2-13B",
        "CSparse",
        "FSparse"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mitigating Selection Bias with Node Pruning and Auxiliary Options": {
    "filename": "Mitigating Selection Bias with Node Pruning and Auxiliary Options.pdf",
    "analysis": {
      "benchmarks": [
        "ARC-Challenge",
        "MMLU-Redux",
        "CommonsenseQA"
      ],
      "models": [
        "Llama-3-8B-Instruct",
        "Mistral-7B-Instruct-v0.2",
        "Bloomz-7b1",
        "Bias Node Pruning (BNP)",
        "Auxiliary Option Injection (AOI)",
        "Chain-of-Thought (CoT)",
        "In-Context Learning (ICL)",
        "Decoding by Contrasting Layers (DoLa)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "JPPO Joint Power and Prompt Optimization for Accelerated Large Language Model Services": {
    "filename": "JPPO Joint Power and Prompt Optimization for Accelerated Large Language Model Services.pdf",
    "analysis": {
      "benchmarks": [
        "MeetingBank-transcript"
      ],
      "models": [
        "JPPO",
        "SLM",
        "LLMLingua",
        "LLM-Slice",
        "GPT-Neo 125M",
        "GPT-J 6B"
      ]
    }
  },
  "IDGen Item Discrimination Induced Prompt Generation for LLM Evaluation": {
    "filename": "IDGen Item Discrimination Induced Prompt Generation for LLM Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "SELF-INSTRUCT",
        "WizardLM",
        "Instruction Tuning with GPT-4",
        "SELF-INSTRUCT_seed_data",
        "SELF-INSTRUCT-Ours",
        "Ours (hard seed data)"
      ],
      "models": [
        "IDGen",
        "SELF-INSTRUCT",
        "WizardLM",
        "Instruction Tuning with GPT-4",
        "GLM-4",
        "GPT-4 Turbo",
        "GPT-4",
        "Claude3",
        "Qwen",
        "Hunyuan",
        "Hunyuan-pro",
        "Baichuan2-13B"
      ]
    }
  },
  "Large Language Models Are Zero-Shot Fuzzers Fuzzing Deep-Learning Libraries via Large Language Models": {
    "filename": "Large Language Models Are Zero-Shot Fuzzers Fuzzing Deep-Learning Libraries via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "TensorFlow",
        "PyTorch"
      ],
      "models": [
        "TitanFuzz",
        "Codex",
        "InCoder",
        "FreeFuzz",
        "DeepREL",
        "LEMON",
        "Muffin"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Telecom Language Models Must They Be Large": {
    "filename": "Telecom Language Models Must They Be Large.pdf",
    "analysis": {
      "benchmarks": [
        "TeleQnA"
      ],
      "models": [
        "Phi-2",
        "GPT-3.5",
        "GPT-4",
        "Phi-2+RAG"
      ]
    }
  },
  "Read Diagnose and Chat Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media": {
    "filename": "Read Diagnose and Chat Towards Explainable and Interactive LLMs-Augmented Depression Detection in Social Media.pdf",
    "analysis": {
      "benchmarks": [
        "Twitter dataset",
        "Weibo dataset",
        "TMDD",
        "WU3D"
      ],
      "models": [
        "Chat-Diagnose",
        "GPT-3",
        "ChatGPT",
        "Time2VecTransformer",
        "SetTransformer",
        "MTAN",
        "GRU + VGG + COMMA",
        "MTAL",
        "BERT(base)",
        "PTDD"
      ]
    }
  },
  "A survey on semantic processing techniques": {
    "filename": "A survey on semantic processing techniques.pdf",
    "analysis": {
      "benchmarks": [
        "SemCor",
        "MultiSemCor",
        "Line-hard-serve",
        "Interest",
        "DSO",
        "OMWE",
        "OMSTI",
        "SensEval-2",
        "SensEval-3",
        "SemEval2007",
        "SemEval2013",
        "SemEval2015"
      ],
      "models": [
        "Lesk",
        "Banerjee et al. (2003)",
        "Navigli and Lapata (2007)",
        "Basile et al. (2014)",
        "Wang and Wang (2020) KB",
        "Agirre and Soroa (2009)",
        "Moro et al. (2014b)",
        "Scozzafava et al. (2020)",
        "Singh et al. (2014)",
        "O'Hara et al. (2004)",
        "Zhong and Ng (2010)",
        "Iacobacci et al. (2016)",
        "Popov (2017)",
        "Yuan et al. (2016)",
        "Le et al. (2018)",
        "Hadiwinoto et al. (2019)",
        "Bevilacqua and Navigli (2019)",
        "Wang and Wang (2020) Sup",
        "Vial et al. (2019)",
        "Loureiro and Jorge (2019)",
        "Kumar et al. (2019)",
        "Bevilacqua and Navigli (2020)",
        "Conia and Navigli (2021)",
        "Huang et al. (2019a)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HPC-GPT Integrating Large Language Model for High-Performance Computing": {
    "filename": "HPC-GPT Integrating Large Language Model for High-Performance Computing.pdf",
    "analysis": {
      "benchmarks": [
        "OpenMP Q&A",
        "DRB",
        "DataRaceBench V1.4.0"
      ],
      "models": [
        "HPC-GPT",
        "LLaMA",
        "LLaMA2",
        "GPT-3.5",
        "GPT-4",
        "ChatGPT",
        "HPC Ontology",
        "LLOV",
        "Intel Inspector",
        "ROMP",
        "Thread Sanitizer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GTBench Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations": {
    "filename": "GTBench Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations.pdf",
    "analysis": {
      "benchmarks": [
        "GTBench",
        "Tic-Tac-Toe",
        "Connect-4",
        "Breakthrough",
        "Nim",
        "Pig",
        "Liar's Dice",
        "Blind Auction",
        "Negotiation",
        "Kuhn Poker",
        "Iterated Prisoner's Dilemma"
      ],
      "models": [
        "GTBench",
        "GPT-4",
        "GPT-3.5-turbo",
        "Llama-2-70b-chat",
        "CodeLlama-34b-Instruct",
        "Llama-3-70b-Instruct",
        "Mistral-Orca",
        "Monte-Carlo Tree Search (MCTS)",
        "Prompt Agent",
        "CoT Agent",
        "SC-CoT Agent",
        "ToT Agent",
        "Random Agent",
        "Tit-for-Tat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Explainable Evaluation Metrics for Machine Translation": {
    "filename": "Towards Explainable Evaluation Metrics for Machine Translation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "BLEU",
        "METEOR",
        "COMET",
        "BERTScore",
        "ChatGPT",
        "GPT4",
        "PRISM",
        "BARTScore",
        "DATScore",
        "GPTScore",
        "ROSCOE",
        "Transquest",
        "BARTScore++",
        "InstructScore",
        "AutoMQM",
        "GEMBA-MQM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-collaboration Code Generation via ChatGPT": {
    "filename": "Self-collaboration Code Generation via ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "MBPP",
        "HumanEval",
        "MBPP-ET",
        "HumanEval-ET",
        "APPS",
        "CoderEval"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "AlphaCode",
        "Incoder",
        "CodeGeeX",
        "StarCoder",
        "CodeGen",
        "PaLM Coder",
        "CodeX",
        "CodeX + CodeT",
        "CodeLlama",
        "Fastchat-3B",
        "ChatGLM-6B",
        "MPT-7B",
        "Vicuna-7B",
        "Vicuna-13B",
        "HuggingChat-30B",
        "Dromedary-65B",
        "Iter-improving",
        "Zero-shot CoT",
        "Self-planning",
        "Self-debugging"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents": {
    "filename": "Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents.pdf",
    "analysis": {
      "benchmarks": [
        "Atari Learning Environments",
        "HackAtari",
        "NoEnemy",
        "LazyEnemy"
      ],
      "models": [
        "Successive Concept Bottleneck Agents (SCoBots)",
        "deep agents",
        "guided SCoBots",
        "NN-SCoBots",
        "unguided SCoBots",
        "decision tree policy",
        "neural object-centric baseline"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Transfer Visual Prompt Generator across LLMs": {
    "filename": "Transfer Visual Prompt Generator across LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "VQAv2",
        "OKVQA",
        "COCO caption",
        "NoCaps",
        "GQA"
      ],
      "models": [
        "VPGTrans",
        "BLIP-2 OPT 2.7B",
        "BLIP-2 OPT 6.7B",
        "VL-LLaMA",
        "VL-Vicuna",
        "FlanT5 XL",
        "FlanT5 XXL",
        "OPT 125M",
        "OPT 350M",
        "OPT 1.3B",
        "OPT 2.7B",
        "FlanT5 base",
        "FlanT5 large",
        "FlanT5 XL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Bias Testing and Mitigation in LLM-based Code Generation": {
    "filename": "Bias Testing and Mitigation in LLM-based Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval"
      ],
      "models": [
        "PALM-2-CodeChat-bison",
        "Claude-instant-1",
        "GPT-3.5-turbo",
        "GPT-4-turbo",
        "GPT-4",
        "Codex",
        "InCoder",
        "CodeGen"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Detecting Multi-Parameter Constraint Inconsistencies in Python Data Science Libraries": {
    "filename": "Detecting Multi-Parameter Constraint Inconsistencies in Python Data Science Libraries.pdf",
    "analysis": {
      "benchmarks": [
        "scikit-learn",
        "scipy",
        "numpy",
        "pandas",
        "keras",
        "dask",
        "statsmodels"
      ],
      "models": [
        "MPDetector",
        "LLM Checker",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey on Prompting Techniques in LLMs": {
    "filename": "A Survey on Prompting Techniques in LLMs.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT",
        "GPT-2",
        "GPT-3",
        "PaLM",
        "BERT",
        "BART",
        "T5",
        "Prefix Tuning",
        "Prompt Tuning",
        "P-tuning",
        "Chain of Thought (CoT)",
        "Zero-shot CoT",
        "Auto CoT",
        "Self-consistency",
        "Tree-of-Thoughts (ToT)",
        "Least-to-most prompting",
        "Generated Knowledge Prompting",
        "Self-ask",
        "Program-aided Language models (PAL)",
        "Program of Thoughts (PoT)",
        "ReAct",
        "ART"
      ]
    }
  },
  "RARe Retrieval Augmented Retrieval with In-Context Examples": {
    "filename": "RARe Retrieval Augmented Retrieval with In-Context Examples.pdf",
    "analysis": {
      "benchmarks": [
        "BeIR",
        "RAR-b",
        "MS-MARCO",
        "NQ",
        "SQuAD",
        "Quora Duplication Questions",
        "HellaSwag",
        "PIQA",
        "ARC-C",
        "TempReason-L1",
        "WinoGrande",
        "\u03b1-NLI",
        "SiQA",
        "Quail",
        "NFCorpus",
        "SciFact",
        "SCIDOCS",
        "FiQA2018",
        "CQA",
        "Touche2020",
        "DBPedia"
      ],
      "models": [
        "RARe",
        "Llama-3",
        "LLM2Vec-Llama-3-8b-Supervised",
        "E5-Mistral-Instruct",
        "RepLLaMA",
        "Promptriever",
        "SFR-Embedding-2-R"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Robots That Ask For Help Uncertainty Alignment for Large Language Model Planners": {
    "filename": "Robots That Ask For Help Uncertainty Alignment for Large Language Model Planners.pdf",
    "analysis": {
      "benchmarks": [
        "PyBullet simulator",
        "Hardware Multi-Step Tabletop Rearrangement",
        "Hardware Mobile Manipulation"
      ],
      "models": [
        "KNOW NO",
        "Simple Set",
        "Ensemble Set",
        "Prompt Set",
        "Binary",
        "No Help",
        "PaLM-2L",
        "PaLM-2L-IF",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InterPreT Interactive Predicate Learning from Language Feedback for Generalizable Task Planning": {
    "filename": "InterPreT Interactive Predicate Learning from Language Feedback for Generalizable Task Planning.pdf",
    "analysis": {
      "benchmarks": [
        "Kitchen2D",
        "StoreObjects",
        "SetTable",
        "CookMeal"
      ],
      "models": [
        "InterPreT",
        "Inner Monologue (IM)",
        "IM + Object",
        "IM + Object + Scene",
        "IM + Object + Scene + Precond",
        "Code-as-Policies (CaP)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Large Language Model based Personal Information Extraction and Countermeasures": {
    "filename": "Evaluating Large Language Model based Personal Information Extraction and Countermeasures.pdf",
    "analysis": {
      "benchmarks": [
        "Synthetic Dataset",
        "Celebrity Dataset",
        "Physician Dataset"
      ],
      "models": [
        "GPT-4",
        "PaLM 2 text-bison-001",
        "PaLM 2 chat-bison-001",
        "Gemini-pro",
        "GPT-3.5-Turbo",
        "Flan-UL-2",
        "Vicuna-13b-v1.3",
        "Vicuna-7b-v1.3",
        "Llama-2-7b-chat",
        "InternLM-Chat-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Conditions for Length Generalization in Learning Reasoning Skills": {
    "filename": "Conditions for Length Generalization in Learning Reasoning Skills.pdf",
    "analysis": {
      "benchmarks": [
        "arithmetic in F7",
        "1-line addition",
        "3-line addition",
        "1-line multiplication"
      ],
      "models": [
        "Chain of Thought (CoT)",
        "Scratchpad"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ZoomEye Enhancing Multimodal LLMs with Human-Like Zooming Capabilities through Tree-Based Image Exploration": {
    "filename": "ZoomEye Enhancing Multimodal LLMs with Human-Like Zooming Capabilities through Tree-Based Image Exploration.pdf",
    "analysis": {
      "benchmarks": [
        "V*Bench",
        "HR-Bench",
        "HR-Bench 4K",
        "HR-Bench 8K",
        "MME-RealWorld"
      ],
      "models": [
        "Zoom Eye",
        "LLaVA-v1.5-7B",
        "LLaVA-v1.5-13B",
        "LLaVA-ov-0.5B",
        "LLaVA-ov-7B",
        "minigptv2-7B",
        "LLaVA-v1.6-7B",
        "LLaVA-v1.6-13B",
        "Yi-VL-34B",
        "LLaVA-HR-X-7B",
        "InternVL-1.5-26B",
        "QWen-VL-max",
        "GPT4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Talk2BEV Language-enhanced Birds-eye View Maps for Autonomous Driving": {
    "filename": "Talk2BEV Language-enhanced Birds-eye View Maps for Autonomous Driving.pdf",
    "analysis": {
      "benchmarks": [
        "Talk2BEV-Bench",
        "NuScenes"
      ],
      "models": [
        "Talk2BEV",
        "Lift-Splat-Shoot",
        "BLIP-2",
        "MiniGPT-4",
        "InstructBLIP-2"
      ]
    }
  },
  "Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt Optimization": {
    "filename": "Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "ATLAS",
        "FED",
        "GSM8K",
        "CodeNet",
        "Education"
      ],
      "models": [
        "HMAW",
        "Zero-shot CoT",
        "RaR",
        "On-MP",
        "Static-EP",
        "Dynamic-EP",
        "Multi-Persona",
        "APE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MMHQA-ICL Multimodal In-context Learning for Hybrid Question Answering over Text Tables and Images": {
    "filename": "MMHQA-ICL Multimodal In-context Learning for Hybrid Question Answering over Text Tables and Images.pdf",
    "analysis": {
      "benchmarks": [
        "MultimodalQA"
      ],
      "models": [
        "MMHQA-ICL",
        "AutoRouting",
        "ImplicitDecomp",
        "MuRAG",
        "SKURG",
        "PReasM-Large",
        "Binder"
      ]
    }
  },
  "Writer-Defined AI Personas for On-Demand Feedback Generation": {
    "filename": "Writer-Defined AI Personas for On-Demand Feedback Generation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5",
        "Impressona"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Neural Machine Translation for Code Generation": {
    "filename": "Neural Machine Translation for Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CodeContests",
        "NL2Bash"
      ],
      "models": [
        "RNN",
        "LSTM",
        "GRU",
        "Transformer",
        "GPT-3",
        "BERT",
        "CODEX",
        "ALPHA CODE",
        "Tree-to-Tree",
        "GNN",
        "DeepCoder",
        "DreamCoder",
        "Neural Decompilation",
        "NEUTRON",
        "Latent Predictor Networks",
        "SYNFIX",
        "DEEPFIX",
        "PIX2CODE",
        "SPARSE POINTER NETWORK",
        "NL2Bash",
        "Program Synthesis from Natural Language Using Recurrent Neural Networks",
        "INCODER",
        "POLYCODER",
        "SEQ2SQL",
        "RLCORRECTION",
        "COMP CODER",
        "SNM",
        "LCPC",
        "ASNS",
        "CNND ECODER",
        "SLM",
        "TREEGEN",
        "GMG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies": {
    "filename": "Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies.pdf",
    "analysis": {
      "benchmarks": [
        "Ultimatum Game",
        "Garden Path Sentences",
        "Milgram Shock Experiment",
        "Wisdom of Crowds"
      ],
      "models": [
        "GPT models",
        "ChatGPT",
        "GPT-4",
        "text-ada-001",
        "text-babbage-001",
        "text-curie-001",
        "text-davinci-001",
        "text-davinci-002",
        "text-davinci-003",
        "gpt-35-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VideoAgent Long-form Video Understanding with Large Language Model as Agent": {
    "filename": "VideoAgent Long-form Video Understanding with Large Language Model as Agent.pdf",
    "analysis": {
      "benchmarks": [
        "EgoSchema",
        "NExT-QA"
      ],
      "models": [
        "VideoAgent",
        "LLoVi",
        "FrozenBiLM",
        "InternVideo",
        "ImageViT",
        "ShortViViT",
        "LongViViT",
        "SeViLA",
        "Vamos",
        "MC-ViT-L",
        "Bard only (blind)",
        "Bard + ImageViT",
        "Bard + ShortViViT",
        "Bard + PALI",
        "GPT-4 Turbo (blind)",
        "GPT-4V",
        "Gemini 1.0 Pro",
        "VFC",
        "ATP",
        "MIST",
        "GF",
        "CoVGT",
        "SeViT",
        "HiTeA",
        "AssistGPT",
        "ViperGPT",
        "R-VLM",
        "R2A",
        "Q-ViD",
        "MovieChat",
        "Chat-UniVi",
        "Llama2-70B",
        "Mistral-8x7B",
        "GPT-3.5",
        "BLIP-2",
        "LaViLa",
        "CogAgent",
        "OpenCLIP ViT-G",
        "EVA-CLIP-8B",
        "EVA-CLIP-8B-plus"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompting Large Language Model for Machine Translation A Case Study": {
    "filename": "Prompting Large Language Model for Machine Translation A Case Study.pdf",
    "analysis": {
      "benchmarks": [
        "FLORES",
        "WMT21",
        "Multi-Domain",
        "PDC"
      ],
      "models": [
        "GLM-130B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Behavior Tree Generation using Large Language Models for Sequential Manipulation Planning with Human Instructions and Feedback": {
    "filename": "Behavior Tree Generation using Large Language Models for Sequential Manipulation Planning with Human Instructions and Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "Siemens Robot Assembly Challenge"
      ],
      "models": [
        "GPT-4",
        "LlaMA2-13B-Chat",
        "Mistral-7B"
      ]
    }
  },
  "Vision-Language Interpreter for Robot Task Planning": {
    "filename": "Vision-Language Interpreter for Robot Task Planning.pdf",
    "analysis": {
      "benchmarks": [
        "problem description generation (ProDG) dataset"
      ],
      "models": [
        "Vision-Language Interpreter (ViLaIn)",
        "Fast Downward",
        "Grounding-DINO",
        "BLIP-2",
        "GPT-4",
        "ViLaIn whole"
      ]
    }
  },
  "GFlowNet Fine-tuning for Diverse Correct Solutions in Mathematical Reasoning Tasks": {
    "filename": "GFlowNet Fine-tuning for Diverse Correct Solutions in Mathematical Reasoning Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "MATH500"
      ],
      "models": [
        "GFlowNet",
        "reward-maximizing RL",
        "Rejection sampling fine-tuning (RFT)",
        "Direct policy optimization (DPO)",
        "Proximal policy optimization (PPO)",
        "Llama3-8B base"
      ]
    }
  },
  "MARS Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset": {
    "filename": "MARS Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset.pdf",
    "analysis": {
      "benchmarks": [
        "MARS"
      ],
      "models": [
        "RoBERTa-Base",
        "RoBERTa-Large",
        "DeBERTa-Base",
        "DeBERTa-Large",
        "GPT2-XL",
        "CAR",
        "CANDLE",
        "VERA",
        "Meta-LLaMa-2-7B",
        "Meta-LLaMa-2-13B",
        "Meta-LLaMa-2-70B",
        "Meta-LLaMa-3-8B",
        "Meta-LLaMa-3-70B",
        "Gemma-1.1-7B",
        "Falcon-7B",
        "Falcon-40B",
        "Mistral-7B",
        "ChatGPT",
        "GPT4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Data Generation Perspective to the Mechanism of In-Context Learning": {
    "filename": "A Data Generation Perspective to the Mechanism of In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Bayesian inference framework",
        "function learning framework",
        "Hidden Markov Model (HMM)",
        "PAC-Bayesian framework",
        "Hopfield Network",
        "transformers",
        "linear transformer",
        "two-layer Neural Network",
        "GD++ algorithm",
        "softmax regression",
        "contrastive learning objective",
        "MLP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Joint Prompt Optimization of Stacked LLMs using Variational Inference": {
    "filename": "Joint Prompt Optimization of Stacked LLMs using Variational Inference.pdf",
    "analysis": {
      "benchmarks": [
        "BigBench-Hard (BBH)",
        "Mpqa",
        "Trec",
        "Subj",
        "Disaster",
        "Airline"
      ],
      "models": [
        "DLN-1",
        "DLN-2",
        "GPT-3 (text-davinci-003)",
        "GPT-4",
        "0-shot",
        "5-shot (ICL)",
        "KATE",
        "APE",
        "APE-15",
        "APE-400",
        "CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multimodal Web Navigation with Instruction-Finetuned Foundation Models": {
    "filename": "Multimodal Web Navigation with Instruction-Finetuned Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "MiniWoB++",
        "WebShop",
        "Mind2Web"
      ],
      "models": [
        "WebGUM",
        "PaLM-540B",
        "Flan-T5",
        "ViT",
        "WebN-T5",
        "CC-Net",
        "GPT-4",
        "RCI",
        "AdaPlanner",
        "Synapse",
        "InstructGPT",
        "GPT-3.5-turbo",
        "Flan-PaLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CustomListener Text-Guided Responsive Interaction for User-Friendly Listening Head Generation": {
    "filename": "CustomListener Text-Guided Responsive Interaction for User-Friendly Listening Head Generation.pdf",
    "analysis": {
      "benchmarks": [
        "ViCo",
        "RealTalk"
      ],
      "models": [
        "CustomListener",
        "RLHG",
        "PCH",
        "L2L",
        "MFR-Net",
        "ELP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ACCORD Closing the Commonsense Measurability Gap": {
    "filename": "ACCORD Closing the Commonsense Measurability Gap.pdf",
    "analysis": {
      "benchmarks": [
        "ACCORD CSQA",
        "CommonsenseQA",
        "CommonsenseQA 2.0",
        "OpenBookQA",
        "StrategyQA"
      ],
      "models": [
        "GPT-4o",
        "Llama-3-70B-Instruct",
        "Mixtral-8x22B-Instruct-v0.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification": {
    "filename": "Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification.pdf",
    "analysis": {
      "benchmarks": [
        "Web-of-Science (WOS)",
        "DBpedia"
      ],
      "models": [
        "HierICRF",
        "BERT (Vanilla FT)",
        "HiMatch-BERT",
        "HGCLR",
        "HPT",
        "SoftVerb",
        "HierVerb",
        "HierICRF-BERT",
        "HierICRF-T5",
        "SoftVerb-T5"
      ]
    }
  },
  "UniGen A Unified Framework for Textual Dataset Generation Using Large Language Models": {
    "filename": "UniGen A Unified Framework for Textual Dataset Generation Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "TruthfulQA",
        "MMLU",
        "HellaSwag"
      ],
      "models": [
        "UNIGEN",
        "GPT-4",
        "Claude3-Opus",
        "Llama3-70b",
        "ChatGPT",
        "Claude-3",
        "Llama3-8b",
        "Mistral-7b",
        "Mixtral-8x7b",
        "Yi-34b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Knowledge Engineering using Large Language Models": {
    "filename": "Knowledge Engineering using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLMs",
        "CommonKADS",
        "NeON",
        "Ontology 101",
        "Presutti\u2019s ontology design patterns",
        "vision-language models",
        "COMET",
        "Jigsaw"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Crossing New Frontiers Knowledge-Augmented Large Language Model Prompting for Zero-Shot Text-Based De Novo Molecule Design": {
    "filename": "Crossing New Frontiers Knowledge-Augmented Large Language Model Prompting for Zero-Shot Text-Based De Novo Molecule Design.pdf",
    "analysis": {
      "benchmarks": [
        "ChEBI-20"
      ],
      "models": [
        "FrontierX: LLM-MG",
        "MolT5",
        "T5",
        "RNN-GRU",
        "Vanilla Transformer",
        "GPT-4",
        "GPT-3.5-turbo",
        "GPT-3.0-text-davinci-003",
        "Google Bard",
        "DeBERTa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Calibrating LLM-Based Evaluator": {
    "filename": "Calibrating LLM-Based Evaluator.pdf",
    "analysis": {
      "benchmarks": [
        "NewsRoom",
        "SummEval",
        "SFRES",
        "SFHOT",
        "QAGS-XSUM",
        "QAGS-CNN"
      ],
      "models": [
        "AUTOCALIBRATE",
        "GPT-4",
        "ChatGPT",
        "GPTScore",
        "G-EVAL-3.5",
        "G-EVAL-4",
        "BERTScore",
        "MoverScore",
        "PRISM",
        "BartScore",
        "CTC",
        "UniEval",
        "ROUGE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models": {
    "filename": "Hierarchical Network Fusion for Multi-Modal Electron Micrograph Representation Learning with Foundational Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SEM dataset",
        "NEU-SDD",
        "CMI",
        "KTH-TIPS"
      ],
      "models": [
        "MultiFusion-LLM W/GPT-3.5",
        "MultiFusion-LLM W/Google Bard",
        "ConvNets",
        "ViTs",
        "Vision Contrastive Learning (VCL)",
        "AlexNet",
        "DenseNet",
        "ResNet",
        "VGG",
        "GoogleNet",
        "SqueezeNet",
        "Barlowtwins",
        "SimCLR",
        "byol",
        "moco",
        "nnclr",
        "simsiam",
        "CCT",
        "CVT",
        "ConViT",
        "ConvVT",
        "CrossViT",
        "PVTC",
        "SwinT",
        "VanillaViT",
        "Visformer",
        "ATS",
        "CaiT",
        "DeepViT",
        "Dino",
        "Distallation",
        "LeViT",
        "MA",
        "NesT",
        "PatchMerger",
        "PiT",
        "RegionViT",
        "SMIM",
        "T2TViT",
        "ViT-SD",
        "GSLGBT",
        "GRACE",
        "BGRL",
        "InfoGraph",
        "APPNP",
        "AGNN",
        "ARMA",
        "DNA",
        "GAT",
        "GGConv",
        "GraphConv",
        "GCN2Conv",
        "ChebConv",
        "GraphUNet",
        "MPNN",
        "RGGConv",
        "SuperGAT",
        "TAGConv"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning": {
    "filename": "Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "CARP",
        "GSM8K",
        "MATH",
        "Algebra",
        "Prealgebra",
        "Counting and Probability",
        "Number Theory",
        "GK-Cloze",
        "SAT-Math"
      ],
      "models": [
        "GPT-3",
        "ChatGPT",
        "text-davinci-002",
        "text-davinci-003",
        "claude-v1.3",
        "gpt-3.5-turbo",
        "DELI",
        "Random CoT",
        "Complex CoT",
        "Retrieval CoT",
        "PAL",
        "ReAct",
        "LP",
        "PHP",
        "Iterative CoT",
        "Iterative ReAct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RARR Researching and Revising What Language Models Say Using Language Models": {
    "filename": "RARR Researching and Revising What Language Models Say Using Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Questions (NQ)",
        "StrategyQA (SQA)",
        "QReCC"
      ],
      "models": [
        "RARR",
        "PaLM 540B",
        "GPT-3 text-davinci-002",
        "LaMDA",
        "EFEC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On the Planning Abilities of Large Language Models - A Critical Investigation": {
    "filename": "On the Planning Abilities of Large Language Models - A Critical Investigation.pdf",
    "analysis": {
      "benchmarks": [
        "Blocksworld",
        "Logistics",
        "Mystery Blocksworld"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Instruct-GPT3.5",
        "Instruct-GPT3",
        "GPT-3",
        "BLOOM",
        "LPG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PACE Improving Prompt with Actor-Critic Editing for Large Language Model": {
    "filename": "PACE Improving Prompt with Actor-Critic Editing for Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "Instruction Induction",
        "Big-Bench"
      ],
      "models": [
        "PACE",
        "ChatGPT",
        "gpt-3.5-turbo",
        "text-davinci-002",
        "text-davinci-003",
        "GPT-4",
        "APE",
        "EvoPrompt",
        "PROmpting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Shopping MMLU A Massive Multi-Task Online Shopping Benchmark for Large Language Models": {
    "filename": "Shopping MMLU A Massive Multi-Task Online Shopping Benchmark for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Shopping MMLU",
        "MA VE",
        "Amazon-M2",
        "Amazon ESCI",
        "EComInstruct-Test (EcomGPT)",
        "ECInstruct (eCeLLM)"
      ],
      "models": [
        "Claude-3 Sonnet",
        "Claude-2",
        "ChatGPT",
        "BLLaMA3-70B-Instruct",
        "QWen1.5-72B",
        "LLaMA3-70B",
        "LLaMA2-70B-chat",
        "LLaMA2-70B",
        "Mixtral-8x7b",
        "QWen1.5-14B",
        "eCeLLM-L",
        "Vicuna-13B",
        "LLaMA2-13B-chat",
        "LLaMA2-13B",
        "LLaMA3-8B-Instruct",
        "LLaMA3-8B",
        "QWen1.5-7B",
        "eCeLLM-M",
        "Zephyr",
        "Mistral-7B-instruct",
        "Mistral-7B",
        "Vicuna-7B",
        "LLaMA2-7B-chat",
        "LLaMA2-7B",
        "QWen1.5-4B",
        "Phi-2",
        "eCeLLM-S"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Digital Avatars Framework Development and Their Evaluation": {
    "filename": "Digital Avatars Framework Development and Their Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "Crowd Vote",
        "Presidential Debate 2020 dataset"
      ],
      "models": [
        "Baseline LLM",
        "Character.ai",
        "Our LLM with show don't tell prompting"
      ]
    }
  },
  "LICO Large Language Models for In-Context Molecular Optimization": {
    "filename": "LICO Large Language Models for In-Context Molecular Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "Practical Molecular Optimization (PMO)"
      ],
      "models": [
        "LICO",
        "REINVENT",
        "Graph GA",
        "GP BO",
        "TNP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Geotechnical Parrot Tales GPT Harnessing Large Language Models in geotechnical engineering": {
    "filename": "Geotechnical Parrot Tales GPT Harnessing Large Language Models in geotechnical engineering.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-3.5",
        "GPT-4",
        "GPT-3.5-turbo",
        "text-davinci-003",
        "LlaMA",
        "Alpaca"
      ]
    }
  },
  "Using Language Models For Knowledge Acquisition in Natural Language Reasoning Problems": {
    "filename": "Using Language Models For Knowledge Acquisition in Natural Language Reasoning Problems.pdf",
    "analysis": {
      "benchmarks": [
        "Smullyan's 'Ladies or Tigers?' puzzles",
        "Alpine Club puzzle",
        "Who\u2019s in the car puzzle"
      ],
      "models": [
        "ChatGPT",
        "GPT4"
      ]
    }
  },
  "Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines": {
    "filename": "Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines.pdf",
    "analysis": {
      "benchmarks": [
        "Synthetic Patient Dataset"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5 Turbo",
        "LLaMA",
        "PaLM 2",
        "Binary Decision Tree (BDT)",
        "Program-Aided Graph Construction (PAGC)",
        "Chain-of-Thought-Few-Shot Prompting (CoT-FSP)",
        "Zero-Shot Prompting (ZSP)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "High-throughput Biomedical Relation Extraction for Semi-Structured Web Articles Empowered by Large Language Models": {
    "filename": "High-throughput Biomedical Relation Extraction for Semi-Structured Web Articles Empowered by Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BioRED",
        "CDR",
        "CHEMPROT",
        "custom benchmark dataset"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Llama2 70B",
        "Llama2 13B",
        "Llama2 7B",
        "SOLAR 70B"
      ]
    }
  },
  "Towards Understanding Chain-of-Thought Prompting An Empirical Study of What Matters": {
    "filename": "Towards Understanding Chain-of-Thought Prompting An Empirical Study of What Matters.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "Bamboogle"
      ],
      "models": [
        "InstructGPT-175B",
        "text-davinci-002",
        "text-davinci-003",
        "PaLM",
        "Flan-PaLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "3DG A Framework for Using Generative AI for Handling Sparse Learner Performance Data From Intelligent Tutoring Systems": {
    "filename": "3DG A Framework for Using Generative AI for Handling Sparse Learner Performance Data From Intelligent Tutoring Systems.pdf",
    "analysis": {
      "benchmarks": [
        "AutoTutor ITS dataset from CSAL"
      ],
      "models": [
        "3DG framework",
        "Generative Adversarial Network (GAN)",
        "Generative Pre-trained Transformer (GPT)",
        "GPT-4"
      ]
    }
  },
  "ChartMimic Evaluating LMMs Cross-Modal Reasoning Capability via Chart-to-Code Generation": {
    "filename": "ChartMimic Evaluating LMMs Cross-Modal Reasoning Capability via Chart-to-Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "ChartMimic"
      ],
      "models": [
        "GPT-4V",
        "Claude-3-opus",
        "GeminiProVision",
        "Phi-3-Vision",
        "LLaVA-Next-Vicuna-7B",
        "DeepSeek-VL-7B",
        "LLaVA-Next-Mistral-7B",
        "IDEFICS2-8B",
        "MiniCPM-Llama3-V2.5",
        "Qwen-VL-Chat",
        "LLaVA-Next-Vicuna-13B",
        "Cogvlm2-llama3-chat-19B",
        "InternVL-Chat-V1.5",
        "LLaVA-Next-Yi-34B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TurtleBench A Visual Programming Benchmark in Turtle Geometry": {
    "filename": "TurtleBench A Visual Programming Benchmark in Turtle Geometry.pdf",
    "analysis": {
      "benchmarks": [
        "TurtleBench"
      ],
      "models": [
        "GPT-4o",
        "Gemini 1.5 Flash",
        "Llava-1.5-13B",
        "Qwen-VL-Max",
        "CogVLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts": {
    "filename": "A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts.pdf",
    "analysis": {
      "benchmarks": [
        "Torrance Tests of Creative Thinking (TTCT)"
      ],
      "models": [
        "GPS framework",
        "ChatGPT 3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Flows Building Blocks of Reasoning and Collaborating AI": {
    "filename": "Flows Building Blocks of Reasoning and Collaborating AI.pdf",
    "analysis": {
      "benchmarks": [
        "Codeforces",
        "LeetCode"
      ],
      "models": [
        "GPT-4",
        "Code",
        "Code_Debug_Collab",
        "Plan_Oracle-Code_Debug_Collab",
        "Code_Reflection",
        "Code_Collaboration",
        "Code_Debug",
        "Plan-Code",
        "Plan_Reflection-Code",
        "Plan_Collaboration-Code",
        "Plan_Oracle-Code"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reflexive Guidance Improving OoDD in Vision-Language Models via Self-Guided Image-Adaptive Concept Generation": {
    "filename": "Reflexive Guidance Improving OoDD in Vision-Language Models via Self-Guided Image-Adaptive Concept Generation.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet200",
        "CIFAR10",
        "NINCO",
        "SSB Hard",
        "iNaturalist",
        "Textures",
        "Openimage-O"
      ],
      "models": [
        "GPT-4o",
        "Gemini Pro 1.5",
        "Claude 3.5 Sonnet",
        "LLaVA-v1.6-Mistral-7B",
        "GLM-4v-9B",
        "QWEN-VL-Chat",
        "InternVL2-InternLM2-Chat-26B",
        "InternVL2-LLaMA3-76B",
        "OpenCLIP",
        "SCALE",
        "fDBD",
        "AugMix+ASH",
        "ReGuide",
        "InternVL2-26B + ReGuide",
        "InternVL2-76B + ReGuide",
        "GPT-4o + ReGuide"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Aligning LLM Agents by Learning Latent Preference from User Edits": {
    "filename": "Aligning LLM Agents by Learning Latent Preference from User Edits.pdf",
    "analysis": {
      "benchmarks": [
        "summarization",
        "email writing"
      ],
      "models": [
        "CIPHER",
        "PRELUDE",
        "GPT-4",
        "No Learning",
        "E-then-e LPI",
        "Continual LPI",
        "ICL-edit",
        "CoT-edit",
        "Oracle Preference"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CodePlan Unlocking Reasoning Potential in Large Langauge Models by Scaling Code-form Planning": {
    "filename": "CodePlan Unlocking Reasoning Potential in Large Langauge Models by Scaling Code-form Planning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "SVAMP",
        "Boolean Expression from Big-bench-hard (BBH)",
        "Coin Flipping",
        "Last Letter Concatenation",
        "Dyck Language from BBH",
        "AlpacaEval 1.0",
        "AlpacaEval 2.0",
        "MT-Bench",
        "HotpotQA",
        "MuSiQue",
        "ALFWorld"
      ],
      "models": [
        "CODEPLAN",
        "Mistral-7B",
        "Llama-2-7B",
        "Llama-2-13B",
        "Plan-and-Solve (PS) Prompting",
        "Quiet-STaR",
        "Vanilla Training",
        "Natural Language Plan",
        "CODEREASON"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can LLMs predict the convergence of Stochastic Gradient Descent": {
    "filename": "Can LLMs predict the convergence of Stochastic Gradient Descent.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLaMA2-13B",
        "LLaMA2-7B"
      ]
    }
  },
  "Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning": {
    "filename": "Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "SVAMP",
        "TabMWP",
        "ASDiv",
        "MAWPS",
        "Hungarian Exam"
      ],
      "models": [
        "Qwen1.5-72B",
        "GPT-4",
        "Gemini",
        "Mistral",
        "Llama-2",
        "DeepSeekMath",
        "MetaMath",
        "MMIQC",
        "WizardMath",
        "Platypus-2",
        "MAmmoTH",
        "KPMath-Plus",
        "KPMath-Plus-Mistral-7B",
        "KPMath-Plus-DSMath",
        "KPMath-Plus-Llama-2",
        "KPMath-Plus-Qwen1.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Brain in a Vat On Missing Pieces Towards Artificial General Intelligence in Large Language Models": {
    "filename": "Brain in a Vat On Missing Pieces Towards Artificial General Intelligence in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SAT",
        "GRE",
        "LSAT",
        "Gaokao",
        "China College Entrance Exam",
        "Lawyer Qualification Test",
        "Civil Service Exam",
        "JEEBench",
        "Vietnamese High School Graduation Examination",
        "USABO Semifinal Exam",
        "USNCO Local Section Exam",
        "Medical Knowledge Self-Assessment Program",
        "Codeforces",
        "AP Art History",
        "AP Biology",
        "AP Calculus BC",
        "AP Chemistry",
        "AP English Language and Composition",
        "AP English Literature and Composition",
        "AP Environmental Science",
        "AP Macroeconomics",
        "AP Microeconomics",
        "AP Physics 2",
        "AP Psychology",
        "AP Statistics",
        "AP US Government",
        "AP US History",
        "AP World History",
        "AMC 10",
        "AMC 12",
        "Introductory Sommelier",
        "Certified Sommelier",
        "Advanced Sommelier",
        "Leetcode",
        "AGIEval",
        "MATH",
        "Corr2Cause",
        "ACRE",
        "ARC",
        "BIG-Bench",
        "Evals",
        "PVR",
        "RAVEN",
        "ToMi",
        "Only Connect"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "GPT-3",
        "ChatGPT",
        "Text-Davinci-003",
        "LLaMa-6.7B",
        "Alpaca-6.7B",
        "Alpaca-LoRA",
        "OPT-2.7B",
        "OPT-6.7B",
        "OPT-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "QFMTS Generating Query-Focused Summaries over Multi-Table Inputs": {
    "filename": "QFMTS Generating Query-Focused Summaries over Multi-Table Inputs.pdf",
    "analysis": {
      "benchmarks": [
        "QFMTS"
      ],
      "models": [
        "QFMTS method",
        "BART-base-FT",
        "BART-large-FT",
        "TAPEX-FT",
        "MultiTab-FT",
        "OmniTab-FT",
        "Llama-2-FT",
        "DirectSumm",
        "Reason-then-Summ"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Uncovering Autoregressive LLM Knowledge of Thematic Fit in Event Representation": {
    "filename": "Uncovering Autoregressive LLM Knowledge of Thematic Fit in Event Representation.pdf",
    "analysis": {
      "benchmarks": [
        "McRae",
        "Pado",
        "Fer-Ins",
        "Fer-Loc"
      ],
      "models": [
        "GPT",
        "Llama",
        "BG: GSD2015",
        "B0: NN RF",
        "B1: ResRoFA-MT",
        "B2: 20% subset v2",
        "B3a: Glove-shared-not-tuned",
        "B3b: Glove-shared-tuned",
        "B3c: Glove-shared-tuned with 20%M"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Training microrobots to swim by a large language model": {
    "filename": "Training microrobots to swim by a large language model.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "Purcell's three-link swimmer",
        "Najafi-Golestanian (NG)'s three-sphere swimmer",
        "Q-learning-based RL"
      ]
    }
  },
  "InstructProtein Aligning Human and Protein Language via Knowledge Instruction": {
    "filename": "InstructProtein Aligning Human and Protein Language via Knowledge Instruction.pdf",
    "analysis": {
      "benchmarks": [
        "DeepLoc",
        "Gene Ontology (GO)",
        "Metal Ion Binding (MIB)",
        "UniProtKB",
        "SCOPe"
      ],
      "models": [
        "InstructProtein",
        "OPT",
        "LLaMA",
        "Alpaca",
        "Galactica",
        "BioMedGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Complexity-Based Theory of Compositionality": {
    "filename": "A Complexity-Based Theory of Compositionality.pdf",
    "analysis": {
      "benchmarks": [
        "COCO"
      ],
      "models": [
        "lookup table representations",
        "context-free grammar representations",
        "emergent languages from multi-agent training",
        "iterated learning",
        "normal language system"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PASS Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork": {
    "filename": "PASS Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork.pdf",
    "analysis": {
      "benchmarks": [
        "CIFAR-10",
        "CIFAR-100",
        "Tiny-ImageNet",
        "Food101",
        "DTD",
        "StanfordCars",
        "ImageNet"
      ],
      "models": [
        "PASS",
        "ResNet-18",
        "ResNet-34",
        "ResNet-50",
        "VGG-16",
        "Group-L1",
        "GrowReg",
        "Slim",
        "DepGraph",
        "ABC Pruner",
        "ResNeXt-50",
        "Swin-T",
        "ViT-B/16",
        "SSS",
        "GFP",
        "X-Pruner",
        "STEP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhance the Robustness of Text-Centric Multimodal Alignments": {
    "filename": "Enhance the Robustness of Text-Centric Multimodal Alignments.pdf",
    "analysis": {
      "benchmarks": [
        "PetFinder"
      ],
      "models": [
        "Kosmos-2",
        "Flamingo",
        "MLP",
        "GPT-4o",
        "GPT-3.5-turbo",
        "Mixtral8x7b"
      ]
    }
  },
  "LLMs can Find Mathematical Reasoning Mistakes by Pedagogical Chain-of-Thought": {
    "filename": "LLMs can Find Mathematical Reasoning Mistakes by Pedagogical Chain-of-Thought.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-Bench Mistake",
        "PRM800K"
      ],
      "models": [
        "PedCoT",
        "Direct-Step Prompting",
        "Vanilla Two-stage Prompting",
        "Zero-shot CoT",
        "Plan-and-Solve Prompting",
        "SelfCheck",
        "GPT-4",
        "GPT-4 Turbo"
      ]
    }
  },
  "LLM Augmentations to support Analytical Reasoning over Multiple Documents": {
    "filename": "LLM Augmentations to support Analytical Reasoning over Multiple Documents.pdf",
    "analysis": {
      "benchmarks": [
        "Sign of the Crescent",
        "Atlantic Storm",
        "Manpad"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Llama-2",
        "Mistral-7B",
        "Gemma-2",
        "Dynamic Evidence Trees (DETs)",
        "Regular DET",
        "Person-based DET"
      ]
    }
  },
  "Improving Image Clustering with Artifacts Attenuation via Inference-Time Attention Engineering": {
    "filename": "Improving Image Clustering with Artifacts Attenuation via Inference-Time Attention Engineering.pdf",
    "analysis": {
      "benchmarks": [
        "Tiny ImageNet",
        "CIFAR-100",
        "CIFAR-10",
        "STL-10",
        "ImageNet-1k",
        "MS COCO"
      ],
      "models": [
        "Vision Transformer (ViT)",
        "DINOv2",
        "Inference-Time Attention Engineering (ITAE)",
        "ViT-S/14 distilled",
        "ViT-B/14 distilled",
        "ViT-L/14 distilled",
        "ViT-g/14",
        "CLIP",
        "DeiT III"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Ask more know better Reinforce-Learned Prompt Questions for Decision Making with Large Language Models": {
    "filename": "Ask more know better Reinforce-Learned Prompt Questions for Decision Making with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Overcooked",
        "FourRoom",
        "Tower of Hanoi",
        "Frozen Lake",
        "ChainWorld"
      ],
      "models": [
        "Bilevel-LLM",
        "GFlan",
        "Vanilla PPO",
        "GPT-3.5",
        "GPT-3.5 with CoT prompt",
        "ReAct",
        "Bilevel-LLM(Random)",
        "Bilevel-LLM(UCB)",
        "Bilevel-LLM-Symbolic"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM3 Large Language Model-based Task and Motion Planning with Motion Failure Reasoning": {
    "filename": "LLM3 Large Language Model-based Task and Motion Planning with Motion Failure Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "simulated tabletop box-packing task"
      ],
      "models": [
        "LLM3",
        "LLM3Backtrack",
        "Backtrack",
        "LLM3Scratch",
        "Scratch"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "WALL-E Embodied Robotic WAiter Load Lifting with Large Language Model": {
    "filename": "WALL-E Embodied Robotic WAiter Load Lifting with Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "real-world scenarios"
      ],
      "models": [
        "WALL-E",
        "ChatGPT",
        "DINO",
        "SAM",
        "SAR-Net"
      ]
    }
  },
  "JiuZhang30 Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models": {
    "filename": "JiuZhang30 Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "MATH",
        "SVAMP",
        "ASDiv",
        "MAWPS",
        "CARP",
        "TabMWP",
        "AQuA",
        "SAT-Math",
        "MMLU-STEM",
        "OCW-Math"
      ],
      "models": [
        "JiuZhang3.0",
        "DeepSeekMath-7B",
        "DeepSeekMath-7B-RL",
        "MAmmoTH2-8x7B-Plus",
        "MAmmoTH2-7B-Plus",
        "MAmmoTH2-8B-Plus",
        "DeepSeekMath-7B-Instruct",
        "ChatGPT",
        "GPT-4",
        "Qwen-1.5-110B",
        "Qwen-1.5-72B",
        "Mixtral-8x7B",
        "Llemma-34B",
        "Intern-Math-20B",
        "ChatGLM-Math-32B",
        "Mistral-7B",
        "LLaMA-3-8B",
        "Gemma-7B",
        "Qwen-1.5-7B",
        "Llemma-7B",
        "InternLM-Math-7B",
        "Rho-1-Math-7B",
        "Mistral-7B-MMIQC",
        "MetaMath-Mistral-7B",
        "Abel-7B-002",
        "WizardMath-7B-1.1",
        "Math-Shepherd-Mistral-7B",
        "KPMath-DSMath-7B",
        "DeepSeek-7B",
        "CodeLLama",
        "MAmmoTH-7B-Mistral",
        "MathCoder-7B-CL",
        "ToRA-7B-Code",
        "MARIO-OVM-7B",
        "MMOS-CODE-7B",
        "OpenMath-Mistral-7B",
        "Rho-1-Math-7B-Code"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Can Language Models Explain Their Own Classification Behavior": {
    "filename": "Can Language Models Explain Their Own Classification Behavior.pdf",
    "analysis": {
      "benchmarks": [
        "ArticulateRules"
      ],
      "models": [
        "GPT-3",
        "GPT-3-plus",
        "GPT-3-c",
        "GPT-3-c-mc",
        "GPT-3-c-f",
        "GPT-4",
        "Curie",
        "Babbage",
        "Ada",
        "Davinci"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Code as Policies Language Model Programs for Embodied Control": {
    "filename": "Code as Policies Language Model Programs for Embodied Control.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "RoboCodeGen"
      ],
      "models": [
        "Code as Policies (CaP)",
        "CLIPort",
        "NL Planner",
        "GPT-3",
        "Codex"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploration with Principles for Diverse AI Supervision": {
    "filename": "Exploration with Principles for Diverse AI Supervision.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "MBPP",
        "HumanEval"
      ],
      "models": [
        "ChatGPT",
        "Vicuna",
        "LLaMA2",
        "GPT-4",
        "Claude2",
        "WizardMath",
        "MAmmoTH",
        "EAI",
        "Self-Instruct",
        "RFT",
        "CodeLLaMA"
      ]
    }
  },
  "DrSpider A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness": {
    "filename": "DrSpider A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness.pdf",
    "analysis": {
      "benchmarks": [
        "Spider",
        "Dr.Spider"
      ],
      "models": [
        "RATSQL",
        "GRAPPA",
        "SMBOP",
        "T5-BASE",
        "T5-LARGE",
        "T5-3B",
        "T5-3B LK",
        "PICARD",
        "GPT-3 CODEX"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning by Self-Explaining": {
    "filename": "Learning by Self-Explaining.pdf",
    "analysis": {
      "benchmarks": [
        "MNIST",
        "ChestMNIST",
        "CLEVR-Hans3",
        "CUB-10",
        "VQA-X",
        "DecoyMNIST",
        "ColorMNIST"
      ],
      "models": [
        "CNN",
        "CNN-LSX",
        "NeSy",
        "NeSy-LSX",
        "VLM",
        "VLM-LSX"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RePLan Robotic Replanning with Perception and Language Models": {
    "filename": "RePLan Robotic Replanning with Perception and Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Reasoning and Control (RC) benchmark"
      ],
      "models": [
        "REPLAN",
        "GPT-4V",
        "Language to Rewards",
        "PDDL",
        "PDDLStream",
        "Qwen-VL-Chat-7B",
        "MuJoCo MPC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Right this way Can VLMs Guide Us to See More to Answer Questions": {
    "filename": "Right this way Can VLMs Guide Us to See More to Answer Questions.pdf",
    "analysis": {
      "benchmarks": [
        "VizWiz",
        "VizWiz-grounding",
        "Directional Guidance dataset"
      ],
      "models": [
        "LLaVA-1.5",
        "InstructBlip",
        "GPT-4o",
        "CLIP",
        "LLaVA-1.5 7b",
        "LLaVA-1.5 13b",
        "InstructBlip 7b",
        "CLIP with linear probing"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "In-Context Learning Unlocked for Diffusion Models": {
    "filename": "In-Context Learning Unlocked for Diffusion Models.pdf",
    "analysis": {
      "benchmarks": [
        "ControlNet example images",
        "DreamBooth data benchmark",
        "test split of our base dataset"
      ],
      "models": [
        "Prompt Diffusion",
        "ControlNet",
        "CN(FT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Revisiting Conversation Discourse for Dialogue Disentanglement": {
    "filename": "Revisiting Conversation Discourse for Dialogue Disentanglement.pdf",
    "analysis": {
      "benchmarks": [
        "Ubuntu IRC",
        "Movie Dialogue"
      ],
      "models": [
        "BERT",
        "DiaBERT",
        "LSTM",
        "CNN",
        "GPT-3.5",
        "DialogueRNN",
        "SCIJE",
        "DialogueGCN",
        "D2G",
        "DSGFNet",
        "EGCN",
        "DropoutConnect BiLSTM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Positional Description Matters for Transformers Arithmetic": {
    "filename": "Positional Description Matters for Transformers Arithmetic.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "GPT2-small",
        "12-layer transformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Ground-A-Score Scaling Up the Score Distillation for Multi-Attribute Editing": {
    "filename": "Ground-A-Score Scaling Up the Score Distillation for Multi-Attribute Editing.pdf",
    "analysis": {
      "benchmarks": [
        "Visual Genome",
        "CLIP score",
        "LPIPS"
      ],
      "models": [
        "Ground-A-Score",
        "StableDiffusion 1.5",
        "GPT4-vision",
        "groundingDINO",
        "InstructPix2Pix",
        "GLIGEN",
        "DDS",
        "CDS"
      ]
    }
  },
  "Progressive Translation Improving Domain Robustness of Neural Machine Translation with Intermediate Sequences": {
    "filename": "Progressive Translation Improving Domain Robustness of Neural Machine Translation with Intermediate Sequences.pdf",
    "analysis": {
      "benchmarks": [
        "IWSLT'14 German-English",
        "OPUS German-English",
        "Allegra German-Romansh",
        "IT",
        "Law",
        "Medical",
        "Koran",
        "Subtitles",
        "Blogs"
      ],
      "models": [
        "Transformer",
        "Progressive Translation (PT)",
        "PT simple",
        "PT full",
        "SSMBA",
        "Reverse+Mono+Replace (RMP)"
      ]
    }
  },
  "Checker Bug Detection and Repair in Deep Learning Libraries": {
    "filename": "Checker Bug Detection and Repair in Deep Learning Libraries.pdf",
    "analysis": {
      "benchmarks": [
        "TensorFlow",
        "PyTorch",
        "JAX"
      ],
      "models": [
        "TensorGuard",
        "AutoCodeRover"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MvP Multi-view Prompting Improves Aspect Sentiment Tuple Prediction": {
    "filename": "MvP Multi-view Prompting Improves Aspect Sentiment Tuple Prediction.pdf",
    "analysis": {
      "benchmarks": [
        "Rest15",
        "Rest16",
        "Restaurant-ACOS",
        "Laptop-ACOS",
        "ASTE (R15)",
        "ASTE (R16)",
        "TASD (R14)",
        "TASD (R15)",
        "TASD (R16)",
        "ASQP (R15)",
        "ASQP (R16)"
      ],
      "models": [
        "MVP",
        "TAS-BERT",
        "Jet-BERT",
        "Extract-Classify",
        "GAS",
        "Paraphrase",
        "UIE",
        "Seq2Path",
        "DLO",
        "UnifiedABSA",
        "LEGO-ABSA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Applications of Generative AI in Healthcare algorithmic ethical legal and societal considerations": {
    "filename": "Applications of Generative AI in Healthcare algorithmic ethical legal and societal considerations.pdf",
    "analysis": {
      "benchmarks": [
        "Med-HALT",
        "MultiMedQA",
        "MedQA",
        "MedMCQA",
        "PubMedQA",
        "LiveQA",
        "MedicationQA",
        "MMLU Clinical Topics",
        "HealthSearchQA"
      ],
      "models": [
        "Generative AI models",
        "Generative adversarial networks (GANs)",
        "Variational autoencoders (VAEs)",
        "LLMs",
        "FlanPaLM",
        "GPT models",
        "Large Language Models (LLMs)",
        "Large Multimodal Models (LMMs)",
        "GPT-3",
        "CLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Online Training of Large Language Models Learn while chatting": {
    "filename": "Online Training of Large Language Models Learn while chatting.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Llama2-7b-chat",
        "Prompt",
        "Full-SFT",
        "Online Training (OT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Beyond Human Vision The Role of Large Vision Language Models in Microscope Image Analysis": {
    "filename": "Beyond Human Vision The Role of Large Vision Language Models in Microscope Image Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "NFFA-Europe - 100% SEM Dataset",
        "NFFA-randomly-sampled",
        "NFFA-manually-sampled",
        "BBBC005",
        "BBBC005-sampled"
      ],
      "models": [
        "ChatGPT",
        "ChatGPT-4",
        "Gemini",
        "LLaVA",
        "Segment Anything Model (SAM)",
        "GPT-visual",
        "GPT-code",
        "SAM-standard",
        "SAM-custom",
        "SAM-custom-w1",
        "SAM-custom-w2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ToolACE Winning the Points of LLM Function Calling": {
    "filename": "ToolACE Winning the Points of LLM Function Calling.pdf",
    "analysis": {
      "benchmarks": [
        "Berkeley Function-Calling Leaderboard",
        "BFCL-v1",
        "BFCL-v2",
        "MMLU",
        "HumanEval",
        "GSM8K",
        "CommonSenseQA"
      ],
      "models": [
        "ToolACE-8B",
        "Gorilla",
        "ToolAlpaca",
        "ToolLLM",
        "Functionary",
        "xLAM",
        "Granite",
        "Claude-3.5-Sonnet-0620",
        "Functionary-Medium-v3.1",
        "xLAM-7b-fc-r",
        "GPT-4-1106-Preview",
        "GPT-4-0613",
        "GPT-4-0125-Preview",
        "Claude-3-Opus-20240229",
        "GPT-4o-mini-2024-07-18",
        "Nemotron-4-340b-instruct",
        "GPT-4-turbo-2024-04-09",
        "GPT-4o-2024-08-06",
        "Gorilla-OpenFunctions-v2",
        "Granite-20b-FunctionCalling",
        "yi-large",
        "Meta-Llama-3-70B-Instruct",
        "Functionary-Small-v3.2",
        "Qwen-1.5-7B-Chat",
        "LLaMA-3-8B-Instruct",
        "LLaMA-3.1-8B-Instruct",
        "xLAM-7B-fc-r"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "List Items One by One A New Data Source and Learning Paradigm for Multimodal LLMs": {
    "filename": "List Items One by One A New Data Source and Learning Paradigm for Multimodal LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "POPE",
        "MME",
        "SEED-Bench",
        "LLaVA-Bench",
        "MM-Vet"
      ],
      "models": [
        "GPT-4V",
        "LLaVA-v1.5",
        "Gemini",
        "SoM-LLaVA",
        "BLIP-2",
        "InstructBLIP",
        "Fuyu-8B",
        "LLaMA-Adapter-V2",
        "mPLUG-Owl-2",
        "Qwen-VL",
        "Qwen-VL-Chat",
        "SPHINX",
        "SoM-LLaVA-1.5",
        "SoM-LLaVA-1.5-T"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TaskWeaver A Code-First Agent Framework": {
    "filename": "TaskWeaver A Code-First Agent Framework.pdf",
    "analysis": {
      "benchmarks": [
        "Eval-Cases",
        "DS-1000",
        "InfiAgent-DABench",
        "DSEval"
      ],
      "models": [
        "TaskWeaver",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Faithful Chain-of-Thought Large Language Models are Bridging Reasoners": {
    "filename": "Towards Faithful Chain-of-Thought Large Language Models are Bridging Reasoners.pdf",
    "analysis": {
      "benchmarks": [
        "AQuA",
        "GSM8K",
        "WinoGrande",
        "SocialIQA",
        "ProofWriter",
        "PronotoQA"
      ],
      "models": [
        "Llama2-13B",
        "Mistral-7B",
        "inferential bridging",
        "CoT",
        "CoT-SC",
        "LtM",
        "SR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Fine-grained Analysis of In-context Linear Estimation Data Architecture and Beyond": {
    "filename": "Fine-grained Analysis of In-context Linear Estimation Data Architecture and Beyond.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Linear Attention",
        "H3",
        "LoRA",
        "1-layer Linear Attention",
        "1-layer H3",
        "SSM",
        "Retrieval Augmented Generation (RAG)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Growing from Exploration A self-exploring framework for robots based on foundation models": {
    "filename": "Growing from Exploration A self-exploring framework for robots based on foundation models.pdf",
    "analysis": {
      "benchmarks": [
        "BLOCKS WOLD",
        "RLBench",
        "Desktop Organization",
        "Cup Acquisition"
      ],
      "models": [
        "GExp",
        "framework without collecting skills",
        "framework without self-verification",
        "Open-Loop",
        "Backtracking"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Closer Look at Reward Decomposition for High-Level Robotic Explanations": {
    "filename": "A Closer Look at Reward Decomposition for High-Level Robotic Explanations.pdf",
    "analysis": {
      "benchmarks": [
        "Ravens benchmark",
        "Airsim Blocks environment"
      ],
      "models": [
        "explainable Q-Map learning framework",
        "X-QMap",
        "normal Q-learning"
      ]
    }
  },
  "Explicit Planning Helps Language Models in Logical Reasoning": {
    "filename": "Explicit Planning Helps Language Models in Logical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Entailment Bank",
        "QASC",
        "PrOntoQA",
        "MNLI"
      ],
      "models": [
        "LEAP",
        "T5",
        "GPT-3",
        "GPT-3.5",
        "DeBERTa",
        "RuleTaker",
        "Neural Unification",
        "Selection-Inference",
        "Chain-of-Thought"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models": {
    "filename": "Measuring and Improving Chain-of-Thought Reasoning in Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "CURE",
        "Sherlock",
        "VCR"
      ],
      "models": [
        "BLIP-2",
        "CoTBLIP",
        "OFA-Large",
        "OFA-Huge",
        "BLIP-2-OPT",
        "BLIP-2-T5",
        "InstructBLIP-T5",
        "LLaVA",
        "miniGPT-4",
        "Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Survey of Natural Language Processing for Education Taxonomy Systematic Review and Future Trends": {
    "filename": "Survey of Natural Language Processing for Education Taxonomy Systematic Review and Future Trends.pdf",
    "analysis": {
      "benchmarks": [
        "TQA",
        "AI2D",
        "DVQA",
        "VLQA",
        "SCIENCE QA",
        "TheoremQA",
        "MedQA",
        "MedMCQA",
        "Dolphin-18K",
        "DRAW-1K",
        "Math23K",
        "MathQA",
        "ASDiv",
        "GSM8K",
        "IconQA",
        "TABMWP",
        "SciQ",
        "RACE",
        "FairytaleQA",
        "LearningQ",
        "KHANQ",
        "EduQG",
        "MCQL",
        "Televic",
        "CLC-FCE",
        "ASAP",
        "TOEFL 11",
        "ICLE",
        "HSK",
        "Lang-8",
        "CLANG-8",
        "CoNLL-2014",
        "BEA-2019",
        "SIGHAN",
        "CTC",
        "FCGEC",
        "FlaCGEC",
        "GECCC",
        "RULEC-GEC",
        "Falko-Merlin",
        "COWS-L2H",
        "UA-GEC",
        "RONACC",
        "Defects4J",
        "ManyBugs",
        "IntroClass",
        "QuixBugs",
        "Bugs2Fix",
        "CodeReview",
        "CodeReview-New"
      ],
      "models": [
        "Seq2Seq",
        "BERT",
        "GPT-3",
        "CodeBERT",
        "CuBERT",
        "GraphCodeBERT",
        "UniXcoder",
        "PLBART",
        "CodeT5",
        "CodePAD",
        "BART",
        "T5",
        "EBGEC",
        "SynGEC",
        "CSynGEC",
        "PIE",
        "EditNTS",
        "LaserTagger",
        "GECToR",
        "TemplateGEC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GRID A Platform for General Robot Intelligence Development": {
    "filename": "GRID A Platform for General Robot Intelligence Development.pdf",
    "analysis": {
      "benchmarks": [
        "AirGen simulator"
      ],
      "models": [
        "GRID",
        "GroundingDINO",
        "GroundedSAM",
        "MIDAS",
        "DPVO",
        "TAPIR",
        "Optical Expansion",
        "LLaVa",
        "GIT",
        "BLIP-2",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EMOTION Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning": {
    "filename": "EMOTION Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "EMOTION",
        "EMOTION++",
        "human oracle"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FanCric  Multi-Agentic Framework for Crafting Fantasy 11 Cricket Teams": {
    "filename": "FanCric  Multi-Agentic Framework for Crafting Fantasy 11 Cricket Teams.pdf",
    "analysis": {
      "benchmarks": [
        "Dream11"
      ],
      "models": [
        "FanCric",
        "Prompt Engineering approach",
        "Wisdom of Crowds"
      ]
    }
  },
  "LLMCad Fast and Scalable On-device Large Language Model Inference": {
    "filename": "LLMCad Fast and Scalable On-device Large Language Model Inference.pdf",
    "analysis": {
      "benchmarks": [
        "IWLST17-de-en",
        "SQuAD_v2",
        "CNN/Daily",
        "Wikitext",
        "WMT14-de-en",
        "Parrot",
        "WMT22-de-en",
        "WMT22-zh-en",
        "TruthfulQA"
      ],
      "models": [
        "LLMCad",
        "GPT2",
        "GPT2-Large",
        "T5-Small",
        "T5-Base",
        "T5-Large",
        "mT5-Small",
        "mT5-Base",
        "mT5-Large",
        "Bart",
        "Bart-Large",
        "Vicuna-7B",
        "Vicuna-13B",
        "LLaMa2-Chat-7B",
        "LLaMa2-Chat-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Elicitron An LLM Agent-Based Simulation Framework for Design Requirements Elicitation": {
    "filename": "Elicitron An LLM Agent-Based Simulation Framework for Design Requirements Elicitation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Elicitron",
        "GPT-4-Turbo",
        "text-embedding-ada-002"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MathCoder Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning": {
    "filename": "MathCoder Seamless Code Integration in LLMs for Enhanced Mathematical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "GSM8K",
        "SVAMP",
        "Mathematics",
        "SimulEq"
      ],
      "models": [
        "MathCoder",
        "MathCoder-Initial",
        "MathCoder-L",
        "MathCoder-CL",
        "Llama-2",
        "CodeLlama",
        "WizardMath",
        "Llama-1 RFT",
        "Galactica",
        "ChatGPT-3.5",
        "GPT-4",
        "GPT-4 Code Interpreter",
        "PaLM-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models in Mental Health Care a Scoping Review": {
    "filename": "Large Language Models in Mental Health Care a Scoping Review.pdf",
    "analysis": {
      "benchmarks": [
        "SMHD",
        "D4",
        "SAD",
        "C-SSRS",
        "DSM-5",
        "PsyQA",
        "Dreaddit"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "LLaMA",
        "LLaMA-2",
        "PaLM",
        "MentaLLaMA",
        "Mental-LLM",
        "ChatCounselor",
        "ExTES-LLaMA",
        "ChatGLM2-6B",
        "GLM-130B",
        "Alpaca",
        "Vicuna"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Explainable Decisions in Dynamic Digital Twins": {
    "filename": "Large Language Models for Explainable Decisions in Dynamic Digital Twins.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Large Language Models (LLMs)",
        "Retrieval-Augmented Generation (RAG)",
        "gpt-4-turbo-2024-04-09",
        "text-embedding-ada-002"
      ]
    }
  },
  "Can LLMs Capture Human Preferences": {
    "filename": "Can LLMs Capture Human Preferences.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "GPT-3.5-turbo",
        "chain-of-thought conjoint"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On Memorization of Large Language Models in Logical Reasoning": {
    "filename": "On Memorization of Large Language Models in Logical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Knights and Knaves (K&K) puzzles"
      ],
      "models": [
        "Llama3-8B",
        "GPT4o-mini",
        "Claude-3.5-sonnet",
        "Gemini-1.5-Flash-002",
        "Gemini-1.5-Pro-002",
        "Deepseek-Math-7b",
        "NuminaMath-7B-CoT",
        "Phi-3-mini",
        "Phi-3-medium",
        "Gemma-2-9b",
        "Llama-3-8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FinTruthQA A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure": {
    "filename": "FinTruthQA A Benchmark Dataset for Evaluating the Quality of Financial Information Disclosure.pdf",
    "analysis": {
      "benchmarks": [
        "FinTruthQA"
      ],
      "models": [
        "BERT",
        "FinBERT",
        "Mengzi-fin",
        "DKPLM",
        "SBERT-nli",
        "RoBERTa-extractive-qa",
        "BERT (Large)",
        "RoBERTa (Large)",
        "Logistic Regression",
        "Support Vector Machine",
        "K-nearest neighbor",
        "Random Forest",
        "GPT-4",
        "Llama-3.1",
        "Qwen2",
        "Mistral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Performance of ChatGPT on the test of understanding graphs in kinematics": {
    "filename": "Performance of ChatGPT on the test of understanding graphs in kinematics.pdf",
    "analysis": {
      "benchmarks": [
        "Test of Understanding Graphs in Kinematics (TUG-K)"
      ],
      "models": [
        "ChatGPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Instant Soup Cheap Pruning Ensembles in A Single Pass Can Draw Lottery Tickets from Large Models": {
    "filename": "Instant Soup Cheap Pruning Ensembles in A Single Pass Can Draw Lottery Tickets from Large Models.pdf",
    "analysis": {
      "benchmarks": [
        "CIFAR-10",
        "MNIST",
        "SVHN",
        "Cars",
        "GTSRB",
        "CIFAR-100",
        "MNLI",
        "QNLI",
        "QQP",
        "SST",
        "STS-B",
        "WNLI",
        "MPRC",
        "RTS",
        "SST-2",
        "CoLA"
      ],
      "models": [
        "CLIP (ViT-B32)",
        "BERT",
        "Instant Soup Pruning (ISP)",
        "Iterative Magnitude Pruning (IMP)",
        "Lottery Ticket Hypothesis (LTH)",
        "EarlyBird",
        "SNIP",
        "GraSP",
        "Progressive Pruning",
        "One-shot Magnitude Pruning",
        "Lottery Pools"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Emergence of Hidden Capabilities Exploring Learning Dynamics in Concept Space": {
    "filename": "Emergence of Hidden Capabilities Exploring Learning Dynamics in Concept Space.pdf",
    "analysis": {
      "benchmarks": [
        "CelebA"
      ],
      "models": [
        "text-to-image diffusion models",
        "variational diffusion model",
        "U-Net",
        "Classifier Free Guidance (CFG)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "R-CoT Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models": {
    "filename": "R-CoT Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models.pdf",
    "analysis": {
      "benchmarks": [
        "MathVista",
        "GeoQA"
      ],
      "models": [
        "R-CoT-8B",
        "GPT-4o",
        "LLaVA",
        "Qwen",
        "InternVL",
        "Mini-Monkey",
        "GeoChain",
        "Reverse A&Q",
        "R-CoT-Qwen-7B",
        "R-CoT-LLaVA-7B",
        "R-CoT-Mini-Monkey-2B",
        "R-CoT-InternLM-XC2-7B",
        "R-CoT-InternVL-2.0-8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LiveIdeaBench Evaluating LLMs Scientific Creativity and Idea Generation with Minimal Context": {
    "filename": "LiveIdeaBench Evaluating LLMs Scientific Creativity and Idea Generation with Minimal Context.pdf",
    "analysis": {
      "benchmarks": [
        "LiveIdeaBench"
      ],
      "models": [
        "QwQ-32B-preview",
        "o1-preview",
        "gpt-4o-2024-11-20",
        "o1-mini",
        "gpt-4o-mini",
        "claude-3.5-sonnet",
        "claude-3.5-haiku",
        "gemini-pro-1.5",
        "gemini-2.0-flash-exp",
        "mistral-large-2411",
        "deepseek-chat",
        "Llama variants",
        "Qwen models",
        "nova-pro-v1",
        "step-2-16k",
        "grok-2-1212"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GraphLLM Boosting Graph Reasoning Ability of Large Language Model": {
    "filename": "GraphLLM Boosting Graph Reasoning Ability of Large Language Model.pdf",
    "analysis": {
      "benchmarks": [
        "Substructure Counting",
        "Maximum Triplet Sum",
        "Shortest Path",
        "Bipartite Graph Matching"
      ],
      "models": [
        "GraphLLM",
        "LLaMA2-7B",
        "LLaMA2-13B",
        "OPT-2.7B",
        "LoRA",
        "Prefix Tuning",
        "Zero-shot",
        "Few-shot",
        "Few-shot CoT",
        "LoRA(attn)",
        "LoRA(attn+ffn)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Sketching for Large Language Models": {
    "filename": "Prompt Sketching for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Date Understanding",
        "Information Essentiality",
        "AQuA",
        "StrategyQA",
        "Multistep Arithmetic",
        "GSM8K",
        "Tracking Shuffled Objects",
        "Matrix Shapes"
      ],
      "models": [
        "text-davinci-003",
        "Llama-2 Chat 13B",
        "text-curie-001",
        "Answer-Only",
        "Chain-Of-Thought",
        "Prompt Sketching",
        "ARGMAX",
        "BEAM",
        "BEAM VAR",
        "VAR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "WebCanvas Benchmarking Web Agents in Online Environments": {
    "filename": "WebCanvas Benchmarking Web Agents in Online Environments.pdf",
    "analysis": {
      "benchmarks": [
        "Mind2Web-Live",
        "Mind2Web"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Claude-3-Opus",
        "Gemini-Pro",
        "DeepSeek-V2",
        "Mixtral-8x22B",
        "MindAct",
        "GPT-4-turbo",
        "Qwen1.5-110B-Chat",
        "Qwen2-72B-Instruct",
        "Claude-3-Sonnet",
        "Qwen1.5-72B-Chat",
        "Claude-3-Haiku",
        "Mistral-7B-Instruct-v0.3",
        "Qwen1.5-7B-Chat",
        "Qwen1.5-14B-Chat",
        "GPT-4V"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tailored-LLaMA Optimizing Few-Shot Learning in Pruned LLaMA Models with Task-Specific Prompts": {
    "filename": "Tailored-LLaMA Optimizing Few-Shot Learning in Pruned LLaMA Models with Task-Specific Prompts.pdf",
    "analysis": {
      "benchmarks": [
        "BoolQ",
        "PIQA",
        "HellaSwag",
        "WinoGrande",
        "ARC-easy",
        "ARC-challenge",
        "OpenbookQA",
        "WikiText2",
        "PTB"
      ],
      "models": [
        "Tailored-LLaMA",
        "LLaMA-7B",
        "Wanda",
        "FLAP",
        "LLM-Pruner",
        "Shortened LLaMA",
        "LoRAPrune"
      ]
    }
  },
  "Large Language Models Are Zero-Shot Time Series Forecasters": {
    "filename": "Large Language Models Are Zero-Shot Time Series Forecasters.pdf",
    "analysis": {
      "benchmarks": [
        "Darts",
        "Monash",
        "Informer",
        "AirPassengers",
        "GasRateCO2",
        "MonthlyMilk"
      ],
      "models": [
        "GPT-3",
        "LLaMA-2",
        "GPT-4",
        "ARIMA",
        "TCN",
        "N-HiTS",
        "N-BEATS",
        "SM-GP",
        "DeepAR",
        "WaveNet",
        "Transformer",
        "Autoformer",
        "FEDformer",
        "PromptCast",
        "LLMTIME"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The BrowserGym Ecosystem for Web Agent Research": {
    "filename": "The BrowserGym Ecosystem for Web Agent Research.pdf",
    "analysis": {
      "benchmarks": [
        "MiniWoB",
        "MiniWoB++",
        "WebArena",
        "VisualWebArena",
        "WorkArena L1",
        "WorkArena L2",
        "WorkArena L3",
        "WebLINX",
        "AssistantBench"
      ],
      "models": [
        "Claude-3.5-Sonnet",
        "GPT-4o",
        "GPT-4o Mini",
        "Llama-3.1 70B",
        "Llama-3.1 405B",
        "o1 Mini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Machine Psychology": {
    "filename": "Machine Psychology.pdf",
    "analysis": {
      "benchmarks": [
        "BIG-bench",
        "Abstraction and Reasoning Challenge",
        "MATH Dataset"
      ],
      "models": [
        "GPT-3",
        "ChatGPT",
        "Claude 3",
        "Gemini 1.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CodeTransOcean A Comprehensive Multilingual Benchmark for Code Translation": {
    "filename": "CodeTransOcean A Comprehensive Multilingual Benchmark for Code Translation.pdf",
    "analysis": {
      "benchmarks": [
        "MultilingualTrans",
        "NicheTrans",
        "LLMTrans",
        "DLTrans"
      ],
      "models": [
        "CodeT5+",
        "ChatGPT",
        "AutoTransExecuter"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PathLDM Text conditioned Latent Diffusion Model for Histopathology": {
    "filename": "PathLDM Text conditioned Latent Diffusion Model for Histopathology.pdf",
    "analysis": {
      "benchmarks": [
        "TCGA-BRCA",
        "NCT-CRC-HE",
        "PCam",
        "CRCDX",
        "Deepglobe"
      ],
      "models": [
        "PathLDM",
        "Stable Diffusion",
        "Medfusion",
        "Moghadam et al.",
        "VAE VQ-f4",
        "VAE VQ-f8",
        "PLIP",
        "OpenAI CLIP"
      ]
    }
  },
  "Federated Learning in Practice Reflections and Projections": {
    "filename": "Federated Learning in Practice Reflections and Projections.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "FedAvg",
        "DP-FTRL",
        "DP-SGD",
        "LoRA",
        "Gboard language models",
        "smart selection models",
        "keyword spotting model",
        "smart text selection",
        "smart reply",
        "emoji prediction"
      ]
    }
  },
  "Automated Text Scoring in the Age of Generative AI for the GPU-poor": {
    "filename": "Automated Text Scoring in the Age of Generative AI for the GPU-poor.pdf",
    "analysis": {
      "benchmarks": [
        "ASAP AES",
        "ASAP SAS",
        "EASE",
        "LSTM+CNN+Att",
        "BERT (base)",
        "NPCR",
        "AutoSAS",
        "Ensemble LLM"
      ],
      "models": [
        "Mistral-7B-Instruct-v0.2",
        "Gemma-1.1-7b-it",
        "Meta-Llama-3-8B-Instruct",
        "Phi-3-mini-4k-instruct",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Agent-FLAN Designing Data and Methods of Effective Agent Tuning for Large Language Models": {
    "filename": "Agent-FLAN Designing Data and Methods of Effective Agent Tuning for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "SciWorld",
        "WebArena",
        "T-Eval",
        "Agent-H"
      ],
      "models": [
        "Llama2-7B",
        "AgentLM-7B",
        "AgentTuning",
        "Agent-FLAN"
      ]
    }
  },
  "DeCoRe Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations": {
    "filename": "DeCoRe Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations.pdf",
    "analysis": {
      "benchmarks": [
        "XSum",
        "MemoTrap",
        "NQ-Open",
        "NQ-Swap",
        "TriviaQA",
        "PopQA",
        "TruthfulQA",
        "MuSiQue",
        "Needle-in-a-Haystack (NitH)"
      ],
      "models": [
        "DeCoRe",
        "Llama3-8b-Instruct",
        "Llama3-70b-Instruct",
        "Greedy decoding",
        "Contrastive Decoding (CD)",
        "Context-Aware Decoding (CAD)",
        "Decoding by Contrasting Layers (DoLa)",
        "Activation Decoding (AD)",
        "ITI"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "In-Context Learning and Fine-Tuning GPT for Argument Mining": {
    "filename": "In-Context Learning and Fine-Tuning GPT for Argument Mining.pdf",
    "analysis": {
      "benchmarks": [
        "Persuasive Essays (PE)"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "GPT-3.5-turbo",
        "GPT-3.5-FeaTxt",
        "BERT",
        "BERT-FeaTxt",
        "BERT-MINUS-FeaTxt"
      ]
    }
  },
  "Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs": {
    "filename": "Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "FMereani XSS dataset",
        "SOFIA SQLi dataset"
      ],
      "models": [
        "GPT-3.5 Turbo",
        "GPT-4",
        "GPT-4 Turbo",
        "Claude 3 Haiku",
        "Claude 3 Sonnet",
        "Claude 3 Opus",
        "Llama3",
        "Mixtral 8x7b",
        "PaLM 2 Chat Bison",
        "CNN (Chen et al.)",
        "MLP (Chen et al.)",
        "SOFIA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NegativePrompt Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli": {
    "filename": "NegativePrompt Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli.pdf",
    "analysis": {
      "benchmarks": [
        "Instruction Induction",
        "BIG-Bench",
        "TruthfulQA"
      ],
      "models": [
        "Flan-T5-Large",
        "Vicuna",
        "Llama 2",
        "ChatGPT",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Refining the Responses of LLMs by Themselves": {
    "filename": "Refining the Responses of LLMs by Themselves.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "GPT-3.5-Turbo",
        "re\ufb01ned GPT-3.5",
        "blind re\ufb01nement version",
        "reckless re\ufb01nement version"
      ]
    }
  },
  "Causal Reasoning and Large Language Models Opening a New Frontier for Causality": {
    "filename": "Causal Reasoning and Large Language Models Opening a New Frontier for Causality.pdf",
    "analysis": {
      "benchmarks": [
        "T\u00fcbingen benchmark",
        "Neuropathic pain diagnosis benchmark",
        "novel Tubingen dataset"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "text-davinci-002",
        "text-davinci-003",
        "gpt-3.5-turbo",
        "gpt-4 (single prompt)",
        "gpt-3.5-turbo (causal agent)",
        "gpt-3.5-turbo (single prompt)",
        "gpt-4 (neuropathic pain expert)",
        "text-davinci-003 (single prompt)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving": {
    "filename": "Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving.pdf",
    "analysis": {
      "benchmarks": [
        "nuScenes",
        "OpenLane-V2"
      ],
      "models": [
        "Atlas",
        "ViT-CLIP",
        "StreamPETR",
        "TopoMLP",
        "LLaMA",
        "LLaVA",
        "Vicuna",
        "Merlin",
        "PETR",
        "BEV-Planner",
        "UniAD",
        "VAD-Base",
        "Ego-MLP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval": {
    "filename": "Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval"
      ],
      "models": [
        "StarCoderBase-1B",
        "StarCoderBase-7B",
        "StarCoderBase-15.5B",
        "StarCoder2-7B",
        "Mistral-7B-v0.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Large to Tiny Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision": {
    "filename": "From Large to Tiny Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision.pdf",
    "analysis": {
      "benchmarks": [
        "Math23K",
        "Weak12K"
      ],
      "models": [
        "FLTT-roformer",
        "FLTT-T5",
        "GTS",
        "roformer+unilm",
        "LBF",
        "ComSearch",
        "WDA",
        "ChatGPT",
        "UniLM",
        "T5",
        "RoFormer-Small",
        "T5-small",
        "T5-Base"
      ]
    }
  },
  "Cohesive Conversations Enhancing Authenticity in Multi-Agent Simulated Dialogues": {
    "filename": "Cohesive Conversations Enhancing Authenticity in Multi-Agent Simulated Dialogues.pdf",
    "analysis": {
      "benchmarks": [
        "ONEDAYLIFE"
      ],
      "models": [
        "SDR framework",
        "Generative Agents",
        "Baseline",
        "GPT-3.5-turbo",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HEIE MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator": {
    "filename": "HEIE MLLM-Based Hierarchical Explainable AIGC Image Implausibility Evaluator.pdf",
    "analysis": {
      "benchmarks": [
        "RichHF-18K",
        "AbHuman",
        "Expl-AIGI-Eval"
      ],
      "models": [
        "HEIE",
        "RAHF",
        "InternViT",
        "CLIP",
        "EVA-CLIP",
        "Qwen2-VL-7B-Instruct",
        "DeepSeek-VL-7B-chat",
        "InternVL2-8B",
        "GLM-4V-9B",
        "GPT-4o",
        "Claude-3.5-Sonnet"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models for Human-like Autonomous Driving A Survey": {
    "filename": "Large Language Models for Human-like Autonomous Driving A Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "GPT-2",
        "gpt-3.5-turbo",
        "GPT-3.5",
        "LLaMA-2",
        "BLIP-2",
        "LLaVA",
        "Flamingo",
        "MTD-GPT",
        "LanguageMPC",
        "TrafficGPT",
        "DriveLLM",
        "Agent-Driver",
        "GPT-Driver",
        "DriveMLM",
        "DiLu",
        "SurrealDriver",
        "VistaGPT",
        "DriveVLM",
        "DME-Driver",
        "ADAPT",
        "DriveGPT4",
        "LLM-driver",
        "Graph VQA",
        "LMDrive"
      ]
    }
  },
  "Language Modeling Is Compression": {
    "filename": "Language Modeling Is Compression.pdf",
    "analysis": {
      "benchmarks": [
        "enwik8",
        "enwik9",
        "ImageNet",
        "LibriSpeech"
      ],
      "models": [
        "Chinchilla 70B",
        "Llama 2",
        "Transformer 200K",
        "Transformer 800K",
        "Transformer 3.2M",
        "Chinchilla 1B",
        "Chinchilla 7B",
        "Chinchilla 70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PRefLexOR Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking": {
    "filename": "PRefLexOR Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "PRefLexOR",
        "Quiet-STaR",
        "X-LoRA",
        "meta-llama/Llama-3.2-3B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChemAlgebra Algebraic Reasoning on Chemical Reactions": {
    "filename": "ChemAlgebra Algebraic Reasoning on Chemical Reactions.pdf",
    "analysis": {
      "benchmarks": [
        "CHEM ALGEBRA",
        "USPTO",
        "USPTO-MIT",
        "USPTO-BAL",
        "USPTO-T1",
        "USPTO-T2"
      ],
      "models": [
        "Molecular Transformer",
        "Augmented Transformer",
        "Chemformer",
        "Graph2SMILES (G2S)",
        "G2S (DGCN)",
        "G2S (DGAT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multi-Level Explanations for Generative Language Models": {
    "filename": "Multi-Level Explanations for Generative Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "XSUM",
        "CNN/Daily Mail",
        "SQuAD"
      ],
      "models": [
        "MExGen",
        "DistilBart",
        "Flan-UL2",
        "Flan-T5-Large",
        "PartitionSHAP",
        "CaptumLIME",
        "MExGen C-LIME",
        "MExGen L-SHAP",
        "MExGen LOO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NaturalProver Grounded Mathematical Proof Generation with Language Models": {
    "filename": "NaturalProver Grounded Mathematical Proof Generation with Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "NATURAL PROOFS",
        "NATURAL PROOFS-GEN"
      ],
      "models": [
        "NATURAL PROVER",
        "GPT-3",
        "NATURAL PROVER RETRIEVE",
        "NATURAL PROVER ++"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting": {
    "filename": "Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "HEADQA",
        "MedMCQA",
        "MMLU-professional medicine",
        "CommonsenseQA",
        "OpenbookQA"
      ],
      "models": [
        "BioLinkBert-Base",
        "BioLinkBert-Large",
        "BioMedLM",
        "QA-GNN",
        "GreaseLM",
        "DRAGON",
        "MurKe",
        "MOEBQA",
        "HDRN",
        "VOD",
        "T5-base",
        "Fusion-in-Decoder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Grounding and Evaluation for Large Language Models Practical Challenges and Lessons Learned Survey": {
    "filename": "Grounding and Evaluation for Large Language Models Practical Challenges and Lessons Learned Survey.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LLMs",
        "RAG",
        "Self-RAG",
        "T5-family",
        "FUDGE",
        "phi-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Code Review Automation Strengths and Weaknesses of the State of the Art": {
    "filename": "Code Review Automation Strengths and Weaknesses of the State of the Art.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "T5CR",
        "COMMENT FINDER",
        "CODEREVIEWER",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoRD An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models": {
    "filename": "AutoRD An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "RareDis2023"
      ],
      "models": [
        "AutoRD",
        "BioClinicalBERT",
        "Base GPT-4",
        "Camel-Platypus2-70B"
      ]
    }
  },
  "Apple Intelligence Foundation Language Models": {
    "filename": "Apple Intelligence Foundation Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HELM MMLU v1.5.0",
        "HuggingFace OpenLLM leaderboard V1",
        "HELM-Lite v1.5.0",
        "GSM8K",
        "ARC-c",
        "HellaSwag",
        "Winogrande",
        "Narrative QA",
        "Natural Questions (open)",
        "Natural Questions (closed)",
        "Openbook QA",
        "MMLU",
        "MATH-CoT",
        "LegalBench",
        "MedQA",
        "WMT 2014",
        "IFEval",
        "AlpacaEval 2.0 LC",
        "Berkeley Function Calling Leaderboard",
        "Gorilla leaderboard",
        "Arena HardInstruction Following Benchmark",
        "GSM8K (8-shot)",
        "MATH (4-shot)"
      ],
      "models": [
        "AFM-on-device",
        "AFM-server",
        "Phi-3-mini",
        "Gemma-7B",
        "Mistral-7B",
        "Llama-3-8B",
        "Llama-3-70B",
        "Mixtral-8x22B",
        "DBRX-Instruct",
        "GPT-3.5",
        "GPT-4",
        "Gemma-2B",
        "Gemma-1.1-2B",
        "Gemma-1.1-7B",
        "Gemini-1.5-Pro-0514",
        "Gemini-1.5-Pro-Preview-0514"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Phenomenal Yet Puzzling Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement": {
    "filename": "Phenomenal Yet Puzzling Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement.pdf",
    "analysis": {
      "benchmarks": [
        "ACRE",
        "MiniSCAN",
        "List Functions",
        "MiniARC"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Claude-2",
        "LLaMA2-70B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DiaSynth Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications": {
    "filename": "DiaSynth Synthetic Dialogue Generation Framework for Low Resource Dialogue Applications.pdf",
    "analysis": {
      "benchmarks": [
        "DialogSum",
        "SAMSum"
      ],
      "models": [
        "DiaSynth",
        "Phi-3",
        "InternLM-2.5",
        "LLaMA-3",
        "GPT-4o",
        "DistilBART",
        "BART",
        "T5",
        "LED"
      ]
    }
  },
  "LLM in the Shell Generative Honeypots": {
    "filename": "LLM in the Shell Generative Honeypots.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "shelLM",
        "GPT-3.5-turbo-16k"
      ]
    }
  },
  "Prompt Engineering Through the Lens of Optimal Control": {
    "filename": "Prompt Engineering Through the Lens of Optimal Control.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "Claude",
        "Progressive-Hint Prompting (PHP)",
        "Least-to-Most (LtM)",
        "Automatic Prompt Engineering (APE)",
        "Tree of Thought (ToT)",
        "RLPrompt",
        "PromptPG",
        "Self-Consistency CoT",
        "Mutual Information",
        "MathPrompter",
        "Step-Aware Verifier"
      ]
    }
  },
  "xFinder Robust and Pinpoint Answer Extraction for Large Language Models": {
    "filename": "xFinder Robust and Pinpoint Answer Extraction for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "KeyAnswer Finder (KAF) dataset",
        "CommonsenseQA",
        "ARC-challenge",
        "ARC-easy",
        "BoolQ",
        "hellaswag",
        "MATH",
        "MetaMathQA",
        "MultiArith",
        "OpenbookQA",
        "QNLI",
        "SIQA",
        "Subj",
        "TREC",
        "WiC",
        "AgNews",
        "Amazon",
        "DBPedia",
        "GSM8K",
        "MMLU"
      ],
      "models": [
        "xFinder",
        "xFinder-qwen1505",
        "xFinder-llama38it",
        "xFinder-qwen1518",
        "xFinder-gemma7",
        "xFinder-chatglm36base",
        "xFinder-llama38",
        "RegEx",
        "GPT-4",
        "LM Eval Harness",
        "OpenCompass",
        "UltraEval"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "E-ICL Enhancing Fine-Grained Emotion Recognition through the Lens of Prototype Theory": {
    "filename": "E-ICL Enhancing Fine-Grained Emotion Recognition through the Lens of Prototype Theory.pdf",
    "analysis": {
      "benchmarks": [
        "EDOS",
        "Empathetic-Dialogues",
        "EmpatheticIntent",
        "GoEmotions"
      ],
      "models": [
        "E-ICL",
        "ICL",
        "ChatGPT-turbo",
        "Claude-haiku",
        "RoBERTaEI_large",
        "RoBERTaGE_large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AtomR Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning": {
    "filename": "AtomR Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "BlendQA",
        "WikiMultihop"
      ],
      "models": [
        "AtomR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CATfOOD Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration": {
    "filename": "CATfOOD Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD",
        "SQuAD-Adversarial",
        "TriviaQA",
        "HotpotQA",
        "Natural Questions",
        "NewsQA",
        "BioASQ"
      ],
      "models": [
        "RoBERTa-base",
        "RGF",
        "GPT-JT",
        "LLaMA",
        "Alpaca",
        "GPT-NeoxT",
        "Flan-T5-xxl",
        "Flan-UL2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Insert-expansions for Tool-enabled Conversational Agents": {
    "filename": "Insert-expansions for Tool-enabled Conversational Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "vanilla bot",
        "enabled bot",
        "OpenAI model gpt-3.5-turbo-0301",
        "distilbert model",
        "Large Language Model gpt-3.5-turbo-0613"
      ]
    }
  },
  "Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models": {
    "filename": "Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.0",
        "GPT-3.5",
        "Curie",
        "Codex-cushman",
        "Davinci",
        "Code-davinci-002",
        "RoBERTa",
        "CodeBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models are Edge-Case Fuzzers Testing Deep Learning Libraries via FuzzGPT": {
    "filename": "Large Language Models are Edge-Case Fuzzers Testing Deep Learning Libraries via FuzzGPT.pdf",
    "analysis": {
      "benchmarks": [
        "PyTorch",
        "TensorFlow"
      ],
      "models": [
        "FuzzGPT",
        "TitanFuzz",
        "Codex",
        "CodeGen",
        "ChatGPT",
        "FreeFuzz",
        "DeepREL",
        "\u2207Fuzz",
        "Muffin"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Counterfactual Causal Inference in Natural Language with Large Language Models": {
    "filename": "Counterfactual Causal Inference in Natural Language with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Cladder",
        "EventRegistry"
      ],
      "models": [
        "LLaMA-3.1",
        "GPT-3.5",
        "GPT-4",
        "GPT-4o",
        "GPT-4o-mini",
        "Counterfactual-CI",
        "Counterfactual-CI-GPT-4o",
        "Counterfactual-CI-GPT-4o-mini",
        "Counterfactual-CI-GPT-3.5",
        "Counterfactual-CI-LLaMA-3.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Valuation Based on Shapley Values": {
    "filename": "Prompt Valuation Based on Shapley Values.pdf",
    "analysis": {
      "benchmarks": [
        "Stanford Sentiment Treebank (SST2)",
        "AQuA",
        "Bigbench Date"
      ],
      "models": [
        "BERT-base",
        "GPT-3.5-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ImProver Agent-Based Automated Proof Optimization": {
    "filename": "ImProver Agent-Based Automated Proof Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "Mathematics in Lean (MIL)",
        "Compfiles",
        "Mathlib"
      ],
      "models": [
        "ImProver",
        "GPT-4o",
        "GPT-4o-mini"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MOSAIC A Modular System for Assistive and Interactive Cooking": {
    "filename": "MOSAIC A Modular System for Assistive and Interactive Cooking.pdf",
    "analysis": {
      "benchmarks": [
        "AMASS",
        "Collaborative Manipulation Dataset (CoMaD)"
      ],
      "models": [
        "MOSAIC",
        "Interactive Task Planner",
        "Human Motion Forecasting",
        "Visuomotor Skill",
        "OwlViT",
        "CLIP",
        "FastSAM",
        "MediaPipe",
        "Forecast (Base)",
        "Forecast (Ours)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "S-Agents Self-organizing Agents in Open-ended Environments": {
    "filename": "S-Agents Self-organizing Agents in Open-ended Environments.pdf",
    "analysis": {
      "benchmarks": [
        "Minecraft"
      ],
      "models": [
        "S-Agents",
        "Voyager",
        "Chain of agents (CoA)",
        "Graph of agents (GoA)",
        "Tree of agents (ToA)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Contribution of Knowledge in Visiolinguistic Learning A Survey on Tasks and Challenges": {
    "filename": "The Contribution of Knowledge in Visiolinguistic Learning A Survey on Tasks and Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "OK-VQA",
        "K-VQA",
        "FVQA",
        "KB-VQA",
        "VCR",
        "COCO",
        "Flickr",
        "Visual Genome",
        "Conceptual Captions",
        "SBU"
      ],
      "models": [
        "ConceptBERT",
        "T5",
        "GPT-3",
        "KRISP",
        "REVIVE",
        "KAT",
        "VL-BERT",
        "BART",
        "XGPT",
        "ClipCap",
        "VC-GPT",
        "Story-DALL-E",
        "KB-VLP",
        "PromptCap",
        "Socratic model framework"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AGIEval A Human-Centric Benchmark for Evaluating Foundation Models": {
    "filename": "AGIEval A Human-Centric Benchmark for Evaluating Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "AGIEval",
        "SAT",
        "LSAT",
        "China College Entrance Exam (Gaokao)",
        "Lawyer Qualification Test",
        "Civil Service Exam",
        "Math Competition",
        "GMAT",
        "GRE",
        "MMLU",
        "LogiQA",
        "JEC-QA",
        "AQuA-RAT",
        "MATH"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "Text-Davinci-003",
        "Vicuna-13B",
        "GLM-130B",
        "LLaMa-65B",
        "InternLM-104B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Hyperion Unveiling DApp Inconsistencies using LLM and Dataflow-Guided Symbolic Execution": {
    "filename": "Hyperion Unveiling DApp Inconsistencies using LLM and Dataflow-Guided Symbolic Execution.pdf",
    "analysis": {
      "benchmarks": [
        "ground truth dataset",
        "DappBay",
        "DappRadar"
      ],
      "models": [
        "HYPERION",
        "HYPER TEXT",
        "HYPER CODE",
        "LLaMA2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Measuring Representational Similarity of Large Language Models": {
    "filename": "Towards Measuring Representational Similarity of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Winogrande",
        "HumanEval"
      ],
      "models": [
        "RedPajama",
        "Bloom",
        "Falcon",
        "Galactica",
        "GPT-J",
        "Llama",
        "MPT",
        "OpenLlama",
        "OPT",
        "Pythia",
        "StableLM Alpha",
        "CodeLlama",
        "CodeLlama-Python"
      ]
    }
  },
  "Task Oriented In-Domain Data Augmentation": {
    "filename": "Task Oriented In-Domain Data Augmentation.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "SAT",
        "MATH",
        "SVAMP",
        "ASDiv",
        "MAWPS",
        "TabMWP",
        "MathQA",
        "MMLU-STEM"
      ],
      "models": [
        "TRAIT",
        "Mistral-7B",
        "Random sampling",
        "DSIR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Merlin Empowering Multimodal LLMs with Foresight Minds": {
    "filename": "Merlin Empowering Multimodal LLMs with Foresight Minds.pdf",
    "analysis": {
      "benchmarks": [
        "LaSOT",
        "GOT10K",
        "MOT17",
        "DanceTrack",
        "SOMPT22",
        "RefCOCO",
        "VCR",
        "MMBench",
        "GQA",
        "VisWiz",
        "MM-Vet",
        "COCO"
      ],
      "models": [
        "Merlin",
        "GPT-4V",
        "Bard",
        "InstructBLIP",
        "MiniGPT-4",
        "OpenFlamingo",
        "MMGPT",
        "LLaVA",
        "mPLUG-Owl",
        "Shikra",
        "Kosmos-2",
        "LLaVA-1.5",
        "SiamFC",
        "ATOM",
        "SiamRPN++",
        "SiamFC++",
        "BLIP-2",
        "IDEFICS-9B",
        "IDEFICS-80B",
        "Qwen-VL",
        "Qwen-VL-Chat",
        "MultiModal-GPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FLASK Fine-grained Language Model Evaluation based on Alignment Skill Sets": {
    "filename": "FLASK Fine-grained Language Model Evaluation based on Alignment Skill Sets.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "TruthfulQA",
        "MMLU",
        "FLASK",
        "FLASK-HARD"
      ],
      "models": [
        "FLASK",
        "GPT-3.5",
        "BARD",
        "VICUNA-13B",
        "ALPACA-13B",
        "EVAL LM",
        "CLAUDE",
        "INSTRUCT GPT",
        "GPT-4",
        "TULU-7B",
        "TULU-13B",
        "TULU-30B",
        "TULU-65B",
        "WIZARDLM-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense": {
    "filename": "Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-1",
        "GPT-2",
        "GPT-3",
        "GPT-3.5",
        "ChatGPT",
        "Bing Chat/GPT4",
        "InstructGPT",
        "CODEX",
        "EleutherAI's GPT-neo",
        "GPT-J",
        "GPT-neoX",
        "HyperCLOVA",
        "Meta's OPT family",
        "BLOOM",
        "Chinchilla",
        "LLaMA",
        "Claude",
        "RoBERTa",
        "T5",
        "BERT",
        "DistilBERT",
        "BART",
        "PaLM",
        "Galactica"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatPCG Large Language Model-Driven Reward Design for Procedural Content Generation": {
    "filename": "ChatPCG Large Language Model-Driven Reward Design for Procedural Content Generation.pdf",
    "analysis": {
      "benchmarks": [
        "RaidEnv II"
      ],
      "models": [
        "ChatPCG",
        "Winrate Reward (RWR)",
        "LLM Reward (RLLM)",
        "Hybrid Reward (RHYB)",
        "Random (RD) agent",
        "Heuristic (HR) agent",
        "DRL model"
      ]
    }
  },
  "Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic": {
    "filename": "Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic.pdf",
    "analysis": {
      "benchmarks": [
        "FLD",
        "RuleTaker",
        "AACorpus",
        "EntailmentBank"
      ],
      "models": [
        "GPT-4",
        "T5",
        "LongAlpaca-13B",
        "GPT-3.5-Turbo",
        "stepwise prover model",
        "RoBERTa"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Environment Interaction for Automated PDDL Generation and Planning with Large Language Models": {
    "filename": "Leveraging Environment Interaction for Automated PDDL Generation and Planning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Grippers",
        "Grippers-ood",
        "Hiking",
        "Miconic",
        "Movie",
        "Termes",
        "Barman",
        "Childsnack",
        "Driverlog",
        "Floortile"
      ],
      "models": [
        "Intrinsic Planning (CoT)",
        "P&D Chain",
        "P&D Tree",
        "P&D Tree + DomProp"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Generations of Knowledge Graphs The Crazy Ideas and the Business Impact": {
    "filename": "Generations of Knowledge Graphs The Crazy Ideas and the Business Impact.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "random forest",
        "ClosedIE",
        "OpenIE",
        "GNN-based extraction",
        "ZeroshotCeres",
        "OpenCeres",
        "PRA (Path ranking algorithm)",
        "TXtract",
        "AdaTag",
        "PAM multi-modal extractor",
        "AutoKnow",
        "ChatGPT",
        "GPT-4"
      ]
    }
  },
  "HLM-Cite Hybrid Language Model Workflow for Text-based Scientific Citation Prediction": {
    "filename": "HLM-Cite Hybrid Language Model Workflow for Text-based Scientific Citation Prediction.pdf",
    "analysis": {
      "benchmarks": [
        "Microsoft Academic Graph (MAG)"
      ],
      "models": [
        "HLM-Cite",
        "SciBERT",
        "METAG",
        "PATTON",
        "SciPATTON",
        "SPECTER",
        "SciNCL",
        "SciMult-vanilla",
        "SciMult-MoE",
        "SPECTER-2.0",
        "BERT-base",
        "BERT-large",
        "OpenAI-ada-002",
        "OpenAI-3",
        "GTE-base",
        "GTE-base-v1.5",
        "GTE-large",
        "GTE-large-v1.5",
        "H-LM (GPT3.5)",
        "H-LM (GPT4o)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DSPy Assertions Computational Constraints for Self-Refining Language Model Pipelines": {
    "filename": "DSPy Assertions Computational Constraints for Self-Refining Language Model Pipelines.pdf",
    "analysis": {
      "benchmarks": [
        "HotPotQA"
      ],
      "models": [
        "MultiHopQAWithAssertions",
        "LongFormQAWithAssertions",
        "QuizChoiceGenerationWithAssertions",
        "TweetGenerationWithAssertions"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ToolLLM Facilitating Large Language Models to Master 16000 Real-world APIs": {
    "filename": "ToolLLM Facilitating Large Language Models to Master 16000 Real-world APIs.pdf",
    "analysis": {
      "benchmarks": [
        "ToolBench",
        "APIBench"
      ],
      "models": [
        "ToolLLaMA",
        "ChatGPT",
        "GPT-4",
        "Claude-2",
        "Text-Davinci-003",
        "Vicuna",
        "Alpaca",
        "Gorilla"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RAPGen An Approach for Fixing Code Inefficiencies in Zero-Shot": {
    "filename": "RAPGen An Approach for Fixing Code Inefficiencies in Zero-Shot.pdf",
    "analysis": {
      "benchmarks": [
        "DeepDev-PERF dataset"
      ],
      "models": [
        "RAPGen",
        "DeepDev-PERF",
        "Static Prompt",
        "Retrieval-based One-shot Prompt",
        "Reasoning-based Prompt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GraphWiz An Instruction-Following Language Model for Graph Problems": {
    "filename": "GraphWiz An Instruction-Following Language Model for Graph Problems.pdf",
    "analysis": {
      "benchmarks": [
        "GraphQA",
        "NLGraph",
        "NLGraph test set"
      ],
      "models": [
        "GraphWiz",
        "GraphWiz-DPO",
        "GPT-4",
        "GPT-3.5",
        "LLaMA 2-7B",
        "LLaMA 2-13B",
        "Mistral-7B",
        "Naive SFT",
        "Graph Convolutional Network (GCN)",
        "Graph Isomorphism Network (GIN)",
        "Graph Attention Network (GAT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LayoutNUWA Revealing the Hidden Layout Expertise of Large Language Models": {
    "filename": "LayoutNUWA Revealing the Hidden Layout Expertise of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Rico",
        "PubLayNet",
        "Magazine"
      ],
      "models": [
        "LayoutNUWA",
        "LayoutTrans",
        "BLT",
        "LayoutGAN++",
        "MaskGIT",
        "DiffusionLM",
        "LayoutDM",
        "LayoutNUWA-L2-DS",
        "LayoutNUWA-L2-DA",
        "LayoutNUWA-CL-DS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AppPoet Large Language Model based Android malware detection via multi-view prompt engineering": {
    "filename": "AppPoet Large Language Model based Android malware detection via multi-view prompt engineering.pdf",
    "analysis": {
      "benchmarks": [
        "AndroZoo"
      ],
      "models": [
        "AppPoet",
        "Drebin",
        "LBDB",
        "MaMaDroid",
        "Malscan",
        "MLP",
        "CNN",
        "TextCNN",
        "RNN",
        "LSTM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Binding Language Models in Symbolic Languages": {
    "filename": "Binding Language Models in Symbolic Languages.pdf",
    "analysis": {
      "benchmarks": [
        "WIKITABLE QUESTIONS",
        "TABFACT",
        "MULTIMODAL QA"
      ],
      "models": [
        "BINDER",
        "GPT-3 Codex",
        "Codex end-to-end QA",
        "Codex SQL",
        "Codex BINDER",
        "T5-3B",
        "Tapex",
        "TaCube",
        "OmniTab",
        "SASP",
        "BART-Large",
        "Implicit-Decomp",
        "PReasM-Large"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Efficient Prompt Optimization Through the Lens of Best Arm Identification": {
    "filename": "Efficient Prompt Optimization Through the Lens of Best Arm Identification.pdf",
    "analysis": {
      "benchmarks": [
        "Instruction-Induction",
        "BigBench"
      ],
      "models": [
        "TRIPLE",
        "TRIPLE-SH",
        "TRIPLE-CR",
        "TRIPLE-CLST",
        "TRIPLE-GSE",
        "GPT-3.5",
        "Llama2",
        "Gemma",
        "Mistral",
        "Uniform",
        "UCB",
        "BO-EI",
        "NeuralUCB",
        "APE",
        "APO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompting Large Language Models with Rationale Heuristics for Knowledge-based Visual Question Answering": {
    "filename": "Prompting Large Language Models with Rationale Heuristics for Knowledge-based Visual Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "OK-VQA",
        "A-OKVQA"
      ],
      "models": [
        "PLRH",
        "PICa",
        "Prophet",
        "PromptCap",
        "MUTAN",
        "Mucko",
        "ConceptBert",
        "KRISP",
        "MAVEx",
        "Visual Retriever-Reader",
        "TRiG",
        "UnifER",
        "GPV-2",
        "VLC-BERT",
        "ClipCap",
        "ViLBERT",
        "LXMERT"
      ]
    }
  },
  "CodeCoT Tackling Code Syntax Errors in CoT Reasoning for Code Generation": {
    "filename": "CodeCoT Tackling Code Syntax Errors in CoT Reasoning for Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "HumanEval-ET",
        "MBPP-ET"
      ],
      "models": [
        "CodeCoT",
        "GPT-3",
        "PaLM",
        "GLaM",
        "MegatronTuring NLG",
        "Meta-OPT",
        "Gopher",
        "LaMDA",
        "Chinchilla",
        "ChatGPT",
        "GPT-4",
        "AlphaCode",
        "Incoder",
        "CodeGeeX",
        "StarCoder",
        "CodeGen-Mono",
        "CodeX",
        "CodeX with CodeT",
        "Few-Shot",
        "ReAct",
        "Reflexion",
        "ToT",
        "RAP",
        "Self-Edit",
        "Self-Planing",
        "Self-Debugging",
        "Self-Collaboration",
        "INTERVENOR",
        "SCOT",
        "CodeChain"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Long-Context LLMs Meet RAG Overcoming Challenges for Long Inputs in RAG": {
    "filename": "Long-Context LLMs Meet RAG Overcoming Challenges for Long Inputs in RAG.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Questions (NQ)",
        "PopQA",
        "TriviaQA",
        "HotpotQA",
        "2wikimultihopqa",
        "Webquestions",
        "Bamboogle",
        "ASQA",
        "T-REx",
        "zsRE"
      ],
      "models": [
        "Gemma-7B-Chat",
        "Gemma-2-9B-Chat",
        "Mistral-Nemo-12B-Instruct",
        "Gemini-1.5-Pro",
        "Gemma-2-9B-Base",
        "Gemini-1.0-Pro",
        "Gemma2-7B-Chat",
        "Gemma2-9B-Chat",
        "Mistral-12B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving ChatGPT Prompt for Code Generation": {
    "filename": "Improving ChatGPT Prompt for Code Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CodeXGlue",
        "CONCODE"
      ],
      "models": [
        "ChatGPT",
        "CodeBERT",
        "CodeGPT",
        "GPT-2",
        "PLBART",
        "CodeT5",
        "RoBERTa",
        "Seq2Seq",
        "Seq2Action+MAML",
        "Transformer",
        "PBSMT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NERIF GPT-4V for Automatic Scoring of Drawn Models": {
    "filename": "NERIF GPT-4V for Automatic Scoring of Drawn Models.pdf",
    "analysis": {
      "benchmarks": [
        "TIMSS",
        "Kaggle COVID-19 lung X-ray dataset",
        "Test About Particles in a Gas"
      ],
      "models": [
        "GPT-4V",
        "NERIF",
        "ResNet-50 V2",
        "Inception-v3",
        "CNNs",
        "FFNs",
        "ResNet",
        "VGG",
        "2D convolutional neural networks",
        "k-nearest neighbor",
        "decision tree",
        "random forest",
        "support vector machine",
        "neural network",
        "logistic regression"
      ]
    }
  },
  "When Large Language Models Meet Personalization Perspectives of Challenges and Opportunities": {
    "filename": "When Large Language Models Meet Personalization Perspectives of Challenges and Opportunities.pdf",
    "analysis": {
      "benchmarks": [
        "LaMP",
        "MovieLens100k",
        "BookCrossing",
        "MovieLens-1M",
        "Amazon Book",
        "Amazon Beauty",
        "Amazon-Games",
        "CDs",
        "MIND-small",
        "Amazon-Music",
        "MIND"
      ],
      "models": [
        "LLM4Rec",
        "BERT",
        "GPT",
        "ChatGPT",
        "Flan-T5-Base",
        "Flan-T5-XXL",
        "LLaMA-7B",
        "text-davinci-002",
        "text-davinci-003",
        "gpt-3.5-turbo",
        "PALR",
        "InstructRec",
        "TALLRe",
        "LLMs-Rec",
        "P5",
        "M6-Rec",
        "GPT-NAS",
        "GENIUS",
        "LLMatic",
        "EvoPrompting",
        "DialoGPT",
        "BARCOR",
        "RecInDial",
        "UniCRS",
        "InstructGPT",
        "ChatRec"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Gender-specific Machine Translation with Large Language Models": {
    "filename": "Gender-specific Machine Translation with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MULTILINGUAL HOLISTIC BIAS",
        "BUG",
        "FLoRes"
      ],
      "models": [
        "LLaMA-2",
        "NLLB"
      ]
    }
  },
  "Large Language Models for Anomaly and Out-of-Distribution Detection A Survey": {
    "filename": "Large Language Models for Anomaly and Out-of-Distribution Detection A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "MVTec AD",
        "CLINC150",
        "ODDS Library",
        "Head CT - Hemorrhage"
      ],
      "models": [
        "GPT-4",
        "LLaMA",
        "CLIP",
        "GPT-4V",
        "SIGLLM",
        "LLMAD",
        "LogPrompt",
        "LA VAD",
        "LLM-Monitor",
        "AnomalyGPT",
        "Myriad",
        "WinCLIP",
        "CLIP-AC",
        "MCM",
        "ZOC",
        "NegLabel",
        "CLIPScope",
        "AnoCLIP",
        "CLIP-AD",
        "InCTRL",
        "MVFA",
        "CoOp",
        "LSN",
        "NegPrompt",
        "CLIPN",
        "MCM-PEFT",
        "LoCoOp",
        "AnomalyCLIP",
        "Holmes-VAD",
        "VAD-LLaMA",
        "AnomalyRuler",
        "AESOP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models": {
    "filename": "Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Wikidata",
        "CaLiGraph"
      ],
      "models": [
        "gpt-4-0125-preview",
        "gpt-3.5-turbo",
        "gemma-7b-it",
        "gemma-2b-it",
        "Mixtral-8x7B-Instruct-v0.1",
        "Mistral-7B-Instruct-v0.2",
        "Llama-2-70b-chat-hf"
      ]
    }
  },
  "KiVA Kid-inspired Visual Analogies for Testing Large Multimodal Models": {
    "filename": "KiVA Kid-inspired Visual Analogies for Testing Large Multimodal Models.pdf",
    "analysis": {
      "benchmarks": [
        "KiV A",
        "KiVA-adults",
        "ConceptARC",
        "Raven\u2019s Progressive Matrices",
        "abstract spatial reasoning"
      ],
      "models": [
        "GPT-4V",
        "LLaVA-1.5",
        "MANTIS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FedBiOT LLM Local Fine-tuning in Federated Learning without Full Model": {
    "filename": "FedBiOT LLM Local Fine-tuning in Federated Learning without Full Model.pdf",
    "analysis": {
      "benchmarks": [
        "GSM-8K",
        "Rosetta",
        "HumanEvalX",
        "dolly-15K",
        "HELM",
        "Alpaca"
      ],
      "models": [
        "FedBiOT",
        "LLaMA-2",
        "Offsite-tuning",
        "FedOT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring Advanced Large Language Models with LLMsuite": {
    "filename": "Exploring Advanced Large Language Models with LLMsuite.pdf",
    "analysis": {
      "benchmarks": [
        "GLUE",
        "SuperGLUE",
        "MMLU",
        "BIG-Bench",
        "HELM",
        "Gemini",
        "CoLA",
        "SST2",
        "MRPC",
        "STS",
        "QQP",
        "MNLI",
        "QNLI",
        "RTE",
        "WNLI",
        "CoT",
        "Muffin",
        "Natural Instructions v2",
        "MGSM",
        "BBH"
      ],
      "models": [
        "ChatGPT",
        "Gemini",
        "Retrieval Augmented Generation (RAG)",
        "Program-Aided Language Models (PAL)",
        "ReAct",
        "LangChain",
        "LoRA",
        "Reinforcement Learning from Human Feedback (RLHF)",
        "Reinforced Self-Training (ReST)",
        "Proximal Policy Optimization (PPO)",
        "FLAN-T5",
        "BitNet b1.58"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Batch Prompting Efficient Inference with Large Language Model APIs": {
    "filename": "Batch Prompting Efficient Inference with Large Language Model APIs.pdf",
    "analysis": {
      "benchmarks": [
        "CommonsenseQA",
        "StrategyQA",
        "GSM8K",
        "SVAMP",
        "AQuA",
        "AddSub",
        "MultiArith",
        "RTE",
        "MNLI",
        "SST-5",
        "WikiTQ"
      ],
      "models": [
        "Codex",
        "GPT-3",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Manipulate-Anything Automating Real-World Robots using Vision-Language Models": {
    "filename": "Manipulate-Anything Automating Real-World Robots using Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "RLBench"
      ],
      "models": [
        "MANIPULATE-ANYTHING",
        "VoxPoser",
        "Scaling-up",
        "Code-As-Policies",
        "PerAct",
        "RVT-2"
      ]
    }
  },
  "Make Them Spill the Beans Coercive Knowledge Extraction from Production LLMs": {
    "filename": "Make Them Spill the Beans Coercive Knowledge Extraction from Production LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "NeurIPS Trojan Detection Challenge 2023"
      ],
      "models": [
        "Yi-34B",
        "Vicuna-13B",
        "Llama2-7B",
        "Llama2-13B",
        "Llama2-70B",
        "Codellama-13B-Instruct",
        "Codellama-13B-Python",
        "Gpt-3.5-turbo-instruct",
        "Gpt-3.5-turbo-instruct-0914",
        "Text-davinci-003",
        "GCG",
        "GPTFuzzer",
        "L INT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VerityMath Advancing Mathematical Reasoning by Self-Verification Through Unit Consistency": {
    "filename": "VerityMath Advancing Mathematical Reasoning by Self-Verification Through Unit Consistency.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP"
      ],
      "models": [
        "Llama 2 (7B)",
        "Code Llama (7B)",
        "Mistral (7B)",
        "VerityMath-Llama-2",
        "VerityMath-Code-Llama",
        "VerityMath-Mistral"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Text to Emotion Unveiling the Emotion Annotation Capabilities of LLMs": {
    "filename": "From Text to Emotion Unveiling the Emotion Annotation Capabilities of LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "ISEAR",
        "SemEval",
        "GoEmotions",
        "Emobank"
      ],
      "models": [
        "GPT-4",
        "BERT",
        "Human annotations"
      ]
    }
  },
  "Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models": {
    "filename": "Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models.pdf",
    "analysis": {
      "benchmarks": [
        "Brick World",
        "NLVR-based Manipulation",
        "Natural Language Navigation",
        "SPARTUN"
      ],
      "models": [
        "COS (Chain-of-Symbol Prompting)",
        "CoT (Chain-of-Thought Prompting)",
        "ChatGPT (gpt-3.5-turbo)",
        "LLAMA-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AFlow Automating Agentic Workflow Generation": {
    "filename": "AFlow Automating Agentic Workflow Generation.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "MATH",
        "GSM8K",
        "HotpotQA",
        "DROP"
      ],
      "models": [
        "AFLOW",
        "IO (GPT-4o-mini)",
        "CoT (Chain-of-Thought)",
        "CoT SC (Self Consistency CoT)",
        "MedPrompt",
        "MultiPersona",
        "Self Refine",
        "ADAS",
        "DeepSeek-V2.5",
        "GPT-4o-mini",
        "Claude-3.5-sonnet",
        "GPT-4o"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Blind Judgement Agent-Based Supreme Court Modelling With GPT": {
    "filename": "Blind Judgement Agent-Based Supreme Court Modelling With GPT.pdf",
    "analysis": {
      "benchmarks": [
        "Supreme Court Database (SCDB)"
      ],
      "models": [
        "Transformer-based multi-agent system",
        "GPT-2",
        "single agent model"
      ]
    }
  },
  "In-Context Editing Learning Knowledge from Self-Induced Distributions": {
    "filename": "In-Context Editing Learning Knowledge from Self-Induced Distributions.pdf",
    "analysis": {
      "benchmarks": [
        "WikiData recent",
        "ZsRE",
        "WikiBio",
        "WikiData counterfact"
      ],
      "models": [
        "Consistent In-Context Editing (ICE)",
        "ROME",
        "MEMIT",
        "FT-L",
        "FT-M",
        "Llama2-7b-chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "COCO is ALL You Need for Visual Instruction Fine-tuning": {
    "filename": "COCO is ALL You Need for Visual Instruction Fine-tuning.pdf",
    "analysis": {
      "benchmarks": [
        "NoCaps",
        "COCO",
        "GQA",
        "VQAv2",
        "VizWiz",
        "MME",
        "SeedBench",
        "MMMU",
        "MM-Vet",
        "InfiMM-Eval"
      ],
      "models": [
        "LLaVA-1.5",
        "LLaVA-mix-665k",
        "COCO-LLaVA-13B",
        "GPT-4V",
        "Qwen-VL",
        "Flamingo",
        "BLIP-2",
        "Mini-GPT4"
      ]
    }
  },
  "Beyond Human Norms Unveiling Unique Values of Large Language Models through Interdisciplinary Approaches": {
    "filename": "Beyond Human Norms Unveiling Unique Values of Large Language Models through Interdisciplinary Approaches.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ValueLex",
        "Mistral",
        "Tulu",
        "Baichuan",
        "LLaMA",
        "GPT-3.5-turbo",
        "GPT-3-text-davinci-003",
        "GPT-3-text-babbage",
        "GPT-3-text-curie",
        "GPT-4",
        "Gemma7b",
        "Baichuan7b-chat",
        "Baichuan13b-chat",
        "LLaMA2-7b-chat",
        "LLaMA2-13b-chat",
        "Baichuan7b-base",
        "Baichuan13b-base",
        "LLaMA2-7b-base",
        "LLaMA2-13b-base",
        "LLaMA2-70b-chat",
        "Mistral-tiny",
        "Mistral-small",
        "Mistral-medium",
        "Mistral-large",
        "GLM3",
        "GLM4",
        "Tulu2-7b",
        "Tulu2-13b",
        "Gemini",
        "GPT-3.5-turbo-0125",
        "GPT-3.5-turbo-16k",
        "GPT-4-turbo-preview",
        "Vicuna-13B-V15",
        "Phi-1",
        "Solar-mini",
        "Google-PaLM2",
        "Orca-2"
      ]
    }
  },
  "Can Language Models Solve Graph Problems in Natural Language": {
    "filename": "Can Language Models Solve Graph Problems in Natural Language.pdf",
    "analysis": {
      "benchmarks": [
        "NLGraph"
      ],
      "models": [
        "GPT-3",
        "GPT-4",
        "Build-a-Graph Prompting",
        "Algorithmic Prompting",
        "TEXT-DAVINCI-003",
        "GPT-3.5-TURBO",
        "CODE-DAVINCI-002"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Balancing Cost and Effectiveness of Synthetic Data Generation Strategies for LLMs": {
    "filename": "Balancing Cost and Effectiveness of Synthetic Data Generation Strategies for LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "Spider",
        "ARC-C"
      ],
      "models": [
        "Llama 2 7B Chat",
        "Llama 3.1 70B Instruct",
        "Mistral 7B"
      ]
    }
  },
  "ToolQA A Dataset for LLM Question Answering with External Tools": {
    "filename": "ToolQA A Dataset for LLM Question Answering with External Tools.pdf",
    "analysis": {
      "benchmarks": [
        "ToolQA",
        "GSM8K",
        "SciREX",
        "DBLP",
        "Flights",
        "Coffee",
        "Yelp",
        "Airbnb",
        "Agenda"
      ],
      "models": [
        "ChatGPT",
        "Chain-of-thoughts prompting",
        "Chameleon",
        "ReAct (GPT-3)",
        "ReAct (GPT-3.5)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Integrating Text-to-Music Models with Language Models Composing Long Structured Music Pieces": {
    "filename": "Integrating Text-to-Music Models with Language Models Composing Long Structured Music Pieces.pdf",
    "analysis": {
      "benchmarks": [
        "Pond5"
      ],
      "models": [
        "Jukebox",
        "Music Transformer",
        "MusicGen",
        "ChatGPT",
        "Our Method"
      ]
    }
  },
  "kNN Prompting Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference": {
    "filename": "kNN Prompting Beyond-Context Learning with Calibration-Free Nearest Neighbor Inference.pdf",
    "analysis": {
      "benchmarks": [
        "SST2",
        "SUBJ",
        "MPQA",
        "AGNews",
        "CB",
        "CR",
        "DBPedia",
        "MR",
        "RTE",
        "TREC"
      ],
      "models": [
        "kNN Prompting",
        "ICL",
        "Contextual Calibration",
        "Noisy Channel",
        "ICL Ensemble",
        "BERT Large FT",
        "GPT Large FT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learn to Explain Multimodal Reasoning via Thought Chains for Science Question Answering": {
    "filename": "Learn to Explain Multimodal Reasoning via Thought Chains for Science Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "SCIENCE QA",
        "AI2D",
        "DVQA",
        "VLQA",
        "FOODWEDS",
        "WorldTree",
        "OpenBookQA",
        "QASC",
        "ARC",
        "TQA",
        "IconQA"
      ],
      "models": [
        "few-shot GPT-3",
        "fine-tuned UnifiedQA",
        "VisualBERT",
        "Patch-TRM",
        "MCAN",
        "Top-Down",
        "BAN",
        "DFAF",
        "ViLT",
        "UnifiedQA SMALL",
        "UnifiedQA BASE",
        "UnifiedQA BASE (CoT)",
        "GPT-3",
        "GPT-3 (CoT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning a Structural Causal Model for Intuition Reasoning in Conversation": {
    "filename": "Learning a Structural Causal Model for Intuition Reasoning in Conversation.pdf",
    "analysis": {
      "benchmarks": [
        "RECCON",
        "Synthetic dataset",
        "Simulation dataset"
      ],
      "models": [
        "CCM",
        "SCM",
        "GNN",
        "RoBERTa",
        "EGAT",
        "DECN",
        "DAG-ERC",
        "CAE",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Samba Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling": {
    "filename": "Samba Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling.pdf",
    "analysis": {
      "benchmarks": [
        "Passkey Retrieval",
        "Phonebook",
        "MMLU-Pro",
        "HumanEval",
        "GSM8K",
        "Proof-Pile",
        "ARC",
        "PIQA",
        "WinoGrande",
        "SIQA",
        "HellaSwag",
        "BoolQ",
        "OpenbookQA",
        "SQuAD",
        "MMLU",
        "TruthfulQA",
        "MBPP",
        "GovReport",
        "SQuALITY",
        "LAMBADA"
      ],
      "models": [
        "SAMBA",
        "Mamba",
        "Sliding Window Attention (SWA)",
        "Llama-3",
        "Mistral",
        "Mamba-SWA-MLP",
        "Mamba-MLP",
        "Llama-2",
        "Sliding GLA",
        "Sliding RetNet",
        "Mega-S6",
        "MLP2-SWA-MLP",
        "SAMBA-NoPE",
        "SE-Llama-3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Challenges Faced by Large Language Models in Solving Multi-Agent Flocking": {
    "filename": "Challenges Faced by Large Language Models in Solving Multi-Agent Flocking.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5-Turbo",
        "GPT-4-Turbo"
      ]
    }
  },
  "A Case Study on Test Case Construction with Large Language Models Unveiling Practical Insights and Challenges": {
    "filename": "A Case Study on Test Case Construction with Large Language Models Unveiling Practical Insights and Challenges.pdf",
    "analysis": {
      "benchmarks": [
        "Da.tes"
      ],
      "models": [
        "GPT-3.5 Turbo",
        "GPT",
        "Codex",
        "PLBART",
        "CodeBERT",
        "GraphCodeBERT"
      ]
    }
  },
  "Negated Complementary Commonsense using Large Language Models": {
    "filename": "Negated Complementary Commonsense using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ATOMIC-2020"
      ],
      "models": [
        "GPT-3",
        "text-davinci-002"
      ]
    }
  },
  "AutoSAT Automatically Optimize SAT Solvers via Large Language Models": {
    "filename": "AutoSAT Automatically Optimize SAT Solvers via Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "cryptography-ascon",
        "register-allocation",
        "social-golfer",
        "hashtable-safety",
        "profitable-robust-product (PRP)",
        "argumentation",
        "set-covering-with-pairs (SCP)",
        "CoinsGrid",
        "MineSweeper",
        "KnightTour",
        "LangFord",
        "Zamkeller"
      ],
      "models": [
        "AutoSAT",
        "MiniSat",
        "Kissat",
        "EasySAT",
        "AutoSAT_GHC",
        "AutoSAT_EA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Domain-Specific Retrieval-Augmented Generation Using Vector Stores Knowledge Graphs and Tensor Factorization": {
    "filename": "Domain-Specific Retrieval-Augmented Generation Using Vector Stores Knowledge Graphs and Tensor Factorization.pdf",
    "analysis": {
      "benchmarks": [
        "SCOPUS",
        "Semantic Scholar (S2)",
        "Office of Scientific and Technical Information (OSTI)",
        "Los Alamos National Laboratory Unified Host and Network Dataset"
      ],
      "models": [
        "SMART-SLIC",
        "GPT-4-instruct",
        "Canonical Polyadic Alternating Poisson Regression (CP-APR)",
        "SCI-NCL",
        "text-embedding-ada-002"
      ]
    }
  },
  "FoodSAM Any Food Segmentation": {
    "filename": "FoodSAM Any Food Segmentation.pdf",
    "analysis": {
      "benchmarks": [
        "FoodSeg103",
        "UECFoodPix Complete"
      ],
      "models": [
        "Segment Anything Model (SAM)",
        "FoodSAM",
        "SETR",
        "deeplabV3+",
        "UniDet",
        "RAM",
        "SEEM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Large Language Models on Graphs Performance Insights and Comparative Analysis": {
    "filename": "Evaluating Large Language Models on Graphs Performance Insights and Comparative Analysis.pdf",
    "analysis": {
      "benchmarks": [
        "randomly generated graph data"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4",
        "CalderaAI/30B-Lazarus",
        "TheBloke/Wizard-Vicuna-13B-Uncensored-HF"
      ]
    }
  },
  "BLIAM Literature-based Data Synthesis for Synergistic Drug Combination Prediction": {
    "filename": "BLIAM Literature-based Data Synthesis for Synergistic Drug Combination Prediction.pdf",
    "analysis": {
      "benchmarks": [
        "GDSC-combo"
      ],
      "models": [
        "BLIAM",
        "PubMedBERT",
        "Base classifier",
        "Manual prompt",
        "Ours (valid vocabulary)",
        "Ours (no warm-start)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Proving Olympiad Algebraic Inequalities without Human Demonstrations": {
    "filename": "Proving Olympiad Algebraic Inequalities without Human Demonstrations.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SAT Math",
        "miniF2F",
        "INT",
        "MO-INT-20"
      ],
      "models": [
        "AIPS",
        "AlphaGeometry",
        "GPT-f",
        "LeanCopilot",
        "Gemini 1.5 Pro",
        "GPT-4",
        "GPT-4 Turbo",
        "Llemma-7b",
        "DE + GPT-4 Turbo\u2019s heuristics",
        "DE + BFS",
        "DE + MCTS",
        "DE + tree-depth heuristic function",
        "AIPS with pretrained value network"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "QLoRA Efficient Finetuning of Quantized LLMs": {
    "filename": "QLoRA Efficient Finetuning of Quantized LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Vicuna",
        "MMLU",
        "GLUE",
        "Super-NaturalInstructions",
        "Alpaca",
        "FLAN v2",
        "OASST1",
        "CrowS"
      ],
      "models": [
        "QLORA",
        "Guanaco",
        "LLaMA",
        "T5",
        "RoBERTa-large",
        "Vicuna",
        "ChatGPT",
        "GPT-4",
        "Bard",
        "Alpaca",
        "Open Assistant",
        "Anthropic HH-RLHF",
        "OPT",
        "BLOOM",
        "Pythia"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning to Predict Concept Ordering for Common Sense Generation": {
    "filename": "Learning to Predict Concept Ordering for Common Sense Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CommonGen"
      ],
      "models": [
        "BERT-gen",
        "BART-base",
        "T5-base",
        "BART-large",
        "T5-large",
        "KG-BART",
        "EKI-BART Dout",
        "CALM",
        "NeuroLogic",
        "[MASK]",
        "GPT-3 Babbage",
        "GPT-3 Curie",
        "GPT-3.5 Turbo"
      ]
    }
  },
  "LLMs for Domain Generation Algorithm Detection": {
    "filename": "LLMs for Domain Generation Algorithm Detection.pdf",
    "analysis": {
      "benchmarks": [
        "custom dataset with 68 malware families and normal domains",
        "Tranco dataset",
        "UMUDGA dataset",
        "DGAarchive",
        "360netlab datasets"
      ],
      "models": [
        "Meta's Llama3 8B",
        "SFT-based LLM DGA detector",
        "LA Bin07 model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RIFF Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models": {
    "filename": "RIFF Learning to Rephrase Inputs for Few-shot Fine-tuning of Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SST2",
        "CR",
        "MR",
        "SST5",
        "TREC",
        "AGNews"
      ],
      "models": [
        "RIFF",
        "BERT",
        "RoBERTa",
        "T5",
        "GPT2",
        "GPT3",
        "Llama-2",
        "PaLM-2",
        "LoRA",
        "AllTune",
        "GS",
        "SpTune",
        "ClsTune",
        "InTune",
        "HTune"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mitigating Adversarial Attacks in LLMs through Defensive Suffix Generation": {
    "filename": "Mitigating Adversarial Attacks in LLMs through Defensive Suffix Generation.pdf",
    "analysis": {
      "benchmarks": [
        "AdvBench",
        "TruthfulQA"
      ],
      "models": [
        "Gemma-7B",
        "Mistral-7B",
        "Llama2-7B",
        "Llama2-13B",
        "Llama3.2-1B",
        "openELM-270M",
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "GLoRE Evaluating Logical Reasoning of Large Language Models": {
    "filename": "GLoRE Evaluating Logical Reasoning of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GLoRE",
        "LogiQA 2.0",
        "LogiQA 2.0 zh",
        "ReClor",
        "AR-LSAT",
        "LogiQA22",
        "ConTRoL",
        "HELP",
        "TaxiNLI",
        "NaN-NLI",
        "FraCas",
        "RuleTaker",
        "ProofWriter"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "LLaMA",
        "Falcon",
        "RoBERTa",
        "LLaMA-7b",
        "Alpaca",
        "LLaMA-30b-supercot",
        "Falcon-40b-instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Aligning Cyber Space with Physical World A Comprehensive Survey on Embodied AI": {
    "filename": "Aligning Cyber Space with Physical World A Comprehensive Survey on Embodied AI.pdf",
    "analysis": {
      "benchmarks": [
        "R2R",
        "Room-for-Room",
        "VLN-CE",
        "TOUCHDOWN",
        "REVERIE",
        "SOON",
        "DDN",
        "ALFRED",
        "OVMM",
        "BEHAVIOR-1K",
        "CVDN",
        "DialFRED"
      ],
      "models": [
        "RT-2",
        "RT-H",
        "LVERG",
        "CMG",
        "RCM",
        "FILM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "When Giant Language Brains Just Arent Enough Domain Pizzazz with Knowledge Sparkle Dust": {
    "filename": "When Giant Language Brains Just Arent Enough Domain Pizzazz with Knowledge Sparkle Dust.pdf",
    "analysis": {
      "benchmarks": [
        "expert-created insurance dataset",
        "synthesized dataset"
      ],
      "models": [
        "GPT",
        "GPT+RB",
        "GPT+RB+DBpedia"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs": {
    "filename": "Dspy-based Neural-Symbolic Pipeline to Enhance Spatial Reasoning in LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "StepGame",
        "SparQA"
      ],
      "models": [
        "Deepseek",
        "Llama3-70B",
        "GPT-4.0 mini",
        "direct prompting baseline",
        "Facts+Rules prompting",
        "DSPy-based LLM+ASP pipeline"
      ]
    }
  },
  "Language to Rewards for Robotic Skill Synthesis": {
    "filename": "Language to Rewards for Robotic Skill Synthesis.pdf",
    "analysis": {
      "benchmarks": [
        "simulated quadruped robot tasks",
        "dexterous manipulator robot tasks"
      ],
      "models": [
        "proposed method with LLMs and MuJoCo MPC",
        "baseline using primitive skills with Code-as-policies",
        "Reward Coder only baseline"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks": {
    "filename": "Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks.pdf",
    "analysis": {
      "benchmarks": [
        "Jailbreakchat"
      ],
      "models": [
        "ChatGPT",
        "Bard",
        "Vicuna",
        "Llama 2",
        "Claude-2",
        "GPT-3.5-Turbo",
        "GPT-4",
        "ChatGLM",
        "Dolly"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models are Biased Reinforcement Learners": {
    "filename": "Large Language Models are Biased Reinforcement Learners.pdf",
    "analysis": {
      "benchmarks": [
        "B2018",
        "V2023",
        "HW2023a",
        "BP2023",
        "HW2023b"
      ],
      "models": [
        "gpt-3.5-turbo-0125",
        "gpt-4-0125-preview",
        "llama-2-70b-chat",
        "mixtral-8x7b-instruct",
        "gemma-7b"
      ]
    }
  },
  "Generative agent-based modeling with actions grounded in physical social or digital space using Concordia": {
    "filename": "Generative agent-based modeling with actions grounded in physical social or digital space using Concordia.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Concordia",
        "Generative Agent-Based Models (GABM)",
        "Game Master (GM)",
        "Concordia agents"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompting Large Language Models With the Socratic Method": {
    "filename": "Prompting Large Language Models With the Socratic Method.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3",
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PREDILECT Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning": {
    "filename": "PREDILECT Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Reacher",
        "Cheetah",
        "social robot navigation environment"
      ],
      "models": [
        "PREDILECT",
        "baseline preference learning",
        "LLM (GPT-4)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BackdoorLLM A Comprehensive Benchmark for Backdoor Attacks on Large Language Models": {
    "filename": "BackdoorLLM A Comprehensive Benchmark for Backdoor Attacks on Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Stanford Alpaca",
        "AdvBench",
        "math reasoning data",
        "SST-2",
        "AGNews",
        "Counterfact Fact-Checking",
        "ToxiGen",
        "BOLD",
        "GSM8K",
        "MATH",
        "ASDiv",
        "CSQA",
        "StrategyQA",
        "Letter"
      ],
      "models": [
        "Llama-7B",
        "Llama-13B",
        "Llama-70B",
        "Mistral",
        "GPT-2",
        "Llama-2-7b-Chat",
        "Llama-2-13b-Chat",
        "Llama-3-8b-Instruct",
        "Vicuna-7b-V1.5",
        "BadNets",
        "VPI",
        "Sleeper",
        "MTBA",
        "CTBA",
        "BadEdit",
        "BadChain",
        "TA2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Magentic-One A Generalist Multi-Agent System for Solving Complex Tasks": {
    "filename": "Magentic-One A Generalist Multi-Agent System for Solving Complex Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "GAIA",
        "AssistantBench",
        "WebArena"
      ],
      "models": [
        "Magentic-One",
        "omne v0.1",
        "Trase Agent v0.2",
        "Multi Agent",
        "das agent v0.4",
        "Sibyl",
        "HF Agents",
        "FRIDAY",
        "GPT-4 + plugins",
        "SPA\u2192CB",
        "Infogent",
        "Jace.AI",
        "WebPilot",
        "AWM",
        "SteP",
        "BrowserGym",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Do Transformers Learn In-Context Beyond Simple Functions A Case Study on Learning with Representations": {
    "filename": "How Do Transformers Learn In-Context Beyond Simple Functions A Case Study on Learning with Representations.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "transformer",
        "\u03a6\u22c6-ridge",
        "\u03a6\u22c6-OLS",
        "\u03a6\u22c6-ridge-dyn",
        "TF_upper+1_layer_TF_embed",
        "TF_upper+linear_copy_embed",
        "TF_upper+linear_embed",
        "fresh_1_layer_TF"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Comprehensive Overview of Large Language Models": {
    "filename": "A Comprehensive Overview of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "HumanEval",
        "MBPP",
        "PubMedQA",
        "MedMCQA",
        "Codeforces"
      ],
      "models": [
        "T5",
        "GPT-3",
        "mT5",
        "PanGu-\u03b1",
        "CPM-2",
        "ERNIE 3.0",
        "Jurassic-1",
        "HyperCLOVA",
        "Yuan 1.0",
        "Gopher",
        "ERNIE 3.0 Titan",
        "GPT-NeoX-20B",
        "OPT",
        "BLOOM",
        "GLaM",
        "MT-NLG",
        "Chinchilla",
        "AlexaTM",
        "PaLM",
        "PaLM-2",
        "U-PaLM",
        "UL2",
        "GLM-130B",
        "LLaMA",
        "LLaMA-2",
        "LLaMA-3",
        "PanGu-\u03a3",
        "Mixtral8x22b",
        "Snowflake Arctic",
        "Grok-1",
        "Grok-1.5",
        "Gemini-1",
        "Gemini-1.5",
        "Nemotron-4 340B",
        "DeepSeek",
        "DeepSeek-v2",
        "CodeGen",
        "Codex",
        "AlphaCode",
        "CodeT5+",
        "StarCoder",
        "Galactica",
        "LaMDA",
        "BloombergGPT",
        "Xuan Yuan 2.0"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings": {
    "filename": "Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings.pdf",
    "analysis": {
      "benchmarks": [
        "Transcriptions",
        "MIMIC-CXR",
        "MS-CXR"
      ],
      "models": [
        "BioLORD-STAMB2-v1-STS2",
        "RoBERTa LARGE-MNLI",
        "T0++",
        "Flan-T5-XXL",
        "BioLORD-PMB",
        "Alpaca 7B",
        "BART Large-MNLI",
        "NLI-DeBERTa base",
        "BERT BASE",
        "BERT LARGE",
        "BiomedBERT",
        "SciBERT",
        "SapBERT",
        "Bio+Clinical BERT",
        "T5-V1.1-Base",
        "T5-V1.1-Large",
        "T5-V1.1-3B",
        "T5-V1.1-11B",
        "Flan-T5-Base",
        "Flan-T5-Large",
        "Flan-T5-XL",
        "Flan-T5-XLL",
        "T0 3B",
        "ClinicalT5-base",
        "ClinicalT5-large",
        "GPT-2 Medium",
        "GPT-2 Large",
        "GPT-2 XL",
        "Palmyra Base 5B",
        "Camel 5B",
        "GPT-J 6B",
        "Instruct GPT-J",
        "Falcon-7B",
        "Falcon-7B-Instruct",
        "MPT-7B",
        "MPT-7B-Instruct",
        "LLaMA-7B",
        "LLaMA 2-7B",
        "LLaMA 2-CHAT-7B",
        "OpenLLaMA 3B",
        "OpenLLaMA 3Bv2",
        "OpenLLaMA 7B",
        "OpenLLaMA 7Bv2",
        "OpenLLaMA 13B",
        "BioGPT",
        "BioGPT-Large",
        "Galactica 1.3B",
        "Galactica 6.7B",
        "MedAlpaca 7b"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods": {
    "filename": "Predictions from language models for multiple-choice tasks are not robust under variation of scoring methods.pdf",
    "analysis": {
      "benchmarks": [
        "pragmatic language interpretation dataset from Hu, Floyd, et al. (2023)"
      ],
      "models": [
        "GPT-3.5-turbo-instruct",
        "text-davinci-002",
        "LLaMA-2",
        "FLAN-T5-XL",
        "text-embedding-ada-002"
      ]
    }
  },
  "Tuning-Free Accountable Intervention for LLM Deployment - A Metacognitive Approach": {
    "filename": "Tuning-Free Accountable Intervention for LLM Deployment - A Metacognitive Approach.pdf",
    "analysis": {
      "benchmarks": [
        "CEBaB",
        "IMDB-C",
        "ASAP-C"
      ],
      "models": [
        "CLEAR",
        "BERT",
        "OPT",
        "T5",
        "GPT-4",
        "Vanilla-CBMs",
        "LF-CBMs",
        "CEMs",
        "ITI",
        "OPT-MoCE",
        "T5-MoCE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Llama 2 Open Foundation and Fine-Tuned Chat Models": {
    "filename": "Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "MBPP",
        "PIQA",
        "SIQA",
        "HellaSwag",
        "WinoGrande",
        "ARC easy",
        "ARC challenge",
        "OpenBookQA",
        "CommonsenseQA",
        "NaturalQuestions",
        "TriviaQA",
        "SQuAD",
        "QuAC",
        "BoolQ",
        "GSM8K",
        "MATH",
        "MMLU",
        "Big Bench Hard",
        "AGI Eval"
      ],
      "models": [
        "Llama 2",
        "Llama 2-Chat",
        "MosaicML Pretrained Transformer (MPT)",
        "Falcon",
        "GPT-3.5",
        "GPT-4",
        "PaLM",
        "PaLM-2-L",
        "SteamSHP-XL",
        "Open Assistant",
        "Safety RM",
        "Helpfulness RM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Document-Level In-Context Few-Shot Relation Extraction via Pre-Trained Language Models": {
    "filename": "Document-Level In-Context Few-Shot Relation Extraction via Pre-Trained Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "DocRED",
        "CDR",
        "GDA",
        "CONLL04",
        "NYT",
        "ADE"
      ],
      "models": [
        "REPLM",
        "REBEL",
        "REBEL-sent",
        "SciBERT",
        "LSR",
        "DHG",
        "GAIN",
        "JEREX",
        "HeterGSAN",
        "DRN",
        "SIRE",
        "SSAN",
        "ATLOP",
        "E2GRE",
        "DocuNet",
        "EIDER",
        "SAIS",
        "DREEAM",
        "DocRE-CLiP",
        "Neural Joint",
        "SpERT",
        "Table-sequence",
        "BILSTM + Att",
        "TANL",
        "TriMF",
        "CMAN",
        "CL",
        "PFN",
        "TabERT",
        "BL",
        "STER",
        "FedJ",
        "PREFER",
        "GPT-RE",
        "CodeIE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Survey on Factuality in Large Language Models Knowledge Retrieval and Domain-Specificity": {
    "filename": "Survey on Factuality in Large Language Models Knowledge Retrieval and Domain-Specificity.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "TruthfulQA",
        "C-Eval",
        "AGIEval",
        "HaluEval",
        "BigBench",
        "ALCE",
        "QUIP",
        "PopQA",
        "UniLC",
        "Pinocchio",
        "SelfAware",
        "RealTimeQA",
        "FreshQA"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "LLaMA",
        "BARD",
        "BingChat",
        "Llama-Index",
        "SelfCheckGPT",
        "FActScore",
        "HuatuoGPT",
        "DISC-MedLLM",
        "LawGPT",
        "ChatLaw",
        "EcomGPT",
        "BloombergGPT",
        "GrammarGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MatExpert Decomposing Materials Discovery by Mimicking Human Experts": {
    "filename": "MatExpert Decomposing Materials Discovery by Mimicking Human Experts.pdf",
    "analysis": {
      "benchmarks": [
        "NOMAD",
        "Material Project"
      ],
      "models": [
        "MatExpert",
        "Crystal Diffusion Variational Autoencoders (CDVAE)",
        "LLaMA-2",
        "CrystaLLM",
        "LM-AC",
        "LM-CH",
        "Crystal-LLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Iterative Graph Alignment": {
    "filename": "Iterative Graph Alignment.pdf",
    "analysis": {
      "benchmarks": [
        "RuleAlign"
      ],
      "models": [
        "Iterative Graph Alignment (IGA)",
        "Claude Sonnet 3.5",
        "Llama3-8B-Instruct",
        "GPT-4o",
        "Chain of Thought (CoT)",
        "Self-Taught Reasoner (STaR)"
      ]
    }
  },
  "Enhancing Knowledge Retrieval with In-Context Learning and Semantic Search through Generative AI": {
    "filename": "Enhancing Knowledge Retrieval with In-Context Learning and Semantic Search through Generative AI.pdf",
    "analysis": {
      "benchmarks": [
        "MSMARCO",
        "Spider"
      ],
      "models": [
        "Generative Text Retrieval (GTR)",
        "Generative Tabular Text Retrieval (GTR-T)",
        "Falcon 7B",
        "Flan T5-XXL",
        "BiDAF",
        "Deep Cascade QA",
        "S-Net+CES2S",
        "BERT+Multi-PGNet",
        "VNET",
        "Masque (Q&A; ensemble)",
        "DAIL-SQL(4)",
        "DIN-SQL(4)",
        "C3"
      ]
    }
  },
  "Quality Prediction of AI Generated Images and Videos Emerging Trends and Opportunities": {
    "filename": "Quality Prediction of AI Generated Images and Videos Emerging Trends and Opportunities.pdf",
    "analysis": {
      "benchmarks": [
        "WebText",
        "BookCorpus",
        "COCO",
        "ImageNet",
        "Conceptual Captions",
        "CLIP (LAION-400M)",
        "LLFF (Local Light Field Fusion) Dataset",
        "Tanks and Temples Dataset",
        "DIV2K",
        "Vimeo-90K",
        "UCF-101",
        "HPD",
        "ImageReward",
        "Pick-A-Pic",
        "AGIQA-1K",
        "AGIQA-3K",
        "AIGCIQA",
        "AIGIQA-20K",
        "PKU-AIGIQA-4K",
        "AGIN",
        "DCU",
        "VBench",
        "FETV",
        "EvalCrafter",
        "T2VQA-DB",
        "AIGCBench"
      ],
      "models": [
        "GPT-2",
        "GPT-3",
        "CTRL",
        "BERT",
        "RoBERTa",
        "XLNet",
        "Pix2Pix",
        "VQ-VAE-2",
        "CLIP",
        "BigGAN",
        "StyleGAN",
        "DALL-E",
        "ESRGAN",
        "SRGAN",
        "EDSR",
        "Super Slomo",
        "BasicVSR",
        "I3D",
        "MoCoGAN",
        "DPC",
        "Stable Diffusion",
        "SSIM",
        "VMAF",
        "LPIPS",
        "PieAPP",
        "DISTS",
        "ST-LPIPS",
        "ARNIQA",
        "UNIQA",
        "NDNetGaming",
        "UVQ",
        "PaQ-2-PiQ",
        "RAPIQUE",
        "CONTRIQUE",
        "Re-IQA",
        "CLIP-IQA",
        "BLIP",
        "viCLIP",
        "HPS",
        "PickScore",
        "ImageReward",
        "NeRF",
        "NSVF",
        "DeepVoxels"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Advances in Embodied Navigation Using Large Language Models A Survey": {
    "filename": "Advances in Embodied Navigation Using Large Language Models A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "REVERIE",
        "ScanNet",
        "Gibson",
        "HM3D",
        "MP3D",
        "R2R",
        "RxR",
        "ProcTHOR",
        "MatterPort3D"
      ],
      "models": [
        "LM-Nav",
        "CLIP-Nav",
        "SQA3D",
        "L3MVN",
        "ESC",
        "NavGPT",
        "VELMA",
        "A2Nav",
        "MiC",
        "SayNav",
        "CoW",
        "ZSON",
        "VLMAP",
        "OVRL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Depth Helps Improving Pre-trained RGB-based Policy with Depth Information Injection": {
    "filename": "Depth Helps Improving Pre-trained RGB-based Policy with Depth Information Injection.pdf",
    "analysis": {
      "benchmarks": [
        "LIBERO"
      ],
      "models": [
        "Depth Information Injection (DI2) framework",
        "Depth Completion Module (DCM)",
        "Depth-Aware Codebook (DAC)",
        "RoboFlamingo",
        "RGB-RF",
        "RGB-D-RF",
        "Data Aug",
        "MM Prompt",
        "CRD",
        "CMKD"
      ]
    }
  },
  "ChemReasoner Heuristic Search over a Large Language Models Knowledge Space using Quantum-Chemical Feedback": {
    "filename": "ChemReasoner Heuristic Search over a Large Language Models Knowledge Space using Quantum-Chemical Feedback.pdf",
    "analysis": {
      "benchmarks": [
        "OpenCatalyst",
        "BioFuels",
        "CO2-Fuel"
      ],
      "models": [
        "CHEM REASONER",
        "CHEM REASONER-Expert",
        "CHEM REASONER-Planner",
        "GPT-4",
        "GPT-3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain of Ideas Revolutionizing Research Via Novel Idea Development with LLM Agents": {
    "filename": "Chain of Ideas Revolutionizing Research Via Novel Idea Development with LLM Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Chain-of-Ideas (CoI) agent",
        "Vanilla RAG",
        "GraphGPT",
        "GoT",
        "CoT",
        "SC",
        "ToT",
        "RAG",
        "ResearchAgent",
        "GPT-Researcher",
        "AI-Scientist",
        "Real Paper"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Neuro-Symbolic Approach to Monitoring Salt Content in Food": {
    "filename": "A Neuro-Symbolic Approach to Monitoring Salt Content in Food.pdf",
    "analysis": {
      "benchmarks": [
        "USFDC",
        "MultiWOZ"
      ],
      "models": [
        "PPTOD",
        "NS-PPTOD"
      ]
    }
  },
  "Explainable Verbal Reasoner Plus EVR A Natural Language Reasoning Framework that Supports Diverse Compositional Reasoning": {
    "filename": "Explainable Verbal Reasoner Plus EVR A Natural Language Reasoning Framework that Supports Diverse Compositional Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "SynthCompR"
      ],
      "models": [
        "Explainable Verbal Reasoner Plus (EVR+)",
        "Explainable Verbal Reasoner (EVR)",
        "Uni\ufb01edQA-T5-large",
        "Uni\ufb01edQA-T5-base"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AgentGen Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation": {
    "filename": "AgentGen Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation.pdf",
    "analysis": {
      "benchmarks": [
        "AgentBoard",
        "Blocksworld",
        "Gripper",
        "Tyreworld",
        "Barman",
        "Alfworld",
        "BabyAI",
        "Jericho"
      ],
      "models": [
        "AGENT GEN-tuned Llama-3.1-8B",
        "AGENT GEN-tuned Llama-3.1-70B",
        "GPT-3.5",
        "GPT-4",
        "CodeLlama",
        "Mistral",
        "Llama-2",
        "Llama-3.1",
        "AgentLM",
        "FireAct",
        "Agent-Flan",
        "AgentInstruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Are Long-LLMs A Necessity For Long-Context Tasks": {
    "filename": "Are Long-LLMs A Necessity For Long-Context Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "NarrativeQA",
        "Qasper",
        "MultiFieldQA",
        "HotpotQA",
        "2WikiMQA",
        "MuSiQue",
        "GovReport",
        "MultiNews",
        "SAMSum",
        "Passage Count",
        "Self-Constructed Dataset",
        "LCC"
      ],
      "models": [
        "LC-Boost",
        "GPT-4-128K",
        "GPT-3.5-turbo-16K",
        "Llama2-7B-Chat-4K",
        "Llama3-8B-Instruct-8K",
        "Vicuna-v1.5-7B-16K",
        "LongChat-v1.5-7B-32K",
        "Mistral-7B-Instruct-v0.2-32K",
        "Llama3-8B-80K",
        "Phi-3-mini-128K",
        "Yi-9B-200K",
        "DeepSeek-v2",
        "Claude-3-Haiku",
        "GPT-3.5-turbo-16K"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMs Understand Glass-Box Models Discover Surprises and Suggest Repairs": {
    "filename": "LLMs Understand Glass-Box Models Discover Surprises and Suggest Repairs.pdf",
    "analysis": {
      "benchmarks": [
        "pneumonia dataset"
      ],
      "models": [
        "Generalized Additive Models (GAMs)",
        "Explainable Boosting Machines (EBMs)",
        "GPT-4",
        "GPT-3.5"
      ]
    }
  },
  "Contrast with Reconstruct Contrastive 3D Representation Learning Guided by Generative Pretraining": {
    "filename": "Contrast with Reconstruct Contrastive 3D Representation Learning Guided by Generative Pretraining.pdf",
    "analysis": {
      "benchmarks": [
        "ScanObjectNN",
        "ModelNet40",
        "ModelNet10",
        "ShapeNet"
      ],
      "models": [
        "RECON",
        "RECON-CMC",
        "RECON-SMC",
        "RECON-Tiny",
        "RECON-Small",
        "Point-BERT",
        "Point-MAE",
        "Point-M2AE",
        "ACT",
        "PointNet",
        "PointNet++",
        "DGCNN",
        "PointCNN",
        "SimpleView",
        "MVTN",
        "PCT",
        "PointMLP",
        "PointNeXt",
        "P2P-HorNet",
        "Transformer",
        "CLIP2Point",
        "PointCLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HCQA  Ego4D EgoSchema Challenge 2024": {
    "filename": "HCQA  Ego4D EgoSchema Challenge 2024.pdf",
    "analysis": {
      "benchmarks": [
        "EgoSchema dataset"
      ],
      "models": [
        "HCQA",
        "LifelongMemory",
        "LaViLa",
        "GPT-4",
        "GPT-4o",
        "EgoVLP",
        "VideoRecap",
        "mPLUG-Owl",
        "LongViViT",
        "InternVideo2",
        "LLoVi",
        "VideoAgent",
        "ProViQ",
        "Gemini 1.5 Pro",
        "VeryLongVQA",
        "PaMsEgoAI",
        "GMMV"
      ]
    }
  },
  "Logical Reasoning over Natural Language as Knowledge Representation A Survey": {
    "filename": "Logical Reasoning over Natural Language as Knowledge Representation A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "D*",
        "ParaRules",
        "Birds-electricity",
        "Leap-of-thought",
        "PARARULE-Plus",
        "FOLIO",
        "D*(CWA)",
        "D*(OWA)",
        "EntailmentBank",
        "ENWN",
        "property-norm",
        "DEERLET",
        "DEER",
        "ARC",
        "OpenD5",
        "C-LBD",
        "TOMATO",
        "\u03b1NLI",
        "\u03b1NLG",
        "AbductionRules",
        "D*-Ab"
      ],
      "models": [
        "RoBERTa-large",
        "PRover",
        "multiPRover",
        "EntailmentWriter",
        "ProofWriter",
        "EVR",
        "IBR",
        "IRGR",
        "SI",
        "FaiRR",
        "MetGen",
        "SCSearch",
        "ADGV",
        "NLProofS",
        "Entailer",
        "Teachme",
        "CoLM",
        "T5-11B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Scaling Instruction-Finetuned Language Models": {
    "filename": "Scaling Instruction-Finetuned Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "BBH",
        "TyDiQA",
        "MGSM",
        "open-ended generation",
        "RealToxicityPrompts"
      ],
      "models": [
        "PaLM",
        "T5",
        "U-PaLM",
        "Flan-PaLM",
        "Flan-T5",
        "GPT-3",
        "Chinchilla",
        "code-davinci-002",
        "ByT5",
        "Flan-cont-PaLM",
        "Flan-U-PaLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Give me a hint Can LLMs take a hint to solve math problems": {
    "filename": "Give me a hint Can LLMs take a hint to solve math problems.pdf",
    "analysis": {
      "benchmarks": [
        "MATH"
      ],
      "models": [
        "base language models",
        "instruction fine-tuned models",
        "math-finetuned LLMs",
        "GPT-4o-mini",
        "Gemini Flash",
        "Gemma-2-2b-it",
        "Qwen2-Math-7B-Instruct",
        "Meta-Llama-3.1-8B-Instruct",
        "Meta-Llama-3.1-8B",
        "Mistral-7B-Instruct-v0.3",
        "Qwen2-7B-Instruct",
        "Qwen2-7B",
        "Mathstral-7B-v0.1",
        "Deepseek-math-7b-instruct",
        "Gemini-1.5-Flash"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Prompts in LLMs to Overcome Imbalances in Complex Educational Text Data": {
    "filename": "Leveraging Prompts in LLMs to Overcome Imbalances in Complex Educational Text Data.pdf",
    "analysis": {
      "benchmarks": [
        "StoryQ curriculum"
      ],
      "models": [
        "Support Vector Machine (SVM)",
        "Random Forest (RF)",
        "Decision Trees (DT)",
        "ADABoost",
        "Large Language Models (LLMs) with assertions",
        "GPT-4"
      ]
    }
  },
  "TabLLM Few-shot Classification of Tabular Data with Large Language Models": {
    "filename": "TabLLM Few-shot Classification of Tabular Data with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Bank",
        "Blood",
        "California",
        "Car",
        "Credit-g",
        "Income",
        "Jungle",
        "Diabetes",
        "Heart",
        "End of Life (EoL)",
        "Surgery",
        "Likelihood of Hospitalization (LoH)"
      ],
      "models": [
        "TabLLM",
        "T0",
        "T-Few",
        "GPT-3",
        "Logistic Regression (LR)",
        "XGBoost",
        "LightGBM",
        "TabNet",
        "SAINT",
        "NODE",
        "TabPFN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMs learn governing principles of dynamical systems revealing an in-context neural scaling law": {
    "filename": "LLMs learn governing principles of dynamical systems revealing an in-context neural scaling law.pdf",
    "analysis": {
      "benchmarks": [
        "discrete Markov chain",
        "stochastic logistic map",
        "Brownian motion",
        "geometric Brownian motion",
        "logistic map",
        "Lorenz system"
      ],
      "models": [
        "LLaMA-13b",
        "LLaMA-70b",
        "unigram model",
        "bi-gram model",
        "linear autoregressive model (AR1)",
        "non-linear autoregressive model (AR1)"
      ]
    }
  },
  "Tulip Agent - Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries": {
    "filename": "Tulip Agent - Enabling LLM-Based Agents to Solve Tasks Using Large Tool Libraries.pdf",
    "analysis": {
      "benchmarks": [
        "mathematics benchmark"
      ],
      "models": [
        "tulip agent",
        "CotTulipAgent",
        "AutoTulipAgent",
        "BaseAgent",
        "NaiveToolAgent",
        "CotToolAgent",
        "MinimalTulipAgent",
        "NaiveTulipAgent",
        "InformedCotTulipAgent",
        "PrimedCotTulipAgent",
        "OneShotCotTulipAgent"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Comparative Analysis of GPT-4 and Human Graders in Evaluating Human Tutors Giving Praise to Students": {
    "filename": "Comparative Analysis of GPT-4 and Human Graders in Evaluating Human Tutors Giving Praise to Students.pdf",
    "analysis": {
      "benchmarks": [
        "synthetic tutoring dialogues"
      ],
      "models": [
        "GPT-4",
        "zero-shot chain of thought",
        "few-shot chain of thought"
      ]
    }
  },
  "Steering Large Language Models between Code Execution and Textual Reasoning": {
    "filename": "Steering Large Language Models between Code Execution and Textual Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Blocksworld",
        "Game 24",
        "Logical Deduction",
        "Number Multiplying",
        "GSM-Hard",
        "MATH-Geometry",
        "MATH-Count&Probability",
        "Date Understanding",
        "Web of Lies",
        "Navigate",
        "BoxNet",
        "Path Plan",
        "Letters",
        "BoxLift"
      ],
      "models": [
        "O1-preview",
        "GPT-4o",
        "GPT-4o-mini",
        "GPT-3.5",
        "Claude-sonnet",
        "Mixtral-8x7b",
        "Code Interpreter",
        "AutoGen"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Teaching Smaller Language Models To Generalise To Unseen Compositional Questions": {
    "filename": "Teaching Smaller Language Models To Generalise To Unseen Compositional Questions.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA",
        "CommonsenseQA",
        "IIRC",
        "DROP",
        "Musique",
        "ARC-DA"
      ],
      "models": [
        "QA Model",
        "Base",
        "Base+RATD",
        "BART",
        "RoBERTa-base",
        "ELECTRA-large",
        "PaLM",
        "OPT",
        "T0++",
        "UnifiedQA v2",
        "GPT3",
        "InstructGPT",
        "UnifiedQA v1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ChatGPT for Arabic Grammatical Error Correction": {
    "filename": "ChatGPT for Arabic Grammatical Error Correction.pdf",
    "analysis": {
      "benchmarks": [
        "QALB 2014",
        "QALB 2015",
        "ARETA"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "AraBart",
        "AraT5",
        "mT0",
        "mT5",
        "LLaMA-7B",
        "Vicuna-13B",
        "Bactrian-X bloom-7B",
        "Bactrian-X llama-7B",
        "ARBERT v2",
        "MARBERT v2",
        "GECToR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Demystifying the DAO Governance Process": {
    "filename": "Demystifying the DAO Governance Process.pdf",
    "analysis": {
      "benchmarks": [
        "16,427 DAOs dataset",
        "183 documentation",
        "122,307 proposals"
      ],
      "models": [
        "Large Language Model (LLM) with Chain of Thought (CoT)",
        "Natural Language Processing (NLP)",
        "BERT",
        "Sentence-BERT",
        "ChatGPT",
        "Claude"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoEval-Video An Automatic Benchmark for Assessing Large Vision Language Models in Open-Ended Video Question Answering": {
    "filename": "AutoEval-Video An Automatic Benchmark for Assessing Large Vision Language Models in Open-Ended Video Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "AutoEval-Video"
      ],
      "models": [
        "GPT-4V(ision)",
        "Gemini-Ultra-Vision",
        "LLaVA-1.5",
        "Qwen-VL",
        "InstructBLIP",
        "BLIP-2",
        "Video-ChatGPT",
        "VideoChat",
        "VideoChat2",
        "Video-LLaMA",
        "LLaMA-VID"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Autonomous GIS the next-generation AI-powered GIS": {
    "filename": "Autonomous GIS the next-generation AI-powered GIS.pdf",
    "analysis": {
      "benchmarks": [
        "NC hazardous waste facility ESRI shape file",
        "NC tract boundary shapefile",
        "NC tract population CSV file",
        "France administrative regions shapefile",
        "COVID-19 data case in 2020 (county-level)",
        "Contiguous US county boundary shapefile",
        "Census data (ACS2020)"
      ],
      "models": [
        "LLM-Geo",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Diffusion Self-Distillation for Zero-Shot Customized Image Generation": {
    "filename": "Diffusion Self-Distillation for Zero-Shot Customized Image Generation.pdf",
    "analysis": {
      "benchmarks": [
        "DreamBench++"
      ],
      "models": [
        "Diffusion Self-Distillation",
        "ControlNet",
        "DreamBooth",
        "LoRA",
        "IP-Adapter",
        "InstantID",
        "BLIP-Diffusion",
        "Emu2",
        "IP-Adapter+",
        "Textual Inversion",
        "DreamBooth-LoRA"
      ]
    }
  },
  "Memory Sharing for Large Language Model based Agents": {
    "filename": "Memory Sharing for Large Language Model based Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Memory Sharing (MS) framework",
        "LLM-based agents",
        "Retriever",
        "LLM evaluator",
        "autonomous learning retriever",
        "gpt-3.5-turbo",
        "gpt-4o",
        "open-mistral-7b",
        "BERTScore"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BLUEX A benchmark based on Brazilian Leading Universities Entrance eXams": {
    "filename": "BLUEX A benchmark based on Brazilian Leading Universities Entrance eXams.pdf",
    "analysis": {
      "benchmarks": [
        "BLUEX",
        "ENEM-challenge",
        "ENEM 2022"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5-Turbo",
        "Sabi\u00e1 65B",
        "Sabi\u00e1 7B",
        "LLaMA 65B",
        "LLaMA 7B",
        "OPT 66B",
        "OPT 6.7B",
        "Alpaca 7B",
        "BloomZ 7B",
        "Bloom 7B",
        "Bertin 6B",
        "XGLM 7.5B",
        "GPT-J 6B"
      ]
    }
  },
  "Where Would I Go Next Large Language Models as Human Mobility Predictors": {
    "filename": "Where Would I Go Next Large Language Models as Human Mobility Predictors.pdf",
    "analysis": {
      "benchmarks": [
        "Geolife",
        "Foursquare New York City (FSQ-NYC)"
      ],
      "models": [
        "LLM-Mob",
        "1-MMC",
        "LSTM",
        "LSTM-Attn",
        "DeepMove",
        "MobTcast",
        "MHSA"
      ]
    }
  },
  "Evaluating Uncertainty-based Failure Detection for Closed-Loop LLM Planners": {
    "filename": "Evaluating Uncertainty-based Failure Detection for Closed-Loop LLM Planners.pdf",
    "analysis": {
      "benchmarks": [
        "self-collected dataset"
      ],
      "models": [
        "KnowLoop",
        "LLaVA",
        "ChatGPT-4V",
        "ChatGPT-4",
        "Voxposer"
      ]
    }
  },
  "Demystifying Large Language Models for Medicine A Primer": {
    "filename": "Demystifying Large Language Models for Medicine A Primer.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA-USMLE",
        "PubMedQA",
        "MedMCQA"
      ],
      "models": [
        "GPT-4",
        "Claude 3",
        "Gemini 1.5",
        "Llama 3",
        "PMC-LlaMA",
        "MEDITRON",
        "Med-PaLM 2",
        "Mixtral",
        "Mistral",
        "Llama 2",
        "FLAN-T5",
        "FLAN-UL2",
        "Alpaca",
        "Med-Alpaca",
        "Vicuna",
        "PaLM",
        "Flan-PaLM",
        "ClinicalBERT",
        "BiomedGPT",
        "Med-PaLM"
      ]
    }
  },
  "The student becomes the master Outperforming GPT3 on Scientific Factual Error Correction": {
    "filename": "The student becomes the master Outperforming GPT3 on Scientific Factual Error Correction.pdf",
    "analysis": {
      "benchmarks": [
        "SciFact",
        "SciFact-Open",
        "CovidFact"
      ],
      "models": [
        "SciFix",
        "GPT3.5 Few-Shot Prompting",
        "ZeroFEC",
        "VENCE",
        "GPT3.5 Zero-Shot Prompting",
        "SciFix Bio",
        "SciFix All"
      ]
    }
  },
  "CREATOR Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models": {
    "filename": "CREATOR Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "TabMWP",
        "Creation Challenge"
      ],
      "models": [
        "CREATOR",
        "ChatGPT",
        "chain-of-thought (CoT)",
        "program-of-thought (PoT)",
        "tool-using baselines"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Marconi Prefix Caching for the Era of Hybrid LLMs": {
    "filename": "Marconi Prefix Caching for the Era of Hybrid LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "LMSys",
        "ShareGPT",
        "SWEBench"
      ],
      "models": [
        "Marconi",
        "vLLM+",
        "SGLang+",
        "Hybrid model",
        "Jamba-1.5-Mini",
        "Transformers",
        "Mamba",
        "SSM",
        "Attention-SSM Hybrid model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cross-Modal Learning for Chemistry Property Prediction Large Language Models Meet Graph Machine Learning": {
    "filename": "Cross-Modal Learning for Chemistry Property Prediction Large Language Models Meet Graph Machine Learning.pdf",
    "analysis": {
      "benchmarks": [
        "QM8",
        "QM9",
        "ESOL",
        "FreeSolv",
        "Lipophilicity",
        "PDBbind",
        "BBBP",
        "HIV",
        "BACE",
        "Tox21",
        "ClinTox"
      ],
      "models": [
        "MMF W/GPT-4",
        "MMF W/GPT-3.5-turbo",
        "MMF W/GPT-3.0-text-davinci-003",
        "MMF W/Google Bard",
        "GCN-FP",
        "GGNN",
        "DCNN",
        "ChebyNet",
        "GCN",
        "MPNN",
        "GraphSAGE",
        "GPNN",
        "GAT",
        "LanczosNet",
        "AdaLanczosNet",
        "SchNet",
        "PhysNet",
        "PPGN",
        "MEGNet-simple",
        "Cormorant",
        "DimeNet",
        "SELFormer",
        "D-MPNN",
        "MolCLR",
        "Hu et al.",
        "MGCN",
        "GEM",
        "KPGT",
        "GraphMVP-C",
        "GIN",
        "ChemBERTa-2",
        "MolBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mining the Explainability and Generalization Fact Verification Based on Self-Instruction": {
    "filename": "Mining the Explainability and Generalization Fact Verification Based on Self-Instruction.pdf",
    "analysis": {
      "benchmarks": [
        "FEVEROUS",
        "HOVER"
      ],
      "models": [
        "Llama-7b",
        "Bert-FC",
        "T5",
        "RoBERTa-NLI",
        "DeBERTa-NLI",
        "FLAN-T5",
        "ChatGPT-3.5",
        "ProgramFC"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Potential Benefits of Employing Large Language Models in Research in Moral Education and Development": {
    "filename": "Potential Benefits of Employing Large Language Models in Research in Moral Education and Development.pdf",
    "analysis": {
      "benchmarks": [
        "Behavioral Defining Issue Test (bDIT)"
      ],
      "models": [
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Internalizing ASR with Implicit Chain of Thought for Efficient Speech-to-Speech Conversational LLM": {
    "filename": "Internalizing ASR with Implicit Chain of Thought for Efficient Speech-to-Speech Conversational LLM.pdf",
    "analysis": {
      "benchmarks": [
        "SODA"
      ],
      "models": [
        "AnyGPT",
        "A-T-T-A Finetuned",
        "A-T-A No ASR ICoT",
        "A-A ICoT",
        "A-T-T-A No Finetuning",
        "A-A No Finetuning",
        "A-T-A ASR ICoT"
      ]
    }
  },
  "Understanding Users Dissatisfaction with ChatGPT Responses Types Resolving Tactics and the Effect of Knowledge Level": {
    "filename": "Understanding Users Dissatisfaction with ChatGPT Responses Types Resolving Tactics and the Effect of Knowledge Level.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "General Purpose Artificial Intelligence Systems GPAIS Properties Definition Taxonomy Open Challenges and Implications": {
    "filename": "General Purpose Artificial Intelligence Systems GPAIS Properties Definition Taxonomy Open Challenges and Implications.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "GPT-4",
        "LLAMA 1",
        "Vicuna",
        "LLAMA 2",
        "Google AI Bard",
        "Github CoPilot",
        "DALL-E",
        "Stable Diffusion",
        "Midjourney",
        "BERT",
        "Gato",
        "Meta-transformer",
        "AutoML-zero",
        "POET",
        "Falcon LLM",
        "Dolly",
        "AutoGPT",
        "HuggingGTP",
        "MetaGPT",
        "GTP-Engineer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Language Model Hallucinations Can Snowball": {
    "filename": "How Language Model Hallucinations Can Snowball.pdf",
    "analysis": {
      "benchmarks": [
        "Primality Testing",
        "Senator Search",
        "Graph Connectivity"
      ],
      "models": [
        "ChatGPT",
        "GPT-4"
      ]
    }
  },
  "Navigation with Large Language Models Semantic Guesswork as a Heuristic for Planning": {
    "filename": "Navigation with Large Language Models Semantic Guesswork as a Heuristic for Planning.pdf",
    "analysis": {
      "benchmarks": [
        "Habitat ObjectNav Challenge",
        "HM3D"
      ],
      "models": [
        "Language Frontier Guide (LFG)",
        "Greedy LLM",
        "L3MVN",
        "LGX",
        "DD-PPO",
        "FBE",
        "SemExp",
        "OVRL-v2"
      ]
    }
  },
  "FIND A Function Description Benchmark for Evaluating Interpretability Methods": {
    "filename": "FIND A Function Description Benchmark for Evaluating Interpretability Methods.pdf",
    "analysis": {
      "benchmarks": [
        "FIND"
      ],
      "models": [
        "Automated Interpretability Agent (AIA)",
        "pretrained language models (LMs)",
        "GPT-4",
        "GPT-3.5",
        "Llama-2-13b-chat",
        "Llama-2-70b-chat",
        "Vicuna-13B",
        "vicuna-evaluator"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Efficient Prompting for LLM-Based Generative Internet of Things": {
    "filename": "Efficient Prompting for LLM-Based Generative Internet of Things.pdf",
    "analysis": {
      "benchmarks": [
        "WikiTableQA",
        "TabFact"
      ],
      "models": [
        "Mixtral-8x7B",
        "Llama-3-70B",
        "Proposed LLM-based GIoT system"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Synergistic Interplay of Large Language Model and Digital Twin for Autonomous Optical Networks Field Demonstrations": {
    "filename": "Synergistic Interplay of Large Language Model and Digital Twin for Autonomous Optical Networks Field Demonstrations.pdf",
    "analysis": {
      "benchmarks": [
        "experimental C+L-band long-haul transmission link",
        "field-deployed six-node mesh network",
        "field-deployed C+L-band transmission link"
      ],
      "models": [
        "Generative Pre-trained Transformer-4 (GPT-4)",
        "DeepONet"
      ]
    }
  },
  "GNN-RAG Graph Neural Retrieval for Large Language Model Reasoning": {
    "filename": "GNN-RAG Graph Neural Retrieval for Large Language Model Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "WebQSP",
        "CWQ"
      ],
      "models": [
        "GNN-RAG",
        "GPT-4",
        "GraftNet",
        "NSM",
        "ReaRev",
        "RoG",
        "ToG",
        "LLaMA2-Chat-7B",
        "ChatGPT",
        "Alpaca-7B",
        "Flan-T5-xl",
        "StructGPT",
        "KB-BINDER",
        "KD-CoT",
        "G-Retriever",
        "UniKGQA",
        "SQALER",
        "PullNet",
        "EmbedKGQA",
        "TransferNet",
        "Rigel",
        "KV-Mem"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Image Segmentation in Foundation Model Era A Survey": {
    "filename": "Image Segmentation in Foundation Model Era A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "COCO-Stuff",
        "COCO",
        "ADE20K",
        "PASCAL VOC"
      ],
      "models": [
        "N-Cut",
        "FCN",
        "MaskFormer",
        "CLIP",
        "Stable Diffusion",
        "DINO",
        "SAM",
        "SAM2",
        "DeepLab",
        "R-CNN",
        "SegGPT",
        "SEEM",
        "MaskCLIP",
        "SCLIP",
        "CLIPSurgery",
        "NACLIP",
        "GEM",
        "FreeSeg-Diff",
        "OVAM",
        "OVDiff",
        "DiffSeg",
        "FreeDA",
        "VPD",
        "TADP",
        "Vermouth",
        "MetaPrompt",
        "Peekaboo",
        "ZeroSeg",
        "CLIP-ZSS",
        "CLIP-DINOiser",
        "DenseCLIP",
        "PPL",
        "CATSeg",
        "OTSeg",
        "ZegCLIP",
        "LDVC",
        "ZegOT",
        "SemiVL",
        "SAN",
        "LSeg",
        "Fusioner",
        "PACL",
        "CLIPpy",
        "SAZS",
        "GroupViT",
        "SegCLIP",
        "SGP",
        "TagAlign",
        "MaskDistill",
        "ODISE",
        "Pix2Seq-D",
        "DFormer",
        "LDMSeg",
        "U2Seg",
        "Semantic-SAM",
        "SEEM",
        "HQ-SAM",
        "OVSAM",
        "GraCo",
        "MedSAM",
        "SAMed",
        "SAMFE",
        "SAM-Med2D",
        "MedSA",
        "3DSAM-Adapter",
        "ZS-RS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploring the Privacy Protection Capabilities of Chinese Large Language Models": {
    "filename": "Exploring the Privacy Protection Capabilities of Chinese Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGLM2-6B",
        "Baichuan2-7B",
        "Qwen-7B",
        "InternLM-7B"
      ]
    }
  },
  "Gesture-Informed Robot Assistance via Foundation Models": {
    "filename": "Gesture-Informed Robot Assistance via Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "GestureInstruct"
      ],
      "models": [
        "GIRAF",
        "CaP",
        "MediaPipe",
        "OpenCLIP",
        "GPT-3.5",
        "InstructBLIP",
        "PaLI"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A decoder-only foundation model for time-series forecasting": {
    "filename": "A decoder-only foundation model for time-series forecasting.pdf",
    "analysis": {
      "benchmarks": [
        "Monash",
        "Darts",
        "Informer",
        "ETTm1",
        "ETTm2",
        "ETTh1",
        "ETTh2"
      ],
      "models": [
        "TimesFM",
        "llmtime",
        "N-BEATS",
        "DeepAR",
        "PatchTST",
        "FEDFormer",
        "Autoformer",
        "DLinear",
        "TimeNet",
        "GPT4TS"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Harnessing Task Overload for Scalable Jailbreak Attacks on Large Language Models": {
    "filename": "Harnessing Task Overload for Scalable Jailbreak Attacks on Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "AdvBench",
        "JBBbehaviors"
      ],
      "models": [
        "Llama3-8B",
        "Mistral-7B",
        "Llama2-7B",
        "Vicuna-7B",
        "Qwen2.5-3B",
        "Qwen2.5-7B",
        "Qwen2.5-14B",
        "Qwen2.5-32B",
        "Qwen2.5-72B",
        "Past Tense",
        "GCG",
        "PAIR",
        "JBC",
        "Ours"
      ]
    }
  },
  "Empirical Study of Zero-Shot NER with ChatGPT": {
    "filename": "Empirical Study of Zero-Shot NER with ChatGPT.pdf",
    "analysis": {
      "benchmarks": [
        "PowerPlantFlat",
        "PowerPlantNested",
        "OntoNotes 4",
        "MSRA",
        "Weibo NER",
        "ACE05",
        "ACE04",
        "BC5CDR"
      ],
      "models": [
        "ChatGPT",
        "GPT-3.5",
        "GPT-4",
        "GPT-3",
        "Llama2",
        "Decomposed-QA",
        "Syntactic Prompting",
        "Tool Augmentation",
        "Self-Consistency with Two-Stage Majority Voting",
        "Standard CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PREFER Prompt Ensemble Learning via Feedback-Reflect-Refine": {
    "filename": "PREFER Prompt Ensemble Learning via Feedback-Reflect-Refine.pdf",
    "analysis": {
      "benchmarks": [
        "SNLI",
        "MNLI",
        "RTE",
        "QNLI",
        "Ethos",
        "Liar",
        "ArSarcasm"
      ],
      "models": [
        "PREFER",
        "PromptBoosting",
        "APO",
        "Single Prompt",
        "Single Prompt (CoT)",
        "Synonym Ensemble"
      ]
    }
  },
  "An Interactive Framework for Profiling News Media Sources": {
    "filename": "An Interactive Framework for Profiling News Media Sources.pdf",
    "analysis": {
      "benchmarks": [
        "Media Bias/Fact Check",
        "Baly et al.",
        "Black Lives Matter",
        "Abortion/Feminism"
      ],
      "models": [
        "Mehta R-GCN",
        "Mehta BEST",
        "Graph Only",
        "LLM Only",
        "LLM + Humans"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Large Language Models for Enhanced Process Model Comprehension": {
    "filename": "Leveraging Large Language Models for Enhanced Process Model Comprehension.pdf",
    "analysis": {
      "benchmarks": [
        "Healthcare Process",
        "Dispatch of Goods",
        "Order Manufacturing"
      ],
      "models": [
        "GPT-4o-2024-05-13",
        "GPT-4-Turbo-2024-04-09",
        "Microsoft WizardLM-2-8x22B",
        "Mixtral-8x22B-Instruct v0.1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AssistGPT A General Multi-modal Assistant that can Plan Execute Inspect and Learn": {
    "filename": "AssistGPT A General Multi-modal Assistant that can Plan Execute Inspect and Learn.pdf",
    "analysis": {
      "benchmarks": [
        "A-OKVQA",
        "NExT-QA"
      ],
      "models": [
        "AssistGPT",
        "LXMERT",
        "KRISP",
        "GPV-2",
        "InstructBLIP Vicuna-7B",
        "PromptCap",
        "BLIP2 FlanT5 XL",
        "HGA",
        "VQA-T",
        "ATP",
        "VGT",
        "MIST",
        "ViperGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OCALM Object-Centric Assessment with Language Models": {
    "filename": "OCALM Object-Centric Assessment with Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Atari Learning Environment (ALE)"
      ],
      "models": [
        "OCALM",
        "OCALM (no relations)",
        "Proximal Policy Optimization (PPO)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TI-PREGO Chain of Thought and In-Context Learning for Online Mistake Detection in PRocedural EGOcentric Videos": {
    "filename": "TI-PREGO Chain of Thought and In-Context Learning for Online Mistake Detection in PRocedural EGOcentric Videos.pdf",
    "analysis": {
      "benchmarks": [
        "Assembly101-O",
        "Epic-tent-O"
      ],
      "models": [
        "TI-PREGO",
        "PREGO",
        "MiniROAD",
        "OadTR",
        "BERT",
        "TGML-DO",
        "One-step memory",
        "Random Anticipation",
        "Best-Case Scenario",
        "Worst-Case Scenario"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VLLaVO Mitigating Visual Gap through LLMs": {
    "filename": "VLLaVO Mitigating Visual Gap through LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "PACS",
        "OfficeHome",
        "DomainNet"
      ],
      "models": [
        "VLLaVO",
        "CLIP",
        "BLIP",
        "MIRO",
        "BCAT",
        "SWAD",
        "SAGM",
        "ERM-ResNet",
        "ERM-CLIP",
        "DPL",
        "CLIPood",
        "ZS-CLIP",
        "ZS-LLM",
        "DANN",
        "AFN",
        "CDAN",
        "SDAT",
        "MCC",
        "ELS",
        "CDTrans",
        "PMTrans",
        "PADCLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SUBLLM A Novel Efficient Architecture with Token Sequence Subsampling for LLM": {
    "filename": "SUBLLM A Novel Efficient Architecture with Token Sequence Subsampling for LLM.pdf",
    "analysis": {
      "benchmarks": [
        "SST2",
        "Amazon",
        "DBpedia",
        "AGNews",
        "Yelp",
        "Hate",
        "MMLU",
        "BBH",
        "AGIEval"
      ],
      "models": [
        "SUBLLM",
        "LLaMA",
        "Funnel-Transformer",
        "Fourier-Transformer",
        "CoLT5",
        "MoD",
        "RWKV",
        "RecurrentGemma",
        "Mamba",
        "MEGALODON"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CohortGPT An Enhanced GPT for Participant Recruitment in Clinical Study": {
    "filename": "CohortGPT An Enhanced GPT for Participant Recruitment in Clinical Study.pdf",
    "analysis": {
      "benchmarks": [
        "IU-RR",
        "MIMIC-CXR"
      ],
      "models": [
        "CohortGPT",
        "ChatGPT",
        "GPT-4",
        "BioBERT",
        "BioGPT",
        "Alpaca",
        "BloomZ"
      ]
    }
  },
  "Well Begun is Half Done Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue": {
    "filename": "Well Begun is Half Done Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue.pdf",
    "analysis": {
      "benchmarks": [
        "Wizard of Wikipedia (WoW)",
        "OpenDialKG"
      ],
      "models": [
        "GATE",
        "BART",
        "T5",
        "ChatGPT",
        "Random",
        "Semantic",
        "TMNet",
        "SKT++",
        "MIKE",
        "KnowledGPT",
        "KINET",
        "DiffKG",
        "NPH",
        "DialKG",
        "AttnIO"
      ]
    }
  },
  "Leveraging Professional Radiologists Expertise to Enhance LLMs Evaluation for Radiology Reports": {
    "filename": "Leveraging Professional Radiologists Expertise to Enhance LLMs Evaluation for Radiology Reports.pdf",
    "analysis": {
      "benchmarks": [
        "MIMIC-CXR"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "LongiFill",
        "Transformer",
        "Regressed GPT-4",
        "Detailed GPT-4 (5-shot)",
        "Detailed GPT-3.5 (5-shot)"
      ]
    }
  },
  "Towards Evaluating AI Systems for Moral Status Using Self-Reports": {
    "filename": "Towards Evaluating AI Systems for Moral Status Using Self-Reports.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "large language models (LLMs)",
        "GPT-4",
        "Lin et al. (2022) model",
        "Kadavath et al. (2022) model",
        "ChatGPT",
        "PALM 2 LLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SocREval Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation": {
    "filename": "SocREval Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "DROP",
        "e-SNLI",
        "Cosmos QA"
      ],
      "models": [
        "GPT-4",
        "ROSCOE",
        "ReCEval",
        "SOCREVAL",
        "SOCREVAL (Definition)",
        "SOCREVAL (Maieutics)",
        "SOCREVAL (Dialectic)",
        "SOCREVAL (All)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Subversive Characters and Stereotyping Readers Characterizing Queer Relationalities with Dialogue-Based Relation Extraction": {
    "filename": "Subversive Characters and Stereotyping Readers Characterizing Queer Relationalities with Dialogue-Based Relation Extraction.pdf",
    "analysis": {
      "benchmarks": [
        "Big Bang Theory",
        "Frasier",
        "Gilmore Girls",
        "Sang et al. dataset"
      ],
      "models": [
        "majority class baseline",
        "Longformer",
        "Longformer with anonymized training set",
        "Longformer with scene attentive pooling",
        "Longformer with both anonymized training set and scene attentive pooling",
        "LLaMA 3\u201370b",
        "LLaMA 3\u201370b one-shot",
        "OpenAI o1-mini"
      ]
    }
  },
  "Auto-Demo Prompting Leveraging Generated Outputs as Demonstrations for Enhanced Batch Prompting": {
    "filename": "Auto-Demo Prompting Leveraging Generated Outputs as Demonstrations for Enhanced Batch Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "BoolQ",
        "RTE",
        "GSM8K",
        "QQP",
        "SVAMP"
      ],
      "models": [
        "GPT-4o",
        "GPT-4o-mini"
      ]
    }
  },
  "MHRC Closed-loop Decentralized Multi-Heterogeneous Robot Collaboration with Large Language Models": {
    "filename": "MHRC Closed-loop Decentralized Multi-Heterogeneous Robot Collaboration with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "PyBullet",
        "BestMan"
      ],
      "models": [
        "MHRC",
        "GPT-3.5-turbo",
        "Llama-3.1-8B",
        "GPT-4o"
      ]
    }
  },
  "From Beginner to Expert Modeling Medical Knowledge into General LLMs": {
    "filename": "From Beginner to Expert Modeling Medical Knowledge into General LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "PubMedQA",
        "MedQA",
        "MedMCQA",
        "MMLU clinical topics"
      ],
      "models": [
        "AntGLM-10B",
        "AntGLM-Med-10B",
        "GPT-3.5",
        "GPT-4",
        "ChatGPT",
        "Med-PaLM 2",
        "PaLM 2",
        "HuatuoGPT",
        "Visual Med-Alpaca",
        "Galactica",
        "GatorTronGPT",
        "Flan-PaLM-3-shot",
        "Codex-5-shot",
        "Palmyra-Med"
      ]
    }
  },
  "In-context Example Selection with Influences": {
    "filename": "In-context Example Selection with Influences.pdf",
    "analysis": {
      "benchmarks": [
        "SuperGLUE",
        "PIQA",
        "BoolQ",
        "RTE",
        "WIC",
        "WSC",
        "ARC (Challenge)",
        "ARC (Easy)",
        "Hellaswag",
        "OpenBookQA"
      ],
      "models": [
        "GPT-3",
        "GPT-J",
        "OPT-6.7B",
        "LLaMA-7B",
        "LLaMA-13B",
        "GPT-NeoX",
        "OPT-13B",
        "OPT-30B",
        "Influence-based Example Selection",
        "IC Datamodels"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Continual Learning Paradigm for Non-differentiable Visual Programming Frameworks on Visual Reasoning Tasks": {
    "filename": "A Continual Learning Paradigm for Non-differentiable Visual Programming Frameworks on Visual Reasoning Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "GQA",
        "NLVRv2",
        "Visual Grounding (VG)",
        "RefCOCO",
        "RefCOCO+"
      ],
      "models": [
        "VisProg",
        "CLVP",
        "CFR",
        "Beit3",
        "BLIP",
        "VisProg CFR",
        "VisProg Beit3-NLVRv2",
        "CLVP Gw/o SSD",
        "CLVP G",
        "CLVP GNw/o SSD",
        "CLVP GN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Visual Chain-of-Thought Diffusion Models": {
    "filename": "Visual Chain-of-Thought Diffusion Models.pdf",
    "analysis": {
      "benchmarks": [
        "AFHQ",
        "FFHQ",
        "ImageNet"
      ],
      "models": [
        "Visual Chain-of-Thought Diffusion Model (VCDM)",
        "EDM",
        "VCDM with oracle",
        "Class-cond"
      ]
    }
  },
  "Trace is the Next AutoDiff Generative Optimization with Rich Feedback Execution Traces and LLMs": {
    "filename": "Trace is the Next AutoDiff Generative Optimization with Rich Feedback Execution Traces and LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "BigBenchHard",
        "MMLU-Machine Learning",
        "MMLU-College Physics",
        "Google-proof QA",
        "BBH Counting",
        "BBH Word Sorting",
        "GSM8K"
      ],
      "models": [
        "OptoPrime",
        "OPRO",
        "Trace",
        "Trace NoMem",
        "Trace Masked",
        "SCATS",
        "GP",
        "PSO",
        "Adam",
        "TextGrad"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Diagnosing Infeasible Optimization Problems Using Large Language Models": {
    "filename": "Diagnosing Infeasible Optimization Problems Using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GAMS Model Library",
        "Pyomo Cookbook by the University of Notre Dame",
        "Resource Task Network model"
      ],
      "models": [
        "OptiChat",
        "GPT-4",
        "ANALYZE",
        "Gurobi"
      ]
    }
  },
  "DARG Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph": {
    "filename": "DARG Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "BBQ",
        "BBH Navigate",
        "BBH Dyck Language"
      ],
      "models": [
        "DARG",
        "GPT-4 Turbo",
        "Gemini-1.5-Pro",
        "Gemini-1.5-Flash",
        "Claude-3-Opus",
        "phi3-mini",
        "Mistral-7B",
        "Llama-3-8B",
        "Llama-3-70B",
        "Command R+",
        "Mixtral-8\u00d77B",
        "Mixtral-8\u00d722B",
        "WizardLM-2-8\u00d722B",
        "DeepSeekMath-7B",
        "GPT-4-o",
        "GPT-3.5 Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CREF An LLM-based Conversational Software Repair Framework for Programming Tutors": {
    "filename": "CREF An LLM-based Conversational Software Repair Framework for Programming Tutors.pdf",
    "analysis": {
      "benchmarks": [
        "TutorCode",
        "Defects4J",
        "QuixBugs"
      ],
      "models": [
        "Cref",
        "GPT-4",
        "GPT-3.5",
        "Claude",
        "Bard",
        "CodeLlama",
        "StarChat",
        "Vicuna-13B",
        "CodeGen-multi-16B",
        "CodeGen-multi-6B",
        "CodeT5p",
        "Incoder",
        "replit-code-v1",
        "DrRepair",
        "ChatRepair",
        "KNOD",
        "Rete",
        "TENURE"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Graph Reasoning for Question Answering with Triplet Retrieval": {
    "filename": "Graph Reasoning for Question Answering with Triplet Retrieval.pdf",
    "analysis": {
      "benchmarks": [
        "CommonsenseQA",
        "OpenbookQA"
      ],
      "models": [
        "RoBERTa-large",
        "RGCN",
        "GconAttn",
        "KagNet",
        "RN",
        "MHGRN",
        "QA-GNN",
        "GreaseLM",
        "SAFE",
        "GSC",
        "Ours"
      ]
    }
  },
  "InfiAgent-DABench Evaluating Agents on Data Analysis Tasks": {
    "filename": "InfiAgent-DABench Evaluating Agents on Data Analysis Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "InfiAgent-DABench",
        "DAEval",
        "HumanEval",
        "MBPP",
        "DS-1000"
      ],
      "models": [
        "DAAgent",
        "GPT-3.5",
        "GPT-4",
        "AutoGPT",
        "BabyAGI",
        "AgentGPT",
        "OpenAI ADA",
        "Open Interpreter",
        "Open Agents",
        "Qwen-Agent",
        "Taskweaver",
        "Vicuna",
        "ChatGLM",
        "Baichuan",
        "Qwen",
        "InternLM",
        "AgentLM",
        "Mistral",
        "Yi",
        "Code Llama",
        "WizardCoder",
        "Phind CodeLlama",
        "DeepSeek Coder",
        "XwinCoder",
        "XAgent",
        "AutoGen",
        "DAAgent-34B",
        "DAAgent-13B",
        "DAAgent-7B",
        "Claude-2.1",
        "Abab5.5",
        "Gemini-Pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "More Agents Is All You Need": {
    "filename": "More Agents Is All You Need.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "MMLU",
        "Chess",
        "HumanEval"
      ],
      "models": [
        "Agent Forest",
        "Llama2-13B",
        "Llama2-70B",
        "GPT-3.5-Turbo",
        "GPT-4",
        "CoT-SC",
        "LLM-Debate",
        "Blended",
        "Zero-Shot CoT",
        "Solo Performance Prompting (SPP)",
        "Reflection",
        "Step-wise Agent Forest",
        "Hierarchical Agent Forest"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B": {
    "filename": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "GSM Hard",
        "MATH",
        "AIME",
        "Math Odyssey",
        "OlympiadBench"
      ],
      "models": [
        "MCT Self-Refine (MCTSr)",
        "LLaMA3-8B",
        "Zero-Shot CoT",
        "Self-Refine",
        "4-rollouts MCTSr",
        "8-rollouts MCTSr",
        "GPT-4",
        "Claude 3",
        "Gemini 1.5-Pro"
      ]
    }
  },
  "Probabilistic medical predictions of large language models": {
    "filename": "Probabilistic medical predictions of large language models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU-CK",
        "MMLU-CM",
        "USMLE",
        "MCMLE",
        "MGB-SDoH"
      ],
      "models": [
        "gemma-2-27b-it",
        "Mistral-Large-Instruct-2407",
        "Yi-1.5-34B-Chat",
        "Phi-3-medium-128k-instruct",
        "Qwen2-72B-Instruct",
        "Meta-Llama-3.1-70B-Instruct",
        "Qwen2-7B-Instruct",
        "Meta-Llama-3.1-8B-Instruct",
        "gemma-2-9b-it",
        "Mistral-7B-Instruct-v0.3",
        "Yi-1.5-9B-Chat",
        "Phi-3-mini-128k-instruct"
      ]
    }
  },
  "Composite Learning Units Generalized Learning Beyond Parameter Updates to Transform LLMs into Adaptive Reasoners": {
    "filename": "Composite Learning Units Generalized Learning Beyond Parameter Updates to Transform LLMs into Adaptive Reasoners.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Composite Learning Units (CLUs)",
        "GPT-4o-mini",
        "Chain-of-Thought (CoT)",
        "Input-Output (IO)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "fPLSA Learning Semantic Structures in Document Collections Using Foundation Models": {
    "filename": "fPLSA Learning Semantic Structures in Document Collections Using Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "WritingPrompts",
        "MATH",
        "Big-Bench Hard (BBH)"
      ],
      "models": [
        "fPLSA",
        "TradLDA",
        "TradLDA+LLM",
        "Prompting",
        "GenOutline"
      ]
    }
  },
  "MOKA Open-World Robotic Manipulation through Mark-Based Visual Prompting": {
    "filename": "MOKA Open-World Robotic Manipulation through Mark-Based Visual Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "Table Wiping",
        "Watch Cleaning",
        "Gift Preparation",
        "Laptop Packing"
      ],
      "models": [
        "MOKA",
        "Code-as-Policies",
        "VoxPoser",
        "MOKA Zero-Shot",
        "MOKA In-Context",
        "MOKA Distilled"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Sub-SA Strengthen In-context Learning via Submodular Selective Annotation": {
    "filename": "Sub-SA Strengthen In-context Learning via Submodular Selective Annotation.pdf",
    "analysis": {
      "benchmarks": [
        "MRPC",
        "MNLI",
        "SST-2",
        "RTE",
        "SST-5",
        "HellaSwag",
        "MWoZ",
        "GeoQuery"
      ],
      "models": [
        "Sub-SA",
        "Vote-k",
        "IDEAL",
        "GPT-J",
        "GPT-3.5-Turbo",
        "GPT-Neo"
      ]
    }
  },
  "Are Large Language Models Good at Utility Judgments": {
    "filename": "Are Large Language Models Good at Utility Judgments.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Questions (NQ)",
        "HotpotQA",
        "MSMARCO-QA"
      ],
      "models": [
        "ChatGPT",
        "Llama2-7B-chat",
        "Llama2-13B-chat",
        "Vicuna-7B",
        "Vicuna-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "UPRISE Universal Prompt Retrieval for Improving Zero-Shot Evaluation": {
    "filename": "UPRISE Universal Prompt Retrieval for Improving Zero-Shot Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "SQuADv1",
        "BoolQ",
        "MultiRC",
        "OBQA",
        "ARC-e",
        "ARC-c",
        "NQ",
        "MRPC",
        "QQP",
        "PAWS",
        "MNLI-m",
        "MNLI-mm",
        "QNLI",
        "SNLI",
        "RTE",
        "SST-2",
        "Yelp",
        "Sent140",
        "PiQA",
        "COPA",
        "HellaSwag",
        "WSC273",
        "DPR",
        "Winogrande",
        "TruthfulQA",
        "FEVER2.0",
        "Covid-19"
      ],
      "models": [
        "UPRISE",
        "GPT-Neo-2.7B",
        "BLOOM-7.1B",
        "OPT-66B",
        "GPT3-175B",
        "ChatGPT",
        "Davinci",
        "text-davinci-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DemoNSF A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task": {
    "filename": "DemoNSF A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task.pdf",
    "analysis": {
      "benchmarks": [
        "RADDLE",
        "SNIPS"
      ],
      "models": [
        "DemoNSF",
        "GPT2",
        "BART",
        "T5",
        "BARTNER",
        "LightNER",
        "InstructionNER",
        "ChatGPT",
        "Text-davinci-003"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Hallucination is Inevitable An Innate Limitation of Large Language Models": {
    "filename": "Hallucination is Inevitable An Innate Limitation of Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "L(m,{a,b})",
        "L(m,{a,b,c})"
      ],
      "models": [
        "llama2-70b-chat-hf",
        "gpt-3.5-turbo-16k",
        "gpt-4-0613"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "nl2spec Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models": {
    "filename": "nl2spec Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "expert user study dataset"
      ],
      "models": [
        "nl2spec",
        "Codex",
        "Bloom",
        "T-5",
        "nl2ltl"
      ]
    }
  },
  "Self-Prompting Large Language Models for Zero-Shot Open-Domain QA": {
    "filename": "Self-Prompting Large Language Models for Zero-Shot Open-Domain QA.pdf",
    "analysis": {
      "benchmarks": [
        "WebQ",
        "NQ",
        "TriviaQA"
      ],
      "models": [
        "Self-Prompting",
        "InstructGPT",
        "Codex",
        "GENREAD",
        "RECITE",
        "DPR+InstructGPT",
        "Google+InstructGPT",
        "T5-SSM",
        "REALM",
        "DPR",
        "RAG",
        "GPT-NeoX",
        "Alpaca"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The RLLLM Taxonomy Tree Reviewing Synergies Between Reinforcement Learning and Large Language Models": {
    "filename": "The RLLLM Taxonomy Tree Reviewing Synergies Between Reinforcement Learning and Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "GRUE Benchmark",
        "MANISKILL2",
        "METAWORLD",
        "MUJOCO",
        "Cartpole",
        "BallBalance",
        "Atari",
        "OpenAI Gym",
        "Hanabi"
      ],
      "models": [
        "Instruct-GPT",
        "HHH Context-Distilled Language Model",
        "SFT",
        "DistilRoBERTa",
        "TEMPERA",
        "RLPROMPT",
        "Prompt-OIRL",
        "Constitutional AI",
        "RL4LM",
        "NLPO",
        "TEXT2REWARD",
        "EUREKA",
        "TaskExplore",
        "ELLM",
        "Instruct-RL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Vulnerability Detection with Code Language Models How Far Are We": {
    "filename": "Vulnerability Detection with Code Language Models How Far Are We.pdf",
    "analysis": {
      "benchmarks": [
        "PRIME VUL",
        "BigVul",
        "SVEN",
        "CodeXGLUE",
        "VulnPatchPairs",
        "CrossVul",
        "CVEfixes",
        "DiverseVul"
      ],
      "models": [
        "StarCoder2",
        "GPT-3.5",
        "GPT-4",
        "CodeT5",
        "CodeBERT",
        "UnixCoder",
        "CodeGen2.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Vul-RAG Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG": {
    "filename": "Vul-RAG Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG.pdf",
    "analysis": {
      "benchmarks": [
        "PairVul"
      ],
      "models": [
        "Vul-RAG",
        "LLMAO",
        "LineVul",
        "DeepDFA",
        "Cppcheck",
        "GPT-4",
        "Code-based RAG"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Probabilistic Reasoning in Generative Large Language Models": {
    "filename": "Probabilistic Reasoning in Generative Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Bayesian Linguistic Inference Dataset (BLInD)",
        "CLADDER"
      ],
      "models": [
        "GPT3.5",
        "Llama3",
        "GPT4",
        "Mistral",
        "Llama2",
        "RuleBERT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ME-Switch A Memory-Efficient Expert Switching Framework for Large Language Models": {
    "filename": "ME-Switch A Memory-Efficient Expert Switching Framework for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "GSM8K",
        "MATH",
        "HumanEval",
        "MBPP",
        "C-Eval",
        "C-MMLU"
      ],
      "models": [
        "ME-Switch",
        "Dolphin-2.2.1-Mistral-7B",
        "MetaMath-Mistral-7B",
        "Speechless-Code-Mistral-7B",
        "LLaMA-2-13B-Chat",
        "MetaMath-13B",
        "LLaMA2-Chinese-13B-Chat",
        "Qwen1.5-1.8B-Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tree-Based Representation and Generation of Natural and Mathematical Language": {
    "filename": "Tree-Based Representation and Generation of Natural and Mathematical Language.pdf",
    "analysis": {
      "benchmarks": [
        "EXEQ-300k",
        "OFEQ-10k",
        "Math23K",
        "Cognitive Tutor"
      ],
      "models": [
        "MathGPT",
        "GPT-2",
        "GPT-2 Wiki",
        "MathBERT",
        "MathSum"
      ]
    }
  },
  "TAGExplainer Narrating Graph Explanations for Text-Attributed Graph Learning Models": {
    "filename": "TAGExplainer Narrating Graph Explanations for Text-Attributed Graph Learning Models.pdf",
    "analysis": {
      "benchmarks": [
        "Cora",
        "DBLP",
        "Book-History"
      ],
      "models": [
        "TAGExplainer",
        "SMV",
        "GPT-4o",
        "GPT-3.5 Turbo",
        "LLaMA 3.1 8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Low-Resource Authorship Style Transfer Can Non-Famous Authors Be Imitated": {
    "filename": "Low-Resource Authorship Style Transfer Can Non-Famous Authors Be Imitated.pdf",
    "analysis": {
      "benchmarks": [
        "Shakespeare author imitation dataset",
        "Reddit corpus"
      ],
      "models": [
        "STRAP",
        "STYLL",
        "COPY SRC",
        "COPY TGT",
        "CAPI",
        "CONT",
        "SYNM",
        "PUNC",
        "EMOJ",
        "PARA NEU",
        "PARA DIV",
        "LING",
        "BERT",
        "GPT-2 1.5B",
        "GPT-3 6.7B",
        "GPT-J 6B",
        "OPT 6.7B",
        "BLOOM 7.1B",
        "FLAN-T5 3B"
      ]
    }
  },
  "SelfDefend LLMs Can Defend Themselves against Jailbreaking in a Practical Manner": {
    "filename": "SelfDefend LLMs Can Defend Themselves against Jailbreaking in a Practical Manner.pdf",
    "analysis": {
      "benchmarks": [
        "JailbreakHub",
        "JailbreakBench",
        "MultiJail",
        "AlpacaEval"
      ],
      "models": [
        "SELFDEFEND",
        "GPT-3.5",
        "GPT-4",
        "Llama-2-7b",
        "Vicuna-7b-v1.3",
        "Vicuna-13b-v1.5",
        "ICD",
        "Perplexity Filter",
        "SmoothLLM",
        "Llama Guard",
        "Llama Guard 2",
        "SafeDecoding"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models as Code Executors An Exploratory Study": {
    "filename": "Large Language Models as Code Executors An Exploratory Study.pdf",
    "analysis": {
      "benchmarks": [
        "Leetcode"
      ],
      "models": [
        "OpenAI's o1",
        "GPT-4o",
        "GPT-3.5",
        "DeepSeek",
        "Qwen-Coder",
        "GPT-4",
        "DeepSeek-Coder",
        "Qwen-2.5-Coder",
        "Qwen-2.5-72B"
      ]
    }
  },
  "Queer People are People First Deconstructing Sexual Identity Stereotypes in Large Language Models": {
    "filename": "Queer People are People First Deconstructing Sexual Identity Stereotypes in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "WikiBio"
      ],
      "models": [
        "GPT-3.5 davinci",
        "regard classifier",
        "SHAP analysis"
      ]
    }
  },
  "Automatic deductive coding in discourse analysis an application of large language models in learning analytics": {
    "filename": "Automatic deductive coding in discourse analysis an application of large language models in learning analytics.pdf",
    "analysis": {
      "benchmarks": [
        "Annotation dataset",
        "Discussion dataset"
      ],
      "models": [
        "Random Forest",
        "RoBERTa",
        "GPT-4",
        "GPT-3.5-Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ICE-SEARCH A Language Model-Driven Feature Selection Approach": {
    "filename": "ICE-SEARCH A Language Model-Driven Feature Selection Approach.pdf",
    "analysis": {
      "benchmarks": [
        "stroke prediction dataset",
        "cardiovascular disease dataset",
        "diabetes dataset"
      ],
      "models": [
        "ICE-SEARCH",
        "Decision-Randomized ICE-SEARCH",
        "Decision Tree",
        "Random Forest",
        "Logistic Regression",
        "Fisher Score",
        "XGBoost",
        "Support Vector Machine (SVM)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "From Sparse Dependence to Sparse Attention Unveiling How Chain-of-Thought Enhances Transformer Sample Efficiency": {
    "filename": "From Sparse Dependence to Sparse Attention Unveiling How Chain-of-Thought Enhances Transformer Sample Efficiency.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K"
      ],
      "models": [
        "4-layer 4-head transformer",
        "1-layer 1-head transformer",
        "Qwen2-7B",
        "Qwen2-Math-7B",
        "GPT-2 architecture",
        "simplified Transformer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluation of Retrieval-Augmented Generation A Survey": {
    "filename": "Evaluation of Retrieval-Augmented Generation A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "WikiEval",
        "EventKG",
        "UJ",
        "NQ",
        "Hotpot",
        "FEVER",
        "WoW",
        "MultiRC",
        "ReCoRD",
        "RGB",
        "MultiHop-RAG",
        "CRUD-RAG",
        "UHGEval",
        "MIRAGE",
        "FeB4RAG",
        "BEIR",
        "CDQA",
        "DomainRAG",
        "RealTimeQA"
      ],
      "models": [
        "RAG",
        "FiD-Light",
        "Diversity Reranker",
        "TruEra RAG Triad",
        "LangChain Bench.",
        "Databricks Eval",
        "RAGAs",
        "RECALL",
        "ARES",
        "RGB",
        "MultiHop-RAG",
        "CRUD-RAG",
        "MedRAG",
        "FeB4RAG",
        "CDQA",
        "DomainRAG",
        "ReEval"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Reasoning on Graphs Faithful and Interpretable Large Language Model Reasoning": {
    "filename": "Reasoning on Graphs Faithful and Interpretable Large Language Model Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "WebQuestionsSP",
        "Complex WebQuestions"
      ],
      "models": [
        "RoG",
        "KV-Mem",
        "EmbedKGQA",
        "NSM",
        "TransferNet",
        "KGT5",
        "GraftNet",
        "PullNet",
        "SR+NSM",
        "SR+NSM+E2E",
        "SPARQL",
        "QGG",
        "ArcaneQA",
        "RnG-KBQA",
        "Flan-T5-xl",
        "Alpaca-7B",
        "LLaMA2-Chat-7B",
        "ChatGPT",
        "ChatGPT+CoT",
        "KD-CoT",
        "UniKGQA",
        "DECAF"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Belief in the Machine Investigating Epistemological Blind Spots of Language Models": {
    "filename": "Belief in the Machine Investigating Epistemological Blind Spots of Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "KaBLE"
      ],
      "models": [
        "GPT-4",
        "Claude-3",
        "Llama-3",
        "GPT-4o",
        "Claude-3.5",
        "Llama-2",
        "GPT-3.5",
        "Claude-3 Opus",
        "Claude-3 Sonnet",
        "Claude-3 Haiku",
        "Llama-3 70B",
        "Llama-3 8B",
        "Llama-2 70B",
        "Llama-2 13B",
        "Llama-2 7B",
        "Mistral 7B",
        "Mixtral 8x7B",
        "Mixtral 8x22B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Towards Complex Ontology Alignment using Large Language Models": {
    "filename": "Towards Complex Ontology Alignment using Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Ontology Alignment Evaluation Initiative (OAEI)",
        "Complex Conference",
        "Populated Complex Conference",
        "Hydrography",
        "GeoLink",
        "Populated GeoLink",
        "Populated Enslaved",
        "Taxon",
        "GeoLink Complex Alignment"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Flan-T5-XXL",
        "Sentence-BERT",
        "MELT"
      ]
    }
  },
  "Neural Graph Reasoning Complex Logical Query Answering Meets Graph Databases": {
    "filename": "Neural Graph Reasoning Complex Logical Query Answering Meets Graph Databases.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Neural Graph Databases (NGDB)",
        "Neural Graph Storage",
        "Neural Query Engine",
        "Graph Query Embedding (GQE)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing": {
    "filename": "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing.pdf",
    "analysis": {
      "benchmarks": [
        "LogiQA-v2",
        "ReClor",
        "GSM8K",
        "MATH"
      ],
      "models": [
        "Llama-2-7B-chat",
        "GPT-3.5-Turbo",
        "GPT-4-Turbo",
        "Mixtral-MoE-8x7B-Instruct",
        "Llama2-7B-SFT",
        "Llama2-7B-DPO",
        "Llama2-7B-pDPO",
        "Llama2-7B-RFT",
        "Llama2-7B-ReST-EM",
        "Llama2-7B-IPO",
        "Iter-1-DPO",
        "Iter-1-pDPO",
        "Iter-1-process PPO",
        "Iter-1-process GRPO",
        "Gemma-7B-Instruct",
        "Gemma-2B-SFT",
        "Gemma-2B-DPO",
        "Gemma-2B-pDPO",
        "DeepSeekMath-7B-Instruct",
        "DeepSeekMath-7B-Instruct + DPO",
        "DeepSeekMath-7B-Instruct + pDPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Influential Language Data Selection via Gradient Trajectory Pursuit": {
    "filename": "Influential Language Data Selection via Gradient Trajectory Pursuit.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld",
        "MMLU",
        "BBH",
        "TydiQA"
      ],
      "models": [
        "Gradient Trajectory Pursuit (GTP)",
        "LESS",
        "G-DIG",
        "RDS (Representation-based Data Selection)",
        "OPT-125M",
        "Mistral-7B"
      ]
    }
  },
  "Large Language Models for Travel Behavior Prediction": {
    "filename": "Large Language Models for Travel Behavior Prediction.pdf",
    "analysis": {
      "benchmarks": [
        "Swissmetro stated preference survey data set"
      ],
      "models": [
        "Large Language Models (LLMs)",
        "multinomial logit (MNL)",
        "random forest (RF)",
        "neural networks (NNs)",
        "GPT-3.5"
      ]
    }
  },
  "Wait but Tylenol is Acetaminophen Investigating and Improving Language Models Ability to Resist Requests for Misinformation": {
    "filename": "Wait but Tylenol is Acetaminophen Investigating and Improving Language Models Ability to Resist Requests for Misinformation.pdf",
    "analysis": {
      "benchmarks": [
        "RABBITS",
        "ARC Challenge",
        "ARC Easy",
        "BoolQ",
        "MMLU",
        "GPQA",
        "TruthfulQA",
        "USMLE Step 1",
        "USMLE Step 2",
        "USMLE Step 3"
      ],
      "models": [
        "Llama3-8B-Instruct",
        "Llama3-70B-Instruct",
        "gpt-4o-mini-2024-07-18",
        "gpt-4o-2024-05-13",
        "gpt-4-0613",
        "GPT4o-mini",
        "GPT4o",
        "GPT4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How to Configure Good In-Context Sequence for Visual Question Answering": {
    "filename": "How to Configure Good In-Context Sequence for Visual Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "VQAv2",
        "VizWiz",
        "OK-VQA"
      ],
      "models": [
        "Open-Flamingo v1",
        "Open-Flamingo v2",
        "Flamingo",
        "BLIP2",
        "MiniGPT-4",
        "LLAVA",
        "mPLUG-Owl",
        "Otter",
        "MMICL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HealthQ Unveiling Questioning Capabilities of LLM Chains in Healthcare Conversations": {
    "filename": "HealthQ Unveiling Questioning Capabilities of LLM Chains in Healthcare Conversations.pdf",
    "analysis": {
      "benchmarks": [
        "ChatDoctor",
        "MTS-Dialog"
      ],
      "models": [
        "HealthQ",
        "Retrieval-Augmented Generation (RAG)",
        "Chain of Thought (CoT)",
        "RAG with Reflection",
        "RAG with CoT",
        "RAG with Reflection and CoT-Self-Consistency (CoT-SC)",
        "ReAct",
        "Hardcoded Workflow"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "General-Purpose In-Context Learning by Meta-Learning Transformers": {
    "filename": "General-Purpose In-Context Learning by Meta-Learning Transformers.pdf",
    "analysis": {
      "benchmarks": [
        "MNIST",
        "Fashion MNIST",
        "CIFAR10",
        "KMNIST",
        "SVHN",
        "Random"
      ],
      "models": [
        "Transformer-based General-Purpose In-Context Learner (GPICL)",
        "MLP",
        "LSTM",
        "VSML",
        "SGD",
        "MAML"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Auto-Formula Recommend Formulas in Spreadsheets using Contrastive Learning for Table Representations": {
    "filename": "Auto-Formula Recommend Formulas in Spreadsheets using Contrastive Learning for Table Representations.pdf",
    "analysis": {
      "benchmarks": [
        "real enterprise spreadsheets",
        "spreadsheets from 4 large organizations (Enron, PGE, TI, and Cisco)"
      ],
      "models": [
        "Auto-Formula",
        "SpreadsheetCoder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LAP Using Action Feasibility for Improved Uncertainty Alignment of Large Language Model Planners": {
    "filename": "LAP Using Action Feasibility for Improved Uncertainty Alignment of Large Language Model Planners.pdf",
    "analysis": {
      "benchmarks": [
        "KnowNo Simulation",
        "Mobile Manipulator Datasets"
      ],
      "models": [
        "LAP",
        "KnowNo",
        "GPT-4",
        "GPT-3.5-Turbo",
        "GPT-4-Turbo",
        "Prompt",
        "Binary",
        "No Help"
      ]
    }
  },
  "ReWOO Decoupling Reasoning from Observations for Efficient Augmented Language Models": {
    "filename": "ReWOO Decoupling Reasoning from Observations for Efficient Augmented Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "HotpotQA",
        "TriviaQA",
        "SportsUnderstanding",
        "StrategyQA",
        "GSM8K",
        "PhysicsQuestions",
        "SOTUQA"
      ],
      "models": [
        "ReWOO",
        "Direct Prompting",
        "Chain-of-Thought prompting",
        "ReAct",
        "GPT-3.5",
        "LLaMA 7B",
        "Planner 7B",
        "Alpaca 7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "BIRD A Trustworthy Bayesian Inference Framework for Large Language Models": {
    "filename": "BIRD A Trustworthy Bayesian Inference Framework for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "COMMON 2SENSE",
        "PLASMA",
        "TODAY",
        "MATRES",
        "TRACIE"
      ],
      "models": [
        "BIRD",
        "OpenAI o1",
        "GPT3.5 CoT",
        "GPT4 CoT",
        "Llama2-70b Instruct Logit",
        "Llama2-70b Instruct Vanilla",
        "Llama2-70b Instruct CoT",
        "Llama3.1-70b Instruct Logit",
        "Llama3.1-70b Instruct Vanilla",
        "Llama3.1-70b Instruct CoT",
        "Llama2-70b Instruct EC",
        "Llama3.1-70b Instruct EC",
        "GPT4 EC",
        "Llama3.1 BIRD (ablation w 1/2 assumption)",
        "Llama3.1 BIRD (ablation w 1/n assumption)",
        "Llama3.1 BIRD (ablation w fixed initial prob)",
        "Llama2 BIRD (ours w optimized prob)",
        "Llama3.1 BIRD (ours w optimized prob)",
        "T5large",
        "PatternTime"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning": {
    "filename": "LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning.pdf",
    "analysis": {
      "benchmarks": [
        "28 exercises from Sipser's Introduction to the Theory of Computation"
      ],
      "models": [
        "TTT algorithm",
        "LStar algorithm",
        "LEARN ANYWAY algorithm",
        "LEARN ANYWAY with Passive Refinement (LAPR)",
        "RPNI-EDSM"
      ]
    }
  },
  "Evaluating Language-Model Agents on Realistic Autonomous Tasks": {
    "filename": "Evaluating Language-Model Agents on Realistic Autonomous Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "Search filesystem for password",
        "List top BBC articles",
        "Find information on Wikipedia",
        "Create Bitcoin wallet",
        "Make phone call with Twilio",
        "Count dogs in image",
        "Find new employees at [company]",
        "Set up GPT-J",
        "Create language model agent",
        "Automatically restart agent",
        "Targeted phishing",
        "Increase LLaMA context length"
      ],
      "models": [
        "GPT-4-simple",
        "GPT-4-delegate",
        "GPT-4-early-delegate",
        "Claude-assistant"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Assessing the Emergent Symbolic Reasoning Abilities of Llama Large Language Models": {
    "filename": "Assessing the Emergent Symbolic Reasoning Abilities of Llama Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ListOps",
        "Arithmetic"
      ],
      "models": [
        "Llama 2 Chat",
        "MAmmoTH",
        "MetaMath"
      ]
    }
  },
  "Re-TASK Revisiting LLM Tasks from Capability Skill and Knowledge Perspectives": {
    "filename": "Re-TASK Revisiting LLM Tasks from Capability Skill and Knowledge Perspectives.pdf",
    "analysis": {
      "benchmarks": [
        "CAIL dataset",
        "FinanceIQ dataset",
        "MMLU-Math dataset"
      ],
      "models": [
        "Yi-1.5-9B",
        "Llama3-Chinese-8B",
        "Qwen1.5-7B",
        "Qwen1.5-14B",
        "Qwen1.5-32B",
        "Mistral-7B",
        "Llama3-8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RAMP Retrieval and Attribute-Marking Enhanced Prompting for Attribute-Controlled Translation": {
    "filename": "RAMP Retrieval and Attribute-Marking Enhanced Prompting for Attribute-Controlled Translation.pdf",
    "analysis": {
      "benchmarks": [
        "COCOA-MT",
        "MT-G ENEVAL"
      ],
      "models": [
        "RAMP",
        "XGLM 7.5B",
        "BLOOM 175B",
        "Adapted MT",
        "GPT-N EOX 20B",
        "BLOOM 7.1B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Exploiting Large Language Models Capabilities for Question Answer-Driven Knowledge Graph Completion Across Static and Temporal Domains": {
    "filename": "Exploiting Large Language Models Capabilities for Question Answer-Driven Knowledge Graph Completion Across Static and Temporal Domains.pdf",
    "analysis": {
      "benchmarks": [
        "WN18RR",
        "UMLS",
        "FB15k-237",
        "FB15k-237N",
        "ICEWS14",
        "ICEWS05-15"
      ],
      "models": [
        "GS-KGC",
        "KG-BERT",
        "SimKGC",
        "KG-S2S",
        "KG-S2S-CD",
        "SimKGC+MPIKGC-S",
        "SimKGC+CP-KGC",
        "KC-GenRe",
        "TiRGN",
        "HGLS",
        "GenTKG",
        "GPT-NeoX-20B-ICL",
        "Llama2-7b-ICL",
        "Llama2-7b-CoH",
        "GS-KGC QA-only"
      ]
    }
  },
  "Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine": {
    "filename": "Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA USMLE"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "Beyond Task Performance Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning": {
    "filename": "Beyond Task Performance Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "COCO",
        "TDIUC",
        "CREPE",
        "SugarCREPE",
        "VQA-X",
        "LlaVA"
      ],
      "models": [
        "Flamingo",
        "OpenFlamingo (OF)",
        "IDEFICS",
        "OFv2-3B",
        "OFv2-3B (I)",
        "OFv2-4B",
        "OFv2-4B (I)",
        "OFv2-9B",
        "OFv1-9B",
        "IDEFICS-9B",
        "IDEFICS-9B (I)",
        "IDEFICS-80B",
        "IDEFICS-80B (I)",
        "Multitask-ICL",
        "Chain-of-Hindsight-ICL",
        "Self-Correcting-ICL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DeepSeek LLM Scaling Open-Source Language Models with Longtermism": {
    "filename": "DeepSeek LLM Scaling Open-Source Language Models with Longtermism.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "C-Eval",
        "CMMLU",
        "HellaSwag",
        "PIQA",
        "ARC",
        "OpenBookQA",
        "BigBench Hard (BBH)",
        "TriviaQA",
        "NaturalQuestions",
        "RACE",
        "DROP",
        "C3",
        "WinoGrande",
        "CLUEWSC",
        "Pile",
        "CHID",
        "CCPM",
        "GSM8K",
        "MATH",
        "CMath",
        "HumanEval",
        "MBPP",
        "AGIEval",
        "AlignBench",
        "MT-Bench"
      ],
      "models": [
        "DeepSeek LLM 67B",
        "DeepSeek LLM 67B Chat",
        "DeepSeek LLM 7B",
        "DeepSeek LLM 7B Chat",
        "LLaMA-2 70B",
        "GPT-3.5",
        "DeepSeek Chat",
        "DeepSeek LLM 67B Chat DPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Survey of Deep Learning for Mathematical Reasoning": {
    "filename": "A Survey of Deep Learning for Mathematical Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "MathQA",
        "SVAMP",
        "IconQA",
        "TabMWP",
        "CoqGym",
        "NaturalProofs",
        "miniF2F+informal",
        "GEOS",
        "GEOS++",
        "Geometry3K",
        "UniGeo",
        "DROP",
        "Mathematics",
        "Lila",
        "TheoremQA",
        "FigureQA",
        "DVQA",
        "ConvFinQA",
        "ScienceQA",
        "P3"
      ],
      "models": [
        "DNS",
        "AnsRat",
        "GTS",
        "Graph2Tree",
        "Math-EN",
        "GROUP-ATT",
        "CNNTP",
        "MathDQN",
        "GenBERT",
        "Minerva",
        "Scratchpad",
        "Bhaskara",
        "Few-shot-CoT",
        "PromptPG",
        "Self-Consistency",
        "Least-to-most"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AutoPSV Automated Process-Supervised Verifier": {
    "filename": "AutoPSV Automated Process-Supervised Verifier.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "HellaSwag",
        "Winogrande",
        "ANLI"
      ],
      "models": [
        "AUTOPSV",
        "Outcome-Supervised Verifier (OSV)",
        "Process-Supervised Verifier (PSV)",
        "OSV + PSV",
        "Self-Consistency",
        "Mistral-Instruct",
        "Mixtral-Instruct",
        "Qwen"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mitigating Interpretation Bias in Rock Records with Large Language Models Insights from Paleoenvironmental Analysis": {
    "filename": "Mitigating Interpretation Bias in Rock Records with Large Language Models Insights from Paleoenvironmental Analysis.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "Claude",
        "K2",
        "GeoGalactica",
        "GPT-4",
        "sentence-transformers/all-MiniLM-L6-v2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Defining and Evaluating Physical Safety for Large Language Models": {
    "filename": "Defining and Evaluating Physical Safety for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "LLM Physical Safety Benchmark",
        "LLM Physical Safety Benchmark Datasets"
      ],
      "models": [
        "GPT-3.5 turbo",
        "Gemini Pro",
        "Llama 2 7B Chat",
        "CodeLlama-7b-Instruct",
        "Meta-Llama-3-8B-Instruct",
        "Mistral-7B-Instruct-v0.2",
        "CodeQwen1.5-7B-Chat",
        "OpenAI GPT-3.5-turbo",
        "Meta Llama2",
        "Meta Code Llama",
        "Meta Llama3",
        "Mistral AI Mistral-7B",
        "Qwen CodeQwen1.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AI Transparency in the Age of LLMs A Human-Centered Research Roadmap": {
    "filename": "AI Transparency in the Age of LLMs A Human-Centered Research Roadmap.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "LaMDA",
        "LLaMA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Text2MDT Extracting Medical Decision Trees from Medical Texts": {
    "filename": "Text2MDT Extracting Medical Decision Trees from Medical Texts.pdf",
    "analysis": {
      "benchmarks": [
        "Text2MDT"
      ],
      "models": [
        "end-to-end framework",
        "pipeline framework",
        "GPT style large language models (LLM)",
        "chain-of-thought (COT) prompting",
        "encoder-based pretrained models",
        "UNIRE",
        "TPLinker",
        "CasRel",
        "Sep-Biaffine",
        "NG-Biaffine",
        "NG-TableFilling",
        "TreeAssemble-Biaffine",
        "TreeAssemble-TableFilling",
        "Generation",
        "COT-Generation",
        "COT-Generation-1",
        "COT-Generation-2",
        "COT-Generation-3",
        "COT-Generation-4",
        "MedBERT",
        "BERT-wwm-ext",
        "BERT-base Chinese",
        "Erlangshen-ZEN1-224M",
        "GPT-2 Chinese",
        "Randeng-T5-784M",
        "BLOOMZ-7.1B-mt",
        "ChatGLM-6B-2",
        "ChatMed",
        "Chinese-LLaMA-2 7B",
        "Chinese-LLaMA-2 13B",
        "Ziya-13B-medical",
        "Baichuan-2 7B",
        "Baichuan-2 13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Video Action Recognition with Attentive Semantic Units": {
    "filename": "Video Action Recognition with Attentive Semantic Units.pdf",
    "analysis": {
      "benchmarks": [
        "Kinetics-400",
        "Kinetics-600",
        "UCF-101",
        "HMDB-51"
      ],
      "models": [
        "ASU-B/16",
        "ASU-L/14",
        "ASU-L/14-336",
        "ActionCLIP",
        "X-CLIP-B/16",
        "X-CLIP-L/14",
        "EVL-B/16",
        "EVL-L/14",
        "MTV-H/16",
        "PromptingCLIP-B/16",
        "MViTv1-B",
        "Uniformer-B",
        "TimeSformer-L",
        "Mformer-HR",
        "Swin-L",
        "MViTv2-L",
        "ViViT-H/16",
        "TokenLearner-L/10",
        "Florence",
        "CoVeR",
        "X-Florence",
        "TSM",
        "Swin-B",
        "MTE",
        "ASR",
        "ZSECOC",
        "UR",
        "TS-GCN",
        "E2E",
        "ER-ZSAR",
        "DEVISE",
        "ALE",
        "SJE",
        "ESZSL",
        "DEM",
        "GCN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Recitation-Augmented Language Models": {
    "filename": "Recitation-Augmented Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Questions",
        "TriviaQA",
        "HotpotQA"
      ],
      "models": [
        "RECITE",
        "PaLM",
        "UL2",
        "OPT",
        "Codex",
        "Atlas"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Distilled Language Models are economically efficient for the enterprise mostly": {
    "filename": "Distilled Language Models are economically efficient for the enterprise mostly.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-2",
        "GPT-3",
        "Cohere",
        "GPT-2 BFT BD",
        "Cohere PE",
        "GPT-3 PE",
        "GPT-2 BFT",
        "GPT-2 BFT BF BFT",
        "GPT-2 GFT BD BFT",
        "GPT-2 GFT GD BFT",
        "GPT-2 XL GFT GD BFT",
        "Cohere FT",
        "GPT-3 BFT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FathomGPT A natural language interface for interactively exploring ocean science data": {
    "filename": "FathomGPT A natural language interface for interactively exploring ocean science data.pdf",
    "analysis": {
      "benchmarks": [
        "FathomNet"
      ],
      "models": [
        "FathomGPT",
        "OpenAI's GPT models",
        "Vision Transformer",
        "EfficientNet V2",
        "Segment Anything model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On the InEffectiveness of Large Language Models for Chinese Text Correction": {
    "filename": "On the InEffectiveness of Large Language Models for Chinese Text Correction.pdf",
    "analysis": {
      "benchmarks": [
        "Chinese Grammatical Error Correction (CGEC)",
        "Chinese Spelling Check (CSC)",
        "SIGHAN15",
        "LAW",
        "MED",
        "ODW",
        "MCSCSet",
        "NLPCC",
        "MuCGEC",
        "NaCGEC"
      ],
      "models": [
        "text-davinci-003",
        "gpt-3.5-turbo",
        "Vicuna-13B-v1.3",
        "ChatGLM-6B",
        "ChatGLM2-6B",
        "Baichuan-13B-Chat",
        "REALISE",
        "Two-Ways",
        "LEAD",
        "Soft-Masked BERT",
        "BERT",
        "ECSpell",
        "MedBERT-Corrector",
        "Seq2Seq-Baseline (BART-Large-Chinese)",
        "Seq2Edit-Baseline (GECToR-Chinese)",
        "GECToR",
        "Baichuan-13B-Chat (LoRA)",
        "Baichuan-13B-Chat (FT)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLM4PlC Harnessing large Language Models for Verifiable Programming of PlCs in Industrial Control Systems": {
    "filename": "LLM4PlC Harnessing large Language Models for Verifiable Programming of PlCs in Industrial Control Systems.pdf",
    "analysis": {
      "benchmarks": [
        "FischerTechnik Manufacturing TestBed (MFTB)"
      ],
      "models": [
        "LLM4PLC",
        "GPT-3.5",
        "GPT-4",
        "Code Llama-7B",
        "fine-tuned Code Llama-7B",
        "Code Llama-34B",
        "fine-tuned Code Llama-34B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GroupDebate Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion": {
    "filename": "GroupDebate Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion.pdf",
    "analysis": {
      "benchmarks": [
        "Arithmetic",
        "GSM8K",
        "MMLU",
        "MATH"
      ],
      "models": [
        "GroupDebate",
        "multi-agent debate (MAD)",
        "Chain-of-Thought (CoT)",
        "Reflection",
        "Self-Consistency with Chain-of-Thought (CoT-SC)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CloudEval-YAML A Practical Benchmark for Cloud Configuration Generation": {
    "filename": "CloudEval-YAML A Practical Benchmark for Cloud Configuration Generation.pdf",
    "analysis": {
      "benchmarks": [
        "CloudEval-YAML"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "PaLM-2-bison",
        "Llama-2-70b-chat",
        "Llama-2-13b-chat",
        "Wizardcoder-34b-v1.0",
        "Llama-2-7b-chat",
        "Wizardcoder-15b-v1.0",
        "Llama-7b",
        "Llama-13b-lora",
        "Codellama-7b-instruct",
        "Codellama-13b-instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Achieving Human Level Partial Credit Grading of Written Responses to Physics Conceptual Question using GPT-35 with Only Prompt Engineering": {
    "filename": "Achieving Human Level Partial Credit Grading of Written Responses to Physics Conceptual Question using GPT-35 with Only Prompt Engineering.pdf",
    "analysis": {
      "benchmarks": [
        "Physics conceptual question dataset"
      ],
      "models": [
        "GPT-3.5 Turbo",
        "Na\u00efve COT",
        "Detailed-rubric COT",
        "Scaffolded COT",
        "GPT-4o"
      ]
    }
  },
  "Chain-of-Note Enhancing Robustness in Retrieval-Augmented Language Models": {
    "filename": "Chain-of-Note Enhancing Robustness in Retrieval-Augmented Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "NQ",
        "TriviaQA",
        "WebQ",
        "RealTimeQA"
      ],
      "models": [
        "CHAIN-OF-NOTE (CON)",
        "GPT-4",
        "LLaMa-2 7B",
        "CHAIN-OF-THOUGHT (COT)",
        "Retrieve-Read",
        "SAIL",
        "QA fine-tune w/o IR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OMPGPT A Generative Pre-trained Transformer Model for OpenMP": {
    "filename": "OMPGPT A Generative Pre-trained Transformer Model for OpenMP.pdf",
    "analysis": {
      "benchmarks": [
        "HPCorpus"
      ],
      "models": [
        "OMPGPT",
        "MonoCoder",
        "GPT-3.5",
        "GPT-Neo",
        "PolyCoder",
        "GPT-J",
        "CodeX",
        "StarCoder",
        "GPT-NeoX"
      ]
    }
  },
  "BPP-Search Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving": {
    "filename": "BPP-Search Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving.pdf",
    "analysis": {
      "benchmarks": [
        "StructuredOR",
        "NL4OPT",
        "MAMO-ComplexLP"
      ],
      "models": [
        "BPP-Search",
        "Chain-of-Thought (CoT)",
        "Self-Consistency (SC)",
        "Tree-of-Thought (ToT)",
        "Greedy",
        "Epsilon Greedy",
        "Beam Search",
        "Random Greedy",
        "GPT-4o",
        "GPT-4o-mini",
        "Llama-3-70B",
        "Llama-3.1-70B",
        "Llama-3.2-11B",
        "Qwen-2-72B-Instruct",
        "Qwen-2.5-MATH-72B-Instruct",
        "Qwen-2.5-72B-Instruct",
        "Mixtral-8\u00d77B-v0.1",
        "Qwen2.5-Math-1.5B"
      ]
    }
  },
  "Complementary Advantages of ChatGPTs and Human Readers in Reasoning Evidence from English Text Reading Comprehension": {
    "filename": "Complementary Advantages of ChatGPTs and Human Readers in Reasoning Evidence from English Text Reading Comprehension.pdf",
    "analysis": {
      "benchmarks": [
        "commonsense inference test",
        "emotional inference test",
        "causal inference test"
      ],
      "models": [
        "ChatGPT",
        "ChatGPT Plus",
        "Chinese senior school students"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Development and Evaluation of a Retrieval-Augmented Generation Tool for Creating SAPPhIRE Models of Artificial Systems": {
    "filename": "Development and Evaluation of a Retrieval-Augmented Generation Tool for Creating SAPPhIRE Models of Artificial Systems.pdf",
    "analysis": {
      "benchmarks": [
        "GPQA"
      ],
      "models": [
        "GPT-4o",
        "Gemini 1.5 Flash",
        "Llama 3.1 405b",
        "GPT-3.5-turbo-0125",
        "GPT-3.5-turbo"
      ],
      "datasets": [
        "orifice plate",
        "thermoelectric cooler (TEC)",
        "solenoid valve"
      ]
    }
  },
  "Improving Socratic Question Generation using Data Augmentation and Preference Optimization": {
    "filename": "Improving Socratic Question Generation using Data Augmentation and Preference Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "Socratic questions dataset for student code debugging"
      ],
      "models": [
        "LLama 2-7B",
        "GPT-3.5-turbo",
        "GPT-4",
        "Flan-T5",
        "Code-Llama (7B)"
      ]
    }
  },
  "TableGPT Towards Unifying Tables Nature Language and Commands into One GPT": {
    "filename": "TableGPT Towards Unifying Tables Nature Language and Commands into One GPT.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "TableGPT",
        "ChatExcel",
        "SheetCopilot",
        "Data-Copilot"
      ]
    }
  },
  "Art or Artifice Large Language Models and the False Promise of Creativity": {
    "filename": "Art or Artifice Large Language Models and the False Promise of Creativity.pdf",
    "analysis": {
      "benchmarks": [
        "Torrance Test of Creative Writing (TTCW)"
      ],
      "models": [
        "ChatGPT",
        "GPT4",
        "Claude 1.3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Learning to Reason With Relational Abstractions": {
    "filename": "Learning to Reason With Relational Abstractions.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "GSM8K-R",
        "unit conversion task"
      ],
      "models": [
        "GPT2-M",
        "GPT2-XL",
        "Numeric only (NN)",
        "Relational-First (RRNN)",
        "Interleaved (RNRN)",
        "Multitask (RRjNN)",
        "Answer only baseline",
        "Socratic + Solution",
        "Socratic + Equation",
        "Relation + Equation"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AIC MLLM Autonomous Interactive Correction MLLM for Robust Robotic Manipulation": {
    "filename": "AIC MLLM Autonomous Interactive Correction MLLM for Robust Robotic Manipulation.pdf",
    "analysis": {
      "benchmarks": [
        "PartNet-Mobility"
      ],
      "models": [
        "AIC MLLM",
        "UMPNet",
        "FlowBot3D",
        "ManipLLM",
        "base model",
        "Ours-w/o pretrain",
        "Ours-w/o pos",
        "Ours-w/o rot",
        "Ours-w/o tta"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cognitive Mirage A Review of Hallucinations in Large Language Models": {
    "filename": "Cognitive Mirage A Review of Hallucinations in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "IWSLT-2014",
        "WMT2018",
        "FLORES-200",
        "Jigsaw",
        "Wikipedia",
        "XQuAD",
        "TyDi",
        "XNLI",
        "XL-Sum",
        "MASSIVE",
        "TruthfulQA",
        "HotpotQA",
        "BoolQ",
        "NQ",
        "TopiOCQA",
        "MEDMCQA",
        "Headqa",
        "USMILE",
        "Medqa",
        "Pubmed",
        "WoW",
        "CMU-DOG",
        "TopicalChat",
        "OpenDialKG",
        "CNN/DM",
        "XSum",
        "MENT",
        "NHNet",
        "Encyclopedic",
        "ETC",
        "TekGen",
        "WebNLG",
        "MSCOCO"
      ],
      "models": [
        "GPT-3",
        "InstructGPT",
        "FLAN",
        "PaLM",
        "LLaMA",
        "FaithDial",
        "BEGIN",
        "MixCL",
        "BARTScore",
        "SelfCheckGPT",
        "FActScore",
        "CLR",
        "TYE",
        "PURR",
        "HISTALIGN",
        "Edit-TA",
        "EWR",
        "EasyEdit",
        "ALLM",
        "mmT5",
        "TRAC",
        "Factual-Nucleus",
        "Inference-Time",
        "NP-Hunter",
        "CoT",
        "ORCA",
        "RR",
        "TRAK",
        "Data-Portraits",
        "Self-Refine",
        "Reflexion",
        "Verify-and-Edit",
        "RETRO",
        "IRCoT",
        "POPQA",
        "LLM-AUGMENTER",
        "In-Context RALM",
        "GeneGPT",
        "cTBL",
        "CoK",
        "FLARE",
        "Gorilla",
        "RETA-LLM",
        "KnowledGPT",
        "LSHF",
        "TLM",
        "BRIO",
        "Chain-of-Hindsight",
        "ZEROFEC",
        "CRITIC",
        "VIVID",
        "LMH-Snowball",
        "MixAlign",
        "REFEED",
        "PaD",
        "ALCE",
        "Do-LLM-Know",
        "CRL",
        "HLMTM",
        "Multiagent-Debate",
        "MAD",
        "FORD",
        "LM-vs-LM",
        "PRD",
        "SPP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models": {
    "filename": "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ScienceQA",
        "TabMWP",
        "NLVRv2",
        "LLM Cloud CLI"
      ],
      "models": [
        "ChatGPT (gpt-3.5-turbo)",
        "text-davinci-002",
        "Grounded-SAM",
        "Track Anything",
        "VisProg"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On Generative Agents in Recommendation": {
    "filename": "On Generative Agents in Recommendation.pdf",
    "analysis": {
      "benchmarks": [
        "MovieLens-1M",
        "Steam",
        "Amazon-Book"
      ],
      "models": [
        "Agent4Rec",
        "Matrix Factorization (MF)",
        "LightGCN",
        "MultVAE",
        "Random",
        "Most Popular"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Adaptive Video Understanding Agent Enhancing efficiency with dynamic frame sampling and feedback-driven reasoning": {
    "filename": "Adaptive Video Understanding Agent Enhancing efficiency with dynamic frame sampling and feedback-driven reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Egoschema",
        "Ego4d NLQ",
        "MovieChat",
        "NextQA"
      ],
      "models": [
        "Adaptive Video Understanding Agent (AVUA)",
        "AssistGPT",
        "DoraemonGPT",
        "VideoAgent",
        "LifelongMemory",
        "FrozenBiLM",
        "InternVid",
        "ShortViViT",
        "LongViViT",
        "LLoVi",
        "VideoChat",
        "VideoLlaMA",
        "VideoChatGPT",
        "MovieChat",
        "ReAct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Innovative Thinking Infinite Humor Humor Research of Large Language Models through Structured Thought Leaps": {
    "filename": "Innovative Thinking Infinite Humor Humor Research of Large Language Models through Structured Thought Leaps.pdf",
    "analysis": {
      "benchmarks": [
        "Oogiri-GO",
        "SemEval 2020",
        "SemEval 2021",
        "Chinese Benchmark",
        "In-house Data"
      ],
      "models": [
        "GPT-4o",
        "LLAMA3",
        "QWEN1.5-32B-Chat",
        "QWEN2-57B",
        "Baichuan2",
        "CLoT",
        "CLoST"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models as Agents in Two-Player Games": {
    "filename": "Large Language Models as Agents in Two-Player Games.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-4",
        "ChatGPT",
        "Transformer",
        "Decision Transformer",
        "AlphaZero"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Show Dont Tell Evaluating Large Language Models Beyond Textual Understanding with ChildPlay": {
    "filename": "Show Dont Tell Evaluating Large Language Models Beyond Textual Understanding with ChildPlay.pdf",
    "analysis": {
      "benchmarks": [
        "Tic-Tac-Toe",
        "Connect Four",
        "Battleship",
        "LEGO Connect Language (LCL)",
        "Game of Shapes",
        "ChildPlay",
        "SQuAD",
        "GLUE",
        "BIG-bench",
        "SuperGLUE",
        "ANLI",
        "TruthfulQA",
        "HellaSwag",
        "lm-evaluation-harness"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "gpt-3.5-turbo-1106",
        "gpt-4-1106-preview",
        "minimax algorithm"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EcoAssistant Using LLM Assistant More Affordably and Accurately": {
    "filename": "EcoAssistant Using LLM Assistant More Affordably and Accurately.pdf",
    "analysis": {
      "benchmarks": [
        "Places",
        "Weather",
        "Stock",
        "Mixed-1",
        "Mixed-2",
        "Mixed-3",
        "Mixed-100"
      ],
      "models": [
        "EcoAssistant",
        "GPT-4",
        "GPT-3.5-turbo",
        "LLAMA-2-13B-chat",
        "AssistantHier-G",
        "AssistantHier-L",
        "GPT-3.5-turbo + SolDemo",
        "GPT-4 + SolDemo",
        "AssistantHier-G + SolDemo",
        "AssistantHier-L + SolDemo",
        "GPT-3.5-turbo + CoT",
        "GPT-4 + CoT",
        "AssistantHier-G + CoT",
        "AssistantHier-L + CoT",
        "GPT-3.5-turbo + CoT + SolDemo",
        "GPT-4 + CoT + SolDemo",
        "AssistantHier-G + CoT + SolDemo",
        "AssistantHier-L + CoT + SolDemo"
      ]
    }
  },
  "Patchscopes A Unifying Framework for Inspecting Hidden Representations of Language Models": {
    "filename": "Patchscopes A Unifying Framework for Inspecting Hidden Representations of Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Pile evaluation set",
        "WikiText-103",
        "PopQA dataset"
      ],
      "models": [
        "Patchscopes",
        "Logit Lens",
        "Tuned Lens",
        "Token Identity Patchscope",
        "Zero-shot Feature Extraction Patchscope",
        "Logistic Regression Probe",
        "Chain-of-Thought Patchscope",
        "Vanilla Baseline",
        "Chain-of-Thought Baseline",
        "LLaMA2 (13B)",
        "Vicuna (13B)",
        "GPT-J (6B)",
        "Pythia (12B)",
        "Vicuna 7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Natural Language Inference Improves Compositionality in Vision-Language Models": {
    "filename": "Natural Language Inference Improves Compositionality in Vision-Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Winoground",
        "EqBen",
        "DrawBench",
        "EditBench",
        "COCO-T2I",
        "TIFA160",
        "Pick-a-Pic",
        "StanfordT23D"
      ],
      "models": [
        "CECE",
        "CLIPScore",
        "BLIP2 ITM",
        "VQAScore",
        "VIEScore",
        "GPT4V-Eval",
        "VisProg",
        "ViperGPT",
        "VPEval",
        "VQ2",
        "DSG",
        "CCoT",
        "LLaVA-1.5",
        "LLaVA-1.6",
        "InstructBLIP",
        "BLIPv2",
        "PaLI-17B",
        "CLIP-FlanT5-11B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prospective Learning Learning for a Dynamic Future": {
    "filename": "Prospective Learning Learning for a Dynamic Future.pdf",
    "analysis": {
      "benchmarks": [
        "MNIST",
        "CIFAR-10"
      ],
      "models": [
        "Prospective ERM",
        "Follow-the-Leader",
        "Online SGD",
        "Bayesian gradient descent"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Superficial Safety Alignment Hypothesis": {
    "filename": "Superficial Safety Alignment Hypothesis.pdf",
    "analysis": {
      "benchmarks": [
        "AdvBench",
        "wiki2",
        "wino",
        "openb",
        "arc c",
        "boolq",
        "hellas",
        "rte",
        "Advkeyword",
        "llama3-guard",
        "HEx-PHI",
        "MT-bench",
        "ARC-C",
        "ARC-E",
        "Hellas",
        "Winog",
        "Boolq",
        "piqa",
        "GSM8K",
        "MMLU"
      ],
      "models": [
        "Llama2-7B",
        "Llama3-8B",
        "Llama3.1-8B",
        "Meta-Llama-2-7B-Chat",
        "Meta-Llama-3-8B-Instruct",
        "Llama-7B",
        "Llama2-7B-Chat",
        "Llama3-8B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Laboratory-Scale AI Open-Weight Models are Competitive with ChatGPT Even in Low-Resource Settings": {
    "filename": "Laboratory-Scale AI Open-Weight Models are Competitive with ChatGPT Even in Low-Resource Settings.pdf",
    "analysis": {
      "benchmarks": [
        "Climate-FEVER",
        "MTS-Dialog",
        "CivilComments-WILDS",
        "QASPER",
        "MedQA"
      ],
      "models": [
        "GPT-3.5-Turbo",
        "GPT-4-Turbo",
        "Mistral-7B-Instruct-v0.1",
        "Falcon-7B-Instruct",
        "LLaMA-2-7B-Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multi-Method Self-Training Improving Code Generation With Text And Vice Versa": {
    "filename": "Multi-Method Self-Training Improving Code Generation With Text And Vice Versa.pdf",
    "analysis": {
      "benchmarks": [
        "SVAMP",
        "GSM8K",
        "MAWPS",
        "MathQA",
        "StrategyQA",
        "CommonSenseQA"
      ],
      "models": [
        "BLOOM",
        "Multi-Method Self-Training (MMST)",
        "Single-Method Self-Training (ST)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MATEval A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation": {
    "filename": "MATEval A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation.pdf",
    "analysis": {
      "benchmarks": [
        "ROCStories",
        "WritingPrompts",
        "Chinese LOngText understanding and generation (LOT)",
        "Ant"
      ],
      "models": [
        "MATEval",
        "GPT-4",
        "BLEU",
        "ROUGE-L",
        "RUBER-BERT",
        "RUBER-BERT r",
        "RUBER-BERT u",
        "UNION",
        "ChatEval",
        "Single-Agent (SA)",
        "One-by-One (ObO)",
        "Self-Reflection (SR)",
        "Chain-of-Thought (CoT)",
        "Self-Reflection + CoT (SR+CoT)"
      ]
    }
  },
  "Artificial general intelligence for radiation oncology": {
    "filename": "Artificial general intelligence for radiation oncology.pdf",
    "analysis": {
      "benchmarks": [
        "Mayo Clinic exam for radiation oncology physics",
        "TG-263 guidelines"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "Segment Anything Model (SAM)",
        "Vision Transformer (ViT)",
        "VideoMAE V2",
        "Swin Transformer",
        "VoxelMorph",
        "Cycle-consistent GAN",
        "RapidPlan",
        "ChatGPT",
        "BERT",
        "PaLM 2",
        "BLOOMZ",
        "Llama series"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Entailment-Driven Privacy Policy Classification with LLMs": {
    "filename": "Entailment-Driven Privacy Policy Classification with LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "OPP-115"
      ],
      "models": [
        "Explained Classifier",
        "Blank Filler",
        "Entailment Verifier",
        "T5",
        "GPT4",
        "LLaMA2",
        "PrivBERT",
        "BERT",
        "RoBERTa",
        "GPT2 Embedding"
      ]
    }
  },
  "LLM4DyG Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs": {
    "filename": "LLM4DyG Can Large Language Models Solve Spatial-Temporal Problems on Dynamic Graphs.pdf",
    "analysis": {
      "benchmarks": [
        "LLM4DyG"
      ],
      "models": [
        "DST2",
        "GPT-3.5",
        "Vicuna-7B",
        "Vicuna-13B",
        "Llama-2-13B",
        "CodeLlama-2-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models": {
    "filename": "Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Genomic Ancestry Dataset",
        "Hereditary Hearing Loss Dataset"
      ],
      "models": [
        "FREEFORM",
        "LASSO",
        "PCA",
        "RF-based Gini Importance",
        "LLM-Select",
        "Logistic Regression",
        "Random Forest",
        "XGBoost",
        "TabPFN",
        "FeatLLM"
      ]
    }
  },
  "JARVIS-1 Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models": {
    "filename": "JARVIS-1 Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Minecraft Universe Benchmark"
      ],
      "models": [
        "JARVIS-1",
        "VPT",
        "MineCLIP",
        "Instruct GPT",
        "ReAct",
        "Inner Monologue",
        "DEPS",
        "Steve-1",
        "GPT-4",
        "ChatGPT",
        "LLaMA2 Pre-Trained",
        "LLaMA2 Fine-tuned"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GigaPevt Multimodal Medical Assistant": {
    "filename": "GigaPevt Multimodal Medical Assistant.pdf",
    "analysis": {
      "benchmarks": [
        "RuMedDaNet",
        "RuMedNLI",
        "AffectNet"
      ],
      "models": [
        "GigaPevt",
        "GigaChat",
        "ChatGPT-3.5",
        "LLaMA",
        "OFAMobileNetV3",
        "MobileNet-V1",
        "EfficientNet-B0",
        "ResNet34",
        "POS algorithm"
      ]
    }
  },
  "Quantifying In-Context Reasoning Effects and Memorization Effects in LLMs": {
    "filename": "Quantifying In-Context Reasoning Effects and Memorization Effects in LLMs.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "OPT-1.3B",
        "LLaMA-7B",
        "GPT-3.5-Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Amortizing intractable inference in large language models": {
    "filename": "Amortizing intractable inference in large language models.pdf",
    "analysis": {
      "benchmarks": [
        "OpenWebText",
        "ROCStories",
        "SUBJ"
      ],
      "models": [
        "GFlowNet",
        "GPT-J 6B",
        "GPT-2 XL",
        "GPT-2 Large",
        "PPO",
        "Supervised fine-tuning",
        "Zero-shot prompting",
        "Few-shot prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LANE Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation": {
    "filename": "LANE Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation.pdf",
    "analysis": {
      "benchmarks": [
        "MovieLens",
        "Amazon",
        "Steam"
      ],
      "models": [
        "LANE",
        "GRU4Rec",
        "BERT4Rec",
        "SASRec",
        "LANE-GRU4Rec",
        "LANE-BERT4Rec",
        "LANE-SASRec"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "TSDS Data Selection for Task-Specific Model Finetuning": {
    "filename": "TSDS Data Selection for Task-Specific Model Finetuning.pdf",
    "analysis": {
      "benchmarks": [
        "TydiQA",
        "MMLU",
        "BBH",
        "ChemProt",
        "IMDB",
        "SCIERC",
        "AGNews"
      ],
      "models": [
        "TSDS",
        "BERT",
        "LLaMA",
        "LLAMA-2-7B",
        "MISTRAL-7B",
        "ALBERT",
        "LESS",
        "DSIR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Rx Strategist Prescription Verification using LLM Agents System": {
    "filename": "Rx Strategist Prescription Verification using LLM Agents System.pdf",
    "analysis": {
      "benchmarks": [
        "Active Ingredients Verification Benchmark",
        "Vietnam hospitals dataset"
      ],
      "models": [
        "Rx Strategist",
        "Llama 3.1 (70B)",
        "Qwen2 72B",
        "LLama3.1 family",
        "GPT4o-mini",
        "Claude 3.5 Sonnet",
        "LLama 3.1 8B",
        "LLama 3.1 405B"
      ]
    }
  },
  "Reimagining Retrieval Augmented Language Models for Answering Queries": {
    "filename": "Reimagining Retrieval Augmented Language Models for Answering Queries.pdf",
    "analysis": {
      "benchmarks": [
        "TimelineQA"
      ],
      "models": [
        "POSTTEXT",
        "REALM",
        "RETRO",
        "Atlas",
        "RAG",
        "FiD",
        "GPT-3",
        "T5",
        "Jurassic-1",
        "Gopher",
        "PaLM",
        "Langchain's RetrievalQAwithSources",
        "Langchain's SQL-DatabaseChain",
        "GPT-3.5-turbo",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On Domain-Specific Post-Training for Multimodal Large Language Models": {
    "filename": "On Domain-Specific Post-Training for Multimodal Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "VQA-RAD",
        "SLAKE",
        "PathVQA",
        "PMC-VQA",
        "Recipe1M",
        "Food101",
        "Nutrition5K",
        "FoodSeg103"
      ],
      "models": [
        "AdaMLLM-8B",
        "AdaMLLM-2B",
        "AdaMLLM-11B",
        "Qwen2-VL-2B",
        "LLaVA-v1.6-8B",
        "Llama-3.2-11B",
        "LLaVA-Med-8B",
        "PubMedVision-8B",
        "LLaVA-Med-2B",
        "PubMedVision-2B",
        "LLaVA-Med-11B",
        "PubMedVision-11B",
        "LLaVA-Chef-8B",
        "LLaVA-Chef-2B",
        "LLaVA-Chef-11B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks": {
    "filename": "Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks.pdf",
    "analysis": {
      "benchmarks": [
        "GSM-8K",
        "ASDiv",
        "MATH"
      ],
      "models": [
        "Gemini-Pro",
        "Mixtral 7B \u00d78",
        "PaLM 2-M",
        "GPT-4",
        "Gemini Flash 1.5",
        "GPT 3.5",
        "Gemma 7B",
        "Mistral 7B",
        "Llama 2 7B",
        "Gemma 2B",
        "Qwen 2B",
        "Rho 1B",
        "TinyLlama"
      ]
    }
  },
  "A Knowledge-Injected Curriculum Pretraining Framework for Question Answering": {
    "filename": "A Knowledge-Injected Curriculum Pretraining Framework for Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "CN-QA",
        "ComplexWebQuestions",
        "FreebaseQA",
        "Math23K"
      ],
      "models": [
        "KICP",
        "BERT",
        "RoBERTa",
        "ERNIE",
        "K-BERT",
        "KEPLER",
        "K-Adapter",
        "EmbedKGQA",
        "GPT4",
        "ChatGLM2-6B",
        "KICP-KA",
        "KICP-ATT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Scaling In-Context Demonstrations with Structured Attention": {
    "filename": "Scaling In-Context Demonstrations with Structured Attention.pdf",
    "analysis": {
      "benchmarks": [
        "CrossFit",
        "UnifiedQA"
      ],
      "models": [
        "SAICL",
        "Fusion-in-Decoder (FiD)",
        "T5 baseline",
        "MetaICL",
        "Channel MetaICL",
        "Multi-task 0-shot",
        "Channel Multi-task 0-shot"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Proving Theorems Recursively": {
    "filename": "Proving Theorems Recursively.pdf",
    "analysis": {
      "benchmarks": [
        "miniF2F",
        "PISA"
      ],
      "models": [
        "POETRY",
        "GPT-f Baseline",
        "Thor",
        "PACT",
        "FMSCL",
        "Leandojo",
        "COPRA",
        "Thor + expert iteration",
        "Thor + Magnushammer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Using Large Language Models to Automate and Expedite Reinforcement Learning with Reward Machine": {
    "filename": "Using Large Language Models to Automate and Expedite Reinforcement Learning with Reward Machine.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "LARL-RM",
        "GPT-3.5-Turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MLLM-Tool A Multimodal Large Language Model For Tool Agent Learning": {
    "filename": "MLLM-Tool A Multimodal Large Language Model For Tool Agent Learning.pdf",
    "analysis": {
      "benchmarks": [
        "ToolMMBench"
      ],
      "models": [
        "MLLM-Tool",
        "MetaTool",
        "APIBank",
        "ToolBench",
        "ToolLLM",
        "APIBench",
        "Visual ChatGPT",
        "GPT4Tool",
        "HuggingGPT",
        "Vicuna",
        "Llama",
        "Llama2",
        "Llama2-Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Vision-Language Models in Remote Sensing Current progress and future trends": {
    "filename": "Vision-Language Models in Remote Sensing Current progress and future trends.pdf",
    "analysis": {
      "benchmarks": [
        "RS5M",
        "RSICap",
        "UCM",
        "RSICD",
        "Sydney",
        "TextRS",
        "RSVQA",
        "RSIVQA",
        "CDVQA",
        "RSVG",
        "DIOR-RSVG",
        "NWPU VHR-10",
        "DIOR",
        "FAIR1M",
        "Vaihingen",
        "Zurich Summer",
        "Houston",
        "Pavia",
        "GID",
        "Oxford-102",
        "GF",
        "RSITMD",
        "NWPU-RESISC45",
        "AID",
        "RSSCN7",
        "MillionAID",
        "GeoPile"
      ],
      "models": [
        "BLIP-2",
        "RSGPT",
        "GPT-based model",
        "Visual ChatGPT",
        "RingMo",
        "ViT",
        "Swin Transformer",
        "ViTAE",
        "GFM",
        "VGG-f",
        "AlexNet",
        "VGG",
        "GoogLeNet",
        "CaffeNet",
        "ResNet-101",
        "ResNet-50",
        "CLIP",
        "GPT-2",
        "GAN",
        "D-sGAN",
        "AttnGAN",
        "VQVAE",
        "VQGAN",
        "BiT",
        "SqueezeNet",
        "Inception V3",
        "Bi-GRU",
        "CNN",
        "GRU",
        "Vision Transformer",
        "Darknetz",
        "Faster RCNN",
        "3D-CNN",
        "LSTM",
        "RNN",
        "Transformer",
        "BERT",
        "Word2vec",
        "Fasttext",
        "Glove",
        "DenseNet",
        "ResNeXt",
        "EfficientNet",
        "DeiT",
        "TNT",
        "PVT",
        "Swin",
        "Twins",
        "ViL",
        "VOLO",
        "VisualBERT",
        "Uniter",
        "OSCAR",
        "InterBert",
        "ViLBERT",
        "LXMERT",
        "Visual Parsing",
        "ALBEF",
        "WenLan",
        "VisualGPT",
        "ALIGN",
        "Flamingo",
        "MiniGPT-4",
        "InstructBLIP",
        "LLAVA",
        "VisionLLM",
        "Kosmos",
        "SAM",
        "ChatGPT",
        "GPT-4",
        "BERT",
        "T5",
        "InstructGPT",
        "GPT-2",
        "GPT-3",
        "GPT",
        "RoBERTa",
        "ALBERT",
        "MacBERT",
        "CoT",
        "BEiT",
        "MAE",
        "SimMIM",
        "UNet++",
        "StackGANs",
        "Txt2Img-MHN",
        "Hopfield network",
        "Deep Bidirectional Triplet Network",
        "Big Transfer Model",
        "Visual Big Transfer Model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SarcasmBench Towards Evaluating Large Language Models on Sarcasm Understanding": {
    "filename": "SarcasmBench Towards Evaluating Large Language Models on Sarcasm Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "IAC-V1",
        "IAC-V2",
        "Ghosh",
        "iSarcasmEval",
        "Riloff",
        "SemEval 2018 Task 3"
      ],
      "models": [
        "ChatGPT",
        "GPT-4",
        "Claude 3",
        "Mistral",
        "Baichuan 2",
        "ChatGLM 2",
        "ChatGLM 3",
        "LLaMA 2",
        "LLaMA 3",
        "Qwen 1.5",
        "Qwen 2",
        "BERT",
        "RoBERTa",
        "DeBERT",
        "XLNet",
        "DC-Net-RoBERTa",
        "TextCNN",
        "LSTM",
        "Bi-LSTM",
        "AT-LSTM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Leveraging Large Language Models to Enhance Domain Expert Inclusion in Data Science Workflows": {
    "filename": "Leveraging Large Language Models to Enhance Domain Expert Inclusion in Data Science Workflows.pdf",
    "analysis": {
      "benchmarks": [
        "Students exam scores",
        "Covid-19 world vaccine adverse reactions"
      ],
      "models": [
        "LinearRegression",
        "LogisticRegression",
        "Keras Sequential"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation": {
    "filename": "Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation.pdf",
    "analysis": {
      "benchmarks": [
        "DreamBooth dataset",
        "Wikiart dataset",
        "DiffusionDB dataset"
      ],
      "models": [
        "PRISM",
        "Stable Diffusion",
        "DALL-E",
        "Midjourney",
        "Textual Inversion",
        "PEZ",
        "BLIP2",
        "CLIP-Interrogator",
        "GPT-4V",
        "SDXL-Turbo",
        "Liu et al. (2024)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "MT4CrossOIE Multi-stage Tuning for Cross-lingual Open Information Extraction": {
    "filename": "MT4CrossOIE Multi-stage Tuning for Cross-lingual Open Information Extraction.pdf",
    "analysis": {
      "benchmarks": [
        "OpenIE4++",
        "Re-OIE2016",
        "CaRB",
        "BenchIE"
      ],
      "models": [
        "MT4CrossOIE",
        "Multi2OIE",
        "Stanford",
        "ClausIE",
        "MinIE",
        "RnnOIE",
        "SpanOIE",
        "IMoJIE",
        "CIGL",
        "OpenIE6",
        "ArgOE",
        "PredPatt"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "EACO Enhancing Alignment in Multimodal LLMs via Critical Observation": {
    "filename": "EACO Enhancing Alignment in Multimodal LLMs via Critical Observation.pdf",
    "analysis": {
      "benchmarks": [
        "HallusionBench",
        "MME-Cognition",
        "MME",
        "SEED-Bench",
        "ScienceQA",
        "MathVista",
        "POPE",
        "AMBER"
      ],
      "models": [
        "LLaV A-v1.6 7B",
        "LLaV A-v1.6 7B w/ EACO",
        "LLaV A-RLHF",
        "Silkie",
        "SIMA",
        "STIC",
        "EACO",
        "LLaV A-v1.6-Mistral-7B",
        "Bunny-8B",
        "MiniCPM-V2.6 8B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Assessing Student Errors in Experimentation Using Artificial Intelligence and Large Language Models A Comparative Study with Human Raters": {
    "filename": "Assessing Student Errors in Experimentation Using Artificial Intelligence and Large Language Models A Comparative Study with Human Raters.pdf",
    "analysis": {
      "benchmarks": [
        "student protocols dataset"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "GPT-3",
        "ChatGPT",
        "LaMDA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Dont Let Your Robot be Harmful Responsible Robotic Manipulation": {
    "filename": "Dont Let Your Robot be Harmful Responsible Robotic Manipulation.pdf",
    "analysis": {
      "benchmarks": [
        "SafeBox"
      ],
      "models": [
        "Safety-as-policy",
        "CAP",
        "VP",
        "GFR",
        "FAR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Answering Unseen Questions With Smaller Language Models Using Rationale Generation and Dense Retrieval": {
    "filename": "Answering Unseen Questions With Smaller Language Models Using Rationale Generation and Dense Retrieval.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA",
        "CommonsenseQA",
        "ARC-DA",
        "IIRC",
        "Musique"
      ],
      "models": [
        "Rationale Ranking (RR) model",
        "Reasoning model",
        "Iterator",
        "BLOOM 175B",
        "StableVicuna 13B",
        "GR model",
        "GR+RATD model",
        "RATD model"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RAG-Modulo Solving Sequential Tasks using Experience Critics and Language Models": {
    "filename": "RAG-Modulo Solving Sequential Tasks using Experience Critics and Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "BabyAI",
        "AlfWorld"
      ],
      "models": [
        "RAG-Modulo",
        "ProgPrompt",
        "LLM-Planner"
      ]
    }
  },
  "Legal Syllogism Prompting Teaching Large Language Models for Legal Judgment Prediction": {
    "filename": "Legal Syllogism Prompting Teaching Large Language Models for Legal Judgment Prediction.pdf",
    "analysis": {
      "benchmarks": [
        "CAIL2018"
      ],
      "models": [
        "GPT-3",
        "Legal syllogism prompting (LoT)",
        "Zero-shot chain-of-thought (Zero-shot CoT)",
        "Baseline zero-shot prompting"
      ]
    }
  },
  "Exploring the Effectiveness of LLMs in Automated Logging Generation An Empirical Study": {
    "filename": "Exploring the Effectiveness of LLMs in Automated Logging Generation An Empirical Study.pdf",
    "analysis": {
      "benchmarks": [
        "LogBench-O",
        "LogBench-T"
      ],
      "models": [
        "Davinci",
        "ChatGPT",
        "Llama2",
        "LANCE",
        "InCoder",
        "CodeGeex",
        "TabNine",
        "Copilot",
        "CodeWhisperer",
        "CodeLlama",
        "StarCoder",
        "DeepLV",
        "WhichVar",
        "LoGenText-Plus"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VCoME Verbal Video Composition with Multimodal Editing Effects": {
    "filename": "VCoME Verbal Video Composition with Multimodal Editing Effects.pdf",
    "analysis": {
      "benchmarks": [
        "Jianying"
      ],
      "models": [
        "VCoME",
        "BERT",
        "Large Multimodal Model (LMM)",
        "LLaV A",
        "CLIP-ViT-L/14",
        "ImageBind",
        "Chinese-LLaMA-2",
        "LLaV A-vicuna"
      ]
    }
  },
  "Reflexion language agents with verbal reinforcement learning": {
    "filename": "Reflexion language agents with verbal reinforcement learning.pdf",
    "analysis": {
      "benchmarks": [
        "HumanEval",
        "AlfWorld",
        "HotPotQA",
        "MBPP",
        "LeetcodeHardGym"
      ],
      "models": [
        "Reflexion",
        "GPT-4",
        "ReAct",
        "Chain of Thought",
        "CodeT",
        "AlphaCode",
        "Self-Debugging",
        "CodeRL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ISR-LLM Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning": {
    "filename": "ISR-LLM Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning.pdf",
    "analysis": {
      "benchmarks": [
        "Cooking",
        "Blocksworld",
        "Ball Moving"
      ],
      "models": [
        "ISR-LLM",
        "ISR-LLM-self",
        "ISR-LLM-external",
        "LLM-direct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CausalBench A Comprehensive Benchmark for Causal Learning Capability of LLMs": {
    "filename": "CausalBench A Comprehensive Benchmark for Causal Learning Capability of LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "CausalBench",
        "Asia",
        "Cancer",
        "Earthquake",
        "Survey",
        "Sachs",
        "Child",
        "Insurance",
        "Water",
        "Mildew",
        "Alarm",
        "Barley",
        "Hailfinder",
        "Hepar II",
        "Win95PTS",
        "Pathfinder"
      ],
      "models": [
        "GPT3.5-Turbo",
        "GPT4",
        "GPT4-Turbo",
        "BERT-large",
        "RoBERTa-large",
        "DeBERTa-large",
        "DistilBERT-mnli",
        "LLAMA-7B",
        "LLAMA-13B",
        "LLAMA-33B",
        "OPT-1.3B",
        "OPT-2.7B",
        "OPT-6.7B",
        "OPT-66B",
        "InternLM-7B",
        "InternLM-20B",
        "Falcon-7B",
        "Falcon-40B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers": {
    "filename": "Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers.pdf",
    "analysis": {
      "benchmarks": [
        "T0 Eval",
        "MMLU",
        "GLUE"
      ],
      "models": [
        "T5",
        "METRO-T0",
        "T0",
        "ELECTRA",
        "COCO-LM",
        "METRO-LM",
        "GPT-3",
        "Flan-T5",
        "T0 11B",
        "T0 3B",
        "T0 base++",
        "METRO-T0 base++",
        "METRO-T0 large++"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "DERA Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents": {
    "filename": "DERA Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents.pdf",
    "analysis": {
      "benchmarks": [
        "MedQA",
        "USMLE",
        "New England Journal of Medicine Test Questions",
        "NEJM"
      ],
      "models": [
        "DERA",
        "GPT-4",
        "RoBERTa",
        "PaLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating Cognitive Maps and Planning in Large Language Models with CogEval": {
    "filename": "Evaluating Cognitive Maps and Planning in Large Language Models with CogEval.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "OpenAI GPT-4",
        "GPT-3.5-turbo-175B",
        "davinci-003-175B",
        "Google Bard",
        "Cohere-xlarge-52.4B",
        "Anthropic Claude-1-52B",
        "LLaMA-13B",
        "Alpaca-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Model for Table Processing A Survey": {
    "filename": "Large Language Model for Table Processing A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "WikiTableQuestions",
        "WikiSQL",
        "SQA",
        "Spider",
        "ScienceBenchmark",
        "SheetCopilot",
        "SpreadsheetBench",
        "DS-1000",
        "InfiAgent-DABench",
        "Tapilot-Crossing",
        "AnaMeta",
        "GitTables",
        "SchemaPile",
        "ComplexTable"
      ],
      "models": [
        "TaBERT",
        "TaPas",
        "TURL",
        "TaPEx",
        "BERT",
        "BART",
        "TableLlama",
        "Table-GPT",
        "Magicoder",
        "Lemur",
        "DAAgent",
        "SENSE",
        "FinSQL",
        "TableLLM",
        "StructLM",
        "ZeroNL2SQL",
        "Table-LLaVA",
        "TableVLM",
        "TabPedia",
        "PixT3",
        "SheetAgent",
        "Chain-of-Table",
        "ReAcTable",
        "TAPERA",
        "E5",
        "DIN-SQL",
        "DEA-SQL",
        "TabSQLify",
        "Dater",
        "Binder",
        "SheetCopilot",
        "DataCopilot",
        "StructGPT",
        "UniDM",
        "TAP4LLM",
        "ChatPipe"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Lemur Log Parsing with Entropy Sampling and Chain-of-Thought Merging": {
    "filename": "Lemur Log Parsing with Entropy Sampling and Chain-of-Thought Merging.pdf",
    "analysis": {
      "benchmarks": [
        "HDFS",
        "Hadoop",
        "Spark",
        "Zookeeper",
        "BGL",
        "HPC",
        "Thunderbird",
        "Windows",
        "Linux",
        "Andriod",
        "HealthApp",
        "Apache",
        "Proxifier",
        "OpenSSH",
        "OpenStack",
        "Mac"
      ],
      "models": [
        "LEMUR",
        "Drain",
        "Spell",
        "IPLOM",
        "ULP",
        "Brain",
        "LogPPT",
        "LLMParser"
      ]
    }
  },
  "Think-Program-reCtify 3D Situated Reasoning with Large Language Models": {
    "filename": "Think-Program-reCtify 3D Situated Reasoning with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SQA3D"
      ],
      "models": [
        "LLM-TPC",
        "ScanQA",
        "3D-VisTA",
        "3D-LLM",
        "LEO",
        "LLM-T"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Shortcut Learning of Large Language Models in Natural Language Understanding": {
    "filename": "Shortcut Learning of Large Language Models in Natural Language Understanding.pdf",
    "analysis": {
      "benchmarks": [
        "MNLI",
        "HANS",
        "Adversarial NLI (ANLI)",
        "GLUE",
        "PAWS"
      ],
      "models": [
        "BERT",
        "RoBERTa",
        "T5",
        "GPT-3",
        "ELECTRA",
        "BERT-base",
        "BERT-large",
        "RoBERTa-base",
        "RoBERTa-large",
        "GPT-2",
        "T0"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Merge Then Compress Demystify Efficient SMoE with Hints from Its Routing Policy": {
    "filename": "Merge Then Compress Demystify Efficient SMoE with Hints from Its Routing Policy.pdf",
    "analysis": {
      "benchmarks": [
        "COPA",
        "SQuAD",
        "WikiQA",
        "SST2",
        "MRPC",
        "MultiRC",
        "WinoGrande",
        "HotpotQA",
        "OpenBookQA"
      ],
      "models": [
        "MC-SMoE",
        "M-SMoE",
        "SMoE",
        "switch-base-32",
        "t5-base",
        "fairseq-moe-15b",
        "fairseq-dense-125m",
        "Averaging",
        "ZipIt",
        "REPAIR",
        "Git Re-basin"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Recursive Search A Living Framework with Adaptive Growth in LLM Auto-Prompting": {
    "filename": "Prompt Recursive Search A Living Framework with Adaptive Growth in LLM Auto-Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "BBH"
      ],
      "models": [
        "Prompt Recursive Search (PRS)",
        "Chain of Thought (CoT)",
        "Yi-34B",
        "Meta-Llama-3-8B",
        "Llama3-7B"
      ]
    }
  },
  "From Words to Wires Generating Functioning Electronic Devices from Natural Language Descriptions": {
    "filename": "From Words to Wires Generating Functioning Electronic Devices from Natural Language Descriptions.pdf",
    "analysis": {
      "benchmarks": [
        "PINS100",
        "MICRO 25"
      ],
      "models": [
        "GPT-4",
        "Claude-V1"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Improving Self Consistency in LLMs through Probabilistic Tokenization": {
    "filename": "Improving Self Consistency in LLMs through Probabilistic Tokenization.pdf",
    "analysis": {
      "benchmarks": [
        "MATH",
        "AQuA",
        "GSM8k",
        "PIQA"
      ],
      "models": [
        "MISTRAL-7B",
        "OLMO-7B",
        "MAMBA-2.8B",
        "GEMMA-2B",
        "GEMMA-7B",
        "LLAMA3-8B",
        "LLAMA3-70B"
      ]
    }
  },
  "SwarmBrain Embodied agent for real-time strategy game StarCraft II via large language models": {
    "filename": "SwarmBrain Embodied agent for real-time strategy game StarCraft II via large language models.pdf",
    "analysis": {
      "benchmarks": [
        "StarCraft II"
      ],
      "models": [
        "SwarmBrain",
        "Overmind Intelligence Matrix",
        "Swarm ReflexNet",
        "gpt-3.5-turbo",
        "gpt-4.0-turbo"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Is Knowledge All Large Language Models Needed for Causal Reasoning": {
    "filename": "Is Knowledge All Large Language Models Needed for Causal Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Galton",
        "Sachs",
        "Alcohol",
        "EcoSystem",
        "MPG",
        "DWD",
        "Cement",
        "Stock",
        "Arrhythmia"
      ],
      "models": [
        "causal attribution model",
        "fine-tuned LLM for pairwise causal discovery",
        "GPT-4 turbo",
        "GPT-4",
        "GPT-3.5",
        "Claude 2",
        "LLaMa2-13B",
        "Mistral-7B-v0.2",
        "Finetuned Mistral-7B-v0.2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue": {
    "filename": "User Simulation with Large Language Models for Evaluating Task-Oriented Dialogue.pdf",
    "analysis": {
      "benchmarks": [
        "MultiWOZ",
        "Schema-Guided Dialogue (SGD)",
        "Human2Bot"
      ],
      "models": [
        "GPTNeoX-20B",
        "GPT3",
        "BLOOM",
        "AlexaTM-20B",
        "PPTOD",
        "Soloist",
        "ConvLab2 TUS",
        "MetaSim"
      ]
    }
  },
  "The Opportunities and Risks of Large Language Models in Mental Health": {
    "filename": "The Opportunities and Risks of Large Language Models in Mental Health.pdf",
    "analysis": {
      "benchmarks": [
        "American College of Obstetricians and Gynecologists (ACOG) frequently asked questions document",
        "DSM-5 (Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition) case examples"
      ],
      "models": [
        "ChatGPT",
        "Gemini",
        "Med-LM",
        "Psy-LLM",
        "GPT-4",
        "LaMDA",
        "Bard",
        "MentalBERT",
        "MentalRoBERTa",
        "Mental-Alpaca",
        "Med-PaLM 2",
        "PaLM 2",
        "Woebot",
        "Wysa",
        "Tess",
        "Replika",
        "Ellie",
        "Sibly"
      ]
    }
  },
  "GUARD-D-LLM An LLM-Based Risk Assessment Engine for the Downstream uses of LLMs": {
    "filename": "GUARD-D-LLM An LLM-Based Risk Assessment Engine for the Downstream uses of LLMs.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GUARD-D-LLM",
        "GPT4",
        "LLama2",
        "Falcon",
        "Mistral"
      ]
    }
  },
  "Talking about Large Language Models": {
    "filename": "Talking about Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "BERT",
        "GPT-2",
        "GPT-3",
        "Gopher",
        "PaLM",
        "ChatGPT",
        "VilBERT",
        "Flamingo",
        "SayCan"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Ask Again Then Fail Large Language Models Vacillations in Judgement": {
    "filename": "Ask Again Then Fail Large Language Models Vacillations in Judgement.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "SVAMP",
        "MultiArith",
        "CSQA",
        "StrategyQA",
        "Last Letter Concatenation",
        "Coin Flip",
        "MMLU"
      ],
      "models": [
        "ChatGPT",
        "Vicuna-13B",
        "GPT-4",
        "PaLM2-Bison",
        "UNWAVERING-FQ"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Autonomous Industrial Control using an Agentic Framework with Large Language Models": {
    "filename": "Autonomous Industrial Control using an Agentic Framework with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "TCLab"
      ],
      "models": [
        "GPT3.5",
        "GPT4omini",
        "GPT4o",
        "GPT4"
      ]
    }
  },
  "Interpretable Video based Stress Detection with Self-Refine Chain-of-thought Reasoning": {
    "filename": "Interpretable Video based Stress Detection with Self-Refine Chain-of-thought Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "UVSD",
        "RSL"
      ],
      "models": [
        "Interpretable Video-based Stress Detection Model",
        "FDASSNN",
        "Gao et al.",
        "Zhang et al.",
        "Jeon et al.",
        "TSDNet",
        "MARLIN",
        "Singh et al.",
        "Ding et al.",
        "GPT-4o",
        "Claude-3.5",
        "Gemini-1.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "An Investigation of LLMs Inefficacy in Understanding Converse Relations": {
    "filename": "An Investigation of LLMs Inefficacy in Understanding Converse Relations.pdf",
    "analysis": {
      "benchmarks": [
        "ConvRe",
        "WN18RR",
        "FB15K-237",
        "Wikidata5M",
        "NELL-ONE",
        "ICEWS14",
        "ConceptNet5"
      ],
      "models": [
        "OpenAI GPT-3",
        "Anthropic Claude",
        "Google Flan-T5",
        "GPT-3.5",
        "GPT-4",
        "Claude-1",
        "Claude-instant-1",
        "Flan-T5-Small",
        "Flan-T5-Base",
        "Flan-T5-Large",
        "Flan-T5-XL",
        "Flan-T5-XXL"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Hierarchical Prompting Assists Large Language Model on Web Navigation": {
    "filename": "Hierarchical Prompting Assists Large Language Model on Web Navigation.pdf",
    "analysis": {
      "benchmarks": [
        "Webshop"
      ],
      "models": [
        "ASH",
        "REACT",
        "CODE-DAVINCI-002",
        "GPT-3.5-TURBO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SuRe Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs": {
    "filename": "SuRe Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Questions",
        "WebQuestions",
        "2WikiMulti-hopQA",
        "HotpotQA"
      ],
      "models": [
        "SURE",
        "ChatGPT",
        "LLaMA",
        "GLaM",
        "PaLM",
        "Contriever",
        "BM25",
        "DPR",
        "GPT-4",
        "LLaMA2-chat",
        "Base",
        "Rerank",
        "RePlug",
        "Selection-inference",
        "Chain-of-thoughts",
        "Self-verification"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chatbot is Not All You Need Information-rich Prompting for More Realistic Responses": {
    "filename": "Chatbot is Not All You Need Information-rich Prompting for More Realistic Responses.pdf",
    "analysis": {
      "benchmarks": [
        "Cornell Movie-Dialog Corpus",
        "Dialogue-Emotion-Attributes-Relationship (DEAR) dataset"
      ],
      "models": [
        "GPT-3.5 Turbo",
        "GPT raw",
        "GPT sense",
        "GPT emotion",
        "GPT memory",
        "GPT interlocutor",
        "GPT full"
      ]
    }
  },
  "Playing repeated games with Large Language Models": {
    "filename": "Playing repeated games with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Prisoner's Dilemma",
        "Battle of the Sexes"
      ],
      "models": [
        "GPT-3",
        "GPT-3.5",
        "GPT-4"
      ]
    }
  },
  "Can GPT models be Financial Analysts An Evaluation of ChatGPT and GPT-4 on mock CFA Exams": {
    "filename": "Can GPT models be Financial Analysts An Evaluation of ChatGPT and GPT-4 on mock CFA Exams.pdf",
    "analysis": {
      "benchmarks": [
        "CFA Level I mock exams",
        "CFA Level II mock exams"
      ],
      "models": [
        "ChatGPT",
        "GPT-4"
      ]
    }
  },
  "Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V": {
    "filename": "Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V.pdf",
    "analysis": {
      "benchmarks": [
        "real-world tabletop and manipulation tasks",
        "real-world bedroom",
        "OVMM tasks"
      ],
      "models": [
        "COME-robot",
        "Code as Policies (CaP)",
        "CaP*"
      ]
    }
  },
  "Details Make a Difference Object State-Sensitive Neurorobotic Task Planning": {
    "filename": "Details Make a Difference Object State-Sensitive Neurorobotic Task Planning.pdf",
    "analysis": {
      "benchmarks": [
        "clear the table",
        "Object State Detection Dataset"
      ],
      "models": [
        "Object State-Sensitive Agent (OSSA)",
        "modular model with dense captioning model (DCM) and LLM",
        "monolithic model with VLM",
        "GRiT",
        "GPT-4V",
        "OSSA-LLM-GRiT",
        "OSSA-LLM-GPT-4V",
        "OSSA-VLM"
      ]
    }
  },
  "Generating consistent PDDL domains with Large Language Models": {
    "filename": "Generating consistent PDDL domains with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "gripper",
        "logistics",
        "tyreworld",
        "household",
        "pizza"
      ],
      "models": [
        "OpenAI GPT-4 (gpt-4-0125-preview)"
      ]
    }
  },
  "Foundation Models in Robotics Applications Challenges and the Future": {
    "filename": "Foundation Models in Robotics Applications Challenges and the Future.pdf",
    "analysis": {
      "benchmarks": [
        "Ego4D",
        "EPIC-KITCHENS"
      ],
      "models": [
        "CLIPort",
        "Play-LMP",
        "PerAct",
        "Multi-Context Imitation",
        "CACTI",
        "Voltron",
        "Adaptive Agent (AdA)",
        "Palo et al.",
        "R3M",
        "VIP",
        "LIV"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Large Language Models Can be Lazy Learners Analyze Shortcuts in In-Context Learning": {
    "filename": "Large Language Models Can be Lazy Learners Analyze Shortcuts in In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "SST2",
        "MR",
        "CR",
        "OLID",
        "ATIS",
        "MIT Movies trivia10k13"
      ],
      "models": [
        "GPT2 base",
        "GPT2 large",
        "OPT-1.3B",
        "OPT-2.7B",
        "OPT-6.7B",
        "OPT-13B"
      ]
    }
  },
  "Active Preference Inference using Language Models and Probabilistic Reasoning": {
    "filename": "Active Preference Inference using Language Models and Probabilistic Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "WebShop"
      ],
      "models": [
        "entropy reduction LLM",
        "vanilla instruction-tuned LLM",
        "ReAct LLM"
      ]
    }
  },
  "Tokenization Matters Degrading Large Language Models through Challenging Their Tokenization": {
    "filename": "Tokenization Matters Degrading Large Language Models through Challenging Their Tokenization.pdf",
    "analysis": {
      "benchmarks": [
        "ADT-Human",
        "ADT-Auto"
      ],
      "models": [
        "GPT-4o",
        "Llama-3",
        "Qwen2.5-max",
        "Chatglm3",
        "Baichuan2",
        "Yi",
        "Qwen",
        "GPT-4",
        "GPT-3.5-Turbo",
        "step-1-8k",
        "moonshot-v1-8k",
        "ERNIE-3.5-8K",
        "Mixtral"
      ]
    }
  },
  "CLAVE An Adaptive Framework for Evaluating Values of LLM Generated Responses": {
    "filename": "CLAVE An Adaptive Framework for Evaluating Values of LLM Generated Responses.pdf",
    "analysis": {
      "benchmarks": [
        "ValEval",
        "BeaverTails",
        "Do-not-Answer",
        "Value Fulcra",
        "DenEvil",
        "Moral Stories"
      ],
      "models": [
        "CLA VE",
        "GPT-4",
        "Mistral-7B (tuned)",
        "ChatGPT",
        "GPT-2-Large",
        "Phi-3",
        "Llama-2-7b-chat",
        "Mistral-7b",
        "Vanilla",
        "Few-shot",
        "Chain-of-thought",
        "G-Eval",
        "FairEval",
        "ChatEval",
        "WideDeep",
        "Calibrate",
        "Allure"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Data-Efficient 3D Visual Grounding via Order-Aware Referring": {
    "filename": "Data-Efficient 3D Visual Grounding via Order-Aware Referring.pdf",
    "analysis": {
      "benchmarks": [
        "NR3D",
        "ScanRefer"
      ],
      "models": [
        "Vigor",
        "Referit3D",
        "ScanRefer",
        "TransRefer3D",
        "SAT",
        "BUTD-DETR",
        "MVT",
        "MVT + CoT3DRef",
        "ViL3DRel + CoT3DRef",
        "3DVG-Trans.",
        "3D-SPS",
        "M3DRef-CLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CoRAL Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation": {
    "filename": "CoRAL Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation.pdf",
    "analysis": {
      "benchmarks": [
        "Amazon Product - Appliances",
        "Amazon Product - Gift Cards",
        "Amazon Product - Prime Pantry",
        "Amazon Product - Software"
      ],
      "models": [
        "CoRAL",
        "AFM",
        "DCN",
        "DFM",
        "WDL",
        "IPS",
        "CausE",
        "LLM-Language",
        "CoRAL-random",
        "CoRAL-DFM",
        "CoRAL-WDL",
        "CoRAL-AFM",
        "CoRAL-DCN"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Chemistry Learning with ChatGPT and Bing Chat as Agents to Think With A Comparative Case Study": {
    "filename": "Enhancing Chemistry Learning with ChatGPT and Bing Chat as Agents to Think With A Comparative Case Study.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT",
        "Bing Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context": {
    "filename": "Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT-4.0-Turbo",
        "Claude-3-Opus",
        "Gemini-1.0-pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Keypoint Abstraction using Large Models for Object-Relative Imitation Learning": {
    "filename": "Keypoint Abstraction using Large Models for Object-Relative Imitation Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Meta-World"
      ],
      "models": [
        "KALM",
        "Diffuser",
        "3D Diffuser Actor",
        "Diffuser with keypoints",
        "3D Diffuser Actor with keypoints"
      ]
    }
  },
  "Towards Foundational AI Models for Additive Manufacturing Language Models for G-Code Debugging Manipulation and Comprehension": {
    "filename": "Towards Foundational AI Models for Additive Manufacturing Language Models for G-Code Debugging Manipulation and Comprehension.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "Bard",
        "Claude-2",
        "Llama-2-70b",
        "Starcoder"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Securing Reliability A Brief Overview on Enhancing In-Context Learning for Foundation Models": {
    "filename": "Securing Reliability A Brief Overview on Enhancing In-Context Learning for Foundation Models.pdf",
    "analysis": {
      "benchmarks": [
        "CC",
        "DC",
        "BC",
        "WebCP",
        "MathChat",
        "LeanDojo",
        "DTV",
        "SeeGULL"
      ],
      "models": [
        "BERT",
        "T5",
        "GPT-3",
        "GPT-3.5",
        "PaLM2",
        "Claude2",
        "Llama2",
        "Vicuna",
        "ChatGLM3",
        "Mistral",
        "CLIP",
        "DALL-E3",
        "GPT4",
        "Gemini",
        "RLPrompt",
        "PromptGen",
        "UniPrompt",
        "LaMDA",
        "SmoothLLM",
        "RPO"
      ]
    }
  },
  "Satisfiability-Aided Language Models Using Declarative Prompting": {
    "filename": "Satisfiability-Aided Language Models Using Declarative Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "GSM",
        "GSM-SYS",
        "ALGEBRA",
        "LSAT",
        "BOARDGAME QA",
        "CLUTRR",
        "PROOF WRITER",
        "COLOR",
        "STREGEX"
      ],
      "models": [
        "SATLM",
        "COT",
        "PROGLM",
        "STANDARD",
        "SATCOTSOLVER",
        "SATNOSOLVER",
        "SATSYMSOLVER"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMeBench A Flexible Framework for Accelerating LLMs Benchmarking": {
    "filename": "LLMeBench A Flexible Framework for Accelerating LLMs Benchmarking.pdf",
    "analysis": {
      "benchmarks": [
        "WikiNews",
        "XNLI",
        "QASR",
        "XQuAD",
        "MADAR",
        "ANERcorp",
        "XGLUE",
        "Aqmar",
        "SANAD",
        "Conll2006",
        "ASAD"
      ],
      "models": [
        "GPT-3.5-Turbo",
        "GPT-4",
        "BLOOMZ 176B",
        "JAIS",
        "LLama2"
      ]
    }
  },
  "WOMD-Reasoning A Large-Scale Dataset and Benchmark for Interaction and Intention Reasoning in Driving": {
    "filename": "WOMD-Reasoning A Large-Scale Dataset and Benchmark for Interaction and Intention Reasoning in Driving.pdf",
    "analysis": {
      "benchmarks": [
        "WOMD-Reasoning",
        "BDD-X",
        "DriveLM",
        "DRAMA",
        "nuScenes-QA"
      ],
      "models": [
        "Motion-LLaVA",
        "LLaVA",
        "MultiPath++"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Watch Out for Your Agents Investigating Backdoor Threats to LLM-Based Agents": {
    "filename": "Watch Out for Your Agents Investigating Backdoor Threats to LLM-Based Agents.pdf",
    "analysis": {
      "benchmarks": [
        "AgentInstruct",
        "ToolBench",
        "WebShop"
      ],
      "models": [
        "Query-Attack",
        "Observation-Attack",
        "Thought-Attack",
        "Clean",
        "Clean\u2020",
        "Query-Attack-0.3%/1.4%",
        "Query-Attack-0.5%/2.8%",
        "Query-Attack-1.1%/5.4%",
        "Query-Attack-1.6%/7.9%",
        "Query-Attack-2.1%/10.2%",
        "Query-Attack-2.6%/12.5%",
        "Observation-Attack-0.3%/1.4%",
        "Observation-Attack-0.5%/2.8%",
        "Observation-Attack-1.1%/5.4%",
        "Observation-Attack-1.6%/7.9%",
        "Observation-Attack-2.1%/10.2%",
        "Observation-Attack-2.6%/12.5%",
        "Thought-Attack-0.5%/25%",
        "Thought-Attack-1.0%/50%",
        "Thought-Attack-1.4%/75%",
        "Thought-Attack-1.9%/100%"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ALCM Autonomous LLM-Augmented Causal Discovery Framework": {
    "filename": "ALCM Autonomous LLM-Augmented Causal Discovery Framework.pdf",
    "analysis": {
      "benchmarks": [
        "Asia",
        "Cancer",
        "Child",
        "Insurance",
        "Sachs",
        "Sangiovese",
        "Neuropathic"
      ],
      "models": [
        "ALCM",
        "PC",
        "LiNGAM",
        "ALCM-PC",
        "ALCM-Hybrid",
        "LLMs-based approach"
      ]
    }
  },
  "NeMo Guardrails A Toolkit for Controllable and Safe LLM Applications with Programmable Rails": {
    "filename": "NeMo Guardrails A Toolkit for Controllable and Safe LLM Applications with Programmable Rails.pdf",
    "analysis": {
      "benchmarks": [
        "Banking dataset",
        "Anthropic Red-Teaming dataset",
        "Helpful dataset",
        "MS-MARCO dataset"
      ],
      "models": [
        "NeMo Guardrails",
        "falcon-7b-instruct",
        "llama2-13b-chat",
        "gpt-3.5-turbo",
        "text-davinci-003"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "OCTO A Suite for Automatic Open-Vocabulary Object Placement in Mixed Reality": {
    "filename": "OCTO A Suite for Automatic Open-Vocabulary Object Placement in Mixed Reality.pdf",
    "analysis": {
      "benchmarks": [
        "PEARL",
        "NYU Depth Dataset",
        "Sun3D Dataset"
      ],
      "models": [
        "OCTO+",
        "OCTOPUS",
        "GPT-4V",
        "RAM++",
        "SCP",
        "ViLT",
        "CLIPSeg",
        "Grounding DINO",
        "LLaVa-1.5-13B",
        "InstructPix2Pix",
        "Shap-E"
      ]
    }
  },
  "Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions": {
    "filename": "Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "error": "Failed to parse GPT response as JSON after 3 attempts: Invalid JSON format: line 1 column 1 (char 0)"
    }
  },
  "RT-2 Vision-Language-Action Models Transfer Web Knowledge to Robotic Control": {
    "filename": "RT-2 Vision-Language-Action Models Transfer Web Knowledge to Robotic Control.pdf",
    "analysis": {
      "benchmarks": [
        "Language-Table"
      ],
      "models": [
        "RT-2",
        "RT-2-PaLI-X",
        "RT-2-PaLM-E",
        "RT-1",
        "VC-1",
        "R3M",
        "MOO",
        "BC-Zero",
        "LAVA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AWT Transferring Vision-Language Models via Augmentation Weighting and Transportation": {
    "filename": "AWT Transferring Vision-Language Models via Augmentation Weighting and Transportation.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "Caltech101",
        "Caltech256",
        "OxfordPets",
        "StanfordCars",
        "OxfordFlowers",
        "Food101",
        "FGVCAircraft",
        "Birdsnap",
        "CUB",
        "SUN397",
        "DTD",
        "EuroSAT",
        "UCF101",
        "ImageNet-A",
        "ImageNetV2",
        "ImageNet-R",
        "ImageNet-Sketch",
        "CIFAR-10",
        "CIFAR-100",
        "HMDB51",
        "Kinetics-600"
      ],
      "models": [
        "AWT",
        "CLIP",
        "CoOp",
        "CoCoOp",
        "MaPLe",
        "PLOT++",
        "POMP",
        "ProVP-Ref",
        "TPT",
        "DiffTPT",
        "PromptAlign",
        "Self-TPT-v",
        "CuPL",
        "VisDesc",
        "WaffleCLIP",
        "SuS-X-SD",
        "ActionCLIP",
        "X-CLIP",
        "Text4Vis",
        "AIM",
        "ST-Adapter",
        "Vita-CLIP",
        "ViFi-CLIP",
        "AdaptFormer",
        "Open-VCLIP",
        "FROSTER"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "RobuT A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations": {
    "filename": "RobuT A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations.pdf",
    "analysis": {
      "benchmarks": [
        "ROBUT",
        "WTQ",
        "WIKISQL-WEAK",
        "SQA"
      ],
      "models": [
        "TAPAS",
        "TableFormer",
        "TAPEX",
        "OmniTab",
        "GPT-3",
        "CodeX",
        "LETA",
        "TaBERT-Small"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cheap Learning Maximising Performance of Language Models for Social Data Science Using Minimal Data": {
    "filename": "Cheap Learning Maximising Performance of Language Models for Social Data Science Using Minimal Data.pdf",
    "analysis": {
      "benchmarks": [
        "Wikipedia Talk: Personal Attacks",
        "IMDb Movie Review Sentiment",
        "TMDB"
      ],
      "models": [
        "Na\u00efve Bayes",
        "LabelModel",
        "DistilBERT",
        "DeBERTa-v3",
        "GPT-2",
        "GPT-3",
        "GPT-3.5",
        "GPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GSM-Symbolic Understanding the Limitations of Mathematical Reasoning in Large Language Models": {
    "filename": "GSM-Symbolic Understanding the Limitations of Mathematical Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "error": "Encountered text corresponding to disallowed special token '<|endoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
    }
  },
  "Text Encoders Lack Knowledge Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity": {
    "filename": "Text Encoders Lack Knowledge Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity.pdf",
    "analysis": {
      "benchmarks": [
        "STS12",
        "STS13",
        "STS14",
        "STS15",
        "STS16",
        "STS-B",
        "SICK-R",
        "STS-Sports",
        "STS-Health",
        "STS-News"
      ],
      "models": [
        "ChatGPT",
        "Llama2-7b",
        "RoBERTa-base",
        "RoBERTa-large",
        "SBERT",
        "SimCSE-BERT-B",
        "SimCSE-RoBERTa-L",
        "GenSE+"
      ]
    }
  },
  "Enhancing LLM-based Autonomous Driving Agents to Mitigate Perception Attacks": {
    "filename": "Enhancing LLM-based Autonomous Driving Agents to Mitigate Perception Attacks.pdf",
    "analysis": {
      "benchmarks": [
        "CARLA"
      ],
      "models": [
        "HUDSON",
        "GPT-4",
        "Llama-3-8B",
        "Gemma-1.1-7B",
        "AgentDriver",
        "DiLu",
        "GPT-Driver",
        "LLM-Assist"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "AgentKit Structured LLM Reasoning with Dynamic Graphs": {
    "filename": "AgentKit Structured LLM Reasoning with Dynamic Graphs.pdf",
    "analysis": {
      "benchmarks": [
        "Crafter",
        "WebShop"
      ],
      "models": [
        "AgentKit",
        "SPRING (GPT-4)",
        "DreamerV3",
        "EDE",
        "DreamerV2",
        "SPRING (GPT-4-turbo on official repo)",
        "ELLM",
        "Rainbow",
        "PPO",
        "CoT (GPT-4-turbo)",
        "Plan2Explore",
        "RND",
        "Random",
        "PaLM-540BReAct",
        "PaLM-540BAgentBench",
        "Best of GPT-4/3.5"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ThoughtSource A central hub for large language model reasoning data": {
    "filename": "ThoughtSource A central hub for large language model reasoning data.pdf",
    "analysis": {
      "benchmarks": [
        "WorldTree V2",
        "EntailmentBank",
        "OpenBookQA",
        "MedQA (USMLE)",
        "MedMCQA",
        "PubmedQA",
        "MMLU",
        "CommonsenseQA",
        "StrategyQA",
        "QED",
        "AQUA-RAT",
        "ASDiv",
        "GSM8K",
        "MAWPS",
        "SVAMP"
      ],
      "models": [
        "GPT-4",
        "T0",
        "GPT-3",
        "InstructGPT",
        "text-davinci-002",
        "code-davinci-002",
        "text-davinci-003",
        "GPT-3.5-turbo",
        "Flan-T5-XXL",
        "Cohere command-xlarge-nightly"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Qwen25-Math Technical Report Toward Mathematical Expert Model via Self-Improvement": {
    "filename": "Qwen25-Math Technical Report Toward Mathematical Expert Model via Self-Improvement.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH",
        "GaoKao",
        "AMC23",
        "AIME24",
        "Minerva Math",
        "Olympiad Bench",
        "College Math",
        "MMLU STEM",
        "CMATH",
        "CN Middle School 24"
      ],
      "models": [
        "Qwen2.5-Math",
        "Qwen2.5-Math-Instruct-1.5B",
        "Qwen2.5-Math-Instruct-7B",
        "Qwen2.5-Math-Instruct-72B",
        "Qwen2-Math-Instruct",
        "Qwen2-Math-72B",
        "Qwen2-Math-7B",
        "Qwen2-Math-1.5B",
        "Qwen2.5-Math-1.5B",
        "Qwen2.5-Math-7B",
        "Qwen2.5-Math-72B",
        "GPT-4o",
        "Gemini Math-Specialized 1.5 Pro",
        "DeepSeekMath-Base-7B",
        "DeepSeek-Coder-V2-Lite-Base",
        "Intermln2-Math-Base-20B",
        "Llama-3.1-8B",
        "Llama-3.1-70B",
        "Llama-3.1-405B",
        "NuminaMath-7B-CoT",
        "NuminaMath-72B-CoT",
        "Claude 3 Opus",
        "GPT-4 Turbo",
        "Gemini 1.5 Pro"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Understanding the Effects of Iterative Prompting on Truthfulness": {
    "filename": "Understanding the Effects of Iterative Prompting on Truthfulness.pdf",
    "analysis": {
      "benchmarks": [
        "TruthfulQA"
      ],
      "models": [
        "OpenAI GPT-3.5",
        "gpt-3.5-turbo-16k-0613",
        "Self-Consistency",
        "Universal Self-Consistency",
        "Random selection",
        "Greedy selection",
        "Improved Prompt-1",
        "Improved Prompt-2"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SimLM Can Language Models Infer Parameters of Physical Systems": {
    "filename": "SimLM Can Language Models Infer Parameters of Physical Systems.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "SimLM",
        "LLM",
        "PaLM-2",
        "GPT-3.5-turbo",
        "Llama-2-70b-chat",
        "Llama-2-13b-chat",
        "Llama-2-7b-chat"
      ]
    }
  },
  "ERUPD -- English to Roman Urdu Parallel Dataset": {
    "filename": "ERUPD -- English to Roman Urdu Parallel Dataset.pdf",
    "analysis": {
      "benchmarks": [
        "ERUPD - English to Roman Urdu Parallel Dataset",
        "Roman Urdu Sentiment Analysis Dataset (RUSAD)",
        "Roman Urdu Data Set"
      ],
      "models": [
        "T5-Small",
        "mBART",
        "GPT-3.5",
        "GPT-3.5 Turbo Instruct",
        "Claude Opus"
      ]
    }
  },
  "Natural Language Reasoning A Survey": {
    "filename": "Natural Language Reasoning A Survey.pdf",
    "analysis": {
      "benchmarks": [
        "StrategyQA",
        "CoNLL",
        "CommonGen",
        "Natural Questions",
        "BigBench",
        "StrategyQA",
        "CommonsenseQA",
        "ARC",
        "OpenBookQA",
        "ReClor",
        "LogiQA",
        "ProofWriter",
        "EntailmentBank",
        "RuleTaker",
        "Abductive NLI",
        "PIQA",
        "SocialIQA",
        "Winograd Schema Challenge",
        "Winogrande",
        "HellaSwag",
        "SWAG",
        "COPA",
        "RACE",
        "DROP",
        "HotpotQA",
        "QASC",
        "MultiRC",
        "BoolQ",
        "OpenBookQA",
        "RTE",
        "ANLI",
        "SNLI",
        "MNLI",
        "SciTail",
        "SICK"
      ],
      "models": [
        "BERT",
        "GPT",
        "RoBERTa",
        "T5",
        "ChatGPT",
        "GPT-3",
        "GPT-4",
        "ReasonFormer",
        "ProofWriter",
        "EntailmentBank",
        "RuleTaker",
        "T5-11B",
        "BART-large",
        "T5-large",
        "GPT-2",
        "Gopher",
        "SI",
        "Chain-of-Thought (CoT)",
        "ReasoningNLP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Small Language Model Can Self-correct": {
    "filename": "Small Language Model Can Self-correct.pdf",
    "analysis": {
      "benchmarks": [
        "OpenBookQA",
        "CommonsenseQA",
        "StrategyQA"
      ],
      "models": [
        "CuteGPT-7B",
        "CuteGPT-13B",
        "ChatGLM-6B",
        "Llama2-7B",
        "Vicuna-7B",
        "Vicuna-13B"
      ]
    }
  },
  "Dynamic Clue Bottlenecks Towards Interpretable-by-Design Visual Question Answering": {
    "filename": "Dynamic Clue Bottlenecks Towards Interpretable-by-Design Visual Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "VQA v2",
        "GQA",
        "DCLUB"
      ],
      "models": [
        "Dynamic Clue Bottleneck Model (DCLUB)",
        "BLIP-2",
        "LLaVA-v1.5",
        "LLaMa"
      ]
    }
  },
  "Knowledge Graph Question Answering for Materials Science KGQA4MAT Developing Natural Language Interface for Metal-Organic Frameworks Knowledge Graph MOF-KG": {
    "filename": "Knowledge Graph Question Answering for Materials Science KGQA4MAT Developing Natural Language Interface for Metal-Organic Frameworks Knowledge Graph MOF-KG.pdf",
    "analysis": {
      "benchmarks": [
        "KGQA4MAT",
        "QALD-9"
      ],
      "models": [
        "ChatGPT",
        "SGPT_Q,K",
        "SGPT_Q",
        "Stage I No Noise",
        "GPT-3.5v3"
      ]
    }
  },
  "Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective": {
    "filename": "Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective.pdf",
    "analysis": {
      "benchmarks": [
        "Human Eval",
        "code contests",
        "RULER",
        "BigCodeBench"
      ],
      "models": [
        "Llama 3",
        "Llama-3-8B-Instruct"
      ]
    }
  },
  "SCIENCE IS EXPLORATION Computational Frontiers for Conceptual Metaphor Theory": {
    "filename": "SCIENCE IS EXPLORATION Computational Frontiers for Conceptual Metaphor Theory.pdf",
    "analysis": {
      "benchmarks": [
        "Trope Finder (TroFi) dataset",
        "MWLB dataset"
      ],
      "models": [
        "gpt-3.5-turbo",
        "gpt-4-turbo",
        "gpt-4o"
      ]
    }
  },
  "Prover-Verifier Games improve legibility of LLM outputs": {
    "filename": "Prover-Verifier Games improve legibility of LLM outputs.pdf",
    "analysis": {
      "benchmarks": [
        "grade-school math problems",
        "GSM"
      ],
      "models": [
        "helpful prover",
        "sneaky prover",
        "verifier",
        "GPT-4",
        "baseline: correctness training only",
        "prover initialized with human-written math derivations"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Discrete compositional and symbolic representations through attractor dynamics": {
    "filename": "Discrete compositional and symbolic representations through attractor dynamics.pdf",
    "analysis": {
      "benchmarks": [
        "HBV dataset",
        "dSprites dataset"
      ],
      "models": [
        "neural stochastic dynamical systems model",
        "VQ-VAE",
        "emergent communication model",
        "fully-compositional (FC) baseline",
        "not-compositional (NC) baseline"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Follow the Wisdom of the Crowd Effective Text Generation via Minimum Bayes Risk Decoding": {
    "filename": "Follow the Wisdom of the Crowd Effective Text Generation via Minimum Bayes Risk Decoding.pdf",
    "analysis": {
      "benchmarks": [
        "WebNLG",
        "WMT16",
        "XSUM",
        "CNN",
        "DailyMail",
        "E2E NLG",
        "Czech Restaurants",
        "BIG-Bench",
        "IPA Transliteration",
        "StrategyQA",
        "Tense",
        "Yelp Sentiment",
        "Shakespeare",
        "GYAFC",
        "COCO Captions",
        "Harvard USPTO Patent Dataset (HUPD)"
      ],
      "models": [
        "crowd sampling",
        "Codex",
        "InstructGPT",
        "Pegasus",
        "BART",
        "T-5",
        "BLIP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Applying Large Language Models and Chain-of-Thought for Automatic Scoring": {
    "filename": "Applying Large Language Models and Chain-of-Thought for Automatic Scoring.pdf",
    "analysis": {
      "benchmarks": [
        "R1_2",
        "J2_2",
        "H4_2",
        "H4_3",
        "J6_2",
        "J6_3"
      ],
      "models": [
        "GPT-3.5",
        "GPT-4",
        "FS_noCoT",
        "FS_CoT",
        "FS_CoT_CR",
        "ZS_noCoT",
        "ZS_CoT",
        "ZS_CoT_CR"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SYNERGAI Perception Alignment for Human-Robot Collaboration": {
    "filename": "SYNERGAI Perception Alignment for Human-Robot Collaboration.pdf",
    "analysis": {
      "benchmarks": [
        "ScanQA"
      ],
      "models": [
        "SYNERG AI",
        "VoteNet+MCAN",
        "ScanRefer+MCAN",
        "ScanQA",
        "Flamingo (MultiView)",
        "BLIP2 (MultiView)",
        "3D-LLM (Flamingo)"
      ]
    }
  },
  "IDs for AI Systems": {
    "filename": "IDs for AI Systems.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [],
      "note": "Analysis based on truncated paper text"
    }
  },
  "What It Wants Me To Say Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models": {
    "filename": "What It Wants Me To Say Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Codex",
        "GPT-3",
        "LaMDA",
        "GitHub Copilot"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Lemur Harmonizing Natural Language and Code for Language Agents": {
    "filename": "Lemur Harmonizing Natural Language and Code for Language Agents.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "BBH",
        "GSM8K",
        "HumanEval",
        "MBPP",
        "Spider",
        "MultiPL-E",
        "DS-1000",
        "M-GSM8K",
        "M-MATH",
        "M-TheoremQA",
        "M-HotpotQA",
        "M-MMLU",
        "IC-Bash",
        "IC-SQL",
        "RoboCodeGen",
        "InterCode-CTF",
        "WebArena",
        "ALFWorld",
        "MINT-Reasoning",
        "MINT-Code"
      ],
      "models": [
        "Lemur",
        "Lemur-Chat",
        "Llama-2-70B",
        "Llama-2-70B-Chat",
        "StarCoder-15B",
        "StarCoderPlus-15B",
        "CodeLlama-34B",
        "CodeLlama-34B-INST",
        "WizardCoder-15B",
        "gpt-3.5-turbo",
        "gpt-4",
        "text-bison-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "CharacterGLM Customizing Chinese Conversational AI Characters with Large Language Models": {
    "filename": "CharacterGLM Customizing Chinese Conversational AI Characters with Large Language Models.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "CharacterGLM",
        "ChatGLM",
        "GPT series",
        "BlenderBot",
        "Meena",
        "LaMDA",
        "EVA",
        "Plato",
        "Claude-2",
        "Baichuan2",
        "ChatGLM2",
        "ERNIEBot",
        "GPT-3.5-turbo",
        "GPT-4",
        "MiniMax",
        "Qwen",
        "SparkDesk",
        "Xingchen"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Entailment as Robust Self-Learner": {
    "filename": "Entailment as Robust Self-Learner.pdf",
    "analysis": {
      "benchmarks": [
        "MNLI",
        "RTE",
        "QNLI",
        "QQP",
        "SST2",
        "CoLA",
        "Adv-QNLI",
        "Adv-QQP",
        "Adv-RTE",
        "Adv-SST2",
        "Copa",
        "Emotion Classification",
        "Amazon Review",
        "Ag-News"
      ],
      "models": [
        "Entailment-based language models",
        "SimPLE",
        "RoBERTa",
        "DeBERTa",
        "LM-BFF",
        "PET",
        "P-tuning",
        "PPT",
        "UPT",
        "EFL",
        "LaMDA",
        "FLAN",
        "DeBERTa-Cat",
        "RoBERTa-Sup",
        "DeBERTa-Sup",
        "Baseline-ST",
        "Dropout",
        "SETRED"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Training Chain-of-Thought via Latent-Variable Inference": {
    "filename": "Training Chain-of-Thought via Latent-Variable Inference.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "BIG-Bench Hard"
      ],
      "models": [
        "TRICE",
        "STaR",
        "PaLM 2-M",
        "Flan PaLM 2",
        "GPT-J"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Instruction Backdoor Attacks Against Customized LLMs": {
    "filename": "Instruction Backdoor Attacks Against Customized LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "Stanford Sentiment Treebank (SST-2)",
        "SMS Spam",
        "AGNews",
        "DBPedia",
        "Amazon Product Reviews"
      ],
      "models": [
        "LLaMA2",
        "Mistral",
        "Mixtral",
        "GPT-3.5",
        "GPT-4",
        "Claude-3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LongSafetyBench Long-Context LLMs Struggle with Safety Issues": {
    "filename": "LongSafetyBench Long-Context LLMs Struggle with Safety Issues.pdf",
    "analysis": {
      "benchmarks": [
        "LongSafetyBench",
        "ManyShotJailbreak",
        "SafetyBench",
        "NeedleInAHayStack",
        "RULER",
        "DetectiveQA",
        "USMLE"
      ],
      "models": [
        "Llama3-8b-Instruct",
        "Intern2.5-7b-Chat",
        "GPT-4-turbo",
        "Claude-3.5-sonnet",
        "Gemini-1.5-pro",
        "Qwen2-72b-Instruct",
        "InternLM2.5-7b-chat",
        "Llama3.1-70b-Instruct",
        "Llama3.1-8b-Instruct",
        "Mistral7B-v0.3",
        "Mixtral8x22B-v0.1",
        "GLM-4-7B-Chat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "NELLIE A Neuro-Symbolic Inference Engine for Grounded Compositional and Explainable Reasoning": {
    "filename": "NELLIE A Neuro-Symbolic Inference Engine for Grounded Compositional and Explainable Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "EntailmentBank",
        "WorldTree",
        "OpenBookQA"
      ],
      "models": [
        "NELLIE",
        "Entailer-3B",
        "Entailer-11B",
        "PathNet",
        "TupleILP",
        "ExplanationLP",
        "Diff-Explainer"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "InstructAV Instruction Fine-tuning Large Language Models for Authorship Verification": {
    "filename": "InstructAV Instruction Fine-tuning Large Language Models for Authorship Verification.pdf",
    "analysis": {
      "benchmarks": [
        "IMDB",
        "Twitter",
        "Yelp Reviews"
      ],
      "models": [
        "InstructAV",
        "BERT",
        "DistilBERT",
        "ALBERT",
        "LIP (GPT-4-turbo)",
        "LIP (LLaMA-2-70B)",
        "LIP (Mistral-7B)",
        "InstructAV (LLaMA-1-7B)",
        "InstructAV (OPT-6.7B)",
        "InstructAV (LLaMA-2-7B)",
        "PromptAV-2shot (GPT-3.5)",
        "PromptAV-4shot (GPT-3.5)",
        "PromptAV-8shot (GPT-3.5)",
        "PromptAV (GPT-4-Turbo)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages": {
    "filename": "Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages.pdf",
    "analysis": {
      "benchmarks": [
        "UCLID5 regression tests",
        "UCLID5 GitHub repository regression tests",
        "textbook exercises and examples"
      ],
      "models": [
        "SPEAC",
        "Eudoxus",
        "gpt-3.5-turbo",
        "gpt-4-turbo",
        "fine-tuned GPT3t",
        "few-shot GPT3t",
        "few-shot GPT4t",
        "self-repair GPT3t",
        "self-repair GPT4t"
      ]
    }
  },
  "Compositional Chain-of-Thought Prompting for Large Multimodal Models": {
    "filename": "Compositional Chain-of-Thought Prompting for Large Multimodal Models.pdf",
    "analysis": {
      "benchmarks": [
        "Winoground",
        "WHOOPS!",
        "SEEDBench",
        "MMBench",
        "LLaVA-Bench In-the-Wild"
      ],
      "models": [
        "Compositional Chain-of-Thought (CCoT)",
        "LLaVA-1.5-13B",
        "InstructBLIP-13B",
        "Sphinx",
        "GPT-4V",
        "CLIP",
        "BLIP",
        "BLIP2",
        "SGVL",
        "mPlug-OWL2",
        "QwenVL-Chat",
        "InstructBLIP-13B-ZS-CoT",
        "LLaVA-1.5-13B-ZS-CoT",
        "Sphinx-ZS-CoT",
        "GPT4V-ZS-CoT",
        "MMCoT",
        "LLaVA-1.5-13B-DDCoT",
        "LLaVA-1.5-13B-VidIL",
        "LLaVA-1.5-13B-CCoT",
        "LLaVA-1.5-7B",
        "LLaVA-1.5-7B-CCoT",
        "LLaVA-1.5-13B-Caption-CoT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating vision-capable chatbots in interpreting kinematics graphs a comparative study of free and subscription-based models": {
    "filename": "Evaluating vision-capable chatbots in interpreting kinematics graphs a comparative study of free and subscription-based models.pdf",
    "analysis": {
      "benchmarks": [
        "Test of Understanding Graphs in Kinematics (TUG-K)"
      ],
      "models": [
        "Gemini 1.0 Pro",
        "Claude 3 Sonnet",
        "Microsoft Copilot",
        "ChatGPT-4o",
        "Gemini 1.0 Ultra",
        "Gemini 1.5 Pro API",
        "Claude 3 Opus",
        "ChatGPT-4"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Chain-of-Thought Reasoning Without Prompting": {
    "filename": "Chain-of-Thought Reasoning Without Prompting.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MultiArith",
        "year parity",
        "Big-Bench-Hard",
        "Sports Understanding",
        "Object Counting"
      ],
      "models": [
        "PaLM-2",
        "Mistral-7B",
        "Gemma-7B",
        "CoT-decoding",
        "Self-consistency",
        "Zero-shot CoT prompting"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "How Can LLM Guide RL A Value-Based Approach": {
    "filename": "How Can LLM Guide RL A Value-Based Approach.pdf",
    "analysis": {
      "benchmarks": [
        "ALFWorld",
        "InterCode",
        "BlocksWorld",
        "InterCode-SQL",
        "InterCode-Bash"
      ],
      "models": [
        "LINVIT",
        "SLINVIT",
        "BUTLER",
        "ReAct",
        "AdaPlanner",
        "Reflexion",
        "Plan & Solve",
        "Try Again",
        "RAP"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "The Fact Selection Problem in LLM-Based Program Repair": {
    "filename": "The Fact Selection Problem in LLM-Based Program Repair.pdf",
    "analysis": {
      "benchmarks": [
        "BugsInPy"
      ],
      "models": [
        "MANIPLE",
        "GPT-3.5",
        "Llama3-70B",
        "T0",
        "T1",
        "T2",
        "T3"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Achieving and Understanding Out-of-Distribution Generalization in Systematic Reasoning in Small-Scale Transformers": {
    "filename": "Achieving and Understanding Out-of-Distribution Generalization in Systematic Reasoning in Small-Scale Transformers.pdf",
    "analysis": {
      "benchmarks": [
        "Sudoku"
      ],
      "models": [
        "small scale transformer-based network",
        "3-layer transformer encoder",
        "HS Only",
        "Simultaneous",
        "Curriculum",
        "ALiBi",
        "SRL"
      ]
    }
  },
  "Teaching Algorithmic Reasoning via In-context Learning": {
    "filename": "Teaching Algorithmic Reasoning via In-context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "GSM8k-Hard"
      ],
      "models": [
        "Algorithmic Prompt",
        "Few-shot",
        "Chain-of-thought",
        "Scratchpad",
        "Instruction-only",
        "Codex model code-davinci-002"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Just rephrase it Uncertainty estimation in closed-source language models via multiple rephrased queries": {
    "filename": "Just rephrase it Uncertainty estimation in closed-source language models via multiple rephrased queries.pdf",
    "analysis": {
      "benchmarks": [
        "ARC-Challenge",
        "ARC-Easy",
        "Openbookqa"
      ],
      "models": [
        "Mistral-7B",
        "Llama-2-7B",
        "Llama-2-13B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PokemonChat Auditing ChatGPT for Pok\u00e9mon Universe Knowledge": {
    "filename": "PokemonChat Auditing ChatGPT for Pok\u00e9mon Universe Knowledge.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "ChatGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "On-Policy Distillation of Language Models Learning from Self-Generated Mistakes": {
    "filename": "On-Policy Distillation of Language Models Learning from Self-Generated Mistakes.pdf",
    "analysis": {
      "benchmarks": [
        "XSum",
        "WMT14 en-de",
        "GSM8K",
        "MMLU",
        "BBH"
      ],
      "models": [
        "T5-Small",
        "T5-Base",
        "T5-Large",
        "T5-XL",
        "FLAN T5-XL",
        "FLAN T5-Base",
        "FLAN T5-Large",
        "PaLM",
        "GPT-3 davinci-002"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation": {
    "filename": "Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation.pdf",
    "analysis": {
      "benchmarks": [
        "PARITY",
        "Even Pairs",
        "Modular Arithmetic",
        "Cycle Navigation",
        "D2",
        "D3",
        "D4",
        "D12",
        "Tomita 3",
        "Tomita 4",
        "Tomita 5",
        "Tomita 6",
        "OpenWebText2"
      ],
      "models": [
        "RegularGPT",
        "RNN",
        "Transformer",
        "KERPLE",
        "T5",
        "ALiBi"
      ]
    }
  },
  "Exploring Large Language Models for Feature Selection A Data-centric Perspective": {
    "filename": "Exploring Large Language Models for Feature Selection A Data-centric Perspective.pdf",
    "analysis": {
      "benchmarks": [
        "Adult",
        "Bank",
        "Communities",
        "Credit-g",
        "Heart",
        "Myocardial",
        "Diabetes",
        "NBA",
        "Rideshare",
        "Wine",
        "Lung Adenocarcinoma (LUAD) in The Cancer Genome Atlas (TCGA)"
      ],
      "models": [
        "GPT-4",
        "ChatGPT",
        "LLaMA-2 7B",
        "LLaMA-2 13B",
        "Retrieval-Augmented Feature Selection (RAFS)",
        "Filtering by Mutual Information (MI)",
        "Recursive Feature Elimination (RFE)",
        "Minimum Redundancy Maximum Relevance selection (MRMR)",
        "Random feature selection"
      ]
    }
  },
  "Can MLLMs Perform Text-to-Image In-Context Learning": {
    "filename": "Can MLLMs Perform Text-to-Image In-Context Learning.pdf",
    "analysis": {
      "benchmarks": [
        "CoBSAT",
        "DreamBooth"
      ],
      "models": [
        "Emu",
        "GILL",
        "SEED-LLaMA",
        "Qwen-VL",
        "Gemini",
        "Claude",
        "GPT-4V",
        "Emu2",
        "LLaVA-1.5",
        "LLaVA-NeXT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GPT Models in Construction Industry Opportunities Limitations and a Use Case Validation": {
    "filename": "GPT Models in Construction Industry Opportunities Limitations and a Use Case Validation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "GPT-3.5-turbo",
        "ChatGPT-4",
        "GPT-2",
        "BIM-GPT",
        "RoboGPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "KwaiYiiMath Technical Report": {
    "filename": "KwaiYiiMath Technical Report.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8k",
        "CMath",
        "KMath"
      ],
      "models": [
        "KwaiYiiMath",
        "KwaiYiiBase",
        "GPT-4",
        "ChatGPT",
        "Ernie Bot",
        "Minerva",
        "MATH-QWEN-CHAT",
        "LLaMA-1",
        "LLaMA-2",
        "BaiChuan1",
        "BaiChuan2",
        "WizardMath",
        "ChatGLM2",
        "QWen",
        "GAIRMath-Abel",
        "MetaMath",
        "KwaiYiiMath-HPA"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models": {
    "filename": "Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MultiWOZ 2.1",
        "STARv2",
        "SGD",
        "SpokenWOZ",
        "MELD",
        "MuTual"
      ],
      "models": [
        "Vanilla",
        "Vanilla + 4-shots",
        "Chain-of-Thought",
        "Plan-and-Solve",
        "Self-Explanation",
        "GPT-4"
      ]
    }
  },
  "DreamBench A Human-Aligned Benchmark for Personalized Image Generation": {
    "filename": "DreamBench A Human-Aligned Benchmark for Personalized Image Generation.pdf",
    "analysis": {
      "benchmarks": [
        "DREAM BENCH ++",
        "DreamBench"
      ],
      "models": [
        "Textual Inversion",
        "DreamBooth",
        "DreamBooth LoRA",
        "BLIP-Diffusion",
        "Emu2",
        "IP-Adapter-Plus ViT-H",
        "IP-Adapter ViT-G"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "WebArena A Realistic Web Environment for Building Autonomous Agents": {
    "filename": "WebArena A Realistic Web Environment for Building Autonomous Agents.pdf",
    "analysis": {
      "benchmarks": [
        "WebArena"
      ],
      "models": [
        "GPT-4",
        "GPT-3.5",
        "TEXT-BISON-001"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Prompt Highlighter Interactive Control for Multi-Modal LLMs": {
    "filename": "Prompt Highlighter Interactive Control for Multi-Modal LLMs.pdf",
    "analysis": {
      "benchmarks": [
        "MMBench",
        "MME-perception",
        "MSCOCO"
      ],
      "models": [
        "Prompt Highlighter",
        "LLaVA-v1.5",
        "Vicuna-13B",
        "InstructBLIP-Vicuna-13B",
        "BLIP2",
        "LLaMA",
        "InternLM-VLComposer",
        "QWen-VL-Chat",
        "mPLUG-Owl-2",
        "Sphinx",
        "MMICL",
        "CoCa-CFG",
        "FuseCap"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Predicting Winning Captions for Weekly New Yorker Comics": {
    "filename": "Predicting Winning Captions for Weekly New Yorker Comics.pdf",
    "analysis": {
      "benchmarks": [
        "New Yorker Caption Contest dataset"
      ],
      "models": [
        "CLIP-GPT2",
        "LLaVA-NeXT",
        "GPT-4V"
      ]
    }
  },
  "Two Heads Are Better Than One A Multi-Agent System Has the Potential to Improve Scientific Idea Generation": {
    "filename": "Two Heads Are Better Than One A Multi-Agent System Has the Potential to Improve Scientific Idea Generation.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "VIRSCI",
        "AI Scientist",
        "GPT-4o",
        "Llama-3.1 (8b)",
        "Llama-3.1 (70b)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Task Facet Learning A Structured Approach to Prompt Optimization": {
    "filename": "Task Facet Learning A Structured Approach to Prompt Optimization.pdf",
    "analysis": {
      "benchmarks": [
        "Ethos",
        "ARC",
        "MedQA",
        "GSM8K",
        "SciQ"
      ],
      "models": [
        "UNIPROMPT",
        "MedPrompt",
        "ProTeGi",
        "Evoke",
        "EvoPrompt",
        "OPRO",
        "Chain-Of-Thought (CoT)",
        "Expert Prompt",
        "Task Description"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Few-Shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt": {
    "filename": "Few-Shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt.pdf",
    "analysis": {
      "benchmarks": [
        "CIFAR100",
        "CUB200-2011",
        "ImageNet-R"
      ],
      "models": [
        "ASP",
        "iCaRL",
        "Foster",
        "CEC",
        "FACT",
        "TEEN",
        "L2P",
        "DualP",
        "CodaP",
        "L2P+",
        "DualP+",
        "CodaP+"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "ZeroGen Efficient Zero-shot Learning via Dataset Generation": {
    "filename": "ZeroGen Efficient Zero-shot Learning via Dataset Generation.pdf",
    "analysis": {
      "benchmarks": [
        "IMDb",
        "SST-2",
        "SQuAD",
        "AdversarialQA",
        "QNLI",
        "RTE"
      ],
      "models": [
        "ZEROGEN",
        "TAM",
        "LSTM",
        "DistilBERT",
        "GPT2",
        "GPT2-large",
        "GPT2-XL",
        "PROMPTING",
        "BiLSTM",
        "BiDAF",
        "RoBERTa-Large",
        "OPT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "HFT Half Fine-Tuning for Large Language Models": {
    "filename": "HFT Half Fine-Tuning for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "MMLU",
        "GSM8K",
        "BBH",
        "TyDiQA",
        "TruthfulQA",
        "HumanEval",
        "NaturalQuestion",
        "TriviaQA",
        "HotpotQA"
      ],
      "models": [
        "LLAMA 2-7B",
        "LLAMA 2-CHAT-7B",
        "Half-Reset",
        "LLAMA 2-13B",
        "LLAMA 2-7B-SFT",
        "LLAMA 2-7B-SFT (R)",
        "LLAMA 2-7B-SFT (H)",
        "LLAMA 2-13B-SFT",
        "LLAMA 2-13B-SFT (R)",
        "LLAMA 2-13B-SFT (H)",
        "LLAMA 2-7B-DPO",
        "LLAMA 2-7B-DPO (R)",
        "LLAMA 2-7B-DPO (H)",
        "LLAMA 2-13B-DPO",
        "LLAMA 2-13B-DPO (R)",
        "LLAMA 2-13B-DPO (H)",
        "SeqFT",
        "GEM",
        "Replay",
        "LoraSeqFT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks": {
    "filename": "Characterizing and Evaluating the Reliability of LLMs against Jailbreak Attacks.pdf",
    "analysis": {
      "benchmarks": [
        "AdvBench",
        "MultiJail",
        "SimpleSafetyTests",
        "MM-SafetyBench",
        "MaliciousInstruct",
        "BeaverTails-Evaluation",
        "Verazuo-jailbreak-llms",
        "Xstest"
      ],
      "models": [
        "GPT-3.5-turbo",
        "GPT-4-0125-preview",
        "LLaMA2-7B-chat",
        "LLaMA2-13B-chat",
        "Vicuna-7B-v1.5",
        "Vicuna-13B-v1.5",
        "Mistral-7B-v0.1",
        "Mistral-7B-v0.2",
        "Baichuan2-7B-chat",
        "Baichuan2-13B-chat",
        "Gemma-2B-it",
        "Gemma-7B-it",
        "Llama-3-8B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Evaluating the Instruction-following Abilities of Language Models using Knowledge Tasks": {
    "filename": "Evaluating the Instruction-following Abilities of Language Models using Knowledge Tasks.pdf",
    "analysis": {
      "benchmarks": [
        "MMLUPro",
        "MathQA",
        "Winogrande",
        "BoolQ",
        "PIQA"
      ],
      "models": [
        "GPT-4o-mini",
        "GPT-4o",
        "Llama-3.2-1B-Instruct",
        "Qwen2.5-1.5B-Instruct",
        "Llama-3.2-3B-Instruct",
        "Phi-3.5-mini-instruct",
        "Mistral-7B-Instruct-v0.3",
        "Qwen2.5-7B-Instruct",
        "Phi-3-small-8k-instruct",
        "Llama-3.1-8B-Instruct",
        "Gemma-2-9b-it",
        "Phi-3-medium-4k-instruct",
        "Qwen2.5-14B-Instruct",
        "Gemma-2-27b-it",
        "Qwen2.5-32B-Instruct",
        "Llama-3.1-70B-Instruct",
        "Qwen2.5-72B-Instruct",
        "Llama-3.1-405B-Instruct"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Multi-Agent Collaboration Harnessing the Power of Intelligent LLM Agents": {
    "filename": "Multi-Agent Collaboration Harnessing the Power of Intelligent LLM Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "Auto-GPT",
        "BabyAGI",
        "Gorilla",
        "GPT-4",
        "GPT-3.5-turbo"
      ]
    }
  },
  "Foundation Models Meet Visualizations Challenges and Opportunities": {
    "filename": "Foundation Models Meet Visualizations Challenges and Opportunities.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "BERT",
        "GPT",
        "InternImage",
        "CLIP",
        "T5",
        "Vision Transformer",
        "Longformer",
        "DeepNLPVis",
        "SliceTeller",
        "CommonsenseVIS",
        "PromptIDE",
        "ScatterShot",
        "PromptMagician",
        "AIChains",
        "Talebrush",
        "Neo",
        "LegalVis",
        "Teddy",
        "ADVISor",
        "Data Player",
        "ChartSpark",
        "DataTales",
        "AutoTitle",
        "Erato",
        "MetaGlyph",
        "ShortCutLens",
        "DataDebugger",
        "Attention Flows",
        "AttentionViz"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "FederatedScope-LLM A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning": {
    "filename": "FederatedScope-LLM A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning.pdf",
    "analysis": {
      "benchmarks": [
        "Fed-CodeAlpaca",
        "Fed-Dolly",
        "Fed-GSM8K-3",
        "HumanEval",
        "HELM",
        "GSM8K-test"
      ],
      "models": [
        "LLaMA-7B",
        "OPT-2.7B",
        "LoRA",
        "P-tuning",
        "Prompt tuning",
        "FedOT",
        "pFedMe",
        "FedAvg"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Hello Again LLM-powered Personalized Agent for Long-term Dialogue": {
    "filename": "Hello Again LLM-powered Personalized Agent for Long-term Dialogue.pdf",
    "analysis": {
      "benchmarks": [
        "MSC",
        "Conversation Chronicles (CC)",
        "Ubuntu IRC"
      ],
      "models": [
        "LD-Agent",
        "ChatGLM",
        "ChatGPT",
        "BlenderBot",
        "BART",
        "HAHT"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Enhancing Language Model Rationality with Bi-Directional Deliberation Reasoning": {
    "filename": "Enhancing Language Model Rationality with Bi-Directional Deliberation Reasoning.pdf",
    "analysis": {
      "benchmarks": [
        "Limit Texas Hold\u2019em",
        "Negotiation"
      ],
      "models": [
        "BIDDER",
        "Random",
        "Rule",
        "Counterfactual Regret Minimization (CFR)",
        "Deep Q-Network (DQN)",
        "Deep Monte Carlo (DMC)",
        "Deep CFR",
        "Direct",
        "Chain-of-Thought (CoT)",
        "Reflexion",
        "Monte Carlo Tree Search (MCTS)",
        "Tree of Thoughts (ToT)"
      ]
    }
  },
  "IDEAL Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models": {
    "filename": "IDEAL Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SST-5",
        "DBpedia",
        "MWoZ",
        "Xsum",
        "GeoQuery",
        "MRPC",
        "MNLI",
        "RTE",
        "HellaSwag",
        "IMDb",
        "BoolQ",
        "BoolQ Contrast Set"
      ],
      "models": [
        "IDEAL",
        "Vote-k",
        "GPT-J 6B",
        "Text-devinci-002",
        "GPT-Neo 2.7B",
        "GPT-3.5-Turbo",
        "Random"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "VACoDe Visual Augmented Contrastive Decoding": {
    "filename": "VACoDe Visual Augmented Contrastive Decoding.pdf",
    "analysis": {
      "benchmarks": [
        "MME",
        "MMBench",
        "VQAv2"
      ],
      "models": [
        "VACoDe",
        "LLaVA-1.5",
        "InstructBLIP",
        "Qwen-VL",
        "VCD",
        "Single (color)",
        "Single (edge)",
        "Single (sharp)",
        "Single (crop)",
        "Single (erase)",
        "Single (flip)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "GPT-Connect Interaction between Text-Driven Human Motion Generator and 3D Scenes in a Training-free Manner": {
    "filename": "GPT-Connect Interaction between Text-Driven Human Motion Generator and 3D Scenes in a Training-free Manner.pdf",
    "analysis": {
      "benchmarks": [
        "HUMANISE"
      ],
      "models": [
        "GPT-Connect",
        "ChatGPT",
        "motion diffusion model",
        "baseline A",
        "baseline B",
        "Wang et al. [35]"
      ]
    }
  },
  "What if LLMs Have Different World Views Simulating Alien Civilizations with LLM-based Agents": {
    "filename": "What if LLMs Have Different World Views Simulating Alien Civilizations with LLM-based Agents.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "CosmoAgent",
        "Secretary Agent"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "diff History for Neural Language Agents": {
    "filename": "diff History for Neural Language Agents.pdf",
    "analysis": {
      "benchmarks": [
        "NetHack",
        "BabyAI-Text"
      ],
      "models": [
        "diff history",
        "full-text history",
        "GPT-2-127M",
        "LSTM (CDGPT5)",
        "Transformer",
        "XL-LSTM (CDGPT5)"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Lean Workbook A large-scale Lean problem set formalized from natural language math problems": {
    "filename": "Lean Workbook A large-scale Lean problem set formalized from natural language math problems.pdf",
    "analysis": {
      "benchmarks": [
        "MiniF2F",
        "Mathlib",
        "ProofNet",
        "Compfiles",
        "IMO"
      ],
      "models": [
        "autoformalization model",
        "InternLM-Math-Plus-20B",
        "Qwen-1.5-14B-Chat",
        "InternLM-Math-Plus",
        "DeepSeek-prover"
      ]
    }
  },
  "Inverse Scaling When Bigger Isnt Better": {
    "filename": "Inverse Scaling When Bigger Isnt Better.pdf",
    "analysis": {
      "benchmarks": [
        "Inverse Scaling Prize",
        "LAMBADA",
        "OpenBookQA",
        "TruthfulQA"
      ],
      "models": [
        "GPT-2",
        "GPT-3",
        "GPT-3 FeedME",
        "GPT-4",
        "GPT-4 RLHF",
        "OPT",
        "Anthropic LM",
        "Anthropic Context Distilled",
        "Anthropic RLHF",
        "Chinchilla",
        "Gopher",
        "PaLM"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Building Math Agents with Multi-Turn Iterative Preference Learning": {
    "filename": "Building Math Agents with Multi-Turn Iterative Preference Learning.pdf",
    "analysis": {
      "benchmarks": [
        "GSM8K",
        "MATH"
      ],
      "models": [
        "Gemma-1.1-it-7B",
        "Gemma-2-it-9B",
        "Gemma",
        "CodeGemma",
        "Mistral",
        "multi-turn DPO",
        "multi-turn KTO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models": {
    "filename": "A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "ASDiv-A",
        "MAWPS",
        "SVAMP"
      ],
      "models": [
        "GPT-2 Distilled",
        "GPT-2 Small",
        "GPT-2 Medium",
        "GPT-2 Large",
        "GPT-2 XL",
        "GPT-Neo 1.3B",
        "GPT-Neo 2.7B",
        "GPT-J-6B",
        "GPT-NeoX-20B",
        "GPT-3 Instruct",
        "GPT-3 Curie",
        "GPT-3 Davinci-002",
        "GPT-3 Davinci-003",
        "LLaMA 7B",
        "LLaMA 13B",
        "LLaMA 30B",
        "Stanford Alpaca"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Mind the Labels Describing Relations in Knowledge Graphs With Pretrained Models": {
    "filename": "Mind the Labels Describing Relations in Knowledge Graphs With Pretrained Models.pdf",
    "analysis": {
      "benchmarks": [
        "REL2TEXT",
        "WebNLG",
        "KELM",
        "INFOTABS"
      ],
      "models": [
        "BART",
        "full-rel2text",
        "full-webnlg",
        "full-kelm",
        "fewshot-25",
        "fewshot-50",
        "fewshot-100",
        "fewshot-200",
        "mask-test",
        "mask-train",
        "mask-all",
        "desc-repl",
        "desc-cat"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "SORRY-Bench Systematically Evaluating Large Language Model Safety Refusal Behaviors": {
    "filename": "SORRY-Bench Systematically Evaluating Large Language Model Safety Refusal Behaviors.pdf",
    "analysis": {
      "benchmarks": [
        "SORRY-Bench",
        "AdvBench",
        "Harmbench",
        "FFT",
        "XSTest",
        "Do-not-answer",
        "ToxicChat",
        "JailbreakBench",
        "ALERT",
        "SALAD-Bench"
      ],
      "models": [
        "GPT-4",
        "Claude-2",
        "Gemini-1.5",
        "Mistral",
        "Llama-3",
        "Llama-2",
        "GPT-3.5-turbo",
        "Gemma",
        "Vicuna",
        "OpenChat",
        "Bert-Base-Cased",
        "Llama-Guard-2-8B",
        "MD-Judge",
        "Perspective API"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Cyber Sentinel Exploring Conversational Agents in Streamlining Security Tasks with GPT-4": {
    "filename": "Cyber Sentinel Exploring Conversational Agents in Streamlining Security Tasks with GPT-4.pdf",
    "analysis": {
      "benchmarks": [
        "Cyber Threat Intelligence (CTI) feed",
        "Open Source Intelligence (OSINT) frameworks and feeds",
        "Elasticsearch database"
      ],
      "models": [
        "Cyber Sentinel",
        "GPT-4",
        "Wazuh"
      ]
    }
  },
  "Multi-Task Program Error Repair and Explanatory Diagnosis": {
    "filename": "Multi-Task Program Error Repair and Explanatory Diagnosis.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "mPRED",
        "DeepFix",
        "DrRepair",
        "DEAR",
        "Codex",
        "PaLM-Coder",
        "AlphaCode"
      ]
    }
  },
  "A Survey on Transformer Compression": {
    "filename": "A Survey on Transformer Compression.pdf",
    "analysis": {
      "benchmarks": [
        "ImageNet",
        "GLUE",
        "SQuAD2",
        "MNLI-m",
        "SST-2",
        "QNLI",
        "CoLA",
        "RTE",
        "MRPC",
        "QQP",
        "WikiText2"
      ],
      "models": [
        "GPT-3",
        "GPT-4",
        "BERT",
        "DistilBERT",
        "MiniLM",
        "MobileBERT",
        "TinyBERT",
        "LLaMA",
        "ViT",
        "DeiT",
        "TinyViT",
        "CLIP",
        "BLIP",
        "LLaVA",
        "PaLM",
        "RetNet",
        "Reformer",
        "Swin",
        "MetaFormer",
        "MLP-Mixer",
        "SmoothQuant",
        "OmniQuant",
        "QLoRA",
        "PTQ-ViT",
        "FQ-ViT",
        "OFQ",
        "LLM Pruner",
        "Sheared LLaMA",
        "Dynamic Context Pruning",
        "ViT-Slim",
        "Patch Sliming",
        "X-pruner",
        "Lion",
        "ManifoldKD",
        "GPTQ",
        "AWQ",
        "Zeroquant",
        "Outlier Suppression",
        "MREM",
        "SignRound",
        "SqueezeLLM",
        "RPTQ",
        "CBQ",
        "PEQA",
        "I-ViT",
        "Q-ViT",
        "AFQ-ViT",
        "Quantformer",
        "VVTQ"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "LLMmap Fingerprinting For Large Language Models": {
    "filename": "LLMmap Fingerprinting For Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "SQuAD 2.0"
      ],
      "models": [
        "LLMmap",
        "ChatGPT",
        "Claude",
        "Phi-3-medium-128k-instruct",
        "Phi-3-medium-4k-instruct",
        "aya-23-35B",
        "aya-23-8B",
        "DeciLM-7B-instruct",
        "zephyr-7b-beta",
        "Nous-Hermes-2-Mixtral-8x7B-DPO",
        "Qwen2-1.5B-Instruct",
        "Qwen2-72B-Instruct",
        "Qwen2-7B-Instruct",
        "Smaug-Llama-3-70B-Instruct",
        "claude-3-5-sonnet-20240620",
        "claude-3-haiku-20240307",
        "claude-3-opus-20240229",
        "gemma-1.1-2b-it",
        "gemma-1.1-7b-it",
        "gemma-2-27b-it",
        "gemma-2-9b-it",
        "gemma-2b-it",
        "gemma-7b-it",
        "gpt-3.5-turbo",
        "gpt-4-turbo-2024-04-09",
        "gpt-4o-2024-05-13",
        "Llama-3-8B-Instruct-Gradient-1048k",
        "internlm2_5-7b-chat",
        "Llama-2-7b-chat-hf",
        "Meta-Llama-3-70B-Instruct",
        "Meta-Llama-3-8B-Instruct",
        "Meta-Llama-3.1-70B-Instruct",
        "Meta-Llama-3.1-8B-Instruct",
        "Phi-3-mini-128k-instruct",
        "Phi-3-mini-4k-instruct",
        "Phi-3.5-MoE-instruct",
        "Mistral-7B-Instruct-v0.1",
        "Mistral-7B-Instruct-v0.2",
        "Mistral-7B-Instruct-v0.3",
        "Mixtral-8x7B-Instruct-v0.1",
        "Llama3-ChatQA-1.5-8B",
        "openchat-3.6-8b-20240522",
        "openchat_3.5",
        "Llama-2-7B-32K-Instruct",
        "SOLAR-10.7B-Instruct-v1.0"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Context Generation Improves Open Domain Question Answering": {
    "filename": "Context Generation Improves Open Domain Question Answering.pdf",
    "analysis": {
      "benchmarks": [
        "Natural Questions",
        "WebQuestions",
        "TriviaQA"
      ],
      "models": [
        "CGAP",
        "LM-530B",
        "T5-11B",
        "T5-11B+SSM",
        "BART-large, pre-finetuned on PAQ",
        "RAG",
        "Fusion-in-Decoder",
        "OBPoE_Google"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification": {
    "filename": "A Simple and Effective Framework for Strict Zero-Shot Hierarchical Classification.pdf",
    "analysis": {
      "benchmarks": [
        "Web of Science (WOS)",
        "Amazon Beauty"
      ],
      "models": [
        "BART-MNLI",
        "T0pp",
        "BART-MNLI + T0pp",
        "BART-MNLI + T0pp (Primed)",
        "BART-MNLI + T0pp (Primed+)"
      ]
    }
  },
  "A Survey on Human Preference Learning for Large Language Models": {
    "filename": "A Survey on Human Preference Learning for Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Koala",
        "Vicuna-bench",
        "HH-RLHF",
        "SELF-INSTRUCT",
        "AlpacaFarm",
        "MT-bench",
        "MMLU",
        "AGIEval",
        "SUP-NATINST",
        "Big-Bench-Hard",
        "TruthfulQA",
        "HumanEval",
        "GSM8K",
        "IMDb",
        "Reddit TL;DR",
        "CNN/DailyMail"
      ],
      "models": [
        "InstructGPT",
        "Llama-2-Chat",
        "UltraRM",
        "Safe RLHF",
        "Constitutional AI",
        "SteerLM",
        "RAFT",
        "SuperHF",
        "IFT",
        "OpenChat",
        "TS-LLM",
        "NLHF",
        "ReMax",
        "DPO",
        "f-DPO",
        "\u03a8PO",
        "KTO",
        "ULMA",
        "ORPO"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Ask and it shall be given Turing completeness of prompting": {
    "filename": "Ask and it shall be given Turing completeness of prompting.pdf",
    "analysis": {
      "benchmarks": [],
      "models": [
        "finite-size Transformer",
        "2-PTMs",
        "decoder-only Transformer",
        "ReLU neural networks"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "PlantoGraphy Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering": {
    "filename": "PlantoGraphy Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering.pdf",
    "analysis": {
      "benchmarks": [
        "vegetation dataset",
        "randomly generated landscape renderings",
        "expert generated landscape renderings"
      ],
      "models": [
        "PlantoGraphy",
        "Stable Diffusion",
        "DALL-E-2",
        "latent diffusion model",
        "LoRA model",
        "GLIGEN",
        "SAM",
        "DDIM inversion",
        "GPT-3.5",
        "GPT-4.0"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Gorilla Large Language Model Connected with Massive APIs": {
    "filename": "Gorilla Large Language Model Connected with Massive APIs.pdf",
    "analysis": {
      "benchmarks": [
        "APIBench"
      ],
      "models": [
        "Gorilla",
        "GPT-4",
        "Claude",
        "GPT-3.5-turbo",
        "LLaMA-7B"
      ],
      "note": "Analysis based on truncated paper text"
    }
  },
  "Id Like to Have an Argument Please Argumentative Reasoning in Large Language Models": {
    "filename": "Id Like to Have an Argument Please Argumentative Reasoning in Large Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "Review-Rebuttal Submission-v2 (RRv2)"
      ],
      "models": [
        "GPT-3",
        "GPT-4",
        "TEXT-DAVINCI-003",
        "MLMC",
        "MRC-APE"
      ]
    }
  },
  "Simple Techniques for Enhancing Sentence Embeddings in Generative Language Models": {
    "filename": "Simple Techniques for Enhancing Sentence Embeddings in Generative Language Models.pdf",
    "analysis": {
      "benchmarks": [
        "STS-12",
        "STS-13",
        "STS-14",
        "STS-15",
        "STS-16",
        "STS-B",
        "SICK-R"
      ],
      "models": [
        "GPT",
        "OPT",
        "LLaMA",
        "BERT",
        "RoBERTa",
        "SimCSE",
        "PromptEOL",
        "AnglE",
        "DeeLM",
        "QLoRA",
        "MetaEOL",
        "CoT-BERT",
        "Mistral",
        "Sentence-BERT",
        "ESimCSE",
        "PromptBERT",
        "SSCL",
        "ST5-Enc",
        "Pretended CoT",
        "Knowledge Enhancement"
      ]
    }
  }
}