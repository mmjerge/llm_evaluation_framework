You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.53s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  2.83s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.00s/it]
